{"step": 1008, "time": 147.6414921283722, "episode/length": 125.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 1384, "time": 150.30728006362915, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 1552, "time": 152.15492033958435, "episode/length": 193.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 153.54707026481628, "episode/length": 194.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 153.55524468421936, "episode/length": 194.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 166.66457867622375, "eval_episode/length": 100.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9504950495049505}
{"step": 1560, "time": 169.05023384094238, "eval_episode/length": 144.0, "eval_episode/score": 2.099999964237213, "eval_episode/reward_rate": 0.9586206896551724}
{"step": 1560, "time": 170.79216957092285, "eval_episode/length": 159.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.99375}
{"step": 1560, "time": 172.34236907958984, "eval_episode/length": 164.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 1560, "time": 174.44526028633118, "eval_episode/length": 193.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 1560, "time": 175.8632197380066, "train_stats/sum_log_reward": 1.0999999776482583, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/max_log_achievement_collect_sapling": 0.5, "train_stats/max_log_achievement_place_plant": 0.5, "train_stats/max_log_achievement_collect_wood": 2.0, "eval_stats/sum_log_reward": 0.8999999850988388, "eval_stats/max_log_achievement_collect_sapling": 0.4, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_place_plant": 0.2, "eval_stats/max_log_achievement_wake_up": 1.8, "eval_stats/max_log_achievement_defeat_zombie": 0.25}
{"step": 1560, "time": 214.3719654083252, "eval_episode/length": 127.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9609375}
{"step": 1560, "time": 216.30056142807007, "eval_episode/length": 137.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 1560, "time": 218.25713539123535, "eval_episode/length": 144.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.993103448275862}
{"step": 1560, "time": 220.22779250144958, "eval_episode/length": 153.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.974025974025974}
{"step": 1560, "time": 222.10992074012756, "eval_episode/length": 162.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 1560, "time": 224.38330340385437, "eval_episode/length": 178.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.994413407821229}
{"step": 1560, "time": 226.0629894733429, "eval_episode/length": 183.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.967391304347826}
{"step": 1560, "time": 229.61653852462769, "eval_episode/length": 102.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9611650485436893}
{"step": 1561, "time": 349.2111783027649, "eval_stats/sum_log_reward": 0.8499999837949872, "eval_stats/max_log_achievement_collect_sapling": 0.25, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/max_log_achievement_collect_drink": 0.2, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.74761962890625, "train/action_min": 0.0, "train/action_std": 4.797914028167725, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00047899773926474154, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -4.591313362121582, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9970703125, "train/cont_loss_mean": 0.4769323468208313, "train/cont_loss_std": 0.22999975085258484, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 1.5596575736999512, "train/cont_pos_acc": 0.8560234904289246, "train/cont_pos_loss": 0.4737509787082672, "train/cont_pred": 0.6374149322509766, "train/cont_rate": 0.9970703125, "train/dyn_loss_mean": 10.478861808776855, "train/dyn_loss_std": 0.4460660219192505, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 16.311317443847656, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 64215.5078125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3610.10107421875, "train/image_loss_std": 221.10353088378906, "train/model_loss_mean": 3622.40673828125, "train/model_loss_std": 221.2020263671875, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 36224068.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.801159381866455, "train/policy_entropy_max": 2.801159381866455, "train/policy_entropy_mean": 2.638672113418579, "train/policy_entropy_min": 1.9297809600830078, "train/policy_entropy_std": 0.08254116028547287, "train/policy_logprob_mag": 5.451395034790039, "train/policy_logprob_max": -0.6982101798057556, "train/policy_logprob_mean": -2.636704921722412, "train/policy_logprob_min": -5.451395034790039, "train/policy_logprob_std": 0.614057183265686, "train/policy_randomness_mag": 0.9886863231658936, "train/policy_randomness_max": 0.9886863231658936, "train/policy_randomness_mean": 0.93133544921875, "train/policy_randomness_min": 0.6811279654502869, "train/policy_randomness_std": 0.02913340926170349, "train/post_ent_mag": 106.32559204101562, "train/post_ent_max": 106.32559204101562, "train/post_ent_mean": 105.68470764160156, "train/post_ent_min": 104.88716888427734, "train/post_ent_std": 0.2364959418773651, "train/prior_ent_mag": 107.17752075195312, "train/prior_ent_max": 107.17752075195312, "train/prior_ent_mean": 105.9881820678711, "train/prior_ent_min": 105.06814575195312, "train/prior_ent_std": 0.29374393820762634, "train/rep_loss_mean": 10.478861808776855, "train/rep_loss_std": 0.4460660219192505, "train/reward_avg": 0.01249999925494194, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263103485107, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.015625, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.49908506870269775, "report/cont_loss_std": 0.23863531649112701, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 1.3558968305587769, "report/cont_pos_acc": 0.8178256154060364, "report/cont_pos_loss": 0.4965674579143524, "report/cont_pred": 0.6245961785316467, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 10.559135437011719, "report/dyn_loss_std": 0.4676792025566101, "report/image_loss_mean": 3610.705322265625, "report/image_loss_std": 216.48049926757812, "report/model_loss_mean": 3623.0810546875, "report/model_loss_std": 216.66172790527344, "report/post_ent_mag": 106.29051208496094, "report/post_ent_max": 106.29051208496094, "report/post_ent_mean": 105.6588363647461, "report/post_ent_min": 104.79095458984375, "report/post_ent_std": 0.24730703234672546, "report/prior_ent_mag": 106.65078735351562, "report/prior_ent_max": 106.65078735351562, "report/prior_ent_mean": 105.94500732421875, "report/prior_ent_min": 104.97261047363281, "report/prior_ent_std": 0.3014996647834778, "report/rep_loss_mean": 10.559135437011719, "report/rep_loss_std": 0.4676792025566101, "report/reward_avg": 0.01249999925494194, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263103485107, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.4893653392791748, "eval/cont_loss_std": 0.23936423659324646, "eval/cont_neg_acc": 0.3333333432674408, "eval/cont_neg_loss": 0.8478186130523682, "eval/cont_pos_acc": 0.8148873448371887, "eval/cont_pos_loss": 0.4883120656013489, "eval/cont_pred": 0.6297423839569092, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 10.584622383117676, "eval/dyn_loss_std": 0.42218002676963806, "eval/image_loss_mean": 3740.723876953125, "eval/image_loss_std": 190.5315399169922, "eval/model_loss_mean": 3753.105224609375, "eval/model_loss_std": 190.64596557617188, "eval/post_ent_mag": 106.19914245605469, "eval/post_ent_max": 106.19914245605469, "eval/post_ent_mean": 105.63473510742188, "eval/post_ent_min": 104.95124053955078, "eval/post_ent_std": 0.19344282150268555, "eval/prior_ent_mag": 106.680908203125, "eval/prior_ent_max": 106.680908203125, "eval/prior_ent_mean": 105.97187042236328, "eval/prior_ent_min": 104.91067504882812, "eval/prior_ent_std": 0.27106258273124695, "eval/rep_loss_mean": 10.584622383117676, "eval/rep_loss_std": 0.42218002676963806, "eval/reward_avg": 0.01318359375, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.542561656417092e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541263103485107, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.015625, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.6398326112283438e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.131776537214006e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2904.0, "eval_replay/inserts": 2904.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 2.6358224800467165e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.579317910330637e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 215.6015567779541, "timer/env.step_count": 196.0, "timer/env.step_total": 23.13925838470459, "timer/env.step_frac": 0.10732417117254622, "timer/env.step_avg": 0.11805744073828872, "timer/env.step_min": 0.019585371017456055, "timer/env.step_max": 11.09631085395813, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.08925867080688477, "timer/replay._sample_frac": 0.00041399826671386877, "timer/replay._sample_avg": 0.000796952417918614, "timer/replay._sample_min": 0.0004267692565917969, "timer/replay._sample_max": 0.005549192428588867, "timer/agent.save_count": 1.0, "timer/agent.save_total": 8.895768880844116, "timer/agent.save_frac": 0.0412602256393064, "timer/agent.save_avg": 8.895768880844116, "timer/agent.save_min": 8.895768880844116, "timer/agent.save_max": 8.895768880844116, "timer/agent.policy_count": 232.0, "timer/agent.policy_total": 22.60378336906433, "timer/agent.policy_frac": 0.10484053875521754, "timer/agent.policy_avg": 0.09743010072872557, "timer/agent.policy_min": 0.009804010391235352, "timer/agent.policy_max": 16.73570418357849, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.600120544433594e-05, "timer/dataset_train_frac": 1.6698026666576077e-07, "timer/dataset_train_avg": 3.600120544433594e-05, "timer/dataset_train_min": 3.600120544433594e-05, "timer/dataset_train_max": 3.600120544433594e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 91.03825402259827, "timer/agent.train_frac": 0.4222523036619706, "timer/agent.train_avg": 91.03825402259827, "timer/agent.train_min": 91.03825402259827, "timer/agent.train_max": 91.03825402259827, "timer/agent.report_count": 2.0, "timer/agent.report_total": 22.921516180038452, "timer/agent.report_frac": 0.10631424245069387, "timer/agent.report_avg": 11.460758090019226, "timer/agent.report_min": 0.24424219131469727, "timer/agent.report_max": 22.677273988723755, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.910064697265625e-05, "timer/dataset_eval_frac": 1.8135605121314414e-07, "timer/dataset_eval_avg": 3.910064697265625e-05, "timer/dataset_eval_min": 3.910064697265625e-05, "timer/dataset_eval_max": 3.910064697265625e-05}
{"step": 1696, "time": 353.7234904766083, "episode/length": 211.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1696, "time": 353.73302388191223, "episode/length": 211.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 1776, "time": 359.7816324234009, "episode/length": 221.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 2104, "time": 372.0495421886444, "episode/length": 89.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 2168, "time": 375.82761430740356, "episode/length": 58.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.0}
{"step": 2544, "time": 390.22404289245605, "episode/length": 191.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 2544, "time": 390.2323188781738, "episode/length": 123.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 2776, "time": 401.07226967811584, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 2944, "time": 408.4604649543762, "episode/length": 172.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 3024, "time": 412.7640676498413, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 3248, "time": 421.9172852039337, "episode/length": 142.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 3600, "time": 435.2530779838562, "episode/length": 227.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 3992, "time": 449.81397104263306, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 3992, "time": 449.83749556541443, "episode/length": 180.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 4096, "time": 456.9395453929901, "episode/length": 143.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 4144, "time": 460.17444705963135, "episode/length": 170.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 4192, "time": 463.3442680835724, "episode/length": 252.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.0}
{"step": 4640, "time": 480.02630639076233, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 4664, "time": 482.25215220451355, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 5000, "time": 494.99595618247986, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 5160, "time": 501.98442935943604, "episode/length": 61.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 5352, "time": 510.05803203582764, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 5376, "time": 512.6676535606384, "episode/length": 172.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 5648, "time": 523.4382927417755, "episode/length": 125.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 5680, "time": 526.0031433105469, "episode/length": 197.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 5936, "time": 536.0890445709229, "episode/length": 223.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 6208, "time": 547.0475881099701, "episode/length": 150.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9470198675496688, "episode/intrinsic_return": 0.0}
{"step": 6344, "time": 553.0207436084747, "episode/length": 50.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 6440, "time": 558.4037978649139, "episode/length": 280.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9857651245551602, "episode/intrinsic_return": 0.0}
{"step": 6672, "time": 568.7766320705414, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 6768, "time": 573.4494543075562, "episode/length": 173.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 6896, "time": 579.3410818576813, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 6928, "time": 581.9855785369873, "episode/length": 31.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 7456, "time": 601.4149734973907, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 7568, "time": 606.7951357364655, "episode/length": 276.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 7584, "time": 608.8712494373322, "episode/length": 237.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 7728, "time": 615.2601482868195, "episode/length": 172.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 7928, "time": 623.3959276676178, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 8056, "time": 629.9251384735107, "episode/length": 140.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 8072, "time": 632.4796669483185, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 8176, "time": 638.3922002315521, "episode/length": 159.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 8848, "time": 664.5598394870758, "episode/length": 159.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 8864, "time": 667.1457147598267, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 9056, "time": 675.5202262401581, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 9448, "time": 690.0954940319061, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 9472, "time": 692.6411025524139, "episode/length": 192.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 9544, "time": 696.5221965312958, "episode/length": 226.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.986784140969163, "episode/intrinsic_return": 0.0}
{"step": 9600, "time": 700.1763849258423, "episode/length": 177.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 9704, "time": 704.9894282817841, "episode/length": 80.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9259259259259259, "episode/intrinsic_return": 0.0}
{"step": 9904, "time": 713.5234122276306, "episode/length": 230.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 9968, "time": 717.4017522335052, "episode/length": 45.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9130434782608695, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 741.065497636795, "eval_episode/length": 127.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.96875}
{"step": 10088, "time": 743.5235555171967, "eval_episode/length": 149.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 10088, "time": 745.8553743362427, "eval_episode/length": 167.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 10088, "time": 747.8511869907379, "eval_episode/length": 175.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 10088, "time": 749.7206981182098, "eval_episode/length": 182.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 10088, "time": 752.5210511684418, "eval_episode/length": 211.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 10088, "time": 755.3513097763062, "eval_episode/length": 241.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.987603305785124}
{"step": 10088, "time": 758.6945171356201, "eval_episode/length": 282.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9929328621908127}
{"step": 10384, "time": 768.7410943508148, "episode/length": 191.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 10384, "time": 768.7490146160126, "episode/length": 84.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 10400, "time": 772.7090857028961, "episode/length": 106.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 10608, "time": 781.3441779613495, "episode/length": 217.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 10848, "time": 790.8537685871124, "episode/length": 174.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 11024, "time": 798.3276610374451, "episode/length": 193.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 11472, "time": 815.9442639350891, "episode/length": 135.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9485294117647058, "episode/intrinsic_return": 0.0}
{"step": 11648, "time": 823.9833612442017, "episode/length": 157.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 11672, "time": 826.1406447887421, "episode/length": 220.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 11696, "time": 828.7891824245453, "episode/length": 161.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 11760, "time": 832.5192692279816, "episode/length": 223.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 12208, "time": 849.113648891449, "episode/length": 169.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 12376, "time": 856.1060538291931, "episode/length": 220.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9864253393665159, "episode/intrinsic_return": 0.0}
{"step": 12456, "time": 860.3500406742096, "episode/length": 178.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 12656, "time": 868.7798566818237, "episode/length": 122.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967479674796748, "episode/intrinsic_return": 0.0}
{"step": 12888, "time": 877.8593020439148, "episode/length": 53.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9074074074074074, "episode/intrinsic_return": 0.0}
{"step": 12912, "time": 880.3915274143219, "episode/length": 151.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 12912, "time": 880.4018094539642, "episode/length": 179.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 13160, "time": 891.8132269382477, "episode/length": 174.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 13624, "time": 908.8857357501984, "episode/length": 246.0, "episode/score": 3.0999999567866325, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 13816, "time": 917.6842045783997, "episode/length": 200.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 13984, "time": 925.6175534725189, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 14048, "time": 929.4345533847809, "episode/length": 208.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 14136, "time": 933.6681287288666, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 14160, "time": 936.2964453697205, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 14400, "time": 945.8579120635986, "episode/length": 96.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9484536082474226, "episode/intrinsic_return": 0.0}
{"step": 14408, "time": 947.5356862545013, "episode/length": 155.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 14512, "time": 952.7558903694153, "episode/length": 199.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 15008, "time": 970.9716246128082, "episode/length": 148.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 15312, "time": 982.6253750324249, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 15368, "time": 985.7488148212433, "episode/length": 164.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 15464, "time": 990.7408735752106, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 15592, "time": 996.6194248199463, "episode/length": 178.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 15736, "time": 1002.8710205554962, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 15856, "time": 1008.6648471355438, "episode/length": 167.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 15872, "time": 1010.9269170761108, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 16128, "time": 1021.1530287265778, "episode/length": 139.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 16496, "time": 1036.0159051418304, "episode/length": 94.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 16824, "time": 1048.4516398906708, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 16928, "time": 1053.6238644123077, "episode/length": 133.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9477611940298507, "episode/intrinsic_return": 0.0}
{"step": 17000, "time": 1057.3997745513916, "episode/length": 203.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 17000, "time": 1057.4088900089264, "episode/length": 210.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 17096, "time": 1063.950483083725, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 17128, "time": 1066.6185626983643, "episode/length": 124.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 17224, "time": 1071.356704235077, "episode/length": 219.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 17480, "time": 1081.5470144748688, "episode/length": 59.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 18216, "time": 1107.7107889652252, "episode/length": 173.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 18248, "time": 1110.2655084133148, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 18248, "time": 1110.274435043335, "episode/length": 218.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 18424, "time": 1119.3638920783997, "episode/length": 161.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 18576, "time": 1126.293817281723, "episode/length": 168.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 18736, "time": 1133.1663963794708, "episode/length": 156.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 18808, "time": 1136.9443664550781, "episode/length": 213.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 18952, "time": 1143.3932423591614, "episode/length": 243.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9877049180327869, "episode/intrinsic_return": 0.0}
{"step": 19448, "time": 1161.6921241283417, "episode/length": 149.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 19584, "time": 1168.7201640605927, "episode/length": 166.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 19704, "time": 1174.7013120651245, "episode/length": 140.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 19768, "time": 1179.0846576690674, "episode/length": 167.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 19872, "time": 1184.837819814682, "episode/length": 206.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 1209.1963477134705, "eval_episode/length": 67.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9264705882352942}
{"step": 20072, "time": 1213.1637110710144, "eval_episode/length": 55.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9107142857142857}
{"step": 20072, "time": 1215.5925459861755, "eval_episode/length": 145.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.952054794520548}
{"step": 20072, "time": 1217.4504618644714, "eval_episode/length": 150.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 20072, "time": 1220.1904232501984, "eval_episode/length": 178.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 20072, "time": 1221.9460155963898, "eval_episode/length": 183.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 20072, "time": 1224.2887654304504, "eval_episode/length": 200.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 20072, "time": 1226.4136958122253, "eval_episode/length": 86.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9425287356321839}
{"step": 20104, "time": 1227.497308731079, "episode/length": 170.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 20160, "time": 1231.1426606178284, "episode/length": 150.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 20288, "time": 1237.0792515277863, "episode/length": 184.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 20600, "time": 1248.9341187477112, "episode/length": 61.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9354838709677419, "episode/intrinsic_return": 0.0}
{"step": 20656, "time": 1252.551662683487, "episode/length": 133.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 20952, "time": 1263.8035762310028, "episode/length": 187.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 21168, "time": 1272.8546631336212, "episode/length": 182.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 21184, "time": 1274.8843686580658, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 21184, "time": 1274.893431186676, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 21240, "time": 1279.8835945129395, "episode/length": 79.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 21600, "time": 1293.7387444972992, "episode/length": 53.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9074074074074074, "episode/intrinsic_return": 0.0}
{"step": 21800, "time": 1301.737018585205, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 21888, "time": 1306.523772239685, "episode/length": 215.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 21960, "time": 1310.2646601200104, "episode/length": 96.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9381443298969072, "episode/intrinsic_return": 0.0}
{"step": 22152, "time": 1318.3333735466003, "episode/length": 68.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9420289855072463, "episode/intrinsic_return": 0.0}
{"step": 22160, "time": 1320.4315133094788, "episode/length": 187.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 22289, "time": 1326.8068776130676, "train_stats/sum_log_reward": 0.9730158416288239, "train_stats/max_log_achievement_collect_drink": 2.4444444444444446, "train_stats/max_log_achievement_collect_sapling": 9.507936507936508, "train_stats/max_log_achievement_collect_wood": 0.1984126984126984, "train_stats/max_log_achievement_defeat_zombie": 0.16666666666666666, "train_stats/max_log_achievement_place_plant": 0.2857142857142857, "train_stats/max_log_achievement_wake_up": 0.5158730158730159, "train_stats/mean_log_entropy": 0.8943804761483556, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.060594662215358, "train/action_min": 0.0, "train/action_std": 2.110670116520667, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01589031992281621, "train/actor_opt_grad_steps": 650.0, "train/actor_opt_loss": 234.50265134489814, "train/adv_mag": 2.419501776059786, "train/adv_max": 2.419501776059786, "train/adv_mean": 0.04115732588652745, "train/adv_min": -0.3263288955284281, "train/adv_std": 0.1854801864490498, "train/cont_avg": 0.9944131540697675, "train/cont_loss_mean": 0.028131871375926706, "train/cont_loss_std": 0.2702282206841217, "train/cont_neg_acc": 0.051291990765305454, "train/cont_neg_loss": 3.43644626288451, "train/cont_pos_acc": 0.9983155963032745, "train/cont_pos_loss": 0.00912290436212089, "train/cont_pred": 0.9915746358013893, "train/cont_rate": 0.9944131540697675, "train/dyn_loss_mean": 5.608763251193734, "train/dyn_loss_std": 7.961635235437127, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.55990894820339, "train/extr_critic_critic_opt_grad_steps": 650.0, "train/extr_critic_critic_opt_loss": 22618.844340479653, "train/extr_critic_mag": 0.3566358070964961, "train/extr_critic_max": 0.3566358061723931, "train/extr_critic_mean": 0.1184946558334385, "train/extr_critic_min": -0.04314136505126953, "train/extr_critic_std": 0.10954091082750494, "train/extr_return_normed_mag": 2.7920067150546455, "train/extr_return_normed_max": 2.7920067150546455, "train/extr_return_normed_mean": 0.22588505448914284, "train/extr_return_normed_min": -0.1623638924650077, "train/extr_return_normed_std": 0.2429828588235329, "train/extr_return_rate": 0.08387940468414608, "train/extr_return_raw_mag": 2.944692529156775, "train/extr_return_raw_max": 2.944692529156775, "train/extr_return_raw_mean": 0.16699086273334515, "train/extr_return_raw_min": -0.2753007691397554, "train/extr_return_raw_std": 0.2747167294669911, "train/extr_reward_mag": 0.5951281268467274, "train/extr_reward_max": 0.5951281268467274, "train/extr_reward_mean": 0.009916163375914208, "train/extr_reward_min": -0.052375844282697336, "train/extr_reward_std": 0.04564478958326126, "train/image_loss_mean": 101.62556288963141, "train/image_loss_std": 51.77315621782643, "train/model_loss_mean": 105.34943979839946, "train/model_loss_std": 53.38617612409961, "train/model_opt_grad_norm": 385.63306113546207, "train/model_opt_grad_steps": 641.0, "train/model_opt_loss": 2186.747968333636, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 23.921996124031008, "train/policy_entropy_mag": 1.1621196536246197, "train/policy_entropy_max": 1.1621196536246197, "train/policy_entropy_mean": 0.8488554843058882, "train/policy_entropy_min": 0.6713248843601508, "train/policy_entropy_std": 0.07479571751607654, "train/policy_logprob_mag": 6.766497042752052, "train/policy_logprob_max": -0.300144398469449, "train/policy_logprob_mean": -0.8497889078287191, "train/policy_logprob_min": -6.766497042752052, "train/policy_logprob_std": 0.801745894343354, "train/policy_randomness_mag": 0.4101772388342277, "train/policy_randomness_max": 0.4101772388342277, "train/policy_randomness_mean": 0.29960873282637246, "train/policy_randomness_min": 0.2369482239000788, "train/policy_randomness_std": 0.02639960594495123, "train/post_ent_mag": 53.78695622525474, "train/post_ent_max": 53.78695622525474, "train/post_ent_mean": 34.37114300099454, "train/post_ent_min": 17.615979268569355, "train/post_ent_std": 6.969649663960287, "train/prior_ent_mag": 58.99744137313015, "train/prior_ent_max": 58.99744137313015, "train/prior_ent_mean": 40.617214321166045, "train/prior_ent_min": 22.438245196675144, "train/prior_ent_std": 6.448504720720672, "train/rep_loss_mean": 5.608763251193734, "train/rep_loss_std": 7.961635235437127, "train/reward_avg": 0.007870790910502795, "train/reward_loss_mean": 0.3304860932073852, "train/reward_loss_std": 0.671628244110208, "train/reward_max_data": 1.0170542676319447, "train/reward_max_pred": 0.6943052896233493, "train/reward_neg_acc": 0.9967397520708483, "train/reward_neg_loss": 0.29314051265286845, "train/reward_pos_acc": 0.4640204010083694, "train/reward_pos_loss": 3.1132860793623816, "train/reward_pred": 0.005522397719504124, "train/reward_rate": 0.012733163759689923, "train_stats/max_log_achievement_place_table": 0.026785714285714284, "train_stats/max_log_achievement_make_wood_sword": 0.01098901098901099, "train_stats/max_log_achievement_eat_cow": 0.21951219512195122, "eval_stats/sum_log_reward": 0.8499999879859388, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 17.3125, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.0625, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.013692989945411682, "report/cont_loss_std": 0.1643880307674408, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.537034034729004, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003797534154728055, "report/cont_pred": 0.9960014820098877, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 7.108532905578613, "report/dyn_loss_std": 5.930163860321045, "report/image_loss_mean": 31.79808235168457, "report/image_loss_std": 27.37832260131836, "report/model_loss_mean": 36.19795227050781, "report/model_loss_std": 28.799209594726562, "report/post_ent_mag": 48.851112365722656, "report/post_ent_max": 48.851112365722656, "report/post_ent_mean": 32.04130554199219, "report/post_ent_min": 16.212907791137695, "report/post_ent_std": 4.382021903991699, "report/prior_ent_mag": 56.31288146972656, "report/prior_ent_max": 56.31288146972656, "report/prior_ent_mean": 38.63664245605469, "report/prior_ent_min": 20.42679214477539, "report/prior_ent_std": 4.959433078765869, "report/rep_loss_mean": 7.108532905578613, "report/rep_loss_std": 5.930163860321045, "report/reward_avg": 0.01083984412252903, "report/reward_loss_mean": 0.12105697393417358, "report/reward_loss_std": 0.5152102708816528, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9860378503799438, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.09545613080263138, "report/reward_pos_acc": 0.75, "report/reward_pos_loss": 1.733911156654358, "report/reward_pred": 0.006580133456736803, "report/reward_rate": 0.015625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.013077560812234879, "eval/cont_loss_std": 0.26074033975601196, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.30493450164795, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004972127731889486, "eval/cont_pred": 0.9954072833061218, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 8.890031814575195, "eval/dyn_loss_std": 6.8253865242004395, "eval/image_loss_mean": 62.68950653076172, "eval/image_loss_std": 64.65016174316406, "eval/model_loss_mean": 68.19912719726562, "eval/model_loss_std": 66.44222259521484, "eval/post_ent_mag": 48.9132080078125, "eval/post_ent_max": 48.9132080078125, "eval/post_ent_mean": 32.579689025878906, "eval/post_ent_min": 14.4339017868042, "eval/post_ent_std": 6.401544094085693, "eval/prior_ent_mag": 57.69280242919922, "eval/prior_ent_max": 57.69280242919922, "eval/prior_ent_mean": 38.285255432128906, "eval/prior_ent_min": 18.759119033813477, "eval/prior_ent_std": 7.4581499099731445, "eval/rep_loss_mean": 8.890031814575195, "eval/rep_loss_std": 6.8253865242004395, "eval/reward_avg": 0.01406249962747097, "eval/reward_loss_mean": 0.1625289022922516, "eval/reward_loss_std": 0.861120879650116, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.986535906791687, "eval/reward_neg_acc": 0.9940416812896729, "eval/reward_neg_loss": 0.09542708843946457, "eval/reward_pos_acc": 0.47058823704719543, "eval/reward_pos_loss": 4.137324810028076, "eval/reward_pred": 0.009114316664636135, "eval/reward_rate": 0.0166015625, "replay/size": 21785.0, "replay/inserts": 20728.0, "replay/samples": 20720.0, "replay/insert_wait_avg": 1.4748641396525835e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.074229888474159e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6856.0, "eval_replay/inserts": 3952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3303056902248367e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 977.5870289802551, "timer/env.step_count": 2591.0, "timer/env.step_total": 276.3144283294678, "timer/env.step_frac": 0.28264944208363535, "timer/env.step_avg": 0.10664393219971739, "timer/env.step_min": 0.022400856018066406, "timer/env.step_max": 3.454674243927002, "timer/replay._sample_count": 20720.0, "timer/replay._sample_total": 11.124707698822021, "timer/replay._sample_frac": 0.011379761974160475, "timer/replay._sample_avg": 0.00053690674222114, "timer/replay._sample_min": 0.0003790855407714844, "timer/replay._sample_max": 0.012059926986694336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3085.0, "timer/agent.policy_total": 51.56327724456787, "timer/agent.policy_frac": 0.052745459704344466, "timer/agent.policy_avg": 0.0167141903548032, "timer/agent.policy_min": 0.009659767150878906, "timer/agent.policy_max": 0.10890078544616699, "timer/dataset_train_count": 1295.0, "timer/dataset_train_total": 0.144639253616333, "timer/dataset_train_frac": 0.0001479553731059727, "timer/dataset_train_avg": 0.00011169054333307568, "timer/dataset_train_min": 7.62939453125e-05, "timer/dataset_train_max": 0.0010695457458496094, "timer/agent.train_count": 1295.0, "timer/agent.train_total": 583.6661586761475, "timer/agent.train_frac": 0.597047773112317, "timer/agent.train_avg": 0.4507074584371795, "timer/agent.train_min": 0.4355125427246094, "timer/agent.train_max": 1.3098385334014893, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47610902786254883, "timer/agent.report_frac": 0.00048702469831170915, "timer/agent.report_avg": 0.23805451393127441, "timer/agent.report_min": 0.23089003562927246, "timer/agent.report_max": 0.24521899223327637, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.268055799894891e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 21.202985410906624}
{"step": 22696, "time": 1340.469942331314, "episode/length": 181.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 22704, "time": 1342.4496676921844, "episode/length": 189.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 22784, "time": 1346.6539058685303, "episode/length": 228.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 22960, "time": 1354.0519795417786, "episode/length": 32.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 23096, "time": 1360.0329859256744, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 23344, "time": 1370.362122297287, "episode/length": 181.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 23384, "time": 1373.580890417099, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 23448, "time": 1377.9670267105103, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 23672, "time": 1387.050198316574, "episode/length": 188.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 24072, "time": 1401.935596704483, "episode/length": 49.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 24368, "time": 1413.8518192768097, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 24384, "time": 1415.9835436344147, "episode/length": 199.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 24456, "time": 1419.7142159938812, "episode/length": 186.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 24560, "time": 1424.9492988586426, "episode/length": 146.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 24688, "time": 1431.9870162010193, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 24696, "time": 1433.6404576301575, "episode/length": 248.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 24856, "time": 1440.5765771865845, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 24888, "time": 1443.2275383472443, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 25296, "time": 1458.758299589157, "episode/length": 54.0, "episode/score": 0.09999996423721313, "episode/reward_rate": 0.9272727272727272, "episode/intrinsic_return": 0.0}
{"step": 25328, "time": 1461.4649279117584, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 25448, "time": 1466.8444383144379, "episode/length": 132.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 25656, "time": 1475.3470437526703, "episode/length": 149.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 25848, "time": 1483.2558381557465, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 25976, "time": 1489.1620750427246, "episode/length": 159.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 26000, "time": 1491.6705915927887, "episode/length": 138.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 26088, "time": 1496.101089000702, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 26448, "time": 1510.377299785614, "episode/length": 139.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 26976, "time": 1530.635008096695, "episode/length": 209.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 27144, "time": 1537.6773443222046, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 27184, "time": 1540.7028822898865, "episode/length": 216.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9631336405529954, "episode/intrinsic_return": 0.0}
{"step": 27616, "time": 1556.8566176891327, "episode/length": 190.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 27664, "time": 1560.663110256195, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 27784, "time": 1566.5786955356598, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 27912, "time": 1572.796550989151, "episode/length": 257.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 27976, "time": 1576.5201511383057, "episode/length": 246.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 28008, "time": 1579.2039601802826, "episode/length": 102.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.0}
{"step": 28080, "time": 1583.4632964134216, "episode/length": 137.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 28584, "time": 1601.754248380661, "episode/length": 71.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 28944, "time": 1615.8576250076294, "episode/length": 165.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 29144, "time": 1624.0777900218964, "episode/length": 169.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 29248, "time": 1629.3476400375366, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 29320, "time": 1633.1011793613434, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 29432, "time": 1638.3984303474426, "episode/length": 285.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 29536, "time": 1643.7421534061432, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 29568, "time": 1646.6332700252533, "episode/length": 206.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9903381642512077, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1680.7928075790405, "eval_episode/length": 81.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.926829268292683}
{"step": 30056, "time": 1685.0020747184753, "eval_episode/length": 116.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9572649572649573}
{"step": 30056, "time": 1687.3134739398956, "eval_episode/length": 134.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9925925925925926}
{"step": 30056, "time": 1690.9756705760956, "eval_episode/length": 176.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 30056, "time": 1694.614634513855, "eval_episode/length": 210.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 30056, "time": 1697.47811961174, "eval_episode/length": 224.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 30056, "time": 1699.6601326465607, "eval_episode/length": 229.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 30056, "time": 1704.294573545456, "eval_episode/length": 201.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 30144, "time": 1707.6444149017334, "episode/length": 194.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 30248, "time": 1713.059927225113, "episode/length": 137.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 30280, "time": 1716.146432876587, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 30280, "time": 1716.161273241043, "episode/length": 128.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 30840, "time": 1739.1894118785858, "episode/length": 189.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 30944, "time": 1744.4664652347565, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 31080, "time": 1750.4355387687683, "episode/length": 188.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 31112, "time": 1753.0448188781738, "episode/length": 209.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 31416, "time": 1764.7354006767273, "episode/length": 145.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 31512, "time": 1769.6290271282196, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 31608, "time": 1774.3487372398376, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 31864, "time": 1784.408314704895, "episode/length": 197.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 32248, "time": 1798.9985134601593, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 32280, "time": 1801.5476114749908, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 32336, "time": 1805.3015704154968, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 32576, "time": 1814.9550602436066, "episode/length": 182.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 32744, "time": 1822.0138504505157, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 33056, "time": 1835.5557074546814, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 33200, "time": 1841.9606108665466, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 33272, "time": 1845.8683018684387, "episode/length": 231.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 33600, "time": 1858.7045574188232, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 33664, "time": 1862.3816199302673, "episode/length": 165.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 33688, "time": 1864.4839177131653, "episode/length": 138.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 33816, "time": 1870.2705886363983, "episode/length": 195.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 33912, "time": 1874.9470286369324, "episode/length": 30.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.0}
{"step": 34304, "time": 1890.0097181797028, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 34544, "time": 1899.6082060337067, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 34544, "time": 1899.6169302463531, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 34752, "time": 1909.8983056545258, "episode/length": 211.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 35160, "time": 1924.9579892158508, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 35336, "time": 1932.7447502613068, "episode/length": 205.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 35416, "time": 1936.929613351822, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 35912, "time": 1955.1368298530579, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 36016, "time": 1960.4602246284485, "episode/length": 213.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 36184, "time": 1967.3886115550995, "episode/length": 204.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 36416, "time": 1977.0457134246826, "episode/length": 156.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 36464, "time": 1980.254676580429, "episode/length": 140.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 36904, "time": 1996.1845412254333, "episode/length": 268.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 36976, "time": 2000.3812239170074, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 37216, "time": 2010.030072927475, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 37248, "time": 2012.688381433487, "episode/length": 428.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9976689976689976, "episode/intrinsic_return": 0.0}
{"step": 37384, "time": 2018.5232865810394, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 37552, "time": 2025.8744912147522, "episode/length": 170.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 37880, "time": 2038.264859676361, "episode/length": 176.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 37960, "time": 2042.4162273406982, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 38208, "time": 2052.47420668602, "episode/length": 81.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9390243902439024, "episode/intrinsic_return": 0.0}
{"step": 38432, "time": 2061.4999170303345, "episode/length": 190.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 38488, "time": 2064.727130651474, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 38504, "time": 2066.9854741096497, "episode/length": 139.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 38552, "time": 2070.097068786621, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 38584, "time": 2072.7654383182526, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 39320, "time": 2099.1318686008453, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 39376, "time": 2103.2435002326965, "episode/length": 117.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9491525423728814, "episode/intrinsic_return": 0.0}
{"step": 39416, "time": 2105.9937353134155, "episode/length": 181.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 39704, "time": 2118.088730573654, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 39728, "time": 2120.564578771591, "episode/length": 154.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 39856, "time": 2126.438318490982, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 39864, "time": 2128.033666610718, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 2150.940047264099, "eval_episode/length": 65.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9242424242424242}
{"step": 40040, "time": 2155.6181075572968, "eval_episode/length": 140.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 40040, "time": 2158.3531017303467, "eval_episode/length": 97.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9489795918367347}
{"step": 40040, "time": 2160.523168563843, "eval_episode/length": 175.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 40040, "time": 2162.102616548538, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 40040, "time": 2163.864633321762, "eval_episode/length": 181.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 40040, "time": 2165.517171859741, "eval_episode/length": 182.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.994535519125683}
{"step": 40040, "time": 2167.1416664123535, "eval_episode/length": 184.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 40288, "time": 2175.640102624893, "episode/length": 212.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 40296, "time": 2177.1337192058563, "episode/length": 121.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9590163934426229, "episode/intrinsic_return": 0.0}
{"step": 40512, "time": 2186.0366911888123, "episode/length": 141.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 40560, "time": 2189.3085763454437, "episode/length": 33.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8529411764705882, "episode/intrinsic_return": 0.0}
{"step": 40616, "time": 2192.5286676883698, "episode/length": 149.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 41160, "time": 2213.2846698760986, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 41200, "time": 2216.529107093811, "episode/length": 186.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 41320, "time": 2221.9017996788025, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 41880, "time": 2242.1619322299957, "episode/length": 164.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 41936, "time": 2245.734726667404, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 41944, "time": 2247.5278804302216, "episode/length": 165.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 41976, "time": 2250.2741692066193, "episode/length": 209.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 42032, "time": 2253.7905180454254, "episode/length": 270.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.988929889298893, "episode/intrinsic_return": 0.0}
{"step": 42296, "time": 2263.852659702301, "episode/length": 39.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 42304, "time": 2265.8102395534515, "episode/length": 137.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 42472, "time": 2272.774593114853, "episode/length": 143.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 42696, "time": 2281.915902376175, "episode/length": 191.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 42720, "time": 2284.4552063941956, "episode/length": 85.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 43376, "time": 2307.8669517040253, "episode/length": 134.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 43424, "time": 2311.054660797119, "episode/length": 185.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 43480, "time": 2314.308431625366, "episode/length": 146.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 43656, "time": 2321.727687597275, "episode/length": 221.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 43656, "time": 2321.736864566803, "episode/length": 213.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 43689, "time": 2327.1072158813477, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.243324849142957, "train/action_min": 0.0, "train/action_std": 3.229780079713508, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03705592532711687, "train/actor_opt_grad_steps": 1965.0, "train/actor_opt_loss": 26.386508575126307, "train/adv_mag": 1.4028329944877482, "train/adv_max": 1.3997418589111585, "train/adv_mean": 0.01890720337178209, "train/adv_min": -0.529006549226704, "train/adv_std": 0.12643114441255135, "train/cont_avg": 0.9943009561567164, "train/cont_loss_mean": 0.00467535805247864, "train/cont_loss_std": 0.06726627279665502, "train/cont_neg_acc": 0.8001184625856912, "train/cont_neg_loss": 0.539263157898492, "train/cont_pos_acc": 0.999618680174671, "train/cont_pos_loss": 0.001652033591053216, "train/cont_pred": 0.9942039331393455, "train/cont_rate": 0.9943009561567164, "train/dyn_loss_mean": 7.357609428576569, "train/dyn_loss_std": 6.486428961825015, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.544581350105912, "train/extr_critic_critic_opt_grad_steps": 1965.0, "train/extr_critic_critic_opt_loss": 18610.4599609375, "train/extr_critic_mag": 2.089827688772287, "train/extr_critic_max": 2.089827688772287, "train/extr_critic_mean": 0.5822413475878203, "train/extr_critic_min": -0.3479132554424343, "train/extr_critic_std": 0.8125892210362563, "train/extr_return_normed_mag": 2.1430440927619365, "train/extr_return_normed_max": 2.1430440927619365, "train/extr_return_normed_mean": 0.3709582598574126, "train/extr_return_normed_min": -0.19741754371450462, "train/extr_return_normed_std": 0.35500613188565666, "train/extr_return_rate": 0.440119735674182, "train/extr_return_raw_mag": 5.306559304692852, "train/extr_return_raw_max": 5.306559304692852, "train/extr_return_raw_mean": 0.6305385505530372, "train/extr_return_raw_min": -0.856669383040115, "train/extr_return_raw_std": 0.94039372855158, "train/extr_reward_mag": 0.9885568698840355, "train/extr_reward_max": 0.9885568698840355, "train/extr_reward_mean": 0.01538415604645435, "train/extr_reward_min": -0.38730750866790314, "train/extr_reward_std": 0.09814687451319908, "train/image_loss_mean": 27.018163453287155, "train/image_loss_std": 26.799731624660208, "train/model_loss_mean": 31.52681910102047, "train/model_loss_std": 28.86484860662204, "train/model_opt_grad_norm": 163.42464219278364, "train/model_opt_grad_steps": 1956.0, "train/model_opt_loss": 1737.6038535957905, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 57.13619402985075, "train/policy_entropy_mag": 2.2238684634664168, "train/policy_entropy_max": 2.2238684634664168, "train/policy_entropy_mean": 0.5387690470957044, "train/policy_entropy_min": 0.07953251520199563, "train/policy_entropy_std": 0.4458610640088124, "train/policy_logprob_mag": 7.437799635218151, "train/policy_logprob_max": -0.009477666176077145, "train/policy_logprob_mean": -0.5390228810372637, "train/policy_logprob_min": -7.437799635218151, "train/policy_logprob_std": 1.1003902567856347, "train/policy_randomness_mag": 0.7849279722171043, "train/policy_randomness_max": 0.7849279722171043, "train/policy_randomness_mean": 0.19016182978651416, "train/policy_randomness_min": 0.02807148765605777, "train/policy_randomness_std": 0.15736938918482013, "train/post_ent_mag": 46.83576444369643, "train/post_ent_max": 46.83576444369643, "train/post_ent_mean": 31.88340952858996, "train/post_ent_min": 15.785663562034493, "train/post_ent_std": 4.8265706852300845, "train/prior_ent_mag": 57.55278407993601, "train/prior_ent_max": 57.55278407993601, "train/prior_ent_mean": 39.556963820955644, "train/prior_ent_min": 21.617086538627966, "train/prior_ent_std": 5.729452974760711, "train/rep_loss_mean": 7.357609428576569, "train/rep_loss_std": 6.486428961825015, "train/reward_avg": 0.007723589008152763, "train/reward_loss_mean": 0.08941455972172431, "train/reward_loss_std": 0.4093143500721277, "train/reward_max_data": 1.005223881842485, "train/reward_max_pred": 0.9887058797167309, "train/reward_neg_acc": 0.9951170656218458, "train/reward_neg_loss": 0.07040623918787312, "train/reward_pos_acc": 0.823885341856017, "train/reward_pos_loss": 1.5472693287614565, "train/reward_pred": 0.006548565844553453, "train/reward_rate": 0.012935809235074628, "train_stats/sum_log_reward": 2.2984126264613773, "train_stats/max_log_achievement_collect_drink": 21.841269841269842, "train_stats/max_log_achievement_collect_sapling": 1.992063492063492, "train_stats/max_log_achievement_collect_wood": 0.746031746031746, "train_stats/max_log_achievement_defeat_zombie": 0.07142857142857142, "train_stats/max_log_achievement_eat_cow": 0.06349206349206349, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.1507936507936507, "train_stats/max_log_achievement_place_table": 0.015873015873015872, "train_stats/max_log_achievement_wake_up": 2.2063492063492065, "train_stats/mean_log_entropy": 0.5017247646455727, "eval_stats/sum_log_reward": 2.5999999195337296, "eval_stats/max_log_achievement_collect_drink": 9.0625, "eval_stats/max_log_achievement_collect_sapling": 3.0625, "eval_stats/max_log_achievement_collect_wood": 0.625, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 2.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.218878423969727e-05, "report/cont_loss_std": 0.00016920952475629747, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0022631962783634663, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.5746604630257934e-06, "report/cont_pred": 0.997071385383606, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 7.068840980529785, "report/dyn_loss_std": 6.624670028686523, "report/image_loss_mean": 17.064971923828125, "report/image_loss_std": 14.529802322387695, "report/model_loss_mean": 21.355335235595703, "report/model_loss_std": 17.056562423706055, "report/post_ent_mag": 42.894744873046875, "report/post_ent_max": 42.894744873046875, "report/post_ent_mean": 31.893028259277344, "report/post_ent_min": 13.885071754455566, "report/post_ent_std": 4.860568523406982, "report/prior_ent_mag": 53.80079650878906, "report/prior_ent_max": 53.80079650878906, "report/prior_ent_mean": 39.034820556640625, "report/prior_ent_min": 17.505199432373047, "report/prior_ent_std": 5.937691688537598, "report/rep_loss_mean": 7.068840980529785, "report/rep_loss_std": 6.624670028686523, "report/reward_avg": 0.01220703125, "report/reward_loss_mean": 0.04904799535870552, "report/reward_loss_std": 0.33262547850608826, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9931528568267822, "report/reward_neg_acc": 0.9980159401893616, "report/reward_neg_loss": 0.026117822155356407, "report/reward_pos_acc": 0.875, "report/reward_pos_loss": 1.4936490058898926, "report/reward_pred": 0.009322313591837883, "report/reward_rate": 0.015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.006508301943540573, "eval/cont_loss_std": 0.15192729234695435, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00036766016273759305, "eval/cont_pos_acc": 0.9980410933494568, "eval/cont_pos_loss": 0.006526344921439886, "eval/cont_pred": 0.9948433637619019, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 12.268863677978516, "eval/dyn_loss_std": 6.899323463439941, "eval/image_loss_mean": 60.969505310058594, "eval/image_loss_std": 50.1306037902832, "eval/model_loss_mean": 68.53125, "eval/model_loss_std": 51.7969970703125, "eval/post_ent_mag": 44.18376922607422, "eval/post_ent_max": 44.18376922607422, "eval/post_ent_mean": 32.81959533691406, "eval/post_ent_min": 15.54891586303711, "eval/post_ent_std": 5.014019012451172, "eval/prior_ent_mag": 53.80079650878906, "eval/prior_ent_max": 53.80079650878906, "eval/prior_ent_mean": 41.57476806640625, "eval/prior_ent_min": 17.222270965576172, "eval/prior_ent_std": 5.914038181304932, "eval/rep_loss_mean": 12.268863677978516, "eval/rep_loss_std": 6.899323463439941, "eval/reward_avg": 0.014648436568677425, "eval/reward_loss_mean": 0.19392052292823792, "eval/reward_loss_std": 0.9544156789779663, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9950448274612427, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.11587740480899811, "eval/reward_pos_acc": 0.3684210479259491, "eval/reward_pos_loss": 4.321991443634033, "eval/reward_pred": 0.0019767521880567074, "eval/reward_rate": 0.0185546875, "replay/size": 43185.0, "replay/inserts": 21400.0, "replay/samples": 21408.0, "replay/insert_wait_avg": 1.3982358379898784e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0758794298442847e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10608.0, "eval_replay/inserts": 3752.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3043758457403448e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.6540288925170898e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.288357257843, "timer/env.step_count": 2675.0, "timer/env.step_total": 274.670615196228, "timer/env.step_frac": 0.2745914347630726, "timer/env.step_avg": 0.10268060381167403, "timer/env.step_min": 0.02214360237121582, "timer/env.step_max": 4.136999607086182, "timer/replay._sample_count": 21408.0, "timer/replay._sample_total": 11.45429277420044, "timer/replay._sample_frac": 0.011450990797894373, "timer/replay._sample_avg": 0.0005350473082119039, "timer/replay._sample_min": 0.0003783702850341797, "timer/replay._sample_max": 0.010026693344116211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3144.0, "timer/agent.policy_total": 52.75581669807434, "timer/agent.policy_frac": 0.05274060856081277, "timer/agent.policy_avg": 0.01677983991669031, "timer/agent.policy_min": 0.009551763534545898, "timer/agent.policy_max": 0.11052870750427246, "timer/dataset_train_count": 1338.0, "timer/dataset_train_total": 0.14686918258666992, "timer/dataset_train_frac": 0.00014682684400055618, "timer/dataset_train_avg": 0.00010976769999003731, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.00039124488830566406, "timer/agent.train_count": 1338.0, "timer/agent.train_total": 604.607034444809, "timer/agent.train_frac": 0.6044327418768108, "timer/agent.train_avg": 0.4518737178212324, "timer/agent.train_min": 0.43621397018432617, "timer/agent.train_max": 1.4790830612182617, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4784703254699707, "timer/agent.report_frac": 0.00047833239485225364, "timer/agent.report_avg": 0.23923516273498535, "timer/agent.report_min": 0.23333740234375, "timer/agent.report_max": 0.2451329231262207, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.241557949019931e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 21.393571962809975}
{"step": 43784, "time": 2330.1129019260406, "episode/length": 135.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 44048, "time": 2340.8180611133575, "episode/length": 196.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 44120, "time": 2344.5100932121277, "episode/length": 174.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 44632, "time": 2363.233939886093, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 44640, "time": 2365.3208136558533, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 44640, "time": 2365.329519033432, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 44768, "time": 2372.9138729572296, "episode/length": 138.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 44800, "time": 2375.574565887451, "episode/length": 142.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 45528, "time": 2401.40159201622, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 45560, "time": 2404.1041519641876, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 45712, "time": 2411.026597261429, "episode/length": 240.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 46008, "time": 2422.204341650009, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 46192, "time": 2430.2907831668854, "episode/length": 193.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 46224, "time": 2432.883890390396, "episode/length": 198.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 46256, "time": 2435.5160517692566, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 46272, "time": 2437.515020608902, "episode/length": 183.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 46328, "time": 2440.7968089580536, "episode/length": 99.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 46760, "time": 2456.8640887737274, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 47088, "time": 2469.645145177841, "episode/length": 103.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 47200, "time": 2474.8792867660522, "episode/length": 148.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 47312, "time": 2480.181142091751, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 47552, "time": 2489.8392577171326, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 47568, "time": 2492.007267475128, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 47640, "time": 2495.698708295822, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 47680, "time": 2498.8514070510864, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 48048, "time": 2512.6448814868927, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 48272, "time": 2522.5597007274628, "episode/length": 27.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8214285714285714, "episode/intrinsic_return": 0.0}
{"step": 48624, "time": 2536.18620800972, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 48672, "time": 2539.3042113780975, "episode/length": 128.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 48712, "time": 2542.1274180412292, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 48816, "time": 2547.4839663505554, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 48880, "time": 2551.226317882538, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 48912, "time": 2553.877557992935, "episode/length": 35.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 49008, "time": 2558.6090726852417, "episode/length": 36.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 49032, "time": 2560.8139226436615, "episode/length": 242.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9711934156378601, "episode/intrinsic_return": 0.0}
{"step": 49032, "time": 2560.823787212372, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 49848, "time": 2592.4748351573944, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 49904, "time": 2596.030685901642, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 2618.769965648651, "eval_episode/length": 110.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.954954954954955}
{"step": 50024, "time": 2621.9994218349457, "eval_episode/length": 154.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 50024, "time": 2623.8355028629303, "eval_episode/length": 163.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 50024, "time": 2625.531332015991, "eval_episode/length": 166.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9580838323353293}
{"step": 50024, "time": 2628.050963640213, "eval_episode/length": 188.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9682539682539683}
{"step": 50024, "time": 2629.641394138336, "eval_episode/length": 190.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9633507853403142}
{"step": 50024, "time": 2631.3655495643616, "eval_episode/length": 192.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 50024, "time": 2632.964018344879, "eval_episode/length": 193.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 50192, "time": 2638.930755138397, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 50216, "time": 2641.0321729183197, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 50296, "time": 2645.1825034618378, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 50472, "time": 2652.5469126701355, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 50832, "time": 2666.1138989925385, "episode/length": 239.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 50896, "time": 2669.9125475883484, "episode/length": 235.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 51152, "time": 2680.2611100673676, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 51464, "time": 2692.0711166858673, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 51472, "time": 2694.671231985092, "episode/length": 159.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 51624, "time": 2701.7111337184906, "episode/length": 165.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 51896, "time": 2713.2086877822876, "episode/length": 33.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 52184, "time": 2725.1527919769287, "episode/length": 88.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 52352, "time": 2733.2456393241882, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 52448, "time": 2738.455426454544, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 52584, "time": 2744.870260000229, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 52704, "time": 2750.6638898849487, "episode/length": 356.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 52864, "time": 2757.588510990143, "episode/length": 298.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9933110367892977, "episode/intrinsic_return": 0.0}
{"step": 53272, "time": 2772.522305727005, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 53392, "time": 2778.3236396312714, "episode/length": 65.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 53424, "time": 2780.860634803772, "episode/length": 190.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 53592, "time": 2787.923339366913, "episode/length": 154.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 53736, "time": 2794.2872207164764, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 53920, "time": 2802.1715755462646, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 54680, "time": 2828.9791815280914, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 54984, "time": 2840.948248386383, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 55072, "time": 2846.195436000824, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 55120, "time": 2849.303922176361, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 55352, "time": 2858.4055848121643, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 55368, "time": 2860.514671564102, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 55904, "time": 2880.2107243537903, "episode/length": 431.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 55976, "time": 2883.945819377899, "episode/length": 408.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779951100244498, "episode/intrinsic_return": 0.0}
{"step": 56280, "time": 2895.7546787261963, "episode/length": 199.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 56472, "time": 2903.7476375102997, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 56536, "time": 2907.4642210006714, "episode/length": 176.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 56784, "time": 2917.469300031662, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 56896, "time": 2922.700654029846, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 56944, "time": 2926.451263666153, "episode/length": 233.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 57216, "time": 2937.628966808319, "episode/length": 154.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 57432, "time": 2947.6027121543884, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 57592, "time": 2954.3769817352295, "episode/length": 210.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 57856, "time": 2964.8663885593414, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 58120, "time": 2975.1693744659424, "episode/length": 205.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9854368932038835, "episode/intrinsic_return": 0.0}
{"step": 58200, "time": 2979.368660926819, "episode/length": 42.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 58448, "time": 2989.5083208084106, "episode/length": 187.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 58488, "time": 2992.1936790943146, "episode/length": 198.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 58864, "time": 3006.7533338069916, "episode/length": 259.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 58992, "time": 3012.603901863098, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 59064, "time": 3016.339102745056, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 59128, "time": 3019.9845378398895, "episode/length": 191.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 59352, "time": 3029.140810728073, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 59616, "time": 3039.611673116684, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 59648, "time": 3042.2115943431854, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 59888, "time": 3051.741874933243, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 3076.128597021103, "eval_episode/length": 153.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 60008, "time": 3077.9732506275177, "eval_episode/length": 158.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 60008, "time": 3079.654565811157, "eval_episode/length": 161.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 60008, "time": 3081.6964671611786, "eval_episode/length": 172.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.976878612716763}
{"step": 60008, "time": 3084.8318045139313, "eval_episode/length": 210.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 60008, "time": 3087.0832228660583, "eval_episode/length": 225.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.995575221238938}
{"step": 60008, "time": 3088.7229614257812, "eval_episode/length": 226.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 60008, "time": 3093.3596436977386, "eval_episode/length": 302.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9900990099009901}
{"step": 60256, "time": 3101.880650281906, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9530201342281879, "episode/intrinsic_return": 0.0}
{"step": 60400, "time": 3108.2684557437897, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 60552, "time": 3114.7064945697784, "episode/length": 82.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 60720, "time": 3122.2982337474823, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 60720, "time": 3122.3073580265045, "episode/length": 170.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 61264, "time": 3143.778124332428, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 61280, "time": 3145.8324751853943, "episode/length": 207.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 61496, "time": 3154.381529569626, "episode/length": 136.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 61560, "time": 3158.0906507968903, "episode/length": 320.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 61760, "time": 3166.4894263744354, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 61840, "time": 3170.72803068161, "episode/length": 34.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 62008, "time": 3177.758661031723, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 62392, "time": 3192.0969829559326, "episode/length": 208.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 62736, "time": 3205.365015029907, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 62840, "time": 3210.314928293228, "episode/length": 264.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 62912, "time": 3214.512717485428, "episode/length": 205.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 62968, "time": 3217.8216252326965, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 62976, "time": 3219.924382209778, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 63480, "time": 3238.481303691864, "episode/length": 204.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 63608, "time": 3244.9049010276794, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 63672, "time": 3248.524275302887, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 63992, "time": 3260.763457298279, "episode/length": 127.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.953125, "episode/intrinsic_return": 0.0}
{"step": 64184, "time": 3269.6626188755035, "episode/length": 180.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 64280, "time": 3274.978298664093, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 64312, "time": 3278.217777967453, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 64400, "time": 3283.4927027225494, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 64840, "time": 3300.1266832351685, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 65008, "time": 3307.553208589554, "episode/length": 166.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 65160, "time": 3314.096014022827, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 65449, "time": 3327.152279138565, "train_stats/sum_log_reward": 2.9583332628011703, "train_stats/max_log_achievement_collect_drink": 8.875, "train_stats/max_log_achievement_collect_sapling": 2.408333333333333, "train_stats/max_log_achievement_collect_wood": 1.1416666666666666, "train_stats/max_log_achievement_defeat_zombie": 0.058333333333333334, "train_stats/max_log_achievement_eat_cow": 0.06666666666666667, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.8333333333333333, "train_stats/max_log_achievement_place_table": 0.09166666666666666, "train_stats/max_log_achievement_wake_up": 1.5583333333333333, "train_stats/mean_log_entropy": 0.8852427750825882, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.004605461569393, "train/action_min": 0.0, "train/action_std": 4.583814138875288, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045703365631839805, "train/actor_opt_grad_steps": 3315.0, "train/actor_opt_loss": 27.24349456609172, "train/adv_mag": 1.2110432259300177, "train/adv_max": 1.2073222858940853, "train/adv_mean": 0.01055716627776265, "train/adv_min": -0.5792226083576679, "train/adv_std": 0.10588520935133976, "train/cont_avg": 0.9939539292279411, "train/cont_loss_mean": 0.0005710106509222696, "train/cont_loss_std": 0.014840258546347981, "train/cont_neg_acc": 0.9829217026482767, "train/cont_neg_loss": 0.05194448874043253, "train/cont_pos_acc": 0.9999276877326124, "train/cont_pos_loss": 0.00024093841161863886, "train/cont_pred": 0.9939813758520519, "train/cont_rate": 0.9939539292279411, "train/dyn_loss_mean": 8.908467390958, "train/dyn_loss_std": 7.221695721149445, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4501859098672867, "train/extr_critic_critic_opt_grad_steps": 3315.0, "train/extr_critic_critic_opt_loss": 16251.020062614889, "train/extr_critic_mag": 2.73773912822499, "train/extr_critic_max": 2.73773912822499, "train/extr_critic_mean": 0.6450394866440226, "train/extr_critic_min": -0.1705247137476416, "train/extr_critic_std": 0.7657139128183618, "train/extr_return_normed_mag": 2.079589404604014, "train/extr_return_normed_max": 2.079589404604014, "train/extr_return_normed_mean": 0.3369070234544137, "train/extr_return_normed_min": -0.15773298425654717, "train/extr_return_normed_std": 0.35013693845009103, "train/extr_return_rate": 0.4232982179040418, "train/extr_return_raw_mag": 4.7663643167299385, "train/extr_return_raw_max": 4.7663643167299385, "train/extr_return_raw_mean": 0.669575880993815, "train/extr_return_raw_min": -0.49252273755915027, "train/extr_return_raw_std": 0.8227503624032525, "train/extr_reward_mag": 0.9994457381613114, "train/extr_reward_max": 0.9994457381613114, "train/extr_reward_mean": 0.014221574154148316, "train/extr_reward_min": -0.32966185054358316, "train/extr_reward_std": 0.09880570420885787, "train/image_loss_mean": 21.681726308429944, "train/image_loss_std": 22.011402859407312, "train/model_loss_mean": 27.088439787135403, "train/model_loss_std": 24.803222144351285, "train/model_opt_grad_norm": 122.25926317888148, "train/model_opt_grad_steps": 3306.0, "train/model_opt_loss": 3655.878643260283, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 134.42095588235293, "train/policy_entropy_mag": 2.5158940448480496, "train/policy_entropy_max": 2.5158940448480496, "train/policy_entropy_mean": 0.8645092397928238, "train/policy_entropy_min": 0.07962132858879425, "train/policy_entropy_std": 0.6006656370180494, "train/policy_logprob_mag": 7.436904468957116, "train/policy_logprob_max": -0.009489841937251827, "train/policy_logprob_mean": -0.8647227887721622, "train/policy_logprob_min": -7.436904468957116, "train/policy_logprob_std": 1.2602825296275757, "train/policy_randomness_mag": 0.888000191134565, "train/policy_randomness_max": 0.888000191134565, "train/policy_randomness_mean": 0.3051338253871483, "train/policy_randomness_min": 0.02810283485964379, "train/policy_randomness_std": 0.21200860960080342, "train/post_ent_mag": 46.45674601723166, "train/post_ent_max": 46.45674601723166, "train/post_ent_mean": 33.50207969721626, "train/post_ent_min": 17.175744652748108, "train/post_ent_std": 4.8156541463206795, "train/prior_ent_mag": 59.62470029382145, "train/prior_ent_max": 59.62470029382145, "train/prior_ent_mean": 42.64792178658878, "train/prior_ent_min": 20.854481977574967, "train/prior_ent_std": 6.647427057518678, "train/rep_loss_mean": 8.908467390958, "train/rep_loss_std": 7.221695721149445, "train/reward_avg": 0.011133530496462138, "train/reward_loss_mean": 0.0610623679616872, "train/reward_loss_std": 0.3139282124226584, "train/reward_max_data": 1.0102941201013678, "train/reward_max_pred": 0.9981725557762033, "train/reward_neg_acc": 0.9947603577200104, "train/reward_neg_loss": 0.04217509493943961, "train/reward_pos_acc": 0.9054272372056457, "train/reward_pos_loss": 1.1818463469252867, "train/reward_pred": 0.00997662332477322, "train/reward_rate": 0.016580020680147058, "eval_stats/sum_log_reward": 2.7874999344348907, "eval_stats/max_log_achievement_collect_drink": 10.8125, "eval_stats/max_log_achievement_collect_sapling": 1.8125, "eval_stats/max_log_achievement_collect_wood": 1.375, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_table": 0.25, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02564102564102564, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 3.327294052724028e-06, "report/cont_loss_std": 7.715239189565182e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.361191041534767e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.0620108191214968e-06, "report/cont_pred": 0.9970675706863403, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 9.75554084777832, "report/dyn_loss_std": 7.9151434898376465, "report/image_loss_mean": 24.161457061767578, "report/image_loss_std": 26.404356002807617, "report/model_loss_mean": 30.046611785888672, "report/model_loss_std": 29.949108123779297, "report/post_ent_mag": 46.37950897216797, "report/post_ent_max": 46.37950897216797, "report/post_ent_mean": 33.429908752441406, "report/post_ent_min": 17.88705825805664, "report/post_ent_std": 5.022457599639893, "report/prior_ent_mag": 63.52914810180664, "report/prior_ent_max": 63.52914810180664, "report/prior_ent_mean": 43.73493194580078, "report/prior_ent_min": 19.258365631103516, "report/prior_ent_std": 8.517359733581543, "report/rep_loss_mean": 9.75554084777832, "report/rep_loss_std": 7.9151434898376465, "report/reward_avg": 0.01416015625, "report/reward_loss_mean": 0.0318266823887825, "report/reward_loss_std": 0.18211296200752258, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9992119073867798, "report/reward_neg_acc": 0.9950347542762756, "report/reward_neg_loss": 0.018275072798132896, "report/reward_pos_acc": 0.9411764740943909, "report/reward_pos_loss": 0.8345602750778198, "report/reward_pred": 0.015066685155034065, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0059468406252563, "eval/cont_loss_std": 0.1479206085205078, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.6855407011462376e-05, "eval/cont_pos_acc": 0.9980391263961792, "eval/cont_pos_loss": 0.005970095284283161, "eval/cont_pred": 0.9941260814666748, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 13.970532417297363, "eval/dyn_loss_std": 7.831733703613281, "eval/image_loss_mean": 32.5953369140625, "eval/image_loss_std": 30.581384658813477, "eval/model_loss_mean": 41.11140441894531, "eval/model_loss_std": 33.588802337646484, "eval/post_ent_mag": 46.6776237487793, "eval/post_ent_max": 46.6776237487793, "eval/post_ent_mean": 33.34192657470703, "eval/post_ent_min": 16.526897430419922, "eval/post_ent_std": 5.658985137939453, "eval/prior_ent_mag": 61.03984069824219, "eval/prior_ent_max": 61.03984069824219, "eval/prior_ent_mean": 45.003902435302734, "eval/prior_ent_min": 17.083133697509766, "eval/prior_ent_std": 8.490034103393555, "eval/rep_loss_mean": 13.970532417297363, "eval/rep_loss_std": 7.831733703613281, "eval/reward_avg": 0.00576171837747097, "eval/reward_loss_mean": 0.12780162692070007, "eval/reward_loss_std": 0.7805417776107788, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9926440715789795, "eval/reward_neg_acc": 0.9970385432243347, "eval/reward_neg_loss": 0.07986459881067276, "eval/reward_pos_acc": 0.4545454680919647, "eval/reward_pos_loss": 4.542367458343506, "eval/reward_pred": 0.0002856161445379257, "eval/reward_rate": 0.0107421875, "replay/size": 64945.0, "replay/inserts": 21760.0, "replay/samples": 21760.0, "replay/insert_wait_avg": 1.4148323851473192e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.086711007006028e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14584.0, "eval_replay/inserts": 3976.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2563747659295617e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2665987014770508e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0286076068878, "timer/env.step_count": 2720.0, "timer/env.step_total": 268.2217423915863, "timer/env.step_frac": 0.2682140694289263, "timer/env.step_avg": 0.09861093470278909, "timer/env.step_min": 0.02216339111328125, "timer/env.step_max": 3.334648847579956, "timer/replay._sample_count": 21760.0, "timer/replay._sample_total": 11.996763467788696, "timer/replay._sample_frac": 0.011996420278913296, "timer/replay._sample_avg": 0.00055132185054176, "timer/replay._sample_min": 0.0004050731658935547, "timer/replay._sample_max": 0.027720212936401367, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3217.0, "timer/agent.policy_total": 53.260029554367065, "timer/agent.policy_frac": 0.05325850595596524, "timer/agent.policy_avg": 0.016555806513636015, "timer/agent.policy_min": 0.009588956832885742, "timer/agent.policy_max": 0.0997014045715332, "timer/dataset_train_count": 1360.0, "timer/dataset_train_total": 0.15266728401184082, "timer/dataset_train_frac": 0.00015266291669113378, "timer/dataset_train_avg": 0.00011225535589105942, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.0010828971862792969, "timer/agent.train_count": 1360.0, "timer/agent.train_total": 613.5804779529572, "timer/agent.train_frac": 0.6135629253859868, "timer/agent.train_avg": 0.4511621161418803, "timer/agent.train_min": 0.4345214366912842, "timer/agent.train_max": 1.3959908485412598, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4792308807373047, "timer/agent.report_frac": 0.0004792171714808491, "timer/agent.report_avg": 0.23961544036865234, "timer/agent.report_min": 0.2306821346282959, "timer/agent.report_max": 0.2485487461090088, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.4092881495771936e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 21.75905406852727}
{"step": 65568, "time": 3332.62282538414, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 65576, "time": 3334.6847591400146, "episode/length": 197.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 65688, "time": 3340.640702724457, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 65832, "time": 3347.6889333724976, "episode/length": 189.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 65848, "time": 3350.243570327759, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 66216, "time": 3365.2200257778168, "episode/length": 150.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 66216, "time": 3365.2300758361816, "episode/length": 171.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 66488, "time": 3378.296339035034, "episode/length": 33.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8823529411764706, "episode/intrinsic_return": 0.0}
{"step": 66680, "time": 3386.5257563591003, "episode/length": 138.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 66832, "time": 3394.1327176094055, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 67064, "time": 3403.869414806366, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 67224, "time": 3411.3899545669556, "episode/length": 205.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 67264, "time": 3415.0977108478546, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 67736, "time": 3432.825295448303, "episode/length": 189.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 67832, "time": 3437.6110334396362, "episode/length": 95.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 67848, "time": 3439.739427804947, "episode/length": 249.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 68128, "time": 3451.075637102127, "episode/length": 204.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 68168, "time": 3453.8148481845856, "episode/length": 41.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 68392, "time": 3462.922099351883, "episode/length": 194.0, "episode/score": 3.099999964237213, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 68480, "time": 3467.5641207695007, "episode/length": 38.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 68584, "time": 3472.382126569748, "episode/length": 56.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 68744, "time": 3479.511333465576, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 68880, "time": 3485.86457157135, "episode/length": 274.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 68904, "time": 3487.9733867645264, "episode/length": 209.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 68928, "time": 3490.6440255641937, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3551.1369593143463, "eval_episode/length": 145.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 70096, "time": 3553.2989189624786, "eval_episode/length": 159.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 70096, "time": 3555.3391630649567, "eval_episode/length": 162.0, "eval_episode/score": 4.100000023841858, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 70096, "time": 3558.267921447754, "eval_episode/length": 163.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 70096, "time": 3560.360883951187, "eval_episode/length": 174.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 70096, "time": 3562.6569344997406, "eval_episode/length": 191.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 70096, "time": 3564.6586196422577, "eval_episode/length": 201.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 70096, "time": 3566.8252024650574, "eval_episode/length": 213.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 70192, "time": 3570.069788455963, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 70208, "time": 3572.0404562950134, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 70216, "time": 3573.7290279865265, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 70256, "time": 3576.895224094391, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 70328, "time": 3580.743857860565, "episode/length": 217.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9862385321100917, "episode/intrinsic_return": 0.0}
{"step": 70344, "time": 3582.7583582401276, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 70544, "time": 3591.1562011241913, "episode/length": 35.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 70880, "time": 3603.926697254181, "episode/length": 378.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9973614775725593, "episode/intrinsic_return": 0.0}
{"step": 70928, "time": 3607.1319668293, "episode/length": 47.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 71408, "time": 3624.4681169986725, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 71488, "time": 3628.6624641418457, "episode/length": 158.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 71704, "time": 3637.17675113678, "episode/length": 169.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 71968, "time": 3647.6423845291138, "episode/length": 204.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 72216, "time": 3657.323807001114, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 72328, "time": 3662.594455718994, "episode/length": 264.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 72360, "time": 3665.204599380493, "episode/length": 431.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9976851851851852, "episode/intrinsic_return": 0.0}
{"step": 73080, "time": 3690.946763277054, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 73136, "time": 3694.5597128868103, "episode/length": 275.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 73136, "time": 3694.5691509246826, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 73440, "time": 3708.1362397670746, "episode/length": 243.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 73512, "time": 3711.94828248024, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 73656, "time": 3718.5107736587524, "episode/length": 210.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 73760, "time": 3725.149894952774, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 74464, "time": 3750.549562692642, "episode/length": 165.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 74504, "time": 3753.2214317321777, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 74536, "time": 3755.8751561641693, "episode/length": 275.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.0}
{"step": 74568, "time": 3758.6488785743713, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 74832, "time": 3769.2555346488953, "episode/length": 146.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 75016, "time": 3776.868584871292, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 75072, "time": 3780.5757281780243, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 75216, "time": 3787.002337694168, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 75432, "time": 3795.397716999054, "episode/length": 51.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 75752, "time": 3807.6498816013336, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 76040, "time": 3819.6266787052155, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 76064, "time": 3822.6868085861206, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 76208, "time": 3829.5260553359985, "episode/length": 212.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 76216, "time": 3831.131914138794, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 76728, "time": 3849.7648038864136, "episode/length": 161.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 77000, "time": 3860.2972939014435, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 77360, "time": 3874.2026994228363, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 77424, "time": 3877.866585969925, "episode/length": 293.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 77472, "time": 3881.0478348731995, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 77640, "time": 3888.117576599121, "episode/length": 235.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 77704, "time": 3891.816196680069, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 78104, "time": 3906.757658481598, "episode/length": 236.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 78360, "time": 3916.8204634189606, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 78560, "time": 3925.162925720215, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 78792, "time": 3934.375160217285, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 78960, "time": 3941.750587463379, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 79008, "time": 3944.928498029709, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 79112, "time": 3949.781884908676, "episode/length": 175.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 79256, "time": 3956.106937646866, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 79304, "time": 3959.374205350876, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9533333333333334, "episode/intrinsic_return": 0.0}
{"step": 79528, "time": 3968.4471352100372, "episode/length": 33.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 79696, "time": 3975.8409399986267, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 79760, "time": 3979.457896232605, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 4010.7790541648865, "eval_episode/length": 40.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.975609756097561}
{"step": 80080, "time": 4018.9969522953033, "eval_episode/length": 167.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 80080, "time": 4021.4383866786957, "eval_episode/length": 175.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 80080, "time": 4024.122873544693, "eval_episode/length": 186.0, "eval_episode/score": 4.099999964237213, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 80080, "time": 4027.141003847122, "eval_episode/length": 207.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 80080, "time": 4028.9378368854523, "eval_episode/length": 169.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 80080, "time": 4030.7808117866516, "eval_episode/length": 32.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8484848484848485}
{"step": 80080, "time": 4032.9448623657227, "eval_episode/length": 234.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9829787234042553}
{"step": 80176, "time": 4036.15918135643, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 80400, "time": 4045.2285599708557, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 80688, "time": 4056.498775959015, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 80712, "time": 4058.6661715507507, "episode/length": 212.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 80808, "time": 4063.5152204036713, "episode/length": 211.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 81016, "time": 4072.6142933368683, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 81184, "time": 4080.6758279800415, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 81496, "time": 4093.6342618465424, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 81736, "time": 4103.2544865608215, "episode/length": 254.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 81856, "time": 4108.994213104248, "episode/length": 209.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 81920, "time": 4112.844764709473, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 82224, "time": 4125.898772239685, "episode/length": 227.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 82248, "time": 4128.050049543381, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 82248, "time": 4128.059447526932, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 82464, "time": 4138.9765474796295, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 82880, "time": 4154.6053240299225, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 83040, "time": 4161.994643211365, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 83208, "time": 4169.106978654861, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 83512, "time": 4180.808889865875, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 83544, "time": 4183.445783853531, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 83584, "time": 4186.507349491119, "episode/length": 139.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 83632, "time": 4189.556967496872, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 83928, "time": 4200.863034963608, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 83984, "time": 4204.506849050522, "episode/length": 219.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 84344, "time": 4217.967755556107, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 84376, "time": 4220.499228715897, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 84840, "time": 4238.076665878296, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 84896, "time": 4242.281929016113, "episode/length": 168.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 85064, "time": 4250.0014905929565, "episode/length": 184.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 85304, "time": 4260.381475925446, "episode/length": 115.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9568965517241379, "episode/intrinsic_return": 0.0}
{"step": 85480, "time": 4267.985567569733, "episode/length": 245.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 86000, "time": 4288.311309337616, "episode/length": 251.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 86072, "time": 4292.656170845032, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 86304, "time": 4302.891875982285, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 86328, "time": 4305.4976460933685, "episode/length": 247.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 86400, "time": 4310.323093414307, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 86456, "time": 4314.001939058304, "episode/length": 315.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 86736, "time": 4325.842845201492, "episode/length": 178.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 86737, "time": 4328.066736459732, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.577278309298637, "train/action_min": 0.0, "train/action_std": 3.2779591424124583, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05036619947032821, "train/actor_opt_grad_steps": 4660.0, "train/actor_opt_loss": 6.8845360987168505, "train/adv_mag": 1.0421257565792341, "train/adv_max": 1.0375033944172967, "train/adv_mean": 0.0054267096822062525, "train/adv_min": -0.5311499497944251, "train/adv_std": 0.09451177685444516, "train/cont_avg": 0.9941920230263158, "train/cont_loss_mean": 0.0005751697614212567, "train/cont_loss_std": 0.014955670964966822, "train/cont_neg_acc": 0.9740870075118273, "train/cont_neg_loss": 0.05872585463908024, "train/cont_pos_acc": 0.9999114266015533, "train/cont_pos_loss": 0.00025146249184562075, "train/cont_pred": 0.9942169888575274, "train/cont_rate": 0.9941920230263158, "train/dyn_loss_mean": 10.92964165909846, "train/dyn_loss_std": 7.893963760003111, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2768286332151944, "train/extr_critic_critic_opt_grad_steps": 4660.0, "train/extr_critic_critic_opt_loss": 15392.41080973919, "train/extr_critic_mag": 3.0192574271582124, "train/extr_critic_max": 3.0192574271582124, "train/extr_critic_mean": 0.719547031293238, "train/extr_critic_min": -0.15171756869868228, "train/extr_critic_std": 0.7762097765628556, "train/extr_return_normed_mag": 2.0181573118482317, "train/extr_return_normed_max": 2.0181573118482317, "train/extr_return_normed_mean": 0.34552029660321715, "train/extr_return_normed_min": -0.1662251463622079, "train/extr_return_normed_std": 0.3449454881194839, "train/extr_return_rate": 0.46215443369141196, "train/extr_return_raw_mag": 4.7022807884933355, "train/extr_return_raw_max": 4.7022807884933355, "train/extr_return_raw_mean": 0.7324209558336359, "train/extr_return_raw_min": -0.4826275746625169, "train/extr_return_raw_std": 0.8192520670424727, "train/extr_reward_mag": 1.0053708849096656, "train/extr_reward_max": 1.0053708849096656, "train/extr_reward_mean": 0.015200906375395064, "train/extr_reward_min": -0.32713766026317626, "train/extr_reward_std": 0.10547953547167599, "train/image_loss_mean": 19.481601686405956, "train/image_loss_std": 18.674984960627736, "train/model_loss_mean": 26.0971400612279, "train/model_loss_std": 22.002538638007373, "train/model_opt_grad_norm": 104.94243131365094, "train/model_opt_grad_steps": 4651.0, "train/model_opt_loss": 9919.12428409892, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 382.9887218045113, "train/policy_entropy_mag": 2.509987739692057, "train/policy_entropy_max": 2.509987739692057, "train/policy_entropy_mean": 0.76487935620143, "train/policy_entropy_min": 0.07940271395937841, "train/policy_entropy_std": 0.5811978907961595, "train/policy_logprob_mag": 7.438088800674095, "train/policy_logprob_max": -0.009460037427121088, "train/policy_logprob_mean": -0.7660814640217257, "train/policy_logprob_min": -7.438088800674095, "train/policy_logprob_std": 1.207096504985838, "train/policy_randomness_mag": 0.8859155267701113, "train/policy_randomness_max": 0.8859155267701113, "train/policy_randomness_mean": 0.26996884724699466, "train/policy_randomness_min": 0.02802567357631554, "train/policy_randomness_std": 0.2051373507295336, "train/post_ent_mag": 48.72584439041023, "train/post_ent_max": 48.72584439041023, "train/post_ent_mean": 34.91407483323176, "train/post_ent_min": 18.521903410890047, "train/post_ent_std": 4.981524528417372, "train/prior_ent_mag": 61.417658985109256, "train/prior_ent_max": 61.417658985109256, "train/prior_ent_mean": 46.10308998509457, "train/prior_ent_min": 22.112939605139253, "train/prior_ent_std": 7.375734246763072, "train/rep_loss_mean": 10.92964165909846, "train/rep_loss_std": 7.893963760003111, "train/reward_avg": 0.01349124758980496, "train/reward_loss_mean": 0.057178498462850884, "train/reward_loss_std": 0.2871017973673971, "train/reward_max_data": 1.0075187987851022, "train/reward_max_pred": 1.001890932706962, "train/reward_neg_acc": 0.9941648894682863, "train/reward_neg_loss": 0.037506229937412684, "train/reward_pos_acc": 0.9190929783018011, "train/reward_pos_loss": 1.0869885929545064, "train/reward_pred": 0.01254881254862994, "train/reward_rate": 0.01881902020676692, "train_stats/sum_log_reward": 3.679831866143631, "train_stats/max_log_achievement_collect_drink": 5.974789915966387, "train_stats/max_log_achievement_collect_sapling": 2.8403361344537816, "train_stats/max_log_achievement_collect_wood": 1.8571428571428572, "train_stats/max_log_achievement_defeat_zombie": 0.12605042016806722, "train_stats/max_log_achievement_eat_cow": 0.06722689075630252, "train_stats/max_log_achievement_make_wood_pickaxe": 0.025210084033613446, "train_stats/max_log_achievement_make_wood_sword": 0.09243697478991597, "train_stats/max_log_achievement_place_plant": 2.7142857142857144, "train_stats/max_log_achievement_place_table": 0.2689075630252101, "train_stats/max_log_achievement_wake_up": 1.2857142857142858, "train_stats/mean_log_entropy": 0.7560956535720024, "eval_stats/sum_log_reward": 3.2874999176710844, "eval_stats/max_log_achievement_collect_drink": 6.625, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_wood": 1.75, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.4733355783391744e-05, "report/cont_loss_std": 0.00030189307290129364, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.9721015835093567e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.4779478078708053e-05, "report/cont_pred": 0.9960790872573853, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.893083572387695, "report/dyn_loss_std": 8.958921432495117, "report/image_loss_mean": 21.312267303466797, "report/image_loss_std": 20.70720672607422, "report/model_loss_mean": 28.482257843017578, "report/model_loss_std": 24.915828704833984, "report/post_ent_mag": 49.641876220703125, "report/post_ent_max": 49.641876220703125, "report/post_ent_mean": 35.49852752685547, "report/post_ent_min": 18.727798461914062, "report/post_ent_std": 5.197390079498291, "report/prior_ent_mag": 60.695472717285156, "report/prior_ent_max": 60.695472717285156, "report/prior_ent_mean": 46.469139099121094, "report/prior_ent_min": 23.607410430908203, "report/prior_ent_std": 8.23711109161377, "report/rep_loss_mean": 11.893083572387695, "report/rep_loss_std": 8.958921432495117, "report/reward_avg": 0.014355468563735485, "report/reward_loss_mean": 0.0341232568025589, "report/reward_loss_std": 0.18438376486301422, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0017147064208984, "report/reward_neg_acc": 0.9920555949211121, "report/reward_neg_loss": 0.020009182393550873, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8701745271682739, "report/reward_pred": 0.013854192569851875, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0012735467171296477, "eval/cont_loss_std": 0.036993637681007385, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.526044954720419e-05, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.0012796716764569283, "eval/cont_pred": 0.9943249225616455, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.007476806640625, "eval/dyn_loss_std": 7.992222309112549, "eval/image_loss_mean": 25.29581069946289, "eval/image_loss_std": 22.05536460876465, "eval/model_loss_mean": 35.00990676879883, "eval/model_loss_std": 24.967897415161133, "eval/post_ent_mag": 46.11638641357422, "eval/post_ent_max": 46.11638641357422, "eval/post_ent_mean": 33.76988983154297, "eval/post_ent_min": 18.690847396850586, "eval/post_ent_std": 4.584256649017334, "eval/prior_ent_mag": 60.695472717285156, "eval/prior_ent_max": 60.695472717285156, "eval/prior_ent_mean": 45.520362854003906, "eval/prior_ent_min": 22.130849838256836, "eval/prior_ent_std": 7.411293983459473, "eval/rep_loss_mean": 16.007476806640625, "eval/rep_loss_std": 7.992222309112549, "eval/reward_avg": 0.00917968712747097, "eval/reward_loss_mean": 0.1083366647362709, "eval/reward_loss_std": 0.6995899677276611, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999592304229736, "eval/reward_neg_acc": 0.9990108609199524, "eval/reward_neg_loss": 0.06855525821447372, "eval/reward_pos_acc": 0.46153849363327026, "eval/reward_pos_loss": 3.202106237411499, "eval/reward_pred": 0.0017210227670148015, "eval/reward_rate": 0.0126953125, "replay/size": 86233.0, "replay/inserts": 21288.0, "replay/samples": 21280.0, "replay/insert_wait_avg": 1.4336361825936541e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0988093856582069e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 18176.0, "eval_replay/inserts": 3592.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3273649067018504e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.8981847763062, "timer/env.step_count": 2661.0, "timer/env.step_total": 272.6281294822693, "timer/env.step_frac": 0.2723834787883043, "timer/env.step_avg": 0.1024532617370422, "timer/env.step_min": 0.02189159393310547, "timer/env.step_max": 4.08233642578125, "timer/replay._sample_count": 21280.0, "timer/replay._sample_total": 11.773993492126465, "timer/replay._sample_frac": 0.011763427760394901, "timer/replay._sample_avg": 0.0005532891678630857, "timer/replay._sample_min": 0.0004069805145263672, "timer/replay._sample_max": 0.024457931518554688, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3110.0, "timer/agent.policy_total": 52.32711744308472, "timer/agent.policy_frac": 0.05228016019909105, "timer/agent.policy_avg": 0.0168254396923102, "timer/agent.policy_min": 0.009698152542114258, "timer/agent.policy_max": 0.10811638832092285, "timer/dataset_train_count": 1330.0, "timer/dataset_train_total": 0.14751601219177246, "timer/dataset_train_frac": 0.0001473836344550283, "timer/dataset_train_avg": 0.00011091429488103192, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.00032019615173339844, "timer/agent.train_count": 1330.0, "timer/agent.train_total": 601.6484026908875, "timer/agent.train_frac": 0.6011084961907007, "timer/agent.train_avg": 0.4523672200683364, "timer/agent.train_min": 0.4370424747467041, "timer/agent.train_max": 1.485576868057251, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4724280834197998, "timer/agent.report_frac": 0.0004720041364900509, "timer/agent.report_avg": 0.2362140417098999, "timer/agent.report_min": 0.22861719131469727, "timer/agent.report_max": 0.24381089210510254, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.287223857176736e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 21.26861397324182}
{"step": 87016, "time": 4337.4922478199005, "episode/length": 88.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 87152, "time": 4343.766394138336, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 87352, "time": 4351.94637966156, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 87608, "time": 4362.11426115036, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 87856, "time": 4372.252414464951, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 88040, "time": 4379.859964132309, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 88072, "time": 4382.487957000732, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 88288, "time": 4391.602194786072, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 88376, "time": 4395.917730331421, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 88552, "time": 4403.403831720352, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 88608, "time": 4407.243671178818, "episode/length": 156.0, "episode/score": 3.099999964237213, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 89416, "time": 4435.68421959877, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 89536, "time": 4441.602030515671, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 89624, "time": 4445.8825507164, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 89864, "time": 4455.728250026703, "episode/length": 281.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9822695035460993, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 4479.271471977234, "eval_episode/length": 34.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 90064, "time": 4480.960506677628, "eval_episode/length": 38.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8717948717948718}
{"step": 90064, "time": 4483.710884809494, "eval_episode/length": 32.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 90064, "time": 4489.658452987671, "eval_episode/length": 164.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 90064, "time": 4491.766073942184, "eval_episode/length": 166.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 90064, "time": 4494.353763103485, "eval_episode/length": 177.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 90064, "time": 4497.577637672424, "eval_episode/length": 197.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 90064, "time": 4500.826479434967, "eval_episode/length": 151.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 90192, "time": 4506.663987398148, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 90200, "time": 4508.746787309647, "episode/length": 227.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 90496, "time": 4520.647009372711, "episode/length": 275.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 90512, "time": 4522.775091648102, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 91184, "time": 4547.103318929672, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 91224, "time": 4549.806586265564, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 91568, "time": 4563.512500762939, "episode/length": 42.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 91584, "time": 4566.131468057632, "episode/length": 255.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 91664, "time": 4570.974622488022, "episode/length": 183.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 91752, "time": 4575.839020490646, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 91808, "time": 4580.262565135956, "episode/length": 298.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 91888, "time": 4584.99596953392, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 92200, "time": 4597.596642494202, "episode/length": 38.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 92360, "time": 4604.592271327972, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 92448, "time": 4609.3277497291565, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 92824, "time": 4623.422332048416, "episode/length": 156.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 93152, "time": 4636.11384510994, "episode/length": 174.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 93184, "time": 4638.739250421524, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 93280, "time": 4643.386500120163, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 93304, "time": 4645.5242693424225, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 93696, "time": 4660.460598230362, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 93776, "time": 4664.68382358551, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 93792, "time": 4666.857387542725, "episode/length": 79.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 94040, "time": 4676.6924641132355, "episode/length": 209.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 94280, "time": 4686.284521102905, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 94416, "time": 4692.502770423889, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 94696, "time": 4703.1162109375, "episode/length": 34.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 94904, "time": 4711.68092250824, "episode/length": 202.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 95048, "time": 4718.143736600876, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 95216, "time": 4725.555494308472, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 95224, "time": 4727.218027353287, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 95384, "time": 4734.197930812836, "episode/length": 259.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 95424, "time": 4737.432254314423, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 95696, "time": 4748.046701908112, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 96184, "time": 4765.6148471832275, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 96232, "time": 4768.89700627327, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 96336, "time": 4774.151670217514, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 96680, "time": 4786.9073095321655, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 96752, "time": 4791.191149711609, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 96800, "time": 4794.37625670433, "episode/length": 171.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 96880, "time": 4798.708922147751, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 96984, "time": 4803.504288434982, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 97416, "time": 4819.578538417816, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 97808, "time": 4834.532603025436, "episode/length": 183.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 97872, "time": 4838.345450639725, "episode/length": 148.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 97928, "time": 4841.646460533142, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 98160, "time": 4851.090666294098, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 98208, "time": 4854.282679796219, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 98312, "time": 4859.364584684372, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 98496, "time": 4868.648048400879, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 98536, "time": 4871.333181858063, "episode/length": 40.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 98560, "time": 4873.800783157349, "episode/length": 85.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9302325581395349, "episode/intrinsic_return": 0.0}
{"step": 98936, "time": 4887.667868375778, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 99160, "time": 4896.6392340660095, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 99408, "time": 4906.5648012161255, "episode/length": 155.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 99840, "time": 4922.507672548294, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 99856, "time": 4924.693575382233, "episode/length": 240.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 99888, "time": 4927.25967669487, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 4953.544590950012, "eval_episode/length": 155.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 100048, "time": 4955.262729167938, "eval_episode/length": 159.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 100048, "time": 4957.195949077606, "eval_episode/length": 168.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9644970414201184}
{"step": 100048, "time": 4959.4190356731415, "eval_episode/length": 182.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 100048, "time": 4961.641249418259, "eval_episode/length": 200.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 100048, "time": 4961.650217533112, "eval_episode/length": 200.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9800995024875622}
{"step": 100048, "time": 4965.503331899643, "eval_episode/length": 215.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 100048, "time": 4969.912473917007, "eval_episode/length": 285.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9895104895104895}
{"step": 100208, "time": 4975.390160083771, "episode/length": 205.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 100272, "time": 4979.700121164322, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 100320, "time": 4983.189368486404, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 100488, "time": 4990.830085515976, "episode/length": 243.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 100696, "time": 5000.039058685303, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 101328, "time": 5023.964909553528, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 101344, "time": 5026.0917773246765, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 101496, "time": 5032.561046600342, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 101600, "time": 5037.888001680374, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 101768, "time": 5044.734269142151, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 101904, "time": 5051.039092302322, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 102584, "time": 5074.863852739334, "episode/length": 235.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 102680, "time": 5079.50044631958, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 102712, "time": 5082.10658454895, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 102856, "time": 5088.395804405212, "episode/length": 295.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9831081081081081, "episode/intrinsic_return": 0.0}
{"step": 103008, "time": 5095.320814847946, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 103296, "time": 5106.613968133926, "episode/length": 211.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 103648, "time": 5119.861696243286, "episode/length": 132.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 103720, "time": 5123.532035589218, "episode/length": 243.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 103808, "time": 5128.304233074188, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 104192, "time": 5142.680726051331, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 104312, "time": 5148.125604391098, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 104536, "time": 5157.844710826874, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 104600, "time": 5161.558057785034, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 104800, "time": 5169.937384366989, "episode/length": 223.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 105104, "time": 5181.676291465759, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 105240, "time": 5187.650757312775, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 105352, "time": 5192.944472074509, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 105600, "time": 5203.0024292469025, "episode/length": 160.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 105864, "time": 5213.1389145851135, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 105920, "time": 5216.888328790665, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 106064, "time": 5223.916190624237, "episode/length": 182.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 106136, "time": 5228.170558691025, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 106184, "time": 5231.943974971771, "episode/length": 32.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 106312, "time": 5238.3835191726685, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 106848, "time": 5260.0294897556305, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 107104, "time": 5269.969368219376, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 107176, "time": 5273.718138933182, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 107184, "time": 5275.700656414032, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 108016, "time": 5304.877078533173, "episode/length": 228.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 108080, "time": 5308.657769918442, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 108136, "time": 5311.864671230316, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 108144, "time": 5313.97088432312, "episode/length": 259.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 108384, "time": 5323.341876506805, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 108400, "time": 5325.415791511536, "episode/length": 39.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 108409, "time": 5328.095900774002, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.751388888888889, "train/action_min": 0.0, "train/action_std": 3.333569145202637, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05407765039967166, "train/actor_opt_grad_steps": 6000.0, "train/actor_opt_loss": 24.971032546239872, "train/adv_mag": 1.0651504428298384, "train/adv_max": 1.0598813432234304, "train/adv_mean": 0.009132221883973451, "train/adv_min": -0.5365172368508798, "train/adv_std": 0.09786383355105364, "train/cont_avg": 0.9942563657407407, "train/cont_loss_mean": 0.0006072452704613708, "train/cont_loss_std": 0.015773895289149315, "train/cont_neg_acc": 0.981231630731512, "train/cont_neg_loss": 0.05594189210949446, "train/cont_pos_acc": 0.9999126103189256, "train/cont_pos_loss": 0.0002662963745088252, "train/cont_pred": 0.9942660954263475, "train/cont_rate": 0.9942563657407407, "train/dyn_loss_mean": 12.53086799339012, "train/dyn_loss_std": 8.384734157279686, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2949775810594912, "train/extr_critic_critic_opt_grad_steps": 6000.0, "train/extr_critic_critic_opt_loss": 15745.84095775463, "train/extr_critic_mag": 3.1706020125636347, "train/extr_critic_max": 3.1706020125636347, "train/extr_critic_mean": 0.8056558772369667, "train/extr_critic_min": -0.15812762754934806, "train/extr_critic_std": 0.7635782098328626, "train/extr_return_normed_mag": 2.023341432324162, "train/extr_return_normed_max": 2.023341432324162, "train/extr_return_normed_mean": 0.3724973444585447, "train/extr_return_normed_min": -0.1646092738542292, "train/extr_return_normed_std": 0.340767827740422, "train/extr_return_rate": 0.5268147439868361, "train/extr_return_raw_mag": 4.751402747189557, "train/extr_return_raw_max": 4.751402747189557, "train/extr_return_raw_mean": 0.8274307794041104, "train/extr_return_raw_min": -0.45223315954208376, "train/extr_return_raw_std": 0.8108522905243768, "train/extr_reward_mag": 1.0047079201097842, "train/extr_reward_max": 1.0047079201097842, "train/extr_reward_mean": 0.017108041465420415, "train/extr_reward_min": -0.3203067788371333, "train/extr_reward_std": 0.109591120812628, "train/image_loss_mean": 16.798951346785934, "train/image_loss_std": 17.23462137999358, "train/model_loss_mean": 24.373643592551904, "train/model_loss_std": 20.80272494422065, "train/model_opt_grad_norm": 91.79875485455548, "train/model_opt_grad_steps": 5990.622222222222, "train/model_opt_loss": 16916.398097511574, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 694.4444444444445, "train/policy_entropy_mag": 2.4179100336851898, "train/policy_entropy_max": 2.4179100336851898, "train/policy_entropy_mean": 0.6999719765451219, "train/policy_entropy_min": 0.07939281640229402, "train/policy_entropy_std": 0.5190522898126532, "train/policy_logprob_mag": 7.438316359343352, "train/policy_logprob_max": -0.009458684072726303, "train/policy_logprob_mean": -0.7008266859584384, "train/policy_logprob_min": -7.438316359343352, "train/policy_logprob_std": 1.167070061189157, "train/policy_randomness_mag": 0.8534161346930045, "train/policy_randomness_max": 0.8534161346930045, "train/policy_randomness_mean": 0.2470593911630136, "train/policy_randomness_min": 0.028022180152712045, "train/policy_randomness_std": 0.18320268094539643, "train/post_ent_mag": 50.35871426617658, "train/post_ent_max": 50.35871426617658, "train/post_ent_mean": 35.91286878232603, "train/post_ent_min": 19.120811716715494, "train/post_ent_std": 5.266570257257532, "train/prior_ent_mag": 62.670253866690175, "train/prior_ent_max": 62.670253866690175, "train/prior_ent_mean": 48.64984345612702, "train/prior_ent_min": 23.617664210001628, "train/prior_ent_std": 7.357159264882406, "train/rep_loss_mean": 12.53086799339012, "train/rep_loss_std": 8.384734157279686, "train/reward_avg": 0.01555266189561398, "train/reward_loss_mean": 0.0555643394175503, "train/reward_loss_std": 0.2845432296947197, "train/reward_max_data": 1.007407409173471, "train/reward_max_pred": 1.0022154030976471, "train/reward_neg_acc": 0.993612340203038, "train/reward_neg_loss": 0.03468497078175898, "train/reward_pos_acc": 0.9255117654800415, "train/reward_pos_loss": 1.0600809424011797, "train/reward_pred": 0.014790968775438765, "train/reward_rate": 0.02060908564814815, "train_stats/sum_log_reward": 4.22711855665607, "train_stats/max_log_achievement_collect_drink": 5.432203389830509, "train_stats/max_log_achievement_collect_sapling": 2.610169491525424, "train_stats/max_log_achievement_collect_wood": 2.3135593220338984, "train_stats/max_log_achievement_defeat_zombie": 0.2457627118644068, "train_stats/max_log_achievement_eat_cow": 0.06779661016949153, "train_stats/max_log_achievement_make_wood_pickaxe": 0.01694915254237288, "train_stats/max_log_achievement_make_wood_sword": 0.1016949152542373, "train_stats/max_log_achievement_place_plant": 2.4152542372881354, "train_stats/max_log_achievement_place_table": 0.7711864406779662, "train_stats/max_log_achievement_wake_up": 1.3389830508474576, "train_stats/mean_log_entropy": 0.7030990878909321, "eval_stats/sum_log_reward": 3.8499999409541488, "eval_stats/max_log_achievement_collect_drink": 3.9375, "eval_stats/max_log_achievement_collect_sapling": 2.3125, "eval_stats/max_log_achievement_collect_wood": 2.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_table": 0.8125, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_defeat_skeleton": 0.038461538461538464, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.0001128422882175073, "report/cont_loss_std": 0.0035962488036602736, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.11513657867908478, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.046301285143272e-07, "report/cont_pred": 0.9991292953491211, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 12.295527458190918, "report/dyn_loss_std": 8.63253402709961, "report/image_loss_mean": 16.175474166870117, "report/image_loss_std": 19.341995239257812, "report/model_loss_mean": 23.578744888305664, "report/model_loss_std": 23.043333053588867, "report/post_ent_mag": 52.44610595703125, "report/post_ent_max": 52.44610595703125, "report/post_ent_mean": 35.58424377441406, "report/post_ent_min": 21.719934463500977, "report/post_ent_std": 5.568495750427246, "report/prior_ent_mag": 64.17955780029297, "report/prior_ent_max": 64.17955780029297, "report/prior_ent_mean": 48.36149215698242, "report/prior_ent_min": 22.58368492126465, "report/prior_ent_std": 7.38171911239624, "report/rep_loss_mean": 12.295527458190918, "report/rep_loss_std": 8.63253402709961, "report/reward_avg": 0.01679687574505806, "report/reward_loss_mean": 0.02584044262766838, "report/reward_loss_std": 0.14465467631816864, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0002169609069824, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010824862867593765, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8200857043266296, "report/reward_pred": 0.014275265857577324, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0001548046275274828, "eval/cont_loss_std": 0.002364820335060358, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.015597028657793999, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00012458501441869885, "eval/cont_pred": 0.9979550838470459, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.74835205078125, "eval/dyn_loss_std": 8.571988105773926, "eval/image_loss_mean": 23.735157012939453, "eval/image_loss_std": 20.078046798706055, "eval/model_loss_mean": 33.951759338378906, "eval/model_loss_std": 23.355554580688477, "eval/post_ent_mag": 46.37401580810547, "eval/post_ent_max": 46.37401580810547, "eval/post_ent_mean": 34.916351318359375, "eval/post_ent_min": 20.920059204101562, "eval/post_ent_std": 4.959169387817383, "eval/prior_ent_mag": 64.17955780029297, "eval/prior_ent_max": 64.17955780029297, "eval/prior_ent_mean": 49.08953857421875, "eval/prior_ent_min": 22.8768310546875, "eval/prior_ent_std": 7.661222457885742, "eval/rep_loss_mean": 16.74835205078125, "eval/rep_loss_std": 8.571988105773926, "eval/reward_avg": 0.01484374888241291, "eval/reward_loss_mean": 0.16743747889995575, "eval/reward_loss_std": 1.0206334590911865, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9988131523132324, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.06179218366742134, "eval/reward_pos_acc": 0.3684210479259491, "eval/reward_pos_loss": 5.755517959594727, "eval/reward_pred": 0.002769659273326397, "eval/reward_rate": 0.0185546875, "replay/size": 107905.0, "replay/inserts": 21672.0, "replay/samples": 21680.0, "replay/insert_wait_avg": 1.4190481966736133e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.242086016383998e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 22224.0, "eval_replay/inserts": 4048.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2873307518337085e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0203976631165, "timer/env.step_count": 2709.0, "timer/env.step_total": 266.88546347618103, "timer/env.step_frac": 0.2668800197474457, "timer/env.step_avg": 0.09851807437289813, "timer/env.step_min": 0.022400379180908203, "timer/env.step_max": 2.9595584869384766, "timer/replay._sample_count": 21680.0, "timer/replay._sample_total": 11.919634819030762, "timer/replay._sample_frac": 0.01191939169129449, "timer/replay._sample_avg": 0.000549798654014334, "timer/replay._sample_min": 0.0004055500030517578, "timer/replay._sample_max": 0.012060165405273438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3215.0, "timer/agent.policy_total": 53.59369230270386, "timer/agent.policy_frac": 0.05359259913892109, "timer/agent.policy_avg": 0.01666988874112095, "timer/agent.policy_min": 0.009722471237182617, "timer/agent.policy_max": 0.09348511695861816, "timer/dataset_train_count": 1355.0, "timer/dataset_train_total": 0.15154600143432617, "timer/dataset_train_frac": 0.00015154291031309393, "timer/dataset_train_avg": 0.0001118420674792075, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0004067420959472656, "timer/agent.train_count": 1355.0, "timer/agent.train_total": 610.5622801780701, "timer/agent.train_frac": 0.6105498263883956, "timer/agent.train_avg": 0.45059946876610335, "timer/agent.train_min": 0.43761277198791504, "timer/agent.train_max": 1.4176912307739258, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47054505348205566, "timer/agent.report_frac": 0.0004705354556583468, "timer/agent.report_avg": 0.23527252674102783, "timer/agent.report_min": 0.22429800033569336, "timer/agent.report_max": 0.2462470531463623, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.313950652662721e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 21.671265297117188}
{"step": 108600, "time": 5334.2702441215515, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 108912, "time": 5346.438394784927, "episode/length": 38.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 108952, "time": 5349.109393596649, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 109040, "time": 5353.790908098221, "episode/length": 231.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 109336, "time": 5364.825608491898, "episode/length": 36.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 109560, "time": 5373.8823029994965, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 109688, "time": 5379.644534111023, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 109752, "time": 5383.313744068146, "episode/length": 216.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 109872, "time": 5389.028286457062, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 5414.0927538871765, "eval_episode/length": 122.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.967479674796748}
{"step": 110032, "time": 5416.667736053467, "eval_episode/length": 150.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 110032, "time": 5416.676234483719, "eval_episode/length": 150.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9602649006622517}
{"step": 110032, "time": 5420.913893699646, "eval_episode/length": 171.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 110032, "time": 5423.4788210392, "eval_episode/length": 194.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 110032, "time": 5426.753032207489, "eval_episode/length": 230.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9826839826839827}
{"step": 110032, "time": 5426.812584161758, "eval_episode/length": 230.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9826839826839827}
{"step": 110032, "time": 5432.575563669205, "eval_episode/length": 258.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9845559845559846}
{"step": 110040, "time": 5432.62753033638, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 110224, "time": 5440.43848991394, "episode/length": 163.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 110304, "time": 5444.598691701889, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 110952, "time": 5467.270881175995, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 111056, "time": 5472.4824476242065, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 111096, "time": 5475.2397792339325, "episode/length": 175.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9602272727272727, "episode/intrinsic_return": 0.0}
{"step": 111264, "time": 5482.523263216019, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 111360, "time": 5487.3492839336395, "episode/length": 252.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 111488, "time": 5493.20965385437, "episode/length": 201.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9851485148514851, "episode/intrinsic_return": 0.0}
{"step": 111560, "time": 5496.880627632141, "episode/length": 166.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 112256, "time": 5521.735523939133, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 112512, "time": 5531.696984052658, "episode/length": 155.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 112600, "time": 5535.925227880478, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 112712, "time": 5541.257332324982, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 112856, "time": 5547.787130117416, "episode/length": 318.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9937304075235109, "episode/intrinsic_return": 0.0}
{"step": 112856, "time": 5547.796408414841, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 112864, "time": 5551.58758354187, "episode/length": 32.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 113016, "time": 5557.928846359253, "episode/length": 181.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 113080, "time": 5561.6214644908905, "episode/length": 198.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9849246231155779, "episode/intrinsic_return": 0.0}
{"step": 113144, "time": 5565.259551286697, "episode/length": 35.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 113736, "time": 5586.339236974716, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 113984, "time": 5596.358412265778, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 114024, "time": 5599.038760900497, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 114104, "time": 5603.240024805069, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 114144, "time": 5606.57589507103, "episode/length": 235.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 114392, "time": 5616.0446174144745, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 114544, "time": 5622.743330955505, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 114576, "time": 5625.2876670360565, "episode/length": 194.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 115304, "time": 5651.96467924118, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 115336, "time": 5654.563920736313, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 115464, "time": 5660.353822469711, "episode/length": 184.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 115512, "time": 5663.534834861755, "episode/length": 185.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 115896, "time": 5677.912901639938, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 115928, "time": 5680.593138456345, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 116328, "time": 5695.451772451401, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 116608, "time": 5706.677798986435, "episode/length": 307.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 116624, "time": 5708.693044424057, "episode/length": 36.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 116952, "time": 5721.095905542374, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 117144, "time": 5729.801964044571, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 117168, "time": 5732.290458917618, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 117176, "time": 5733.929481983185, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 117216, "time": 5737.071316480637, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 117536, "time": 5749.168709516525, "episode/length": 258.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 117936, "time": 5763.971974611282, "episode/length": 165.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 118256, "time": 5776.034129142761, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 118328, "time": 5779.817581415176, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 118472, "time": 5786.228024721146, "episode/length": 26.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8518518518518519, "episode/intrinsic_return": 0.0}
{"step": 118480, "time": 5788.27964925766, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 118640, "time": 5795.061137676239, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 118760, "time": 5800.34191608429, "episode/length": 34.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 118968, "time": 5808.828274965286, "episode/length": 251.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 119152, "time": 5816.892789363861, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 119264, "time": 5822.596556425095, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 119312, "time": 5826.239279985428, "episode/length": 266.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 119584, "time": 5837.2667508125305, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 119688, "time": 5842.181845426559, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 119728, "time": 5845.266545057297, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 5870.5666880607605, "eval_episode/length": 35.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9444444444444444}
{"step": 120016, "time": 5877.139492750168, "eval_episode/length": 153.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 120016, "time": 5880.0174016952515, "eval_episode/length": 184.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 120016, "time": 5881.900888204575, "eval_episode/length": 192.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 120016, "time": 5883.97759604454, "eval_episode/length": 204.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9707317073170731}
{"step": 120016, "time": 5885.650206565857, "eval_episode/length": 206.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 120016, "time": 5889.160378217697, "eval_episode/length": 251.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9801587301587301}
{"step": 120016, "time": 5889.170510530472, "eval_episode/length": 251.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 120088, "time": 5891.332562923431, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 120232, "time": 5897.738524675369, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 120552, "time": 5909.846120595932, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 120584, "time": 5912.417686700821, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 120864, "time": 5923.5052280426025, "episode/length": 199.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 120984, "time": 5928.855753660202, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 121216, "time": 5938.462281227112, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 121232, "time": 5940.61172413826, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 121424, "time": 5948.43279838562, "episode/length": 166.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 121752, "time": 5960.609684467316, "episode/length": 149.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 122280, "time": 5979.465964317322, "episode/length": 255.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 122288, "time": 5981.519290685654, "episode/length": 212.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 122296, "time": 5983.086323976517, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 122384, "time": 5987.795385360718, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 122616, "time": 5996.840962648392, "episode/length": 41.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 122880, "time": 6007.692332744598, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 122992, "time": 6014.388167381287, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 123328, "time": 6027.305333137512, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 123544, "time": 6036.088198184967, "episode/length": 156.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 123608, "time": 6039.780273199081, "episode/length": 272.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 123832, "time": 6048.698516368866, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 123856, "time": 6051.244940519333, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 123912, "time": 6054.489410638809, "episode/length": 45.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 124536, "time": 6076.725025653839, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 124544, "time": 6078.717730522156, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 124872, "time": 6091.286988973618, "episode/length": 248.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 124920, "time": 6094.941546678543, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 125040, "time": 6100.9831347465515, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 125072, "time": 6103.692731142044, "episode/length": 217.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 125288, "time": 6112.080051422119, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 125304, "time": 6114.183478593826, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 125600, "time": 6125.818581342697, "episode/length": 38.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 125944, "time": 6138.481201887131, "episode/length": 133.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9552238805970149, "episode/intrinsic_return": 0.0}
{"step": 126040, "time": 6143.26044511795, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 126104, "time": 6146.959885597229, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 126256, "time": 6153.752110481262, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9539473684210527, "episode/intrinsic_return": 0.0}
{"step": 126344, "time": 6157.948604106903, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 126688, "time": 6171.071054697037, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 126920, "time": 6180.318206787109, "episode/length": 249.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.988, "episode/intrinsic_return": 0.0}
{"step": 127248, "time": 6192.95254278183, "episode/length": 142.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 127568, "time": 6205.165699481964, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 127616, "time": 6208.428128480911, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 127648, "time": 6211.070365190506, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 127728, "time": 6215.16405248642, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 128112, "time": 6229.384418964386, "episode/length": 148.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 128120, "time": 6230.895769119263, "episode/length": 232.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 128288, "time": 6238.376639127731, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 128976, "time": 6262.724728107452, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 129056, "time": 6266.973228693008, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 129072, "time": 6269.01143860817, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 129184, "time": 6274.246042251587, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 129320, "time": 6280.0803480148315, "episode/length": 149.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 129608, "time": 6291.072926998138, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 129688, "time": 6295.270984888077, "episode/length": 258.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 6323.916933774948, "eval_episode/length": 26.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 130000, "time": 6329.729188919067, "eval_episode/length": 133.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9552238805970149}
{"step": 130000, "time": 6332.202146291733, "eval_episode/length": 157.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 130000, "time": 6333.850243091583, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 130000, "time": 6335.592462539673, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 130000, "time": 6337.35403752327, "eval_episode/length": 164.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 130000, "time": 6339.036069154739, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 130000, "time": 6341.897886514664, "eval_episode/length": 202.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9704433497536946}
{"step": 130001, "time": 6342.4703006744385, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.1178408022280095, "train/action_min": 0.0, "train/action_std": 2.5637634930787265, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05321792979483251, "train/actor_opt_grad_steps": 7350.0, "train/actor_opt_loss": 10.80601737929715, "train/adv_mag": 0.9545141255414045, "train/adv_max": 0.9469799130051224, "train/adv_mean": 0.007371574331827341, "train/adv_min": -0.5257579584916433, "train/adv_std": 0.09158849197405355, "train/cont_avg": 0.9943938078703703, "train/cont_loss_mean": 0.0005246682201827836, "train/cont_loss_std": 0.01416794981309303, "train/cont_neg_acc": 0.9853057053354052, "train/cont_neg_loss": 0.05286414247503773, "train/cont_pos_acc": 0.9999271679807592, "train/cont_pos_loss": 0.00016524128015439138, "train/cont_pred": 0.994425043353328, "train/cont_rate": 0.9943938078703703, "train/dyn_loss_mean": 13.695247494732891, "train/dyn_loss_std": 8.632073504836471, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2220904208995678, "train/extr_critic_critic_opt_grad_steps": 7350.0, "train/extr_critic_critic_opt_loss": 15921.90287181713, "train/extr_critic_mag": 3.474879833504006, "train/extr_critic_max": 3.474879833504006, "train/extr_critic_mean": 0.950300207844487, "train/extr_critic_min": -0.17286569365748652, "train/extr_critic_std": 0.8890912797715929, "train/extr_return_normed_mag": 1.9418558835983277, "train/extr_return_normed_max": 1.9418558835983277, "train/extr_return_normed_mean": 0.3798736019266976, "train/extr_return_normed_min": -0.14694323236191714, "train/extr_return_normed_std": 0.34537730250093673, "train/extr_return_rate": 0.5842944946553972, "train/extr_return_raw_mag": 5.219833928567392, "train/extr_return_raw_max": 5.219833928567392, "train/extr_return_raw_mean": 0.9703826665878296, "train/extr_return_raw_min": -0.46399564036616575, "train/extr_return_raw_std": 0.9412714388635424, "train/extr_reward_mag": 1.005012771818373, "train/extr_reward_max": 1.005012771818373, "train/extr_reward_mean": 0.018930398251999308, "train/extr_reward_min": -0.2918199141820272, "train/extr_reward_std": 0.11852843176435542, "train/image_loss_mean": 14.126989060861092, "train/image_loss_std": 15.10349599343759, "train/model_loss_mean": 22.40060184620045, "train/model_loss_std": 18.78347043637876, "train/model_opt_grad_norm": 93.30076014200846, "train/model_opt_grad_steps": 7339.377777777778, "train/model_opt_loss": 14179.874088541666, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 634.2592592592592, "train/policy_entropy_mag": 2.322456469359221, "train/policy_entropy_max": 2.322456469359221, "train/policy_entropy_mean": 0.5398715549045139, "train/policy_entropy_min": 0.07938335101913523, "train/policy_entropy_std": 0.42093339562416077, "train/policy_logprob_mag": 7.4383558414600515, "train/policy_logprob_max": -0.009457267124067853, "train/policy_logprob_mean": -0.5400415360927582, "train/policy_logprob_min": -7.4383558414600515, "train/policy_logprob_std": 1.0555280650103533, "train/policy_randomness_mag": 0.8197252127859328, "train/policy_randomness_max": 0.8197252127859328, "train/policy_randomness_mean": 0.1905509673886829, "train/policy_randomness_min": 0.028018839298575012, "train/policy_randomness_std": 0.1485710162807394, "train/post_ent_mag": 52.56460235030563, "train/post_ent_max": 52.56460235030563, "train/post_ent_mean": 36.94804526435004, "train/post_ent_min": 19.827487210874203, "train/post_ent_std": 5.6673787399574564, "train/prior_ent_mag": 63.843971704553674, "train/prior_ent_max": 63.843971704553674, "train/prior_ent_mean": 50.80626342208297, "train/prior_ent_min": 25.106020242196543, "train/prior_ent_std": 7.021216106414795, "train/rep_loss_mean": 13.695247494732891, "train/rep_loss_std": 8.632073504836471, "train/reward_avg": 0.01667173026405551, "train/reward_loss_mean": 0.055939740963556146, "train/reward_loss_std": 0.28271560613755825, "train/reward_max_data": 1.0133333365122477, "train/reward_max_pred": 1.0034031788508098, "train/reward_neg_acc": 0.9932040589827078, "train/reward_neg_loss": 0.0344010250022014, "train/reward_pos_acc": 0.9394341791117633, "train/reward_pos_loss": 1.0305424919834842, "train/reward_pred": 0.01596350167291584, "train/reward_rate": 0.02175925925925926, "train_stats/sum_log_reward": 4.391666606068611, "train_stats/max_log_achievement_collect_drink": 3.275, "train_stats/max_log_achievement_collect_sapling": 2.591666666666667, "train_stats/max_log_achievement_collect_wood": 2.95, "train_stats/max_log_achievement_defeat_skeleton": 0.016666666666666666, "train_stats/max_log_achievement_defeat_zombie": 0.18333333333333332, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008333333333333333, "train_stats/max_log_achievement_make_wood_sword": 0.025, "train_stats/max_log_achievement_place_plant": 2.441666666666667, "train_stats/max_log_achievement_place_table": 1.0916666666666666, "train_stats/max_log_achievement_wake_up": 1.35, "train_stats/mean_log_entropy": 0.5337846448024114, "eval_stats/sum_log_reward": 4.058333324889342, "eval_stats/max_log_achievement_collect_drink": 2.0, "eval_stats/max_log_achievement_collect_sapling": 2.7083333333333335, "eval_stats/max_log_achievement_collect_wood": 2.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_table": 0.875, "eval_stats/max_log_achievement_wake_up": 1.1666666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.006712953560054302, "report/cont_loss_std": 0.2060478925704956, "report/cont_neg_acc": 0.800000011920929, "report/cont_neg_loss": 1.3186545372009277, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00027555663837119937, "report/cont_pred": 0.995854377746582, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.63325309753418, "report/dyn_loss_std": 8.633376121520996, "report/image_loss_mean": 11.91313362121582, "report/image_loss_std": 12.690120697021484, "report/model_loss_mean": 19.565202713012695, "report/model_loss_std": 16.405847549438477, "report/post_ent_mag": 53.18257141113281, "report/post_ent_max": 53.18257141113281, "report/post_ent_mean": 36.8799934387207, "report/post_ent_min": 19.362083435058594, "report/post_ent_std": 6.2042622566223145, "report/prior_ent_mag": 64.31330871582031, "report/prior_ent_max": 64.31330871582031, "report/prior_ent_mean": 49.75579071044922, "report/prior_ent_min": 23.777231216430664, "report/prior_ent_std": 7.606719970703125, "report/rep_loss_mean": 12.63325309753418, "report/rep_loss_std": 8.633376121520996, "report/reward_avg": 0.02070312574505806, "report/reward_loss_mean": 0.06540538370609283, "report/reward_loss_std": 0.37056243419647217, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.005504846572876, "report/reward_neg_acc": 0.9979960322380066, "report/reward_neg_loss": 0.03394009545445442, "report/reward_pos_acc": 0.884615421295166, "report/reward_pos_loss": 1.273188591003418, "report/reward_pred": 0.016714448109269142, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00022981184883974493, "eval/cont_loss_std": 0.006035610102117062, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001048461184836924, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00022740640270058066, "eval/cont_pred": 0.9968637824058533, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.062469482421875, "eval/dyn_loss_std": 8.766003608703613, "eval/image_loss_mean": 20.008756637573242, "eval/image_loss_std": 15.980263710021973, "eval/model_loss_mean": 30.9674015045166, "eval/model_loss_std": 19.81229591369629, "eval/post_ent_mag": 52.927093505859375, "eval/post_ent_max": 52.927093505859375, "eval/post_ent_mean": 34.858543395996094, "eval/post_ent_min": 21.682781219482422, "eval/post_ent_std": 4.762807369232178, "eval/prior_ent_mag": 64.31330871582031, "eval/prior_ent_max": 64.31330871582031, "eval/prior_ent_mean": 49.382568359375, "eval/prior_ent_min": 23.73400115966797, "eval/prior_ent_std": 8.123665809631348, "eval/rep_loss_mean": 18.062469482421875, "eval/rep_loss_std": 8.766003608703613, "eval/reward_avg": 0.008496093563735485, "eval/reward_loss_mean": 0.12093303352594376, "eval/reward_loss_std": 0.8523852825164795, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9990460872650146, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.08044305443763733, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 3.535588026046753, "eval/reward_pred": 0.004524744115769863, "eval/reward_rate": 0.01171875, "replay/size": 129497.0, "replay/inserts": 21592.0, "replay/samples": 21584.0, "replay/insert_wait_avg": 1.3857803860608186e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0740544903799725e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 27936.0, "eval_replay/inserts": 5712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2430156312402891e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1014.3584439754486, "timer/env.step_count": 2699.0, "timer/env.step_total": 261.80210852622986, "timer/env.step_frac": 0.2580962480089203, "timer/env.step_avg": 0.09699966970219706, "timer/env.step_min": 0.022118330001831055, "timer/env.step_max": 3.3364646434783936, "timer/replay._sample_count": 21584.0, "timer/replay._sample_total": 11.219351768493652, "timer/replay._sample_frac": 0.011060539629879794, "timer/replay._sample_avg": 0.0005197994703712775, "timer/replay._sample_min": 0.0003914833068847656, "timer/replay._sample_max": 0.010986089706420898, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3413.0, "timer/agent.policy_total": 54.8257954120636, "timer/agent.policy_frac": 0.05404972545719804, "timer/agent.policy_avg": 0.0160638134814133, "timer/agent.policy_min": 0.009337663650512695, "timer/agent.policy_max": 0.08273839950561523, "timer/dataset_train_count": 1349.0, "timer/dataset_train_total": 0.14643049240112305, "timer/dataset_train_frac": 0.00014435773988062472, "timer/dataset_train_avg": 0.00010854743691706675, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0005018711090087891, "timer/agent.train_count": 1349.0, "timer/agent.train_total": 600.3700785636902, "timer/agent.train_frac": 0.5918717216083247, "timer/agent.train_avg": 0.44504824207834703, "timer/agent.train_min": 0.4321410655975342, "timer/agent.train_max": 1.405076503753662, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47138023376464844, "timer/agent.report_frac": 0.000464707753520764, "timer/agent.report_avg": 0.23569011688232422, "timer/agent.report_min": 0.22924232482910156, "timer/agent.report_max": 0.24213790893554688, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.0790726934650174e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 21.286084403742848}
{"step": 130144, "time": 6347.4332280159, "episode/length": 135.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 130240, "time": 6352.063658952713, "episode/length": 265.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 130408, "time": 6359.004683256149, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 130408, "time": 6359.0144073963165, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 130448, "time": 6363.745410442352, "episode/length": 37.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 130560, "time": 6369.02348279953, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 130888, "time": 6381.105344057083, "episode/length": 80.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9259259259259259, "episode/intrinsic_return": 0.0}
{"step": 130976, "time": 6385.739228010178, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 131304, "time": 6399.359011888504, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 131608, "time": 6410.892260551453, "episode/length": 249.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 131728, "time": 6416.771904230118, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 131912, "time": 6424.1343603134155, "episode/length": 187.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 132112, "time": 6432.502186059952, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 132240, "time": 6438.293147087097, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 132328, "time": 6442.545729875565, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 132456, "time": 6448.4092428684235, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 132928, "time": 6466.275017738342, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 132968, "time": 6469.010917425156, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 133320, "time": 6482.393204212189, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 133336, "time": 6485.003699541092, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 133424, "time": 6490.350586414337, "episode/length": 147.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 133720, "time": 6501.936249494553, "episode/length": 36.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 133768, "time": 6505.244491100311, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 134152, "time": 6519.604560852051, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 134224, "time": 6523.7688891887665, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 134528, "time": 6535.695269584656, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 134752, "time": 6545.233871221542, "episode/length": 122.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.943089430894309, "episode/intrinsic_return": 0.0}
{"step": 134832, "time": 6549.585025072098, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 134984, "time": 6555.787245988846, "episode/length": 358.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9860724233983287, "episode/intrinsic_return": 0.0}
{"step": 135048, "time": 6559.340261936188, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 135288, "time": 6568.90117764473, "episode/length": 294.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 135384, "time": 6573.720552444458, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 135584, "time": 6582.160959482193, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 135768, "time": 6589.612275123596, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 135976, "time": 6598.181552648544, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 136312, "time": 6610.782415390015, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 136480, "time": 6618.0737590789795, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 136656, "time": 6625.439615011215, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 136664, "time": 6627.134929418564, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 136792, "time": 6632.928128957748, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 137080, "time": 6644.11430978775, "episode/length": 186.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 137128, "time": 6647.254360437393, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 137248, "time": 6652.95447063446, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 137488, "time": 6662.631513595581, "episode/length": 146.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 137576, "time": 6666.830608844757, "episode/length": 40.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 137680, "time": 6672.088156938553, "episode/length": 126.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9448818897637795, "episode/intrinsic_return": 0.0}
{"step": 137800, "time": 6677.355020523071, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 138072, "time": 6687.911245107651, "episode/length": 33.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 138192, "time": 6693.782944440842, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 138288, "time": 6698.488968610764, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 138672, "time": 6712.6937782764435, "episode/length": 251.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 138976, "time": 6724.394678115845, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 139016, "time": 6727.5885972976685, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 139112, "time": 6732.844945907593, "episode/length": 247.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 139264, "time": 6740.458485364914, "episode/length": 210.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 139528, "time": 6752.650632381439, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 139552, "time": 6755.751720666885, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 139584, "time": 6758.891854286194, "episode/length": 39.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 6797.263593196869, "eval_episode/length": 50.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 140088, "time": 6803.511274814606, "eval_episode/length": 154.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9612903225806452}
{"step": 140088, "time": 6805.432152032852, "eval_episode/length": 161.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 140088, "time": 6807.367444515228, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 140088, "time": 6809.53214263916, "eval_episode/length": 186.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9625668449197861}
{"step": 140088, "time": 6811.622159957886, "eval_episode/length": 198.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 140088, "time": 6813.503612041473, "eval_episode/length": 205.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9805825242718447}
{"step": 140088, "time": 6815.587730646133, "eval_episode/length": 215.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 140136, "time": 6817.197779178619, "episode/length": 230.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 140448, "time": 6829.282749414444, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 140624, "time": 6836.759325027466, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 140832, "time": 6845.291707992554, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 140848, "time": 6847.4119329452515, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 140920, "time": 6851.081219911575, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 140976, "time": 6854.729854106903, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 141072, "time": 6859.490909814835, "episode/length": 192.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 141344, "time": 6869.962361335754, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 141952, "time": 6891.94472527504, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 142048, "time": 6896.6467571258545, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 142192, "time": 6902.92077922821, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 142360, "time": 6909.885679244995, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 142392, "time": 6912.528649330139, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 142432, "time": 6915.780859470367, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 142992, "time": 6936.005560874939, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 143208, "time": 6944.55707359314, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 143224, "time": 6946.680240392685, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 143224, "time": 6946.691150903702, "episode/length": 268.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 143656, "time": 6964.3063588142395, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 143704, "time": 6967.450902938843, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 143768, "time": 6971.189331293106, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 143968, "time": 6979.535078287125, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 144480, "time": 6998.121783018112, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 144776, "time": 7009.280083656311, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 144840, "time": 7013.005645275116, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 145048, "time": 7021.587073802948, "episode/length": 167.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 145056, "time": 7023.620786190033, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 145480, "time": 7038.953280687332, "episode/length": 310.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9871382636655949, "episode/intrinsic_return": 0.0}
{"step": 145480, "time": 7038.963336229324, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 145536, "time": 7044.249707221985, "episode/length": 195.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 145824, "time": 7055.478026390076, "episode/length": 167.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 146016, "time": 7063.353175878525, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 146328, "time": 7074.939944028854, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 146368, "time": 7078.161161661148, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 146472, "time": 7082.919735908508, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 146848, "time": 7097.0262570381165, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 146872, "time": 7099.110349416733, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 147128, "time": 7109.246308326721, "episode/length": 205.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 147408, "time": 7120.243375778198, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 147744, "time": 7134.402574300766, "episode/length": 215.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 147752, "time": 7135.9878623485565, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 147880, "time": 7141.950647592545, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 148256, "time": 7156.287493228912, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 148424, "time": 7163.199355125427, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 148600, "time": 7170.6350519657135, "episode/length": 215.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 148696, "time": 7175.478055477142, "episode/length": 54.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 148840, "time": 7182.370095729828, "episode/length": 308.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 148896, "time": 7186.520241498947, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 148936, "time": 7189.624796867371, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 149432, "time": 7208.822353839874, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 149520, "time": 7214.2390167713165, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 149856, "time": 7227.084671735764, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 150000, "time": 7233.433443069458, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 150048, "time": 7236.637886762619, "episode/length": 168.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 150064, "time": 7238.7995591163635, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 7259.55747795105, "eval_episode/length": 149.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 150072, "time": 7262.2174253463745, "eval_episode/length": 172.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.976878612716763}
{"step": 150072, "time": 7264.411903381348, "eval_episode/length": 183.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 150072, "time": 7266.805933713913, "eval_episode/length": 184.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 150072, "time": 7269.138855934143, "eval_episode/length": 192.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9896373056994818}
{"step": 150072, "time": 7271.414852380753, "eval_episode/length": 196.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 150072, "time": 7274.044711351395, "eval_episode/length": 209.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9809523809523809}
{"step": 150072, "time": 7276.5290331840515, "eval_episode/length": 32.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 150240, "time": 7282.311459064484, "episode/length": 167.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 150568, "time": 7294.427905797958, "episode/length": 203.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 150688, "time": 7300.182410955429, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 150856, "time": 7306.955166101456, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 151320, "time": 7324.118009567261, "episode/length": 182.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 151408, "time": 7328.908504724503, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 151753, "time": 7342.723889827728, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.467582253848805, "train/action_min": 0.0, "train/action_std": 3.1600923380431007, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05100591787520577, "train/actor_opt_grad_steps": 8705.0, "train/actor_opt_loss": 3.6043652453843285, "train/adv_mag": 0.8345422280185363, "train/adv_max": 0.8269425597699249, "train/adv_mean": 0.0055246967376660905, "train/adv_min": -0.47561296360457644, "train/adv_std": 0.08346834710306104, "train/cont_avg": 0.9944781135110294, "train/cont_loss_mean": 0.000474209225377736, "train/cont_loss_std": 0.012943889881405405, "train/cont_neg_acc": 0.9850198424914304, "train/cont_neg_loss": 0.04091267726222307, "train/cont_pos_acc": 0.999913351939005, "train/cont_pos_loss": 0.00028267495071829403, "train/cont_pred": 0.9944289699196815, "train/cont_rate": 0.9944781135110294, "train/dyn_loss_mean": 14.56763993291294, "train/dyn_loss_std": 8.911977957276736, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1896360477103907, "train/extr_critic_critic_opt_grad_steps": 8705.0, "train/extr_critic_critic_opt_loss": 16218.637487074908, "train/extr_critic_mag": 3.901703038636376, "train/extr_critic_max": 3.901703038636376, "train/extr_critic_mean": 1.0223323860589195, "train/extr_critic_min": -0.19745873616022222, "train/extr_critic_std": 1.0122753565802294, "train/extr_return_normed_mag": 1.8108707946889542, "train/extr_return_normed_max": 1.8108707946889542, "train/extr_return_normed_mean": 0.3647559770547292, "train/extr_return_normed_min": -0.1454561340403469, "train/extr_return_normed_std": 0.34150194245226245, "train/extr_return_rate": 0.5890338079017752, "train/extr_return_raw_mag": 5.512644006925471, "train/extr_return_raw_max": 5.512644006925471, "train/extr_return_raw_mean": 1.0394046876360388, "train/extr_return_raw_min": -0.5390800884103074, "train/extr_return_raw_std": 1.0565846089054556, "train/extr_reward_mag": 1.0064526428194607, "train/extr_reward_max": 1.0064526428194607, "train/extr_reward_mean": 0.02072648174019859, "train/extr_reward_min": -0.3351171069285449, "train/extr_reward_std": 0.12846494986511328, "train/image_loss_mean": 12.418683174778433, "train/image_loss_std": 14.319720643408159, "train/model_loss_mean": 21.213999776279223, "train/model_loss_std": 18.066354898845447, "train/model_opt_grad_norm": 82.7213176839492, "train/model_opt_grad_steps": 8693.213235294117, "train/model_opt_loss": 14986.712926528033, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 707.7205882352941, "train/policy_entropy_mag": 2.2816040095160988, "train/policy_entropy_max": 2.2816040095160988, "train/policy_entropy_mean": 0.5373620645088308, "train/policy_entropy_min": 0.07937851181144223, "train/policy_entropy_std": 0.43308621776454587, "train/policy_logprob_mag": 7.438372205285465, "train/policy_logprob_max": -0.00945645903565866, "train/policy_logprob_mean": -0.5362039499861353, "train/policy_logprob_min": -7.438372205285465, "train/policy_logprob_std": 1.0471047465415562, "train/policy_randomness_mag": 0.8053060905898318, "train/policy_randomness_max": 0.8053060905898318, "train/policy_randomness_mean": 0.18966522801886587, "train/policy_randomness_min": 0.0280171312556109, "train/policy_randomness_std": 0.15286042782313683, "train/post_ent_mag": 53.99758167827831, "train/post_ent_max": 53.99758167827831, "train/post_ent_mean": 37.479092233321246, "train/post_ent_min": 20.543594542671652, "train/post_ent_std": 5.878238993532517, "train/prior_ent_mag": 64.71424902186675, "train/prior_ent_max": 64.71424902186675, "train/prior_ent_mean": 52.17741250991821, "train/prior_ent_min": 27.996117942473468, "train/prior_ent_std": 6.705383114955005, "train/rep_loss_mean": 14.56763993291294, "train/rep_loss_std": 8.911977957276736, "train/reward_avg": 0.018157599808867362, "train/reward_loss_mean": 0.054258610121905804, "train/reward_loss_std": 0.27179797300521064, "train/reward_max_data": 1.0058823543436386, "train/reward_max_pred": 1.0033892130150515, "train/reward_neg_acc": 0.9937892635078991, "train/reward_neg_loss": 0.03261262086658355, "train/reward_pos_acc": 0.9413691263865022, "train/reward_pos_loss": 0.9741924365653711, "train/reward_pred": 0.017299982037751332, "train/reward_rate": 0.02311437270220588, "train_stats/sum_log_reward": 4.633333285649617, "train_stats/max_log_achievement_collect_drink": 3.925, "train_stats/max_log_achievement_collect_sapling": 2.683333333333333, "train_stats/max_log_achievement_collect_wood": 4.108333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.016666666666666666, "train_stats/max_log_achievement_defeat_zombie": 0.21666666666666667, "train_stats/max_log_achievement_eat_cow": 0.06666666666666667, "train_stats/max_log_achievement_make_wood_pickaxe": 0.041666666666666664, "train_stats/max_log_achievement_make_wood_sword": 0.03333333333333333, "train_stats/max_log_achievement_place_plant": 2.575, "train_stats/max_log_achievement_place_table": 1.5583333333333333, "train_stats/max_log_achievement_wake_up": 1.4166666666666667, "train_stats/mean_log_entropy": 0.512251186867555, "eval_stats/sum_log_reward": 4.5374999940395355, "eval_stats/max_log_achievement_collect_drink": 3.75, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_wood": 3.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_table": 1.3125, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 4.8039646571851335e-06, "report/cont_loss_std": 4.495393659453839e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004136898787692189, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.9896067442459753e-06, "report/cont_pred": 0.9931648969650269, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 15.891361236572266, "report/dyn_loss_std": 8.930377006530762, "report/image_loss_mean": 11.996465682983398, "report/image_loss_std": 12.927521705627441, "report/model_loss_mean": 21.59396743774414, "report/model_loss_std": 16.798484802246094, "report/post_ent_mag": 58.29792022705078, "report/post_ent_max": 58.29792022705078, "report/post_ent_mean": 37.915611267089844, "report/post_ent_min": 22.850873947143555, "report/post_ent_std": 6.436763763427734, "report/prior_ent_mag": 64.26231384277344, "report/prior_ent_max": 64.26231384277344, "report/prior_ent_mean": 54.026695251464844, "report/prior_ent_min": 30.147029876708984, "report/prior_ent_std": 5.602040767669678, "report/rep_loss_mean": 15.891361236572266, "report/rep_loss_std": 8.930377006530762, "report/reward_avg": 0.02080078050494194, "report/reward_loss_mean": 0.06267991662025452, "report/reward_loss_std": 0.303963840007782, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012741088867188, "report/reward_neg_acc": 0.9919679760932922, "report/reward_neg_loss": 0.036879997700452805, "report/reward_pos_acc": 0.9642857313156128, "report/reward_pos_loss": 0.9804199934005737, "report/reward_pred": 0.02054917812347412, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.709995669647469e-06, "eval/cont_loss_std": 3.694613405968994e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00010114422184415162, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.420766577415634e-06, "eval/cont_pred": 0.9970681667327881, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 14.778247833251953, "eval/dyn_loss_std": 8.282301902770996, "eval/image_loss_mean": 10.919154167175293, "eval/image_loss_std": 11.876461029052734, "eval/model_loss_mean": 19.857715606689453, "eval/model_loss_std": 15.158682823181152, "eval/post_ent_mag": 53.47615051269531, "eval/post_ent_max": 53.47615051269531, "eval/post_ent_mean": 40.141265869140625, "eval/post_ent_min": 21.05838394165039, "eval/post_ent_std": 6.040408134460449, "eval/prior_ent_mag": 64.06192779541016, "eval/prior_ent_max": 64.06192779541016, "eval/prior_ent_mean": 52.050655364990234, "eval/prior_ent_min": 29.326499938964844, "eval/prior_ent_std": 4.764165878295898, "eval/rep_loss_mean": 14.778247833251953, "eval/rep_loss_std": 8.282301902770996, "eval/reward_avg": 0.00859374925494194, "eval/reward_loss_mean": 0.07160934805870056, "eval/reward_loss_std": 0.5503326058387756, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017359256744385, "eval/reward_neg_acc": 0.9970356225967407, "eval/reward_neg_loss": 0.038566187024116516, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 2.8582491874694824, "eval/reward_pred": 0.004481697455048561, "eval/reward_rate": 0.01171875, "replay/size": 151249.0, "replay/inserts": 21752.0, "replay/samples": 21760.0, "replay/insert_wait_avg": 1.3893318772535194e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.058278276639826e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31408.0, "eval_replay/inserts": 3472.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2778604085544288e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2423808574677, "timer/env.step_count": 2719.0, "timer/env.step_total": 269.0717704296112, "timer/env.step_frac": 0.2690065683869012, "timer/env.step_avg": 0.09895982730033513, "timer/env.step_min": 0.02220940589904785, "timer/env.step_max": 3.381599187850952, "timer/replay._sample_count": 21760.0, "timer/replay._sample_total": 11.217051982879639, "timer/replay._sample_frac": 0.011214333843026838, "timer/replay._sample_avg": 0.0005154895212720422, "timer/replay._sample_min": 0.00038313865661621094, "timer/replay._sample_max": 0.00912165641784668, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3153.0, "timer/agent.policy_total": 51.30659794807434, "timer/agent.policy_frac": 0.05129416522432418, "timer/agent.policy_avg": 0.016272311432944605, "timer/agent.policy_min": 0.009094715118408203, "timer/agent.policy_max": 0.09736084938049316, "timer/dataset_train_count": 1360.0, "timer/dataset_train_total": 0.1422715187072754, "timer/dataset_train_frac": 0.000142237043170788, "timer/dataset_train_avg": 0.00010461141081417308, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0002484321594238281, "timer/agent.train_count": 1360.0, "timer/agent.train_total": 608.2752375602722, "timer/agent.train_frac": 0.6081278390132022, "timer/agent.train_avg": 0.44726120408843545, "timer/agent.train_min": 0.43267107009887695, "timer/agent.train_max": 1.4526727199554443, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47128963470458984, "timer/agent.report_frac": 0.00047117543079965496, "timer/agent.report_avg": 0.23564481735229492, "timer/agent.report_min": 0.23000574111938477, "timer/agent.report_max": 0.24128389358520508, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.289379109072569e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 21.746445507996068}
{"step": 151968, "time": 7350.010687589645, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 151984, "time": 7352.231878042221, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 151992, "time": 7353.854107379913, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 152000, "time": 7355.925941944122, "episode/length": 142.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.951048951048951, "episode/intrinsic_return": 0.0}
{"step": 152104, "time": 7360.784137248993, "episode/length": 254.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 152184, "time": 7364.986156702042, "episode/length": 242.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 152776, "time": 7386.162819385529, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 152888, "time": 7391.4072070121765, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 153248, "time": 7405.183934688568, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 153288, "time": 7408.026455879211, "episode/length": 137.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 153352, "time": 7411.682521104813, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 153456, "time": 7416.9196083545685, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 153528, "time": 7420.712627649307, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 153688, "time": 7427.579357624054, "episode/length": 212.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 154448, "time": 7455.174510478973, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 154480, "time": 7458.28790640831, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 154496, "time": 7460.867855787277, "episode/length": 214.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 154552, "time": 7464.691515922546, "episode/length": 149.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 154632, "time": 7469.583876371384, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 154672, "time": 7473.226641893387, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 155672, "time": 7510.191250085831, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 155840, "time": 7517.530904054642, "episode/length": 268.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 155840, "time": 7517.540086269379, "episode/length": 145.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 156000, "time": 7526.106365919113, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 156136, "time": 7532.062678575516, "episode/length": 206.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 156424, "time": 7543.134471178055, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 156432, "time": 7545.175562143326, "episode/length": 362.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9944903581267218, "episode/intrinsic_return": 0.0}
{"step": 156688, "time": 7555.095794916153, "episode/length": 32.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 156776, "time": 7559.4574184417725, "episode/length": 277.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 157216, "time": 7575.6495106220245, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 157416, "time": 7583.736156463623, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 157456, "time": 7586.810763597488, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 157656, "time": 7594.860034227371, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 158296, "time": 7617.797906398773, "episode/length": 269.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 158320, "time": 7620.324285268784, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 158424, "time": 7625.249455213547, "episode/length": 248.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 158504, "time": 7629.516576290131, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 158888, "time": 7643.736688375473, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 158936, "time": 7647.449666261673, "episode/length": 214.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 159288, "time": 7661.475496530533, "episode/length": 233.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 159568, "time": 7673.32040977478, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 159696, "time": 7679.89159321785, "episode/length": 100.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9405940594059405, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 7712.444323062897, "eval_episode/length": 23.0, "eval_episode/score": 2.1000000163912773, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 160056, "time": 7715.247425317764, "eval_episode/length": 38.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 160056, "time": 7717.319256782532, "eval_episode/length": 39.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.925}
{"step": 160056, "time": 7726.7977459430695, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 160056, "time": 7729.030514955521, "eval_episode/length": 175.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 160056, "time": 7731.688622236252, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 160056, "time": 7735.009040355682, "eval_episode/length": 214.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 160056, "time": 7737.47185587883, "eval_episode/length": 178.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.994413407821229}
{"step": 160096, "time": 7739.069184303284, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 160120, "time": 7741.326785087585, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 160384, "time": 7751.667937755585, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 160384, "time": 7751.678030490875, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 160400, "time": 7755.548822879791, "episode/length": 342.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9854227405247813, "episode/intrinsic_return": 0.0}
{"step": 160536, "time": 7761.3779883384705, "episode/length": 155.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 160920, "time": 7775.526783704758, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 161232, "time": 7787.579428195953, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 161712, "time": 7805.037699699402, "episode/length": 165.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 161816, "time": 7809.663048028946, "episode/length": 211.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 161928, "time": 7815.005029678345, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 161984, "time": 7818.669807195663, "episode/length": 197.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 161984, "time": 7818.679045915604, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 162008, "time": 7822.434708118439, "episode/length": 135.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 162208, "time": 7830.925215005875, "episode/length": 263.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 162528, "time": 7843.070828199387, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 163032, "time": 7861.099166631699, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 163056, "time": 7863.702394485474, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 163240, "time": 7871.092663049698, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 163304, "time": 7874.664280653, "episode/length": 33.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 163352, "time": 7878.291543960571, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 163408, "time": 7882.508705615997, "episode/length": 177.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 163504, "time": 7887.744309186935, "episode/length": 189.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 163680, "time": 7895.848772525787, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 164280, "time": 7919.858094453812, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 164376, "time": 7924.988747835159, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 164464, "time": 7929.806876897812, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 164680, "time": 7938.284597158432, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 164728, "time": 7941.37353682518, "episode/length": 185.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 164936, "time": 7949.819662570953, "episode/length": 197.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 164976, "time": 7952.977771282196, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 164992, "time": 7955.085412025452, "episode/length": 163.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.0}
{"step": 165344, "time": 7968.37025642395, "episode/length": 43.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 165640, "time": 7980.252244949341, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 165880, "time": 7990.548203706741, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 165896, "time": 7993.134211063385, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 166064, "time": 8001.012586593628, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 166080, "time": 8003.476896762848, "episode/length": 137.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 166104, "time": 8006.070929765701, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 166360, "time": 8017.000647783279, "episode/length": 177.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 166496, "time": 8023.763832569122, "episode/length": 143.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 167104, "time": 8046.063197612762, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 167232, "time": 8052.452318906784, "episode/length": 143.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 167296, "time": 8056.576411724091, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 167624, "time": 8069.324696779251, "episode/length": 40.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 167728, "time": 8074.507884025574, "episode/length": 170.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 167776, "time": 8077.645761728287, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 167896, "time": 8082.9305539131165, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 167912, "time": 8085.199353694916, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 168000, "time": 8089.718561887741, "episode/length": 187.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 168440, "time": 8105.547850847244, "episode/length": 166.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 168600, "time": 8112.444464445114, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 168936, "time": 8125.148578643799, "episode/length": 163.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 169088, "time": 8131.961332559586, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 169232, "time": 8138.14822268486, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 169288, "time": 8141.358558177948, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 169392, "time": 8146.555588006973, "episode/length": 207.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 169640, "time": 8156.090080738068, "episode/length": 50.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9215686274509803, "episode/intrinsic_return": 0.0}
{"step": 169720, "time": 8160.487397909164, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 169896, "time": 8167.885157108307, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 8193.26531124115, "eval_episode/length": 146.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9727891156462585}
{"step": 170040, "time": 8195.480432987213, "eval_episode/length": 160.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 170040, "time": 8195.488562345505, "eval_episode/length": 160.0, "eval_episode/score": 5.099999964237213, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 170040, "time": 8199.587019205093, "eval_episode/length": 174.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 170040, "time": 8201.534396409988, "eval_episode/length": 181.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 170040, "time": 8203.213893651962, "eval_episode/length": 183.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 170040, "time": 8204.830489873886, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 170040, "time": 8207.970561742783, "eval_episode/length": 223.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 170120, "time": 8210.619407176971, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 170952, "time": 8239.674770355225, "episode/length": 251.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 170960, "time": 8241.614492416382, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700854700854701, "episode/intrinsic_return": 0.0}
{"step": 170968, "time": 8243.138122320175, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 171016, "time": 8246.279368638992, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 171176, "time": 8253.15452337265, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 171176, "time": 8253.16365647316, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 171312, "time": 8261.169946670532, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 171664, "time": 8274.35127210617, "episode/length": 60.0, "episode/score": 2.1000000163912773, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 171768, "time": 8279.227391719818, "episode/length": 205.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 172184, "time": 8295.81866145134, "episode/length": 152.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 172456, "time": 8306.493369102478, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 172648, "time": 8314.518338918686, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 172680, "time": 8317.174148321152, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 172712, "time": 8319.800711393356, "episode/length": 217.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 172840, "time": 8325.688630104065, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 173281, "time": 8342.74025440216, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.616745334201389, "train/action_min": 0.0, "train/action_std": 3.4140772342681887, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04932008082116092, "train/actor_opt_grad_steps": 10060.0, "train/actor_opt_loss": -4.79802773616932, "train/adv_mag": 0.7491146635126185, "train/adv_max": 0.729375770577678, "train/adv_mean": 0.003423312146225254, "train/adv_min": -0.5159787771878419, "train/adv_std": 0.07948226045679163, "train/cont_avg": 0.9943142361111111, "train/cont_loss_mean": 0.0004112467409335615, "train/cont_loss_std": 0.010776373954164834, "train/cont_neg_acc": 0.9903027640448676, "train/cont_neg_loss": 0.023358372932883262, "train/cont_pos_acc": 0.9999125878016154, "train/cont_pos_loss": 0.0002600285813779616, "train/cont_pred": 0.9942682425181071, "train/cont_rate": 0.9943142361111111, "train/dyn_loss_mean": 15.16458784032751, "train/dyn_loss_std": 9.215918851781774, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1047371793676306, "train/extr_critic_critic_opt_grad_steps": 10060.0, "train/extr_critic_critic_opt_loss": 16147.751663773148, "train/extr_critic_mag": 4.16516361589785, "train/extr_critic_max": 4.16516361589785, "train/extr_critic_mean": 0.9705633565231606, "train/extr_critic_min": -0.19817286685661034, "train/extr_critic_std": 1.0410707650361237, "train/extr_return_normed_mag": 1.8102836741341486, "train/extr_return_normed_max": 1.8102836741341486, "train/extr_return_normed_mean": 0.33204582024503637, "train/extr_return_normed_min": -0.1470868687386866, "train/extr_return_normed_std": 0.3400261303892842, "train/extr_return_rate": 0.5362046963638729, "train/extr_return_raw_mag": 5.672394462868019, "train/extr_return_raw_max": 5.672394462868019, "train/extr_return_raw_mean": 0.9814827640851339, "train/extr_return_raw_min": -0.5387546603326444, "train/extr_return_raw_std": 1.0789612982008192, "train/extr_reward_mag": 1.0081735805228904, "train/extr_reward_max": 1.0081735805228904, "train/extr_reward_mean": 0.02100173621955845, "train/extr_reward_min": -0.3357598816906964, "train/extr_reward_std": 0.13030552218357722, "train/image_loss_mean": 11.679953115957755, "train/image_loss_std": 13.908740280292653, "train/model_loss_mean": 20.836816632306135, "train/model_loss_std": 17.781128388864023, "train/model_opt_grad_norm": 78.96773141931604, "train/model_opt_grad_steps": 10046.785185185185, "train/model_opt_loss": 13768.434816261573, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 662.0370370370371, "train/policy_entropy_mag": 2.3066916871953893, "train/policy_entropy_max": 2.3066916871953893, "train/policy_entropy_mean": 0.5666890537297284, "train/policy_entropy_min": 0.07937681321744565, "train/policy_entropy_std": 0.4733203715748257, "train/policy_logprob_mag": 7.438377768905075, "train/policy_logprob_max": -0.009456162168471902, "train/policy_logprob_mean": -0.5665899943422388, "train/policy_logprob_min": -7.438377768905075, "train/policy_logprob_std": 1.067008090902258, "train/policy_randomness_mag": 0.8141609386161521, "train/policy_randomness_max": 0.8141609386161521, "train/policy_randomness_mean": 0.20001636820810811, "train/policy_randomness_min": 0.028016531646803573, "train/policy_randomness_std": 0.16706131900902146, "train/post_ent_mag": 55.174645770037614, "train/post_ent_max": 55.174645770037614, "train/post_ent_mean": 37.97733391655816, "train/post_ent_min": 20.904621435094764, "train/post_ent_std": 6.2577759318881565, "train/prior_ent_mag": 65.45122960408528, "train/prior_ent_max": 65.45122960408528, "train/prior_ent_mean": 53.2747683207194, "train/prior_ent_min": 29.031295635082103, "train/prior_ent_std": 6.499321623201723, "train/rep_loss_mean": 15.16458784032751, "train/rep_loss_std": 9.215918851781774, "train/reward_avg": 0.019612268303279525, "train/reward_loss_mean": 0.05769970441857974, "train/reward_loss_std": 0.28280079144018666, "train/reward_max_data": 1.016296300181636, "train/reward_max_pred": 1.0047944757673475, "train/reward_neg_acc": 0.9933459767588863, "train/reward_neg_loss": 0.03478014887207084, "train/reward_pos_acc": 0.9439271308757641, "train/reward_pos_loss": 0.9683779455997326, "train/reward_pred": 0.01874693490702797, "train/reward_rate": 0.024739583333333332, "train_stats/sum_log_reward": 4.566101624677747, "train_stats/max_log_achievement_collect_drink": 3.6864406779661016, "train_stats/max_log_achievement_collect_sapling": 2.330508474576271, "train_stats/max_log_achievement_collect_wood": 5.093220338983051, "train_stats/max_log_achievement_defeat_skeleton": 0.00847457627118644, "train_stats/max_log_achievement_defeat_zombie": 0.2966101694915254, "train_stats/max_log_achievement_eat_cow": 0.059322033898305086, "train_stats/max_log_achievement_make_wood_pickaxe": 0.00847457627118644, "train_stats/max_log_achievement_make_wood_sword": 0.0847457627118644, "train_stats/max_log_achievement_place_plant": 2.2203389830508473, "train_stats/max_log_achievement_place_table": 2.152542372881356, "train_stats/max_log_achievement_wake_up": 1.5423728813559323, "train_stats/mean_log_entropy": 0.5382747839568025, "eval_stats/sum_log_reward": 4.037499912083149, "eval_stats/max_log_achievement_collect_drink": 3.4375, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_wood": 4.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.1875, "eval_stats/max_log_achievement_place_plant": 2.25, "eval_stats/max_log_achievement_place_table": 1.5, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0007468272815458477, "report/cont_loss_std": 0.022795673459768295, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 0.18438182771205902, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.6689915102906525e-05, "report/cont_pred": 0.9965808391571045, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.76862907409668, "report/dyn_loss_std": 8.896775245666504, "report/image_loss_mean": 10.556184768676758, "report/image_loss_std": 11.809619903564453, "report/model_loss_mean": 19.462677001953125, "report/model_loss_std": 15.378387451171875, "report/post_ent_mag": 56.856109619140625, "report/post_ent_max": 56.856109619140625, "report/post_ent_mean": 39.76676940917969, "report/post_ent_min": 22.362918853759766, "report/post_ent_std": 7.007546901702881, "report/prior_ent_mag": 65.82884216308594, "report/prior_ent_max": 65.82884216308594, "report/prior_ent_mean": 54.84825897216797, "report/prior_ent_min": 31.159486770629883, "report/prior_ent_std": 5.75499153137207, "report/rep_loss_mean": 14.76862907409668, "report/rep_loss_std": 8.896775245666504, "report/reward_avg": 0.005468749441206455, "report/reward_loss_mean": 0.04456917196512222, "report/reward_loss_std": 0.2027950882911682, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.998534083366394, "report/reward_neg_acc": 0.9950593113899231, "report/reward_neg_loss": 0.03425973653793335, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.9139983654022217, "report/reward_pred": 0.004901524633169174, "report/reward_rate": 0.01171875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00015445280587300658, "eval/cont_loss_std": 0.0034167072735726833, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.03057803213596344, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.171263183001429e-06, "eval/cont_pred": 0.9952556490898132, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.091887474060059, "eval/dyn_loss_std": 10.270085334777832, "eval/image_loss_mean": 16.23443031311035, "eval/image_loss_std": 24.248207092285156, "eval/model_loss_mean": 25.351966857910156, "eval/model_loss_std": 28.719200134277344, "eval/post_ent_mag": 56.52214050292969, "eval/post_ent_max": 56.52214050292969, "eval/post_ent_mean": 40.1313362121582, "eval/post_ent_min": 21.82231330871582, "eval/post_ent_std": 6.5572404861450195, "eval/prior_ent_mag": 65.82884216308594, "eval/prior_ent_max": 65.82884216308594, "eval/prior_ent_mean": 52.187828063964844, "eval/prior_ent_min": 25.866241455078125, "eval/prior_ent_std": 6.731120586395264, "eval/rep_loss_mean": 15.091887474060059, "eval/rep_loss_std": 10.270085334777832, "eval/reward_avg": 0.01630859263241291, "eval/reward_loss_mean": 0.06225115805864334, "eval/reward_loss_std": 0.4547407031059265, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0015239715576172, "eval/reward_neg_acc": 0.999002993106842, "eval/reward_neg_loss": 0.030693983659148216, "eval/reward_pos_acc": 0.8571428656578064, "eval/reward_pos_loss": 1.5694819688796997, "eval/reward_pred": 0.014586633071303368, "eval/reward_rate": 0.0205078125, "replay/size": 172777.0, "replay/inserts": 21528.0, "replay/samples": 21520.0, "replay/insert_wait_avg": 1.5086664315361553e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0005714281784115e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 34952.0, "eval_replay/inserts": 3544.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2944837186998492e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0063767433167, "timer/env.step_count": 2691.0, "timer/env.step_total": 267.75355887413025, "timer/env.step_frac": 0.26775185148930075, "timer/env.step_avg": 0.09949965026909337, "timer/env.step_min": 0.022025108337402344, "timer/env.step_max": 3.371265411376953, "timer/replay._sample_count": 21520.0, "timer/replay._sample_total": 11.17537522315979, "timer/replay._sample_frac": 0.011175303961114944, "timer/replay._sample_avg": 0.0005193018226375368, "timer/replay._sample_min": 0.00038909912109375, "timer/replay._sample_max": 0.011091947555541992, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3134.0, "timer/agent.policy_total": 53.214776277542114, "timer/agent.policy_frac": 0.05321443694273699, "timer/agent.policy_avg": 0.016979826508469086, "timer/agent.policy_min": 0.009577751159667969, "timer/agent.policy_max": 0.11450815200805664, "timer/dataset_train_count": 1345.0, "timer/dataset_train_total": 0.1501755714416504, "timer/dataset_train_frac": 0.0001501746138166854, "timer/dataset_train_avg": 0.00011165469995661739, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0008730888366699219, "timer/agent.train_count": 1345.0, "timer/agent.train_total": 605.2451658248901, "timer/agent.train_frac": 0.6052413063564349, "timer/agent.train_avg": 0.4499964058177622, "timer/agent.train_min": 0.43392467498779297, "timer/agent.train_max": 1.4951746463775635, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4732787609100342, "timer/agent.report_frac": 0.0004732757429521034, "timer/agent.report_avg": 0.2366393804550171, "timer/agent.report_min": 0.22860431671142578, "timer/agent.report_max": 0.2446744441986084, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.361701965332031e-05, "timer/dataset_eval_frac": 3.361680528758187e-08, "timer/dataset_eval_avg": 3.361701965332031e-05, "timer/dataset_eval_min": 3.361701965332031e-05, "timer/dataset_eval_max": 3.361701965332031e-05, "fps": 21.527606628697576}
{"step": 173376, "time": 8346.174018621445, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 173472, "time": 8351.05826306343, "episode/length": 225.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9867256637168141, "episode/intrinsic_return": 0.0}
{"step": 173552, "time": 8355.358526468277, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 173752, "time": 8363.2724442482, "episode/length": 34.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 173760, "time": 8365.468549966812, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 174024, "time": 8375.647200107574, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 174104, "time": 8379.865216493607, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 174288, "time": 8387.749640703201, "episode/length": 180.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 174304, "time": 8389.95086812973, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 174648, "time": 8402.696879386902, "episode/length": 136.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 175168, "time": 8422.339283943176, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 175464, "time": 8434.14243388176, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 175544, "time": 8438.320323228836, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 175648, "time": 8443.657980680466, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 175864, "time": 8452.242594242096, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 175880, "time": 8454.313847541809, "episode/length": 221.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 175880, "time": 8454.322806358337, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 175976, "time": 8460.968352556229, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 176512, "time": 8480.372072696686, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 177016, "time": 8498.51304769516, "episode/length": 62.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9206349206349206, "episode/intrinsic_return": 0.0}
{"step": 177152, "time": 8504.821643352509, "episode/length": 158.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 177216, "time": 8508.60688328743, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 177224, "time": 8510.26613664627, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 177248, "time": 8512.877657175064, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 177368, "time": 8518.36278128624, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 177408, "time": 8521.45522761345, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 177648, "time": 8531.111060142517, "episode/length": 208.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 178520, "time": 8561.268176555634, "episode/length": 162.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 178592, "time": 8565.443292617798, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 178632, "time": 8568.083485841751, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 178728, "time": 8572.770425319672, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 178840, "time": 8578.176406621933, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 178864, "time": 8580.746929645538, "episode/length": 201.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 179032, "time": 8587.645954608917, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 179544, "time": 8606.480513095856, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 179808, "time": 8617.906215667725, "episode/length": 160.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 8647.029470682144, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 180024, "time": 8648.712601661682, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 180024, "time": 8650.310881376266, "eval_episode/length": 187.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 180024, "time": 8652.141373872757, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 180024, "time": 8654.25713467598, "eval_episode/length": 195.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 180024, "time": 8656.626498222351, "eval_episode/length": 202.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 180024, "time": 8659.133588790894, "eval_episode/length": 212.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 180024, "time": 8661.933907032013, "eval_episode/length": 227.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 180168, "time": 8666.879078149796, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 180216, "time": 8670.048544168472, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 180264, "time": 8674.423630475998, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 180272, "time": 8676.488155603409, "episode/length": 406.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9975429975429976, "episode/intrinsic_return": 0.0}
{"step": 180304, "time": 8679.048063516617, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 180392, "time": 8683.158168077469, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 181080, "time": 8707.2828207016, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 181208, "time": 8712.988392353058, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 181416, "time": 8721.320956707, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 181472, "time": 8725.024440050125, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 181912, "time": 8741.035157203674, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 181976, "time": 8744.73676609993, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 182152, "time": 8752.09414935112, "episode/length": 234.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 182384, "time": 8761.736697673798, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 182424, "time": 8764.432414531708, "episode/length": 125.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 182512, "time": 8769.19341635704, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 182520, "time": 8770.711660146713, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 182976, "time": 8787.889045238495, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 183112, "time": 8794.206517457962, "episode/length": 85.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 183392, "time": 8805.19388461113, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 183480, "time": 8809.56737947464, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 183984, "time": 8827.991172075272, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 184296, "time": 8839.73730134964, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 184320, "time": 8842.345064401627, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 184400, "time": 8846.5678524971, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 184680, "time": 8857.04449725151, "episode/length": 286.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 184800, "time": 8862.724105834961, "episode/length": 330.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9909365558912386, "episode/intrinsic_return": 0.0}
{"step": 184920, "time": 8868.038650035858, "episode/length": 190.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 184984, "time": 8871.742018461227, "episode/length": 37.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 185040, "time": 8875.33316230774, "episode/length": 194.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 185528, "time": 8892.77314376831, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 185624, "time": 8898.137475252151, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 185688, "time": 8902.26864027977, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 186088, "time": 8917.620507478714, "episode/length": 210.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 186272, "time": 8925.613042593002, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 186368, "time": 8930.355974674225, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 186480, "time": 8935.548847913742, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 186736, "time": 8945.529229164124, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 186872, "time": 8951.326337099075, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 187064, "time": 8959.169958114624, "episode/length": 179.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 187144, "time": 8963.285928964615, "episode/length": 50.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9215686274509803, "episode/intrinsic_return": 0.0}
{"step": 187336, "time": 8971.284751415253, "episode/length": 155.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 187584, "time": 8981.343780755997, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 187592, "time": 8983.537910699844, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 187640, "time": 8987.365023374557, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 188184, "time": 9007.275038480759, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 188296, "time": 9012.474622964859, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 188304, "time": 9014.545499801636, "episode/length": 178.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 188512, "time": 9024.22823023796, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 188832, "time": 9036.435518980026, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 188840, "time": 9038.122688770294, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 188960, "time": 9043.855520486832, "episode/length": 171.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 188968, "time": 9045.505542039871, "episode/length": 203.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 189536, "time": 9066.339478254318, "episode/length": 242.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 189784, "time": 9075.94101691246, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 9104.293563365936, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.99375}
{"step": 190008, "time": 9106.143281698227, "eval_episode/length": 167.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 190008, "time": 9107.781514406204, "eval_episode/length": 169.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 190008, "time": 9109.424786806107, "eval_episode/length": 173.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 190008, "time": 9111.68991613388, "eval_episode/length": 191.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.984375}
{"step": 190008, "time": 9114.247941493988, "eval_episode/length": 213.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9719626168224299}
{"step": 190008, "time": 9116.190769672394, "eval_episode/length": 221.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 190008, "time": 9118.95396900177, "eval_episode/length": 250.0, "eval_episode/score": 7.099999964237213, "eval_episode/reward_rate": 0.9800796812749004}
{"step": 190272, "time": 9127.958545446396, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 190376, "time": 9132.752277135849, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 190408, "time": 9135.379920721054, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 190744, "time": 9149.569829702377, "episode/length": 305.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 190768, "time": 9152.528421878815, "episode/length": 281.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 190776, "time": 9154.684919595718, "episode/length": 225.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 191008, "time": 9164.828303337097, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 191080, "time": 9168.485549926758, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 191704, "time": 9190.669514417648, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 191888, "time": 9198.3716943264, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 192408, "time": 9217.447681188583, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 192424, "time": 9220.035932779312, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 192472, "time": 9223.65588593483, "episode/length": 212.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 192496, "time": 9226.242508888245, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 192624, "time": 9231.995652914047, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 193264, "time": 9254.668191194534, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 193544, "time": 9265.262917041779, "episode/length": 34.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 193576, "time": 9267.95490193367, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 193720, "time": 9274.267426013947, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 193784, "time": 9277.888433218002, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 193880, "time": 9282.591627597809, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 194152, "time": 9293.387765407562, "episode/length": 467.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9978632478632479, "episode/intrinsic_return": 0.0}
{"step": 194192, "time": 9297.011282444, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 194408, "time": 9306.25759768486, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 194672, "time": 9317.531880378723, "episode/length": 140.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 195040, "time": 9332.240677595139, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 195184, "time": 9339.145203113556, "episode/length": 200.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 195225, "time": 9342.818310499191, "train_stats/sum_log_reward": 5.328813500828662, "train_stats/max_log_achievement_collect_drink": 4.0508474576271185, "train_stats/max_log_achievement_collect_sapling": 2.1610169491525424, "train_stats/max_log_achievement_collect_wood": 6.745762711864407, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.4152542372881356, "train_stats/max_log_achievement_eat_cow": 0.1271186440677966, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.9491525423728814, "train_stats/max_log_achievement_place_plant": 2.059322033898305, "train_stats/max_log_achievement_place_table": 2.542372881355932, "train_stats/max_log_achievement_wake_up": 1.38135593220339, "train_stats/mean_log_entropy": 0.5577057612649465, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.291470047331204, "train/action_min": 0.0, "train/action_std": 3.2001725670194974, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05036848223339902, "train/actor_opt_grad_steps": 11420.0, "train/actor_opt_loss": 1.4847615044699969, "train/adv_mag": 0.7612614518534528, "train/adv_max": 0.7486443299881733, "train/adv_mean": 0.0053191281941992975, "train/adv_min": -0.4890919945535869, "train/adv_std": 0.0793144436430757, "train/cont_avg": 0.9943972399635036, "train/cont_loss_mean": 0.00031943215797928566, "train/cont_loss_std": 0.009179108400602187, "train/cont_neg_acc": 0.9893552321587166, "train/cont_neg_loss": 0.026815432771091385, "train/cont_pos_acc": 0.9999355303980139, "train/cont_pos_loss": 0.00017421359999836376, "train/cont_pred": 0.9943811262611055, "train/cont_rate": 0.9943972399635036, "train/dyn_loss_mean": 15.54766967522837, "train/dyn_loss_std": 9.179523530667716, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.054439619509843, "train/extr_critic_critic_opt_grad_steps": 11420.0, "train/extr_critic_critic_opt_loss": 16469.48478843522, "train/extr_critic_mag": 4.5136011743197475, "train/extr_critic_max": 4.5136011743197475, "train/extr_critic_mean": 0.9689497730157671, "train/extr_critic_min": -0.2196783332058983, "train/extr_critic_std": 1.0668349740278982, "train/extr_return_normed_mag": 1.7962772097900837, "train/extr_return_normed_max": 1.7962772097900837, "train/extr_return_normed_mean": 0.3223061105848229, "train/extr_return_normed_min": -0.1389610923717927, "train/extr_return_normed_std": 0.3344060562170335, "train/extr_return_rate": 0.539958304297315, "train/extr_return_raw_mag": 5.896058590742793, "train/extr_return_raw_max": 5.896058590742793, "train/extr_return_raw_mean": 0.9866653032546496, "train/extr_return_raw_min": -0.5498429232270178, "train/extr_return_raw_std": 1.113926524228423, "train/extr_reward_mag": 1.0077757852791, "train/extr_reward_max": 1.0077757852791, "train/extr_reward_mean": 0.02277548291659268, "train/extr_reward_min": -0.31255219017502167, "train/extr_reward_std": 0.1366284675624249, "train/image_loss_mean": 10.84410749560725, "train/image_loss_std": 13.383963508327511, "train/model_loss_mean": 20.229144444430833, "train/model_loss_std": 17.20759747498227, "train/model_opt_grad_norm": 69.2092482156127, "train/model_opt_grad_steps": 11405.56204379562, "train/model_opt_loss": 13170.030579949818, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 652.3722627737226, "train/policy_entropy_mag": 2.248791182998323, "train/policy_entropy_max": 2.248791182998323, "train/policy_entropy_mean": 0.5614561662621742, "train/policy_entropy_min": 0.07937609926409965, "train/policy_entropy_std": 0.49436916117250485, "train/policy_logprob_mag": 7.438380530280789, "train/policy_logprob_max": -0.009455987639779593, "train/policy_logprob_mean": -0.5612301352250315, "train/policy_logprob_min": -7.438380530280789, "train/policy_logprob_std": 1.0595205796025966, "train/policy_randomness_mag": 0.7937246012861712, "train/policy_randomness_max": 0.7937246012861712, "train/policy_randomness_mean": 0.19816938945411766, "train/policy_randomness_min": 0.02801627970307413, "train/policy_randomness_std": 0.17449061877101008, "train/post_ent_mag": 56.46651656436224, "train/post_ent_max": 56.46651656436224, "train/post_ent_mean": 38.49010328306769, "train/post_ent_min": 21.080584630478906, "train/post_ent_std": 6.470424481552013, "train/prior_ent_mag": 66.03025801164391, "train/prior_ent_max": 66.03025801164391, "train/prior_ent_mean": 54.12657009598112, "train/prior_ent_min": 30.674367292083964, "train/prior_ent_std": 6.023883704721492, "train/rep_loss_mean": 15.54766967522837, "train/rep_loss_std": 9.179523530667716, "train/reward_avg": 0.019233291431663246, "train/reward_loss_mean": 0.05611584569415907, "train/reward_loss_std": 0.27432319565411034, "train/reward_max_data": 1.0116788349012389, "train/reward_max_pred": 1.005238365952986, "train/reward_neg_acc": 0.9930336967001866, "train/reward_neg_loss": 0.03366931273608747, "train/reward_pos_acc": 0.9503040957624895, "train/reward_pos_loss": 0.9560678100933994, "train/reward_pred": 0.018438492068871312, "train/reward_rate": 0.024307139598540146, "eval_stats/sum_log_reward": 5.7249999940395355, "eval_stats/max_log_achievement_collect_drink": 4.125, "eval_stats/max_log_achievement_collect_sapling": 2.6875, "eval_stats/max_log_achievement_collect_wood": 7.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_table": 2.875, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 5.3087874221091624e-06, "report/cont_loss_std": 0.00015385018195956945, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00014550256310030818, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.8968563532980625e-06, "report/cont_pred": 0.9970659017562866, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 15.672416687011719, "report/dyn_loss_std": 8.866251945495605, "report/image_loss_mean": 9.61032772064209, "report/image_loss_std": 11.512993812561035, "report/model_loss_mean": 19.058523178100586, "report/model_loss_std": 15.082249641418457, "report/post_ent_mag": 57.48329162597656, "report/post_ent_max": 57.48329162597656, "report/post_ent_mean": 37.90206527709961, "report/post_ent_min": 22.2586727142334, "report/post_ent_std": 6.395761489868164, "report/prior_ent_mag": 66.68694305419922, "report/prior_ent_max": 66.68694305419922, "report/prior_ent_mean": 54.04991149902344, "report/prior_ent_min": 32.63569259643555, "report/prior_ent_std": 5.906100749969482, "report/rep_loss_mean": 15.672416687011719, "report/rep_loss_std": 8.866251945495605, "report/reward_avg": 0.03291015699505806, "report/reward_loss_mean": 0.044740088284015656, "report/reward_loss_std": 0.2027748078107834, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0079669952392578, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.01608537882566452, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.8091238141059875, "report/reward_pred": 0.02988390251994133, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0002696371520869434, "eval/cont_loss_std": 0.008589121513068676, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.06883960962295532, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.352990678555216e-07, "eval/cont_pred": 0.9963282346725464, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.232035636901855, "eval/dyn_loss_std": 9.43028736114502, "eval/image_loss_mean": 18.93339729309082, "eval/image_loss_std": 25.889616012573242, "eval/model_loss_mean": 28.125045776367188, "eval/model_loss_std": 29.208847045898438, "eval/post_ent_mag": 58.17597579956055, "eval/post_ent_max": 58.17597579956055, "eval/post_ent_mean": 41.92631530761719, "eval/post_ent_min": 19.303829193115234, "eval/post_ent_std": 7.034296035766602, "eval/prior_ent_mag": 66.68694305419922, "eval/prior_ent_max": 66.68694305419922, "eval/prior_ent_mean": 54.79998779296875, "eval/prior_ent_min": 30.021211624145508, "eval/prior_ent_std": 5.92732572555542, "eval/rep_loss_mean": 15.232035636901855, "eval/rep_loss_std": 9.43028736114502, "eval/reward_avg": 0.013964843936264515, "eval/reward_loss_mean": 0.05216003209352493, "eval/reward_loss_std": 0.32440927624702454, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0058605670928955, "eval/reward_neg_acc": 1.0000001192092896, "eval/reward_neg_loss": 0.02709200233221054, "eval/reward_pos_acc": 0.8333333134651184, "eval/reward_pos_loss": 1.4531846046447754, "eval/reward_pred": 0.009736517444252968, "eval/reward_rate": 0.017578125, "replay/size": 194721.0, "replay/inserts": 21944.0, "replay/samples": 21952.0, "replay/insert_wait_avg": 1.3799681265424561e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.624427172602439e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38784.0, "eval_replay/inserts": 3832.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2658209790765368e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0649893283844, "timer/env.step_count": 2743.0, "timer/env.step_total": 265.329176902771, "timer/env.step_frac": 0.26531193445833817, "timer/env.step_avg": 0.09672955774800256, "timer/env.step_min": 0.021702051162719727, "timer/env.step_max": 3.474416732788086, "timer/replay._sample_count": 21952.0, "timer/replay._sample_total": 11.120213270187378, "timer/replay._sample_frac": 0.01111949062195988, "timer/replay._sample_avg": 0.000506569482060285, "timer/replay._sample_min": 0.0003731250762939453, "timer/replay._sample_max": 0.011810779571533203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3222.0, "timer/agent.policy_total": 51.79999899864197, "timer/agent.policy_frac": 0.05179663277026565, "timer/agent.policy_avg": 0.01607697051478646, "timer/agent.policy_min": 0.009018659591674805, "timer/agent.policy_max": 0.09559321403503418, "timer/dataset_train_count": 1372.0, "timer/dataset_train_total": 0.14596080780029297, "timer/dataset_train_frac": 0.00014595132252186546, "timer/dataset_train_avg": 0.00010638542842586951, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.00037550926208496094, "timer/agent.train_count": 1372.0, "timer/agent.train_total": 616.5554146766663, "timer/agent.train_frac": 0.6165153477582768, "timer/agent.train_avg": 0.4493844130296401, "timer/agent.train_min": 0.43503761291503906, "timer/agent.train_max": 1.4791004657745361, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4722905158996582, "timer/agent.report_frac": 0.0004722598240508702, "timer/agent.report_avg": 0.2361452579498291, "timer/agent.report_min": 0.22994399070739746, "timer/agent.report_max": 0.24234652519226074, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9561982595199177e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 21.942295268959775}
{"step": 195272, "time": 9344.20158791542, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 195624, "time": 9357.473168373108, "episode/length": 229.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 195784, "time": 9364.238394737244, "episode/length": 171.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 196072, "time": 9375.304376125336, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 196136, "time": 9378.88828253746, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 196272, "time": 9385.185752391815, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 196344, "time": 9388.93115735054, "episode/length": 273.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 196560, "time": 9397.710668087006, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 196760, "time": 9406.893603801727, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 196848, "time": 9411.514174938202, "episode/length": 35.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 197056, "time": 9419.975340127945, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 197200, "time": 9426.203468561172, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 197216, "time": 9428.295310258865, "episode/length": 142.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 197496, "time": 9438.968230485916, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 197776, "time": 9449.948638439178, "episode/length": 34.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 198104, "time": 9462.081682920456, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 198152, "time": 9465.284857273102, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 198312, "time": 9472.063150167465, "episode/length": 138.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 198400, "time": 9476.815721988678, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 198504, "time": 9481.549127101898, "episode/length": 269.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 198560, "time": 9485.138749361038, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 198976, "time": 9500.276659965515, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 199160, "time": 9507.749162197113, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 199280, "time": 9513.595343112946, "episode/length": 140.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 199624, "time": 9526.177708864212, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 199856, "time": 9536.284111499786, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 199864, "time": 9538.223696947098, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 9561.81252193451, "eval_episode/length": 35.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 200096, "time": 9565.037448883057, "eval_episode/length": 39.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.975}
{"step": 200096, "time": 9569.525556564331, "eval_episode/length": 150.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 200096, "time": 9571.765586137772, "eval_episode/length": 167.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 200096, "time": 9573.802681446075, "eval_episode/length": 179.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 200096, "time": 9575.364580631256, "eval_episode/length": 180.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 200096, "time": 9577.677308559418, "eval_episode/length": 201.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 200096, "time": 9581.774854183197, "eval_episode/length": 228.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 200288, "time": 9588.094733476639, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 200368, "time": 9592.230658054352, "episode/length": 245.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 200528, "time": 9598.958445310593, "episode/length": 276.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 200792, "time": 9608.967916965485, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 200800, "time": 9610.939303398132, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 201016, "time": 9619.48817539215, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 201088, "time": 9624.30521440506, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8918918918918919, "episode/intrinsic_return": 0.0}
{"step": 201304, "time": 9633.486888885498, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 201424, "time": 9639.8088722229, "episode/length": 41.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 201656, "time": 9649.261738538742, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 201672, "time": 9651.344870090485, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 201752, "time": 9655.550844430923, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 202040, "time": 9666.679941654205, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 202472, "time": 9682.461728811264, "episode/length": 181.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 202496, "time": 9684.999868631363, "episode/length": 92.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.946236559139785, "episode/intrinsic_return": 0.0}
{"step": 202664, "time": 9692.043053865433, "episode/length": 266.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 202904, "time": 9701.513559818268, "episode/length": 184.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 202920, "time": 9703.675438404083, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 202992, "time": 9707.761087656021, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 203112, "time": 9713.067412853241, "episode/length": 225.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 203120, "time": 9715.1103951931, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 203264, "time": 9721.549222946167, "episode/length": 42.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 203312, "time": 9724.628485679626, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 203552, "time": 9734.229099988937, "episode/length": 35.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 203896, "time": 9746.888152122498, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 204040, "time": 9753.215900421143, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 204296, "time": 9763.28554058075, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 204600, "time": 9774.951064109802, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 204712, "time": 9780.300114154816, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 204768, "time": 9783.919533252716, "episode/length": 151.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 205016, "time": 9794.697597503662, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 205168, "time": 9801.518664121628, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 205496, "time": 9813.705551147461, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 205752, "time": 9823.8276116848, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 205768, "time": 9826.396263837814, "episode/length": 233.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 205904, "time": 9833.529541015625, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 206296, "time": 9847.904059886932, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 206384, "time": 9852.504029035568, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 206448, "time": 9856.106750011444, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 206664, "time": 9864.417380571365, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 207096, "time": 9880.303035497665, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 207104, "time": 9882.252806901932, "episode/length": 168.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 207112, "time": 9883.847413539886, "episode/length": 101.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 207136, "time": 9886.324939489365, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 207768, "time": 9909.225372076035, "episode/length": 232.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 207824, "time": 9912.863292217255, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 208008, "time": 9920.217672348022, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 208368, "time": 9933.879695892334, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 208552, "time": 9941.2638297081, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 208824, "time": 9951.827427387238, "episode/length": 296.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 209000, "time": 9959.270678281784, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 209160, "time": 9966.03848528862, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 209400, "time": 9975.580578804016, "episode/length": 286.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 209536, "time": 9981.690434932709, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 209720, "time": 9989.01138973236, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 209776, "time": 9992.641467094421, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 209904, "time": 9998.498860359192, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 210056, "time": 10004.728017091751, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 10021.82095360756, "eval_episode/length": 43.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 210080, "time": 10027.524870157242, "eval_episode/length": 149.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 210080, "time": 10029.580514669418, "eval_episode/length": 161.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9567901234567902}
{"step": 210080, "time": 10031.54186964035, "eval_episode/length": 174.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 210080, "time": 10033.303950309753, "eval_episode/length": 179.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 210080, "time": 10034.911526441574, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 210080, "time": 10036.879556179047, "eval_episode/length": 192.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 210080, "time": 10039.073968172073, "eval_episode/length": 211.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 210360, "time": 10048.121088981628, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 210632, "time": 10058.45203447342, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 210656, "time": 10060.98231601715, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 210760, "time": 10065.804130077362, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 211264, "time": 10084.235345840454, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 211320, "time": 10087.452251195908, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 211336, "time": 10089.50276350975, "episode/length": 194.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 211864, "time": 10108.603529691696, "episode/length": 225.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 211912, "time": 10111.773722171783, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 212048, "time": 10117.992388010025, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 212128, "time": 10122.0801820755, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 212464, "time": 10134.764878749847, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 212488, "time": 10137.04565834999, "episode/length": 44.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 212640, "time": 10143.859979629517, "episode/length": 162.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 212840, "time": 10151.960654735565, "episode/length": 43.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 212856, "time": 10154.095957279205, "episode/length": 26.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8518518518518519, "episode/intrinsic_return": 0.0}
{"step": 213000, "time": 10160.902149677277, "episode/length": 135.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 213112, "time": 10167.461252450943, "episode/length": 223.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 213152, "time": 10170.580672979355, "episode/length": 298.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.979933110367893, "episode/intrinsic_return": 0.0}
{"step": 213352, "time": 10178.617106437683, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 213416, "time": 10182.277789592743, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 214096, "time": 10206.568917036057, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 214264, "time": 10213.550815820694, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 214312, "time": 10216.716395616531, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 214440, "time": 10222.482297182083, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 214696, "time": 10232.52615404129, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 214840, "time": 10238.834151983261, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 214896, "time": 10242.448642015457, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 215000, "time": 10247.168874263763, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 215168, "time": 10254.529843568802, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 215856, "time": 10278.883223056793, "episode/length": 176.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 215864, "time": 10280.494168519974, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 216256, "time": 10295.26168012619, "episode/length": 156.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 216280, "time": 10297.347917318344, "episode/length": 172.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 216504, "time": 10306.139154434204, "episode/length": 300.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9800664451827242, "episode/intrinsic_return": 0.0}
{"step": 216512, "time": 10308.188241004944, "episode/length": 280.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9822064056939501, "episode/intrinsic_return": 0.0}
{"step": 216624, "time": 10313.517863988876, "episode/length": 240.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.970954356846473, "episode/intrinsic_return": 0.0}
{"step": 217232, "time": 10335.213866472244, "episode/length": 257.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 217312, "time": 10339.343625068665, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 217353, "time": 10342.91314458847, "train_stats/sum_log_reward": 5.390322544882374, "train_stats/max_log_achievement_collect_drink": 3.0403225806451615, "train_stats/max_log_achievement_collect_sapling": 2.370967741935484, "train_stats/max_log_achievement_collect_wood": 7.403225806451613, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.41935483870967744, "train_stats/max_log_achievement_eat_cow": 0.12903225806451613, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008064516129032258, "train_stats/max_log_achievement_make_wood_sword": 1.4758064516129032, "train_stats/max_log_achievement_place_plant": 2.225806451612903, "train_stats/max_log_achievement_place_table": 2.3306451612903225, "train_stats/max_log_achievement_wake_up": 1.2338709677419355, "train_stats/mean_log_entropy": 0.47852884857885297, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.362417027570199, "train/action_min": 0.0, "train/action_std": 3.3092002868652344, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.051056009379849915, "train/actor_opt_grad_steps": 12795.0, "train/actor_opt_loss": 5.236395033562313, "train/adv_mag": 0.7287103088869564, "train/adv_max": 0.7040385312360266, "train/adv_mean": 0.0057392562193327, "train/adv_min": -0.5172678802324377, "train/adv_std": 0.07895691223118616, "train/cont_avg": 0.9941547780797102, "train/cont_loss_mean": 0.00037758818431224216, "train/cont_loss_std": 0.010920789841858437, "train/cont_neg_acc": 0.9826317014901534, "train/cont_neg_loss": 0.048115032381220786, "train/cont_pos_acc": 0.9999501480572466, "train/cont_pos_loss": 0.00016457173260935062, "train/cont_pred": 0.9941433849542037, "train/cont_rate": 0.9941547780797102, "train/dyn_loss_mean": 15.387368589207746, "train/dyn_loss_std": 9.170093633126521, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0807235141595204, "train/extr_critic_critic_opt_grad_steps": 12795.0, "train/extr_critic_critic_opt_loss": 16620.696267832882, "train/extr_critic_mag": 4.811746721682341, "train/extr_critic_max": 4.811746721682341, "train/extr_critic_mean": 1.1138049912625465, "train/extr_critic_min": -0.2214892307917277, "train/extr_critic_std": 1.1429954870887424, "train/extr_return_normed_mag": 1.7689177057017451, "train/extr_return_normed_max": 1.7689177057017451, "train/extr_return_normed_mean": 0.34239135790562286, "train/extr_return_normed_min": -0.1353751779736384, "train/extr_return_normed_std": 0.3367780481559643, "train/extr_return_rate": 0.5946827202603437, "train/extr_return_raw_mag": 6.15514113937599, "train/extr_return_raw_max": 6.15514113937599, "train/extr_return_raw_mean": 1.1340307601983997, "train/extr_return_raw_min": -0.5488333784151769, "train/extr_return_raw_std": 1.185982229485028, "train/extr_reward_mag": 1.0110922360765762, "train/extr_reward_max": 1.0110922360765762, "train/extr_reward_mean": 0.026284550613575222, "train/extr_reward_min": -0.3395515861718551, "train/extr_reward_std": 0.14843366656830345, "train/image_loss_mean": 9.91858236340509, "train/image_loss_std": 12.597240724425385, "train/model_loss_mean": 19.208892200304113, "train/model_loss_std": 16.340862440026324, "train/model_opt_grad_norm": 69.9580761685091, "train/model_opt_grad_steps": 12778.826086956522, "train/model_opt_loss": 9706.829979053442, "train/model_opt_model_opt_grad_overflow": 0.014492753623188406, "train/model_opt_model_opt_grad_scale": 495.92391304347825, "train/policy_entropy_mag": 2.216645336669424, "train/policy_entropy_max": 2.216645336669424, "train/policy_entropy_mean": 0.49749254143756366, "train/policy_entropy_min": 0.07937568658287975, "train/policy_entropy_std": 0.4401962955792745, "train/policy_logprob_mag": 7.438382331875787, "train/policy_logprob_max": -0.009455893040243267, "train/policy_logprob_mean": -0.4983679729959239, "train/policy_logprob_min": -7.438382331875787, "train/policy_logprob_std": 1.0309267666028894, "train/policy_randomness_mag": 0.7823785267014435, "train/policy_randomness_max": 0.7823785267014435, "train/policy_randomness_mean": 0.17559303548456967, "train/policy_randomness_min": 0.02801613409774027, "train/policy_randomness_std": 0.15536997478077377, "train/post_ent_mag": 57.236033094102055, "train/post_ent_max": 57.236033094102055, "train/post_ent_mean": 38.91259608061417, "train/post_ent_min": 21.170177100361258, "train/post_ent_std": 6.742313889489657, "train/prior_ent_mag": 66.5390723960987, "train/prior_ent_max": 66.5390723960987, "train/prior_ent_mean": 54.42863785011181, "train/prior_ent_min": 31.775200567383695, "train/prior_ent_std": 5.954546137132507, "train/rep_loss_mean": 15.387368589207746, "train/rep_loss_std": 9.170093633126521, "train/reward_avg": 0.021624490173290604, "train/reward_loss_mean": 0.05751114187465198, "train/reward_loss_std": 0.27519572331853537, "train/reward_max_data": 1.0108695678088977, "train/reward_max_pred": 1.0055671869844631, "train/reward_neg_acc": 0.9935423088246498, "train/reward_neg_loss": 0.0332649358264778, "train/reward_pos_acc": 0.9494181715923807, "train/reward_pos_loss": 0.9418133415173793, "train/reward_pred": 0.020805328605237646, "train/reward_rate": 0.026848392210144928, "eval_stats/sum_log_reward": 5.412500061094761, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_wood": 7.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.1875, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.000262221263255924, "report/cont_loss_std": 0.005918459035456181, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001519631769042462, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00026276224525645375, "report/cont_pred": 0.994873046875, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 15.492636680603027, "report/dyn_loss_std": 9.427999496459961, "report/image_loss_mean": 8.498449325561523, "report/image_loss_std": 12.761587142944336, "report/model_loss_mean": 17.833412170410156, "report/model_loss_std": 16.404518127441406, "report/post_ent_mag": 53.712181091308594, "report/post_ent_max": 53.712181091308594, "report/post_ent_mean": 38.15949249267578, "report/post_ent_min": 18.287275314331055, "report/post_ent_std": 6.331096172332764, "report/prior_ent_mag": 66.53844451904297, "report/prior_ent_max": 66.53844451904297, "report/prior_ent_mean": 53.58323669433594, "report/prior_ent_min": 28.474720001220703, "report/prior_ent_std": 5.818597316741943, "report/rep_loss_mean": 15.492636680603027, "report/rep_loss_std": 9.427999496459961, "report/reward_avg": 0.01308593712747097, "report/reward_loss_mean": 0.03911859542131424, "report/reward_loss_std": 0.2421407699584961, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0050230026245117, "report/reward_neg_acc": 0.995029866695404, "report/reward_neg_loss": 0.020702723413705826, "report/reward_pos_acc": 0.8888888955116272, "report/reward_pos_loss": 1.0683610439300537, "report/reward_pred": 0.012874425388872623, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 6.863648013677448e-05, "eval/cont_loss_std": 0.0017466350691393018, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0003465375048108399, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.781992851756513e-05, "eval/cont_pred": 0.9970052242279053, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.778156280517578, "eval/dyn_loss_std": 9.603528022766113, "eval/image_loss_mean": 16.512245178222656, "eval/image_loss_std": 17.757898330688477, "eval/model_loss_mean": 27.244049072265625, "eval/model_loss_std": 21.481603622436523, "eval/post_ent_mag": 57.38999938964844, "eval/post_ent_max": 57.38999938964844, "eval/post_ent_mean": 39.68267822265625, "eval/post_ent_min": 18.607402801513672, "eval/post_ent_std": 6.112625598907471, "eval/prior_ent_mag": 66.53844451904297, "eval/prior_ent_max": 66.53844451904297, "eval/prior_ent_mean": 54.31753921508789, "eval/prior_ent_min": 26.868192672729492, "eval/prior_ent_std": 6.746912956237793, "eval/rep_loss_mean": 17.778156280517578, "eval/rep_loss_std": 9.603528022766113, "eval/reward_avg": 0.02255859412252903, "eval/reward_loss_mean": 0.06483986973762512, "eval/reward_loss_std": 0.38224005699157715, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0034732818603516, "eval/reward_neg_acc": 0.9929789304733276, "eval/reward_neg_loss": 0.03549450263381004, "eval/reward_pos_acc": 0.9629629850387573, "eval/reward_pos_loss": 1.1484445333480835, "eval/reward_pred": 0.02091929502785206, "eval/reward_rate": 0.0263671875, "replay/size": 216849.0, "replay/inserts": 22128.0, "replay/samples": 22128.0, "replay/insert_wait_avg": 1.3461146592576696e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.398630613877302e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 42312.0, "eval_replay/inserts": 3528.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1962827911722956e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0789291858673, "timer/env.step_count": 2766.0, "timer/env.step_total": 268.36535000801086, "timer/env.step_frac": 0.26834416982115467, "timer/env.step_avg": 0.09702290311207913, "timer/env.step_min": 0.02219390869140625, "timer/env.step_max": 2.8972601890563965, "timer/replay._sample_count": 22128.0, "timer/replay._sample_total": 11.286090612411499, "timer/replay._sample_frac": 0.01128519988077256, "timer/replay._sample_avg": 0.0005100366328819369, "timer/replay._sample_min": 0.00038933753967285156, "timer/replay._sample_max": 0.01098942756652832, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3207.0, "timer/agent.policy_total": 51.654083490371704, "timer/agent.policy_frac": 0.05165000679738514, "timer/agent.policy_avg": 0.016106667755027036, "timer/agent.policy_min": 0.009300708770751953, "timer/agent.policy_max": 0.10173344612121582, "timer/dataset_train_count": 1383.0, "timer/dataset_train_total": 0.1437547206878662, "timer/dataset_train_frac": 0.00014374337514029258, "timer/dataset_train_avg": 0.00010394412197242677, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.000560760498046875, "timer/agent.train_count": 1383.0, "timer/agent.train_total": 617.0713486671448, "timer/agent.train_frac": 0.6170226475719103, "timer/agent.train_avg": 0.4461831877564315, "timer/agent.train_min": 0.435990571975708, "timer/agent.train_max": 1.428328514099121, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4753901958465576, "timer/agent.report_frac": 0.00047535267664679004, "timer/agent.report_avg": 0.2376950979232788, "timer/agent.report_min": 0.23093557357788086, "timer/agent.report_max": 0.24445462226867676, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7177572913874183e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 22.12598192858298}
{"step": 217616, "time": 10351.732351064682, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 217696, "time": 10355.960352182388, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 217848, "time": 10362.33773136139, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 217952, "time": 10367.45267868042, "episode/length": 208.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 218176, "time": 10376.301949262619, "episode/length": 289.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9896551724137931, "episode/intrinsic_return": 0.0}
{"step": 218528, "time": 10389.523933649063, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 218664, "time": 10395.315564870834, "episode/length": 254.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 218752, "time": 10399.99284029007, "episode/length": 99.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.94, "episode/intrinsic_return": 0.0}
{"step": 218816, "time": 10403.627904176712, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 219152, "time": 10416.518329143524, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 219280, "time": 10422.996958255768, "episode/length": 255.0, "episode/score": 7.1000000461936, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 219352, "time": 10426.67988538742, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 219896, "time": 10446.562376737595, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 219992, "time": 10451.279726028442, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 10475.077128648758, "eval_episode/length": 165.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 220064, "time": 10476.915376901627, "eval_episode/length": 174.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 220064, "time": 10478.541836500168, "eval_episode/length": 176.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 220064, "time": 10480.588088035583, "eval_episode/length": 189.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 220064, "time": 10482.292681455612, "eval_episode/length": 193.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 220064, "time": 10484.007964372635, "eval_episode/length": 196.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 220064, "time": 10486.650641918182, "eval_episode/length": 223.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9776785714285714}
{"step": 220064, "time": 10488.236711025238, "eval_episode/length": 224.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 220096, "time": 10489.292265176773, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 220384, "time": 10500.333307981491, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 220552, "time": 10507.14666724205, "episode/length": 158.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 220576, "time": 10509.680862665176, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 220584, "time": 10511.193368673325, "episode/length": 153.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 220768, "time": 10519.053543567657, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 221192, "time": 10534.466825723648, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 221400, "time": 10544.32730436325, "episode/length": 175.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 221888, "time": 10562.073684930801, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 221888, "time": 10562.082942962646, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 221944, "time": 10566.874789714813, "episode/length": 230.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 222088, "time": 10573.116465091705, "episode/length": 188.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 222264, "time": 10580.338320970535, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 222616, "time": 10593.58325123787, "episode/length": 230.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 222664, "time": 10596.814690351486, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 222712, "time": 10599.937258720398, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 222752, "time": 10603.012484550476, "episode/length": 107.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 223232, "time": 10620.499438524246, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 223344, "time": 10625.766824483871, "episode/length": 134.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 223344, "time": 10625.775620937347, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 223688, "time": 10640.13194513321, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 223880, "time": 10648.010890960693, "episode/length": 157.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 224280, "time": 10662.567804574966, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 224456, "time": 10669.793758392334, "episode/length": 212.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 224784, "time": 10682.417644500732, "episode/length": 264.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 224792, "time": 10683.963410377502, "episode/length": 41.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 224920, "time": 10689.851463317871, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 224944, "time": 10692.382390022278, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 225024, "time": 10696.486735582352, "episode/length": 223.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 225256, "time": 10705.557972192764, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 225256, "time": 10705.56838274002, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 225568, "time": 10719.445924758911, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 226088, "time": 10737.918703317642, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 226120, "time": 10740.554359197617, "episode/length": 166.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 226136, "time": 10742.528906345367, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 226248, "time": 10747.759642362595, "episode/length": 152.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 226624, "time": 10761.86756849289, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 226648, "time": 10763.96978712082, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 226720, "time": 10768.238730192184, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 227000, "time": 10778.67376112938, "episode/length": 34.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9142857142857143, "episode/intrinsic_return": 0.0}
{"step": 227128, "time": 10784.483401298523, "episode/length": 272.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 227360, "time": 10793.864033937454, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 227384, "time": 10795.996862888336, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 227536, "time": 10802.85724234581, "episode/length": 160.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 227592, "time": 10806.072149515152, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 227880, "time": 10816.87565779686, "episode/length": 35.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 228120, "time": 10826.306935548782, "episode/length": 94.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 228312, "time": 10834.133531808853, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 228480, "time": 10841.484208583832, "episode/length": 228.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 228528, "time": 10844.689345359802, "episode/length": 190.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 228792, "time": 10854.671193599701, "episode/length": 156.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 229024, "time": 10864.329725027084, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 229192, "time": 10871.103348016739, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 229232, "time": 10874.029759168625, "episode/length": 262.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 229472, "time": 10884.676988363266, "episode/length": 29.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8666666666666667, "episode/intrinsic_return": 0.0}
{"step": 229680, "time": 10893.148370742798, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 229880, "time": 10901.095527172089, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 230024, "time": 10907.335817098618, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 10924.67610168457, "eval_episode/length": 35.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 230048, "time": 10926.337092876434, "eval_episode/length": 38.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 230048, "time": 10930.797733783722, "eval_episode/length": 114.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9565217391304348}
{"step": 230048, "time": 10933.890357255936, "eval_episode/length": 154.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 230048, "time": 10936.150624275208, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 230048, "time": 10937.942932128906, "eval_episode/length": 176.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 230048, "time": 10939.672656297684, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 230048, "time": 10941.40455031395, "eval_episode/length": 188.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 230200, "time": 10946.229682683945, "episode/length": 235.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 230248, "time": 10949.40255689621, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 230504, "time": 10959.251790761948, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 230616, "time": 10964.382050991058, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 230792, "time": 10971.582195997238, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 231264, "time": 10988.829316139221, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 231472, "time": 10997.099450826645, "episode/length": 158.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 231512, "time": 10999.740455150604, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 231536, "time": 11002.229135036469, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 231848, "time": 11013.917322158813, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 231848, "time": 11013.925877809525, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 231872, "time": 11018.024909973145, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 232280, "time": 11032.541981458664, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 232448, "time": 11039.863404750824, "episode/length": 147.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 232776, "time": 11051.849625825882, "episode/length": 40.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 232832, "time": 11055.449161291122, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 233080, "time": 11064.896970272064, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 233168, "time": 11069.601369380951, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 233424, "time": 11079.517440319061, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 233528, "time": 11084.842303037643, "episode/length": 155.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 233968, "time": 11101.649063110352, "episode/length": 264.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9886792452830189, "episode/intrinsic_return": 0.0}
{"step": 234120, "time": 11107.884855031967, "episode/length": 325.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9969325153374233, "episode/intrinsic_return": 0.0}
{"step": 234352, "time": 11117.236628293991, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 234424, "time": 11120.934929847717, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 234616, "time": 11128.869568109512, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 234744, "time": 11134.609121799469, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 234872, "time": 11140.295232772827, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 235008, "time": 11147.134751558304, "episode/length": 184.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 235040, "time": 11150.28158068657, "episode/length": 36.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 235408, "time": 11164.94573521614, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 235560, "time": 11171.622864723206, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 235592, "time": 11174.311895132065, "episode/length": 121.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9508196721311475, "episode/intrinsic_return": 0.0}
{"step": 235720, "time": 11180.08826136589, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 235848, "time": 11185.777326345444, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9606741573033708, "episode/intrinsic_return": 0.0}
{"step": 236040, "time": 11193.666377544403, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 236288, "time": 11203.701961994171, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 236432, "time": 11210.023105621338, "episode/length": 173.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 236696, "time": 11220.176693677902, "episode/length": 210.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 236760, "time": 11223.914189100266, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 236800, "time": 11226.965177297592, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 237184, "time": 11241.187380075455, "episode/length": 47.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 237304, "time": 11246.573330640793, "episode/length": 157.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 237560, "time": 11256.621391534805, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 237608, "time": 11261.136221170425, "episode/length": 251.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 237864, "time": 11271.05947136879, "episode/length": 251.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 238112, "time": 11281.094624757767, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 238296, "time": 11288.45460486412, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 238432, "time": 11294.726068973541, "episode/length": 155.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 238600, "time": 11301.862263202667, "episode/length": 229.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9652173913043478, "episode/intrinsic_return": 0.0}
{"step": 238680, "time": 11306.010743379593, "episode/length": 133.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 238848, "time": 11313.387832164764, "episode/length": 160.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 239136, "time": 11324.354399204254, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 239192, "time": 11327.58410692215, "episode/length": 42.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 239296, "time": 11332.791675329208, "episode/length": 107.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 239513, "time": 11342.930086135864, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.36736928816322, "train/action_min": 0.0, "train/action_std": 3.2525723855272473, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04782780551974722, "train/actor_opt_grad_steps": 14180.0, "train/actor_opt_loss": -5.455598061676506, "train/adv_mag": 0.6672950140435061, "train/adv_max": 0.6475319560054394, "train/adv_mean": 0.003757093061434219, "train/adv_min": -0.4834616340750413, "train/adv_std": 0.07355355581255268, "train/cont_avg": 0.9944427270683454, "train/cont_loss_mean": 0.00027938165791381754, "train/cont_loss_std": 0.008196743282992396, "train/cont_neg_acc": 0.9937992486164724, "train/cont_neg_loss": 0.018989584065958368, "train/cont_pos_acc": 0.9999717289595296, "train/cont_pos_loss": 0.00014695378750039306, "train/cont_pred": 0.9944393450407674, "train/cont_rate": 0.9944427270683454, "train/dyn_loss_mean": 15.570346942050852, "train/dyn_loss_std": 9.225818558562574, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0254074159286004, "train/extr_critic_critic_opt_grad_steps": 14180.0, "train/extr_critic_critic_opt_loss": 16495.076277259443, "train/extr_critic_mag": 5.131848764076508, "train/extr_critic_max": 5.131848764076508, "train/extr_critic_mean": 1.1904163892320592, "train/extr_critic_min": -0.1978538731019274, "train/extr_critic_std": 1.1985144503682637, "train/extr_return_normed_mag": 1.7129429544476296, "train/extr_return_normed_max": 1.7129429544476296, "train/extr_return_normed_mean": 0.33572517464058005, "train/extr_return_normed_min": -0.13160196257580956, "train/extr_return_normed_std": 0.33133337426957465, "train/extr_return_rate": 0.6033414214206256, "train/extr_return_raw_mag": 6.3513821595006705, "train/extr_return_raw_max": 6.3513821595006705, "train/extr_return_raw_mean": 1.2044493899070958, "train/extr_return_raw_min": -0.5421345739913501, "train/extr_return_raw_std": 1.2381237625218124, "train/extr_reward_mag": 1.0122859529454074, "train/extr_reward_max": 1.0122859529454074, "train/extr_reward_mean": 0.02822265849053431, "train/extr_reward_min": -0.3405193073286427, "train/extr_reward_std": 0.15386780951734927, "train/image_loss_mean": 9.535767490057637, "train/image_loss_std": 12.530326843261719, "train/model_loss_mean": 18.932899241824803, "train/model_loss_std": 16.318737736708826, "train/model_opt_grad_norm": 72.99456704777779, "train/model_opt_grad_steps": 14163.0, "train/model_opt_loss": 11249.903492440422, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 598.0215827338129, "train/policy_entropy_mag": 2.2116937208518705, "train/policy_entropy_max": 2.2116937208518705, "train/policy_entropy_mean": 0.4917513558761679, "train/policy_entropy_min": 0.07937552812073728, "train/policy_entropy_std": 0.4475024209605704, "train/policy_logprob_mag": 7.43838238201553, "train/policy_logprob_max": -0.009455835386413893, "train/policy_logprob_mean": -0.4923969003365194, "train/policy_logprob_min": -7.43838238201553, "train/policy_logprob_std": 1.0302102359936391, "train/policy_randomness_mag": 0.7806308248060213, "train/policy_randomness_max": 0.7806308248060213, "train/policy_randomness_mean": 0.17356664896440163, "train/policy_randomness_min": 0.028016078171970174, "train/policy_randomness_std": 0.15794871629570886, "train/post_ent_mag": 57.64020818257504, "train/post_ent_max": 57.64020818257504, "train/post_ent_mean": 39.09678979228726, "train/post_ent_min": 21.248709767842463, "train/post_ent_std": 6.7937719358814705, "train/prior_ent_mag": 66.79986643619675, "train/prior_ent_max": 66.79986643619675, "train/prior_ent_mean": 54.74676774388595, "train/prior_ent_min": 32.333499963334994, "train/prior_ent_std": 5.739653933820107, "train/rep_loss_mean": 15.570346942050852, "train/rep_loss_std": 9.225818558562574, "train/reward_avg": 0.021766805135236263, "train/reward_loss_mean": 0.05464426355717851, "train/reward_loss_std": 0.2595775538532854, "train/reward_max_data": 1.0107913694793371, "train/reward_max_pred": 1.005566962331319, "train/reward_neg_acc": 0.9934830373997311, "train/reward_neg_loss": 0.03129617179737246, "train/reward_pos_acc": 0.9549552056429197, "train/reward_pos_loss": 0.9085607292840807, "train/reward_pred": 0.020925284102023076, "train/reward_rate": 0.02670441771582734, "train_stats/sum_log_reward": 5.3857142354051275, "train_stats/max_log_achievement_collect_drink": 3.253968253968254, "train_stats/max_log_achievement_collect_sapling": 2.126984126984127, "train_stats/max_log_achievement_collect_wood": 7.4603174603174605, "train_stats/max_log_achievement_defeat_skeleton": 0.007936507936507936, "train_stats/max_log_achievement_defeat_zombie": 0.42857142857142855, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_make_wood_pickaxe": 0.007936507936507936, "train_stats/max_log_achievement_make_wood_sword": 1.3333333333333333, "train_stats/max_log_achievement_place_plant": 1.9841269841269842, "train_stats/max_log_achievement_place_table": 2.1904761904761907, "train_stats/max_log_achievement_wake_up": 1.2857142857142858, "train_stats/mean_log_entropy": 0.45727552639113533, "eval_stats/sum_log_reward": 5.287499997764826, "eval_stats/max_log_achievement_collect_drink": 2.5625, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_wood": 6.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.3125, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_stone": 0.015151515151515152, "eval_stats/max_log_achievement_collect_stone": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.212311483162921e-05, "report/cont_loss_std": 0.0005493773496709764, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.336128717521206e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.1920764993410558e-05, "report/cont_pred": 0.9950958490371704, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.62938117980957, "report/dyn_loss_std": 8.897398948669434, "report/image_loss_mean": 8.655221939086914, "report/image_loss_std": 10.64691162109375, "report/model_loss_mean": 16.874736785888672, "report/model_loss_std": 14.067336082458496, "report/post_ent_mag": 59.221473693847656, "report/post_ent_max": 59.221473693847656, "report/post_ent_mean": 39.87261962890625, "report/post_ent_min": 20.439035415649414, "report/post_ent_std": 7.591480255126953, "report/prior_ent_mag": 66.60386657714844, "report/prior_ent_max": 66.60386657714844, "report/prior_ent_mean": 53.79207229614258, "report/prior_ent_min": 29.195178985595703, "report/prior_ent_std": 7.306758880615234, "report/rep_loss_mean": 13.62938117980957, "report/rep_loss_std": 8.897398948669434, "report/reward_avg": 0.01249999925494194, "report/reward_loss_mean": 0.04186445102095604, "report/reward_loss_std": 0.17357267439365387, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0017099380493164, "report/reward_neg_acc": 0.9900597333908081, "report/reward_neg_loss": 0.02821248769760132, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.804857611656189, "report/reward_pred": 0.012499636970460415, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.0007588439621031284, "eval/cont_loss_std": 0.02273876778781414, "eval/cont_neg_acc": 0.8571429252624512, "eval/cont_neg_loss": 0.11091979593038559, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.072544920243672e-07, "eval/cont_pred": 0.9937155246734619, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 19.51369857788086, "eval/dyn_loss_std": 10.888700485229492, "eval/image_loss_mean": 21.206920623779297, "eval/image_loss_std": 36.168636322021484, "eval/model_loss_mean": 33.02516555786133, "eval/model_loss_std": 40.227542877197266, "eval/post_ent_mag": 59.759971618652344, "eval/post_ent_max": 59.759971618652344, "eval/post_ent_mean": 40.29704666137695, "eval/post_ent_min": 23.08390235900879, "eval/post_ent_std": 7.571955680847168, "eval/prior_ent_mag": 66.67803955078125, "eval/prior_ent_max": 66.67803955078125, "eval/prior_ent_mean": 56.14837646484375, "eval/prior_ent_min": 33.65545654296875, "eval/prior_ent_std": 5.955275058746338, "eval/rep_loss_mean": 19.51369857788086, "eval/rep_loss_std": 10.888700485229492, "eval/reward_avg": 0.01259765587747097, "eval/reward_loss_mean": 0.10926632583141327, "eval/reward_loss_std": 0.7602013945579529, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0004520416259766, "eval/reward_neg_acc": 0.996023952960968, "eval/reward_neg_loss": 0.0489211268723011, "eval/reward_pos_acc": 0.6111111044883728, "eval/reward_pos_loss": 3.4818928241729736, "eval/reward_pred": 0.006707801017910242, "eval/reward_rate": 0.017578125, "replay/size": 239009.0, "replay/inserts": 22160.0, "replay/samples": 22160.0, "replay/insert_wait_avg": 1.3497547122115262e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.537988800434429e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 45624.0, "eval_replay/inserts": 3312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.229957681923097e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0082716941833, "timer/env.step_count": 2770.0, "timer/env.step_total": 271.6104018688202, "timer/env.step_frac": 0.2716081552092226, "timer/env.step_avg": 0.0980542967035452, "timer/env.step_min": 0.021929025650024414, "timer/env.step_max": 3.487438917160034, "timer/replay._sample_count": 22160.0, "timer/replay._sample_total": 11.463960409164429, "timer/replay._sample_frac": 0.011463865583574163, "timer/replay._sample_avg": 0.0005173267332655428, "timer/replay._sample_min": 0.0003921985626220703, "timer/replay._sample_max": 0.02774643898010254, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3184.0, "timer/agent.policy_total": 50.13207006454468, "timer/agent.policy_frac": 0.05013165539082238, "timer/agent.policy_avg": 0.01574499687956805, "timer/agent.policy_min": 0.009405374526977539, "timer/agent.policy_max": 0.09826231002807617, "timer/dataset_train_count": 1385.0, "timer/dataset_train_total": 0.1430809497833252, "timer/dataset_train_frac": 0.00014307976627125479, "timer/dataset_train_avg": 0.00010330754496990989, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0002467632293701172, "timer/agent.train_count": 1385.0, "timer/agent.train_total": 615.543459892273, "timer/agent.train_frac": 0.6155383683471318, "timer/agent.train_avg": 0.44443571111355445, "timer/agent.train_min": 0.4346456527709961, "timer/agent.train_max": 1.4491653442382812, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46754002571105957, "timer/agent.report_frac": 0.0004675361583949377, "timer/agent.report_avg": 0.23377001285552979, "timer/agent.report_min": 0.22536993026733398, "timer/agent.report_max": 0.24217009544372559, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.147099212298376e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 22.15954042098471}
{"step": 239680, "time": 11348.498399496078, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 239960, "time": 11359.014359235764, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 240016, "time": 11362.608338594437, "episode/length": 268.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 11378.253847122192, "eval_episode/length": 22.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8260869565217391}
{"step": 240032, "time": 11385.015647888184, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 240032, "time": 11387.064683198929, "eval_episode/length": 166.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 240032, "time": 11389.05727148056, "eval_episode/length": 171.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 240032, "time": 11390.946877002716, "eval_episode/length": 180.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9613259668508287}
{"step": 240032, "time": 11393.066192626953, "eval_episode/length": 195.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 240032, "time": 11395.04066491127, "eval_episode/length": 183.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 240032, "time": 11398.561975479126, "eval_episode/length": 254.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 240336, "time": 11408.526663064957, "episode/length": 216.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 240416, "time": 11412.687819719315, "episode/length": 287.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 240544, "time": 11418.547466516495, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 240936, "time": 11432.91248703003, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 241088, "time": 11439.702313899994, "episode/length": 236.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 241272, "time": 11447.18832707405, "episode/length": 156.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 241272, "time": 11447.199319601059, "episode/length": 266.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 241896, "time": 11471.371323108673, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 241928, "time": 11473.954292535782, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 242056, "time": 11479.670762777328, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 242184, "time": 11485.363162994385, "episode/length": 277.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 242344, "time": 11492.277848005295, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 242376, "time": 11494.907509565353, "episode/length": 39.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 242384, "time": 11496.845427513123, "episode/length": 56.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 242512, "time": 11502.603651285172, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 243224, "time": 11527.879593372345, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 243256, "time": 11531.079969644547, "episode/length": 133.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 243312, "time": 11535.20812034607, "episode/length": 254.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 243616, "time": 11547.799280166626, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 243616, "time": 11547.808965921402, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 243848, "time": 11559.542838096619, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 243952, "time": 11565.349784135818, "episode/length": 86.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 244000, "time": 11568.891085624695, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 244104, "time": 11574.270947217941, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 244640, "time": 11594.094884872437, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 244832, "time": 11601.912701368332, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 244968, "time": 11607.627796649933, "episode/length": 40.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 245208, "time": 11617.067286491394, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 245304, "time": 11621.807452917099, "episode/length": 149.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 245320, "time": 11624.002738237381, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 245432, "time": 11629.237120628357, "episode/length": 226.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647577092511013, "episode/intrinsic_return": 0.0}
{"step": 245464, "time": 11631.87346482277, "episode/length": 230.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 245592, "time": 11637.750110387802, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 245744, "time": 11644.45074748993, "episode/length": 34.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 246504, "time": 11673.010334730148, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 246568, "time": 11676.743068218231, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 246576, "time": 11678.922878742218, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 246624, "time": 11682.058696985245, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 246632, "time": 11683.570742368698, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 246632, "time": 11683.579793214798, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 246960, "time": 11697.929358243942, "episode/length": 40.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 247064, "time": 11702.711599588394, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 247384, "time": 11715.066449403763, "episode/length": 223.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 247848, "time": 11732.579107046127, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 247920, "time": 11736.705257177353, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 248040, "time": 11742.126187801361, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 248272, "time": 11751.613800048828, "episode/length": 163.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 248360, "time": 11755.834712028503, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 248656, "time": 11767.551116228104, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 248864, "time": 11776.13392162323, "episode/length": 279.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 248992, "time": 11782.567131757736, "episode/length": 302.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 249248, "time": 11793.404257535934, "episode/length": 174.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 249544, "time": 11804.997743844986, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 249816, "time": 11815.604174137115, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 249880, "time": 11819.454876184464, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 249888, "time": 11821.532952785492, "episode/length": 153.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 11848.028188228607, "eval_episode/length": 150.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 250016, "time": 11849.70602273941, "eval_episode/length": 152.0, "eval_episode/score": 7.100000038743019, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 250016, "time": 11851.616669654846, "eval_episode/length": 158.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 250016, "time": 11854.167926549911, "eval_episode/length": 182.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 250016, "time": 11855.708541870117, "eval_episode/length": 183.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 250016, "time": 11859.042475223541, "eval_episode/length": 227.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 250016, "time": 11861.413636922836, "eval_episode/length": 248.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 250016, "time": 11864.001777410507, "eval_episode/length": 273.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9854014598540146}
{"step": 250048, "time": 11865.079799890518, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 250232, "time": 11872.486710309982, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 250736, "time": 11891.904294490814, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 251008, "time": 11902.391896247864, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 251400, "time": 11916.61186504364, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 251456, "time": 11920.132871866226, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 251688, "time": 11929.324305057526, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 251736, "time": 11933.084480047226, "episode/length": 230.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 251800, "time": 11937.327555656433, "episode/length": 49.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 251920, "time": 11943.643467664719, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 252304, "time": 11958.646677017212, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 252392, "time": 11963.392380714417, "episode/length": 172.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 252744, "time": 11977.5017786026, "episode/length": 131.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 253072, "time": 11990.878329515457, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 253168, "time": 11995.47239279747, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 253216, "time": 11998.715421676636, "episode/length": 527.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 253400, "time": 12006.007140398026, "episode/length": 242.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 253728, "time": 12018.502429008484, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 253744, "time": 12020.633620977402, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 253760, "time": 12022.739647626877, "episode/length": 252.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 254144, "time": 12038.26020026207, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 254448, "time": 12049.82069182396, "episode/length": 159.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 254880, "time": 12065.770763635635, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 254912, "time": 12068.37528347969, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 255048, "time": 12074.173632144928, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 255280, "time": 12083.556330442429, "episode/length": 275.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 255296, "time": 12085.725855827332, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 255504, "time": 12094.316246509552, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 255824, "time": 12106.49547457695, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 256080, "time": 12116.542369365692, "episode/length": 99.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 256096, "time": 12118.632240533829, "episode/length": 130.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9541984732824428, "episode/intrinsic_return": 0.0}
{"step": 256120, "time": 12120.791622400284, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 256376, "time": 12130.824175357819, "episode/length": 328.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9878419452887538, "episode/intrinsic_return": 0.0}
{"step": 256488, "time": 12135.998141288757, "episode/length": 122.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.959349593495935, "episode/intrinsic_return": 0.0}
{"step": 256616, "time": 12141.834749937057, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 256840, "time": 12151.58723950386, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 257120, "time": 12162.540249586105, "episode/length": 34.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 257184, "time": 12166.092419862747, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 257352, "time": 12172.866441726685, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 257464, "time": 12178.290544748306, "episode/length": 167.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 257632, "time": 12186.28137922287, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 257904, "time": 12197.678627729416, "episode/length": 225.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 258256, "time": 12211.455142259598, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 258472, "time": 12219.806557178497, "episode/length": 125.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 258520, "time": 12222.985626935959, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 258600, "time": 12227.18028974533, "episode/length": 263.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 258896, "time": 12238.838103055954, "episode/length": 221.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 259128, "time": 12247.717503786087, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 259296, "time": 12255.016487121582, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 259560, "time": 12265.108053684235, "episode/length": 240.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 259840, "time": 12276.199628829956, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 12302.343989133835, "eval_episode/length": 161.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 260000, "time": 12304.360306501389, "eval_episode/length": 170.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 260000, "time": 12306.186518192291, "eval_episode/length": 178.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.994413407821229}
{"step": 260000, "time": 12308.360174655914, "eval_episode/length": 193.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 260000, "time": 12310.998408079147, "eval_episode/length": 221.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9684684684684685}
{"step": 260000, "time": 12313.17805147171, "eval_episode/length": 237.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 260000, "time": 12316.480309963226, "eval_episode/length": 281.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9822695035460993}
{"step": 260000, "time": 12320.086324214935, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 260072, "time": 12322.221988201141, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 260152, "time": 12326.341675519943, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 260424, "time": 12336.870796442032, "episode/length": 33.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 260480, "time": 12340.490560054779, "episode/length": 197.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 260489, "time": 12343.052069187164, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.435993689617128, "train/action_min": 0.0, "train/action_std": 3.3520840561116927, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048837591673581655, "train/actor_opt_grad_steps": 15530.0, "train/actor_opt_loss": 0.06942118579194746, "train/adv_mag": 0.7059140519331429, "train/adv_max": 0.6888226336650266, "train/adv_mean": 0.004654049248619446, "train/adv_min": -0.4824390798124648, "train/adv_std": 0.07490194799335859, "train/cont_avg": 0.9947369990458015, "train/cont_loss_mean": 0.00028586347751372563, "train/cont_loss_std": 0.007725844837277656, "train/cont_neg_acc": 0.9917302809598791, "train/cont_neg_loss": 0.022698000126630553, "train/cont_pos_acc": 0.9999400145224943, "train/cont_pos_loss": 0.0001720802272926294, "train/cont_pred": 0.9947232226379045, "train/cont_rate": 0.9947369990458015, "train/dyn_loss_mean": 15.600555616480703, "train/dyn_loss_std": 9.083112731234717, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9743859180967316, "train/extr_critic_critic_opt_grad_steps": 15530.0, "train/extr_critic_critic_opt_loss": 16493.654878339694, "train/extr_critic_mag": 5.265745869119659, "train/extr_critic_max": 5.265745869119659, "train/extr_critic_mean": 1.1632802177021522, "train/extr_critic_min": -0.23264115184318018, "train/extr_critic_std": 1.197632364644349, "train/extr_return_normed_mag": 1.735885021340756, "train/extr_return_normed_max": 1.735885021340756, "train/extr_return_normed_mean": 0.33416648288719525, "train/extr_return_normed_min": -0.12984888884061166, "train/extr_return_normed_std": 0.3295636667322566, "train/extr_return_rate": 0.5933464854273177, "train/extr_return_raw_mag": 6.4512381189652075, "train/extr_return_raw_max": 6.4512381189652075, "train/extr_return_raw_mean": 1.1807529271103954, "train/extr_return_raw_min": -0.5641029024397144, "train/extr_return_raw_std": 1.2395638286612416, "train/extr_reward_mag": 1.010018863750778, "train/extr_reward_max": 1.010018863750778, "train/extr_reward_mean": 0.02867093769733915, "train/extr_reward_min": -0.3401745366686173, "train/extr_reward_std": 0.15552584349199106, "train/image_loss_mean": 9.168855248516753, "train/image_loss_std": 12.24649236038441, "train/model_loss_mean": 18.586255255546277, "train/model_loss_std": 15.933167100862692, "train/model_opt_grad_norm": 67.84003208247759, "train/model_opt_grad_steps": 15512.213740458015, "train/model_opt_loss": 14383.39623091603, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 772.9007633587786, "train/policy_entropy_mag": 2.224664040194213, "train/policy_entropy_max": 2.224664040194213, "train/policy_entropy_mean": 0.5013628736252093, "train/policy_entropy_min": 0.07937541825853231, "train/policy_entropy_std": 0.4615671131902069, "train/policy_logprob_mag": 7.438382680179509, "train/policy_logprob_max": -0.009455816450578566, "train/policy_logprob_mean": -0.5014443973093542, "train/policy_logprob_min": -7.438382680179509, "train/policy_logprob_std": 1.0381050947058292, "train/policy_randomness_mag": 0.7852087794369413, "train/policy_randomness_max": 0.7852087794369413, "train/policy_randomness_mean": 0.1769590912429431, "train/policy_randomness_min": 0.02801603937649545, "train/policy_randomness_std": 0.16291293513228874, "train/post_ent_mag": 58.24310774475563, "train/post_ent_max": 58.24310774475563, "train/post_ent_mean": 39.438360869429495, "train/post_ent_min": 21.288998349022318, "train/post_ent_std": 6.959437923576996, "train/prior_ent_mag": 67.09062864580227, "train/prior_ent_max": 67.09062864580227, "train/prior_ent_mean": 55.13935059991502, "train/prior_ent_min": 33.66835036532569, "train/prior_ent_std": 5.423354651181753, "train/rep_loss_mean": 15.600555616480703, "train/rep_loss_std": 9.083112731234717, "train/reward_avg": 0.023152731195490325, "train/reward_loss_mean": 0.05678069540335022, "train/reward_loss_std": 0.27260047129092324, "train/reward_max_data": 1.0129771023306229, "train/reward_max_pred": 1.0053563199880469, "train/reward_neg_acc": 0.9929204241920063, "train/reward_neg_loss": 0.03208802518868492, "train/reward_pos_acc": 0.9575986907682346, "train/reward_pos_loss": 0.9139865345627297, "train/reward_pred": 0.022427128379069666, "train/reward_rate": 0.027969942748091604, "train_stats/sum_log_reward": 5.757894716503327, "train_stats/max_log_achievement_collect_drink": 4.0964912280701755, "train_stats/max_log_achievement_collect_sapling": 2.912280701754386, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 6.780701754385965, "train_stats/max_log_achievement_defeat_skeleton": 0.008771929824561403, "train_stats/max_log_achievement_defeat_zombie": 0.5175438596491229, "train_stats/max_log_achievement_eat_cow": 0.18421052631578946, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008771929824561403, "train_stats/max_log_achievement_make_wood_sword": 1.105263157894737, "train_stats/max_log_achievement_place_plant": 2.8157894736842106, "train_stats/max_log_achievement_place_table": 1.868421052631579, "train_stats/max_log_achievement_wake_up": 1.4473684210526316, "train_stats/mean_log_entropy": 0.4680714813763635, "eval_stats/sum_log_reward": 6.058333282979826, "eval_stats/max_log_achievement_collect_drink": 3.7083333333333335, "eval_stats/max_log_achievement_collect_sapling": 3.1666666666666665, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.7916666666666666, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.0833333333333333, "eval_stats/max_log_achievement_place_plant": 3.0833333333333335, "eval_stats/max_log_achievement_place_table": 2.0833333333333335, "eval_stats/max_log_achievement_wake_up": 1.6666666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.8010761777986772e-05, "report/cont_loss_std": 0.00031370416400022805, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002379592042416334, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.091815753781702e-06, "report/cont_pred": 0.9941505193710327, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 14.044767379760742, "report/dyn_loss_std": 8.643400192260742, "report/image_loss_mean": 6.737369537353516, "report/image_loss_std": 8.927988052368164, "report/model_loss_mean": 15.206666946411133, "report/model_loss_std": 12.544526100158691, "report/post_ent_mag": 56.03246307373047, "report/post_ent_max": 56.03246307373047, "report/post_ent_mean": 40.59813690185547, "report/post_ent_min": 21.12238311767578, "report/post_ent_std": 6.516261100769043, "report/prior_ent_mag": 66.84184265136719, "report/prior_ent_max": 66.84184265136719, "report/prior_ent_mean": 54.8991813659668, "report/prior_ent_min": 34.42767333984375, "report/prior_ent_std": 5.465227127075195, "report/rep_loss_mean": 14.044767379760742, "report/rep_loss_std": 8.643400192260742, "report/reward_avg": 0.01484375074505806, "report/reward_loss_mean": 0.0424196794629097, "report/reward_loss_std": 0.17338666319847107, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0014252662658691, "report/reward_neg_acc": 0.9910269379615784, "report/reward_neg_loss": 0.02771478332579136, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7447535991668701, "report/reward_pred": 0.014822068624198437, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 9.180781489703804e-06, "eval/cont_loss_std": 0.00019825910567305982, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0010743041057139635, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.096391982486239e-06, "eval/cont_pred": 0.9980419874191284, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.541011810302734, "eval/dyn_loss_std": 10.545841217041016, "eval/image_loss_mean": 15.881909370422363, "eval/image_loss_std": 18.93024444580078, "eval/model_loss_mean": 26.491819381713867, "eval/model_loss_std": 23.106239318847656, "eval/post_ent_mag": 57.91566467285156, "eval/post_ent_max": 57.91566467285156, "eval/post_ent_mean": 41.17391586303711, "eval/post_ent_min": 21.401376724243164, "eval/post_ent_std": 7.298783779144287, "eval/prior_ent_mag": 66.84184265136719, "eval/prior_ent_max": 66.84184265136719, "eval/prior_ent_mean": 55.568992614746094, "eval/prior_ent_min": 32.158050537109375, "eval/prior_ent_std": 4.977734088897705, "eval/rep_loss_mean": 17.541011810302734, "eval/rep_loss_std": 10.545841217041016, "eval/reward_avg": 0.01923828199505806, "eval/reward_loss_mean": 0.08529571443796158, "eval/reward_loss_std": 0.6957216858863831, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0016701221466064, "eval/reward_neg_acc": 0.9920159578323364, "eval/reward_neg_loss": 0.022060077637434006, "eval/reward_pos_acc": 0.6818181872367859, "eval/reward_pos_loss": 2.9653913974761963, "eval/reward_pred": 0.01249617151916027, "eval/reward_rate": 0.021484375, "replay/size": 259985.0, "replay/inserts": 20976.0, "replay/samples": 20976.0, "replay/insert_wait_avg": 1.3824322130914683e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.709848063488575e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 52520.0, "eval_replay/inserts": 6896.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2359666160530392e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1092402935028, "timer/env.step_count": 2622.0, "timer/env.step_total": 258.37387323379517, "timer/env.step_frac": 0.2583456514790024, "timer/env.step_avg": 0.09854076019595544, "timer/env.step_min": 0.02211737632751465, "timer/env.step_max": 4.036589622497559, "timer/replay._sample_count": 20976.0, "timer/replay._sample_total": 10.853595972061157, "timer/replay._sample_frac": 0.010852410451558216, "timer/replay._sample_avg": 0.0005174292511470804, "timer/replay._sample_min": 0.0004029273986816406, "timer/replay._sample_max": 0.009048938751220703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3484.0, "timer/agent.policy_total": 56.041547775268555, "timer/agent.policy_frac": 0.05603542644883673, "timer/agent.policy_avg": 0.016085404068676392, "timer/agent.policy_min": 0.009166479110717773, "timer/agent.policy_max": 0.14562010765075684, "timer/dataset_train_count": 1311.0, "timer/dataset_train_total": 0.13845324516296387, "timer/dataset_train_frac": 0.0001384381221418691, "timer/dataset_train_avg": 0.00010560888265672302, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0010712146759033203, "timer/agent.train_count": 1311.0, "timer/agent.train_total": 587.6980361938477, "timer/agent.train_frac": 0.587633842900377, "timer/agent.train_avg": 0.4482822549152156, "timer/agent.train_min": 0.4350440502166748, "timer/agent.train_max": 1.505516767501831, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46786952018737793, "timer/agent.report_frac": 0.00046781841556635547, "timer/agent.report_avg": 0.23393476009368896, "timer/agent.report_min": 0.22776174545288086, "timer/agent.report_max": 0.24010777473449707, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0275852202917746e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 20.973450440333185}
{"step": 260536, "time": 12344.428593158722, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 260592, "time": 12348.127412319183, "episode/length": 248.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 260936, "time": 12360.845815896988, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 261408, "time": 12378.13222026825, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 261408, "time": 12378.141650676727, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 261832, "time": 12395.120532035828, "episode/length": 248.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 262016, "time": 12402.880692243576, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 262216, "time": 12412.285782814026, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 262232, "time": 12414.364390134811, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 262488, "time": 12424.548186540604, "episode/length": 243.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 262616, "time": 12430.463653564453, "episode/length": 252.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9881422924901185, "episode/intrinsic_return": 0.0}
{"step": 262624, "time": 12432.577185630798, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 263312, "time": 12457.417789697647, "episode/length": 237.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 263416, "time": 12462.790654420853, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 263608, "time": 12470.635741710663, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9684684684684685, "episode/intrinsic_return": 0.0}
{"step": 263656, "time": 12473.797558546066, "episode/length": 204.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 263760, "time": 12479.068546295166, "episode/length": 42.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 263864, "time": 12483.830399274826, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 263912, "time": 12486.972532272339, "episode/length": 211.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 263928, "time": 12489.254237413406, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 264032, "time": 12494.407485485077, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 264648, "time": 12515.902786970139, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 264848, "time": 12524.177665233612, "episode/length": 154.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 264944, "time": 12528.834278583527, "episode/length": 147.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 265096, "time": 12535.15445280075, "episode/length": 179.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 265488, "time": 12549.843911647797, "episode/length": 181.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 265656, "time": 12556.676337480545, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 265896, "time": 12566.319579839706, "episode/length": 247.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 266176, "time": 12578.18652677536, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 266248, "time": 12582.469960451126, "episode/length": 297.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9865771812080537, "episode/intrinsic_return": 0.0}
{"step": 266280, "time": 12585.450665473938, "episode/length": 147.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 266744, "time": 12603.47239947319, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 266792, "time": 12607.235255241394, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 266920, "time": 12613.652671337128, "episode/length": 92.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 267448, "time": 12632.583661317825, "episode/length": 223.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 267560, "time": 12637.81647849083, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 267568, "time": 12639.85170674324, "episode/length": 208.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 267816, "time": 12649.261906862259, "episode/length": 133.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 267832, "time": 12651.293452501297, "episode/length": 292.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9897610921501706, "episode/intrinsic_return": 0.0}
{"step": 268024, "time": 12659.24943113327, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 268264, "time": 12668.71554517746, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 268704, "time": 12684.857298612595, "episode/length": 156.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 268744, "time": 12687.667160749435, "episode/length": 146.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 269328, "time": 12708.588919401169, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 269640, "time": 12720.332033395767, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 269640, "time": 12720.344453334808, "episode/length": 419.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 270024, "time": 12736.090277910233, "episode/length": 219.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9863636363636363, "episode/intrinsic_return": 0.0}
{"step": 270048, "time": 12738.599646806717, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 12760.630651712418, "eval_episode/length": 166.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 270088, "time": 12763.045778036118, "eval_episode/length": 186.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 270088, "time": 12764.637606620789, "eval_episode/length": 187.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 270088, "time": 12766.545506477356, "eval_episode/length": 197.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 270088, "time": 12769.059756278992, "eval_episode/length": 219.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9681818181818181}
{"step": 270088, "time": 12770.639601230621, "eval_episode/length": 221.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9819819819819819}
{"step": 270088, "time": 12772.843263149261, "eval_episode/length": 238.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9790794979079498}
{"step": 270088, "time": 12776.61524271965, "eval_episode/length": 105.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9433962264150944}
{"step": 270160, "time": 12779.212705850601, "episode/length": 266.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 270312, "time": 12785.573807477951, "episode/length": 35.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 270336, "time": 12788.41098189354, "episode/length": 198.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 270640, "time": 12801.402578353882, "episode/length": 40.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 271320, "time": 12825.144545555115, "episode/length": 209.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 271560, "time": 12834.598849058151, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 271584, "time": 12837.310079813004, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 271616, "time": 12839.928261518478, "episode/length": 36.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 271672, "time": 12843.15848827362, "episode/length": 253.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 271712, "time": 12846.208244800568, "episode/length": 297.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 271736, "time": 12848.342387676239, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 272088, "time": 12861.443925619125, "episode/length": 43.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 272776, "time": 12885.685943603516, "episode/length": 651.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9984662576687117, "episode/intrinsic_return": 0.0}
{"step": 272888, "time": 12890.81357884407, "episode/length": 280.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9750889679715302, "episode/intrinsic_return": 0.0}
{"step": 273032, "time": 12897.194251537323, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 273072, "time": 12900.33485364914, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 273376, "time": 12912.03820347786, "episode/length": 223.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 273392, "time": 12914.229349136353, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 273400, "time": 12915.719552516937, "episode/length": 210.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 273784, "time": 12929.912889957428, "episode/length": 211.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 273952, "time": 12937.347004413605, "episode/length": 109.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 274168, "time": 12946.521218538284, "episode/length": 173.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9540229885057471, "episode/intrinsic_return": 0.0}
{"step": 274688, "time": 12965.580635786057, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 274760, "time": 12969.305844068527, "episode/length": 215.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 274824, "time": 12972.930574655533, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 274824, "time": 12972.939736366272, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 275360, "time": 12994.102684020996, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 275368, "time": 12995.662303209305, "episode/length": 309.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 275576, "time": 13004.1474609375, "episode/length": 175.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 275680, "time": 13009.244854927063, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 275880, "time": 13017.344868421555, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 276080, "time": 13025.67169380188, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 276168, "time": 13029.917574644089, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 276312, "time": 13036.076070308685, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 276704, "time": 13050.756611824036, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 276920, "time": 13059.157126188278, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 277216, "time": 13070.799126386642, "episode/length": 230.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 277272, "time": 13074.052506923676, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 277280, "time": 13076.192752361298, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 277512, "time": 13085.200850486755, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 277664, "time": 13091.95503616333, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 277840, "time": 13099.224506616592, "episode/length": 40.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 277984, "time": 13105.590747833252, "episode/length": 208.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 278096, "time": 13110.981302976608, "episode/length": 146.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 278552, "time": 13128.717671632767, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 278592, "time": 13131.984003305435, "episode/length": 171.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 278928, "time": 13144.76704287529, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 278984, "time": 13147.9036693573, "episode/length": 142.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 279240, "time": 13157.889131784439, "episode/length": 38.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 279512, "time": 13168.508263587952, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 279680, "time": 13175.745399236679, "episode/length": 300.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 279696, "time": 13177.89096069336, "episode/length": 301.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9834437086092715, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 13205.919555664062, "eval_episode/length": 37.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 280072, "time": 13213.204750537872, "eval_episode/length": 183.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9891304347826086}
{"step": 280072, "time": 13214.913923978806, "eval_episode/length": 186.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 280072, "time": 13217.482026338577, "eval_episode/length": 210.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 280072, "time": 13223.08651304245, "eval_episode/length": 269.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9851851851851852}
{"step": 280072, "time": 13224.640535354614, "eval_episode/length": 270.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.985239852398524}
{"step": 280072, "time": 13226.75812625885, "eval_episode/length": 280.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9822064056939501}
{"step": 280072, "time": 13228.60593366623, "eval_episode/length": 250.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9800796812749004}
{"step": 280312, "time": 13236.524676084518, "episode/length": 276.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 280320, "time": 13238.680572271347, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 280544, "time": 13247.575459957123, "episode/length": 243.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 280744, "time": 13255.516290664673, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 280848, "time": 13260.794898033142, "episode/length": 166.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 280976, "time": 13266.532413005829, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 281080, "time": 13271.315665006638, "episode/length": 261.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9885496183206107, "episode/intrinsic_return": 0.0}
{"step": 281144, "time": 13275.05883193016, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 281720, "time": 13296.05111336708, "episode/length": 174.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 282048, "time": 13308.689192771912, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 282184, "time": 13314.56412434578, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 282312, "time": 13320.425467729568, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 282640, "time": 13333.068434715271, "episode/length": 236.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 282680, "time": 13336.118570327759, "episode/length": 78.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 282809, "time": 13343.510455846786, "train_stats/sum_log_reward": 6.082456088902657, "train_stats/max_log_achievement_collect_drink": 5.114035087719298, "train_stats/max_log_achievement_collect_sapling": 3.192982456140351, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 8.0, "train_stats/max_log_achievement_defeat_skeleton": 0.008771929824561403, "train_stats/max_log_achievement_defeat_zombie": 0.7368421052631579, "train_stats/max_log_achievement_eat_cow": 0.20175438596491227, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 1.1754385964912282, "train_stats/max_log_achievement_place_plant": 3.0964912280701755, "train_stats/max_log_achievement_place_table": 1.9736842105263157, "train_stats/max_log_achievement_wake_up": 1.4473684210526316, "train_stats/mean_log_entropy": 0.4474692742029826, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.236033487662994, "train/action_min": 0.0, "train/action_std": 3.079495822782997, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04753670399244741, "train/actor_opt_grad_steps": 16880.0, "train/actor_opt_loss": -0.48022547053347386, "train/adv_mag": 0.6766184667031542, "train/adv_max": 0.6463673412799835, "train/adv_mean": 0.0046844570281942164, "train/adv_min": -0.49853682217838097, "train/adv_std": 0.0725388337435911, "train/cont_avg": 0.9946183678057554, "train/cont_loss_mean": 0.000408948946791912, "train/cont_loss_std": 0.011974961240490602, "train/cont_neg_acc": 0.9890684879941049, "train/cont_neg_loss": 0.03756172837094984, "train/cont_pos_acc": 0.9999364005575935, "train/cont_pos_loss": 0.00017650845941830084, "train/cont_pred": 0.9946096659564286, "train/cont_rate": 0.9946183678057554, "train/dyn_loss_mean": 15.515940316289448, "train/dyn_loss_std": 9.028994224054351, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9912328870176411, "train/extr_critic_critic_opt_grad_steps": 16880.0, "train/extr_critic_critic_opt_loss": 16747.753843019334, "train/extr_critic_mag": 5.468030305217496, "train/extr_critic_max": 5.468030305217496, "train/extr_critic_mean": 1.203990374966491, "train/extr_critic_min": -0.23093040641263235, "train/extr_critic_std": 1.2454328326870212, "train/extr_return_normed_mag": 1.7013254165649414, "train/extr_return_normed_max": 1.7013254165649414, "train/extr_return_normed_mean": 0.3340456461091693, "train/extr_return_normed_min": -0.12646808971067985, "train/extr_return_normed_std": 0.3288845193686245, "train/extr_return_rate": 0.5941205164082617, "train/extr_return_raw_mag": 6.567543873684012, "train/extr_return_raw_max": 6.567543873684012, "train/extr_return_raw_mean": 1.2223351902241328, "train/extr_return_raw_min": -0.5777017011059274, "train/extr_return_raw_std": 1.2857865755506557, "train/extr_reward_mag": 1.0103248863769092, "train/extr_reward_max": 1.0103248863769092, "train/extr_reward_mean": 0.02890673955808655, "train/extr_reward_min": -0.3401048852385377, "train/extr_reward_std": 0.15717544797941935, "train/image_loss_mean": 8.515556266839555, "train/image_loss_std": 11.854128528841965, "train/model_loss_mean": 17.881646883573463, "train/model_loss_std": 15.52270728735615, "train/model_opt_grad_norm": 67.32725419243462, "train/model_opt_grad_steps": 16861.45323741007, "train/model_opt_loss": 19732.37388292491, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1101.6187050359713, "train/policy_entropy_mag": 2.1788212978582586, "train/policy_entropy_max": 2.1788212978582586, "train/policy_entropy_mean": 0.476806234755962, "train/policy_entropy_min": 0.07937532636544688, "train/policy_entropy_std": 0.4463739015644403, "train/policy_logprob_mag": 7.438383177887622, "train/policy_logprob_max": -0.0094557698856262, "train/policy_logprob_mean": -0.4761296077597913, "train/policy_logprob_min": -7.438383177887622, "train/policy_logprob_std": 1.0199192016244791, "train/policy_randomness_mag": 0.7690283021480917, "train/policy_randomness_max": 0.7690283021480917, "train/policy_randomness_mean": 0.16829167574429685, "train/policy_randomness_min": 0.028016006909042813, "train/policy_randomness_std": 0.15755039796554784, "train/post_ent_mag": 58.158770828795944, "train/post_ent_max": 58.158770828795944, "train/post_ent_mean": 39.708340130263956, "train/post_ent_min": 21.505630520607927, "train/post_ent_std": 6.978960658148896, "train/prior_ent_mag": 67.42083416396765, "train/prior_ent_max": 67.42083416396765, "train/prior_ent_mean": 55.32377501014325, "train/prior_ent_min": 34.95889334369907, "train/prior_ent_std": 5.205843079861977, "train/rep_loss_mean": 15.515940316289448, "train/rep_loss_std": 9.028994224054351, "train/reward_avg": 0.023242889843184313, "train/reward_loss_mean": 0.05611765848325311, "train/reward_loss_std": 0.2665175642255399, "train/reward_max_data": 1.0107913694793371, "train/reward_max_pred": 1.0058785676956177, "train/reward_neg_acc": 0.992980961319354, "train/reward_neg_loss": 0.031273468390857574, "train/reward_pos_acc": 0.9545784442544841, "train/reward_pos_loss": 0.9213895999270377, "train/reward_pred": 0.02224496877316734, "train/reward_rate": 0.028228979316546762, "eval_stats/sum_log_reward": 6.537500023841858, "eval_stats/max_log_achievement_collect_drink": 4.6875, "eval_stats/max_log_achievement_collect_sapling": 3.25, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.9375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_plant": 3.125, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.9430848371703178e-05, "report/cont_loss_std": 0.000436511734733358, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.7808573577203788e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.944201150967274e-05, "report/cont_pred": 0.9931350946426392, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 14.428184509277344, "report/dyn_loss_std": 8.75706672668457, "report/image_loss_mean": 5.894039154052734, "report/image_loss_std": 8.708487510681152, "report/model_loss_mean": 14.615985870361328, "report/model_loss_std": 12.669853210449219, "report/post_ent_mag": 60.04901123046875, "report/post_ent_max": 60.04901123046875, "report/post_ent_mean": 39.72553253173828, "report/post_ent_min": 22.25568389892578, "report/post_ent_std": 7.32862663269043, "report/prior_ent_mag": 67.45743560791016, "report/prior_ent_max": 67.45743560791016, "report/prior_ent_mean": 54.642635345458984, "report/prior_ent_min": 33.310020446777344, "report/prior_ent_std": 5.299444198608398, "report/rep_loss_mean": 14.428184509277344, "report/rep_loss_std": 8.75706672668457, "report/reward_avg": 0.03515625, "report/reward_loss_mean": 0.0650072768330574, "report/reward_loss_std": 0.3270384669303894, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0050861835479736, "report/reward_neg_acc": 0.9908537268638611, "report/reward_neg_loss": 0.03192440792918205, "report/reward_pos_acc": 0.949999988079071, "report/reward_pos_loss": 0.8788458704948425, "report/reward_pred": 0.03342389687895775, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0018090044613927603, "eval/cont_loss_std": 0.0550873801112175, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.707554267544765e-05, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.001815992291085422, "eval/cont_pred": 0.9951985478401184, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 20.38900375366211, "eval/dyn_loss_std": 10.409825325012207, "eval/image_loss_mean": 21.475276947021484, "eval/image_loss_std": 26.40422248840332, "eval/model_loss_mean": 33.80824661254883, "eval/model_loss_std": 30.009288787841797, "eval/post_ent_mag": 61.180992126464844, "eval/post_ent_max": 61.180992126464844, "eval/post_ent_mean": 39.05229949951172, "eval/post_ent_min": 20.069122314453125, "eval/post_ent_std": 6.6815667152404785, "eval/prior_ent_mag": 67.45743560791016, "eval/prior_ent_max": 67.45743560791016, "eval/prior_ent_mean": 56.0078125, "eval/prior_ent_min": 33.67033767700195, "eval/prior_ent_std": 5.3118181228637695, "eval/rep_loss_mean": 20.38900375366211, "eval/rep_loss_std": 10.409825325012207, "eval/reward_avg": 0.02314453199505806, "eval/reward_loss_mean": 0.09776139259338379, "eval/reward_loss_std": 0.5943219065666199, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001476526260376, "eval/reward_neg_acc": 0.9899699091911316, "eval/reward_neg_loss": 0.044598065316677094, "eval/reward_pos_acc": 0.7037037014961243, "eval/reward_pos_loss": 2.060866594314575, "eval/reward_pred": 0.016529161483049393, "eval/reward_rate": 0.0263671875, "replay/size": 282305.0, "replay/inserts": 22320.0, "replay/samples": 22320.0, "replay/insert_wait_avg": 1.352672935813986e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.573989287072185e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 57176.0, "eval_replay/inserts": 4656.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.207864571273122e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4441759586334, "timer/env.step_count": 2790.0, "timer/env.step_total": 256.38938307762146, "timer/env.step_frac": 0.256275551638798, "timer/env.step_avg": 0.09189583622853816, "timer/env.step_min": 0.021925687789916992, "timer/env.step_max": 3.2213966846466064, "timer/replay._sample_count": 22320.0, "timer/replay._sample_total": 11.579054355621338, "timer/replay._sample_frac": 0.01157391350149667, "timer/replay._sample_avg": 0.0005187748367213861, "timer/replay._sample_min": 0.00037479400634765625, "timer/replay._sample_max": 0.00959014892578125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3372.0, "timer/agent.policy_total": 54.537360429763794, "timer/agent.policy_frac": 0.05451314700043675, "timer/agent.policy_avg": 0.016173594433500534, "timer/agent.policy_min": 0.009312868118286133, "timer/agent.policy_max": 0.09688353538513184, "timer/dataset_train_count": 1395.0, "timer/dataset_train_total": 0.1463308334350586, "timer/dataset_train_frac": 0.0001462658656539664, "timer/dataset_train_avg": 0.0001048966547921567, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.00044083595275878906, "timer/agent.train_count": 1395.0, "timer/agent.train_total": 622.6174912452698, "timer/agent.train_frac": 0.6223410623073224, "timer/agent.train_avg": 0.4463207822546737, "timer/agent.train_min": 0.43483877182006836, "timer/agent.train_max": 1.4626085758209229, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46729183197021484, "timer/agent.report_frac": 0.0004670843643249281, "timer/agent.report_avg": 0.23364591598510742, "timer/agent.report_min": 0.2214524745941162, "timer/agent.report_max": 0.24583935737609863, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9550778063419067e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 22.30978004753649}
{"step": 282928, "time": 13347.739089012146, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9713114754098361, "episode/intrinsic_return": 0.0}
{"step": 282984, "time": 13350.907337665558, "episode/length": 237.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 283240, "time": 13360.9723341465, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 283496, "time": 13370.974366664886, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 283592, "time": 13375.684551000595, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 284040, "time": 13392.134861469269, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 284352, "time": 13404.249776124954, "episode/length": 400.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9950124688279302, "episode/intrinsic_return": 0.0}
{"step": 284392, "time": 13407.04233288765, "episode/length": 43.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 284672, "time": 13418.042116165161, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 284824, "time": 13424.423427581787, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 285064, "time": 13433.925236940384, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 285096, "time": 13436.586373090744, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 285112, "time": 13438.60188961029, "episode/length": 303.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 285208, "time": 13443.398370981216, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 285816, "time": 13465.831202030182, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 285968, "time": 13472.72961807251, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 286016, "time": 13475.85040640831, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 286160, "time": 13482.213464736938, "episode/length": 42.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 286216, "time": 13485.489547014236, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9844559585492227, "episode/intrinsic_return": 0.0}
{"step": 286400, "time": 13493.322668075562, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 286456, "time": 13496.517065763474, "episode/length": 36.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8918918918918919, "episode/intrinsic_return": 0.0}
{"step": 286744, "time": 13508.991132736206, "episode/length": 35.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 286880, "time": 13515.293049573898, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 286992, "time": 13520.585472345352, "episode/length": 234.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 287064, "time": 13524.282713651657, "episode/length": 249.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 287408, "time": 13537.652127504349, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 287656, "time": 13548.026165246964, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 287728, "time": 13552.712158679962, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 288072, "time": 13566.035488843918, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 288352, "time": 13577.145846366882, "episode/length": 266.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 288416, "time": 13580.918739318848, "episode/length": 191.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 288448, "time": 13583.576047897339, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 288792, "time": 13596.426744222641, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 289080, "time": 13608.34150147438, "episode/length": 90.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9560439560439561, "episode/intrinsic_return": 0.0}
{"step": 289200, "time": 13614.800654411316, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 289648, "time": 13632.16715168953, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 289776, "time": 13637.95722770691, "episode/length": 212.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 289832, "time": 13641.093160867691, "episode/length": 172.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 289960, "time": 13646.854584217072, "episode/length": 278.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 13665.921454191208, "eval_episode/length": 37.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 290056, "time": 13667.747944116592, "eval_episode/length": 44.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 290056, "time": 13673.71519613266, "eval_episode/length": 157.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 290056, "time": 13675.84892463684, "eval_episode/length": 173.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9540229885057471}
{"step": 290056, "time": 13677.51058101654, "eval_episode/length": 175.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 290056, "time": 13679.150592327118, "eval_episode/length": 177.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 290056, "time": 13681.459024190903, "eval_episode/length": 196.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 290056, "time": 13683.133997917175, "eval_episode/length": 160.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 290320, "time": 13692.05901312828, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 290512, "time": 13700.010061264038, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 290648, "time": 13705.882210493088, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 291160, "time": 13724.49681353569, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 291200, "time": 13727.62519288063, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 291208, "time": 13729.271511793137, "episode/length": 443.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 291256, "time": 13732.393538475037, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 291344, "time": 13737.178849220276, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 291424, "time": 13741.285679340363, "episode/length": 137.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 291904, "time": 13758.52304816246, "episode/length": 87.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 292184, "time": 13769.301388978958, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 292536, "time": 13783.308525562286, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 292544, "time": 13785.791013479233, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 292744, "time": 13794.404666423798, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 292816, "time": 13799.211915493011, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 293272, "time": 13816.201853275299, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 293544, "time": 13827.126680374146, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 293712, "time": 13835.19356226921, "episode/length": 306.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9837133550488599, "episode/intrinsic_return": 0.0}
{"step": 294104, "time": 13849.900346517563, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 294400, "time": 13861.487841367722, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 294400, "time": 13861.49843120575, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 294400, "time": 13861.509600400925, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 295016, "time": 13888.81011390686, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 295080, "time": 13892.968853712082, "episode/length": 170.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 295144, "time": 13897.09776544571, "episode/length": 92.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 295472, "time": 13910.355714559555, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 295648, "time": 13917.867858171463, "episode/length": 262.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 295672, "time": 13920.06762433052, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 295864, "time": 13928.004008293152, "episode/length": 651.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995398773006135, "episode/intrinsic_return": 0.0}
{"step": 296344, "time": 13945.534819364548, "episode/length": 242.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 296664, "time": 13958.736329078674, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 296712, "time": 13962.490902423859, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 296736, "time": 13965.50931763649, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 296760, "time": 13968.078878879547, "episode/length": 138.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 296768, "time": 13970.543380022049, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 297192, "time": 13986.978631019592, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 297264, "time": 13991.189049959183, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 297512, "time": 14000.687980890274, "episode/length": 145.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 298040, "time": 14019.723195791245, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 298144, "time": 14024.998803377151, "episode/length": 118.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.957983193277311, "episode/intrinsic_return": 0.0}
{"step": 298144, "time": 14025.00942492485, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 298248, "time": 14031.523644208908, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 298440, "time": 14039.500166893005, "episode/length": 36.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 298496, "time": 14043.179476737976, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 298816, "time": 14055.193889379501, "episode/length": 262.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 298928, "time": 14060.405299663544, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 299064, "time": 14066.353642702103, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 299480, "time": 14081.631019353867, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 299528, "time": 14084.676089763641, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 299848, "time": 14096.891295909882, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 299880, "time": 14099.511667728424, "episode/length": 203.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 300032, "time": 14106.318880558014, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 14126.996842384338, "eval_episode/length": 38.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 300040, "time": 14131.014424085617, "eval_episode/length": 83.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9404761904761905}
{"step": 300040, "time": 14136.191289663315, "eval_episode/length": 153.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.961038961038961}
{"step": 300040, "time": 14136.199388980865, "eval_episode/length": 153.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 300040, "time": 14140.086899280548, "eval_episode/length": 166.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 300040, "time": 14142.535018205643, "eval_episode/length": 189.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 300040, "time": 14144.375001430511, "eval_episode/length": 194.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 300040, "time": 14149.32101559639, "eval_episode/length": 277.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9748201438848921}
{"step": 300272, "time": 14157.367273330688, "episode/length": 150.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 300376, "time": 14162.160801887512, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 300416, "time": 14165.260658740997, "episode/length": 116.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9658119658119658, "episode/intrinsic_return": 0.0}
{"step": 300576, "time": 14172.221616744995, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 301104, "time": 14191.238164424896, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 301504, "time": 14206.005020618439, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 301712, "time": 14214.540825605392, "episode/length": 166.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9880239520958084, "episode/intrinsic_return": 0.0}
{"step": 301736, "time": 14216.821290969849, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 301744, "time": 14218.87071466446, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 301928, "time": 14226.174103021622, "episode/length": 255.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 302120, "time": 14234.112219810486, "episode/length": 260.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 302240, "time": 14239.855149507523, "episode/length": 38.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 302352, "time": 14245.104597330093, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 302608, "time": 14255.137591123581, "episode/length": 253.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 303104, "time": 14273.189363241196, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 303160, "time": 14278.56059885025, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 303216, "time": 14282.823632717133, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 303704, "time": 14301.229516744614, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 303864, "time": 14308.660398244858, "episode/length": 268.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 304152, "time": 14319.80036520958, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 304232, "time": 14323.794003725052, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 304304, "time": 14328.0989716053, "episode/length": 74.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 304344, "time": 14330.821331501007, "episode/length": 262.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 304408, "time": 14334.419271945953, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 304520, "time": 14339.766391992569, "episode/length": 176.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 304569, "time": 14343.837628602982, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.33955966725069, "train/action_min": 0.0, "train/action_std": 3.2569865321411804, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04742054422112072, "train/actor_opt_grad_steps": 18255.0, "train/actor_opt_loss": -1.2275857361690963, "train/adv_mag": 0.6590122799662983, "train/adv_max": 0.6271804211770787, "train/adv_mean": 0.0044652463282224795, "train/adv_min": -0.47740690322483287, "train/adv_std": 0.07112059082068942, "train/cont_avg": 0.9947366153492647, "train/cont_loss_mean": 0.0003033079680693283, "train/cont_loss_std": 0.008786068968457612, "train/cont_neg_acc": 0.9860206596991595, "train/cont_neg_loss": 0.04169852298805916, "train/cont_pos_acc": 0.9999566380591953, "train/cont_pos_loss": 0.0001018413866384904, "train/cont_pred": 0.9947603379978853, "train/cont_rate": 0.9947366153492647, "train/dyn_loss_mean": 15.282461096258725, "train/dyn_loss_std": 8.949438466745264, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9726813926416285, "train/extr_critic_critic_opt_grad_steps": 18255.0, "train/extr_critic_critic_opt_loss": 16638.137544519763, "train/extr_critic_mag": 5.667045263683095, "train/extr_critic_max": 5.667045263683095, "train/extr_critic_mean": 1.3073730613378918, "train/extr_critic_min": -0.23470396592336543, "train/extr_critic_std": 1.3062711463255041, "train/extr_return_normed_mag": 1.7062422422801746, "train/extr_return_normed_max": 1.7062422422801746, "train/extr_return_normed_mean": 0.34506626799702644, "train/extr_return_normed_min": -0.1229210845194757, "train/extr_return_normed_std": 0.3313977312954033, "train/extr_return_rate": 0.6266994414960637, "train/extr_return_raw_mag": 6.87182135441724, "train/extr_return_raw_max": 6.87182135441724, "train/extr_return_raw_mean": 1.325546314172885, "train/extr_return_raw_min": -0.581489044953795, "train/extr_return_raw_std": 1.350437791470219, "train/extr_reward_mag": 1.0098682501736809, "train/extr_reward_max": 1.0098682501736809, "train/extr_reward_mean": 0.030161875060430783, "train/extr_reward_min": -0.35521528563078714, "train/extr_reward_std": 0.16230460700085936, "train/image_loss_mean": 8.20663614132825, "train/image_loss_std": 11.572496677146239, "train/model_loss_mean": 17.431217144517337, "train/model_loss_std": 15.185327053070068, "train/model_opt_grad_norm": 67.97550219648025, "train/model_opt_grad_steps": 18234.514705882353, "train/model_opt_loss": 11284.740306181066, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 647.9779411764706, "train/policy_entropy_mag": 2.335554196554072, "train/policy_entropy_max": 2.335554196554072, "train/policy_entropy_mean": 0.49680422027321425, "train/policy_entropy_min": 0.07937528154648402, "train/policy_entropy_std": 0.48426782405551744, "train/policy_logprob_mag": 7.438383316292482, "train/policy_logprob_max": -0.009455762796706575, "train/policy_logprob_mean": -0.49681489454472766, "train/policy_logprob_min": -7.438383316292482, "train/policy_logprob_std": 1.0401858029996647, "train/policy_randomness_mag": 0.8243481367826462, "train/policy_randomness_max": 0.8243481367826462, "train/policy_randomness_mean": 0.17535008785917477, "train/policy_randomness_min": 0.02801599107025301, "train/policy_randomness_std": 0.17092529081684701, "train/post_ent_mag": 58.66227952171774, "train/post_ent_max": 58.66227952171774, "train/post_ent_mean": 40.1282948886647, "train/post_ent_min": 21.414648546892053, "train/post_ent_std": 7.133196644923267, "train/prior_ent_mag": 67.63288284750546, "train/prior_ent_max": 67.63288284750546, "train/prior_ent_mean": 55.48436162051033, "train/prior_ent_min": 35.41525065197664, "train/prior_ent_std": 5.125350089634166, "train/rep_loss_mean": 15.282461096258725, "train/rep_loss_std": 8.949438466745264, "train/reward_avg": 0.023089958546145626, "train/reward_loss_mean": 0.05480111698510454, "train/reward_loss_std": 0.2554393930031973, "train/reward_max_data": 1.0110294143943226, "train/reward_max_pred": 1.0068534638951807, "train/reward_neg_acc": 0.992905322681455, "train/reward_neg_loss": 0.030516100177705726, "train/reward_pos_acc": 0.9572023749351501, "train/reward_pos_loss": 0.899607377455515, "train/reward_pred": 0.022422214923768908, "train/reward_rate": 0.028018727022058824, "train_stats/sum_log_reward": 6.065517233363513, "train_stats/max_log_achievement_collect_drink": 4.525862068965517, "train_stats/max_log_achievement_collect_sapling": 3.2758620689655173, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 8.439655172413794, "train_stats/max_log_achievement_defeat_skeleton": 0.008620689655172414, "train_stats/max_log_achievement_defeat_zombie": 0.6810344827586207, "train_stats/max_log_achievement_eat_cow": 0.14655172413793102, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008620689655172414, "train_stats/max_log_achievement_make_wood_sword": 1.1637931034482758, "train_stats/max_log_achievement_place_plant": 3.1810344827586206, "train_stats/max_log_achievement_place_table": 2.0948275862068964, "train_stats/max_log_achievement_wake_up": 1.3448275862068966, "train_stats/mean_log_entropy": 0.4561844686495847, "eval_stats/sum_log_reward": 5.224999964237213, "eval_stats/max_log_achievement_collect_drink": 3.25, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 7.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0016849202802404761, "report/cont_loss_std": 0.05074388161301613, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00058670126600191, "report/cont_pos_acc": 0.999018669128418, "report/cont_pos_loss": 0.0016903089126572013, "report/cont_pred": 0.9942423105239868, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 15.235296249389648, "report/dyn_loss_std": 8.975505828857422, "report/image_loss_mean": 7.830165863037109, "report/image_loss_std": 13.259140014648438, "report/model_loss_mean": 17.022945404052734, "report/model_loss_std": 16.97553253173828, "report/post_ent_mag": 54.9241943359375, "report/post_ent_max": 54.9241943359375, "report/post_ent_mean": 38.96057891845703, "report/post_ent_min": 22.486425399780273, "report/post_ent_std": 5.982542037963867, "report/prior_ent_mag": 66.98548889160156, "report/prior_ent_max": 66.98548889160156, "report/prior_ent_mean": 54.789222717285156, "report/prior_ent_min": 35.87873077392578, "report/prior_ent_std": 4.81306791305542, "report/rep_loss_mean": 15.235296249389648, "report/rep_loss_std": 8.975505828857422, "report/reward_avg": 0.01972656324505806, "report/reward_loss_mean": 0.04991847276687622, "report/reward_loss_std": 0.2858356535434723, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0021309852600098, "report/reward_neg_acc": 0.9919919967651367, "report/reward_neg_loss": 0.03273795172572136, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7364521622657776, "report/reward_pred": 0.019608834758400917, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.948641329363454e-05, "eval/cont_loss_std": 0.0005385351250879467, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.384373849257827e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.9430108295637183e-05, "eval/cont_pred": 0.9960747361183167, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.104705810546875, "eval/dyn_loss_std": 10.499713897705078, "eval/image_loss_mean": 18.047780990600586, "eval/image_loss_std": 22.255876541137695, "eval/model_loss_mean": 29.585262298583984, "eval/model_loss_std": 26.51539421081543, "eval/post_ent_mag": 59.0748291015625, "eval/post_ent_max": 59.0748291015625, "eval/post_ent_mean": 40.007686614990234, "eval/post_ent_min": 21.644559860229492, "eval/post_ent_std": 6.763731956481934, "eval/prior_ent_mag": 66.98548889160156, "eval/prior_ent_max": 66.98548889160156, "eval/prior_ent_mean": 56.451698303222656, "eval/prior_ent_min": 35.03167724609375, "eval/prior_ent_std": 4.863945007324219, "eval/rep_loss_mean": 19.104705810546875, "eval/rep_loss_std": 10.499713897705078, "eval/reward_avg": 0.01630859263241291, "eval/reward_loss_mean": 0.07463957369327545, "eval/reward_loss_std": 0.5237392783164978, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017499923706055, "eval/reward_neg_acc": 0.9940119981765747, "eval/reward_neg_loss": 0.03885592892765999, "eval/reward_pos_acc": 0.8181818723678589, "eval/reward_pos_loss": 1.7044219970703125, "eval/reward_pred": 0.014411178417503834, "eval/reward_rate": 0.021484375, "replay/size": 304065.0, "replay/inserts": 21760.0, "replay/samples": 21760.0, "replay/insert_wait_avg": 1.374664990340962e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.687596110736623e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 60992.0, "eval_replay/inserts": 3816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2268310322951471e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3118300437927, "timer/env.step_count": 2720.0, "timer/env.step_total": 268.7399950027466, "timer/env.step_frac": 0.2686562199219231, "timer/env.step_avg": 0.09880146875100977, "timer/env.step_min": 0.0224454402923584, "timer/env.step_max": 5.0988452434539795, "timer/replay._sample_count": 21760.0, "timer/replay._sample_total": 11.417681455612183, "timer/replay._sample_frac": 0.01141412218939001, "timer/replay._sample_avg": 0.0005247096257174716, "timer/replay._sample_min": 0.00041031837463378906, "timer/replay._sample_max": 0.032984256744384766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3197.0, "timer/agent.policy_total": 50.859424114227295, "timer/agent.policy_frac": 0.05084356956170429, "timer/agent.policy_avg": 0.01590848423967072, "timer/agent.policy_min": 0.009263753890991211, "timer/agent.policy_max": 0.08694338798522949, "timer/dataset_train_count": 1360.0, "timer/dataset_train_total": 0.14294791221618652, "timer/dataset_train_frac": 0.00014290335065809267, "timer/dataset_train_avg": 0.0001051087589824901, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.0003154277801513672, "timer/agent.train_count": 1360.0, "timer/agent.train_total": 610.7139544487, "timer/agent.train_frac": 0.6105235748556163, "timer/agent.train_avg": 0.4490543782711029, "timer/agent.train_min": 0.434736967086792, "timer/agent.train_max": 1.4942703247070312, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4690849781036377, "timer/agent.report_frac": 0.000468938748913028, "timer/agent.report_avg": 0.23454248905181885, "timer/agent.report_min": 0.2271275520324707, "timer/agent.report_max": 0.241957426071167, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.693290095079361e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 21.75293424211115}
{"step": 305056, "time": 14359.986472606659, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 305432, "time": 14374.434046268463, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 305680, "time": 14384.35336112976, "episode/length": 180.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 305816, "time": 14390.169800281525, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 305888, "time": 14394.310560703278, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 305968, "time": 14398.6335272789, "episode/length": 35.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 305984, "time": 14400.67601275444, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 306288, "time": 14412.250675439835, "episode/length": 153.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 306296, "time": 14413.878956079483, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9684684684684685, "episode/intrinsic_return": 0.0}
{"step": 306632, "time": 14426.508107662201, "episode/length": 149.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 306976, "time": 14439.848742485046, "episode/length": 144.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 307272, "time": 14451.419127702713, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 307272, "time": 14451.42955160141, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 307536, "time": 14463.730072498322, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 307704, "time": 14470.731758832932, "episode/length": 479.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9854166666666667, "episode/intrinsic_return": 0.0}
{"step": 308032, "time": 14483.936492681503, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 308128, "time": 14488.770200490952, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 308176, "time": 14491.799218654633, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 308472, "time": 14502.969816207886, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 308624, "time": 14509.782490730286, "episode/length": 291.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 308816, "time": 14517.878685235977, "episode/length": 42.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 308848, "time": 14520.50335764885, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 309032, "time": 14528.0708796978, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 309408, "time": 14542.349913835526, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 309768, "time": 14555.650907993317, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 310000, "time": 14565.159182786942, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 310008, "time": 14566.831113815308, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 14585.396106243134, "eval_episode/length": 40.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.975609756097561}
{"step": 310024, "time": 14592.294807195663, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 310024, "time": 14594.342002630234, "eval_episode/length": 166.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 310024, "time": 14597.50687623024, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 310024, "time": 14600.292395353317, "eval_episode/length": 164.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 310024, "time": 14602.554779529572, "eval_episode/length": 208.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 310024, "time": 14604.94189286232, "eval_episode/length": 216.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 310024, "time": 14607.240413427353, "eval_episode/length": 220.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.995475113122172}
{"step": 310176, "time": 14612.695410728455, "episode/length": 142.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 310312, "time": 14619.005302667618, "episode/length": 266.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 310512, "time": 14627.409205436707, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 310784, "time": 14638.152569532394, "episode/length": 58.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 311144, "time": 14651.364885807037, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 311224, "time": 14655.529291629791, "episode/length": 493.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 311384, "time": 14663.66917181015, "episode/length": 246.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 311488, "time": 14668.889847040176, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 311512, "time": 14671.078120231628, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 311792, "time": 14682.14634847641, "episode/length": 37.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 311944, "time": 14688.495629310608, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 312176, "time": 14697.978740692139, "episode/length": 270.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704797047970479, "episode/intrinsic_return": 0.0}
{"step": 312448, "time": 14708.546961545944, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 312632, "time": 14715.861368179321, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 312696, "time": 14719.50045132637, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 312816, "time": 14725.286351680756, "episode/length": 208.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 313016, "time": 14734.0526201725, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 313528, "time": 14753.595537424088, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 313608, "time": 14758.573826313019, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 313776, "time": 14766.323807954788, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 313952, "time": 14773.779083490372, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 314016, "time": 14777.470259428024, "episode/length": 277.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 314088, "time": 14781.177643060684, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 314344, "time": 14791.515434980392, "episode/length": 165.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 314440, "time": 14796.84359908104, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 314880, "time": 14813.985805273056, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 315024, "time": 14820.978049993515, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 315232, "time": 14829.229199886322, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 315408, "time": 14836.504028081894, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 315632, "time": 14845.362519979477, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 315704, "time": 14849.23537492752, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 315928, "time": 14858.138350009918, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 316160, "time": 14867.527331829071, "episode/length": 141.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 316192, "time": 14870.010852098465, "episode/length": 230.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 316376, "time": 14877.731834888458, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 316864, "time": 14896.311891794205, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 316896, "time": 14899.301706075668, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 317224, "time": 14912.401584148407, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 317600, "time": 14927.629331111908, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 317672, "time": 14931.824421405792, "episode/length": 254.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 317736, "time": 14935.496140956879, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 317752, "time": 14937.816200971603, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 318192, "time": 14954.382769107819, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 318248, "time": 14958.06739616394, "episode/length": 260.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 318320, "time": 14962.66487121582, "episode/length": 136.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 318728, "time": 14978.50523018837, "episode/length": 131.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.946969696969697, "episode/intrinsic_return": 0.0}
{"step": 318888, "time": 14986.05917429924, "episode/length": 141.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 319016, "time": 14992.417744398117, "episode/length": 264.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 319096, "time": 14996.608867645264, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 319376, "time": 15007.684524774551, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 319392, "time": 15009.654039382935, "episode/length": 206.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 319560, "time": 15018.093412160873, "episode/length": 170.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 320000, "time": 15035.488627195358, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 15056.687498569489, "eval_episode/length": 48.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 320008, "time": 15063.153933048248, "eval_episode/length": 143.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 320008, "time": 15065.775410175323, "eval_episode/length": 160.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 320008, "time": 15067.690978050232, "eval_episode/length": 168.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 320008, "time": 15069.295664787292, "eval_episode/length": 171.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 320008, "time": 15071.681727170944, "eval_episode/length": 193.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 320008, "time": 15073.91321015358, "eval_episode/length": 41.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 320008, "time": 15076.547912359238, "eval_episode/length": 185.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 320296, "time": 15086.081380605698, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 320360, "time": 15089.889791965485, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 320368, "time": 15091.891720533371, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 320504, "time": 15097.777845144272, "episode/length": 272.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 320696, "time": 15105.888327598572, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 320808, "time": 15111.790084600449, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 321048, "time": 15122.063877820969, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 321848, "time": 15150.916296243668, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 321912, "time": 15154.626653432846, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 322216, "time": 15166.215532779694, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 322520, "time": 15177.932671546936, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 322608, "time": 15182.618202447891, "episode/length": 238.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9665271966527197, "episode/intrinsic_return": 0.0}
{"step": 322704, "time": 15187.362585067749, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 323088, "time": 15201.684315919876, "episode/length": 254.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 323304, "time": 15210.093792915344, "episode/length": 412.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975786924939467, "episode/intrinsic_return": 0.0}
{"step": 323328, "time": 15212.63959312439, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 323584, "time": 15222.556119441986, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 323760, "time": 15230.115715742111, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 323960, "time": 15238.766015529633, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 324224, "time": 15249.012686729431, "episode/length": 288.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 324360, "time": 15254.914922237396, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 324504, "time": 15261.275640249252, "episode/length": 146.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 324568, "time": 15265.037339448929, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 324664, "time": 15269.85668516159, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 324912, "time": 15279.743836641312, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 325032, "time": 15284.9956843853, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 325256, "time": 15293.846665143967, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 325728, "time": 15311.493066310883, "episode/length": 170.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 325872, "time": 15317.789680242538, "episode/length": 170.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 326080, "time": 15326.351980686188, "episode/length": 176.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 326232, "time": 15332.611572027206, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 326256, "time": 15335.204983234406, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968503937007874, "episode/intrinsic_return": 0.0}
{"step": 326328, "time": 15338.89289522171, "episode/length": 219.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 326409, "time": 15344.067078351974, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.309522642706432, "train/action_min": 0.0, "train/action_std": 3.2411142109084303, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04517680572441025, "train/actor_opt_grad_steps": 19620.0, "train/actor_opt_loss": -3.95948931596575, "train/adv_mag": 0.6016834637109381, "train/adv_max": 0.5644331141544955, "train/adv_mean": 0.003415436789947991, "train/adv_min": -0.4701349469867066, "train/adv_std": 0.06750613926862278, "train/cont_avg": 0.9945112910583942, "train/cont_loss_mean": 0.00020793078081810413, "train/cont_loss_std": 0.0060814312056175, "train/cont_neg_acc": 0.9928745231489196, "train/cont_neg_loss": 0.01293982251565573, "train/cont_pos_acc": 0.9999569959014002, "train/cont_pos_loss": 0.00014557752959874456, "train/cont_pred": 0.9944994614942231, "train/cont_rate": 0.9945112910583942, "train/dyn_loss_mean": 15.078433057687578, "train/dyn_loss_std": 9.075675435309863, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9391088011491038, "train/extr_critic_critic_opt_grad_steps": 19620.0, "train/extr_critic_critic_opt_loss": 16497.77580406022, "train/extr_critic_mag": 5.6892332125754255, "train/extr_critic_max": 5.6892332125754255, "train/extr_critic_mean": 1.324213462589431, "train/extr_critic_min": -0.24165095203984394, "train/extr_critic_std": 1.3558189185866474, "train/extr_return_normed_mag": 1.6756235996302027, "train/extr_return_normed_max": 1.6756235996302027, "train/extr_return_normed_mean": 0.3422632301158279, "train/extr_return_normed_min": -0.11466999069182542, "train/extr_return_normed_std": 0.3319612938339693, "train/extr_return_rate": 0.6122595759203834, "train/extr_return_raw_mag": 6.929726005470665, "train/extr_return_raw_max": 6.929726005470665, "train/extr_return_raw_mean": 1.3385532602776575, "train/extr_return_raw_min": -0.5778053683521104, "train/extr_return_raw_std": 1.3922514958973349, "train/extr_reward_mag": 1.0118469904809102, "train/extr_reward_max": 1.0118469904809102, "train/extr_reward_mean": 0.03012869486680431, "train/extr_reward_min": -0.3763778870993287, "train/extr_reward_std": 0.162378713706114, "train/image_loss_mean": 7.9749420298277025, "train/image_loss_std": 11.700711758467403, "train/model_loss_mean": 17.07809851291406, "train/model_loss_std": 15.355635893605921, "train/model_opt_grad_norm": 69.03669602331453, "train/model_opt_grad_steps": 19598.89781021898, "train/model_opt_loss": 17572.7137602646, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1031.021897810219, "train/policy_entropy_mag": 2.4154780920404586, "train/policy_entropy_max": 2.4154780920404586, "train/policy_entropy_mean": 0.5210986461517585, "train/policy_entropy_min": 0.0793752472874892, "train/policy_entropy_std": 0.5443659803293047, "train/policy_logprob_mag": 7.438383342575853, "train/policy_logprob_max": -0.009455744761728892, "train/policy_logprob_mean": -0.5209043950495058, "train/policy_logprob_min": -7.438383342575853, "train/policy_logprob_std": 1.0596095023364047, "train/policy_randomness_mag": 0.8525577670466291, "train/policy_randomness_max": 0.8525577670466291, "train/policy_randomness_mean": 0.18392495397668684, "train/policy_randomness_min": 0.02801597898785215, "train/policy_randomness_std": 0.19213730270845175, "train/post_ent_mag": 59.04493718947808, "train/post_ent_max": 59.04493718947808, "train/post_ent_mean": 40.40571449446852, "train/post_ent_min": 21.36308373499961, "train/post_ent_std": 7.1780371213481375, "train/prior_ent_mag": 67.81899345008127, "train/prior_ent_max": 67.81899345008127, "train/prior_ent_mean": 55.542824042104456, "train/prior_ent_min": 35.749017729376355, "train/prior_ent_std": 5.107151362147644, "train/rep_loss_mean": 15.078433057687578, "train/rep_loss_std": 9.075675435309863, "train/reward_avg": 0.02421376009872795, "train/reward_loss_mean": 0.055888954495644044, "train/reward_loss_std": 0.2590191526352054, "train/reward_max_data": 1.010218980538584, "train/reward_max_pred": 1.005983829498291, "train/reward_neg_acc": 0.9927154366117324, "train/reward_neg_loss": 0.03111097734611835, "train/reward_pos_acc": 0.9637687145358454, "train/reward_pos_loss": 0.8842337262021364, "train/reward_pred": 0.023403527221921152, "train/reward_rate": 0.02909015739051095, "train_stats/sum_log_reward": 6.197345121244414, "train_stats/max_log_achievement_collect_drink": 3.672566371681416, "train_stats/max_log_achievement_collect_sapling": 3.150442477876106, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 8.876106194690266, "train_stats/max_log_achievement_defeat_skeleton": 0.017699115044247787, "train_stats/max_log_achievement_defeat_zombie": 0.7964601769911505, "train_stats/max_log_achievement_eat_cow": 0.1592920353982301, "train_stats/max_log_achievement_make_wood_pickaxe": 0.017699115044247787, "train_stats/max_log_achievement_make_wood_sword": 1.1150442477876106, "train_stats/max_log_achievement_place_plant": 3.0265486725663715, "train_stats/max_log_achievement_place_table": 2.309734513274336, "train_stats/max_log_achievement_wake_up": 1.2566371681415929, "train_stats/mean_log_entropy": 0.48302560042491, "eval_stats/sum_log_reward": 5.7249999195337296, "eval_stats/max_log_achievement_collect_drink": 2.875, "eval_stats/max_log_achievement_collect_sapling": 3.3125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.8125, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_plant": 3.3125, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.0622299669194035e-05, "report/cont_loss_std": 0.00024323361867573112, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0025570339057594538, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.363712259371823e-07, "report/cont_pred": 0.9961031675338745, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.650395393371582, "report/dyn_loss_std": 9.363666534423828, "report/image_loss_mean": 7.839746475219727, "report/image_loss_std": 12.089868545532227, "report/model_loss_mean": 16.675979614257812, "report/model_loss_std": 15.97270679473877, "report/post_ent_mag": 57.115478515625, "report/post_ent_max": 57.115478515625, "report/post_ent_mean": 39.624420166015625, "report/post_ent_min": 20.780994415283203, "report/post_ent_std": 6.69242525100708, "report/prior_ent_mag": 68.18896484375, "report/prior_ent_max": 68.18896484375, "report/prior_ent_mean": 54.99589538574219, "report/prior_ent_min": 37.474090576171875, "report/prior_ent_std": 4.849094390869141, "report/rep_loss_mean": 14.650395393371582, "report/rep_loss_std": 9.363666534423828, "report/reward_avg": 0.02646484225988388, "report/reward_loss_mean": 0.045985765755176544, "report/reward_loss_std": 0.20182588696479797, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0083403587341309, "report/reward_neg_acc": 0.9919517040252686, "report/reward_neg_loss": 0.023861711844801903, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.7790294885635376, "report/reward_pred": 0.027132820338010788, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 5.03582941746572e-06, "eval/cont_loss_std": 0.0001306825433857739, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0012403401779010892, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.9149919694427808e-07, "eval/cont_pred": 0.9960984587669373, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.029510498046875, "eval/dyn_loss_std": 9.465004920959473, "eval/image_loss_mean": 20.76964569091797, "eval/image_loss_std": 22.417179107666016, "eval/model_loss_mean": 31.660537719726562, "eval/model_loss_std": 25.304595947265625, "eval/post_ent_mag": 59.23177719116211, "eval/post_ent_max": 59.23177719116211, "eval/post_ent_mean": 41.3227653503418, "eval/post_ent_min": 19.16415023803711, "eval/post_ent_std": 7.304439544677734, "eval/prior_ent_mag": 68.18896484375, "eval/prior_ent_max": 68.18896484375, "eval/prior_ent_mean": 56.262306213378906, "eval/prior_ent_min": 37.079463958740234, "eval/prior_ent_std": 5.3099846839904785, "eval/rep_loss_mean": 18.029510498046875, "eval/rep_loss_std": 9.465004920959473, "eval/reward_avg": 0.01152343675494194, "eval/reward_loss_mean": 0.07318124175071716, "eval/reward_loss_std": 0.5556825995445251, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002089500427246, "eval/reward_neg_acc": 0.9940416812896729, "eval/reward_neg_loss": 0.03754933178424835, "eval/reward_pos_acc": 0.7647058963775635, "eval/reward_pos_loss": 2.183847665786743, "eval/reward_pred": 0.0093145240098238, "eval/reward_rate": 0.0166015625, "replay/size": 325905.0, "replay/inserts": 21840.0, "replay/samples": 21840.0, "replay/insert_wait_avg": 1.367369850913247e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.706972275898134e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 64640.0, "eval_replay/inserts": 3648.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2848330171484696e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2180829048157, "timer/env.step_count": 2730.0, "timer/env.step_total": 261.33508467674255, "timer/env.step_frac": 0.2612781043887727, "timer/env.step_avg": 0.09572713724422804, "timer/env.step_min": 0.021963119506835938, "timer/env.step_max": 3.3191514015197754, "timer/replay._sample_count": 21840.0, "timer/replay._sample_total": 11.493124723434448, "timer/replay._sample_frac": 0.011490618815904945, "timer/replay._sample_avg": 0.0005262419745162293, "timer/replay._sample_min": 0.0004055500030517578, "timer/replay._sample_max": 0.0316767692565918, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3186.0, "timer/agent.policy_total": 50.9146523475647, "timer/agent.policy_frac": 0.05090355115326376, "timer/agent.policy_avg": 0.015980744616310327, "timer/agent.policy_min": 0.009318113327026367, "timer/agent.policy_max": 0.09013605117797852, "timer/dataset_train_count": 1365.0, "timer/dataset_train_total": 0.1454761028289795, "timer/dataset_train_frac": 0.0001454443838952505, "timer/dataset_train_avg": 0.00010657589950840988, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0002486705780029297, "timer/agent.train_count": 1365.0, "timer/agent.train_total": 613.1662015914917, "timer/agent.train_frac": 0.6130325096810341, "timer/agent.train_avg": 0.4492060084919353, "timer/agent.train_min": 0.43449950218200684, "timer/agent.train_max": 1.5112202167510986, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4717419147491455, "timer/agent.report_frac": 0.00047163905833327966, "timer/agent.report_avg": 0.23587095737457275, "timer/agent.report_min": 0.22787022590637207, "timer/agent.report_max": 0.24387168884277344, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8842358046064642e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 21.834949474751394}
{"step": 326560, "time": 15349.088600635529, "episode/length": 162.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 326608, "time": 15352.290236711502, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 327320, "time": 15377.212506532669, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 327584, "time": 15387.65631532669, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 327648, "time": 15391.380903959274, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 327720, "time": 15396.422696113586, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 328000, "time": 15407.497567892075, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 328120, "time": 15412.75162410736, "episode/length": 235.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 328152, "time": 15415.348562717438, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 328592, "time": 15431.737425327301, "episode/length": 158.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 328752, "time": 15438.450893640518, "episode/length": 267.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 328928, "time": 15445.88585805893, "episode/length": 41.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 329192, "time": 15455.994708299637, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 329360, "time": 15464.418750047684, "episode/length": 154.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 329536, "time": 15471.778145313263, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 329576, "time": 15474.439626693726, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 329600, "time": 15477.128907203674, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 330000, "time": 15492.662287473679, "episode/length": 301.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 15517.841400623322, "eval_episode/length": 157.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 330096, "time": 15520.149402856827, "eval_episode/length": 175.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 330096, "time": 15522.230690717697, "eval_episode/length": 187.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 330096, "time": 15523.831413984299, "eval_episode/length": 190.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 330096, "time": 15525.579490661621, "eval_episode/length": 193.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 330096, "time": 15528.250878572464, "eval_episode/length": 221.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 330096, "time": 15530.806647062302, "eval_episode/length": 247.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9758064516129032}
{"step": 330096, "time": 15533.979162931442, "eval_episode/length": 67.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9852941176470589}
{"step": 330584, "time": 15549.910366296768, "episode/length": 228.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9868995633187773, "episode/intrinsic_return": 0.0}
{"step": 330688, "time": 15555.064153432846, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 330808, "time": 15560.418632745743, "episode/length": 234.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 330880, "time": 15564.4870595932, "episode/length": 162.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 331008, "time": 15570.341078519821, "episode/length": 39.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 331088, "time": 15574.670199871063, "episode/length": 236.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 331120, "time": 15577.330548763275, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 331872, "time": 15604.207588672638, "episode/length": 233.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 331880, "time": 15605.720294475555, "episode/length": 284.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 332064, "time": 15613.52357006073, "episode/length": 156.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 332296, "time": 15622.48295712471, "episode/length": 160.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 332400, "time": 15627.815189361572, "episode/length": 226.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.986784140969163, "episode/intrinsic_return": 0.0}
{"step": 332464, "time": 15631.48641371727, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 332560, "time": 15636.161549568176, "episode/length": 179.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 332568, "time": 15637.740998506546, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 332888, "time": 15649.834579706192, "episode/length": 40.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 333064, "time": 15657.160380601883, "episode/length": 61.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 333296, "time": 15666.733526229858, "episode/length": 176.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 333552, "time": 15676.85047197342, "episode/length": 209.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 333608, "time": 15680.102759838104, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 333704, "time": 15684.832990169525, "episode/length": 175.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 333976, "time": 15695.81694149971, "episode/length": 33.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 334216, "time": 15706.198082447052, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 334392, "time": 15714.249353647232, "episode/length": 51.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 334512, "time": 15720.198104381561, "episode/length": 36.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 334520, "time": 15721.727774620056, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 334672, "time": 15728.550681352615, "episode/length": 222.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 334984, "time": 15740.137212514877, "episode/length": 210.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.985781990521327, "episode/intrinsic_return": 0.0}
{"step": 335304, "time": 15752.287898540497, "episode/length": 211.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 335320, "time": 15754.37280702591, "episode/length": 364.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945205479452055, "episode/intrinsic_return": 0.0}
{"step": 335624, "time": 15765.868507146835, "episode/length": 258.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 335952, "time": 15779.976261138916, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 336208, "time": 15790.049463748932, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 336216, "time": 15791.685972690582, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 336376, "time": 15798.41728591919, "episode/length": 231.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 336496, "time": 15804.121536493301, "episode/length": 188.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 336768, "time": 15814.71859884262, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 337040, "time": 15825.219317913055, "episode/length": 67.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9558823529411765, "episode/intrinsic_return": 0.0}
{"step": 337184, "time": 15831.495238304138, "episode/length": 232.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 337296, "time": 15836.855229139328, "episode/length": 208.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 337416, "time": 15842.605776071548, "episode/length": 150.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 337448, "time": 15845.777961969376, "episode/length": 153.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 337560, "time": 15851.413779258728, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 338120, "time": 15871.940613269806, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 338440, "time": 15884.023491382599, "episode/length": 39.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 338576, "time": 15890.260100364685, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 338776, "time": 15898.219447851181, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 338848, "time": 15902.4007999897, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 338928, "time": 15906.492986679077, "episode/length": 318.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 339088, "time": 15913.27862739563, "episode/length": 208.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 339120, "time": 15916.047081232071, "episode/length": 33.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 339216, "time": 15920.797389268875, "episode/length": 271.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 339232, "time": 15922.908447265625, "episode/length": 241.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 339904, "time": 15946.590008974075, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 15972.551142930984, "eval_episode/length": 142.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.958041958041958}
{"step": 340080, "time": 15974.649951457977, "eval_episode/length": 154.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 340080, "time": 15976.416893720627, "eval_episode/length": 158.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 340080, "time": 15978.002277374268, "eval_episode/length": 160.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 340080, "time": 15979.670776844025, "eval_episode/length": 163.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 340080, "time": 15981.736514091492, "eval_episode/length": 177.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 340080, "time": 15984.42179608345, "eval_episode/length": 208.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 340080, "time": 15986.423349618912, "eval_episode/length": 215.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 340088, "time": 15986.474248409271, "episode/length": 205.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 340272, "time": 15994.298635482788, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 340408, "time": 16000.11217546463, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 340488, "time": 16004.29938697815, "episode/length": 170.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 340616, "time": 16010.004879713058, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 341152, "time": 16029.900918722153, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 341424, "time": 16040.40924835205, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 341488, "time": 16044.072049856186, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 341544, "time": 16047.251175642014, "episode/length": 131.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 341696, "time": 16053.924057483673, "episode/length": 33.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8823529411764706, "episode/intrinsic_return": 0.0}
{"step": 341736, "time": 16056.570793151855, "episode/length": 369.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9891891891891892, "episode/intrinsic_return": 0.0}
{"step": 341848, "time": 16061.75756573677, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 341976, "time": 16067.570372104645, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 342240, "time": 16078.23612833023, "episode/length": 135.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 342304, "time": 16082.458124637604, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 342920, "time": 16104.620035409927, "episode/length": 152.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 343168, "time": 16114.710857391357, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 343312, "time": 16120.960861206055, "episode/length": 220.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9683257918552036, "episode/intrinsic_return": 0.0}
{"step": 343360, "time": 16124.143741369247, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 343496, "time": 16129.978306055069, "episode/length": 40.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 343520, "time": 16132.564700841904, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 343768, "time": 16142.193746805191, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 343800, "time": 16144.812789201736, "episode/length": 243.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 343856, "time": 16148.553872585297, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 344160, "time": 16161.472320318222, "episode/length": 79.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 344368, "time": 16169.944239616394, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 344424, "time": 16173.0125041008, "episode/length": 132.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 344472, "time": 16176.130615234375, "episode/length": 87.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9431818181818182, "episode/intrinsic_return": 0.0}
{"step": 345032, "time": 16196.191613197327, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 345048, "time": 16198.479182004929, "episode/length": 155.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 345136, "time": 16203.700518369675, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 345536, "time": 16218.983845949173, "episode/length": 209.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 345592, "time": 16222.177546262741, "episode/length": 56.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 345696, "time": 16227.372515678406, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 345736, "time": 16230.177725791931, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 345928, "time": 16238.096371650696, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 345952, "time": 16240.662804365158, "episode/length": 44.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 346096, "time": 16247.02188372612, "episode/length": 130.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 346104, "time": 16248.745527267456, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 346976, "time": 16279.444128513336, "episode/length": 127.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.953125, "episode/intrinsic_return": 0.0}
{"step": 347040, "time": 16283.115323066711, "episode/length": 187.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 347176, "time": 16289.010375738144, "episode/length": 267.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 347448, "time": 16299.575109004974, "episode/length": 213.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 347560, "time": 16304.821886062622, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 347600, "time": 16307.838861942291, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 347616, "time": 16309.83342218399, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 347800, "time": 16317.394257068634, "episode/length": 262.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 348537, "time": 16344.172976493835, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.309210293534873, "train/action_min": 0.0, "train/action_std": 3.3358448190965513, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045981080338790795, "train/actor_opt_grad_steps": 20995.0, "train/actor_opt_loss": -1.3966831994661386, "train/adv_mag": 0.6182177317315254, "train/adv_max": 0.5796721067981444, "train/adv_mean": 0.004271487830656174, "train/adv_min": -0.486354639996653, "train/adv_std": 0.06809536435141944, "train/cont_avg": 0.9944590692934783, "train/cont_loss_mean": 0.00036573125614343854, "train/cont_loss_std": 0.010727861957647016, "train/cont_neg_acc": 0.9872038204600846, "train/cont_neg_loss": 0.03958028438021269, "train/cont_pos_acc": 0.9999501480572466, "train/cont_pos_loss": 0.0001318714479705777, "train/cont_pred": 0.9944828118103138, "train/cont_rate": 0.9944590692934783, "train/dyn_loss_mean": 15.139000084089195, "train/dyn_loss_std": 9.0533088946688, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9143224483814792, "train/extr_critic_critic_opt_grad_steps": 20995.0, "train/extr_critic_critic_opt_loss": 16448.916178385418, "train/extr_critic_mag": 5.671657258185787, "train/extr_critic_max": 5.671657258185787, "train/extr_critic_mean": 1.365920081950616, "train/extr_critic_min": -0.23998909843140753, "train/extr_critic_std": 1.35052541287049, "train/extr_return_normed_mag": 1.67583562930425, "train/extr_return_normed_max": 1.67583562930425, "train/extr_return_normed_mean": 0.3514267834632293, "train/extr_return_normed_min": -0.12119673035930896, "train/extr_return_normed_std": 0.3318968593426373, "train/extr_return_rate": 0.6345835567816444, "train/extr_return_raw_mag": 6.910812460857889, "train/extr_return_raw_max": 6.910812460857889, "train/extr_return_raw_mean": 1.3837175278559974, "train/extr_return_raw_min": -0.5887885467297789, "train/extr_return_raw_std": 1.3853373190631038, "train/extr_reward_mag": 1.0137653005295906, "train/extr_reward_max": 1.0137653005295906, "train/extr_reward_mean": 0.030893254782194676, "train/extr_reward_min": -0.3654169103373652, "train/extr_reward_std": 0.16506299155129903, "train/image_loss_mean": 7.910053508869116, "train/image_loss_std": 11.816184434337892, "train/model_loss_mean": 17.04915667962337, "train/model_loss_std": 15.481622695922852, "train/model_opt_grad_norm": 60.43134683802508, "train/model_opt_grad_steps": 20972.630434782608, "train/model_opt_loss": 10745.068960880888, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 629.5289855072464, "train/policy_entropy_mag": 2.4020448283872744, "train/policy_entropy_max": 2.4020448283872744, "train/policy_entropy_mean": 0.519871453444163, "train/policy_entropy_min": 0.07937520326695581, "train/policy_entropy_std": 0.5433108007562333, "train/policy_logprob_mag": 7.438383295916129, "train/policy_logprob_max": -0.009455717560173809, "train/policy_logprob_mean": -0.520714921147927, "train/policy_logprob_min": -7.438383295916129, "train/policy_logprob_std": 1.063326737155085, "train/policy_randomness_mag": 0.8478164141592772, "train/policy_randomness_max": 0.8478164141592772, "train/policy_randomness_mean": 0.18349180953658145, "train/policy_randomness_min": 0.028015963544232258, "train/policy_randomness_std": 0.19176487041556317, "train/post_ent_mag": 59.026383745497554, "train/post_ent_max": 59.026383745497554, "train/post_ent_mean": 40.48946513300357, "train/post_ent_min": 21.22857193324877, "train/post_ent_std": 7.181540820909583, "train/prior_ent_mag": 67.96275876915973, "train/prior_ent_max": 67.96275876915973, "train/prior_ent_mean": 55.65985618812451, "train/prior_ent_min": 36.86043787693632, "train/prior_ent_std": 4.9599173794622, "train/rep_loss_mean": 15.139000084089195, "train/rep_loss_std": 9.0533088946688, "train/reward_avg": 0.02448270473278303, "train/reward_loss_mean": 0.055337532882349216, "train/reward_loss_std": 0.2526111833859181, "train/reward_max_data": 1.01449275707853, "train/reward_max_pred": 1.0089226071385369, "train/reward_neg_acc": 0.9931885237279146, "train/reward_neg_loss": 0.031088874540359215, "train/reward_pos_acc": 0.9659937684950621, "train/reward_pos_loss": 0.8582124351591304, "train/reward_pred": 0.02385351906085144, "train/reward_rate": 0.029480865036231884, "train_stats/sum_log_reward": 6.024369717646046, "train_stats/max_log_achievement_collect_drink": 3.092436974789916, "train_stats/max_log_achievement_collect_sapling": 2.7142857142857144, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 9.210084033613445, "train_stats/max_log_achievement_defeat_skeleton": 0.008403361344537815, "train_stats/max_log_achievement_defeat_zombie": 0.7563025210084033, "train_stats/max_log_achievement_eat_cow": 0.1092436974789916, "train_stats/max_log_achievement_make_wood_pickaxe": 0.03361344537815126, "train_stats/max_log_achievement_make_wood_sword": 1.3697478991596639, "train_stats/max_log_achievement_place_plant": 2.630252100840336, "train_stats/max_log_achievement_place_table": 2.3361344537815127, "train_stats/max_log_achievement_wake_up": 1.1680672268907564, "train_stats/mean_log_entropy": 0.4841425485220276, "eval_stats/sum_log_reward": 6.287499934434891, "eval_stats/max_log_achievement_collect_drink": 2.9375, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 9.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.4375, "eval_stats/max_log_achievement_place_plant": 2.3125, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.463868051767349e-05, "report/cont_loss_std": 0.0008981734863482416, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006768724415451288, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.14873868774157e-05, "report/cont_pred": 0.9950896501541138, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.247856140136719, "report/dyn_loss_std": 9.199378967285156, "report/image_loss_mean": 7.414746284484863, "report/image_loss_std": 10.994499206542969, "report/model_loss_mean": 16.01988983154297, "report/model_loss_std": 14.606547355651855, "report/post_ent_mag": 60.85834884643555, "report/post_ent_max": 60.85834884643555, "report/post_ent_mean": 42.81993865966797, "report/post_ent_min": 20.630340576171875, "report/post_ent_std": 8.380880355834961, "report/prior_ent_mag": 68.53417205810547, "report/prior_ent_max": 68.53417205810547, "report/prior_ent_mean": 57.05372619628906, "report/prior_ent_min": 35.769500732421875, "report/prior_ent_std": 5.808436870574951, "report/rep_loss_mean": 14.247856140136719, "report/rep_loss_std": 9.199378967285156, "report/reward_avg": 0.02021484449505806, "report/reward_loss_mean": 0.056396715342998505, "report/reward_loss_std": 0.28030985593795776, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023224353790283, "report/reward_neg_acc": 0.9939939975738525, "report/reward_neg_loss": 0.035425424575805664, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.8944092988967896, "report/reward_pred": 0.017786525189876556, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.851034176070243e-05, "eval/cont_loss_std": 0.0005375574110075831, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004550119861960411, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.393235250674479e-07, "eval/cont_pred": 0.9961107969284058, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 20.284648895263672, "eval/dyn_loss_std": 10.749136924743652, "eval/image_loss_mean": 15.406240463256836, "eval/image_loss_std": 17.478635787963867, "eval/model_loss_mean": 27.659292221069336, "eval/model_loss_std": 22.119192123413086, "eval/post_ent_mag": 57.243751525878906, "eval/post_ent_max": 57.243751525878906, "eval/post_ent_mean": 39.50884246826172, "eval/post_ent_min": 22.561016082763672, "eval/post_ent_std": 6.802389621734619, "eval/prior_ent_mag": 68.53417205810547, "eval/prior_ent_max": 68.53417205810547, "eval/prior_ent_mean": 56.28443908691406, "eval/prior_ent_min": 39.0732307434082, "eval/prior_ent_std": 4.553790092468262, "eval/rep_loss_mean": 20.284648895263672, "eval/rep_loss_std": 10.749136924743652, "eval/reward_avg": 0.01484375074505806, "eval/reward_loss_mean": 0.08224499225616455, "eval/reward_loss_std": 0.6024565696716309, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012123584747314, "eval/reward_neg_acc": 0.9940239191055298, "eval/reward_neg_loss": 0.041149720549583435, "eval/reward_pos_acc": 0.800000011920929, "eval/reward_pos_loss": 2.1452279090881348, "eval/reward_pred": 0.014013800770044327, "eval/reward_rate": 0.01953125, "replay/size": 348033.0, "replay/inserts": 22128.0, "replay/samples": 22128.0, "replay/insert_wait_avg": 1.3590548578070628e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.658296546467128e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 68688.0, "eval_replay/inserts": 4048.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.205286018462049e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0940773487091, "timer/env.step_count": 2766.0, "timer/env.step_total": 262.27271485328674, "timer/env.step_frac": 0.26224804325267337, "timer/env.step_avg": 0.09482021505903353, "timer/env.step_min": 0.022321224212646484, "timer/env.step_max": 2.1837306022644043, "timer/replay._sample_count": 22128.0, "timer/replay._sample_total": 11.559858083724976, "timer/replay._sample_frac": 0.011558770665226455, "timer/replay._sample_avg": 0.0005224086263433196, "timer/replay._sample_min": 0.00036525726318359375, "timer/replay._sample_max": 0.015850067138671875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3272.0, "timer/agent.policy_total": 53.11849617958069, "timer/agent.policy_frac": 0.05311349940237625, "timer/agent.policy_avg": 0.01623425922358823, "timer/agent.policy_min": 0.009282588958740234, "timer/agent.policy_max": 0.21255993843078613, "timer/dataset_train_count": 1383.0, "timer/dataset_train_total": 0.1443309783935547, "timer/dataset_train_frac": 0.00014431740139505885, "timer/dataset_train_avg": 0.00010436079421081323, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.00033926963806152344, "timer/agent.train_count": 1383.0, "timer/agent.train_total": 619.8925144672394, "timer/agent.train_frac": 0.6198342021088658, "timer/agent.train_avg": 0.4482230762597537, "timer/agent.train_min": 0.43208932876586914, "timer/agent.train_max": 1.4939591884613037, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.472531795501709, "timer/agent.report_frac": 0.0004724873451449791, "timer/agent.report_avg": 0.2362658977508545, "timer/agent.report_min": 0.2304224967956543, "timer/agent.report_max": 0.2421092987060547, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9322726625114374e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 22.125633936771386}
{"step": 348592, "time": 16346.056542158127, "episode/length": 201.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 348600, "time": 16347.66337299347, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 349104, "time": 16366.041645050049, "episode/length": 187.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 349128, "time": 16368.12677693367, "episode/length": 195.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 349248, "time": 16373.758409261703, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 349272, "time": 16375.991429328918, "episode/length": 206.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 349288, "time": 16378.320068359375, "episode/length": 229.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 349304, "time": 16380.433012008667, "episode/length": 265.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 350048, "time": 16406.740253448486, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 16422.953731298447, "eval_episode/length": 35.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 350064, "time": 16428.496689081192, "eval_episode/length": 141.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.971830985915493}
{"step": 350064, "time": 16431.116038560867, "eval_episode/length": 168.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 350064, "time": 16433.21632885933, "eval_episode/length": 184.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 350064, "time": 16435.490179777145, "eval_episode/length": 198.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 350064, "time": 16437.581072330475, "eval_episode/length": 173.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 350064, "time": 16439.766288995743, "eval_episode/length": 223.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 350064, "time": 16441.984320878983, "eval_episode/length": 240.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.995850622406639}
{"step": 350304, "time": 16450.098898887634, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 350472, "time": 16457.671660661697, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 350584, "time": 16462.87880754471, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 350624, "time": 16466.0304915905, "episode/length": 166.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 350672, "time": 16469.41272330284, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 350712, "time": 16472.1496052742, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 350776, "time": 16475.739107131958, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 351904, "time": 16515.12150502205, "episode/length": 231.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 352008, "time": 16519.913642406464, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 352048, "time": 16522.960569620132, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 352264, "time": 16531.806965351105, "episode/length": 223.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 352304, "time": 16536.31807899475, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 352560, "time": 16546.212857961655, "episode/length": 281.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 352624, "time": 16549.82124042511, "episode/length": 243.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 352992, "time": 16563.653873443604, "episode/length": 284.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 353352, "time": 16576.787036418915, "episode/length": 44.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 353368, "time": 16578.831161499023, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 353560, "time": 16586.839897871017, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 353664, "time": 16592.096630573273, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 353680, "time": 16594.05881214142, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 353784, "time": 16598.802282571793, "episode/length": 144.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 353880, "time": 16603.542184352875, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 354016, "time": 16609.972558259964, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 354120, "time": 16614.746634960175, "episode/length": 41.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 354616, "time": 16633.123787164688, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 354744, "time": 16639.551132917404, "episode/length": 147.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 354784, "time": 16643.06066417694, "episode/length": 137.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 354976, "time": 16651.7946434021, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 355096, "time": 16657.837102890015, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 355248, "time": 16665.259333372116, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 355472, "time": 16674.860445261, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 355624, "time": 16681.971610307693, "episode/length": 18.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.8947368421052632, "episode/intrinsic_return": 0.0}
{"step": 355984, "time": 16696.32948255539, "episode/length": 154.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 356176, "time": 16704.167079925537, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 356328, "time": 16710.548046827316, "episode/length": 153.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 356424, "time": 16715.23434996605, "episode/length": 300.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9867109634551495, "episode/intrinsic_return": 0.0}
{"step": 356472, "time": 16718.22354722023, "episode/length": 36.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 356544, "time": 16722.298989772797, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 356960, "time": 16737.64500808716, "episode/length": 271.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 357016, "time": 16740.730617761612, "episode/length": 173.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 357608, "time": 16761.743837356567, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 357656, "time": 16764.900893449783, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 357864, "time": 16773.5156519413, "episode/length": 191.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 358280, "time": 16788.531336784363, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 358288, "time": 16790.528531312943, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9518072289156626, "episode/intrinsic_return": 0.0}
{"step": 358488, "time": 16798.437220335007, "episode/length": 251.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 358528, "time": 16801.580273866653, "episode/length": 409.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9902439024390244, "episode/intrinsic_return": 0.0}
{"step": 358632, "time": 16806.368756771088, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 359112, "time": 16823.645529270172, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 359256, "time": 16830.03577899933, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 359344, "time": 16834.71997642517, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 359696, "time": 16847.858916044235, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 359936, "time": 16857.5638794899, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 16881.329741477966, "eval_episode/length": 33.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 360048, "time": 16883.554679632187, "eval_episode/length": 37.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 360048, "time": 16893.34330010414, "eval_episode/length": 204.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9707317073170731}
{"step": 360048, "time": 16895.478529691696, "eval_episode/length": 208.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 360048, "time": 16897.855736494064, "eval_episode/length": 178.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 360048, "time": 16897.86440229416, "eval_episode/length": 182.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 360048, "time": 16902.536804437637, "eval_episode/length": 227.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9780701754385965}
{"step": 360048, "time": 16905.040254831314, "eval_episode/length": 238.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9790794979079498}
{"step": 360296, "time": 16913.298017024994, "episode/length": 220.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9638009049773756, "episode/intrinsic_return": 0.0}
{"step": 360416, "time": 16919.85372209549, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 360768, "time": 16935.27300095558, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 360872, "time": 16940.69462800026, "episode/length": 190.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 361208, "time": 16954.14987897873, "episode/length": 243.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9877049180327869, "episode/intrinsic_return": 0.0}
{"step": 361224, "time": 16956.639759778976, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 361792, "time": 16977.459400892258, "episode/length": 412.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9975786924939467, "episode/intrinsic_return": 0.0}
{"step": 361824, "time": 16980.0581073761, "episode/length": 235.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 361880, "time": 16983.240177869797, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 362048, "time": 16990.60230064392, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 362392, "time": 17003.251834392548, "episode/length": 202.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9852216748768473, "episode/intrinsic_return": 0.0}
{"step": 362568, "time": 17010.676512002945, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 362928, "time": 17024.2767868042, "episode/length": 256.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 363192, "time": 17034.20180273056, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 363440, "time": 17044.191947221756, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 363496, "time": 17047.311167240143, "episode/length": 285.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 364016, "time": 17066.568164348602, "episode/length": 277.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 364032, "time": 17068.520643234253, "episode/length": 247.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 364264, "time": 17077.553050518036, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 364464, "time": 17086.59517288208, "episode/length": 258.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 364472, "time": 17088.658628940582, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 364824, "time": 17102.396536827087, "episode/length": 172.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 364888, "time": 17106.046827554703, "episode/length": 211.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 364984, "time": 17110.756808519363, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 365256, "time": 17121.198705911636, "episode/length": 152.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 365648, "time": 17135.933619976044, "episode/length": 172.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 365896, "time": 17145.406371593475, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 365968, "time": 17149.560725927353, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 366088, "time": 17155.00994825363, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 366184, "time": 17160.34304046631, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 366504, "time": 17172.827862262726, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 366776, "time": 17183.235624074936, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 367032, "time": 17193.47684264183, "episode/length": 255.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 367072, "time": 17197.11703801155, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 367440, "time": 17210.641936302185, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 367576, "time": 17216.58256793022, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 367640, "time": 17220.186945676804, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 367672, "time": 17222.81524658203, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 367720, "time": 17225.900546073914, "episode/length": 34.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 368024, "time": 17237.371269464493, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 368184, "time": 17244.213226795197, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 368344, "time": 17251.013898849487, "episode/length": 163.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 369056, "time": 17277.657888174057, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 369280, "time": 17286.72790622711, "episode/length": 275.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746376811594203, "episode/intrinsic_return": 0.0}
{"step": 369352, "time": 17290.402546167374, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 369360, "time": 17292.40820121765, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 369544, "time": 17299.81363749504, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 369568, "time": 17302.37143421173, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 369696, "time": 17308.11019229889, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 369904, "time": 17316.496970415115, "episode/length": 194.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 17343.607349157333, "eval_episode/length": 173.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 370032, "time": 17345.533653736115, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 370032, "time": 17347.085334539413, "eval_episode/length": 183.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 370032, "time": 17348.99488735199, "eval_episode/length": 193.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9690721649484536}
{"step": 370032, "time": 17350.621930122375, "eval_episode/length": 197.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 370032, "time": 17352.69049692154, "eval_episode/length": 211.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 370032, "time": 17354.35130572319, "eval_episode/length": 213.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 370032, "time": 17358.47037267685, "eval_episode/length": 64.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 370033, "time": 17359.03758430481, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.274367947048611, "train/action_min": 0.0, "train/action_std": 3.2346354025381583, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04473843476562588, "train/actor_opt_grad_steps": 22360.0, "train/actor_opt_loss": -5.5470336851146484, "train/adv_mag": 0.6104309013596287, "train/adv_max": 0.5732844867088177, "train/adv_mean": 0.0033772216200035204, "train/adv_min": -0.4797322962019179, "train/adv_std": 0.06611070508758227, "train/cont_avg": 0.9946614583333333, "train/cont_loss_mean": 0.00028393849998335725, "train/cont_loss_std": 0.008565606730098808, "train/cont_neg_acc": 0.9872839517063565, "train/cont_neg_loss": 0.030540728213236435, "train/cont_pos_acc": 0.9999489978507713, "train/cont_pos_loss": 0.0001427016115245452, "train/cont_pred": 0.9946387551448963, "train/cont_rate": 0.9946614583333333, "train/dyn_loss_mean": 14.797209329958315, "train/dyn_loss_std": 9.005949910481771, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9083587818675571, "train/extr_critic_critic_opt_grad_steps": 22360.0, "train/extr_critic_critic_opt_loss": 16402.40002170139, "train/extr_critic_mag": 5.766326144889549, "train/extr_critic_max": 5.766326144889549, "train/extr_critic_mean": 1.3703631816086945, "train/extr_critic_min": -0.26411029586085566, "train/extr_critic_std": 1.3637782759136623, "train/extr_return_normed_mag": 1.6507025912955955, "train/extr_return_normed_max": 1.6507025912955955, "train/extr_return_normed_mean": 0.3458629536407965, "train/extr_return_normed_min": -0.11801228352166988, "train/extr_return_normed_std": 0.326378352995272, "train/extr_return_rate": 0.6299383030997382, "train/extr_return_raw_mag": 6.974826431274414, "train/extr_return_raw_max": 6.974826431274414, "train/extr_return_raw_mean": 1.3848388742517541, "train/extr_return_raw_min": -0.6023140092690785, "train/extr_return_raw_std": 1.398292190940292, "train/extr_reward_mag": 1.0108503376996076, "train/extr_reward_max": 1.0108503376996076, "train/extr_reward_mean": 0.030732586710817283, "train/extr_reward_min": -0.36253466341230606, "train/extr_reward_std": 0.1645888939499855, "train/image_loss_mean": 7.523691654205322, "train/image_loss_std": 11.2028327871252, "train/model_loss_mean": 16.458025035151728, "train/model_loss_std": 14.834326383802626, "train/model_opt_grad_norm": 64.06592393098055, "train/model_opt_grad_steps": 22337.0, "train/model_opt_loss": 16785.36296657986, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1023.1481481481482, "train/policy_entropy_mag": 2.432845613691542, "train/policy_entropy_max": 2.432845613691542, "train/policy_entropy_mean": 0.5212915091602891, "train/policy_entropy_min": 0.07937518358230591, "train/policy_entropy_std": 0.5452857796792631, "train/policy_logprob_mag": 7.438383416776304, "train/policy_logprob_max": -0.009455742549013208, "train/policy_logprob_mean": -0.5215626341325266, "train/policy_logprob_min": -7.438383416776304, "train/policy_logprob_std": 1.0736836808699148, "train/policy_randomness_mag": 0.8586877399020725, "train/policy_randomness_max": 0.8586877399020725, "train/policy_randomness_mean": 0.18399302749722093, "train/policy_randomness_min": 0.028015956530968347, "train/policy_randomness_std": 0.1924619526774795, "train/post_ent_mag": 59.12775881731952, "train/post_ent_max": 59.12775881731952, "train/post_ent_mean": 40.91001137627496, "train/post_ent_min": 21.18977647004304, "train/post_ent_std": 7.244493258440936, "train/prior_ent_mag": 68.07184860794632, "train/prior_ent_max": 68.07184860794632, "train/prior_ent_mean": 55.766425719084566, "train/prior_ent_min": 37.129558365433304, "train/prior_ent_std": 4.880775236200403, "train/rep_loss_mean": 14.797209329958315, "train/rep_loss_std": 9.005949910481771, "train/reward_avg": 0.023880931590166358, "train/reward_loss_mean": 0.0557238375975026, "train/reward_loss_std": 0.2585240851949762, "train/reward_max_data": 1.0096296319255122, "train/reward_max_pred": 1.0058685249752468, "train/reward_neg_acc": 0.9927024563153585, "train/reward_neg_loss": 0.031296634170468206, "train/reward_pos_acc": 0.9595903970577099, "train/reward_pos_loss": 0.8884235541025798, "train/reward_pred": 0.023349146624268204, "train/reward_rate": 0.028812210648148148, "train_stats/sum_log_reward": 6.40357140983854, "train_stats/max_log_achievement_collect_drink": 3.732142857142857, "train_stats/max_log_achievement_collect_sapling": 3.169642857142857, "train_stats/max_log_achievement_collect_stone": 0.017857142857142856, "train_stats/max_log_achievement_collect_wood": 10.392857142857142, "train_stats/max_log_achievement_defeat_skeleton": 0.008928571428571428, "train_stats/max_log_achievement_defeat_zombie": 0.9821428571428571, "train_stats/max_log_achievement_eat_cow": 0.17857142857142858, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05357142857142857, "train_stats/max_log_achievement_make_wood_sword": 1.5357142857142858, "train_stats/max_log_achievement_place_plant": 3.0982142857142856, "train_stats/max_log_achievement_place_table": 2.7589285714285716, "train_stats/max_log_achievement_wake_up": 1.1875, "train_stats/mean_log_entropy": 0.5003558200384889, "eval_stats/sum_log_reward": 6.016666675607364, "eval_stats/max_log_achievement_collect_drink": 2.25, "eval_stats/max_log_achievement_collect_sapling": 3.0833333333333335, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 10.458333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.9166666666666666, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 2.1666666666666665, "eval_stats/max_log_achievement_place_plant": 3.0416666666666665, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.1666666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.00022917661408428103, "report/cont_loss_std": 0.0060836696065962315, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.005111434031277895, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0001907336263684556, "report/cont_pred": 0.992054283618927, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 13.805896759033203, "report/dyn_loss_std": 9.285893440246582, "report/image_loss_mean": 5.164062976837158, "report/image_loss_std": 6.837343692779541, "report/model_loss_mean": 13.512222290039062, "report/model_loss_std": 10.894412994384766, "report/post_ent_mag": 61.175628662109375, "report/post_ent_max": 61.175628662109375, "report/post_ent_mean": 41.70431900024414, "report/post_ent_min": 23.673147201538086, "report/post_ent_std": 7.619386196136475, "report/prior_ent_mag": 67.81681060791016, "report/prior_ent_max": 67.81681060791016, "report/prior_ent_mean": 55.646907806396484, "report/prior_ent_min": 33.98093795776367, "report/prior_ent_std": 4.464937686920166, "report/rep_loss_mean": 13.805896759033203, "report/rep_loss_std": 9.285893440246582, "report/reward_avg": 0.0361328125, "report/reward_loss_mean": 0.06439241766929626, "report/reward_loss_std": 0.24930702149868011, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0067939758300781, "report/reward_neg_acc": 0.9938837289810181, "report/reward_neg_loss": 0.027586426585912704, "report/reward_pos_acc": 0.9302325248718262, "report/reward_pos_loss": 0.9040825366973877, "report/reward_pred": 0.03254150599241257, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.122925141316955e-06, "eval/cont_loss_std": 1.991176941373851e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00021157736773602664, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.110769502105541e-07, "eval/cont_pred": 0.9980466365814209, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.700756072998047, "eval/dyn_loss_std": 9.970209121704102, "eval/image_loss_mean": 12.715376853942871, "eval/image_loss_std": 15.463438987731934, "eval/model_loss_mean": 23.418685913085938, "eval/model_loss_std": 19.47858428955078, "eval/post_ent_mag": 58.889217376708984, "eval/post_ent_max": 58.889217376708984, "eval/post_ent_mean": 39.99237060546875, "eval/post_ent_min": 22.692873001098633, "eval/post_ent_std": 7.163215160369873, "eval/prior_ent_mag": 67.81681060791016, "eval/prior_ent_max": 67.81681060791016, "eval/prior_ent_mean": 55.844539642333984, "eval/prior_ent_min": 37.05837631225586, "eval/prior_ent_std": 4.2769060134887695, "eval/rep_loss_mean": 17.700756072998047, "eval/rep_loss_std": 9.970209121704102, "eval/reward_avg": 0.02695312350988388, "eval/reward_loss_mean": 0.08285680413246155, "eval/reward_loss_std": 0.5405584573745728, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006089210510254, "eval/reward_neg_acc": 0.9909456372261047, "eval/reward_neg_loss": 0.0352812260389328, "eval/reward_pos_acc": 0.8666667342185974, "eval/reward_pos_loss": 1.6591943502426147, "eval/reward_pred": 0.02359072118997574, "eval/reward_rate": 0.029296875, "replay/size": 369529.0, "replay/inserts": 21496.0, "replay/samples": 21488.0, "replay/insert_wait_avg": 1.3443764408680867e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.715570461190821e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 74744.0, "eval_replay/inserts": 6056.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2288635284141632e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1014.8483045101166, "timer/env.step_count": 2687.0, "timer/env.step_total": 256.7100307941437, "timer/env.step_frac": 0.25295409141769387, "timer/env.step_avg": 0.09553778593008697, "timer/env.step_min": 0.02225351333618164, "timer/env.step_max": 2.984004020690918, "timer/replay._sample_count": 21488.0, "timer/replay._sample_total": 11.050615072250366, "timer/replay._sample_frac": 0.010888932881042427, "timer/replay._sample_avg": 0.0005142691303169382, "timer/replay._sample_min": 0.00042128562927246094, "timer/replay._sample_max": 0.011093378067016602, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3444.0, "timer/agent.policy_total": 55.648988008499146, "timer/agent.policy_frac": 0.054834784431513434, "timer/agent.policy_avg": 0.016158242743466653, "timer/agent.policy_min": 0.009344339370727539, "timer/agent.policy_max": 0.10602426528930664, "timer/dataset_train_count": 1343.0, "timer/dataset_train_total": 0.14192652702331543, "timer/dataset_train_frac": 0.00013984999175992676, "timer/dataset_train_avg": 0.0001056787245147546, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.001066446304321289, "timer/agent.train_count": 1343.0, "timer/agent.train_total": 599.9045603275299, "timer/agent.train_frac": 0.591127321848474, "timer/agent.train_avg": 0.4466899183376991, "timer/agent.train_min": 0.43409109115600586, "timer/agent.train_max": 1.4526348114013672, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4660072326660156, "timer/agent.report_frac": 0.0004591890537679567, "timer/agent.report_avg": 0.2330036163330078, "timer/agent.report_min": 0.2254173755645752, "timer/agent.report_max": 0.24058985710144043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.795670129909855e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 21.181215591215736}
{"step": 370416, "time": 17371.978531599045, "episode/length": 141.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 370560, "time": 17378.25511074066, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 370568, "time": 17379.82429599762, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 370888, "time": 17391.834718942642, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 371088, "time": 17400.311683893204, "episode/length": 65.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 371296, "time": 17408.786720991135, "episode/length": 241.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.0}
{"step": 371432, "time": 17414.600432157516, "episode/length": 232.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 371688, "time": 17424.667889356613, "episode/length": 248.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 371864, "time": 17432.222927570343, "episode/length": 244.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 372208, "time": 17445.33340406418, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 372288, "time": 17449.642904996872, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 372376, "time": 17453.93489909172, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 372808, "time": 17470.29656815529, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 373112, "time": 17482.615449905396, "episode/length": 37.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 373120, "time": 17485.038471221924, "episode/length": 253.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 373216, "time": 17490.560002088547, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 373392, "time": 17497.913646697998, "episode/length": 190.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 373520, "time": 17503.68364930153, "episode/length": 37.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 373552, "time": 17506.311593294144, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 373616, "time": 17510.06813454628, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 374000, "time": 17524.453672647476, "episode/length": 223.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 374272, "time": 17534.906848430634, "episode/length": 236.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 374592, "time": 17547.424290418625, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 374848, "time": 17557.895616054535, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 375032, "time": 17565.4741897583, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 375160, "time": 17571.65753507614, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 375288, "time": 17577.931283950806, "episode/length": 216.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 375504, "time": 17586.950484752655, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 375528, "time": 17589.110377073288, "episode/length": 300.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9900332225913622, "episode/intrinsic_return": 0.0}
{"step": 375904, "time": 17603.2047457695, "episode/length": 46.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 376176, "time": 17613.932440519333, "episode/length": 237.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 376176, "time": 17613.94689822197, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 376224, "time": 17618.79587984085, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 376272, "time": 17621.84311723709, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 376320, "time": 17625.023071289062, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 376616, "time": 17636.26030898094, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 377064, "time": 17654.066658496857, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 377368, "time": 17665.61621117592, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 377488, "time": 17671.507321357727, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 377576, "time": 17675.82864880562, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 377744, "time": 17683.79464316368, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 378128, "time": 17698.68572831154, "episode/length": 79.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 378272, "time": 17704.863678455353, "episode/length": 345.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9855491329479769, "episode/intrinsic_return": 0.0}
{"step": 378344, "time": 17708.591417074203, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 378376, "time": 17711.136649370193, "episode/length": 256.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9883268482490273, "episode/intrinsic_return": 0.0}
{"step": 378448, "time": 17715.20038485527, "episode/length": 108.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 378672, "time": 17724.24850678444, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 378736, "time": 17728.066677570343, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 379288, "time": 17747.617430448532, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 379320, "time": 17750.238008499146, "episode/length": 72.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9178082191780822, "episode/intrinsic_return": 0.0}
{"step": 379504, "time": 17758.29150414467, "episode/length": 171.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 379600, "time": 17763.150172472, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 379648, "time": 17766.391498088837, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 379752, "time": 17771.194904088974, "episode/length": 171.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 379808, "time": 17774.792001008987, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 17797.462203741074, "eval_episode/length": 38.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8974358974358975}
{"step": 380016, "time": 17803.804717302322, "eval_episode/length": 157.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 380016, "time": 17806.080152273178, "eval_episode/length": 171.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 380016, "time": 17808.170717954636, "eval_episode/length": 172.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.976878612716763}
{"step": 380016, "time": 17810.25982093811, "eval_episode/length": 175.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 380016, "time": 17812.8655500412, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 380016, "time": 17816.52786707878, "eval_episode/length": 221.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9684684684684685}
{"step": 380016, "time": 17818.653574705124, "eval_episode/length": 222.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 380480, "time": 17834.496611118317, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 380544, "time": 17838.133477449417, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 380704, "time": 17845.05210876465, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 380824, "time": 17850.52958035469, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 381136, "time": 17862.59085202217, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 381256, "time": 17867.97731423378, "episode/length": 96.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9381443298969072, "episode/intrinsic_return": 0.0}
{"step": 381256, "time": 17867.986756563187, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 381464, "time": 17878.249255418777, "episode/length": 213.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 381664, "time": 17886.88251209259, "episode/length": 251.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 382168, "time": 17905.82609629631, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 382176, "time": 17907.93807721138, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 382216, "time": 17910.566343307495, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 382576, "time": 17924.161057949066, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 382776, "time": 17932.089111328125, "episode/length": 189.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 382816, "time": 17935.26382279396, "episode/length": 168.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9881656804733728, "episode/intrinsic_return": 0.0}
{"step": 382888, "time": 17939.096618175507, "episode/length": 152.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 383344, "time": 17955.851051568985, "episode/length": 260.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 383408, "time": 17959.408602952957, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 383520, "time": 17964.73462176323, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 383952, "time": 17980.691511631012, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 384256, "time": 17992.268408298492, "episode/length": 179.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 384424, "time": 17999.23350405693, "episode/length": 205.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 384736, "time": 18011.469165325165, "episode/length": 269.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 384832, "time": 18016.13224196434, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 384952, "time": 18021.47679567337, "episode/length": 178.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 384984, "time": 18024.05404639244, "episode/length": 261.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 385296, "time": 18037.652051210403, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 385464, "time": 18044.505379915237, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 385904, "time": 18060.94770216942, "episode/length": 243.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 386272, "time": 18075.08901810646, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 386296, "time": 18077.286685466766, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 386392, "time": 18082.08285188675, "episode/length": 245.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 386392, "time": 18082.09180378914, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 386664, "time": 18094.441548347473, "episode/length": 209.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 386768, "time": 18099.87041091919, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 387088, "time": 18112.63681101799, "episode/length": 223.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 387712, "time": 18134.888476133347, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 387792, "time": 18139.031900167465, "episode/length": 235.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 387808, "time": 18140.979225873947, "episode/length": 188.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 388240, "time": 18156.87425017357, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 388392, "time": 18163.295967817307, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 388648, "time": 18173.214875221252, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 388840, "time": 18181.162052631378, "episode/length": 305.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 388968, "time": 18186.964708805084, "episode/length": 287.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 389000, "time": 18189.58237338066, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 389328, "time": 18202.22792339325, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 389336, "time": 18203.88360762596, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 389656, "time": 18216.056156158447, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 389712, "time": 18219.72384238243, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 18249.802623987198, "eval_episode/length": 45.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 390000, "time": 18256.092490196228, "eval_episode/length": 143.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 390000, "time": 18260.097873449326, "eval_episode/length": 185.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.978494623655914}
{"step": 390000, "time": 18262.548042297363, "eval_episode/length": 194.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 390000, "time": 18265.49034333229, "eval_episode/length": 210.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 390000, "time": 18268.091500282288, "eval_episode/length": 221.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 390000, "time": 18271.02292752266, "eval_episode/length": 193.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 390000, "time": 18274.193164348602, "eval_episode/length": 267.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9776119402985075}
{"step": 390408, "time": 18287.92396903038, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 390464, "time": 18292.142137289047, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 390568, "time": 18297.564180850983, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 390624, "time": 18301.631720781326, "episode/length": 246.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 390632, "time": 18303.689051151276, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 390672, "time": 18307.331451892853, "episode/length": 212.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 391712, "time": 18344.91412305832, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 391736, "time": 18347.54980993271, "episode/length": 252.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 391760, "time": 18350.495053768158, "episode/length": 140.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 391848, "time": 18355.333287239075, "episode/length": 273.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 391873, "time": 18359.074823617935, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.26680576100069, "train/action_min": 0.0, "train/action_std": 3.2426620336139904, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04444817138616653, "train/actor_opt_grad_steps": 23715.0, "train/actor_opt_loss": -4.409077893285191, "train/adv_mag": 0.5792660656220773, "train/adv_max": 0.5510270777432358, "train/adv_mean": 0.0033475338075410997, "train/adv_min": -0.41782648313571424, "train/adv_std": 0.06475216714555726, "train/cont_avg": 0.9947222541360294, "train/cont_loss_mean": 0.0003106581872065603, "train/cont_loss_std": 0.008639317347091231, "train/cont_neg_acc": 0.9921481109717313, "train/cont_neg_loss": 0.030966408235385375, "train/cont_pos_acc": 0.9999710812288172, "train/cont_pos_loss": 0.00012729713851346875, "train/cont_pred": 0.9947288772639107, "train/cont_rate": 0.9947222541360294, "train/dyn_loss_mean": 14.713584009338827, "train/dyn_loss_std": 8.92692884978126, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8677589827600647, "train/extr_critic_critic_opt_grad_steps": 23715.0, "train/extr_critic_critic_opt_loss": 16164.421149758731, "train/extr_critic_mag": 5.7685975432395935, "train/extr_critic_max": 5.7685975432395935, "train/extr_critic_mean": 1.3912158814423226, "train/extr_critic_min": -0.2476638310095843, "train/extr_critic_std": 1.3424446337363298, "train/extr_return_normed_mag": 1.675414676175398, "train/extr_return_normed_max": 1.675414676175398, "train/extr_return_normed_mean": 0.34944789002046867, "train/extr_return_normed_min": -0.11651469684918137, "train/extr_return_normed_std": 0.3235642971361385, "train/extr_return_rate": 0.6497415319523391, "train/extr_return_raw_mag": 7.034771947299733, "train/extr_return_raw_max": 7.034771947299733, "train/extr_return_raw_mean": 1.4053913113825462, "train/extr_return_raw_min": -0.5732066832921084, "train/extr_return_raw_std": 1.3739264949279673, "train/extr_reward_mag": 1.0137151444659513, "train/extr_reward_max": 1.0137151444659513, "train/extr_reward_mean": 0.030145139241700664, "train/extr_reward_min": -0.35992464686141296, "train/extr_reward_std": 0.1635696609668872, "train/image_loss_mean": 7.26133915606667, "train/image_loss_std": 11.104664756971246, "train/model_loss_mean": 16.145707600256976, "train/model_loss_std": 14.693185371511122, "train/model_opt_grad_norm": 60.54650384988358, "train/model_opt_grad_steps": 23690.977941176472, "train/model_opt_loss": 20896.921472886028, "train/model_opt_model_opt_grad_overflow": 0.014705882352941176, "train/model_opt_model_opt_grad_scale": 1277.5735294117646, "train/policy_entropy_mag": 2.4062979151220882, "train/policy_entropy_max": 2.4062979151220882, "train/policy_entropy_mean": 0.5419577837866896, "train/policy_entropy_min": 0.0793751994805301, "train/policy_entropy_std": 0.5464032088570735, "train/policy_logprob_mag": 7.438383400440216, "train/policy_logprob_max": -0.009455761927015641, "train/policy_logprob_mean": -0.5416291391148287, "train/policy_logprob_min": -7.438383400440216, "train/policy_logprob_std": 1.0899331701152466, "train/policy_randomness_mag": 0.8493175664368797, "train/policy_randomness_max": 0.8493175664368797, "train/policy_randomness_mean": 0.19128731506712296, "train/policy_randomness_min": 0.028015962075989914, "train/policy_randomness_std": 0.19285635737811818, "train/post_ent_mag": 59.088349903331085, "train/post_ent_max": 59.088349903331085, "train/post_ent_mean": 41.07412329842062, "train/post_ent_min": 21.098271818721997, "train/post_ent_std": 7.238438616780674, "train/prior_ent_mag": 68.21031542385326, "train/prior_ent_max": 68.21031542385326, "train/prior_ent_mean": 55.83763015971464, "train/prior_ent_min": 37.64683057280148, "train/prior_ent_std": 4.711527312503142, "train/rep_loss_mean": 14.713584009338827, "train/rep_loss_std": 8.92692884978126, "train/reward_avg": 0.02510052834473112, "train/reward_loss_mean": 0.0559074868557646, "train/reward_loss_std": 0.2558774451779969, "train/reward_max_data": 1.0139705915661419, "train/reward_max_pred": 1.006534101331935, "train/reward_neg_acc": 0.9925063519793398, "train/reward_neg_loss": 0.030427353888037887, "train/reward_pos_acc": 0.9598217742408023, "train/reward_pos_loss": 0.8843700802501511, "train/reward_pred": 0.02421642785809715, "train/reward_rate": 0.029943129595588234, "train_stats/sum_log_reward": 6.354385969931619, "train_stats/max_log_achievement_collect_drink": 3.412280701754386, "train_stats/max_log_achievement_collect_sapling": 3.254385964912281, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 9.614035087719298, "train_stats/max_log_achievement_defeat_skeleton": 0.017543859649122806, "train_stats/max_log_achievement_defeat_zombie": 0.8508771929824561, "train_stats/max_log_achievement_eat_cow": 0.14035087719298245, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02631578947368421, "train_stats/max_log_achievement_make_wood_sword": 1.6140350877192982, "train_stats/max_log_achievement_place_plant": 3.2017543859649122, "train_stats/max_log_achievement_place_table": 2.6315789473684212, "train_stats/max_log_achievement_wake_up": 1.1140350877192982, "train_stats/mean_log_entropy": 0.5207608629736984, "eval_stats/sum_log_reward": 6.099999967031181, "eval_stats/max_log_achievement_collect_drink": 3.125, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 9.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_plant": 2.8125, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.553035862249089e-07, "report/cont_loss_std": 6.261514954530867e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.058811777620576e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.607363285278552e-07, "report/cont_pred": 0.9951173067092896, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 16.824012756347656, "report/dyn_loss_std": 8.66297721862793, "report/image_loss_mean": 7.086917877197266, "report/image_loss_std": 10.353477478027344, "report/model_loss_mean": 17.231639862060547, "report/model_loss_std": 13.897191047668457, "report/post_ent_mag": 57.30521011352539, "report/post_ent_max": 57.30521011352539, "report/post_ent_mean": 39.32530975341797, "report/post_ent_min": 21.70244598388672, "report/post_ent_std": 6.532146453857422, "report/prior_ent_mag": 68.38798522949219, "report/prior_ent_max": 68.38798522949219, "report/prior_ent_mean": 56.00132369995117, "report/prior_ent_min": 41.72136688232422, "report/prior_ent_std": 4.238615989685059, "report/rep_loss_mean": 16.824012756347656, "report/rep_loss_std": 8.66297721862793, "report/reward_avg": 0.02421874925494194, "report/reward_loss_mean": 0.05031411349773407, "report/reward_loss_std": 0.2388961762189865, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0070819854736328, "report/reward_neg_acc": 0.991959810256958, "report/reward_neg_loss": 0.03166639804840088, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6901236176490784, "report/reward_pred": 0.024518974125385284, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 7.32073340259376e-06, "eval/cont_loss_std": 0.00017877320351544768, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.1517643694533035e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.220252427941887e-06, "eval/cont_pred": 0.9970633387565613, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.836458206176758, "eval/dyn_loss_std": 9.940205574035645, "eval/image_loss_mean": 14.123092651367188, "eval/image_loss_std": 17.244834899902344, "eval/model_loss_mean": 25.493019104003906, "eval/model_loss_std": 21.163476943969727, "eval/post_ent_mag": 60.17213821411133, "eval/post_ent_max": 60.17213821411133, "eval/post_ent_mean": 40.74374008178711, "eval/post_ent_min": 21.237154006958008, "eval/post_ent_std": 7.375437259674072, "eval/prior_ent_mag": 68.38798522949219, "eval/prior_ent_max": 68.38798522949219, "eval/prior_ent_mean": 56.50233459472656, "eval/prior_ent_min": 38.54441833496094, "eval/prior_ent_std": 4.5858564376831055, "eval/rep_loss_mean": 18.836458206176758, "eval/rep_loss_std": 9.940205574035645, "eval/reward_avg": 0.02060546725988388, "eval/reward_loss_mean": 0.06804502755403519, "eval/reward_loss_std": 0.4022386372089386, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011794567108154, "eval/reward_neg_acc": 0.9869869947433472, "eval/reward_neg_loss": 0.03281942754983902, "eval/reward_pos_acc": 0.8799999952316284, "eval/reward_pos_loss": 1.475659728050232, "eval/reward_pred": 0.01830686628818512, "eval/reward_rate": 0.0244140625, "replay/size": 391369.0, "replay/inserts": 21840.0, "replay/samples": 21840.0, "replay/insert_wait_avg": 1.3624901299948222e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.775637700007512e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 78672.0, "eval_replay/inserts": 3928.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2612876969782252e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0261924266815, "timer/env.step_count": 2730.0, "timer/env.step_total": 260.79073429107666, "timer/env.step_frac": 0.2607839037277985, "timer/env.step_avg": 0.09552774149856288, "timer/env.step_min": 0.02206277847290039, "timer/env.step_max": 3.3252789974212646, "timer/replay._sample_count": 21840.0, "timer/replay._sample_total": 11.325001239776611, "timer/replay._sample_frac": 0.011324704618281207, "timer/replay._sample_avg": 0.0005185440128102844, "timer/replay._sample_min": 0.0003688335418701172, "timer/replay._sample_max": 0.009163141250610352, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3221.0, "timer/agent.policy_total": 51.543004512786865, "timer/agent.policy_frac": 0.05154165451178002, "timer/agent.policy_avg": 0.0160021746391763, "timer/agent.policy_min": 0.009449005126953125, "timer/agent.policy_max": 0.09240174293518066, "timer/dataset_train_count": 1365.0, "timer/dataset_train_total": 0.14548897743225098, "timer/dataset_train_frac": 0.00014548516682268573, "timer/dataset_train_avg": 0.00010658533145219852, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0004596710205078125, "timer/agent.train_count": 1365.0, "timer/agent.train_total": 612.1352281570435, "timer/agent.train_frac": 0.612119195269901, "timer/agent.train_avg": 0.4484507165985666, "timer/agent.train_min": 0.4361541271209717, "timer/agent.train_max": 1.4922642707824707, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47630834579467773, "timer/agent.report_frac": 0.00047629587045001226, "timer/agent.report_avg": 0.23815417289733887, "timer/agent.report_min": 0.2291123867034912, "timer/agent.report_max": 0.24719595909118652, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2900902161548e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 21.83913589625414}
{"step": 392064, "time": 18365.943163394928, "episode/length": 40.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 392128, "time": 18370.121606826782, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 392152, "time": 18372.70913529396, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 392344, "time": 18381.0952501297, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 392352, "time": 18383.121079921722, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 392408, "time": 18386.48825120926, "episode/length": 42.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 393024, "time": 18408.571960687637, "episode/length": 163.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 393192, "time": 18415.572197198868, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 393336, "time": 18424.041172742844, "episode/length": 150.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 393568, "time": 18434.015723466873, "episode/length": 151.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 393592, "time": 18436.1211643219, "episode/length": 147.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 393656, "time": 18439.77365732193, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 393992, "time": 18452.557674646378, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 394112, "time": 18458.221325159073, "episode/length": 244.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 394192, "time": 18462.427626609802, "episode/length": 303.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 394744, "time": 18482.266969680786, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 394752, "time": 18484.67798948288, "episode/length": 147.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 395096, "time": 18498.189915657043, "episode/length": 258.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 395112, "time": 18500.60626912117, "episode/length": 139.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 395312, "time": 18509.21640110016, "episode/length": 206.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 395344, "time": 18511.79585337639, "episode/length": 218.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 395760, "time": 18527.01232814789, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 395808, "time": 18530.06316423416, "episode/length": 201.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 396280, "time": 18547.404099225998, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 396392, "time": 18553.266971588135, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 396616, "time": 18562.941383123398, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 396800, "time": 18571.538279771805, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 396840, "time": 18574.73578095436, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 396968, "time": 18581.230793952942, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 397456, "time": 18599.587236166, "episode/length": 211.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 397672, "time": 18608.08169221878, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 397696, "time": 18610.799968242645, "episode/length": 235.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 397760, "time": 18614.68163228035, "episode/length": 142.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 397888, "time": 18620.86267900467, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 398064, "time": 18628.242196321487, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 398240, "time": 18635.730056762695, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 398400, "time": 18642.449836730957, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 398928, "time": 18661.650824308395, "episode/length": 153.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 399008, "time": 18666.36731505394, "episode/length": 193.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 399032, "time": 18668.9447183609, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 399288, "time": 18679.64930176735, "episode/length": 174.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 399584, "time": 18691.39539194107, "episode/length": 238.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 399816, "time": 18700.44158935547, "episode/length": 218.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 399840, "time": 18703.0683259964, "episode/length": 31.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 18730.731550455093, "eval_episode/length": 133.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9552238805970149}
{"step": 400088, "time": 18733.454052448273, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9559748427672956}
{"step": 400088, "time": 18735.940967082977, "eval_episode/length": 181.0, "eval_episode/score": 7.099999964237213, "eval_episode/reward_rate": 0.978021978021978}
{"step": 400088, "time": 18738.09722518921, "eval_episode/length": 193.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 400088, "time": 18739.75807595253, "eval_episode/length": 195.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 400088, "time": 18741.9083173275, "eval_episode/length": 209.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9809523809523809}
{"step": 400088, "time": 18743.686949968338, "eval_episode/length": 213.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 400088, "time": 18745.4465842247, "eval_episode/length": 218.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9680365296803652}
{"step": 400160, "time": 18748.16178750992, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9708333333333333, "episode/intrinsic_return": 0.0}
{"step": 400200, "time": 18750.847351312637, "episode/length": 148.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 400440, "time": 18760.34967637062, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 400464, "time": 18762.873535633087, "episode/length": 178.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 400520, "time": 18766.00648379326, "episode/length": 264.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735849056603774, "episode/intrinsic_return": 0.0}
{"step": 401200, "time": 18790.266472816467, "episode/length": 238.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 401312, "time": 18795.531542539597, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 401328, "time": 18797.51578783989, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 401488, "time": 18805.7044403553, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 401712, "time": 18814.73720741272, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 402192, "time": 18832.669115543365, "episode/length": 208.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 402224, "time": 18835.16915345192, "episode/length": 252.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 402600, "time": 18848.923006772995, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 402616, "time": 18850.981529951096, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 402672, "time": 18854.60371351242, "episode/length": 275.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 402984, "time": 18866.296040534973, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 403112, "time": 18872.127875089645, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 403288, "time": 18879.47138261795, "episode/length": 76.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.922077922077922, "episode/intrinsic_return": 0.0}
{"step": 403384, "time": 18884.14404439926, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 403664, "time": 18895.10354423523, "episode/length": 243.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 403688, "time": 18897.385295391083, "episode/length": 37.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8947368421052632, "episode/intrinsic_return": 0.0}
{"step": 403912, "time": 18906.449757814407, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 404288, "time": 18920.55795931816, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 404384, "time": 18925.187124967575, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 404520, "time": 18931.098751544952, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 404576, "time": 18934.662135362625, "episode/length": 246.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 405144, "time": 18954.855394124985, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 405384, "time": 18964.43130350113, "episode/length": 211.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 405480, "time": 18968.99103164673, "episode/length": 273.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 405784, "time": 18980.53452897072, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 405888, "time": 18985.713825941086, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 405896, "time": 18987.430492162704, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 406032, "time": 18993.704921245575, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 406096, "time": 18997.260499477386, "episode/length": 303.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 407232, "time": 19036.433608055115, "episode/length": 141.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 407256, "time": 19038.649338960648, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 407288, "time": 19041.237913370132, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 407296, "time": 19043.298400878906, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 407360, "time": 19047.08538889885, "episode/length": 182.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 407392, "time": 19049.62997150421, "episode/length": 250.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 407560, "time": 19056.612037181854, "episode/length": 301.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 407856, "time": 19068.070954322815, "episode/length": 227.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 408592, "time": 19094.02922463417, "episode/length": 169.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 408752, "time": 19100.977778434753, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 409024, "time": 19111.715003728867, "episode/length": 203.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 409032, "time": 19113.782648324966, "episode/length": 216.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 409112, "time": 19118.479040145874, "episode/length": 218.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 409192, "time": 19123.296786546707, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 409192, "time": 19123.30692243576, "episode/length": 241.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 409408, "time": 19135.03018927574, "episode/length": 193.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 19177.889517068863, "eval_episode/length": 39.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 410072, "time": 19184.284051179886, "eval_episode/length": 127.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9609375}
{"step": 410072, "time": 19189.29441690445, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 410072, "time": 19189.30340719223, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9617486338797814}
{"step": 410072, "time": 19194.105932235718, "eval_episode/length": 220.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.995475113122172}
{"step": 410072, "time": 19195.771480321884, "eval_episode/length": 221.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 410072, "time": 19197.98359966278, "eval_episode/length": 235.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9745762711864406}
{"step": 410072, "time": 19203.2946267128, "eval_episode/length": 200.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 410104, "time": 19204.349618911743, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 410160, "time": 19207.931329727173, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 410376, "time": 19216.453054904938, "episode/length": 33.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 410464, "time": 19221.202670812607, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 410496, "time": 19223.795645475388, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 410504, "time": 19225.343039751053, "episode/length": 173.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 410512, "time": 19227.503529548645, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 410800, "time": 19238.460166454315, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 410824, "time": 19240.566544294357, "episode/length": 38.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 410952, "time": 19246.269207954407, "episode/length": 219.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 411616, "time": 19271.03485059738, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 411720, "time": 19275.839949846268, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 411856, "time": 19282.123983860016, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 411904, "time": 19285.283717393875, "episode/length": 190.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 412032, "time": 19291.251682043076, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 412216, "time": 19298.615190267563, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 412264, "time": 19301.706013917923, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 412296, "time": 19304.27547478676, "episode/length": 32.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8787878787878788, "episode/intrinsic_return": 0.0}
{"step": 412432, "time": 19310.60364341736, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 412816, "time": 19325.648289203644, "episode/length": 113.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.956140350877193, "episode/intrinsic_return": 0.0}
{"step": 413128, "time": 19337.89906835556, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 413376, "time": 19347.88916039467, "episode/length": 206.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 413657, "time": 19359.402091741562, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.117732328527114, "train/action_min": 0.0, "train/action_std": 3.1561678998610554, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045091093572623586, "train/actor_opt_grad_steps": 25075.0, "train/actor_opt_loss": -4.913551773656817, "train/adv_mag": 0.5850566224578548, "train/adv_max": 0.5631421175511444, "train/adv_mean": 0.003706645881118889, "train/adv_min": -0.44176595438929167, "train/adv_std": 0.06675581551869125, "train/cont_avg": 0.9943345013786765, "train/cont_loss_mean": 0.00013737221905074648, "train/cont_loss_std": 0.003978747024595631, "train/cont_neg_acc": 0.9956407568910542, "train/cont_neg_loss": 0.011150471456584028, "train/cont_pos_acc": 0.9999711027040201, "train/cont_pos_loss": 7.839653382562768e-05, "train/cont_pred": 0.9943159183158594, "train/cont_rate": 0.9943345013786765, "train/dyn_loss_mean": 14.41136517945458, "train/dyn_loss_std": 8.997116292224211, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8427998960456428, "train/extr_critic_critic_opt_grad_steps": 25075.0, "train/extr_critic_critic_opt_loss": 15852.883523380055, "train/extr_critic_mag": 5.866137918303995, "train/extr_critic_max": 5.866137918303995, "train/extr_critic_mean": 1.498199547038359, "train/extr_critic_min": -0.21877732084077947, "train/extr_critic_std": 1.39947328322074, "train/extr_return_normed_mag": 1.6989591542412252, "train/extr_return_normed_max": 1.6989591542412252, "train/extr_return_normed_mean": 0.3612193864058046, "train/extr_return_normed_min": -0.11835660692304373, "train/extr_return_normed_std": 0.33484724755672846, "train/extr_return_rate": 0.6583592181696611, "train/extr_return_raw_mag": 7.247037982239442, "train/extr_return_raw_max": 7.247037982239442, "train/extr_return_raw_mean": 1.5140828797045875, "train/extr_return_raw_min": -0.5414898724240416, "train/extr_return_raw_std": 1.4350279254071854, "train/extr_reward_mag": 1.0119507645859438, "train/extr_reward_max": 1.0119507645859438, "train/extr_reward_mean": 0.03331592674914967, "train/extr_reward_min": -0.3732818671885659, "train/extr_reward_std": 0.17061489184989648, "train/image_loss_mean": 6.911766935797298, "train/image_loss_std": 10.518288268762475, "train/model_loss_mean": 15.615834818166846, "train/model_loss_std": 14.155494002734914, "train/model_opt_grad_norm": 55.929558024686926, "train/model_opt_grad_steps": 25049.220588235294, "train/model_opt_loss": 12293.739771225873, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 790.4411764705883, "train/policy_entropy_mag": 2.4179319984772625, "train/policy_entropy_max": 2.4179319984772625, "train/policy_entropy_mean": 0.5234940623974099, "train/policy_entropy_min": 0.07937519076992483, "train/policy_entropy_std": 0.5269953483606086, "train/policy_logprob_mag": 7.438383354860194, "train/policy_logprob_max": -0.009455762796706575, "train/policy_logprob_mean": -0.5241205111584243, "train/policy_logprob_min": -7.438383354860194, "train/policy_logprob_std": 1.0810774875914348, "train/policy_randomness_mag": 0.853423890822074, "train/policy_randomness_max": 0.853423890822074, "train/policy_randomness_mean": 0.18477043005473473, "train/policy_randomness_min": 0.028015959021799704, "train/policy_randomness_std": 0.1860062321100165, "train/post_ent_mag": 59.55311932283289, "train/post_ent_max": 59.55311932283289, "train/post_ent_mean": 41.35177219615263, "train/post_ent_min": 20.987823907066794, "train/post_ent_std": 7.3291904365315155, "train/prior_ent_mag": 68.20859252705293, "train/prior_ent_max": 68.20859252705293, "train/prior_ent_mean": 55.84275781407076, "train/prior_ent_min": 37.63322875078987, "train/prior_ent_std": 4.705753217725193, "train/rep_loss_mean": 14.41136517945458, "train/rep_loss_std": 8.997116292224211, "train/reward_avg": 0.026388728922671256, "train/reward_loss_mean": 0.05711153130430509, "train/reward_loss_std": 0.2588669786996701, "train/reward_max_data": 1.0147058858590967, "train/reward_max_pred": 1.0060351780232262, "train/reward_neg_acc": 0.9930511818212622, "train/reward_neg_loss": 0.031301263151416445, "train/reward_pos_acc": 0.9675038001116585, "train/reward_pos_loss": 0.8486529601847425, "train/reward_pred": 0.02554198435973376, "train/reward_rate": 0.03146541819852941, "train_stats/sum_log_reward": 6.082758584926868, "train_stats/max_log_achievement_collect_drink": 3.3879310344827585, "train_stats/max_log_achievement_collect_sapling": 2.3879310344827585, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 10.336206896551724, "train_stats/max_log_achievement_defeat_skeleton": 0.017241379310344827, "train_stats/max_log_achievement_defeat_zombie": 0.7844827586206896, "train_stats/max_log_achievement_eat_cow": 0.13793103448275862, "train_stats/max_log_achievement_make_wood_pickaxe": 0.034482758620689655, "train_stats/max_log_achievement_make_wood_sword": 1.6810344827586208, "train_stats/max_log_achievement_place_plant": 2.2844827586206895, "train_stats/max_log_achievement_place_table": 2.853448275862069, "train_stats/max_log_achievement_wake_up": 1.1379310344827587, "train_stats/mean_log_entropy": 0.5012837456988877, "eval_stats/sum_log_reward": 6.2874999940395355, "eval_stats/max_log_achievement_collect_drink": 3.3125, "eval_stats/max_log_achievement_collect_sapling": 2.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 10.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_plant": 2.5, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.6231194283354853e-07, "report/cont_loss_std": 3.0192504709702916e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.7132406355813146e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.7953428255168546e-07, "report/cont_pred": 0.9951171875, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.623456001281738, "report/dyn_loss_std": 8.703242301940918, "report/image_loss_mean": 7.143249034881592, "report/image_loss_std": 10.365872383117676, "report/model_loss_mean": 15.977533340454102, "report/model_loss_std": 13.932487487792969, "report/post_ent_mag": 58.13887023925781, "report/post_ent_max": 58.13887023925781, "report/post_ent_mean": 41.2191047668457, "report/post_ent_min": 20.0672607421875, "report/post_ent_std": 7.019231796264648, "report/prior_ent_mag": 68.35946655273438, "report/prior_ent_max": 68.35946655273438, "report/prior_ent_mean": 55.99201583862305, "report/prior_ent_min": 41.8860969543457, "report/prior_ent_std": 4.088732719421387, "report/rep_loss_mean": 14.623456001281738, "report/rep_loss_std": 8.703242301940918, "report/reward_avg": 0.01894531212747097, "report/reward_loss_mean": 0.06020919978618622, "report/reward_loss_std": 0.26693296432495117, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0021679401397705, "report/reward_neg_acc": 0.9919919967651367, "report/reward_neg_loss": 0.0399002879858017, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.871753454208374, "report/reward_pred": 0.017148863524198532, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 4.401226760819554e-05, "eval/cont_loss_std": 0.001384786213748157, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.005575519520789385, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.5708512175224314e-07, "eval/cont_pred": 0.992229700088501, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 17.554180145263672, "eval/dyn_loss_std": 11.16256332397461, "eval/image_loss_mean": 17.119304656982422, "eval/image_loss_std": 28.464126586914062, "eval/model_loss_mean": 27.75348663330078, "eval/model_loss_std": 32.509761810302734, "eval/post_ent_mag": 59.827362060546875, "eval/post_ent_max": 59.827362060546875, "eval/post_ent_mean": 41.72247314453125, "eval/post_ent_min": 22.408828735351562, "eval/post_ent_std": 7.860470771789551, "eval/prior_ent_mag": 68.35946655273438, "eval/prior_ent_max": 68.35946655273438, "eval/prior_ent_mean": 57.05940246582031, "eval/prior_ent_min": 38.523170471191406, "eval/prior_ent_std": 4.135957717895508, "eval/rep_loss_mean": 17.554180145263672, "eval/rep_loss_std": 11.16256332397461, "eval/reward_avg": 0.02031249925494194, "eval/reward_loss_mean": 0.10162834823131561, "eval/reward_loss_std": 0.571235179901123, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0475742816925049, "eval/reward_neg_acc": 0.9929789304733276, "eval/reward_neg_loss": 0.05449710786342621, "eval/reward_pos_acc": 0.7407407760620117, "eval/reward_pos_loss": 1.841992974281311, "eval/reward_pred": 0.015530312433838844, "eval/reward_rate": 0.0263671875, "replay/size": 413153.0, "replay/inserts": 21784.0, "replay/samples": 21792.0, "replay/insert_wait_avg": 1.3472882430867766e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.725165970700078e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 83056.0, "eval_replay/inserts": 4384.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2100939333003803e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3142113685608, "timer/env.step_count": 2723.0, "timer/env.step_total": 263.48009181022644, "timer/env.step_frac": 0.2633973293748883, "timer/env.step_avg": 0.0967609591664438, "timer/env.step_min": 0.021960735321044922, "timer/env.step_max": 4.164514541625977, "timer/replay._sample_count": 21792.0, "timer/replay._sample_total": 11.332442045211792, "timer/replay._sample_frac": 0.011328882381574413, "timer/replay._sample_avg": 0.0005200276268911432, "timer/replay._sample_min": 0.0004029273986816406, "timer/replay._sample_max": 0.011239290237426758, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3271.0, "timer/agent.policy_total": 52.14445424079895, "timer/agent.policy_frac": 0.052128075007010555, "timer/agent.policy_avg": 0.015941441223111877, "timer/agent.policy_min": 0.009266138076782227, "timer/agent.policy_max": 0.10106015205383301, "timer/dataset_train_count": 1362.0, "timer/dataset_train_total": 0.1430501937866211, "timer/dataset_train_frac": 0.00014300525990819396, "timer/dataset_train_avg": 0.00010502951085655, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0003886222839355469, "timer/agent.train_count": 1362.0, "timer/agent.train_total": 612.1398260593414, "timer/agent.train_frac": 0.6119475451836819, "timer/agent.train_avg": 0.4494418693534078, "timer/agent.train_min": 0.43580055236816406, "timer/agent.train_max": 1.6838622093200684, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4709343910217285, "timer/agent.report_frac": 0.0004707864645623985, "timer/agent.report_avg": 0.23546719551086426, "timer/agent.report_min": 0.22949862480163574, "timer/agent.report_max": 0.24143576622009277, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.764786790137017e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 21.776882113219386}
{"step": 413768, "time": 19362.899167776108, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 413888, "time": 19368.59606385231, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 414056, "time": 19375.36054635048, "episode/length": 35.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 414112, "time": 19379.151304483414, "episode/length": 161.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 414112, "time": 19379.16024494171, "episode/length": 226.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 414128, "time": 19383.067576646805, "episode/length": 232.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 414240, "time": 19388.193884134293, "episode/length": 43.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 414440, "time": 19395.96816921234, "episode/length": 163.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 414736, "time": 19407.599757909775, "episode/length": 359.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 414880, "time": 19413.96228122711, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 415248, "time": 19427.951692342758, "episode/length": 100.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 415360, "time": 19433.877599716187, "episode/length": 153.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 415592, "time": 19443.731910467148, "episode/length": 184.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 415880, "time": 19454.846195936203, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9692982456140351, "episode/intrinsic_return": 0.0}
{"step": 415928, "time": 19457.916981220245, "episode/length": 226.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 415952, "time": 19460.373549938202, "episode/length": 213.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9672897196261683, "episode/intrinsic_return": 0.0}
{"step": 416232, "time": 19470.943708896637, "episode/length": 34.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 416504, "time": 19481.540095806122, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 416560, "time": 19485.169796705246, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 416792, "time": 19494.157618522644, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 416888, "time": 19499.003680944443, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 417032, "time": 19505.330738544464, "episode/length": 143.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9513888888888888, "episode/intrinsic_return": 0.0}
{"step": 417488, "time": 19522.04393529892, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 417624, "time": 19527.954073667526, "episode/length": 253.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 417840, "time": 19538.220839738846, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 417904, "time": 19541.83383989334, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 418112, "time": 19550.950346708298, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 418200, "time": 19555.708290100098, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 418208, "time": 19558.413288354874, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 418296, "time": 19563.205717802048, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 419224, "time": 19597.023001909256, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 419264, "time": 19600.63508439064, "episode/length": 204.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 419288, "time": 19603.179616689682, "episode/length": 180.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 419400, "time": 19608.37558245659, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 419544, "time": 19614.764666080475, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 419576, "time": 19617.381239652634, "episode/length": 38.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 419584, "time": 19619.41016626358, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 419872, "time": 19630.44849562645, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 19656.738423109055, "eval_episode/length": 153.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 420056, "time": 19658.365849018097, "eval_episode/length": 156.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9554140127388535}
{"step": 420056, "time": 19660.36909508705, "eval_episode/length": 166.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 420056, "time": 19662.725492954254, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 420056, "time": 19664.596505641937, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 420056, "time": 19666.699458122253, "eval_episode/length": 201.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 420056, "time": 19670.04517197609, "eval_episode/length": 55.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 420056, "time": 19673.09570789337, "eval_episode/length": 281.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9964539007092199}
{"step": 420400, "time": 19685.0740377903, "episode/length": 273.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 420720, "time": 19697.963107585907, "episode/length": 164.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 420784, "time": 19702.196130514145, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 420856, "time": 19706.591964244843, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 421008, "time": 19714.013012886047, "episode/length": 35.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 421056, "time": 19717.673555374146, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 421176, "time": 19723.55154132843, "episode/length": 198.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9849246231155779, "episode/intrinsic_return": 0.0}
{"step": 421208, "time": 19726.674967050552, "episode/length": 247.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 421480, "time": 19737.995741844177, "episode/length": 237.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 421744, "time": 19749.32048034668, "episode/length": 91.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9456521739130435, "episode/intrinsic_return": 0.0}
{"step": 421848, "time": 19754.68416452408, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 422144, "time": 19767.09346652031, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 422256, "time": 19772.846918821335, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 422448, "time": 19781.116583824158, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 422504, "time": 19784.220741271973, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 422528, "time": 19786.79369187355, "episode/length": 33.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 422792, "time": 19796.897787332535, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 422928, "time": 19803.146398305893, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 423032, "time": 19807.934848070145, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 423304, "time": 19818.397366046906, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 423760, "time": 19835.60449886322, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 423960, "time": 19844.207533836365, "episode/length": 178.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 424080, "time": 19850.508481502533, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 424112, "time": 19853.024577140808, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 424472, "time": 19866.38139295578, "episode/length": 209.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 424472, "time": 19866.390762090683, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 424552, "time": 19872.26847052574, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 424752, "time": 19880.546330690384, "episode/length": 214.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 425208, "time": 19896.927547454834, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 425368, "time": 19904.25887989998, "episode/length": 160.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 425872, "time": 19923.91033935547, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 425984, "time": 19929.385644435883, "episode/length": 233.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 426008, "time": 19932.956367254257, "episode/length": 255.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 426080, "time": 19937.11308002472, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 426208, "time": 19942.74963617325, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 426328, "time": 19948.05065345764, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 426712, "time": 19962.252115011215, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 426984, "time": 19972.69344353676, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 427280, "time": 19984.438657283783, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 427416, "time": 19990.441266059875, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 427464, "time": 19993.612839460373, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 427704, "time": 20003.096957206726, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 428232, "time": 20022.20859861374, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 428392, "time": 20029.091398477554, "episode/length": 314.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 428512, "time": 20034.836592674255, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 428552, "time": 20037.581362485886, "episode/length": 39.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 428592, "time": 20040.79988861084, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 428616, "time": 20042.974109888077, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 428992, "time": 20057.379234075546, "episode/length": 196.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 429272, "time": 20068.843516349792, "episode/length": 195.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 429632, "time": 20083.348334550858, "episode/length": 270.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 429736, "time": 20088.680238962173, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 429816, "time": 20093.314150571823, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 429936, "time": 20099.76634001732, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 429968, "time": 20102.982175827026, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 20124.692620754242, "eval_episode/length": 36.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.972972972972973}
{"step": 430040, "time": 20126.51385140419, "eval_episode/length": 39.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.875}
{"step": 430040, "time": 20128.2708067894, "eval_episode/length": 48.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 430040, "time": 20133.47653889656, "eval_episode/length": 142.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.958041958041958}
{"step": 430040, "time": 20135.655007839203, "eval_episode/length": 157.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9810126582278481}
{"step": 430040, "time": 20137.16351914406, "eval_episode/length": 109.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 430040, "time": 20140.787008047104, "eval_episode/length": 208.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 430040, "time": 20142.591262578964, "eval_episode/length": 215.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 430040, "time": 20142.603245019913, "eval_episode/length": 178.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 430656, "time": 20163.230332374573, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 430824, "time": 20170.03534388542, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 430888, "time": 20173.81807565689, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 430912, "time": 20176.460109472275, "episode/length": 286.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790940766550522, "episode/intrinsic_return": 0.0}
{"step": 431000, "time": 20180.648226737976, "episode/length": 128.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 431048, "time": 20183.766863822937, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 431112, "time": 20187.438279628754, "episode/length": 35.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 431392, "time": 20198.321434259415, "episode/length": 42.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 431512, "time": 20204.17593574524, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 432224, "time": 20230.078654527664, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 432312, "time": 20234.256201267242, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 432520, "time": 20242.66156935692, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 432536, "time": 20244.804338932037, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 432672, "time": 20251.134343624115, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 432976, "time": 20262.588221788406, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 433096, "time": 20267.90879869461, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 433208, "time": 20273.013981580734, "episode/length": 408.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779951100244498, "episode/intrinsic_return": 0.0}
{"step": 433528, "time": 20285.206483125687, "episode/length": 39.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 433752, "time": 20294.120534420013, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 434040, "time": 20305.015909910202, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 434072, "time": 20307.716508865356, "episode/length": 39.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 434272, "time": 20317.41184568405, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 434416, "time": 20323.66521334648, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 434536, "time": 20328.9236536026, "episode/length": 249.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968, "episode/intrinsic_return": 0.0}
{"step": 434536, "time": 20328.933709859848, "episode/length": 277.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748201438848921, "episode/intrinsic_return": 0.0}
{"step": 434680, "time": 20337.073433160782, "episode/length": 143.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 435000, "time": 20349.075404405594, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 435241, "time": 20359.39901304245, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.451309769241898, "train/action_min": 0.0, "train/action_std": 3.580996953116523, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04613100185438439, "train/actor_opt_grad_steps": 26430.0, "train/actor_opt_loss": -6.540478808350033, "train/adv_mag": 0.6132195154825847, "train/adv_max": 0.5714646496154644, "train/adv_mean": 0.0031910037493583297, "train/adv_min": -0.47364543610148957, "train/adv_std": 0.06707846174637476, "train/cont_avg": 0.9944444444444445, "train/cont_loss_mean": 0.0002496723880645496, "train/cont_loss_std": 0.007369837967347916, "train/cont_neg_acc": 0.9935714297824436, "train/cont_neg_loss": 0.02189646488557089, "train/cont_pos_acc": 0.9999490477420666, "train/cont_pos_loss": 0.00012317055233823895, "train/cont_pred": 0.9944463822576735, "train/cont_rate": 0.9944444444444445, "train/dyn_loss_mean": 14.203531095716688, "train/dyn_loss_std": 9.009491199917264, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8310898255418848, "train/extr_critic_critic_opt_grad_steps": 26430.0, "train/extr_critic_critic_opt_loss": 15950.86685474537, "train/extr_critic_mag": 5.901910785392479, "train/extr_critic_max": 5.901910785392479, "train/extr_critic_mean": 1.441106942847923, "train/extr_critic_min": -0.2218745434725726, "train/extr_critic_std": 1.3724495852435077, "train/extr_return_normed_mag": 1.6983366930926287, "train/extr_return_normed_max": 1.6983366930926287, "train/extr_return_normed_mean": 0.350425648910028, "train/extr_return_normed_min": -0.12704148684386854, "train/extr_return_normed_std": 0.33135817569715004, "train/extr_return_rate": 0.6491483721468184, "train/extr_return_raw_mag": 7.171203468464039, "train/extr_return_raw_max": 7.171203468464039, "train/extr_return_raw_mean": 1.454647919425258, "train/extr_return_raw_min": -0.5708672704520049, "train/extr_return_raw_std": 1.40549235785449, "train/extr_reward_mag": 1.0162094080889668, "train/extr_reward_max": 1.0162094080889668, "train/extr_reward_mean": 0.03276480348021896, "train/extr_reward_min": -0.40911385659818295, "train/extr_reward_std": 0.16990127718007123, "train/image_loss_mean": 6.707982271688956, "train/image_loss_std": 10.614871551372387, "train/model_loss_mean": 15.285030018841779, "train/model_loss_std": 14.253665599116573, "train/model_opt_grad_norm": 58.28672806068703, "train/model_opt_grad_steps": 26403.4, "train/model_opt_loss": 13389.303855613425, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 875.0, "train/policy_entropy_mag": 2.430996306737264, "train/policy_entropy_max": 2.430996306737264, "train/policy_entropy_mean": 0.5665278836532875, "train/policy_entropy_min": 0.07937518137472648, "train/policy_entropy_std": 0.5808644400702583, "train/policy_logprob_mag": 7.438383346133762, "train/policy_logprob_max": -0.009455748681944829, "train/policy_logprob_mean": -0.566426835015968, "train/policy_logprob_min": -7.438383346133762, "train/policy_logprob_std": 1.1063158247205946, "train/policy_randomness_mag": 0.8580350134107801, "train/policy_randomness_max": 0.8580350134107801, "train/policy_randomness_mean": 0.1999594823077873, "train/policy_randomness_min": 0.028015955647936575, "train/policy_randomness_std": 0.20501965648598142, "train/post_ent_mag": 59.57780801278574, "train/post_ent_max": 59.57780801278574, "train/post_ent_mean": 41.607729283085575, "train/post_ent_min": 21.01543549431695, "train/post_ent_std": 7.36053319507175, "train/prior_ent_mag": 68.28423066315827, "train/prior_ent_max": 68.28423066315827, "train/prior_ent_mean": 55.86588482326931, "train/prior_ent_min": 37.546897351300274, "train/prior_ent_std": 4.654429034833555, "train/rep_loss_mean": 14.203531095716688, "train/rep_loss_std": 9.009491199917264, "train/reward_avg": 0.02642288768870963, "train/reward_loss_mean": 0.05467939427881329, "train/reward_loss_std": 0.24819828503661687, "train/reward_max_data": 1.0118518546775535, "train/reward_max_pred": 1.0058377098154139, "train/reward_neg_acc": 0.9931658197332311, "train/reward_neg_loss": 0.029120906780439396, "train/reward_pos_acc": 0.9688914449126632, "train/reward_pos_loss": 0.8442272164203503, "train/reward_pred": 0.025658189898563756, "train/reward_rate": 0.03138744212962963, "train_stats/sum_log_reward": 5.983333304027716, "train_stats/max_log_achievement_collect_drink": 3.5416666666666665, "train_stats/max_log_achievement_collect_sapling": 2.558333333333333, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 8.766666666666667, "train_stats/max_log_achievement_defeat_skeleton": 0.008333333333333333, "train_stats/max_log_achievement_defeat_zombie": 0.8333333333333334, "train_stats/max_log_achievement_eat_cow": 0.11666666666666667, "train_stats/max_log_achievement_make_wood_pickaxe": 0.016666666666666666, "train_stats/max_log_achievement_make_wood_sword": 1.1916666666666667, "train_stats/max_log_achievement_place_plant": 2.441666666666667, "train_stats/max_log_achievement_place_table": 2.591666666666667, "train_stats/max_log_achievement_wake_up": 1.1, "train_stats/mean_log_entropy": 0.5272498674690723, "eval_stats/sum_log_reward": 5.747058868408203, "eval_stats/max_log_achievement_collect_drink": 2.0, "eval_stats/max_log_achievement_collect_sapling": 2.235294117647059, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.352941176470589, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.6470588235294118, "eval_stats/max_log_achievement_eat_cow": 0.058823529411764705, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.2352941176470589, "eval_stats/max_log_achievement_place_plant": 2.235294117647059, "eval_stats/max_log_achievement_place_table": 2.588235294117647, "eval_stats/max_log_achievement_wake_up": 0.8823529411764706, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.261213123550988e-06, "report/cont_loss_std": 6.132957787485793e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00020297565788496286, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.2812600946053863e-06, "report/cont_pred": 0.9951159954071045, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.653975486755371, "report/dyn_loss_std": 9.295086860656738, "report/image_loss_mean": 6.685822486877441, "report/image_loss_std": 9.175615310668945, "report/model_loss_mean": 14.93680191040039, "report/model_loss_std": 12.954553604125977, "report/post_ent_mag": 63.063507080078125, "report/post_ent_max": 63.063507080078125, "report/post_ent_mean": 42.60912322998047, "report/post_ent_min": 20.794797897338867, "report/post_ent_std": 8.057968139648438, "report/prior_ent_mag": 68.4845962524414, "report/prior_ent_max": 68.4845962524414, "report/prior_ent_mean": 55.95402526855469, "report/prior_ent_min": 36.026947021484375, "report/prior_ent_std": 5.11624813079834, "report/rep_loss_mean": 13.653975486755371, "report/rep_loss_std": 9.295086860656738, "report/reward_avg": 0.03271484375, "report/reward_loss_mean": 0.05859183892607689, "report/reward_loss_std": 0.23119884729385376, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0002024173736572, "report/reward_neg_acc": 0.9949238896369934, "report/reward_neg_loss": 0.03154103085398674, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7417981028556824, "report/reward_pred": 0.03146028146147728, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.7006713025912177e-06, "eval/cont_loss_std": 5.172153396415524e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00010142684186575934, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2162448658491485e-06, "eval/cont_pred": 0.9951155781745911, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.163116455078125, "eval/dyn_loss_std": 10.26942253112793, "eval/image_loss_mean": 18.283050537109375, "eval/image_loss_std": 26.93756866455078, "eval/model_loss_mean": 29.861980438232422, "eval/model_loss_std": 30.196313858032227, "eval/post_ent_mag": 60.52294158935547, "eval/post_ent_max": 60.52294158935547, "eval/post_ent_mean": 41.06906509399414, "eval/post_ent_min": 20.311458587646484, "eval/post_ent_std": 7.5797200202941895, "eval/prior_ent_mag": 68.4845962524414, "eval/prior_ent_max": 68.4845962524414, "eval/prior_ent_mean": 57.2486572265625, "eval/prior_ent_min": 37.90106201171875, "eval/prior_ent_std": 4.329405784606934, "eval/rep_loss_mean": 19.163116455078125, "eval/rep_loss_std": 10.26942253112793, "eval/reward_avg": 0.02509765699505806, "eval/reward_loss_mean": 0.08105558156967163, "eval/reward_loss_std": 0.49444854259490967, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0044527053833008, "eval/reward_neg_acc": 0.9929506778717041, "eval/reward_neg_loss": 0.030563343316316605, "eval/reward_pos_acc": 0.8064515590667725, "eval/reward_pos_loss": 1.6984357833862305, "eval/reward_pred": 0.02167404070496559, "eval/reward_rate": 0.0302734375, "replay/size": 434737.0, "replay/inserts": 21584.0, "replay/samples": 21584.0, "replay/insert_wait_avg": 1.366753503956381e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.805050860518788e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 87040.0, "eval_replay/inserts": 3984.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2571433461813562e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.985422372818, "timer/env.step_count": 2698.0, "timer/env.step_total": 277.1345226764679, "timer/env.step_frac": 0.2771385626991127, "timer/env.step_avg": 0.10271850358653369, "timer/env.step_min": 0.022294044494628906, "timer/env.step_max": 3.3990588188171387, "timer/replay._sample_count": 21584.0, "timer/replay._sample_total": 11.224582195281982, "timer/replay._sample_frac": 0.011224745825441838, "timer/replay._sample_avg": 0.0005200417992625084, "timer/replay._sample_min": 0.00038886070251464844, "timer/replay._sample_max": 0.009713888168334961, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3196.0, "timer/agent.policy_total": 50.558356046676636, "timer/agent.policy_frac": 0.05055909307828619, "timer/agent.policy_avg": 0.01581926034001146, "timer/agent.policy_min": 0.009140729904174805, "timer/agent.policy_max": 0.09061861038208008, "timer/dataset_train_count": 1349.0, "timer/dataset_train_total": 0.144622802734375, "timer/dataset_train_frac": 0.0001446249110224091, "timer/dataset_train_avg": 0.0001072074149254077, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.00028133392333984375, "timer/agent.train_count": 1349.0, "timer/agent.train_total": 604.276243686676, "timer/agent.train_frac": 0.6042850527288863, "timer/agent.train_avg": 0.4479438426142891, "timer/agent.train_min": 0.4351053237915039, "timer/agent.train_max": 1.4977891445159912, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4648463726043701, "timer/agent.report_frac": 0.0004648531490602715, "timer/agent.report_avg": 0.23242318630218506, "timer/agent.report_min": 0.22172164916992188, "timer/agent.report_max": 0.24312472343444824, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.00543212890625e-05, "timer/dataset_eval_frac": 4.005490519453724e-08, "timer/dataset_eval_avg": 4.00543212890625e-05, "timer/dataset_eval_min": 4.00543212890625e-05, "timer/dataset_eval_max": 4.00543212890625e-05, "fps": 21.584051223670453}
{"step": 435520, "time": 20368.712759256363, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 435544, "time": 20370.788189649582, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 435736, "time": 20378.649458169937, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 435768, "time": 20381.24672436714, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 436040, "time": 20391.72963285446, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 436264, "time": 20400.824459791183, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 436960, "time": 20425.40465903282, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 436976, "time": 20427.5573015213, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 437144, "time": 20434.41775727272, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 437240, "time": 20439.18818283081, "episode/length": 352.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9830028328611898, "episode/intrinsic_return": 0.0}
{"step": 437520, "time": 20450.186758756638, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 437552, "time": 20452.728723287582, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 437928, "time": 20466.58367753029, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 438720, "time": 20494.429878473282, "episode/length": 219.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 438824, "time": 20499.27808380127, "episode/length": 230.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 439032, "time": 20507.829726696014, "episode/length": 223.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 439288, "time": 20518.00763297081, "episode/length": 267.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 439360, "time": 20522.323165416718, "episode/length": 225.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 439472, "time": 20528.09077191353, "episode/length": 93.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.0}
{"step": 439504, "time": 20531.244078874588, "episode/length": 853.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9964871194379391, "episode/intrinsic_return": 0.0}
{"step": 439728, "time": 20540.90012049675, "episode/length": 224.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 439920, "time": 20549.568544864655, "episode/length": 299.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 20573.02082681656, "eval_episode/length": 42.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9069767441860465}
{"step": 440024, "time": 20576.703542232513, "eval_episode/length": 90.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.945054945054945}
{"step": 440024, "time": 20582.51573061943, "eval_episode/length": 194.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 440024, "time": 20584.088407039642, "eval_episode/length": 195.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 440024, "time": 20585.79607272148, "eval_episode/length": 198.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 440024, "time": 20585.804527759552, "eval_episode/length": 198.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9849246231155779}
{"step": 440024, "time": 20590.270767211914, "eval_episode/length": 226.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.973568281938326}
{"step": 440024, "time": 20590.28043460846, "eval_episode/length": 226.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 440192, "time": 20596.012655973434, "episode/length": 170.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 440360, "time": 20602.84225153923, "episode/length": 133.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 440720, "time": 20616.58277487755, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 440736, "time": 20618.794392108917, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 440792, "time": 20621.912217378616, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 441256, "time": 20638.92404270172, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 441264, "time": 20640.93985271454, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 441312, "time": 20644.05848789215, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 441752, "time": 20659.94076371193, "episode/length": 54.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 441840, "time": 20664.594237089157, "episode/length": 205.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 442128, "time": 20675.80553627014, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 442240, "time": 20681.64050245285, "episode/length": 189.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 442368, "time": 20688.236549139023, "episode/length": 203.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 442808, "time": 20706.114273309708, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 442928, "time": 20712.498096704483, "episode/length": 146.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 443176, "time": 20722.78757596016, "episode/length": 351.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 443208, "time": 20725.789137125015, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 443480, "time": 20737.141798257828, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 443552, "time": 20741.316217422485, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 444112, "time": 20761.49482703209, "episode/length": 217.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 444248, "time": 20767.254784345627, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 444336, "time": 20771.94781112671, "episode/length": 190.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 444400, "time": 20775.59660220146, "episode/length": 283.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753521126760564, "episode/intrinsic_return": 0.0}
{"step": 444496, "time": 20780.27328491211, "episode/length": 30.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8709677419354839, "episode/intrinsic_return": 0.0}
{"step": 444632, "time": 20786.076924562454, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 444832, "time": 20794.668035507202, "episode/length": 202.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 444960, "time": 20800.494760274887, "episode/length": 222.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 444976, "time": 20802.490882396698, "episode/length": 42.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 445848, "time": 20832.73905491829, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 445872, "time": 20835.309633493423, "episode/length": 219.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 445880, "time": 20836.909556150436, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 446256, "time": 20851.085161209106, "episode/length": 177.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 447040, "time": 20878.646985530853, "episode/length": 329.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 447040, "time": 20878.657652139664, "episode/length": 259.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 447152, "time": 20885.585564374924, "episode/length": 449.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 447328, "time": 20892.950152635574, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 447352, "time": 20895.083892822266, "episode/length": 38.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 447384, "time": 20897.711485624313, "episode/length": 300.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 447528, "time": 20903.982189655304, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 448136, "time": 20925.53945207596, "episode/length": 234.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 448184, "time": 20928.65177464485, "episode/length": 287.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 448576, "time": 20943.415580511093, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 448648, "time": 20947.126690149307, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 448736, "time": 20951.81265425682, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 448856, "time": 20957.143851041794, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 449072, "time": 20966.844314575195, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 449152, "time": 20971.16569542885, "episode/length": 202.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 449544, "time": 20985.441824674606, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 449960, "time": 21000.819000005722, "episode/length": 172.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 21024.530673742294, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 450008, "time": 21027.029990196228, "eval_episode/length": 166.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 450008, "time": 21029.96039366722, "eval_episode/length": 184.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 450008, "time": 21032.056094884872, "eval_episode/length": 187.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 450008, "time": 21034.147268295288, "eval_episode/length": 190.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 450008, "time": 21036.608659267426, "eval_episode/length": 198.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9849246231155779}
{"step": 450008, "time": 21039.46900820732, "eval_episode/length": 218.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 450008, "time": 21041.96394777298, "eval_episode/length": 46.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 450104, "time": 21045.262130975723, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 450328, "time": 21054.789316654205, "episode/length": 198.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 450416, "time": 21060.018356084824, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 450472, "time": 21063.15023636818, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 450568, "time": 21068.172165870667, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 450960, "time": 21084.29343342781, "episode/length": 176.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 451432, "time": 21101.128566741943, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 451544, "time": 21106.233478069305, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 451992, "time": 21122.679331302643, "episode/length": 177.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9606741573033708, "episode/intrinsic_return": 0.0}
{"step": 451992, "time": 21122.690442562103, "episode/length": 364.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9972602739726028, "episode/intrinsic_return": 0.0}
{"step": 452112, "time": 21130.3653485775, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 452192, "time": 21134.425472021103, "episode/length": 278.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974910394265233, "episode/intrinsic_return": 0.0}
{"step": 452240, "time": 21137.639106988907, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 452280, "time": 21140.22508072853, "episode/length": 232.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 452944, "time": 21164.574202537537, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 453048, "time": 21169.768530845642, "episode/length": 201.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 453136, "time": 21174.41713285446, "episode/length": 142.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 453312, "time": 21181.82438993454, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 453392, "time": 21186.008410453796, "episode/length": 149.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 453400, "time": 21187.650145292282, "episode/length": 160.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 453576, "time": 21194.94176363945, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 453640, "time": 21198.521189928055, "episode/length": 174.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 453672, "time": 21201.12866139412, "episode/length": 33.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 454008, "time": 21213.687178850174, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 454256, "time": 21223.552489042282, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 454448, "time": 21231.413044929504, "episode/length": 187.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 454720, "time": 21241.852640151978, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 454744, "time": 21243.90181827545, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 454760, "time": 21245.909030914307, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 454872, "time": 21251.267929792404, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 455072, "time": 21259.531492233276, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 455520, "time": 21275.942192554474, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 456056, "time": 21295.508548498154, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 456256, "time": 21303.910831212997, "episode/length": 188.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9894179894179894, "episode/intrinsic_return": 0.0}
{"step": 456272, "time": 21305.97457742691, "episode/length": 227.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 456384, "time": 21311.181192159653, "episode/length": 202.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 456408, "time": 21313.31176328659, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 456480, "time": 21317.501579761505, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 456576, "time": 21322.23027253151, "episode/length": 231.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 457152, "time": 21342.76546382904, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 457336, "time": 21350.161913871765, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 457488, "time": 21356.977845668793, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 457497, "time": 21359.56497144699, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.494991165270909, "train/action_min": 0.0, "train/action_std": 3.4583903628287556, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0452163636202006, "train/actor_opt_grad_steps": 27800.0, "train/actor_opt_loss": -4.788550692067729, "train/adv_mag": 0.6010085522270888, "train/adv_max": 0.5725833640681753, "train/adv_mean": 0.003597075599932494, "train/adv_min": -0.4620836795233994, "train/adv_std": 0.06619594018343541, "train/cont_avg": 0.9944848808453237, "train/cont_loss_mean": 0.000304692943759799, "train/cont_loss_std": 0.00918713604940474, "train/cont_neg_acc": 0.9917266193053705, "train/cont_neg_loss": 0.029010587512981776, "train/cont_pos_acc": 0.9999575396235898, "train/cont_pos_loss": 0.00015731984807388038, "train/cont_pred": 0.9944824096110227, "train/cont_rate": 0.9944848808453237, "train/dyn_loss_mean": 14.339634957073404, "train/dyn_loss_std": 8.9387020515881, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8234133248706516, "train/extr_critic_critic_opt_grad_steps": 27800.0, "train/extr_critic_critic_opt_loss": 15931.507566602968, "train/extr_critic_mag": 6.036637779620054, "train/extr_critic_max": 6.036637779620054, "train/extr_critic_mean": 1.4257132046514278, "train/extr_critic_min": -0.2498806269048787, "train/extr_critic_std": 1.4018319124798122, "train/extr_return_normed_mag": 1.6860646275307636, "train/extr_return_normed_max": 1.6860646275307636, "train/extr_return_normed_mean": 0.3490244476057643, "train/extr_return_normed_min": -0.12532445823224328, "train/extr_return_normed_std": 0.3314767638556391, "train/extr_return_rate": 0.6331230627118255, "train/extr_return_raw_mag": 7.2422566208050405, "train/extr_return_raw_max": 7.2422566208050405, "train/extr_return_raw_mean": 1.4413281490476868, "train/extr_return_raw_min": -0.6165908892377675, "train/extr_return_raw_std": 1.4382643373750097, "train/extr_reward_mag": 1.0150681742661292, "train/extr_reward_max": 1.0150681742661292, "train/extr_reward_mean": 0.033001009964471244, "train/extr_reward_min": -0.4127468016507814, "train/extr_reward_std": 0.17169643123801664, "train/image_loss_mean": 6.8738456767240015, "train/image_loss_std": 11.18279699627444, "train/model_loss_mean": 15.533895636634004, "train/model_loss_std": 14.761799565322107, "train/model_opt_grad_norm": 60.03402736032609, "train/model_opt_grad_steps": 27772.237410071943, "train/model_opt_loss": 11135.807090265287, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 714.9280575539568, "train/policy_entropy_mag": 2.414666127815521, "train/policy_entropy_max": 2.414666127815521, "train/policy_entropy_mean": 0.5469317515548184, "train/policy_entropy_min": 0.07937516105903995, "train/policy_entropy_std": 0.5617929431174299, "train/policy_logprob_mag": 7.438383414590959, "train/policy_logprob_max": -0.009455719681309281, "train/policy_logprob_mean": -0.5468353963584351, "train/policy_logprob_min": -7.438383414590959, "train/policy_logprob_std": 1.08757012782337, "train/policy_randomness_mag": 0.8522711803587221, "train/policy_randomness_max": 0.8522711803587221, "train/policy_randomness_mean": 0.1930429083194664, "train/policy_randomness_min": 0.028015948590829218, "train/policy_randomness_std": 0.19828825610147105, "train/post_ent_mag": 59.170852633688945, "train/post_ent_max": 59.170852633688945, "train/post_ent_mean": 41.50855098696921, "train/post_ent_min": 20.807869451509106, "train/post_ent_std": 7.2607850136516765, "train/prior_ent_mag": 68.39742224165003, "train/prior_ent_max": 68.39742224165003, "train/prior_ent_mean": 55.912430331003755, "train/prior_ent_min": 38.53584026089675, "train/prior_ent_std": 4.500406181211952, "train/rep_loss_mean": 14.339634957073404, "train/rep_loss_std": 8.9387020515881, "train/reward_avg": 0.027260847235594292, "train/reward_loss_mean": 0.05596444814754047, "train/reward_loss_std": 0.2514575962111247, "train/reward_max_data": 1.0143884926391162, "train/reward_max_pred": 1.0075271678485458, "train/reward_neg_acc": 0.9929887879666665, "train/reward_neg_loss": 0.029875544737354456, "train/reward_pos_acc": 0.9679049424987902, "train/reward_pos_loss": 0.8400614145848391, "train/reward_pred": 0.026528798968350288, "train/reward_rate": 0.03215630620503597, "train_stats/sum_log_reward": 6.5955752018278675, "train_stats/max_log_achievement_collect_drink": 4.247787610619469, "train_stats/max_log_achievement_collect_sapling": 3.1327433628318584, "train_stats/max_log_achievement_collect_stone": 0.035398230088495575, "train_stats/max_log_achievement_collect_wood": 10.070796460176991, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.9026548672566371, "train_stats/max_log_achievement_eat_cow": 0.20353982300884957, "train_stats/max_log_achievement_make_wood_pickaxe": 0.11504424778761062, "train_stats/max_log_achievement_make_wood_sword": 1.8495575221238938, "train_stats/max_log_achievement_place_plant": 3.0530973451327434, "train_stats/max_log_achievement_place_table": 2.8849557522123894, "train_stats/max_log_achievement_wake_up": 1.247787610619469, "train_stats/mean_log_entropy": 0.5354818162401166, "eval_stats/sum_log_reward": 6.225000016391277, "eval_stats/max_log_achievement_collect_drink": 2.5, "eval_stats/max_log_achievement_collect_sapling": 2.3125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 10.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.9375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.625, "eval_stats/max_log_achievement_place_plant": 2.3125, "eval_stats/max_log_achievement_place_table": 2.6875, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.0012100747553631663, "report/cont_loss_std": 0.03571118414402008, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001846583909355104, "report/cont_pos_acc": 0.999015748500824, "report/cont_pos_loss": 0.0012050628429278731, "report/cont_pred": 0.9914587140083313, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 14.371950149536133, "report/dyn_loss_std": 8.928643226623535, "report/image_loss_mean": 6.521862983703613, "report/image_loss_std": 11.136651039123535, "report/model_loss_mean": 15.214813232421875, "report/model_loss_std": 14.524045944213867, "report/post_ent_mag": 59.06996154785156, "report/post_ent_max": 59.06996154785156, "report/post_ent_mean": 41.77500534057617, "report/post_ent_min": 20.361663818359375, "report/post_ent_std": 8.089581489562988, "report/prior_ent_mag": 67.71612548828125, "report/prior_ent_max": 67.71612548828125, "report/prior_ent_mean": 56.314170837402344, "report/prior_ent_min": 39.624671936035156, "report/prior_ent_std": 4.150986194610596, "report/rep_loss_mean": 14.371950149536133, "report/rep_loss_std": 8.928643226623535, "report/reward_avg": 0.03574218600988388, "report/reward_loss_mean": 0.0685703456401825, "report/reward_loss_std": 0.30965524911880493, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.005072832107544, "report/reward_neg_acc": 0.9959267377853394, "report/reward_neg_loss": 0.03853178396821022, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.770900547504425, "report/reward_pred": 0.03567924350500107, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.123667400155682e-05, "eval/cont_loss_std": 0.0003159102634526789, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005842334358021617, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.95824231923325e-05, "eval/cont_pred": 0.9970526099205017, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.21142578125, "eval/dyn_loss_std": 10.404688835144043, "eval/image_loss_mean": 15.977029800415039, "eval/image_loss_std": 27.363656997680664, "eval/model_loss_mean": 26.378253936767578, "eval/model_loss_std": 31.03775978088379, "eval/post_ent_mag": 60.64864730834961, "eval/post_ent_max": 60.64864730834961, "eval/post_ent_mean": 42.528038024902344, "eval/post_ent_min": 21.73299789428711, "eval/post_ent_std": 8.148002624511719, "eval/prior_ent_mag": 67.71612548828125, "eval/prior_ent_max": 67.71612548828125, "eval/prior_ent_mean": 57.13530349731445, "eval/prior_ent_min": 40.07825469970703, "eval/prior_ent_std": 4.129082679748535, "eval/rep_loss_mean": 17.21142578125, "eval/rep_loss_std": 10.404688835144043, "eval/reward_avg": 0.03095703199505806, "eval/reward_loss_mean": 0.07434892654418945, "eval/reward_loss_std": 0.5116446018218994, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0065226554870605, "eval/reward_neg_acc": 0.9969727396965027, "eval/reward_neg_loss": 0.025426913052797318, "eval/reward_pos_acc": 0.8484848141670227, "eval/reward_pos_loss": 1.5434914827346802, "eval/reward_pred": 0.024795610457658768, "eval/reward_rate": 0.0322265625, "replay/size": 456993.0, "replay/inserts": 22256.0, "replay/samples": 22256.0, "replay/insert_wait_avg": 1.3544737735641336e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.799505268044818e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 90712.0, "eval_replay/inserts": 3672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2553335534721158e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1520986557007, "timer/env.step_count": 2782.0, "timer/env.step_total": 259.39367961883545, "timer/env.step_frac": 0.25935423218876924, "timer/env.step_avg": 0.09323999986298902, "timer/env.step_min": 0.02247142791748047, "timer/env.step_max": 3.5035488605499268, "timer/replay._sample_count": 22256.0, "timer/replay._sample_total": 11.495100975036621, "timer/replay._sample_frac": 0.011493352851518411, "timer/replay._sample_avg": 0.0005164944722787842, "timer/replay._sample_min": 0.0004100799560546875, "timer/replay._sample_max": 0.011473894119262695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3241.0, "timer/agent.policy_total": 51.941550970077515, "timer/agent.policy_frac": 0.051933651931433115, "timer/agent.policy_avg": 0.016026396473334623, "timer/agent.policy_min": 0.009210824966430664, "timer/agent.policy_max": 0.11355757713317871, "timer/dataset_train_count": 1391.0, "timer/dataset_train_total": 0.14562749862670898, "timer/dataset_train_frac": 0.00014560535224836918, "timer/dataset_train_avg": 0.00010469266615866929, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.00038170814514160156, "timer/agent.train_count": 1391.0, "timer/agent.train_total": 619.0967228412628, "timer/agent.train_frac": 0.6190025733819762, "timer/agent.train_avg": 0.4450731292891897, "timer/agent.train_min": 0.43204188346862793, "timer/agent.train_max": 0.573824405670166, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4747498035430908, "timer/agent.report_frac": 0.00047467760571737, "timer/agent.report_avg": 0.2373749017715454, "timer/agent.report_min": 0.2311863899230957, "timer/agent.report_max": 0.24356341361999512, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.0751319469749194e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 22.25231760916121}
{"step": 457656, "time": 21364.65674519539, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 457672, "time": 21366.787536859512, "episode/length": 160.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 457728, "time": 21370.504247903824, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 457960, "time": 21379.41321182251, "episode/length": 28.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8620689655172413, "episode/intrinsic_return": 0.0}
{"step": 458032, "time": 21383.660848140717, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 458680, "time": 21406.44754099846, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9530201342281879, "episode/intrinsic_return": 0.0}
{"step": 458928, "time": 21417.925967931747, "episode/length": 305.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 458944, "time": 21419.939187288284, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 459264, "time": 21432.059145450592, "episode/length": 39.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 459352, "time": 21436.307245731354, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 459384, "time": 21438.85874938965, "episode/length": 213.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 459408, "time": 21441.43730354309, "episode/length": 281.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 459800, "time": 21455.75478696823, "episode/length": 307.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9837662337662337, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 21485.79732298851, "eval_episode/length": 146.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9727891156462585}
{"step": 460096, "time": 21488.820348262787, "eval_episode/length": 181.0, "eval_episode/score": 8.099999964237213, "eval_episode/reward_rate": 0.967032967032967}
{"step": 460096, "time": 21490.475553035736, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 460096, "time": 21492.883790254593, "eval_episode/length": 204.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 460096, "time": 21494.946624279022, "eval_episode/length": 217.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.981651376146789}
{"step": 460096, "time": 21498.17723107338, "eval_episode/length": 260.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9731800766283525}
{"step": 460096, "time": 21499.991289138794, "eval_episode/length": 266.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 460096, "time": 21501.621403694153, "eval_episode/length": 268.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9702602230483272}
{"step": 460112, "time": 21502.172983646393, "episode/length": 178.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 460360, "time": 21511.607120990753, "episode/length": 290.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 460552, "time": 21519.537548542023, "episode/length": 149.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 460640, "time": 21524.195716142654, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 460744, "time": 21528.99832057953, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 460816, "time": 21533.08788061142, "episode/length": 235.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 461032, "time": 21541.645946979523, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 461440, "time": 21556.77006340027, "episode/length": 204.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 461736, "time": 21567.942735910416, "episode/length": 136.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 461752, "time": 21570.010476350784, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 462064, "time": 21581.958370923996, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 462248, "time": 21589.450691223145, "episode/length": 211.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 462336, "time": 21594.135627508163, "episode/length": 198.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 462448, "time": 21599.472764015198, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 462568, "time": 21604.79244852066, "episode/length": 275.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 462872, "time": 21616.43092942238, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9832402234636871, "episode/intrinsic_return": 0.0}
{"step": 463024, "time": 21623.950776338577, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 463296, "time": 21635.042342424393, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 463504, "time": 21643.417448043823, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 463592, "time": 21647.673446416855, "episode/length": 156.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 463616, "time": 21650.26261138916, "episode/length": 145.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 463776, "time": 21657.092408895493, "episode/length": 112.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.0}
{"step": 463976, "time": 21665.072944879532, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 464048, "time": 21669.18831062317, "episode/length": 93.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.0}
{"step": 464080, "time": 21671.801165103912, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 464496, "time": 21687.372102975845, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 464880, "time": 21701.88740181923, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 465048, "time": 21708.754353761673, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 465264, "time": 21717.895545244217, "episode/length": 160.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 465352, "time": 21722.053500652313, "episode/length": 216.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 465568, "time": 21730.881307840347, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 465600, "time": 21733.484087467194, "episode/length": 227.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 465680, "time": 21737.66382932663, "episode/length": 51.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 465728, "time": 21740.76861667633, "episode/length": 209.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 465848, "time": 21746.081141471863, "episode/length": 168.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 466200, "time": 21759.295981168747, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 466272, "time": 21763.502385616302, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 466768, "time": 21781.859833955765, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 466880, "time": 21787.64944767952, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 466944, "time": 21792.042542934418, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 467160, "time": 21801.914216041565, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 467400, "time": 21811.510986328125, "episode/length": 193.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 467544, "time": 21817.702730178833, "episode/length": 242.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 467640, "time": 21822.442718029022, "episode/length": 170.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 467672, "time": 21825.08463191986, "episode/length": 63.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 467824, "time": 21831.874831438065, "episode/length": 202.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 468160, "time": 21844.885759830475, "episode/length": 151.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 468504, "time": 21858.392097711563, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 468536, "time": 21861.36037659645, "episode/length": 220.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 468800, "time": 21872.587397813797, "episode/length": 156.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 469016, "time": 21881.751811027527, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 469056, "time": 21885.24376130104, "episode/length": 206.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 469560, "time": 21904.368332624435, "episode/length": 235.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 469792, "time": 21914.558506011963, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 469928, "time": 21920.958962202072, "episode/length": 220.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 470072, "time": 21928.035872220993, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 21954.765005350113, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 470080, "time": 21957.10728287697, "eval_episode/length": 176.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 470080, "time": 21958.65553832054, "eval_episode/length": 178.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9608938547486033}
{"step": 470080, "time": 21960.51096868515, "eval_episode/length": 185.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 470080, "time": 21962.86834216118, "eval_episode/length": 207.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 470080, "time": 21964.790937900543, "eval_episode/length": 215.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 470080, "time": 21966.475030183792, "eval_episode/length": 40.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.975609756097561}
{"step": 470080, "time": 21969.098538160324, "eval_episode/length": 247.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9959677419354839}
{"step": 470216, "time": 21973.378239154816, "episode/length": 81.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 470272, "time": 21977.059190034866, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 470328, "time": 21980.275101184845, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 470352, "time": 21982.82695889473, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 470632, "time": 21993.441251516342, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 471328, "time": 22018.176931142807, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 471504, "time": 22025.493537187576, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9626168224299065, "episode/intrinsic_return": 0.0}
{"step": 471664, "time": 22032.294100522995, "episode/length": 41.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 471784, "time": 22037.57781457901, "episode/length": 195.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 471952, "time": 22045.035921812057, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 471992, "time": 22047.879014253616, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 472104, "time": 22053.080492258072, "episode/length": 271.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 472320, "time": 22062.11164212227, "episode/length": 40.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 472368, "time": 22065.276409864426, "episode/length": 254.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 472552, "time": 22072.665894031525, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 473048, "time": 22090.931859493256, "episode/length": 172.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 473064, "time": 22093.38101053238, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 473424, "time": 22108.12339067459, "episode/length": 239.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 473600, "time": 22116.122668504715, "episode/length": 186.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 473720, "time": 22121.977796792984, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 473752, "time": 22125.24432182312, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9688888888888889, "episode/intrinsic_return": 0.0}
{"step": 474192, "time": 22142.460761785507, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 474200, "time": 22144.54794859886, "episode/length": 234.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 474376, "time": 22152.43622660637, "episode/length": 165.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 474480, "time": 22157.59193468094, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 474744, "time": 22167.654343128204, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 475280, "time": 22188.569205760956, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 475392, "time": 22193.937334775925, "episode/length": 223.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 475536, "time": 22201.025278806686, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 475632, "time": 22206.32550740242, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 475880, "time": 22216.664703130722, "episode/length": 141.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 476040, "time": 22224.123162269592, "episode/length": 230.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 476064, "time": 22227.255546808243, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 476536, "time": 22245.09631419182, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 476728, "time": 22252.943036079407, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 476944, "time": 22261.869203805923, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 477224, "time": 22272.42051267624, "episode/length": 342.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941690962099126, "episode/intrinsic_return": 0.0}
{"step": 477320, "time": 22277.14430642128, "episode/length": 210.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 477392, "time": 22281.35781121254, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 477504, "time": 22286.77050948143, "episode/length": 179.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 477616, "time": 22292.04736971855, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 478248, "time": 22314.32719016075, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 478368, "time": 22320.185642004013, "episode/length": 228.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 478600, "time": 22329.23642230034, "episode/length": 171.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 478912, "time": 22341.46926665306, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 478944, "time": 22344.11489224434, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 479120, "time": 22351.615641355515, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 479120, "time": 22351.640644788742, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 479224, "time": 22358.171631336212, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 479225, "time": 22360.72984480858, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.600724612965303, "train/action_min": 0.0, "train/action_std": 3.447589891798356, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04468560273594716, "train/actor_opt_grad_steps": 29175.0, "train/actor_opt_loss": -5.951220078503384, "train/adv_mag": 0.5869840482140288, "train/adv_max": 0.5635826975545463, "train/adv_mean": 0.002873246940035552, "train/adv_min": -0.4453640093698221, "train/adv_std": 0.0653125974623596, "train/cont_avg": 0.9949161305147058, "train/cont_loss_mean": 0.0001834796122562419, "train/cont_loss_std": 0.005397082303119305, "train/cont_neg_acc": 0.9958858551347957, "train/cont_neg_loss": 0.01590995617667592, "train/cont_pos_acc": 0.9999711027040201, "train/cont_pos_loss": 8.834536081949468e-05, "train/cont_pred": 0.9949238125015708, "train/cont_rate": 0.9949161305147058, "train/dyn_loss_mean": 14.024618036606732, "train/dyn_loss_std": 8.999742430799147, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7958385080975645, "train/extr_critic_critic_opt_grad_steps": 29175.0, "train/extr_critic_critic_opt_loss": 15879.675551470587, "train/extr_critic_mag": 6.116730178103728, "train/extr_critic_max": 6.116730178103728, "train/extr_critic_mean": 1.4249784275889397, "train/extr_critic_min": -0.2456978927640354, "train/extr_critic_std": 1.4007432697450413, "train/extr_return_normed_mag": 1.6854311017429127, "train/extr_return_normed_max": 1.6854311017429127, "train/extr_return_normed_mean": 0.3465010906186174, "train/extr_return_normed_min": -0.11183751453919445, "train/extr_return_normed_std": 0.32755073915947885, "train/extr_return_rate": 0.6377398663145655, "train/extr_return_raw_mag": 7.301264605101417, "train/extr_return_raw_max": 7.301264605101417, "train/extr_return_raw_mean": 1.4375579326468355, "train/extr_return_raw_min": -0.5693423813756775, "train/extr_return_raw_std": 1.43453347595299, "train/extr_reward_mag": 1.014244325020734, "train/extr_reward_max": 1.014244325020734, "train/extr_reward_mean": 0.031948714900542706, "train/extr_reward_min": -0.4027950553333058, "train/extr_reward_std": 0.16811676416546106, "train/image_loss_mean": 6.396013421170852, "train/image_loss_std": 10.540883004665375, "train/model_loss_mean": 14.865074487293468, "train/model_loss_std": 14.200120652423186, "train/model_opt_grad_norm": 57.08961169859942, "train/model_opt_grad_steps": 29146.70588235294, "train/model_opt_loss": 19103.75885368796, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1295.9558823529412, "train/policy_entropy_mag": 2.4206767415299133, "train/policy_entropy_max": 2.4206767415299133, "train/policy_entropy_mean": 0.6024898159153321, "train/policy_entropy_min": 0.07937513768453808, "train/policy_entropy_std": 0.61132927786778, "train/policy_logprob_mag": 7.4383834565387055, "train/policy_logprob_max": -0.009455693221431883, "train/policy_logprob_mean": -0.6026661619544029, "train/policy_logprob_min": -7.4383834565387055, "train/policy_logprob_std": 1.1281886556569267, "train/policy_randomness_mag": 0.8543926622061169, "train/policy_randomness_max": 0.8543926622061169, "train/policy_randomness_mean": 0.21265246609554572, "train/policy_randomness_min": 0.02801594035426045, "train/policy_randomness_std": 0.21577240822508054, "train/post_ent_mag": 59.39071846008301, "train/post_ent_max": 59.39071846008301, "train/post_ent_mean": 41.81777443605311, "train/post_ent_min": 20.761887851883383, "train/post_ent_std": 7.330184270353878, "train/prior_ent_mag": 68.38072614108815, "train/prior_ent_max": 68.38072614108815, "train/prior_ent_mean": 55.94051582673017, "train/prior_ent_min": 38.99353966993444, "train/prior_ent_std": 4.4974785184159, "train/rep_loss_mean": 14.024618036606732, "train/rep_loss_std": 8.999742430799147, "train/reward_avg": 0.027211626731407118, "train/reward_loss_mean": 0.05410694091252106, "train/reward_loss_std": 0.2429148420034086, "train/reward_max_data": 1.0102941201013678, "train/reward_max_pred": 1.0056880484609043, "train/reward_neg_acc": 0.9932206316905863, "train/reward_neg_loss": 0.02887458587750135, "train/reward_pos_acc": 0.9736504169071422, "train/reward_pos_loss": 0.8246414648259387, "train/reward_pred": 0.02660270209205063, "train/reward_rate": 0.03186753216911765, "train_stats/sum_log_reward": 6.506779650510368, "train_stats/max_log_achievement_collect_drink": 3.4745762711864407, "train_stats/max_log_achievement_collect_sapling": 2.8559322033898304, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 9.042372881355933, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.8813559322033898, "train_stats/max_log_achievement_eat_cow": 0.1440677966101695, "train_stats/max_log_achievement_make_wood_pickaxe": 0.23728813559322035, "train_stats/max_log_achievement_make_wood_sword": 1.4661016949152543, "train_stats/max_log_achievement_place_plant": 2.711864406779661, "train_stats/max_log_achievement_place_table": 2.7457627118644066, "train_stats/max_log_achievement_wake_up": 1.305084745762712, "train_stats/mean_log_entropy": 0.5709467148881847, "eval_stats/sum_log_reward": 6.412500023841858, "eval_stats/max_log_achievement_collect_drink": 3.75, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 9.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.9375, "eval_stats/max_log_achievement_place_plant": 2.5, "eval_stats/max_log_achievement_place_table": 2.6875, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 2.9484173865057528e-05, "report/cont_loss_std": 0.00068604142870754, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0008247339865192771, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.2432701371144503e-05, "report/cont_pred": 0.9911962151527405, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 13.301861763000488, "report/dyn_loss_std": 9.412725448608398, "report/image_loss_mean": 6.525003910064697, "report/image_loss_std": 10.904681205749512, "report/model_loss_mean": 14.560810089111328, "report/model_loss_std": 14.61809253692627, "report/post_ent_mag": 61.51631164550781, "report/post_ent_max": 61.51631164550781, "report/post_ent_mean": 42.28398895263672, "report/post_ent_min": 20.370338439941406, "report/post_ent_std": 7.527498722076416, "report/prior_ent_mag": 68.42345428466797, "report/prior_ent_max": 68.42345428466797, "report/prior_ent_mean": 55.3724365234375, "report/prior_ent_min": 34.99358367919922, "report/prior_ent_std": 5.192594051361084, "report/rep_loss_mean": 13.301861763000488, "report/rep_loss_std": 9.412725448608398, "report/reward_avg": 0.0322265625, "report/reward_loss_mean": 0.054659586399793625, "report/reward_loss_std": 0.20387808978557587, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012273788452148, "report/reward_neg_acc": 0.9949238896369934, "report/reward_neg_loss": 0.025292081758379936, "report/reward_pos_acc": 0.9743589758872986, "report/reward_pos_loss": 0.7963773608207703, "report/reward_pred": 0.030513953417539597, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 9.719517038320191e-06, "eval/cont_loss_std": 0.00027256167959421873, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.002922046696767211, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.162237936114252e-06, "eval/cont_pred": 0.9970777630805969, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.50527000427246, "eval/dyn_loss_std": 10.614387512207031, "eval/image_loss_mean": 12.592652320861816, "eval/image_loss_std": 19.389385223388672, "eval/model_loss_mean": 23.802091598510742, "eval/model_loss_std": 23.476930618286133, "eval/post_ent_mag": 56.787925720214844, "eval/post_ent_max": 56.787925720214844, "eval/post_ent_mean": 40.44495391845703, "eval/post_ent_min": 20.959823608398438, "eval/post_ent_std": 7.22901725769043, "eval/prior_ent_mag": 68.42345428466797, "eval/prior_ent_max": 68.42345428466797, "eval/prior_ent_mean": 56.74666976928711, "eval/prior_ent_min": 38.995330810546875, "eval/prior_ent_std": 4.460279941558838, "eval/rep_loss_mean": 18.50527000427246, "eval/rep_loss_std": 10.614387512207031, "eval/reward_avg": 0.03945312649011612, "eval/reward_loss_mean": 0.10626862943172455, "eval/reward_loss_std": 0.6105586886405945, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017430782318115, "eval/reward_neg_acc": 0.9908162951469421, "eval/reward_neg_loss": 0.03597321733832359, "eval/reward_pos_acc": 0.8181818723678589, "eval/reward_pos_loss": 1.6719390153884888, "eval/reward_pred": 0.0358881875872612, "eval/reward_rate": 0.04296875, "replay/size": 478721.0, "replay/inserts": 21728.0, "replay/samples": 21728.0, "replay/insert_wait_avg": 1.3744071762410812e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.976139095289542e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 94848.0, "eval_replay/inserts": 4136.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2530233689387486e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.1473770141602, "timer/env.step_count": 2716.0, "timer/env.step_total": 271.07026958465576, "timer/env.step_frac": 0.2707596062360974, "timer/env.step_avg": 0.09980495934633865, "timer/env.step_min": 0.02227497100830078, "timer/env.step_max": 3.3315184116363525, "timer/replay._sample_count": 21728.0, "timer/replay._sample_total": 11.33073377609253, "timer/replay._sample_frac": 0.011317748052125464, "timer/replay._sample_avg": 0.0005214807518452011, "timer/replay._sample_min": 0.0004227161407470703, "timer/replay._sample_max": 0.01116490364074707, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3233.0, "timer/agent.policy_total": 51.57102155685425, "timer/agent.policy_frac": 0.0515119179662245, "timer/agent.policy_avg": 0.015951444960363208, "timer/agent.policy_min": 0.009252548217773438, "timer/agent.policy_max": 0.11089324951171875, "timer/dataset_train_count": 1358.0, "timer/dataset_train_total": 0.1459975242614746, "timer/dataset_train_frac": 0.00014583020203968395, "timer/dataset_train_avg": 0.00010750922257840546, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0010879039764404297, "timer/agent.train_count": 1358.0, "timer/agent.train_total": 608.5873384475708, "timer/agent.train_frac": 0.6078898595955299, "timer/agent.train_avg": 0.4481497337610978, "timer/agent.train_min": 0.43444299697875977, "timer/agent.train_max": 1.492699146270752, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47475504875183105, "timer/agent.report_frac": 0.0004742109500079289, "timer/agent.report_avg": 0.23737752437591553, "timer/agent.report_min": 0.23064208030700684, "timer/agent.report_max": 0.24411296844482422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.524550981921233e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 21.702796378203804}
{"step": 479744, "time": 22378.17182993889, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 479816, "time": 22381.888823986053, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 22410.888785362244, "eval_episode/length": 40.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.975609756097561}
{"step": 480064, "time": 22418.379747629166, "eval_episode/length": 159.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 480064, "time": 22421.393157482147, "eval_episode/length": 181.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 480064, "time": 22421.403237104416, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 480064, "time": 22425.917900800705, "eval_episode/length": 188.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 480064, "time": 22428.62158203125, "eval_episode/length": 200.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 480064, "time": 22430.781516313553, "eval_episode/length": 205.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.970873786407767}
{"step": 480064, "time": 22432.94779443741, "eval_episode/length": 211.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9669811320754716}
{"step": 480136, "time": 22435.18698334694, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 480192, "time": 22439.23522877693, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 480568, "time": 22453.009348869324, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 480632, "time": 22456.605053901672, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 480640, "time": 22458.581053495407, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 481072, "time": 22474.345084428787, "episode/length": 265.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 481296, "time": 22483.36756181717, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 481312, "time": 22485.392731428146, "episode/length": 84.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 481480, "time": 22492.293847322464, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 481600, "time": 22498.13164448738, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 481688, "time": 22502.407955884933, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 482464, "time": 22529.898493766785, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 482520, "time": 22533.094111442566, "episode/length": 150.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 482528, "time": 22535.068235874176, "episode/length": 235.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 482616, "time": 22539.246578216553, "episode/length": 255.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 483160, "time": 22559.256329536438, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 483360, "time": 22569.839198112488, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 483480, "time": 22575.81213450432, "episode/length": 234.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 484168, "time": 22600.769877910614, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 484432, "time": 22611.286217212677, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 484504, "time": 22615.0184135437, "episode/length": 142.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 484608, "time": 22620.465921640396, "episode/length": 260.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 484712, "time": 22625.196938037872, "episode/length": 426.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953161592505855, "episode/intrinsic_return": 0.0}
{"step": 485056, "time": 22638.30167722702, "episode/length": 236.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 485344, "time": 22649.46450161934, "episode/length": 232.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 485840, "time": 22667.32816028595, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 485968, "time": 22673.183403730392, "episode/length": 429.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9930232558139535, "episode/intrinsic_return": 0.0}
{"step": 486080, "time": 22679.105715751648, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 486208, "time": 22685.396765470505, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 486424, "time": 22694.140790700912, "episode/length": 213.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 486520, "time": 22698.81607580185, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 486752, "time": 22708.32407951355, "episode/length": 322.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9907120743034056, "episode/intrinsic_return": 0.0}
{"step": 487224, "time": 22725.163575410843, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 487328, "time": 22730.3805372715, "episode/length": 169.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 487576, "time": 22739.84681749344, "episode/length": 216.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 487608, "time": 22742.51161789894, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 487776, "time": 22749.820326566696, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 487848, "time": 22753.499281167984, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 487936, "time": 22758.12535047531, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 488368, "time": 22773.89977478981, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 488864, "time": 22791.803789377213, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 489088, "time": 22800.88266992569, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9567567567567568, "episode/intrinsic_return": 0.0}
{"step": 489232, "time": 22807.11447429657, "episode/length": 237.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 489232, "time": 22807.12428855896, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 489240, "time": 22810.713508844376, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 489360, "time": 22816.441418409348, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 489520, "time": 22823.204967975616, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 489896, "time": 22837.001712560654, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 22864.10077214241, "eval_episode/length": 166.0, "eval_episode/score": 5.099999964237213, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 490048, "time": 22866.621845960617, "eval_episode/length": 173.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 490048, "time": 22868.157722711563, "eval_episode/length": 175.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 490048, "time": 22869.81565260887, "eval_episode/length": 178.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9608938547486033}
{"step": 490048, "time": 22872.657699346542, "eval_episode/length": 208.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9712918660287081}
{"step": 490048, "time": 22874.76777768135, "eval_episode/length": 223.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 490048, "time": 22877.506707191467, "eval_episode/length": 253.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9724409448818898}
{"step": 490048, "time": 22879.357954263687, "eval_episode/length": 260.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9808429118773946}
{"step": 490192, "time": 22884.089013814926, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 490512, "time": 22896.177437067032, "episode/length": 159.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 490552, "time": 22898.945588827133, "episode/length": 164.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 490736, "time": 22906.755319833755, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 490808, "time": 22910.41060566902, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 490960, "time": 22917.428517580032, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 491112, "time": 22923.91303062439, "episode/length": 233.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 491256, "time": 22930.227843284607, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 491744, "time": 22949.880962610245, "episode/length": 148.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 491904, "time": 22957.268115520477, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 491944, "time": 22960.33645749092, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 492016, "time": 22964.474566936493, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 492096, "time": 22968.638315677643, "episode/length": 43.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 492384, "time": 22979.73531961441, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 492568, "time": 22987.18717122078, "episode/length": 219.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 492800, "time": 22996.65562105179, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 492816, "time": 22998.640414237976, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 493312, "time": 23016.563289165497, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 493360, "time": 23019.66775560379, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 493504, "time": 23025.977727413177, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 493720, "time": 23034.35131907463, "episode/length": 143.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 494080, "time": 23047.97291779518, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 494144, "time": 23051.660145998, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 494152, "time": 23053.272477388382, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 494408, "time": 23063.198074817657, "episode/length": 312.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.0}
{"step": 494528, "time": 23069.01388692856, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 494656, "time": 23074.748391389847, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 494976, "time": 23087.031153202057, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 495176, "time": 23095.62348008156, "episode/length": 208.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9856459330143541, "episode/intrinsic_return": 0.0}
{"step": 495464, "time": 23106.763885974884, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 495536, "time": 23110.868624210358, "episode/length": 44.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 495592, "time": 23114.065460920334, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 495976, "time": 23128.83539223671, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 496008, "time": 23131.954827785492, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 496040, "time": 23135.021248579025, "episode/length": 244.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 496200, "time": 23142.31048154831, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 496384, "time": 23150.0504693985, "episode/length": 50.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 496416, "time": 23152.652768611908, "episode/length": 250.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 496928, "time": 23171.062086343765, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 497040, "time": 23176.251450777054, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 497040, "time": 23176.26105952263, "episode/length": 180.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 497328, "time": 23189.15892314911, "episode/length": 49.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 497576, "time": 23198.688884735107, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 497608, "time": 23201.260863542557, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 497704, "time": 23205.970239162445, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 497704, "time": 23205.979068994522, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 497792, "time": 23212.385865211487, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 498312, "time": 23230.873595237732, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 498472, "time": 23237.63727259636, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 498544, "time": 23241.750710487366, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 499336, "time": 23269.194077014923, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 499344, "time": 23271.291486263275, "episode/length": 220.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 499456, "time": 23276.627721309662, "episode/length": 207.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 499472, "time": 23278.723737716675, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 499688, "time": 23287.219923973083, "episode/length": 171.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 23325.479528427124, "eval_episode/length": 160.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 500032, "time": 23327.820529937744, "eval_episode/length": 169.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 500032, "time": 23330.178689956665, "eval_episode/length": 175.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9659090909090909}
{"step": 500032, "time": 23332.25207710266, "eval_episode/length": 176.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 500032, "time": 23334.654506206512, "eval_episode/length": 185.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.978494623655914}
{"step": 500032, "time": 23338.073940753937, "eval_episode/length": 214.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 500032, "time": 23340.11885547638, "eval_episode/length": 215.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 500032, "time": 23343.806327581406, "eval_episode/length": 40.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.975609756097561}
{"step": 500144, "time": 23347.638788461685, "episode/length": 304.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 500184, "time": 23350.820756673813, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 500296, "time": 23356.761919498444, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 500329, "time": 23360.925136089325, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.348829789595171, "train/action_min": 0.0, "train/action_std": 3.0182604031129316, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04460670719995643, "train/actor_opt_grad_steps": 30515.0, "train/actor_opt_loss": -0.9791754330437856, "train/adv_mag": 0.6199171789216272, "train/adv_max": 0.5977799953384832, "train/adv_mean": 0.004701840105994823, "train/adv_min": -0.44207040514006757, "train/adv_std": 0.06735646194129279, "train/cont_avg": 0.9946215080492424, "train/cont_loss_mean": 0.0002325231702601608, "train/cont_loss_std": 0.007134798785934253, "train/cont_neg_acc": 0.9872561502092667, "train/cont_neg_loss": 0.03631717929737401, "train/cont_pos_acc": 0.9999925507740541, "train/cont_pos_loss": 3.0121677603852614e-05, "train/cont_pred": 0.9946715849818606, "train/cont_rate": 0.9946215080492424, "train/dyn_loss_mean": 13.916230382341327, "train/dyn_loss_std": 8.962308847542966, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8490392335436561, "train/extr_critic_critic_opt_grad_steps": 30515.0, "train/extr_critic_critic_opt_loss": 16101.389145359848, "train/extr_critic_mag": 6.346458868546919, "train/extr_critic_max": 6.346458868546919, "train/extr_critic_mean": 1.4882834874319308, "train/extr_critic_min": -0.22830334667003516, "train/extr_critic_std": 1.4203934100541202, "train/extr_return_normed_mag": 1.7074757398981038, "train/extr_return_normed_max": 1.7074757398981038, "train/extr_return_normed_mean": 0.35206253702441853, "train/extr_return_normed_min": -0.11978840652966138, "train/extr_return_normed_std": 0.32956352762200614, "train/extr_return_rate": 0.6434506536884741, "train/extr_return_raw_mag": 7.50572694792892, "train/extr_return_raw_max": 7.50572694792892, "train/extr_return_raw_mean": 1.5091063443458441, "train/extr_return_raw_min": -0.5778851803730835, "train/extr_return_raw_std": 1.4579241040981177, "train/extr_reward_mag": 1.016874049649094, "train/extr_reward_max": 1.016874049649094, "train/extr_reward_mean": 0.03342777448988548, "train/extr_reward_min": -0.4080067918156133, "train/extr_reward_std": 0.1714446061488354, "train/image_loss_mean": 6.40423152663491, "train/image_loss_std": 10.491845102021188, "train/model_loss_mean": 14.810787945082694, "train/model_loss_std": 14.105562043912483, "train/model_opt_grad_norm": 60.80388967918627, "train/model_opt_grad_steps": 30485.0, "train/model_opt_loss": 11935.144091057055, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 804.9242424242424, "train/policy_entropy_mag": 2.318675180276235, "train/policy_entropy_max": 2.318675180276235, "train/policy_entropy_mean": 0.5007376065759948, "train/policy_entropy_min": 0.0793751094377402, "train/policy_entropy_std": 0.4838077304038135, "train/policy_logprob_mag": 7.4383835539673315, "train/policy_logprob_max": -0.009455676381052895, "train/policy_logprob_mean": -0.5012115000775366, "train/policy_logprob_min": -7.4383835539673315, "train/policy_logprob_std": 1.0571511514259107, "train/policy_randomness_mag": 0.818390587514097, "train/policy_randomness_max": 0.818390587514097, "train/policy_randomness_mean": 0.17673840068958022, "train/policy_randomness_min": 0.028015930403136845, "train/policy_randomness_std": 0.17076289755376903, "train/post_ent_mag": 59.86448793700247, "train/post_ent_max": 59.86448793700247, "train/post_ent_mean": 42.02938432404489, "train/post_ent_min": 20.860572865515046, "train/post_ent_std": 7.412349812912218, "train/prior_ent_mag": 68.55511116259026, "train/prior_ent_max": 68.55511116259026, "train/prior_ent_mean": 56.01580434856993, "train/prior_ent_min": 38.77412790240663, "train/prior_ent_std": 4.467547351663763, "train/rep_loss_mean": 13.916230382341327, "train/rep_loss_std": 8.962308847542966, "train/reward_avg": 0.028639174793197802, "train/reward_loss_mean": 0.05658574261222825, "train/reward_loss_std": 0.2513651940407175, "train/reward_max_data": 1.0128787909493302, "train/reward_max_pred": 1.0095654653780388, "train/reward_neg_acc": 0.9931732127160737, "train/reward_neg_loss": 0.029430808562954717, "train/reward_pos_acc": 0.9701524534911821, "train/reward_pos_loss": 0.8351942802017386, "train/reward_pred": 0.027851776135238735, "train/reward_rate": 0.03350645123106061, "train_stats/sum_log_reward": 6.479629587244104, "train_stats/max_log_achievement_collect_drink": 4.425925925925926, "train_stats/max_log_achievement_collect_sapling": 2.0833333333333335, "train_stats/max_log_achievement_collect_stone": 0.18518518518518517, "train_stats/max_log_achievement_collect_wood": 10.62962962962963, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.6018518518518519, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_make_wood_pickaxe": 2.5833333333333335, "train_stats/max_log_achievement_make_wood_sword": 0.49074074074074076, "train_stats/max_log_achievement_place_plant": 2.037037037037037, "train_stats/max_log_achievement_place_table": 3.0, "train_stats/max_log_achievement_wake_up": 1.5185185185185186, "train_stats/mean_log_entropy": 0.4845819702302968, "eval_stats/sum_log_reward": 6.4749999443689985, "eval_stats/max_log_achievement_collect_drink": 3.4583333333333335, "eval_stats/max_log_achievement_collect_sapling": 2.3333333333333335, "eval_stats/max_log_achievement_collect_stone": 0.20833333333333334, "eval_stats/max_log_achievement_collect_wood": 10.666666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.7916666666666666, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.875, "eval_stats/max_log_achievement_make_wood_sword": 0.5833333333333334, "eval_stats/max_log_achievement_place_plant": 2.3333333333333335, "eval_stats/max_log_achievement_place_table": 2.9166666666666665, "eval_stats/max_log_achievement_wake_up": 1.2083333333333333, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_coal": 0.012987012987012988, "eval_stats/max_log_achievement_collect_coal": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 9.91741762845777e-06, "report/cont_loss_std": 0.00019392097601667047, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003124354116152972, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.835187716409564e-06, "report/cont_pred": 0.9931584596633911, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 11.854925155639648, "report/dyn_loss_std": 8.745491027832031, "report/image_loss_mean": 5.6881866455078125, "report/image_loss_std": 7.992567539215088, "report/model_loss_mean": 12.848276138305664, "report/model_loss_std": 11.630120277404785, "report/post_ent_mag": 60.165321350097656, "report/post_ent_max": 60.165321350097656, "report/post_ent_mean": 43.60747528076172, "report/post_ent_min": 21.684072494506836, "report/post_ent_std": 6.9715752601623535, "report/prior_ent_mag": 68.7597885131836, "report/prior_ent_max": 68.7597885131836, "report/prior_ent_mean": 55.898101806640625, "report/prior_ent_min": 37.762847900390625, "report/prior_ent_std": 4.866762638092041, "report/rep_loss_mean": 11.854925155639648, "report/rep_loss_std": 8.745491027832031, "report/reward_avg": 0.02041015774011612, "report/reward_loss_mean": 0.047124460339546204, "report/reward_loss_std": 0.18378359079360962, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.000596523284912, "report/reward_neg_acc": 0.9929859638214111, "report/reward_neg_loss": 0.02998504228889942, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7050143480300903, "report/reward_pred": 0.021514881402254105, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 3.2447619560116436e-06, "eval/cont_loss_std": 3.500099410302937e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0001474323944421485, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.679320232346072e-06, "eval/cont_pred": 0.9960917234420776, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.051475524902344, "eval/dyn_loss_std": 9.823467254638672, "eval/image_loss_mean": 12.57247543334961, "eval/image_loss_std": 13.943286895751953, "eval/model_loss_mean": 24.10541534423828, "eval/model_loss_std": 17.590986251831055, "eval/post_ent_mag": 57.434722900390625, "eval/post_ent_max": 57.434722900390625, "eval/post_ent_mean": 39.51340866088867, "eval/post_ent_min": 22.61236000061035, "eval/post_ent_std": 6.812117099761963, "eval/prior_ent_mag": 68.7597885131836, "eval/prior_ent_max": 68.7597885131836, "eval/prior_ent_mean": 56.416656494140625, "eval/prior_ent_min": 41.810218811035156, "eval/prior_ent_std": 4.096915245056152, "eval/rep_loss_mean": 19.051475524902344, "eval/rep_loss_std": 9.823467254638672, "eval/reward_avg": 0.03076171875, "eval/reward_loss_mean": 0.102052241563797, "eval/reward_loss_std": 0.5997911691665649, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0027549266815186, "eval/reward_neg_acc": 0.9929220676422119, "eval/reward_neg_loss": 0.03585837408900261, "eval/reward_pos_acc": 0.8285714387893677, "eval/reward_pos_loss": 1.9725018739700317, "eval/reward_pred": 0.022700145840644836, "eval/reward_rate": 0.0341796875, "replay/size": 499825.0, "replay/inserts": 21104.0, "replay/samples": 21104.0, "replay/insert_wait_avg": 1.3599032430236677e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.580199329124607e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5832.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3021856996094086e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1853506565094, "timer/env.step_count": 2638.0, "timer/env.step_total": 243.82531261444092, "timer/env.step_frac": 0.2437801278077078, "timer/env.step_avg": 0.09242809424353332, "timer/env.step_min": 0.022270917892456055, "timer/env.step_max": 3.5730183124542236, "timer/replay._sample_count": 21104.0, "timer/replay._sample_total": 10.968712329864502, "timer/replay._sample_frac": 0.010966679648591908, "timer/replay._sample_avg": 0.0005197456562672717, "timer/replay._sample_min": 0.0004150867462158203, "timer/replay._sample_max": 0.02477097511291504, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3367.0, "timer/agent.policy_total": 54.27744174003601, "timer/agent.policy_frac": 0.054267383244924514, "timer/agent.policy_avg": 0.016120416317207013, "timer/agent.policy_min": 0.009280204772949219, "timer/agent.policy_max": 0.10786271095275879, "timer/dataset_train_count": 1319.0, "timer/dataset_train_total": 0.14244580268859863, "timer/dataset_train_frac": 0.00014241940515835285, "timer/dataset_train_avg": 0.00010799530150765628, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0010790824890136719, "timer/agent.train_count": 1319.0, "timer/agent.train_total": 590.902272939682, "timer/agent.train_frac": 0.5907927691120661, "timer/agent.train_avg": 0.44799262542811374, "timer/agent.train_min": 0.4349963665008545, "timer/agent.train_max": 1.5634417533874512, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4782564640045166, "timer/agent.report_frac": 0.00047816783528232534, "timer/agent.report_avg": 0.2391282320022583, "timer/agent.report_min": 0.23161649703979492, "timer/agent.report_max": 0.24663996696472168, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0273548323841744e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 21.099813952425414}
{"step": 500696, "time": 23372.920697927475, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 500808, "time": 23378.085342884064, "episode/length": 139.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 500816, "time": 23380.145097970963, "episode/length": 167.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 500832, "time": 23382.182970762253, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 501016, "time": 23389.514241695404, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 501928, "time": 23421.343574523926, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 502040, "time": 23426.624628067017, "episode/length": 231.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 502072, "time": 23429.24585533142, "episode/length": 240.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 502144, "time": 23433.488070249557, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 502344, "time": 23441.417673826218, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 502368, "time": 23444.122740268707, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 502576, "time": 23452.53833937645, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 502680, "time": 23457.374069213867, "episode/length": 207.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 503456, "time": 23484.61650276184, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 503576, "time": 23491.556638002396, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 503672, "time": 23496.3802857399, "episode/length": 190.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 503744, "time": 23501.184856653214, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 503760, "time": 23503.802109241486, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 503832, "time": 23508.040095806122, "episode/length": 182.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 503952, "time": 23514.07420873642, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 504392, "time": 23529.915098428726, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 504800, "time": 23545.409296035767, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 505032, "time": 23555.284565925598, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 505184, "time": 23562.075810194016, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 505184, "time": 23562.08497619629, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 505376, "time": 23571.720105409622, "episode/length": 201.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 505496, "time": 23577.025518655777, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 505592, "time": 23581.74738407135, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 506000, "time": 23596.864514112473, "episode/length": 149.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 506200, "time": 23604.851438760757, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 506400, "time": 23613.434118509293, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 506472, "time": 23617.71704030037, "episode/length": 160.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 506696, "time": 23627.26809310913, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 506760, "time": 23631.340137004852, "episode/length": 215.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 507312, "time": 23652.352845430374, "episode/length": 241.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 507456, "time": 23659.116837739944, "episode/length": 181.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 508000, "time": 23681.213737249374, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 508016, "time": 23683.770275592804, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 508072, "time": 23687.251824617386, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 508088, "time": 23689.336342573166, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 508096, "time": 23691.39208841324, "episode/length": 166.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 508744, "time": 23714.00776720047, "episode/length": 393.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974619289340102, "episode/intrinsic_return": 0.0}
{"step": 509096, "time": 23727.872979164124, "episode/length": 204.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 509192, "time": 23732.70515370369, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9872340425531915, "episode/intrinsic_return": 0.0}
{"step": 509584, "time": 23747.845484972, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 509640, "time": 23751.620178937912, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 509704, "time": 23755.805366039276, "episode/length": 210.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 509736, "time": 23759.101217269897, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 509808, "time": 23763.318532705307, "episode/length": 213.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 23790.518169403076, "eval_episode/length": 142.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9790209790209791}
{"step": 510016, "time": 23792.240223169327, "eval_episode/length": 147.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.972972972972973}
{"step": 510016, "time": 23794.293409585953, "eval_episode/length": 157.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 510016, "time": 23796.02751684189, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9570552147239264}
{"step": 510016, "time": 23797.724493026733, "eval_episode/length": 165.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 510016, "time": 23800.771512031555, "eval_episode/length": 200.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 510016, "time": 23803.67377781868, "eval_episode/length": 235.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 510016, "time": 23803.682398557663, "eval_episode/length": 235.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 510240, "time": 23811.238791704178, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 510632, "time": 23826.23718237877, "episode/length": 179.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 510856, "time": 23835.185325860977, "episode/length": 151.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 510976, "time": 23840.994122743607, "episode/length": 234.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 511072, "time": 23845.74187541008, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 511096, "time": 23847.986038446426, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 511128, "time": 23850.699565172195, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 511288, "time": 23857.736349344254, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 511744, "time": 23875.47784590721, "episode/length": 187.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 512232, "time": 23893.911816596985, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 512296, "time": 23898.00861644745, "episode/length": 207.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 512424, "time": 23904.1220266819, "episode/length": 141.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 512512, "time": 23908.8635058403, "episode/length": 172.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 512592, "time": 23913.112510204315, "episode/length": 44.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 512616, "time": 23915.244894504547, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 512784, "time": 23922.69088125229, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 513072, "time": 23933.55998802185, "episode/length": 276.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 513168, "time": 23938.387402534485, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 513448, "time": 23948.860390663147, "episode/length": 143.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 513632, "time": 23956.537814617157, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 514040, "time": 23971.328593492508, "episode/length": 190.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 514072, "time": 23973.959035396576, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 514232, "time": 23980.77549791336, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 514248, "time": 23982.81778693199, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 514456, "time": 23991.181485414505, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 514728, "time": 24001.628675937653, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 514792, "time": 24005.281613111496, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 514832, "time": 24008.355849266052, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 515552, "time": 24033.656195163727, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 515672, "time": 24039.00872707367, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 515744, "time": 24043.104637622833, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 515920, "time": 24050.5544321537, "episode/length": 135.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 515944, "time": 24052.78689312935, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 516480, "time": 24073.762416362762, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 516544, "time": 24077.318906784058, "episode/length": 226.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 517400, "time": 24107.57314825058, "episode/length": 206.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 517480, "time": 24112.50097513199, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 517544, "time": 24116.67408633232, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 517576, "time": 24119.841512441635, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 517728, "time": 24127.295946121216, "episode/length": 271.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 517952, "time": 24136.985753536224, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 518784, "time": 24167.58715057373, "episode/length": 287.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 518880, "time": 24172.80308675766, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 519184, "time": 24185.260097265244, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 519224, "time": 24188.352278232574, "episode/length": 595.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.988255033557047, "episode/intrinsic_return": 0.0}
{"step": 519240, "time": 24190.876764774323, "episode/length": 44.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 519344, "time": 24196.609834432602, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 519424, "time": 24201.27283358574, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 519800, "time": 24215.88491678238, "episode/length": 299.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 24249.559103250504, "eval_episode/length": 187.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 520000, "time": 24252.24115896225, "eval_episode/length": 213.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 520000, "time": 24254.092334270477, "eval_episode/length": 218.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 520000, "time": 24255.649978399277, "eval_episode/length": 219.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9727272727272728}
{"step": 520000, "time": 24257.22696352005, "eval_episode/length": 223.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 520000, "time": 24258.85379433632, "eval_episode/length": 226.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9823788546255506}
{"step": 520000, "time": 24260.81357550621, "eval_episode/length": 233.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 520000, "time": 24262.4303753376, "eval_episode/length": 237.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 520088, "time": 24265.092700004578, "episode/length": 294.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 520376, "time": 24276.15672683716, "episode/length": 148.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 520544, "time": 24283.570497512817, "episode/length": 219.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 520648, "time": 24288.925478696823, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 520888, "time": 24298.759987831116, "episode/length": 192.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 520912, "time": 24301.308529138565, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 521328, "time": 24316.430662870407, "episode/length": 51.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 521376, "time": 24320.013927698135, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 521984, "time": 24342.394781589508, "episode/length": 236.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 522473, "time": 24361.19241833687, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.3695240850033965, "train/action_min": 0.0, "train/action_std": 3.2473999158195825, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044700686158477394, "train/actor_opt_grad_steps": 31865.0, "train/actor_opt_loss": -4.409355260107828, "train/adv_mag": 0.584415936599607, "train/adv_max": 0.5416631836822068, "train/adv_mean": 0.0035689109848834155, "train/adv_min": -0.47666997818843176, "train/adv_std": 0.06537500655521518, "train/cont_avg": 0.9944873754528986, "train/cont_loss_mean": 0.0002585193222529061, "train/cont_loss_std": 0.0075912088760419156, "train/cont_neg_acc": 0.9915286423503489, "train/cont_neg_loss": 0.033424771821810806, "train/cont_pos_acc": 0.9999714670837789, "train/cont_pos_loss": 7.759246625907555e-05, "train/cont_pred": 0.9945265300895857, "train/cont_rate": 0.9944873754528986, "train/dyn_loss_mean": 13.734716491422791, "train/dyn_loss_std": 9.03260324312293, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8352925056132717, "train/extr_critic_critic_opt_grad_steps": 31865.0, "train/extr_critic_critic_opt_loss": 16023.287342900816, "train/extr_critic_mag": 6.548281451930171, "train/extr_critic_max": 6.548281451930171, "train/extr_critic_mean": 1.6460134736869647, "train/extr_critic_min": -0.24537805629813153, "train/extr_critic_std": 1.5099919585214145, "train/extr_return_normed_mag": 1.6779405837473662, "train/extr_return_normed_max": 1.6779405837473662, "train/extr_return_normed_mean": 0.3669516471201095, "train/extr_return_normed_min": -0.10857060573239258, "train/extr_return_normed_std": 0.332746089692565, "train/extr_return_rate": 0.6603218764066696, "train/extr_return_raw_mag": 7.767871217451233, "train/extr_return_raw_max": 7.767871217451233, "train/extr_return_raw_mean": 1.6625816714072572, "train/extr_return_raw_min": -0.5509039336356564, "train/extr_return_raw_std": 1.549921535063481, "train/extr_reward_mag": 1.0185450695563054, "train/extr_reward_max": 1.0185450695563054, "train/extr_reward_mean": 0.03323021462268155, "train/extr_reward_min": -0.36963603030080383, "train/extr_reward_std": 0.17179896855267926, "train/image_loss_mean": 6.477122445037399, "train/image_loss_std": 10.784168533656908, "train/model_loss_mean": 14.773465453714564, "train/model_loss_std": 14.450843009395875, "train/model_opt_grad_norm": 53.449485364167586, "train/model_opt_grad_steps": 31834.376811594204, "train/model_opt_loss": 17930.28220887115, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1213.768115942029, "train/policy_entropy_mag": 2.3698676306268442, "train/policy_entropy_max": 2.3698676306268442, "train/policy_entropy_mean": 0.49345781556938006, "train/policy_entropy_min": 0.07937509512555772, "train/policy_entropy_std": 0.5094199532615966, "train/policy_logprob_mag": 7.438383582709492, "train/policy_logprob_max": -0.00945566442079734, "train/policy_logprob_mean": -0.4937788576319598, "train/policy_logprob_min": -7.438383582709492, "train/policy_logprob_std": 1.0442889781965725, "train/policy_randomness_mag": 0.8364592751731044, "train/policy_randomness_max": 0.8364592751731044, "train/policy_randomness_mean": 0.17416895526474802, "train/policy_randomness_min": 0.028015925373504127, "train/policy_randomness_std": 0.17980289092098456, "train/post_ent_mag": 59.84579752493596, "train/post_ent_max": 59.84579752493596, "train/post_ent_mean": 42.053880663885586, "train/post_ent_min": 20.713884837385535, "train/post_ent_std": 7.354967072390128, "train/prior_ent_mag": 68.58684771993886, "train/prior_ent_max": 68.58684771993886, "train/prior_ent_mean": 55.88164746934089, "train/prior_ent_min": 38.541085339974664, "train/prior_ent_std": 4.487242655477662, "train/rep_loss_mean": 13.734716491422791, "train/rep_loss_std": 9.03260324312293, "train/reward_avg": 0.028048573075321274, "train/reward_loss_mean": 0.05525459889052571, "train/reward_loss_std": 0.23810715638640997, "train/reward_max_data": 1.0166666706403096, "train/reward_max_pred": 1.008655255255492, "train/reward_neg_acc": 0.992667048305705, "train/reward_neg_loss": 0.029035097318768934, "train/reward_pos_acc": 0.9718147917934086, "train/reward_pos_loss": 0.8260115907675978, "train/reward_pred": 0.027351996206772932, "train/reward_rate": 0.032920063405797104, "train_stats/sum_log_reward": 7.314953422992029, "train_stats/max_log_achievement_collect_coal": 0.037383177570093455, "train_stats/max_log_achievement_collect_drink": 4.205607476635514, "train_stats/max_log_achievement_collect_sapling": 2.3457943925233646, "train_stats/max_log_achievement_collect_stone": 0.7476635514018691, "train_stats/max_log_achievement_collect_wood": 13.36448598130841, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.9252336448598131, "train_stats/max_log_achievement_eat_cow": 0.06542056074766354, "train_stats/max_log_achievement_make_wood_pickaxe": 3.8878504672897196, "train_stats/max_log_achievement_make_wood_sword": 0.4766355140186916, "train_stats/max_log_achievement_place_plant": 2.2616822429906542, "train_stats/max_log_achievement_place_table": 3.196261682242991, "train_stats/max_log_achievement_wake_up": 1.1775700934579438, "train_stats/mean_log_entropy": 0.44424341549383145, "train_stats/max_log_achievement_place_stone": 0.015151515151515152, "eval_stats/sum_log_reward": 7.850000113248825, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.3125, "eval_stats/max_log_achievement_collect_sapling": 3.0, "eval_stats/max_log_achievement_collect_stone": 0.25, "eval_stats/max_log_achievement_collect_wood": 14.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.9375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 3.5625, "eval_stats/max_log_achievement_make_wood_sword": 0.8125, "eval_stats/max_log_achievement_place_plant": 2.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.3125, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.00011588967754505575, "report/cont_loss_std": 0.0035903349053114653, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0008594858227297664, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00011370476568117738, "report/cont_pred": 0.996965765953064, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.640345573425293, "report/dyn_loss_std": 8.754983901977539, "report/image_loss_mean": 5.9229278564453125, "report/image_loss_std": 10.825736999511719, "report/model_loss_mean": 13.558395385742188, "report/model_loss_std": 14.145524978637695, "report/post_ent_mag": 58.350975036621094, "report/post_ent_max": 58.350975036621094, "report/post_ent_mean": 42.922393798828125, "report/post_ent_min": 22.216022491455078, "report/post_ent_std": 8.048449516296387, "report/prior_ent_mag": 68.22189331054688, "report/prior_ent_max": 68.22189331054688, "report/prior_ent_mean": 55.927818298339844, "report/prior_ent_min": 39.29431915283203, "report/prior_ent_std": 4.299633026123047, "report/rep_loss_mean": 12.640345573425293, "report/rep_loss_std": 8.754983901977539, "report/reward_avg": 0.02460937574505806, "report/reward_loss_mean": 0.051143668591976166, "report/reward_loss_std": 0.2358926385641098, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0058376789093018, "report/reward_neg_acc": 0.9979920387268066, "report/reward_neg_loss": 0.03127095475792885, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7580444812774658, "report/reward_pred": 0.023500509560108185, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 6.125276286184089e-07, "eval/cont_loss_std": 1.0711666618590243e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00017701117030810565, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.421622593208667e-08, "eval/cont_pred": 0.9970707893371582, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.102435111999512, "eval/dyn_loss_std": 10.69302749633789, "eval/image_loss_mean": 9.651885986328125, "eval/image_loss_std": 12.451138496398926, "eval/model_loss_mean": 18.79623794555664, "eval/model_loss_std": 16.933147430419922, "eval/post_ent_mag": 60.5352783203125, "eval/post_ent_max": 60.5352783203125, "eval/post_ent_mean": 42.138458251953125, "eval/post_ent_min": 21.798690795898438, "eval/post_ent_std": 7.583869457244873, "eval/prior_ent_mag": 68.22189331054688, "eval/prior_ent_max": 68.22189331054688, "eval/prior_ent_mean": 55.55137634277344, "eval/prior_ent_min": 39.295814514160156, "eval/prior_ent_std": 4.527840614318848, "eval/rep_loss_mean": 15.102435111999512, "eval/rep_loss_std": 10.69302749633789, "eval/reward_avg": 0.03193359449505806, "eval/reward_loss_mean": 0.08288951963186264, "eval/reward_loss_std": 0.4461875259876251, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023088455200195, "eval/reward_neg_acc": 0.9949442744255066, "eval/reward_neg_loss": 0.04971306025981903, "eval/reward_pos_acc": 0.9428571462631226, "eval/reward_pos_loss": 1.0203614234924316, "eval/reward_pred": 0.030512947589159012, "eval/reward_rate": 0.0341796875, "replay/size": 521969.0, "replay/inserts": 22144.0, "replay/samples": 22144.0, "replay/insert_wait_avg": 1.3829655729966357e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.397407269891287e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2030958626340713e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2519588470459, "timer/env.step_count": 2768.0, "timer/env.step_total": 260.52041721343994, "timer/env.step_frac": 0.26045479332400645, "timer/env.step_avg": 0.09411864783722541, "timer/env.step_min": 0.022217750549316406, "timer/env.step_max": 3.2995474338531494, "timer/replay._sample_count": 22144.0, "timer/replay._sample_total": 11.452191591262817, "timer/replay._sample_frac": 0.011449306837112663, "timer/replay._sample_avg": 0.0005171690566863628, "timer/replay._sample_min": 0.0004177093505859375, "timer/replay._sample_max": 0.027851104736328125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3242.0, "timer/agent.policy_total": 51.789658069610596, "timer/agent.policy_frac": 0.05177661249402266, "timer/agent.policy_avg": 0.015974601502039047, "timer/agent.policy_min": 0.009382247924804688, "timer/agent.policy_max": 0.12798380851745605, "timer/dataset_train_count": 1384.0, "timer/dataset_train_total": 0.14958620071411133, "timer/dataset_train_frac": 0.00014954852064127312, "timer/dataset_train_avg": 0.00010808251496684345, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0010821819305419922, "timer/agent.train_count": 1384.0, "timer/agent.train_total": 621.1297852993011, "timer/agent.train_frac": 0.6209733255761427, "timer/agent.train_avg": 0.4487931974705933, "timer/agent.train_min": 0.434128999710083, "timer/agent.train_max": 1.8520910739898682, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47559452056884766, "timer/agent.report_frac": 0.00047547472050646936, "timer/agent.report_avg": 0.23779726028442383, "timer/agent.report_min": 0.23290681838989258, "timer/agent.report_max": 0.24268770217895508, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8126305662438006e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 22.138109789478037}
{"step": 522656, "time": 24367.58735203743, "episode/length": 263.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 522880, "time": 24377.01632642746, "episode/length": 248.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 522944, "time": 24380.789299488068, "episode/length": 286.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 522952, "time": 24382.453225135803, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9593908629441624, "episode/intrinsic_return": 0.0}
{"step": 523384, "time": 24398.71931743622, "episode/length": 54.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 523416, "time": 24401.709119796753, "episode/length": 57.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.0}
{"step": 523472, "time": 24405.93672633171, "episode/length": 267.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 523944, "time": 24423.44792318344, "episode/length": 244.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 524408, "time": 24442.085752010345, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 524416, "time": 24444.699402093887, "episode/length": 623.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9839743589743589, "episode/intrinsic_return": 0.0}
{"step": 524688, "time": 24455.899931430817, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 524776, "time": 24460.19358944893, "episode/length": 45.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 524912, "time": 24466.56488966942, "episode/length": 281.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 525128, "time": 24475.037321329117, "episode/length": 206.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 525304, "time": 24482.498999595642, "episode/length": 615.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9918831168831169, "episode/intrinsic_return": 0.0}
{"step": 525608, "time": 24494.125282764435, "episode/length": 207.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 525792, "time": 24502.098706007004, "episode/length": 296.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9831649831649831, "episode/intrinsic_return": 0.0}
{"step": 526080, "time": 24514.05968761444, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 526224, "time": 24520.360746383667, "episode/length": 136.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 526240, "time": 24522.50281214714, "episode/length": 227.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 526464, "time": 24531.39318704605, "episode/length": 210.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 526552, "time": 24535.67263174057, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 526840, "time": 24546.84677052498, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 527000, "time": 24553.624049186707, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 527224, "time": 24562.5539355278, "episode/length": 178.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 527672, "time": 24578.96350812912, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 527880, "time": 24587.33374285698, "episode/length": 224.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 528056, "time": 24594.664121866226, "episode/length": 131.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 528168, "time": 24599.91858315468, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 528600, "time": 24615.63827776909, "episode/length": 296.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764309764309764, "episode/intrinsic_return": 0.0}
{"step": 528904, "time": 24627.168384552002, "episode/length": 304.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 528968, "time": 24630.824298143387, "episode/length": 265.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 529048, "time": 24635.016133785248, "episode/length": 227.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 529080, "time": 24637.68200802803, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 529720, "time": 24660.323747634888, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 529760, "time": 24663.374963998795, "episode/length": 198.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 530040, "time": 24673.951418876648, "episode/length": 247.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 24691.636793851852, "eval_episode/length": 39.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.975}
{"step": 530088, "time": 24697.307272434235, "eval_episode/length": 140.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9574468085106383}
{"step": 530088, "time": 24699.62450146675, "eval_episode/length": 157.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 530088, "time": 24701.27777004242, "eval_episode/length": 160.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 530088, "time": 24703.64824271202, "eval_episode/length": 178.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 530088, "time": 24707.427619218826, "eval_episode/length": 202.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 530088, "time": 24709.675873041153, "eval_episode/length": 208.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9665071770334929}
{"step": 530088, "time": 24713.10190153122, "eval_episode/length": 212.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9812206572769953}
{"step": 530440, "time": 24724.808069705963, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 530608, "time": 24732.053389310837, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 530776, "time": 24738.82742381096, "episode/length": 271.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 530848, "time": 24742.978343248367, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683257918552036, "episode/intrinsic_return": 0.0}
{"step": 531232, "time": 24757.115748643875, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 531368, "time": 24762.99916625023, "episode/length": 289.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 531568, "time": 24771.462786197662, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 531952, "time": 24785.875587701797, "episode/length": 273.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744525547445255, "episode/intrinsic_return": 0.0}
{"step": 532184, "time": 24794.73991703987, "episode/length": 166.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 532320, "time": 24801.058153390884, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 532400, "time": 24805.25300836563, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 532512, "time": 24812.069133520126, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 532568, "time": 24815.31952381134, "episode/length": 223.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 532888, "time": 24827.390043497086, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 533000, "time": 24832.702159643173, "episode/length": 178.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 533304, "time": 24844.276875257492, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 533760, "time": 24861.05241036415, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 533808, "time": 24864.105253458023, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 534088, "time": 24874.74653840065, "episode/length": 220.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9909502262443439, "episode/intrinsic_return": 0.0}
{"step": 534144, "time": 24878.400493860245, "episode/length": 244.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 534408, "time": 24888.39011311531, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 534472, "time": 24892.005694627762, "episode/length": 258.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 534576, "time": 24897.319375514984, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 534800, "time": 24906.314876556396, "episode/length": 40.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 534904, "time": 24911.59624171257, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 535064, "time": 24918.97543168068, "episode/length": 271.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 535200, "time": 24925.402785778046, "episode/length": 138.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 535384, "time": 24932.867114305496, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 535568, "time": 24940.634865522385, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 535816, "time": 24950.129371881485, "episode/length": 208.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 536128, "time": 24962.161621570587, "episode/length": 165.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 536352, "time": 24971.10151529312, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 536736, "time": 24985.434626817703, "episode/length": 228.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 536768, "time": 24988.21156835556, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 536808, "time": 24990.85343313217, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 536848, "time": 24993.99790740013, "episode/length": 304.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.980327868852459, "episode/intrinsic_return": 0.0}
{"step": 537040, "time": 25001.938232421875, "episode/length": 206.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 537144, "time": 25006.708081007004, "episode/length": 36.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 537656, "time": 25025.195721149445, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 537752, "time": 25029.93128323555, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 538040, "time": 25041.022082328796, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 538496, "time": 25058.311421632767, "episode/length": 334.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 538536, "time": 25061.368315696716, "episode/length": 224.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 538592, "time": 25065.47432923317, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 538824, "time": 25075.00185418129, "episode/length": 251.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 538976, "time": 25081.956302165985, "episode/length": 241.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 539104, "time": 25087.758554697037, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 539168, "time": 25091.48663020134, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 539824, "time": 25114.694887161255, "episode/length": 160.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 25142.75083231926, "eval_episode/length": 141.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.971830985915493}
{"step": 540072, "time": 25144.94613313675, "eval_episode/length": 155.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 540072, "time": 25146.68032026291, "eval_episode/length": 159.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 540072, "time": 25149.07033777237, "eval_episode/length": 36.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 540072, "time": 25151.998499393463, "eval_episode/length": 208.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9712918660287081}
{"step": 540072, "time": 25153.53788638115, "eval_episode/length": 209.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 540072, "time": 25155.254920482635, "eval_episode/length": 211.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 540072, "time": 25157.78458213806, "eval_episode/length": 236.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 540128, "time": 25159.889409780502, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 540224, "time": 25164.48960018158, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 540256, "time": 25167.16729784012, "episode/length": 276.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9711191335740073, "episode/intrinsic_return": 0.0}
{"step": 540408, "time": 25173.646469593048, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 540848, "time": 25192.161146640778, "episode/length": 209.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 540872, "time": 25194.28842997551, "episode/length": 236.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 540920, "time": 25197.459377527237, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 541440, "time": 25216.467633247375, "episode/length": 64.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 541568, "time": 25222.337577581406, "episode/length": 217.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 541784, "time": 25230.84017419815, "episode/length": 206.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 541936, "time": 25237.708180189133, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 542176, "time": 25247.055985212326, "episode/length": 243.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 542248, "time": 25250.794093370438, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 542312, "time": 25254.46920323372, "episode/length": 46.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 542480, "time": 25261.82687807083, "episode/length": 258.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 542696, "time": 25270.338543653488, "episode/length": 230.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 542792, "time": 25275.531774282455, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 543064, "time": 25286.923305511475, "episode/length": 33.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 543448, "time": 25301.898887872696, "episode/length": 207.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 543736, "time": 25312.844405412674, "episode/length": 177.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 543768, "time": 25315.510582208633, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 543928, "time": 25322.557109355927, "episode/length": 294.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796610169491525, "episode/intrinsic_return": 0.0}
{"step": 544552, "time": 25344.580703258514, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 544608, "time": 25348.266095876694, "episode/length": 192.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 544896, "time": 25359.192511320114, "episode/length": 301.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9900662251655629, "episode/intrinsic_return": 0.0}
{"step": 544897, "time": 25361.39396214485, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.482207815987723, "train/action_min": 0.0, "train/action_std": 3.4864138432911465, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043272968527993984, "train/actor_opt_grad_steps": 33255.0, "train/actor_opt_loss": -2.951166234910488, "train/adv_mag": 0.5564417766673224, "train/adv_max": 0.5178797894290516, "train/adv_mean": 0.0038739084463973736, "train/adv_min": -0.45330675627504075, "train/adv_std": 0.06354061383754014, "train/cont_avg": 0.9944405691964285, "train/cont_loss_mean": 0.0003427965486052541, "train/cont_loss_std": 0.009524176139343256, "train/cont_neg_acc": 0.9850198413644519, "train/cont_neg_loss": 0.03250758647369431, "train/cont_pos_acc": 0.9999438081468854, "train/cont_pos_loss": 0.0002163571973831324, "train/cont_pred": 0.9944261244365147, "train/cont_rate": 0.9944405691964285, "train/dyn_loss_mean": 13.863368620191302, "train/dyn_loss_std": 9.067487478256226, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8107041197163718, "train/extr_critic_critic_opt_grad_steps": 33255.0, "train/extr_critic_critic_opt_loss": 15931.228648158482, "train/extr_critic_mag": 6.667771237237113, "train/extr_critic_max": 6.667771237237113, "train/extr_critic_mean": 1.6411067375114985, "train/extr_critic_min": -0.2613947646958487, "train/extr_critic_std": 1.5600138425827026, "train/extr_return_normed_mag": 1.6471415655953543, "train/extr_return_normed_max": 1.6471415655953543, "train/extr_return_normed_mean": 0.35694633637155804, "train/extr_return_normed_min": -0.10959318514381136, "train/extr_return_normed_std": 0.331496255419084, "train/extr_return_rate": 0.6481506087950297, "train/extr_return_raw_mag": 7.875362845829555, "train/extr_return_raw_max": 7.875362845829555, "train/extr_return_raw_mean": 1.6597597335066114, "train/extr_return_raw_min": -0.5881934027586665, "train/extr_return_raw_std": 1.5971050594534193, "train/extr_reward_mag": 1.0271839601652963, "train/extr_reward_max": 1.0271839601652963, "train/extr_reward_mean": 0.03310465766782207, "train/extr_reward_min": -0.40667106424059185, "train/extr_reward_std": 0.1717115409140076, "train/image_loss_mean": 6.693938946723938, "train/image_loss_std": 11.015877897398813, "train/model_loss_mean": 15.070239802769253, "train/model_loss_std": 14.667398405075073, "train/model_opt_grad_norm": 55.19145195824759, "train/model_opt_grad_steps": 33223.0, "train/model_opt_loss": 12944.997415597098, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 857.1428571428571, "train/policy_entropy_mag": 2.4051699348858424, "train/policy_entropy_max": 2.4051699348858424, "train/policy_entropy_mean": 0.49019933747393746, "train/policy_entropy_min": 0.07937507799693516, "train/policy_entropy_std": 0.5260334023407527, "train/policy_logprob_mag": 7.4383836167199275, "train/policy_logprob_max": -0.009455660098631467, "train/policy_logprob_mean": -0.48901232268129075, "train/policy_logprob_min": -7.4383836167199275, "train/policy_logprob_std": 1.0361229504857745, "train/policy_randomness_mag": 0.8489194397415434, "train/policy_randomness_max": 0.8489194397415434, "train/policy_randomness_mean": 0.17301885347281185, "train/policy_randomness_min": 0.028015919295804843, "train/policy_randomness_std": 0.18566670886107853, "train/post_ent_mag": 59.78471121106829, "train/post_ent_max": 59.78471121106829, "train/post_ent_mean": 42.247307123456686, "train/post_ent_min": 20.848631817953926, "train/post_ent_std": 7.4355588640485495, "train/prior_ent_mag": 68.57931692940848, "train/prior_ent_max": 68.57931692940848, "train/prior_ent_mean": 56.13687158312116, "train/prior_ent_min": 39.17708967753819, "train/prior_ent_std": 4.43272294487272, "train/rep_loss_mean": 13.863368620191302, "train/rep_loss_std": 9.067487478256226, "train/reward_avg": 0.027633230913696544, "train/reward_loss_mean": 0.057936855352350644, "train/reward_loss_std": 0.25491883807948656, "train/reward_max_data": 1.019285718883787, "train/reward_max_pred": 1.010755056142807, "train/reward_neg_acc": 0.9922340712377004, "train/reward_neg_loss": 0.031757713302171656, "train/reward_pos_acc": 0.9719970430646624, "train/reward_pos_loss": 0.8358646311930248, "train/reward_pred": 0.02698142190596887, "train/reward_rate": 0.032652064732142855, "train_stats/sum_log_reward": 7.334234352584358, "train_stats/max_log_achievement_collect_coal": 0.06306306306306306, "train_stats/max_log_achievement_collect_drink": 5.594594594594595, "train_stats/max_log_achievement_collect_sapling": 3.045045045045045, "train_stats/max_log_achievement_collect_stone": 1.072072072072072, "train_stats/max_log_achievement_collect_wood": 12.756756756756756, "train_stats/max_log_achievement_defeat_skeleton": 0.009009009009009009, "train_stats/max_log_achievement_defeat_zombie": 0.9099099099099099, "train_stats/max_log_achievement_eat_cow": 0.15315315315315314, "train_stats/max_log_achievement_make_wood_pickaxe": 2.684684684684685, "train_stats/max_log_achievement_make_wood_sword": 0.4954954954954955, "train_stats/max_log_achievement_place_plant": 2.954954954954955, "train_stats/max_log_achievement_place_stone": 0.05405405405405406, "train_stats/max_log_achievement_place_table": 3.045045045045045, "train_stats/max_log_achievement_wake_up": 1.1711711711711712, "train_stats/mean_log_entropy": 0.4678976133063033, "eval_stats/sum_log_reward": 7.35000005364418, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 2.5625, "eval_stats/max_log_achievement_collect_sapling": 3.125, "eval_stats/max_log_achievement_collect_stone": 1.625, "eval_stats/max_log_achievement_collect_wood": 9.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.8125, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3125, "eval_stats/max_log_achievement_make_wood_sword": 0.5625, "eval_stats/max_log_achievement_place_plant": 2.9375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 3.136168288619956e-06, "report/cont_loss_std": 1.6166526620509103e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00023421244986820966, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.6839641122933244e-06, "report/cont_pred": 0.9980446696281433, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 13.430994033813477, "report/dyn_loss_std": 8.80419921875, "report/image_loss_mean": 6.464660167694092, "report/image_loss_std": 11.787726402282715, "report/model_loss_mean": 14.56335735321045, "report/model_loss_std": 15.30012321472168, "report/post_ent_mag": 61.258750915527344, "report/post_ent_max": 61.258750915527344, "report/post_ent_mean": 42.8072624206543, "report/post_ent_min": 20.013347625732422, "report/post_ent_std": 7.630710124969482, "report/prior_ent_mag": 69.23504638671875, "report/prior_ent_max": 69.23504638671875, "report/prior_ent_mean": 56.451499938964844, "report/prior_ent_min": 39.717445373535156, "report/prior_ent_std": 4.645296096801758, "report/rep_loss_mean": 13.430994033813477, "report/rep_loss_std": 8.80419921875, "report/reward_avg": 0.02617187425494194, "report/reward_loss_mean": 0.0400979183614254, "report/reward_loss_std": 0.16230623424053192, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0527560710906982, "report/reward_neg_acc": 0.9909456372261047, "report/reward_neg_loss": 0.01971125602722168, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7155760526657104, "report/reward_pred": 0.026730500161647797, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.008762072771787643, "eval/cont_loss_std": 0.23246893286705017, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.430894672870636, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0071066501550376415, "eval/cont_pred": 0.9959174394607544, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.974159240722656, "eval/dyn_loss_std": 10.839404106140137, "eval/image_loss_mean": 13.181474685668945, "eval/image_loss_std": 18.75902557373047, "eval/model_loss_mean": 24.713581085205078, "eval/model_loss_std": 22.871112823486328, "eval/post_ent_mag": 59.36521530151367, "eval/post_ent_max": 59.36521530151367, "eval/post_ent_mean": 40.732810974121094, "eval/post_ent_min": 22.786062240600586, "eval/post_ent_std": 7.301269054412842, "eval/prior_ent_mag": 69.23504638671875, "eval/prior_ent_max": 69.23504638671875, "eval/prior_ent_mean": 57.105342864990234, "eval/prior_ent_min": 40.73149108886719, "eval/prior_ent_std": 4.112603187561035, "eval/rep_loss_mean": 18.974159240722656, "eval/rep_loss_std": 10.839404106140137, "eval/reward_avg": 0.03408202901482582, "eval/reward_loss_mean": 0.13884949684143066, "eval/reward_loss_std": 0.895427405834198, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0041725635528564, "eval/reward_neg_acc": 0.9847716093063354, "eval/reward_neg_loss": 0.035426780581474304, "eval/reward_pos_acc": 0.692307710647583, "eval/reward_pos_loss": 2.7509360313415527, "eval/reward_pred": 0.026383347809314728, "eval/reward_rate": 0.0380859375, "replay/size": 544393.0, "replay/inserts": 22424.0, "replay/samples": 22416.0, "replay/insert_wait_avg": 1.3771905160741298e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.554606672527959e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3920.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.235275852436922e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1903192996979, "timer/env.step_count": 2803.0, "timer/env.step_total": 255.5000536441803, "timer/env.step_frac": 0.25545143630571576, "timer/env.step_avg": 0.09115235592014995, "timer/env.step_min": 0.022235870361328125, "timer/env.step_max": 2.1423535346984863, "timer/replay._sample_count": 22416.0, "timer/replay._sample_total": 11.473573446273804, "timer/replay._sample_frac": 0.011471390219320702, "timer/replay._sample_avg": 0.0005118474949265616, "timer/replay._sample_min": 0.0004177093505859375, "timer/replay._sample_max": 0.01111292839050293, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3293.0, "timer/agent.policy_total": 53.041446924209595, "timer/agent.policy_frac": 0.0530313540340478, "timer/agent.policy_avg": 0.01610733280419362, "timer/agent.policy_min": 0.009376764297485352, "timer/agent.policy_max": 0.11006021499633789, "timer/dataset_train_count": 1401.0, "timer/dataset_train_total": 0.14841175079345703, "timer/dataset_train_frac": 0.0001483835105476429, "timer/dataset_train_avg": 0.0001059327271901906, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.00046539306640625, "timer/agent.train_count": 1401.0, "timer/agent.train_total": 625.7880237102509, "timer/agent.train_frac": 0.6256689468344466, "timer/agent.train_avg": 0.4466723937974667, "timer/agent.train_min": 0.4335634708404541, "timer/agent.train_max": 1.639348030090332, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4713115692138672, "timer/agent.report_frac": 0.0004712218865944082, "timer/agent.report_avg": 0.2356557846069336, "timer/agent.report_min": 0.22682857513427734, "timer/agent.report_max": 0.24448299407958984, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8843158661531524e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 22.4194336944064}
{"step": 545240, "time": 25372.710908651352, "episode/length": 223.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 545328, "time": 25377.37230205536, "episode/length": 194.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 545344, "time": 25379.454441547394, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 545584, "time": 25388.86214184761, "episode/length": 230.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 545728, "time": 25395.085494041443, "episode/length": 139.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 545768, "time": 25397.742898225784, "episode/length": 439.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795454545454545, "episode/intrinsic_return": 0.0}
{"step": 545776, "time": 25399.886076450348, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 546632, "time": 25429.64230823517, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 546656, "time": 25432.614223003387, "episode/length": 176.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 546944, "time": 25443.775470495224, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 547056, "time": 25449.179762601852, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 547216, "time": 25456.030873775482, "episode/length": 235.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 547352, "time": 25461.84297990799, "episode/length": 202.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 547360, "time": 25463.870273590088, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 547376, "time": 25466.011296749115, "episode/length": 223.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 547464, "time": 25470.24771809578, "episode/length": 64.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9384615384615385, "episode/intrinsic_return": 0.0}
{"step": 547952, "time": 25487.945323228836, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 548360, "time": 25502.716718673706, "episode/length": 215.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 548720, "time": 25516.21596622467, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 548904, "time": 25525.03490948677, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 548928, "time": 25527.90565252304, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 548992, "time": 25531.597077846527, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 549056, "time": 25535.219700813293, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 549064, "time": 25536.78925561905, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 549272, "time": 25545.17483639717, "episode/length": 45.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 549296, "time": 25547.60733819008, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 549696, "time": 25562.28448987007, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 549952, "time": 25572.287050008774, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 25591.432221651077, "eval_episode/length": 46.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8936170212765957}
{"step": 550056, "time": 25597.49810051918, "eval_episode/length": 160.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.968944099378882}
{"step": 550056, "time": 25600.697167396545, "eval_episode/length": 203.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 550056, "time": 25602.302149295807, "eval_episode/length": 204.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 550056, "time": 25604.765204429626, "eval_episode/length": 227.0, "eval_episode/score": 8.100000016391277, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 550056, "time": 25607.181304216385, "eval_episode/length": 202.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 550056, "time": 25609.450776338577, "eval_episode/length": 268.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9962825278810409}
{"step": 550056, "time": 25611.28915786743, "eval_episode/length": 274.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9963636363636363}
{"step": 550176, "time": 25615.44741153717, "episode/length": 138.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 550416, "time": 25625.076757907867, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 550704, "time": 25636.138860702515, "episode/length": 221.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 550760, "time": 25639.297342777252, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 550784, "time": 25641.808841228485, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 550976, "time": 25649.710703372955, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 551192, "time": 25658.104720830917, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 551560, "time": 25671.675132513046, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 552256, "time": 25696.576790332794, "episode/length": 186.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 552384, "time": 25702.286509990692, "episode/length": 209.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 552608, "time": 25711.256088495255, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 552720, "time": 25716.471117973328, "episode/length": 190.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 552728, "time": 25718.051258325577, "episode/length": 145.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 553384, "time": 25741.447060585022, "episode/length": 428.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 553504, "time": 25747.675510644913, "episode/length": 139.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 553728, "time": 25757.35335803032, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 553760, "time": 25760.29412508011, "episode/length": 417.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9784688995215312, "episode/intrinsic_return": 0.0}
{"step": 554040, "time": 25771.340463638306, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 554040, "time": 25771.34971666336, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 554152, "time": 25778.35973572731, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 554464, "time": 25790.434016942978, "episode/length": 38.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 554688, "time": 25800.14334011078, "episode/length": 487.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9979508196721312, "episode/intrinsic_return": 0.0}
{"step": 555368, "time": 25825.11287498474, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 555384, "time": 25827.252040863037, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 555512, "time": 25832.982226848602, "episode/length": 130.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9541984732824428, "episode/intrinsic_return": 0.0}
{"step": 555656, "time": 25839.358241081238, "episode/length": 283.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 555672, "time": 25841.828673362732, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 556168, "time": 25860.72408246994, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 556424, "time": 25871.39124107361, "episode/length": 332.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.984984984984985, "episode/intrinsic_return": 0.0}
{"step": 556744, "time": 25884.26712656021, "episode/length": 171.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 556840, "time": 25889.586120843887, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 556872, "time": 25892.724712848663, "episode/length": 420.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.997624703087886, "episode/intrinsic_return": 0.0}
{"step": 557088, "time": 25903.967582702637, "episode/length": 178.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 557664, "time": 25925.646302700043, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 557752, "time": 25930.413600444794, "episode/length": 165.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 558424, "time": 25954.29532122612, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 558448, "time": 25956.835346221924, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 558544, "time": 25961.61594080925, "episode/length": 224.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 558568, "time": 25963.704188108444, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 558816, "time": 25973.676394701004, "episode/length": 428.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 558856, "time": 25976.401152849197, "episode/length": 397.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9874371859296482, "episode/intrinsic_return": 0.0}
{"step": 559464, "time": 25998.321355342865, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 559672, "time": 26006.81202030182, "episode/length": 137.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 559832, "time": 26013.557693719864, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 559864, "time": 26016.19827604294, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 26037.887479305267, "eval_episode/length": 39.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 560040, "time": 26042.11643075943, "eval_episode/length": 106.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9906542056074766}
{"step": 560040, "time": 26045.150985479355, "eval_episode/length": 142.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.972027972027972}
{"step": 560040, "time": 26049.29830789566, "eval_episode/length": 201.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 560040, "time": 26052.967582941055, "eval_episode/length": 250.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9681274900398407}
{"step": 560040, "time": 26055.242750406265, "eval_episode/length": 160.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 560040, "time": 26059.61211705208, "eval_episode/length": 295.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9966216216216216}
{"step": 560040, "time": 26062.396825313568, "eval_episode/length": 166.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 560040, "time": 26062.405514240265, "eval_episode/length": 225.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 560120, "time": 26065.068515777588, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 560136, "time": 26067.24408507347, "episode/length": 297.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 560216, "time": 26071.37650680542, "episode/length": 43.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 560400, "time": 26079.193767786026, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 560520, "time": 26084.508922100067, "episode/length": 246.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 560856, "time": 26097.16320514679, "episode/length": 147.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 561176, "time": 26109.360893964767, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 561440, "time": 26119.860461711884, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 561664, "time": 26128.898764133453, "episode/length": 190.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 561968, "time": 26141.361070156097, "episode/length": 266.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 562160, "time": 26149.751875162125, "episode/length": 219.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 562576, "time": 26165.162175178528, "episode/length": 214.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 562624, "time": 26168.29952430725, "episode/length": 300.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9867109634551495, "episode/intrinsic_return": 0.0}
{"step": 562672, "time": 26171.448699474335, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 563160, "time": 26188.94170641899, "episode/length": 214.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 563312, "time": 26195.746612548828, "episode/length": 348.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9914040114613181, "episode/intrinsic_return": 0.0}
{"step": 563432, "time": 26200.902361631393, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 563440, "time": 26202.848735809326, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 563656, "time": 26211.170203447342, "episode/length": 128.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 564008, "time": 26224.256272792816, "episode/length": 178.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 564072, "time": 26227.95286631584, "episode/length": 94.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 564392, "time": 26239.931363105774, "episode/length": 340.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9882697947214076, "episode/intrinsic_return": 0.0}
{"step": 564408, "time": 26242.0422539711, "episode/length": 49.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 564472, "time": 26245.81939792633, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 564736, "time": 26256.25834274292, "episode/length": 257.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 565104, "time": 26269.92915725708, "episode/length": 207.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 565304, "time": 26279.953283548355, "episode/length": 24.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.88, "episode/intrinsic_return": 0.0}
{"step": 565744, "time": 26296.12537074089, "episode/length": 166.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 566224, "time": 26313.735134601593, "episode/length": 348.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9856733524355301, "episode/intrinsic_return": 0.0}
{"step": 566224, "time": 26313.74524450302, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 566256, "time": 26318.01448583603, "episode/length": 272.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 566760, "time": 26335.881301403046, "episode/length": 252.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 566760, "time": 26335.897247314453, "episode/length": 62.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 566816, "time": 26341.42747282982, "episode/length": 302.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 566920, "time": 26346.139986991882, "episode/length": 407.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975490196078431, "episode/intrinsic_return": 0.0}
{"step": 567304, "time": 26360.150923490524, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 567305, "time": 26362.78937602043, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4488192078069595, "train/action_min": 0.0, "train/action_std": 3.380833722175436, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04251837698703117, "train/actor_opt_grad_steps": 34660.0, "train/actor_opt_loss": 0.18820410309002755, "train/adv_mag": 0.5552470350096411, "train/adv_max": 0.519760880487185, "train/adv_mean": 0.004745228945092688, "train/adv_min": -0.43080510251910975, "train/adv_std": 0.06252926780928111, "train/cont_avg": 0.9946046653368794, "train/cont_loss_mean": 0.0002124394372143223, "train/cont_loss_std": 0.006169357580958591, "train/cont_neg_acc": 0.9917857148817607, "train/cont_neg_loss": 0.024130318031140113, "train/cont_pos_acc": 0.9999721126353487, "train/cont_pos_loss": 6.682998948230926e-05, "train/cont_pred": 0.9945988388771706, "train/cont_rate": 0.9946046653368794, "train/dyn_loss_mean": 13.83827853371911, "train/dyn_loss_std": 8.995594132876565, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8581472115313753, "train/extr_critic_critic_opt_grad_steps": 34660.0, "train/extr_critic_critic_opt_loss": 16084.587024878103, "train/extr_critic_mag": 6.849722037078641, "train/extr_critic_max": 6.849722037078641, "train/extr_critic_mean": 1.7350635748383, "train/extr_critic_min": -0.2412077856402025, "train/extr_critic_std": 1.6421670879878052, "train/extr_return_normed_mag": 1.6462266090068411, "train/extr_return_normed_max": 1.6462266090068411, "train/extr_return_normed_mean": 0.358944999622115, "train/extr_return_normed_min": -0.110407163382422, "train/extr_return_normed_std": 0.33451713431388774, "train/extr_return_rate": 0.6583499906333625, "train/extr_return_raw_mag": 8.228018567917195, "train/extr_return_raw_max": 8.228018567917195, "train/extr_return_raw_mean": 1.7590068223628592, "train/extr_return_raw_min": -0.599454309077973, "train/extr_return_raw_std": 1.680958500145175, "train/extr_reward_mag": 1.025146464084057, "train/extr_reward_max": 1.025146464084057, "train/extr_reward_mean": 0.03387991702250132, "train/extr_reward_min": -0.4354456248858296, "train/extr_reward_std": 0.1739002045587445, "train/image_loss_mean": 6.746806171768946, "train/image_loss_std": 11.117610278704488, "train/model_loss_mean": 15.106782886153418, "train/model_loss_std": 14.728109041849772, "train/model_opt_grad_norm": 56.45060721864092, "train/model_opt_grad_steps": 34627.397163120564, "train/model_opt_loss": 19956.379529587764, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1320.9219858156027, "train/policy_entropy_mag": 2.4184126752488155, "train/policy_entropy_max": 2.4184126752488155, "train/policy_entropy_mean": 0.49596873961441906, "train/policy_entropy_min": 0.07937506126596573, "train/policy_entropy_std": 0.5433477865043261, "train/policy_logprob_mag": 7.438383646890626, "train/policy_logprob_max": -0.009455659241805263, "train/policy_logprob_mean": -0.4959066343222949, "train/policy_logprob_min": -7.438383646890626, "train/policy_logprob_std": 1.0383389541443357, "train/policy_randomness_mag": 0.8535935443343846, "train/policy_randomness_max": 0.8535935443343846, "train/policy_randomness_mean": 0.17505520022084528, "train/policy_randomness_min": 0.028015913349305484, "train/policy_randomness_std": 0.19177792353410247, "train/post_ent_mag": 59.782153190450465, "train/post_ent_max": 59.782153190450465, "train/post_ent_mean": 42.23753170256919, "train/post_ent_min": 20.740549249851956, "train/post_ent_std": 7.374138013690922, "train/prior_ent_mag": 68.75655029513312, "train/prior_ent_max": 68.75655029513312, "train/prior_ent_mean": 56.15241254982374, "train/prior_ent_min": 39.243809341538885, "train/prior_ent_std": 4.419059092271413, "train/rep_loss_mean": 13.83827853371911, "train/rep_loss_std": 8.995594132876565, "train/reward_avg": 0.027604858886371268, "train/reward_loss_mean": 0.056797235226588895, "train/reward_loss_std": 0.250570795743178, "train/reward_max_data": 1.0198581607629222, "train/reward_max_pred": 1.0109555974919746, "train/reward_neg_acc": 0.9924073844936723, "train/reward_neg_loss": 0.030368949887706033, "train/reward_pos_acc": 0.9687534287466225, "train/reward_pos_loss": 0.850463829987438, "train/reward_pred": 0.02687263814402176, "train/reward_rate": 0.03245511968085106, "train_stats/sum_log_reward": 7.577064345736022, "train_stats/max_log_achievement_collect_coal": 0.21100917431192662, "train_stats/max_log_achievement_collect_drink": 5.3577981651376145, "train_stats/max_log_achievement_collect_sapling": 3.1559633027522938, "train_stats/max_log_achievement_collect_stone": 1.81651376146789, "train_stats/max_log_achievement_collect_wood": 12.275229357798166, "train_stats/max_log_achievement_defeat_skeleton": 0.03669724770642202, "train_stats/max_log_achievement_defeat_zombie": 0.6788990825688074, "train_stats/max_log_achievement_eat_cow": 0.12844036697247707, "train_stats/max_log_achievement_make_wood_pickaxe": 1.8990825688073394, "train_stats/max_log_achievement_make_wood_sword": 0.6055045871559633, "train_stats/max_log_achievement_place_plant": 3.0642201834862384, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.761467889908257, "train_stats/max_log_achievement_wake_up": 1.4220183486238531, "train_stats/mean_log_entropy": 0.48059599908120043, "train_stats/max_log_achievement_place_furnace": 0.018518518518518517, "train_stats/max_log_achievement_make_stone_pickaxe": 0.028846153846153848, "eval_stats/sum_log_reward": 7.452941361595602, "eval_stats/max_log_achievement_collect_coal": 0.058823529411764705, "eval_stats/max_log_achievement_collect_drink": 6.352941176470588, "eval_stats/max_log_achievement_collect_sapling": 2.4705882352941178, "eval_stats/max_log_achievement_collect_stone": 1.8823529411764706, "eval_stats/max_log_achievement_collect_wood": 10.823529411764707, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.7647058823529411, "eval_stats/max_log_achievement_eat_cow": 0.17647058823529413, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.7058823529411764, "eval_stats/max_log_achievement_make_wood_sword": 0.5294117647058824, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.235294117647059, "eval_stats/max_log_achievement_place_stone": 0.11764705882352941, "eval_stats/max_log_achievement_place_table": 2.411764705882353, "eval_stats/max_log_achievement_wake_up": 1.411764705882353, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.05, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.7528907847008668e-05, "report/cont_loss_std": 0.00046178599586710334, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002298219478689134, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.606769728823565e-05, "report/cont_pred": 0.9931497573852539, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.790569305419922, "report/dyn_loss_std": 9.036433219909668, "report/image_loss_mean": 6.505184173583984, "report/image_loss_std": 11.440208435058594, "report/model_loss_mean": 14.830806732177734, "report/model_loss_std": 14.796040534973145, "report/post_ent_mag": 60.87921905517578, "report/post_ent_max": 60.87921905517578, "report/post_ent_mean": 42.0269775390625, "report/post_ent_min": 19.372634887695312, "report/post_ent_std": 7.716061592102051, "report/prior_ent_mag": 68.9389877319336, "report/prior_ent_max": 68.9389877319336, "report/prior_ent_mean": 56.17921447753906, "report/prior_ent_min": 41.31682586669922, "report/prior_ent_std": 4.098176002502441, "report/rep_loss_mean": 13.790569305419922, "report/rep_loss_std": 9.036433219909668, "report/reward_avg": 0.03544922173023224, "report/reward_loss_mean": 0.051264047622680664, "report/reward_loss_std": 0.19583207368850708, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0044820308685303, "report/reward_neg_acc": 0.9938962459564209, "report/reward_neg_loss": 0.02181440033018589, "report/reward_pos_acc": 0.9756097197532654, "report/reward_pos_loss": 0.7573373317718506, "report/reward_pred": 0.036067746579647064, "report/reward_rate": 0.0400390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.0813971584866522e-06, "eval/cont_loss_std": 4.8906117626756895e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.592005956918001e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.90882006387983e-07, "eval/cont_pred": 0.9970695972442627, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.267044067382812, "eval/dyn_loss_std": 10.377137184143066, "eval/image_loss_mean": 12.52374267578125, "eval/image_loss_std": 17.561681747436523, "eval/model_loss_mean": 23.593379974365234, "eval/model_loss_std": 21.51911163330078, "eval/post_ent_mag": 58.271240234375, "eval/post_ent_max": 58.271240234375, "eval/post_ent_mean": 40.14396286010742, "eval/post_ent_min": 22.10933494567871, "eval/post_ent_std": 6.890329360961914, "eval/prior_ent_mag": 68.9389877319336, "eval/prior_ent_max": 68.9389877319336, "eval/prior_ent_mean": 55.64051818847656, "eval/prior_ent_min": 37.32861328125, "eval/prior_ent_std": 4.00567626953125, "eval/rep_loss_mean": 18.267044067382812, "eval/rep_loss_std": 10.377137184143066, "eval/reward_avg": 0.03730468451976776, "eval/reward_loss_mean": 0.1094084158539772, "eval/reward_loss_std": 0.6820904612541199, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0038859844207764, "eval/reward_neg_acc": 0.9847251176834106, "eval/reward_neg_loss": 0.041551683098077774, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 1.6959636211395264, "eval/reward_pred": 0.03630269318819046, "eval/reward_rate": 0.041015625, "replay/size": 566801.0, "replay/inserts": 22408.0, "replay/samples": 22416.0, "replay/insert_wait_avg": 1.3715558629170437e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.492917354237939e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5152.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1698337075132761e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.3821914196014, "timer/env.step_count": 2801.0, "timer/env.step_total": 253.84540510177612, "timer/env.step_frac": 0.2534950264513035, "timer/env.step_avg": 0.09062670656971657, "timer/env.step_min": 0.02270054817199707, "timer/env.step_max": 3.4919872283935547, "timer/replay._sample_count": 22416.0, "timer/replay._sample_total": 11.453392028808594, "timer/replay._sample_frac": 0.011437583099587366, "timer/replay._sample_avg": 0.0005109471818704761, "timer/replay._sample_min": 0.0003771781921386719, "timer/replay._sample_max": 0.011565208435058594, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3445.0, "timer/agent.policy_total": 54.45609998703003, "timer/agent.policy_frac": 0.0543809351251102, "timer/agent.policy_avg": 0.015807285917860677, "timer/agent.policy_min": 0.009328126907348633, "timer/agent.policy_max": 0.10578560829162598, "timer/dataset_train_count": 1401.0, "timer/dataset_train_total": 0.14926767349243164, "timer/dataset_train_frac": 0.0001490616417701852, "timer/dataset_train_avg": 0.00010654366416304899, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0002675056457519531, "timer/agent.train_count": 1401.0, "timer/agent.train_total": 624.718745470047, "timer/agent.train_frac": 0.623856456428908, "timer/agent.train_avg": 0.4459091687866146, "timer/agent.train_min": 0.4337162971496582, "timer/agent.train_max": 1.548095941543579, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47475242614746094, "timer/agent.report_frac": 0.00047409713315795237, "timer/agent.report_avg": 0.23737621307373047, "timer/agent.report_min": 0.2314748764038086, "timer/agent.report_max": 0.24327754974365234, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.047545521229712e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 22.37679732697809}
{"step": 568512, "time": 26403.20796918869, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9900249376558603, "episode/intrinsic_return": 0.0}
{"step": 568600, "time": 26407.550188541412, "episode/length": 222.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 569072, "time": 26425.266718626022, "episode/length": 268.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 569264, "time": 26433.957910060883, "episode/length": 312.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 569352, "time": 26438.662744045258, "episode/length": 390.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9974424552429667, "episode/intrinsic_return": 0.0}
{"step": 569568, "time": 26447.493853092194, "episode/length": 417.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9976076555023924, "episode/intrinsic_return": 0.0}
{"step": 569920, "time": 26460.656792879105, "episode/length": 326.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9969418960244648, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 26484.86683821678, "eval_episode/length": 123.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9919354838709677}
{"step": 570024, "time": 26487.63725543022, "eval_episode/length": 151.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 570024, "time": 26489.195640087128, "eval_episode/length": 153.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 570024, "time": 26492.318056821823, "eval_episode/length": 191.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 570024, "time": 26494.155524015427, "eval_episode/length": 198.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 570024, "time": 26494.16423010826, "eval_episode/length": 198.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 570024, "time": 26497.535027742386, "eval_episode/length": 202.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 570024, "time": 26503.74179172516, "eval_episode/length": 165.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 570048, "time": 26504.78090453148, "episode/length": 410.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951338199513382, "episode/intrinsic_return": 0.0}
{"step": 570216, "time": 26511.544853687286, "episode/length": 212.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 570344, "time": 26517.41118478775, "episode/length": 158.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 570536, "time": 26525.35486316681, "episode/length": 241.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 570984, "time": 26541.6311647892, "episode/length": 203.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 571088, "time": 26547.03766965866, "episode/length": 227.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 571256, "time": 26553.96803021431, "episode/length": 166.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 571288, "time": 26556.66388440132, "episode/length": 37.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.8947368421052632, "episode/intrinsic_return": 0.0}
{"step": 571624, "time": 26569.634433031082, "episode/length": 196.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 571688, "time": 26573.660762786865, "episode/length": 264.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 571920, "time": 26583.93774843216, "episode/length": 196.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 572008, "time": 26588.29277396202, "episode/length": 183.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 572168, "time": 26595.070655345917, "episode/length": 243.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 572520, "time": 26608.299065351486, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 572712, "time": 26616.154928684235, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 572752, "time": 26619.335399627686, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 573272, "time": 26638.491687059402, "episode/length": 197.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 573504, "time": 26649.527055501938, "episode/length": 166.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 573912, "time": 26664.189001321793, "episode/length": 248.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 573960, "time": 26667.384164094925, "episode/length": 179.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 573992, "time": 26670.0720911026, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 574632, "time": 26692.78793144226, "episode/length": 327.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 574744, "time": 26698.08137202263, "episode/length": 154.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 574904, "time": 26704.944722175598, "episode/length": 409.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 574952, "time": 26708.02554678917, "episode/length": 274.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709090909090909, "episode/intrinsic_return": 0.0}
{"step": 575736, "time": 26735.46144247055, "episode/length": 227.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 575984, "time": 26745.386380910873, "episode/length": 248.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 575992, "time": 26746.905343055725, "episode/length": 129.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9538461538461539, "episode/intrinsic_return": 0.0}
{"step": 576048, "time": 26750.63230895996, "episode/length": 346.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9913544668587896, "episode/intrinsic_return": 0.0}
{"step": 576464, "time": 26766.047358989716, "episode/length": 312.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712460063897763, "episode/intrinsic_return": 0.0}
{"step": 576816, "time": 26779.204381227493, "episode/length": 272.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 576896, "time": 26783.35960173607, "episode/length": 268.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 577224, "time": 26795.919173002243, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 577592, "time": 26810.56520676613, "episode/length": 335.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 577840, "time": 26820.658962726593, "episode/length": 230.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 577912, "time": 26824.37153196335, "episode/length": 39.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 578088, "time": 26831.706352233887, "episode/length": 293.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 578360, "time": 26842.207120656967, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9662447257383966, "episode/intrinsic_return": 0.0}
{"step": 578384, "time": 26844.770047664642, "episode/length": 144.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 578712, "time": 26857.07321691513, "episode/length": 332.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.984984984984985, "episode/intrinsic_return": 0.0}
{"step": 578744, "time": 26859.60391187668, "episode/length": 240.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.991701244813278, "episode/intrinsic_return": 0.0}
{"step": 578792, "time": 26862.684688091278, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 579056, "time": 26873.189435482025, "episode/length": 38.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 579208, "time": 26879.696403980255, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 579632, "time": 26895.87446331978, "episode/length": 214.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 579704, "time": 26900.032896518707, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 579760, "time": 26904.19872736931, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 579936, "time": 26912.053840875626, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 26930.05660557747, "eval_episode/length": 36.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.972972972972973}
{"step": 580008, "time": 26932.070115804672, "eval_episode/length": 47.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 580008, "time": 26938.895952939987, "eval_episode/length": 139.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 580008, "time": 26940.69928765297, "eval_episode/length": 182.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.994535519125683}
{"step": 580008, "time": 26942.597178459167, "eval_episode/length": 189.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 580008, "time": 26944.239941120148, "eval_episode/length": 192.0, "eval_episode/score": 9.100000016391277, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 580008, "time": 26946.406618595123, "eval_episode/length": 162.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 580008, "time": 26948.078392267227, "eval_episode/length": 215.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 580256, "time": 26956.40489578247, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 580328, "time": 26960.19128727913, "episode/length": 70.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 580408, "time": 26964.32273364067, "episode/length": 211.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 580528, "time": 26970.20440506935, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 581192, "time": 26993.34159708023, "episode/length": 266.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 581224, "time": 26996.03508734703, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 581424, "time": 27004.56624007225, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 581752, "time": 27018.347091674805, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 582104, "time": 27031.59308362007, "episode/length": 221.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 582192, "time": 27036.238285303116, "episode/length": 222.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 582384, "time": 27044.101282596588, "episode/length": 231.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 582440, "time": 27047.264275550842, "episode/length": 151.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 582496, "time": 27050.943502426147, "episode/length": 162.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 583016, "time": 27069.490349054337, "episode/length": 157.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 583360, "time": 27082.589448213577, "episode/length": 465.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9871244635193133, "episode/intrinsic_return": 0.0}
{"step": 583488, "time": 27088.389438152313, "episode/length": 137.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 583624, "time": 27094.18878388405, "episode/length": 189.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 583712, "time": 27098.824320554733, "episode/length": 151.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 583896, "time": 27106.21582531929, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 584112, "time": 27115.13741517067, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 584696, "time": 27135.66961336136, "episode/length": 408.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975550122249389, "episode/intrinsic_return": 0.0}
{"step": 584760, "time": 27139.38395500183, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 584968, "time": 27147.938238859177, "episode/length": 33.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8529411764705882, "episode/intrinsic_return": 0.0}
{"step": 584984, "time": 27150.096701145172, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 585032, "time": 27153.247307777405, "episode/length": 251.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 585272, "time": 27162.697321414948, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 585352, "time": 27166.92053604126, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 585616, "time": 27177.374965429306, "episode/length": 42.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 585648, "time": 27179.950429201126, "episode/length": 191.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 585936, "time": 27190.912457227707, "episode/length": 120.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 586016, "time": 27195.08176088333, "episode/length": 45.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 586504, "time": 27212.615474939346, "episode/length": 217.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 586592, "time": 27217.28337740898, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 586672, "time": 27221.42579460144, "episode/length": 346.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9971181556195965, "episode/intrinsic_return": 0.0}
{"step": 586712, "time": 27224.08594894409, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 586848, "time": 27230.284110307693, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 587184, "time": 27243.274527072906, "episode/length": 41.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9047619047619048, "episode/intrinsic_return": 0.0}
{"step": 587256, "time": 27247.519948482513, "episode/length": 277.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 587400, "time": 27254.554661273956, "episode/length": 182.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 587952, "time": 27275.70491862297, "episode/length": 159.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 588032, "time": 27280.41026711464, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 588240, "time": 27289.50325703621, "episode/length": 277.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 588264, "time": 27292.087075471878, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 588360, "time": 27297.464468955994, "episode/length": 220.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 588416, "time": 27301.496206521988, "episode/length": 153.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 589008, "time": 27323.31373000145, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 589360, "time": 27336.617423057556, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 589528, "time": 27343.61568069458, "episode/length": 160.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 589728, "time": 27352.146884441376, "episode/length": 163.0, "episode/score": 2.1000000163912773, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 589856, "time": 27360.09750342369, "episode/length": 198.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 589873, "time": 27362.814399003983, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.464622118794326, "train/action_min": 0.0, "train/action_std": 3.4161196245369334, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.042344021855305274, "train/actor_opt_grad_steps": 36070.0, "train/actor_opt_loss": -1.0601795562493437, "train/adv_mag": 0.5215503869327247, "train/adv_max": 0.4802742995691638, "train/adv_mean": 0.004259817662206313, "train/adv_min": -0.4256093772590583, "train/adv_std": 0.06164610882600149, "train/cont_avg": 0.9948055186170213, "train/cont_loss_mean": 0.00038163104097296624, "train/cont_loss_std": 0.011635000280021969, "train/cont_neg_acc": 0.9877378154308238, "train/cont_neg_loss": 0.0381005344351387, "train/cont_pos_acc": 0.9999442616253035, "train/cont_pos_loss": 0.0001655807353359199, "train/cont_pred": 0.9947996469254189, "train/cont_rate": 0.9948055186170213, "train/dyn_loss_mean": 13.63989098190416, "train/dyn_loss_std": 9.055708168246221, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8705634259163065, "train/extr_critic_critic_opt_grad_steps": 36070.0, "train/extr_critic_critic_opt_loss": 16468.245401152482, "train/extr_critic_mag": 7.352745505934911, "train/extr_critic_max": 7.352745505934911, "train/extr_critic_mean": 2.0492144231255174, "train/extr_critic_min": -0.2250886115622013, "train/extr_critic_std": 1.7532373353944604, "train/extr_return_normed_mag": 1.6121945414982788, "train/extr_return_normed_max": 1.6121945414982788, "train/extr_return_normed_mean": 0.38073786976912344, "train/extr_return_normed_min": -0.09718311017920785, "train/extr_return_normed_std": 0.3288871272869989, "train/extr_return_rate": 0.734284075439399, "train/extr_return_raw_mag": 8.792979101762704, "train/extr_return_raw_max": 8.792979101762704, "train/extr_return_raw_mean": 2.072277752220208, "train/extr_return_raw_min": -0.5359738551555796, "train/extr_return_raw_std": 1.7953092806728175, "train/extr_reward_mag": 1.0302941477890555, "train/extr_reward_max": 1.0302941477890555, "train/extr_reward_mean": 0.0366477074352562, "train/extr_reward_min": -0.3736291438975233, "train/extr_reward_std": 0.18007665957119448, "train/image_loss_mean": 6.552277433111312, "train/image_loss_std": 11.034654221636183, "train/model_loss_mean": 14.7935132033436, "train/model_loss_std": 14.703538258870443, "train/model_opt_grad_norm": 58.351637268066405, "train/model_opt_grad_steps": 36035.397163120564, "train/model_opt_loss": 13204.97876149712, "train/model_opt_model_opt_grad_overflow": 0.0070921985815602835, "train/model_opt_model_opt_grad_scale": 895.3900709219859, "train/policy_entropy_mag": 2.4168511739013887, "train/policy_entropy_max": 2.4168511739013887, "train/policy_entropy_mean": 0.4799301495366063, "train/policy_entropy_min": 0.07937507178132416, "train/policy_entropy_std": 0.5217456348398899, "train/policy_logprob_mag": 7.438383616454212, "train/policy_logprob_max": -0.009455659241805263, "train/policy_logprob_mean": -0.4786227616012519, "train/policy_logprob_min": -7.438383616454212, "train/policy_logprob_std": 1.023761103339229, "train/policy_randomness_mag": 0.8530424038569132, "train/policy_randomness_max": 0.8530424038569132, "train/policy_randomness_mean": 0.1693942812106288, "train/policy_randomness_min": 0.028015917114226532, "train/policy_randomness_std": 0.18415331301536966, "train/post_ent_mag": 59.999377744417664, "train/post_ent_max": 59.999377744417664, "train/post_ent_mean": 42.512264251708984, "train/post_ent_min": 20.726190445270944, "train/post_ent_std": 7.483231804895063, "train/prior_ent_mag": 68.78017301085993, "train/prior_ent_max": 68.78017301085993, "train/prior_ent_mean": 56.18270543957433, "train/prior_ent_min": 39.640551546786696, "train/prior_ent_std": 4.378061925265806, "train/rep_loss_mean": 13.63989098190416, "train/rep_loss_std": 9.055708168246221, "train/reward_avg": 0.029005984029342943, "train/reward_loss_mean": 0.05691965339137307, "train/reward_loss_std": 0.2519661252591627, "train/reward_max_data": 1.0170212806539332, "train/reward_max_pred": 1.0110606048124056, "train/reward_neg_acc": 0.9922420268363141, "train/reward_neg_loss": 0.030005327967517342, "train/reward_pos_acc": 0.9712519869736745, "train/reward_pos_loss": 0.8327576399694944, "train/reward_pred": 0.028480045636125068, "train/reward_rate": 0.03366023936170213, "train_stats/sum_log_reward": 7.833333541098095, "train_stats/max_log_achievement_collect_coal": 0.20952380952380953, "train_stats/max_log_achievement_collect_drink": 7.619047619047619, "train_stats/max_log_achievement_collect_sapling": 2.2285714285714286, "train_stats/max_log_achievement_collect_stone": 2.619047619047619, "train_stats/max_log_achievement_collect_wood": 12.41904761904762, "train_stats/max_log_achievement_defeat_skeleton": 0.02857142857142857, "train_stats/max_log_achievement_defeat_zombie": 0.9142857142857143, "train_stats/max_log_achievement_eat_cow": 0.13333333333333333, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.009523809523809525, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4952380952380953, "train_stats/max_log_achievement_make_wood_sword": 0.9714285714285714, "train_stats/max_log_achievement_place_furnace": 0.01904761904761905, "train_stats/max_log_achievement_place_plant": 2.1714285714285713, "train_stats/max_log_achievement_place_stone": 0.0380952380952381, "train_stats/max_log_achievement_place_table": 2.704761904761905, "train_stats/max_log_achievement_wake_up": 1.361904761904762, "train_stats/mean_log_entropy": 0.48777646124362944, "eval_stats/sum_log_reward": 7.537500277161598, "eval_stats/max_log_achievement_collect_coal": 0.3125, "eval_stats/max_log_achievement_collect_drink": 6.1875, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 2.9375, "eval_stats/max_log_achievement_collect_wood": 8.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.0019863543566316366, "report/cont_loss_std": 0.059681884944438934, "report/cont_neg_acc": 0.8333333730697632, "report/cont_neg_loss": 0.3387637138366699, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.4188179875418427e-06, "report/cont_pred": 0.9950879216194153, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 15.534627914428711, "report/dyn_loss_std": 9.518424987792969, "report/image_loss_mean": 6.270109176635742, "report/image_loss_std": 14.385069847106934, "report/model_loss_mean": 15.642946243286133, "report/model_loss_std": 18.031097412109375, "report/post_ent_mag": 59.35374069213867, "report/post_ent_max": 59.35374069213867, "report/post_ent_mean": 40.45698165893555, "report/post_ent_min": 17.079395294189453, "report/post_ent_std": 7.0406293869018555, "report/prior_ent_mag": 69.13259887695312, "report/prior_ent_max": 69.13259887695312, "report/prior_ent_mean": 55.909934997558594, "report/prior_ent_min": 39.151885986328125, "report/prior_ent_std": 4.189178466796875, "report/rep_loss_mean": 15.534627914428711, "report/rep_loss_std": 9.518424987792969, "report/reward_avg": 0.02968750149011612, "report/reward_loss_mean": 0.0500740185379982, "report/reward_loss_std": 0.19357028603553772, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011281967163086, "report/reward_neg_acc": 0.9969635605812073, "report/reward_neg_loss": 0.025839542970061302, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7151758074760437, "report/reward_pred": 0.0294745285063982, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.2820324375061318e-05, "eval/cont_loss_std": 0.0006071478128433228, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0008884251583367586, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.9425795471761376e-05, "eval/cont_pred": 0.9960781335830688, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.571353912353516, "eval/dyn_loss_std": 10.367438316345215, "eval/image_loss_mean": 13.236006736755371, "eval/image_loss_std": 17.318416595458984, "eval/model_loss_mean": 23.27513313293457, "eval/model_loss_std": 20.84554100036621, "eval/post_ent_mag": 59.39997863769531, "eval/post_ent_max": 59.39997863769531, "eval/post_ent_mean": 42.03375244140625, "eval/post_ent_min": 19.56606674194336, "eval/post_ent_std": 7.338830947875977, "eval/prior_ent_mag": 69.13259887695312, "eval/prior_ent_max": 69.13259887695312, "eval/prior_ent_mean": 56.55078125, "eval/prior_ent_min": 37.96576690673828, "eval/prior_ent_std": 4.094006061553955, "eval/rep_loss_mean": 16.571353912353516, "eval/rep_loss_std": 10.367438316345215, "eval/reward_avg": 0.0185546875, "eval/reward_loss_mean": 0.09628988802433014, "eval/reward_loss_std": 0.6615331768989563, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011794567108154, "eval/reward_neg_acc": 0.9960000514984131, "eval/reward_neg_loss": 0.03553763031959534, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 2.627634048461914, "eval/reward_pred": 0.011716476641595364, "eval/reward_rate": 0.0234375, "replay/size": 589369.0, "replay/inserts": 22568.0, "replay/samples": 22560.0, "replay/insert_wait_avg": 1.3702623981907199e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.166576108188494e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4272.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1655275294843238e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0125863552094, "timer/env.step_count": 2821.0, "timer/env.step_total": 247.9856882095337, "timer/env.step_frac": 0.24798256701285953, "timer/env.step_avg": 0.08790701460812964, "timer/env.step_min": 0.02200627326965332, "timer/env.step_max": 2.187323808670044, "timer/replay._sample_count": 22560.0, "timer/replay._sample_total": 11.016138553619385, "timer/replay._sample_frac": 0.011015999902331628, "timer/replay._sample_avg": 0.0004883040139015684, "timer/replay._sample_min": 0.0003998279571533203, "timer/replay._sample_max": 0.010424375534057617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3355.0, "timer/agent.policy_total": 54.66158366203308, "timer/agent.policy_frac": 0.054660895680583986, "timer/agent.policy_avg": 0.016292573371693913, "timer/agent.policy_min": 0.009179830551147461, "timer/agent.policy_max": 0.10751724243164062, "timer/dataset_train_count": 1410.0, "timer/dataset_train_total": 0.14774537086486816, "timer/dataset_train_frac": 0.00014774351131255492, "timer/dataset_train_avg": 0.00010478395096799161, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.00022554397583007812, "timer/agent.train_count": 1410.0, "timer/agent.train_total": 631.4498784542084, "timer/agent.train_frac": 0.6314419309017719, "timer/agent.train_avg": 0.447836793229935, "timer/agent.train_min": 0.43286609649658203, "timer/agent.train_max": 1.5890207290649414, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47020435333251953, "timer/agent.report_frac": 0.0004701984352479946, "timer/agent.report_avg": 0.23510217666625977, "timer/agent.report_min": 0.22800111770629883, "timer/agent.report_max": 0.2422032356262207, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.266293422962167e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 22.567416571796286}
{"step": 590000, "time": 27367.24724841118, "episode/length": 342.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9854227405247813, "episode/intrinsic_return": 0.0}
{"step": 590064, "time": 27370.894213438034, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 27392.918328523636, "eval_episode/length": 160.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 590096, "time": 27394.979524374008, "eval_episode/length": 171.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 590096, "time": 27397.74277997017, "eval_episode/length": 196.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 590096, "time": 27399.45803141594, "eval_episode/length": 199.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.995}
{"step": 590096, "time": 27401.10534644127, "eval_episode/length": 202.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9704433497536946}
{"step": 590096, "time": 27402.920832395554, "eval_episode/length": 207.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 590096, "time": 27404.64655327797, "eval_episode/length": 209.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 590096, "time": 27407.40846014023, "eval_episode/length": 239.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9958333333333333}
{"step": 590696, "time": 27426.957014799118, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 590888, "time": 27434.907092809677, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 591016, "time": 27440.74879717827, "episode/length": 250.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 591240, "time": 27449.91943216324, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 591448, "time": 27458.9893348217, "episode/length": 172.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 591800, "time": 27473.14654660225, "episode/length": 224.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 591832, "time": 27476.157967090607, "episode/length": 433.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9976958525345622, "episode/intrinsic_return": 0.0}
{"step": 592016, "time": 27484.682201862335, "episode/length": 140.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 592088, "time": 27488.98600244522, "episode/length": 278.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 592320, "time": 27499.268858909607, "episode/length": 162.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 592392, "time": 27503.524836301804, "episode/length": 46.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 592528, "time": 27510.461550951004, "episode/length": 54.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 592808, "time": 27521.814192533493, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 593128, "time": 27534.05029964447, "episode/length": 165.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 593136, "time": 27536.7500436306, "episode/length": 75.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 593696, "time": 27557.983691692352, "episode/length": 374.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 594080, "time": 27573.277701616287, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.0}
{"step": 594112, "time": 27576.406606912613, "episode/length": 223.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 594616, "time": 27595.3246114254, "episode/length": 421.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.985781990521327, "episode/intrinsic_return": 0.0}
{"step": 594672, "time": 27598.994307518005, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 594992, "time": 27611.430455207825, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 595024, "time": 27614.50142455101, "episode/length": 328.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9969604863221885, "episode/intrinsic_return": 0.0}
{"step": 595352, "time": 27627.485091924667, "episode/length": 439.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 595592, "time": 27636.977982759476, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 595856, "time": 27647.568206071854, "episode/length": 154.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 595952, "time": 27652.183107614517, "episode/length": 233.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 596168, "time": 27660.61878991127, "episode/length": 378.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9973614775725593, "episode/intrinsic_return": 0.0}
{"step": 596216, "time": 27663.6750061512, "episode/length": 192.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 596256, "time": 27666.780807733536, "episode/length": 37.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 596288, "time": 27669.41842365265, "episode/length": 161.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 596712, "time": 27684.59221291542, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 596896, "time": 27692.344782829285, "episode/length": 192.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 597688, "time": 27720.14000582695, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 597824, "time": 27726.64369726181, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 597888, "time": 27730.307792901993, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 597912, "time": 27732.369230747223, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 597968, "time": 27736.037111759186, "episode/length": 209.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 597984, "time": 27738.196407556534, "episode/length": 298.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.0}
{"step": 598360, "time": 27753.40131020546, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9562841530054644, "episode/intrinsic_return": 0.0}
{"step": 598544, "time": 27761.098547935486, "episode/length": 335.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 599032, "time": 27778.722774982452, "episode/length": 167.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 599328, "time": 27790.308044433594, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 599376, "time": 27793.566969633102, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 599480, "time": 27798.361206769943, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 599832, "time": 27811.924541711807, "episode/length": 43.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 599840, "time": 27814.4957010746, "episode/length": 63.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 599872, "time": 27817.586644411087, "episode/length": 235.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 27850.129144906998, "eval_episode/length": 154.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 600080, "time": 27853.360196113586, "eval_episode/length": 179.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 600080, "time": 27856.760078430176, "eval_episode/length": 207.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9663461538461539}
{"step": 600080, "time": 27859.79427742958, "eval_episode/length": 230.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 600080, "time": 27862.763582468033, "eval_episode/length": 251.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9801587301587301}
{"step": 600080, "time": 27865.989023685455, "eval_episode/length": 277.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9748201438848921}
{"step": 600080, "time": 27870.91123151779, "eval_episode/length": 331.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9969879518072289}
{"step": 600080, "time": 27875.619534015656, "eval_episode/length": 203.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 600120, "time": 27876.736625432968, "episode/length": 268.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 600256, "time": 27883.000849723816, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 600536, "time": 27893.496333122253, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 600704, "time": 27901.01109814644, "episode/length": 165.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 601080, "time": 27914.721548318863, "episode/length": 154.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 601176, "time": 27919.416036844254, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 601816, "time": 27942.528119802475, "episode/length": 431.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 601976, "time": 27949.7785923481, "episode/length": 267.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9738805970149254, "episode/intrinsic_return": 0.0}
{"step": 602056, "time": 27953.97686982155, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 602304, "time": 27964.147888183594, "episode/length": 152.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 602392, "time": 27968.466006994247, "episode/length": 210.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 602520, "time": 27974.204023361206, "episode/length": 167.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 602856, "time": 27986.856112718582, "episode/length": 341.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9853801169590644, "episode/intrinsic_return": 0.0}
{"step": 602944, "time": 27991.511430501938, "episode/length": 335.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9970238095238095, "episode/intrinsic_return": 0.0}
{"step": 603088, "time": 27997.80154275894, "episode/length": 128.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 603272, "time": 28005.156040668488, "episode/length": 161.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 603688, "time": 28020.730523109436, "episode/length": 161.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 604080, "time": 28036.391268014908, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 604176, "time": 28041.669341802597, "episode/length": 294.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 604304, "time": 28048.095468521118, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 604592, "time": 28060.058459997177, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 604664, "time": 28064.13943171501, "episode/length": 214.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 604720, "time": 28067.720271587372, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 604912, "time": 28075.73455429077, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 604928, "time": 28077.991653442383, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 605416, "time": 28095.097640514374, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 605448, "time": 28097.707646131516, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 605888, "time": 28114.036462068558, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 605904, "time": 28116.073509454727, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 606072, "time": 28122.93107700348, "episode/length": 184.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 606192, "time": 28128.744884490967, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 606640, "time": 28146.611082315445, "episode/length": 215.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 606736, "time": 28151.381275177002, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 607328, "time": 28172.352680444717, "episode/length": 156.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 607384, "time": 28175.525697231293, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 607440, "time": 28179.029846191406, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 607720, "time": 28189.5529024601, "episode/length": 426.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9929742388758782, "episode/intrinsic_return": 0.0}
{"step": 607744, "time": 28192.11278486252, "episode/length": 231.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 608064, "time": 28204.233951807022, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 608216, "time": 28210.625273942947, "episode/length": 196.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 608576, "time": 28224.046056747437, "episode/length": 394.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9772151898734177, "episode/intrinsic_return": 0.0}
{"step": 608848, "time": 28234.669371128082, "episode/length": 189.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 608864, "time": 28236.721884965897, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 609120, "time": 28246.701110839844, "episode/length": 174.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 609168, "time": 28250.27918124199, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 609584, "time": 28265.80409836769, "episode/length": 189.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 609768, "time": 28273.184919834137, "episode/length": 193.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 28299.201229572296, "eval_episode/length": 39.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9}
{"step": 610064, "time": 28305.464983463287, "eval_episode/length": 157.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 610064, "time": 28307.223872423172, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 610064, "time": 28310.46740269661, "eval_episode/length": 203.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 610064, "time": 28312.29354405403, "eval_episode/length": 45.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 610064, "time": 28314.573133468628, "eval_episode/length": 228.0, "eval_episode/score": 9.099999964237213, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 610064, "time": 28316.425674915314, "eval_episode/length": 193.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 610064, "time": 28318.694585323334, "eval_episode/length": 253.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9803149606299213}
{"step": 610448, "time": 28331.325272083282, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 610448, "time": 28331.336002588272, "episode/length": 337.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 610560, "time": 28340.04058599472, "episode/length": 247.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 610720, "time": 28346.933205366135, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 610856, "time": 28352.776114940643, "episode/length": 50.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 611056, "time": 28361.130322933197, "episode/length": 61.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9354838709677419, "episode/intrinsic_return": 0.0}
{"step": 611057, "time": 28363.163073301315, "train_stats/sum_log_reward": 8.158823747260898, "train_stats/max_log_achievement_collect_coal": 0.4117647058823529, "train_stats/max_log_achievement_collect_drink": 5.6568627450980395, "train_stats/max_log_achievement_collect_sapling": 2.2549019607843137, "train_stats/max_log_achievement_collect_stone": 3.3333333333333335, "train_stats/max_log_achievement_collect_wood": 12.42156862745098, "train_stats/max_log_achievement_defeat_skeleton": 0.0196078431372549, "train_stats/max_log_achievement_defeat_zombie": 0.7745098039215687, "train_stats/max_log_achievement_eat_cow": 0.16666666666666666, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.00980392156862745, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7254901960784315, "train_stats/max_log_achievement_make_wood_sword": 0.9509803921568627, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.1862745098039214, "train_stats/max_log_achievement_place_stone": 0.0392156862745098, "train_stats/max_log_achievement_place_table": 3.215686274509804, "train_stats/max_log_achievement_wake_up": 1.2352941176470589, "train_stats/mean_log_entropy": 0.46197325371059716, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.440742261482008, "train/action_min": 0.0, "train/action_std": 3.40924209356308, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04080374354045048, "train/actor_opt_grad_steps": 37435.0, "train/actor_opt_loss": -7.070083556753216, "train/adv_mag": 0.5191622374184204, "train/adv_max": 0.47795143633177783, "train/adv_mean": 0.002843130446776878, "train/adv_min": -0.41015121363329166, "train/adv_std": 0.05922183013436469, "train/cont_avg": 0.9946215080492424, "train/cont_loss_mean": 0.00015931250530041834, "train/cont_loss_std": 0.004871266288949466, "train/cont_neg_acc": 0.9948773460857796, "train/cont_neg_loss": 0.013253965590427635, "train/cont_pos_acc": 0.9999627854787942, "train/cont_pos_loss": 8.164091249747555e-05, "train/cont_pred": 0.994619942072666, "train/cont_rate": 0.9946215080492424, "train/dyn_loss_mean": 13.72726701967644, "train/dyn_loss_std": 9.031162746024854, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8479953593376911, "train/extr_critic_critic_opt_grad_steps": 37435.0, "train/extr_critic_critic_opt_loss": 16303.80477627841, "train/extr_critic_mag": 7.5723875291419755, "train/extr_critic_max": 7.5723875291419755, "train/extr_critic_mean": 2.051809819358768, "train/extr_critic_min": -0.23499289425936612, "train/extr_critic_std": 1.812629068439657, "train/extr_return_normed_mag": 1.5636487729621655, "train/extr_return_normed_max": 1.5636487729621655, "train/extr_return_normed_mean": 0.3726062545496406, "train/extr_return_normed_min": -0.10065806211169923, "train/extr_return_normed_std": 0.32962156200047693, "train/extr_return_rate": 0.7252885690241149, "train/extr_return_raw_mag": 8.730761499115914, "train/extr_return_raw_max": 8.730761499115914, "train/extr_return_raw_mean": 2.0677129301157864, "train/extr_return_raw_min": -0.5799080082638697, "train/extr_return_raw_std": 1.8443832578081074, "train/extr_reward_mag": 1.0328894691033796, "train/extr_reward_max": 1.0328894691033796, "train/extr_reward_mean": 0.03742989210524794, "train/extr_reward_min": -0.45351162101283216, "train/extr_reward_std": 0.18214641138911247, "train/image_loss_mean": 6.58986594098987, "train/image_loss_std": 11.132545644586736, "train/model_loss_mean": 14.883187886440393, "train/model_loss_std": 14.756447315216064, "train/model_opt_grad_norm": 52.2893947688016, "train/model_opt_grad_steps": 37399.68939393939, "train/model_opt_loss": 18603.984892874054, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1259.469696969697, "train/policy_entropy_mag": 2.4292313221729165, "train/policy_entropy_max": 2.4292313221729165, "train/policy_entropy_mean": 0.48578781273328897, "train/policy_entropy_min": 0.07937506755644624, "train/policy_entropy_std": 0.5476889930891268, "train/policy_logprob_mag": 7.438383676789024, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.48650145621010754, "train/policy_logprob_min": -7.438383676789024, "train/policy_logprob_std": 1.0429432902372244, "train/policy_randomness_mag": 0.8574120506192698, "train/policy_randomness_max": 0.8574120506192698, "train/policy_randomness_mean": 0.17146177928556094, "train/policy_randomness_min": 0.02801591550197565, "train/policy_randomness_std": 0.19331018209005846, "train/post_ent_mag": 60.13375562610048, "train/post_ent_max": 60.13375562610048, "train/post_ent_mean": 42.48516946850401, "train/post_ent_min": 20.628531152551826, "train/post_ent_std": 7.490104415199974, "train/prior_ent_mag": 68.73322486877441, "train/prior_ent_max": 68.73322486877441, "train/prior_ent_mean": 56.29455667553526, "train/prior_ent_min": 39.56233351158373, "train/prior_ent_std": 4.432246036601789, "train/rep_loss_mean": 13.72726701967644, "train/rep_loss_std": 9.031162746024854, "train/reward_avg": 0.028705758607071457, "train/reward_loss_mean": 0.05680252021799485, "train/reward_loss_std": 0.24479928985238075, "train/reward_max_data": 1.0166666706403096, "train/reward_max_pred": 1.0111749885660228, "train/reward_neg_acc": 0.9922679120844061, "train/reward_neg_loss": 0.030156687776924984, "train/reward_pos_acc": 0.9695141717340007, "train/reward_pos_loss": 0.8276662429173788, "train/reward_pred": 0.02805501268471055, "train/reward_rate": 0.03352124763257576, "eval_stats/sum_log_reward": 8.016666829586029, "eval_stats/max_log_achievement_collect_coal": 0.16666666666666666, "eval_stats/max_log_achievement_collect_drink": 6.166666666666667, "eval_stats/max_log_achievement_collect_sapling": 1.9583333333333333, "eval_stats/max_log_achievement_collect_stone": 3.1666666666666665, "eval_stats/max_log_achievement_collect_wood": 11.708333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.08333333333333333, "eval_stats/max_log_achievement_defeat_zombie": 1.0833333333333333, "eval_stats/max_log_achievement_eat_cow": 0.20833333333333334, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.7083333333333333, "eval_stats/max_log_achievement_make_wood_sword": 1.0833333333333333, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.9166666666666667, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.0833333333333335, "eval_stats/max_log_achievement_wake_up": 1.3333333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 1.560157443236676e-07, "report/cont_loss_std": 3.713283831530134e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00011867500143125653, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.016139953932907e-08, "report/cont_pred": 0.9990235567092896, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 14.414989471435547, "report/dyn_loss_std": 9.368125915527344, "report/image_loss_mean": 7.694082736968994, "report/image_loss_std": 12.642528533935547, "report/model_loss_mean": 16.398725509643555, "report/model_loss_std": 16.48175621032715, "report/post_ent_mag": 60.524410247802734, "report/post_ent_max": 60.524410247802734, "report/post_ent_mean": 42.97454071044922, "report/post_ent_min": 19.678302764892578, "report/post_ent_std": 7.761599063873291, "report/prior_ent_mag": 68.88545227050781, "report/prior_ent_max": 68.88545227050781, "report/prior_ent_mean": 57.05080795288086, "report/prior_ent_min": 39.499794006347656, "report/prior_ent_std": 4.208232879638672, "report/rep_loss_mean": 14.414989471435547, "report/rep_loss_std": 9.368125915527344, "report/reward_avg": 0.01972656138241291, "report/reward_loss_mean": 0.05564913898706436, "report/reward_loss_std": 0.2713949382305145, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0035715103149414, "report/reward_neg_acc": 0.987000048160553, "report/reward_neg_loss": 0.02773134596645832, "report/reward_pos_acc": 0.875, "report/reward_pos_loss": 1.2188907861709595, "report/reward_pred": 0.014593069441616535, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.7103936897910899e-06, "eval/cont_loss_std": 4.2549298086669296e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005705371149815619, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.901278589069079e-08, "eval/cont_pred": 0.9970719814300537, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.66349983215332, "eval/dyn_loss_std": 10.726249694824219, "eval/image_loss_mean": 9.469964981079102, "eval/image_loss_std": 10.880166053771973, "eval/model_loss_mean": 19.547523498535156, "eval/model_loss_std": 15.233743667602539, "eval/post_ent_mag": 57.13929748535156, "eval/post_ent_max": 57.13929748535156, "eval/post_ent_mean": 42.24774932861328, "eval/post_ent_min": 22.669158935546875, "eval/post_ent_std": 7.413046360015869, "eval/prior_ent_mag": 68.88545227050781, "eval/prior_ent_max": 68.88545227050781, "eval/prior_ent_mean": 56.773353576660156, "eval/prior_ent_min": 39.066551208496094, "eval/prior_ent_std": 4.229049205780029, "eval/rep_loss_mean": 16.66349983215332, "eval/rep_loss_std": 10.726249694824219, "eval/reward_avg": 0.0283203125, "eval/reward_loss_mean": 0.07945653796195984, "eval/reward_loss_std": 0.49149757623672485, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0035834312438965, "eval/reward_neg_acc": 0.9939393401145935, "eval/reward_neg_loss": 0.034555427730083466, "eval/reward_pos_acc": 0.8823529481887817, "eval/reward_pos_loss": 1.3868714570999146, "eval/reward_pred": 0.024673890322446823, "eval/reward_rate": 0.033203125, "replay/size": 610553.0, "replay/inserts": 21184.0, "replay/samples": 21184.0, "replay/insert_wait_avg": 1.3897583743956874e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.174592454627922e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6824.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2378619955404982e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3341698646545, "timer/env.step_count": 2648.0, "timer/env.step_total": 242.96336436271667, "timer/env.step_frac": 0.24288220045066508, "timer/env.step_avg": 0.09175353639075404, "timer/env.step_min": 0.021953821182250977, "timer/env.step_max": 3.4791080951690674, "timer/replay._sample_count": 21184.0, "timer/replay._sample_total": 10.339986562728882, "timer/replay._sample_frac": 0.010336532405094074, "timer/replay._sample_avg": 0.0004881035952949812, "timer/replay._sample_min": 0.0003871917724609375, "timer/replay._sample_max": 0.010894775390625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3501.0, "timer/agent.policy_total": 55.72719359397888, "timer/agent.policy_frac": 0.05570857746618691, "timer/agent.policy_avg": 0.015917507453293026, "timer/agent.policy_min": 0.00932455062866211, "timer/agent.policy_max": 0.10374760627746582, "timer/dataset_train_count": 1324.0, "timer/dataset_train_total": 0.13922405242919922, "timer/dataset_train_frac": 0.00013917754348832876, "timer/dataset_train_avg": 0.00010515411814894201, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0008797645568847656, "timer/agent.train_count": 1324.0, "timer/agent.train_total": 593.6287000179291, "timer/agent.train_frac": 0.5934303934636634, "timer/agent.train_avg": 0.4483600453307621, "timer/agent.train_min": 0.43329477310180664, "timer/agent.train_max": 1.980125904083252, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4712991714477539, "timer/agent.report_frac": 0.00047114173007958013, "timer/agent.report_avg": 0.23564958572387695, "timer/agent.report_min": 0.22751617431640625, "timer/agent.report_max": 0.24378299713134766, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.793571472167969e-05, "timer/dataset_eval_frac": 5.791636081922344e-08, "timer/dataset_eval_avg": 5.793571472167969e-05, "timer/dataset_eval_min": 5.793571472167969e-05, "timer/dataset_eval_max": 5.793571472167969e-05, "fps": 21.176660072510167}
{"step": 611144, "time": 28366.07514476776, "episode/length": 286.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 611328, "time": 28374.047490119934, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 611336, "time": 28375.591027259827, "episode/length": 270.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 611616, "time": 28386.553981542587, "episode/length": 230.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 611728, "time": 28391.744250297546, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 611904, "time": 28398.98914027214, "episode/length": 94.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9578947368421052, "episode/intrinsic_return": 0.0}
{"step": 612208, "time": 28410.700151205063, "episode/length": 37.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 612272, "time": 28414.44702744484, "episode/length": 193.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 612296, "time": 28416.663489580154, "episode/length": 70.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 612456, "time": 28423.453219652176, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 612688, "time": 28433.093341588974, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 612936, "time": 28443.348341226578, "episode/length": 200.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 613024, "time": 28448.47206926346, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 613256, "time": 28458.050879240036, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 613512, "time": 28468.443180322647, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 613552, "time": 28471.53190588951, "episode/length": 167.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 613776, "time": 28480.451533079147, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 614056, "time": 28490.985755205154, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 614112, "time": 28494.563127040863, "episode/length": 206.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 614352, "time": 28504.16406726837, "episode/length": 104.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 614984, "time": 28527.865396499634, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 614992, "time": 28530.068682909012, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 615048, "time": 28533.28398489952, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 615304, "time": 28543.307270765305, "episode/length": 148.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 615496, "time": 28551.220519065857, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 615536, "time": 28554.343678712845, "episode/length": 313.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 615784, "time": 28564.023362398148, "episode/length": 59.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 616344, "time": 28585.018394708633, "episode/length": 425.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 616464, "time": 28591.074607610703, "episode/length": 263.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 616688, "time": 28600.141129016876, "episode/length": 42.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 616720, "time": 28602.80908513069, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 616832, "time": 28608.105899572372, "episode/length": 229.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 616856, "time": 28610.339341640472, "episode/length": 225.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 616904, "time": 28613.38154578209, "episode/length": 170.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 617224, "time": 28625.513493299484, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 617608, "time": 28639.67175745964, "episode/length": 227.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 617688, "time": 28643.903346061707, "episode/length": 106.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 618208, "time": 28663.12998533249, "episode/length": 217.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 618312, "time": 28667.94495177269, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 618344, "time": 28670.618191242218, "episode/length": 206.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 618376, "time": 28673.285511016846, "episode/length": 189.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 618944, "time": 28693.910450458527, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 619072, "time": 28699.670191287994, "episode/length": 293.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 619288, "time": 28708.465621948242, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 619584, "time": 28720.967762708664, "episode/length": 150.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 619928, "time": 28734.272676467896, "episode/length": 42.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 28758.867598056793, "eval_episode/length": 156.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9617834394904459}
{"step": 620048, "time": 28761.43358850479, "eval_episode/length": 180.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 620048, "time": 28763.106297016144, "eval_episode/length": 184.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 620048, "time": 28764.675449371338, "eval_episode/length": 185.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 620048, "time": 28766.517199754715, "eval_episode/length": 188.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 620048, "time": 28768.632781267166, "eval_episode/length": 202.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 620048, "time": 28770.32366013527, "eval_episode/length": 207.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 620048, "time": 28776.766897439957, "eval_episode/length": 138.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 620056, "time": 28776.818841457367, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 620072, "time": 28778.837885141373, "episode/length": 297.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 620072, "time": 28778.847571611404, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 620192, "time": 28786.239451169968, "episode/length": 112.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.0}
{"step": 620480, "time": 28797.603087425232, "episode/length": 283.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 620640, "time": 28804.99117922783, "episode/length": 195.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 621312, "time": 28829.271249055862, "episode/length": 172.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 621480, "time": 28836.131973028183, "episode/length": 175.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 621608, "time": 28841.959953546524, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 621744, "time": 28848.267396450043, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 622232, "time": 28865.869459867477, "episode/length": 254.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 622760, "time": 28886.58746123314, "episode/length": 476.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9979035639412998, "episode/intrinsic_return": 0.0}
{"step": 622880, "time": 28892.33188843727, "episode/length": 195.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 623040, "time": 28899.17426967621, "episode/length": 178.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 623088, "time": 28902.275792598724, "episode/length": 200.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 623104, "time": 28904.302456617355, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 623216, "time": 28909.57161450386, "episode/length": 41.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 623256, "time": 28912.29190659523, "episode/length": 399.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975, "episode/intrinsic_return": 0.0}
{"step": 623448, "time": 28920.27607011795, "episode/length": 151.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 623512, "time": 28923.92895078659, "episode/length": 93.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 623568, "time": 28927.50817489624, "episode/length": 365.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9972677595628415, "episode/intrinsic_return": 0.0}
{"step": 623960, "time": 28941.935331106186, "episode/length": 114.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 624456, "time": 28960.482532024384, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 624568, "time": 28965.66276407242, "episode/length": 184.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 624712, "time": 28971.98370909691, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 624712, "time": 28971.992691755295, "episode/length": 142.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 625288, "time": 28995.133142471313, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 625352, "time": 28999.29954648018, "episode/length": 229.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 625512, "time": 29006.868611574173, "episode/length": 281.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 625960, "time": 29024.22976875305, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 626096, "time": 29031.091615200043, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 626160, "time": 29035.18712735176, "episode/length": 180.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 626200, "time": 29038.515319108963, "episode/length": 185.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 626752, "time": 29058.855571985245, "episode/length": 412.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9878934624697336, "episode/intrinsic_return": 0.0}
{"step": 626944, "time": 29066.943081617355, "episode/length": 198.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 627568, "time": 29089.15321135521, "episode/length": 200.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 627856, "time": 29100.298120737076, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 627912, "time": 29103.54924440384, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 627912, "time": 29103.558759212494, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 627952, "time": 29108.494153022766, "episode/length": 304.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.0}
{"step": 628000, "time": 29111.646436929703, "episode/length": 53.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 628264, "time": 29121.928691148758, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 628728, "time": 29139.440296411514, "episode/length": 429.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9930232558139535, "episode/intrinsic_return": 0.0}
{"step": 628856, "time": 29145.186785936356, "episode/length": 238.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 629296, "time": 29161.747524023056, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 629504, "time": 29170.246124505997, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 629536, "time": 29172.841079235077, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 629712, "time": 29180.221378326416, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 629864, "time": 29186.57516694069, "episode/length": 40.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 629912, "time": 29190.274634838104, "episode/length": 249.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 29218.19158911705, "eval_episode/length": 190.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 630032, "time": 29220.831127643585, "eval_episode/length": 201.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 630032, "time": 29222.90098285675, "eval_episode/length": 204.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 630032, "time": 29224.941772460938, "eval_episode/length": 205.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 630032, "time": 29227.655564785004, "eval_episode/length": 217.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 630032, "time": 29230.623918533325, "eval_episode/length": 235.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9661016949152542}
{"step": 630032, "time": 29233.512051343918, "eval_episode/length": 250.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9800796812749004}
{"step": 630032, "time": 29238.08242201805, "eval_episode/length": 305.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9967320261437909}
{"step": 630416, "time": 29251.288049697876, "episode/length": 210.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 630448, "time": 29254.17493867874, "episode/length": 143.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 630640, "time": 29262.706064224243, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 631104, "time": 29281.681950092316, "episode/length": 154.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 631224, "time": 29287.014363765717, "episode/length": 214.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 631232, "time": 29289.002135038376, "episode/length": 421.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9976303317535545, "episode/intrinsic_return": 0.0}
{"step": 631376, "time": 29295.329064130783, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 631408, "time": 29297.85498523712, "episode/length": 37.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 631504, "time": 29302.609047412872, "episode/length": 198.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 631720, "time": 29311.219954013824, "episode/length": 158.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 632288, "time": 29332.336676359177, "episode/length": 233.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 632456, "time": 29339.418424367905, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 632624, "time": 29346.71474480629, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 632736, "time": 29351.937470912933, "episode/length": 188.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 632920, "time": 29359.30165553093, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 632969, "time": 29363.498143672943, "train_stats/sum_log_reward": 7.865765964662707, "train_stats/max_log_achievement_collect_coal": 0.35135135135135137, "train_stats/max_log_achievement_collect_drink": 5.963963963963964, "train_stats/max_log_achievement_collect_sapling": 2.126126126126126, "train_stats/max_log_achievement_collect_stone": 3.7027027027027026, "train_stats/max_log_achievement_collect_wood": 12.207207207207206, "train_stats/max_log_achievement_defeat_skeleton": 0.018018018018018018, "train_stats/max_log_achievement_defeat_zombie": 0.9369369369369369, "train_stats/max_log_achievement_eat_cow": 0.09009009009009009, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.009009009009009009, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6126126126126126, "train_stats/max_log_achievement_make_wood_sword": 1.09009009009009, "train_stats/max_log_achievement_place_furnace": 0.018018018018018018, "train_stats/max_log_achievement_place_plant": 2.081081081081081, "train_stats/max_log_achievement_place_stone": 0.018018018018018018, "train_stats/max_log_achievement_place_table": 3.4144144144144146, "train_stats/max_log_achievement_wake_up": 1.2882882882882882, "train_stats/mean_log_entropy": 0.4784346433641674, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.495794811388002, "train/action_min": 0.0, "train/action_std": 3.480621346592033, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.041812537768243875, "train/actor_opt_grad_steps": 38780.0, "train/actor_opt_loss": -6.259769616553383, "train/adv_mag": 0.5147814391738307, "train/adv_max": 0.4728347278424423, "train/adv_mean": 0.0028940379713017434, "train/adv_min": -0.42955562581111045, "train/adv_std": 0.06007164368664261, "train/cont_avg": 0.9944756500912408, "train/cont_loss_mean": 0.00014759271250152465, "train/cont_loss_std": 0.004393994475781687, "train/cont_neg_acc": 0.9903186283567372, "train/cont_neg_loss": 0.017192463450288308, "train/cont_pos_acc": 0.9999784727166169, "train/cont_pos_loss": 6.232984239014877e-05, "train/cont_pred": 0.99449323389652, "train/cont_rate": 0.9944756500912408, "train/dyn_loss_mean": 13.692751000397397, "train/dyn_loss_std": 9.068680143704379, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8395443245442245, "train/extr_critic_critic_opt_grad_steps": 38780.0, "train/extr_critic_critic_opt_loss": 16184.815251482663, "train/extr_critic_mag": 7.51029513700165, "train/extr_critic_max": 7.51029513700165, "train/extr_critic_mean": 2.045025153751791, "train/extr_critic_min": -0.22844145593852022, "train/extr_critic_std": 1.7731254240022087, "train/extr_return_normed_mag": 1.5764247849039787, "train/extr_return_normed_max": 1.5764247849039787, "train/extr_return_normed_mean": 0.3754604257588839, "train/extr_return_normed_min": -0.09995508990692396, "train/extr_return_normed_std": 0.32826069660865476, "train/extr_return_rate": 0.7315009497377994, "train/extr_return_raw_mag": 8.67412341946233, "train/extr_return_raw_max": 8.67412341946233, "train/extr_return_raw_mean": 2.0609591677241084, "train/extr_return_raw_min": -0.5568052505272149, "train/extr_return_raw_std": 1.8075352480811795, "train/extr_reward_mag": 1.03158315254824, "train/extr_reward_max": 1.03158315254824, "train/extr_reward_mean": 0.03954178786897746, "train/extr_reward_min": -0.4123852444391181, "train/extr_reward_std": 0.1874611991165328, "train/image_loss_mean": 6.349473995013828, "train/image_loss_std": 10.917133721121907, "train/model_loss_mean": 14.622806757906057, "train/model_loss_std": 14.597775974412905, "train/model_opt_grad_norm": 53.741320032272895, "train/model_opt_grad_steps": 38743.437956204376, "train/model_opt_loss": 18397.761070084398, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1259.1240875912408, "train/policy_entropy_mag": 2.415951335517159, "train/policy_entropy_max": 2.415951335517159, "train/policy_entropy_mean": 0.47020377969219734, "train/policy_entropy_min": 0.07937505917392508, "train/policy_entropy_std": 0.5363798546094964, "train/policy_logprob_mag": 7.438383603618092, "train/policy_logprob_max": -0.009455658427446428, "train/policy_logprob_mean": -0.4695294579885302, "train/policy_logprob_min": -7.438383603618092, "train/policy_logprob_std": 1.0286326491049607, "train/policy_randomness_mag": 0.8527248018849505, "train/policy_randomness_max": 0.8527248018849505, "train/policy_randomness_mean": 0.16596129960822362, "train/policy_randomness_min": 0.02801591258523238, "train/policy_randomness_std": 0.18931854989406835, "train/post_ent_mag": 59.76331320992352, "train/post_ent_max": 59.76331320992352, "train/post_ent_mean": 42.428690694544436, "train/post_ent_min": 20.8175340220876, "train/post_ent_std": 7.455338617310907, "train/prior_ent_mag": 68.84711834984104, "train/prior_ent_max": 68.84711834984104, "train/prior_ent_mean": 56.18977361525933, "train/prior_ent_min": 39.20659161310126, "train/prior_ent_std": 4.433649379841603, "train/rep_loss_mean": 13.692751000397397, "train/rep_loss_std": 9.068680143704379, "train/reward_avg": 0.030361826857891832, "train/reward_loss_mean": 0.05753472229860125, "train/reward_loss_std": 0.2472231731797657, "train/reward_max_data": 1.0145985436265486, "train/reward_max_pred": 1.0100705084139414, "train/reward_neg_acc": 0.9926609379531693, "train/reward_neg_loss": 0.029763857487344395, "train/reward_pos_acc": 0.9720352962069267, "train/reward_pos_loss": 0.8224849966320679, "train/reward_pred": 0.029761260171441265, "train/reward_rate": 0.03517050638686131, "eval_stats/sum_log_reward": 8.225000113248825, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 5.125, "eval_stats/max_log_achievement_collect_sapling": 2.3125, "eval_stats/max_log_achievement_collect_stone": 3.0625, "eval_stats/max_log_achievement_collect_wood": 14.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.1875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.875, "eval_stats/max_log_achievement_make_wood_sword": 1.3125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 4.0, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00028018929879181087, "report/cont_loss_std": 0.008856683038175106, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0474265031516552, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.313189497726853e-06, "report/cont_pred": 0.9943804740905762, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 14.831205368041992, "report/dyn_loss_std": 9.008279800415039, "report/image_loss_mean": 5.772243022918701, "report/image_loss_std": 11.068253517150879, "report/model_loss_mean": 14.71269702911377, "report/model_loss_std": 14.773061752319336, "report/post_ent_mag": 63.076515197753906, "report/post_ent_max": 63.076515197753906, "report/post_ent_mean": 41.36475372314453, "report/post_ent_min": 21.11478042602539, "report/post_ent_std": 7.2543439865112305, "report/prior_ent_mag": 68.92107391357422, "report/prior_ent_max": 68.92107391357422, "report/prior_ent_mean": 56.50743103027344, "report/prior_ent_min": 42.819358825683594, "report/prior_ent_std": 4.096786022186279, "report/rep_loss_mean": 14.831205368041992, "report/rep_loss_std": 9.008279800415039, "report/reward_avg": 0.01669921912252903, "report/reward_loss_mean": 0.04145050048828125, "report/reward_loss_std": 0.16804713010787964, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029785633087158, "report/reward_neg_acc": 0.9970029592514038, "report/reward_neg_loss": 0.026462974026799202, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6937335133552551, "report/reward_pred": 0.017196884378790855, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.0005761450156569481, "eval/cont_loss_std": 0.01813008263707161, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.08302891254425049, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.623522262496408e-06, "eval/cont_pred": 0.9935863614082336, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 17.74810218811035, "eval/dyn_loss_std": 10.579469680786133, "eval/image_loss_mean": 9.869799613952637, "eval/image_loss_std": 17.098901748657227, "eval/model_loss_mean": 20.63914680480957, "eval/model_loss_std": 20.92110824584961, "eval/post_ent_mag": 57.654075622558594, "eval/post_ent_max": 57.654075622558594, "eval/post_ent_mean": 41.28263473510742, "eval/post_ent_min": 20.38178825378418, "eval/post_ent_std": 7.519289970397949, "eval/prior_ent_mag": 68.92107391357422, "eval/prior_ent_max": 68.92107391357422, "eval/prior_ent_mean": 56.39221954345703, "eval/prior_ent_min": 39.35894012451172, "eval/prior_ent_std": 4.337493896484375, "eval/rep_loss_mean": 17.74810218811035, "eval/rep_loss_std": 10.579469680786133, "eval/reward_avg": 0.0458984375, "eval/reward_loss_mean": 0.11990784853696823, "eval/reward_loss_std": 0.6712034940719604, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005862712860107, "eval/reward_neg_acc": 0.9907503128051758, "eval/reward_neg_loss": 0.03574195131659508, "eval/reward_pos_acc": 0.8039215803146362, "eval/reward_pos_loss": 1.7256613969802856, "eval/reward_pred": 0.037574946880340576, "eval/reward_rate": 0.0498046875, "replay/size": 632465.0, "replay/inserts": 21912.0, "replay/samples": 21920.0, "replay/insert_wait_avg": 1.3775767179769772e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.181063798222228e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5072.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.236937399542294e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.385807991027832e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3207700252533, "timer/env.step_count": 2739.0, "timer/env.step_total": 257.7301781177521, "timer/env.step_frac": 0.25764753251224165, "timer/env.step_avg": 0.09409645057238118, "timer/env.step_min": 0.022560834884643555, "timer/env.step_max": 3.394641876220703, "timer/replay._sample_count": 21920.0, "timer/replay._sample_total": 10.842147588729858, "timer/replay._sample_frac": 0.010838670868001818, "timer/replay._sample_avg": 0.0004946235213836614, "timer/replay._sample_min": 0.0004000663757324219, "timer/replay._sample_max": 0.02787160873413086, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3373.0, "timer/agent.policy_total": 53.66690111160278, "timer/agent.policy_frac": 0.05364969189857764, "timer/agent.policy_avg": 0.015910732615358074, "timer/agent.policy_min": 0.009114503860473633, "timer/agent.policy_max": 0.10273957252502441, "timer/dataset_train_count": 1370.0, "timer/dataset_train_total": 0.1453249454498291, "timer/dataset_train_frac": 0.00014527834451159136, "timer/dataset_train_avg": 0.00010607660251812343, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0009248256683349609, "timer/agent.train_count": 1370.0, "timer/agent.train_total": 615.5737898349762, "timer/agent.train_frac": 0.6153763955330408, "timer/agent.train_avg": 0.449323934186114, "timer/agent.train_min": 0.43450212478637695, "timer/agent.train_max": 1.6153411865234375, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47019219398498535, "timer/agent.report_frac": 0.0004700414187872109, "timer/agent.report_avg": 0.23509609699249268, "timer/agent.report_min": 0.22840023040771484, "timer/agent.report_max": 0.2417919635772705, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.907773938319437e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 21.904689262747294}
{"step": 632976, "time": 29363.520325422287, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 633536, "time": 29384.17677783966, "episode/length": 269.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 633872, "time": 29396.903591156006, "episode/length": 295.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 634160, "time": 29407.980219602585, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 634216, "time": 29411.160586595535, "episode/length": 161.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 634512, "time": 29422.59267807007, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 634600, "time": 29426.84752225876, "episode/length": 202.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 634864, "time": 29437.300274133682, "episode/length": 300.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 635032, "time": 29444.084987401962, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 635472, "time": 29460.328167438507, "episode/length": 199.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 635680, "time": 29468.716494083405, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 635744, "time": 29472.379282712936, "episode/length": 142.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 636016, "time": 29482.886751413345, "episode/length": 423.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787735849056604, "episode/intrinsic_return": 0.0}
{"step": 636024, "time": 29484.5441634655, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 636304, "time": 29495.601035118103, "episode/length": 158.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 636400, "time": 29500.321252822876, "episode/length": 235.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 636552, "time": 29506.64124894142, "episode/length": 66.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9253731343283582, "episode/intrinsic_return": 0.0}
{"step": 637016, "time": 29523.47401380539, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 637120, "time": 29528.608254909515, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 637208, "time": 29532.854187250137, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 637584, "time": 29547.0379049778, "episode/length": 339.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9970588235294118, "episode/intrinsic_return": 0.0}
{"step": 638040, "time": 29563.291380405426, "episode/length": 56.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9298245614035088, "episode/intrinsic_return": 0.0}
{"step": 638384, "time": 29576.40929365158, "episode/length": 247.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 638520, "time": 29582.329560995102, "episode/length": 187.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 638576, "time": 29586.042565584183, "episode/length": 318.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9968652037617555, "episode/intrinsic_return": 0.0}
{"step": 638648, "time": 29589.772444725037, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 638784, "time": 29596.01511979103, "episode/length": 207.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 639000, "time": 29606.024489879608, "episode/length": 223.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 639112, "time": 29611.435336112976, "episode/length": 350.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 639232, "time": 29617.040111780167, "episode/length": 105.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 639568, "time": 29629.69289803505, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 29660.16978955269, "eval_episode/length": 37.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.8947368421052632}
{"step": 640016, "time": 29667.324151039124, "eval_episode/length": 135.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 640016, "time": 29669.04479289055, "eval_episode/length": 138.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9568345323741008}
{"step": 640016, "time": 29670.931436538696, "eval_episode/length": 147.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9662162162162162}
{"step": 640016, "time": 29672.92747616768, "eval_episode/length": 158.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 640016, "time": 29675.830943346024, "eval_episode/length": 153.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.974025974025974}
{"step": 640016, "time": 29678.304762601852, "eval_episode/length": 52.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 640016, "time": 29682.031461954117, "eval_episode/length": 263.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9810606060606061}
{"step": 640208, "time": 29688.343849897385, "episode/length": 210.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 640328, "time": 29693.653588056564, "episode/length": 209.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 640352, "time": 29696.109315395355, "episode/length": 139.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 640528, "time": 29703.50293827057, "episode/length": 217.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9862385321100917, "episode/intrinsic_return": 0.0}
{"step": 640752, "time": 29712.601001501083, "episode/length": 218.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 640776, "time": 29714.670076608658, "episode/length": 274.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9781818181818182, "episode/intrinsic_return": 0.0}
{"step": 640936, "time": 29721.421914815903, "episode/length": 227.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 641448, "time": 29739.806282758713, "episode/length": 234.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 641888, "time": 29756.28114748001, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 641992, "time": 29761.655740499496, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 642048, "time": 29765.879155397415, "episode/length": 211.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 642320, "time": 29777.33611679077, "episode/length": 223.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 642688, "time": 29792.10102915764, "episode/length": 238.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 642936, "time": 29802.303612947464, "episode/length": 272.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 643240, "time": 29814.651349782944, "episode/length": 287.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9756944444444444, "episode/intrinsic_return": 0.0}
{"step": 643512, "time": 29825.82646870613, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 643816, "time": 29837.29901123047, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 643904, "time": 29841.92202115059, "episode/length": 251.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 644056, "time": 29848.3915643692, "episode/length": 325.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.0}
{"step": 644176, "time": 29854.172248125076, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 644416, "time": 29863.85689163208, "episode/length": 146.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 644568, "time": 29870.88762831688, "episode/length": 48.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 644728, "time": 29877.950093507767, "episode/length": 300.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 644976, "time": 29887.998309612274, "episode/length": 144.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 645224, "time": 29897.600661754608, "episode/length": 285.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 645440, "time": 29906.5674264431, "episode/length": 240.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 645576, "time": 29912.386137008667, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 645688, "time": 29917.631585597992, "episode/length": 203.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 646056, "time": 29931.218802690506, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 646376, "time": 29943.394664525986, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 646440, "time": 29947.064455747604, "episode/length": 233.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 646688, "time": 29956.97970843315, "episode/length": 155.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 646872, "time": 29964.369270324707, "episode/length": 236.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 646896, "time": 29967.06703209877, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 647184, "time": 29979.75711131096, "episode/length": 200.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 647720, "time": 29998.989753246307, "episode/length": 207.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 647784, "time": 30002.720579862595, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 647784, "time": 30002.730392932892, "episode/length": 261.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 648016, "time": 30014.061237573624, "episode/length": 36.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 648160, "time": 30020.293952465057, "episode/length": 157.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 648408, "time": 30029.906559228897, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 648512, "time": 30035.69459629059, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 648520, "time": 30037.773636817932, "episode/length": 228.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 649288, "time": 30065.406769514084, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 649288, "time": 30065.41686606407, "episode/length": 262.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 649680, "time": 30081.89453125, "episode/length": 236.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 649768, "time": 30086.265392303467, "episode/length": 156.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 649808, "time": 30089.36651778221, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 30117.13280940056, "eval_episode/length": 168.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 650000, "time": 30118.813449144363, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 650000, "time": 30120.576001167297, "eval_episode/length": 178.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 650000, "time": 30125.100549459457, "eval_episode/length": 249.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.996}
{"step": 650000, "time": 30127.705775022507, "eval_episode/length": 275.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9963768115942029}
{"step": 650000, "time": 30127.71491408348, "eval_episode/length": 275.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9963768115942029}
{"step": 650000, "time": 30131.863523244858, "eval_episode/length": 295.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9831081081081081}
{"step": 650000, "time": 30133.58179306984, "eval_episode/length": 298.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9966555183946488}
{"step": 650064, "time": 30135.716102600098, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 650104, "time": 30138.495431900024, "episode/length": 260.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 650264, "time": 30145.267255067825, "episode/length": 231.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 650584, "time": 30157.35803794861, "episode/length": 64.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 650808, "time": 30166.224707603455, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 650888, "time": 30170.385954380035, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 651032, "time": 30176.800228595734, "episode/length": 168.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 651232, "time": 30185.17555141449, "episode/length": 177.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 651288, "time": 30188.34336733818, "episode/length": 189.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 651328, "time": 30191.425130605698, "episode/length": 152.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 651808, "time": 30208.989827156067, "episode/length": 192.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 651904, "time": 30214.229196310043, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 652384, "time": 30232.588207244873, "episode/length": 143.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 652528, "time": 30239.000766038895, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 653208, "time": 30262.797615528107, "episode/length": 162.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 653248, "time": 30265.888041496277, "episode/length": 244.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 653272, "time": 30268.047694683075, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 653528, "time": 30277.925985574722, "episode/length": 274.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 653672, "time": 30284.126406431198, "episode/length": 357.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9860335195530726, "episode/intrinsic_return": 0.0}
{"step": 654136, "time": 30301.095839977264, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 654384, "time": 30311.064321041107, "episode/length": 106.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 654432, "time": 30314.17762875557, "episode/length": 442.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954853273137697, "episode/intrinsic_return": 0.0}
{"step": 654440, "time": 30315.709579467773, "episode/length": 256.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 654568, "time": 30321.53053832054, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 654632, "time": 30325.152187108994, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 654840, "time": 30333.578950166702, "episode/length": 145.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 655184, "time": 30346.704785108566, "episode/length": 238.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9874476987447699, "episode/intrinsic_return": 0.0}
{"step": 655536, "time": 30361.38553929329, "episode/length": 136.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 655545, "time": 30363.974319696426, "train_stats/sum_log_reward": 8.333645117617099, "train_stats/max_log_achievement_collect_coal": 0.2523364485981308, "train_stats/max_log_achievement_collect_drink": 5.289719626168225, "train_stats/max_log_achievement_collect_sapling": 1.9813084112149533, "train_stats/max_log_achievement_collect_stone": 3.8130841121495327, "train_stats/max_log_achievement_collect_wood": 13.728971962616823, "train_stats/max_log_achievement_defeat_skeleton": 0.009345794392523364, "train_stats/max_log_achievement_defeat_zombie": 1.0654205607476634, "train_stats/max_log_achievement_eat_cow": 0.2336448598130841, "train_stats/max_log_achievement_make_stone_pickaxe": 0.028037383177570093, "train_stats/max_log_achievement_make_stone_sword": 0.009345794392523364, "train_stats/max_log_achievement_make_wood_pickaxe": 1.9906542056074767, "train_stats/max_log_achievement_make_wood_sword": 1.4205607476635513, "train_stats/max_log_achievement_place_furnace": 0.009345794392523364, "train_stats/max_log_achievement_place_plant": 1.897196261682243, "train_stats/max_log_achievement_place_stone": 0.037383177570093455, "train_stats/max_log_achievement_place_table": 3.869158878504673, "train_stats/max_log_achievement_wake_up": 1.3457943925233644, "train_stats/mean_log_entropy": 0.4947783699102491, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.345348168772163, "train/action_min": 0.0, "train/action_std": 3.2920631770546556, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04265253758388208, "train/actor_opt_grad_steps": 40170.0, "train/actor_opt_loss": -5.050655091168188, "train/adv_mag": 0.5403212488543058, "train/adv_max": 0.491150771261107, "train/adv_mean": 0.0034170356826404282, "train/adv_min": -0.4345124869059164, "train/adv_std": 0.06115430899968384, "train/cont_avg": 0.9946254432624113, "train/cont_loss_mean": 0.00022933730779132165, "train/cont_loss_std": 0.006787007374299693, "train/cont_neg_acc": 0.9919537326968308, "train/cont_neg_loss": 0.022043509340296977, "train/cont_pos_acc": 0.9999720851580302, "train/cont_pos_loss": 0.00011807277353762895, "train/cont_pred": 0.994631994277873, "train/cont_rate": 0.9946254432624113, "train/dyn_loss_mean": 13.542121190551326, "train/dyn_loss_std": 9.11443863185585, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8261528103909594, "train/extr_critic_critic_opt_grad_steps": 40170.0, "train/extr_critic_critic_opt_loss": 16256.02830646055, "train/extr_critic_mag": 7.472358331612662, "train/extr_critic_max": 7.472358331612662, "train/extr_critic_mean": 2.068004769636384, "train/extr_critic_min": -0.23020940215875071, "train/extr_critic_std": 1.7414654307331598, "train/extr_return_normed_mag": 1.6018969792846247, "train/extr_return_normed_max": 1.6018969792846247, "train/extr_return_normed_mean": 0.38366973421252365, "train/extr_return_normed_min": -0.10619908026981016, "train/extr_return_normed_std": 0.328331839531026, "train/extr_return_rate": 0.7482394576072693, "train/extr_return_raw_mag": 8.667765590316016, "train/extr_return_raw_max": 8.667765590316016, "train/extr_return_raw_mean": 2.086431833023721, "train/extr_return_raw_min": -0.5598375678907895, "train/extr_return_raw_std": 1.7736655938709882, "train/extr_reward_mag": 1.0314182744804004, "train/extr_reward_max": 1.0314182744804004, "train/extr_reward_mean": 0.040362710820127885, "train/extr_reward_min": -0.40739860264122063, "train/extr_reward_std": 0.18958530485207306, "train/image_loss_mean": 6.311186090428778, "train/image_loss_std": 10.98221791382377, "train/model_loss_mean": 14.494612200040343, "train/model_loss_std": 14.68750088603784, "train/model_opt_grad_norm": 52.42440283213947, "train/model_opt_grad_steps": 40132.09219858156, "train/model_opt_loss": 11710.69142010195, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 806.7375886524823, "train/policy_entropy_mag": 2.425293915660669, "train/policy_entropy_max": 2.425293915660669, "train/policy_entropy_mean": 0.47861142847554905, "train/policy_entropy_min": 0.07937506739552139, "train/policy_entropy_std": 0.5484300703867108, "train/policy_logprob_mag": 7.4383836333633315, "train/policy_logprob_max": -0.009455658402954432, "train/policy_logprob_mean": -0.4785271616692239, "train/policy_logprob_min": -7.4383836333633315, "train/policy_logprob_std": 1.04400276165482, "train/policy_randomness_mag": 0.8560223236997077, "train/policy_randomness_max": 0.8560223236997077, "train/policy_randomness_mean": 0.1689288323441296, "train/policy_randomness_min": 0.028015915528996616, "train/policy_randomness_std": 0.19357174920274856, "train/post_ent_mag": 60.130889540868445, "train/post_ent_max": 60.130889540868445, "train/post_ent_mean": 42.59922825698312, "train/post_ent_min": 20.45363689990754, "train/post_ent_std": 7.556199493137657, "train/prior_ent_mag": 68.9424708481376, "train/prior_ent_max": 68.9424708481376, "train/prior_ent_mean": 56.22673624458042, "train/prior_ent_min": 39.88577124413023, "train/prior_ent_std": 4.3561360971302, "train/rep_loss_mean": 13.542121190551326, "train/rep_loss_std": 9.11443863185585, "train/reward_avg": 0.0313718970006345, "train/reward_loss_mean": 0.057924129835045926, "train/reward_loss_std": 0.25166137907521946, "train/reward_max_data": 1.0248227009536526, "train/reward_max_pred": 1.0175012383900635, "train/reward_neg_acc": 0.9928059079122882, "train/reward_neg_loss": 0.029154447640510315, "train/reward_pos_acc": 0.9722355168761937, "train/reward_pos_loss": 0.8276427548827855, "train/reward_pred": 0.0305384773602511, "train/reward_rate": 0.036098182624113476, "eval_stats/sum_log_reward": 7.350000210106373, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.1875, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 3.625, "eval_stats/max_log_achievement_collect_wood": 10.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.1875, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 3.25, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 2.3866318770160433e-06, "report/cont_loss_std": 3.072614345001057e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00024057974223978817, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.110955498821568e-07, "report/cont_pred": 0.9921889305114746, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 12.085234642028809, "report/dyn_loss_std": 8.572044372558594, "report/image_loss_mean": 5.547939300537109, "report/image_loss_std": 7.950503826141357, "report/model_loss_mean": 12.847116470336914, "report/model_loss_std": 11.447602272033691, "report/post_ent_mag": 61.762786865234375, "report/post_ent_max": 61.762786865234375, "report/post_ent_mean": 43.47164535522461, "report/post_ent_min": 22.144153594970703, "report/post_ent_std": 7.612146854400635, "report/prior_ent_mag": 68.91570281982422, "report/prior_ent_max": 68.91570281982422, "report/prior_ent_mean": 55.883628845214844, "report/prior_ent_min": 40.76322937011719, "report/prior_ent_std": 4.754480838775635, "report/rep_loss_mean": 12.085234642028809, "report/rep_loss_std": 8.572044372558594, "report/reward_avg": 0.02314453199505806, "report/reward_loss_mean": 0.04803445190191269, "report/reward_loss_std": 0.17058636248111725, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005848407745361, "report/reward_neg_acc": 0.9959757924079895, "report/reward_neg_loss": 0.027432983741164207, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7306296825408936, "report/reward_pred": 0.022113749757409096, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 7.774318873998709e-06, "eval/cont_loss_std": 0.00021566631039604545, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0001103716203942895, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.37197615308105e-06, "eval/cont_pred": 0.9960869550704956, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.559297561645508, "eval/dyn_loss_std": 10.006028175354004, "eval/image_loss_mean": 7.461597442626953, "eval/image_loss_std": 11.51856517791748, "eval/model_loss_mean": 17.524715423583984, "eval/model_loss_std": 15.33619213104248, "eval/post_ent_mag": 59.38336181640625, "eval/post_ent_max": 59.38336181640625, "eval/post_ent_mean": 42.110809326171875, "eval/post_ent_min": 18.31208610534668, "eval/post_ent_std": 7.4441070556640625, "eval/prior_ent_mag": 68.91570281982422, "eval/prior_ent_max": 68.91570281982422, "eval/prior_ent_mean": 56.6368293762207, "eval/prior_ent_min": 41.75262451171875, "eval/prior_ent_std": 4.116039276123047, "eval/rep_loss_mean": 16.559297561645508, "eval/rep_loss_std": 10.006028175354004, "eval/reward_avg": 0.03798828274011612, "eval/reward_loss_mean": 0.12753117084503174, "eval/reward_loss_std": 0.6942389607429504, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0019567012786865, "eval/reward_neg_acc": 0.9795917868614197, "eval/reward_neg_loss": 0.06345807760953903, "eval/reward_pos_acc": 0.8636363744735718, "eval/reward_pos_loss": 1.5546140670776367, "eval/reward_pred": 0.038697436451911926, "eval/reward_rate": 0.04296875, "replay/size": 655041.0, "replay/inserts": 22576.0, "replay/samples": 22576.0, "replay/insert_wait_avg": 1.35919500292826e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.299978467101835e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4504.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1784357033656716e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4633271694183, "timer/env.step_count": 2822.0, "timer/env.step_total": 247.96073722839355, "timer/env.step_frac": 0.24784590348747876, "timer/env.step_avg": 0.08786702240552571, "timer/env.step_min": 0.022762060165405273, "timer/env.step_max": 3.4485743045806885, "timer/replay._sample_count": 22576.0, "timer/replay._sample_total": 11.15549898147583, "timer/replay._sample_frac": 0.011150332729374256, "timer/replay._sample_avg": 0.0004941308903913816, "timer/replay._sample_min": 0.0004107952117919922, "timer/replay._sample_max": 0.027811527252197266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3385.0, "timer/agent.policy_total": 54.601743936538696, "timer/agent.policy_frac": 0.05457645718111609, "timer/agent.policy_avg": 0.016130500424383663, "timer/agent.policy_min": 0.009027242660522461, "timer/agent.policy_max": 0.14690089225769043, "timer/dataset_train_count": 1411.0, "timer/dataset_train_total": 0.14583849906921387, "timer/dataset_train_frac": 0.00014577095942320092, "timer/dataset_train_avg": 0.00010335825589597014, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0002567768096923828, "timer/agent.train_count": 1411.0, "timer/agent.train_total": 630.0194406509399, "timer/agent.train_frac": 0.6297276707117646, "timer/agent.train_avg": 0.44650562767607366, "timer/agent.train_min": 0.4335293769836426, "timer/agent.train_max": 1.600212574005127, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47699499130249023, "timer/agent.report_frac": 0.000476774088913422, "timer/agent.report_avg": 0.23849749565124512, "timer/agent.report_min": 0.23116397857666016, "timer/agent.report_max": 0.24583101272583008, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7167130747787536e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 22.565232892352363}
{"step": 655824, "time": 30373.291093587875, "episode/length": 173.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 655856, "time": 30375.90010213852, "episode/length": 214.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 656040, "time": 30383.405220270157, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 656120, "time": 30387.680379867554, "episode/length": 36.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 656376, "time": 30397.654782533646, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 656656, "time": 30408.771369457245, "episode/length": 260.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 656736, "time": 30412.94643521309, "episode/length": 149.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 656816, "time": 30417.314663410187, "episode/length": 272.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 656864, "time": 30420.48265337944, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 657336, "time": 30437.42066717148, "episode/length": 184.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 657512, "time": 30444.818766593933, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 657712, "time": 30453.350377321243, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 657720, "time": 30454.85359120369, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 658008, "time": 30466.013026714325, "episode/length": 158.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 658144, "time": 30472.82882332802, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 658192, "time": 30475.955709457397, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 658440, "time": 30485.45387649536, "episode/length": 36.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 658528, "time": 30490.08004307747, "episode/length": 207.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 658864, "time": 30502.94309616089, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 659136, "time": 30513.51111483574, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 659368, "time": 30522.385390520096, "episode/length": 169.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 659400, "time": 30524.95988702774, "episode/length": 210.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 659464, "time": 30528.65347790718, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 659672, "time": 30537.10890698433, "episode/length": 153.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 30567.107360839844, "eval_episode/length": 54.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 660088, "time": 30572.495428562164, "eval_episode/length": 154.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 660088, "time": 30575.168035030365, "eval_episode/length": 180.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.994475138121547}
{"step": 660088, "time": 30577.821370363235, "eval_episode/length": 209.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9809523809523809}
{"step": 660088, "time": 30582.144174575806, "eval_episode/length": 222.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 660088, "time": 30584.082503795624, "eval_episode/length": 287.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9965277777777778}
{"step": 660088, "time": 30587.048005580902, "eval_episode/length": 324.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9784615384615385}
{"step": 660088, "time": 30590.85561132431, "eval_episode/length": 378.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9920844327176781}
{"step": 660112, "time": 30591.888267040253, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 660584, "time": 30608.762595415115, "episode/length": 180.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 660648, "time": 30612.39889717102, "episode/length": 155.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 660648, "time": 30612.409163475037, "episode/length": 306.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 660856, "time": 30622.50763297081, "episode/length": 147.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 661056, "time": 30630.991380929947, "episode/length": 315.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9778481012658228, "episode/intrinsic_return": 0.0}
{"step": 661472, "time": 30646.43621325493, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 661600, "time": 30652.66951227188, "episode/length": 266.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 661688, "time": 30657.458362579346, "episode/length": 289.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 661784, "time": 30662.671861171722, "episode/length": 141.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 662560, "time": 30691.072229623795, "episode/length": 246.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 662576, "time": 30693.582318782806, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 662640, "time": 30697.812616586685, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 662888, "time": 30708.19556260109, "episode/length": 279.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 663096, "time": 30717.455350637436, "episode/length": 202.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 663104, "time": 30720.01864695549, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 663312, "time": 30729.14783835411, "episode/length": 202.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 663464, "time": 30736.14236688614, "episode/length": 45.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 663704, "time": 30747.728034973145, "episode/length": 262.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 663808, "time": 30753.661673069, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 664232, "time": 30769.73559832573, "episode/length": 167.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 664424, "time": 30777.653606653214, "episode/length": 164.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 664864, "time": 30794.08107805252, "episode/length": 277.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 664976, "time": 30799.391293764114, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 665088, "time": 30804.551424503326, "episode/length": 159.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 665120, "time": 30807.216921567917, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 665392, "time": 30817.70580792427, "episode/length": 259.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 665528, "time": 30823.54902100563, "episode/length": 50.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 665872, "time": 30836.826018095016, "episode/length": 204.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 665872, "time": 30836.83517384529, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 666032, "time": 30845.335525751114, "episode/length": 431.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9976851851851852, "episode/intrinsic_return": 0.0}
{"step": 666176, "time": 30851.5964076519, "episode/length": 37.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 666544, "time": 30865.232243061066, "episode/length": 195.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 666568, "time": 30867.507191181183, "episode/length": 212.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 666656, "time": 30872.1604013443, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 666960, "time": 30883.77273464203, "episode/length": 178.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 667120, "time": 30890.60626912117, "episode/length": 155.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 667376, "time": 30900.608943462372, "episode/length": 100.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 667480, "time": 30905.411923646927, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 667920, "time": 30922.10626220703, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 667952, "time": 30925.233826637268, "episode/length": 357.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9860335195530726, "episode/intrinsic_return": 0.0}
{"step": 668000, "time": 30928.864532232285, "episode/length": 181.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 668064, "time": 30933.131856441498, "episode/length": 235.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 668736, "time": 30957.87535071373, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 668776, "time": 30961.17160463333, "episode/length": 206.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 669144, "time": 30975.542786836624, "episode/length": 220.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 669424, "time": 30986.78525209427, "episode/length": 177.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 669544, "time": 30992.055179595947, "episode/length": 198.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 669712, "time": 30999.380056858063, "episode/length": 223.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 669808, "time": 31004.110433340073, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 669856, "time": 31007.250516414642, "episode/length": 296.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9831649831649831, "episode/intrinsic_return": 0.0}
{"step": 669976, "time": 31012.444477796555, "episode/length": 32.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8787878787878788, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 31031.650484085083, "eval_episode/length": 38.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 670072, "time": 31036.661338329315, "eval_episode/length": 127.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9921875}
{"step": 670072, "time": 31039.286712408066, "eval_episode/length": 153.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 670072, "time": 31042.45502781868, "eval_episode/length": 188.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 670072, "time": 31046.027433633804, "eval_episode/length": 191.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 670072, "time": 31048.601924180984, "eval_episode/length": 213.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 670072, "time": 31050.967853307724, "eval_episode/length": 45.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9130434782608695}
{"step": 670072, "time": 31054.159757614136, "eval_episode/length": 271.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9779411764705882}
{"step": 670088, "time": 31054.69681453705, "episode/length": 168.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 670816, "time": 31080.52916955948, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 670824, "time": 31082.140100955963, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 671112, "time": 31093.268140554428, "episode/length": 195.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 671296, "time": 31101.1354637146, "episode/length": 314.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 671344, "time": 31104.3273665905, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 671384, "time": 31106.950845003128, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 671400, "time": 31108.930117845535, "episode/length": 35.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 671792, "time": 31125.202261447906, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 672328, "time": 31144.313200473785, "episode/length": 308.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 672392, "time": 31147.94956922531, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 672488, "time": 31152.73202896118, "episode/length": 135.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 672728, "time": 31162.165905714035, "episode/length": 172.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 673000, "time": 31172.728237628937, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 673816, "time": 31202.39747595787, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 673880, "time": 31206.62449645996, "episode/length": 311.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9967948717948718, "episode/intrinsic_return": 0.0}
{"step": 674088, "time": 31215.48673725128, "episode/length": 408.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951100244498777, "episode/intrinsic_return": 0.0}
{"step": 674272, "time": 31223.331663370132, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 674288, "time": 31225.45707988739, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 674472, "time": 31233.00939798355, "episode/length": 259.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 674504, "time": 31235.54556632042, "episode/length": 400.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9875311720698254, "episode/intrinsic_return": 0.0}
{"step": 675568, "time": 31272.600430488586, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 675576, "time": 31274.201281547546, "episode/length": 211.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 675840, "time": 31284.746008634567, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 675936, "time": 31289.5205783844, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 676104, "time": 31296.41342329979, "episode/length": 228.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9694323144104804, "episode/intrinsic_return": 0.0}
{"step": 676168, "time": 31300.141253709793, "episode/length": 459.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 676456, "time": 31311.203778982162, "episode/length": 329.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 676552, "time": 31315.9305434227, "episode/length": 47.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 676752, "time": 31324.43684196472, "episode/length": 284.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 676872, "time": 31329.67715191841, "episode/length": 162.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 677048, "time": 31337.04964351654, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 677785, "time": 31363.986402750015, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.460522987859712, "train/action_min": 0.0, "train/action_std": 3.415181947269028, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.042277537634690034, "train/actor_opt_grad_steps": 41570.0, "train/actor_opt_loss": -3.46467086511979, "train/adv_mag": 0.5276194193380342, "train/adv_max": 0.47969698820182743, "train/adv_mean": 0.003929891122038989, "train/adv_min": -0.4244303820158938, "train/adv_std": 0.06045029821584551, "train/cont_avg": 0.9948502135791367, "train/cont_loss_mean": 0.00011779649254452929, "train/cont_loss_std": 0.003408419782229728, "train/cont_neg_acc": 0.994835560699161, "train/cont_neg_loss": 0.014408527829309998, "train/cont_pos_acc": 0.9999929216268252, "train/cont_pos_loss": 4.190622511110524e-05, "train/cont_pred": 0.9948552323759888, "train/cont_rate": 0.9948502135791367, "train/dyn_loss_mean": 13.528731428461967, "train/dyn_loss_std": 9.067715850665415, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8505907804845906, "train/extr_critic_critic_opt_grad_steps": 41570.0, "train/extr_critic_critic_opt_loss": 16285.735140793615, "train/extr_critic_mag": 7.635835297673726, "train/extr_critic_max": 7.635835297673726, "train/extr_critic_mean": 2.145739623110929, "train/extr_critic_min": -0.21172431990397061, "train/extr_critic_std": 1.7532569778908929, "train/extr_return_normed_mag": 1.5978405475616455, "train/extr_return_normed_max": 1.5978405475616455, "train/extr_return_normed_mean": 0.38698072849417764, "train/extr_return_normed_min": -0.10489099462040895, "train/extr_return_normed_std": 0.32603319203682085, "train/extr_return_rate": 0.776428585001033, "train/extr_return_raw_mag": 8.806805871373458, "train/extr_return_raw_max": 8.806805871373458, "train/extr_return_raw_mean": 2.1672619564070117, "train/extr_return_raw_min": -0.5294149327192376, "train/extr_return_raw_std": 1.7876134862145074, "train/extr_reward_mag": 1.0398391528095272, "train/extr_reward_max": 1.0398391528095272, "train/extr_reward_mean": 0.04057090157281152, "train/extr_reward_min": -0.41724153388318397, "train/extr_reward_std": 0.19016784440270432, "train/image_loss_mean": 6.225930320273201, "train/image_loss_std": 10.996551417618347, "train/model_loss_mean": 14.399678737997151, "train/model_loss_std": 14.676869502170481, "train/model_opt_grad_norm": 55.72214016015979, "train/model_opt_grad_steps": 41531.1654676259, "train/model_opt_loss": 11529.763889669515, "train/model_opt_model_opt_grad_overflow": 0.007194244604316547, "train/model_opt_model_opt_grad_scale": 795.863309352518, "train/policy_entropy_mag": 2.426870205419527, "train/policy_entropy_max": 2.426870205419527, "train/policy_entropy_mean": 0.4801024689520006, "train/policy_entropy_min": 0.07937507594017673, "train/policy_entropy_std": 0.5451986536705237, "train/policy_logprob_mag": 7.438383603267533, "train/policy_logprob_max": -0.009455662669627357, "train/policy_logprob_mean": -0.47979229216952973, "train/policy_logprob_min": -7.438383603267533, "train/policy_logprob_std": 1.0458956708153375, "train/policy_randomness_mag": 0.8565786828240045, "train/policy_randomness_max": 0.8565786828240045, "train/policy_randomness_mean": 0.16945510384418982, "train/policy_randomness_min": 0.028015918614302606, "train/policy_randomness_std": 0.1924311995720692, "train/post_ent_mag": 60.32798863143372, "train/post_ent_max": 60.32798863143372, "train/post_ent_mean": 42.68018151701783, "train/post_ent_min": 20.354428298181766, "train/post_ent_std": 7.574868167904641, "train/prior_ent_mag": 68.97933493415229, "train/prior_ent_max": 68.97933493415229, "train/prior_ent_mean": 56.289602320828884, "train/prior_ent_min": 40.09965487692853, "train/prior_ent_std": 4.337422484116589, "train/rep_loss_mean": 13.528731428461967, "train/rep_loss_std": 9.067715850665415, "train/reward_avg": 0.030413949976025298, "train/reward_loss_mean": 0.0563917860603161, "train/reward_loss_std": 0.24540749277999932, "train/reward_max_data": 1.011510794111293, "train/reward_max_pred": 1.010002956973563, "train/reward_neg_acc": 0.9929193815739035, "train/reward_neg_loss": 0.02868934747555273, "train/reward_pos_acc": 0.9721750882889727, "train/reward_pos_loss": 0.8193243613346017, "train/reward_pred": 0.029765417919956523, "train/reward_rate": 0.0351632756294964, "train_stats/sum_log_reward": 8.211111309351745, "train_stats/max_log_achievement_collect_coal": 0.2222222222222222, "train_stats/max_log_achievement_collect_drink": 4.064814814814815, "train_stats/max_log_achievement_collect_sapling": 1.8240740740740742, "train_stats/max_log_achievement_collect_stone": 4.268518518518518, "train_stats/max_log_achievement_collect_wood": 12.944444444444445, "train_stats/max_log_achievement_defeat_skeleton": 0.027777777777777776, "train_stats/max_log_achievement_defeat_zombie": 1.0740740740740742, "train_stats/max_log_achievement_eat_cow": 0.1574074074074074, "train_stats/max_log_achievement_make_stone_pickaxe": 0.009259259259259259, "train_stats/max_log_achievement_make_stone_sword": 0.009259259259259259, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7314814814814814, "train_stats/max_log_achievement_make_wood_sword": 1.3888888888888888, "train_stats/max_log_achievement_place_furnace": 0.018518518518518517, "train_stats/max_log_achievement_place_plant": 1.7777777777777777, "train_stats/max_log_achievement_place_stone": 0.07407407407407407, "train_stats/max_log_achievement_place_table": 3.7685185185185186, "train_stats/max_log_achievement_wake_up": 1.2407407407407407, "train_stats/mean_log_entropy": 0.47480783777104485, "eval_stats/sum_log_reward": 7.475000217556953, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 5.0625, "eval_stats/max_log_achievement_collect_sapling": 1.8125, "eval_stats/max_log_achievement_collect_stone": 3.75, "eval_stats/max_log_achievement_collect_wood": 12.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.9375, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0005596785922534764, "report/cont_loss_std": 0.01696113497018814, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.18077093362808228, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.0164581403369084e-05, "report/cont_pred": 0.997449517250061, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.177714347839355, "report/dyn_loss_std": 9.356021881103516, "report/image_loss_mean": 7.407268524169922, "report/image_loss_std": 12.87985610961914, "report/model_loss_mean": 15.365248680114746, "report/model_loss_std": 16.57721710205078, "report/post_ent_mag": 62.8383674621582, "report/post_ent_max": 62.8383674621582, "report/post_ent_mean": 42.80989456176758, "report/post_ent_min": 21.818511962890625, "report/post_ent_std": 7.832911968231201, "report/prior_ent_mag": 69.04444885253906, "report/prior_ent_max": 69.04444885253906, "report/prior_ent_mean": 56.12468719482422, "report/prior_ent_min": 41.069236755371094, "report/prior_ent_std": 4.49869441986084, "report/rep_loss_mean": 13.177714347839355, "report/rep_loss_std": 9.356021881103516, "report/reward_avg": 0.02587890625, "report/reward_loss_mean": 0.050792619585990906, "report/reward_loss_std": 0.24680888652801514, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0035855770111084, "report/reward_neg_acc": 0.9889335632324219, "report/reward_neg_loss": 0.027787277474999428, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.8130362629890442, "report/reward_pred": 0.02808930166065693, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.0057553936348995e-06, "eval/cont_loss_std": 8.259835340140853e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.406862667063251e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.963202281440317e-07, "eval/cont_pred": 0.9951168894767761, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.717540740966797, "eval/dyn_loss_std": 10.242530822753906, "eval/image_loss_mean": 13.587507247924805, "eval/image_loss_std": 19.155719757080078, "eval/model_loss_mean": 25.533926010131836, "eval/model_loss_std": 22.597061157226562, "eval/post_ent_mag": 57.96540069580078, "eval/post_ent_max": 57.96540069580078, "eval/post_ent_mean": 40.4240837097168, "eval/post_ent_min": 21.632781982421875, "eval/post_ent_std": 7.241812229156494, "eval/prior_ent_mag": 69.04444885253906, "eval/prior_ent_max": 69.04444885253906, "eval/prior_ent_mean": 56.77241134643555, "eval/prior_ent_min": 41.81113052368164, "eval/prior_ent_std": 3.7172958850860596, "eval/rep_loss_mean": 19.717540740966797, "eval/rep_loss_std": 10.242530822753906, "eval/reward_avg": 0.03642577677965164, "eval/reward_loss_mean": 0.11589290201663971, "eval/reward_loss_std": 0.685843825340271, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.004991054534912, "eval/reward_neg_acc": 0.9887984395027161, "eval/reward_neg_loss": 0.0445299968123436, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 1.7844257354736328, "eval/reward_pred": 0.03019944578409195, "eval/reward_rate": 0.041015625, "replay/size": 677281.0, "replay/inserts": 22240.0, "replay/samples": 22240.0, "replay/insert_wait_avg": 1.3775748314617348e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.411544690029227e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5208.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2085734424503168e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9968891143799, "timer/env.step_count": 2780.0, "timer/env.step_total": 253.7396638393402, "timer/env.step_frac": 0.2537404531968673, "timer/env.step_avg": 0.09127326037386338, "timer/env.step_min": 0.022624492645263672, "timer/env.step_max": 3.318134069442749, "timer/replay._sample_count": 22240.0, "timer/replay._sample_total": 11.000912189483643, "timer/replay._sample_frac": 0.011000946412169643, "timer/replay._sample_avg": 0.0004946453322609551, "timer/replay._sample_min": 0.000396728515625, "timer/replay._sample_max": 0.010977745056152344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3431.0, "timer/agent.policy_total": 54.17324686050415, "timer/agent.policy_frac": 0.05417341538780307, "timer/agent.policy_avg": 0.015789346214078737, "timer/agent.policy_min": 0.009290218353271484, "timer/agent.policy_max": 0.10452938079833984, "timer/dataset_train_count": 1390.0, "timer/dataset_train_total": 0.1463329792022705, "timer/dataset_train_frac": 0.00014633343442884742, "timer/dataset_train_avg": 0.00010527552460595, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.0004134178161621094, "timer/agent.train_count": 1390.0, "timer/agent.train_total": 621.75022149086, "timer/agent.train_frac": 0.6217521556907004, "timer/agent.train_avg": 0.4473023176193237, "timer/agent.train_min": 0.43439817428588867, "timer/agent.train_max": 1.5560908317565918, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4734318256378174, "timer/agent.report_frac": 0.00047343329843465757, "timer/agent.report_avg": 0.2367159128189087, "timer/agent.report_min": 0.2311382293701172, "timer/agent.report_max": 0.2422935962677002, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.6226125287647905e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 22.23976805825849}
{"step": 677856, "time": 31366.410476207733, "episode/length": 174.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 677904, "time": 31369.603219032288, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 677968, "time": 31373.315715551376, "episode/length": 136.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 678120, "time": 31379.771383285522, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 678504, "time": 31393.893750190735, "episode/length": 332.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.993993993993994, "episode/intrinsic_return": 0.0}
{"step": 678768, "time": 31404.315893650055, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 678816, "time": 31407.491215467453, "episode/length": 359.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 679680, "time": 31438.011034727097, "episode/length": 365.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 679752, "time": 31441.592622041702, "episode/length": 230.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 679872, "time": 31447.35141801834, "episode/length": 237.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 31471.186172246933, "eval_episode/length": 44.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 680056, "time": 31473.275563001633, "eval_episode/length": 58.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9491525423728814}
{"step": 680056, "time": 31479.947774410248, "eval_episode/length": 183.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.967391304347826}
{"step": 680056, "time": 31482.306050539017, "eval_episode/length": 202.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 680056, "time": 31484.09340620041, "eval_episode/length": 206.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 680056, "time": 31486.128947019577, "eval_episode/length": 157.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 680056, "time": 31489.99822950363, "eval_episode/length": 272.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9853479853479854}
{"step": 680056, "time": 31492.12980890274, "eval_episode/length": 240.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.979253112033195}
{"step": 680168, "time": 31495.86635708809, "episode/length": 255.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 680360, "time": 31503.808035373688, "episode/length": 60.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 680456, "time": 31508.544045209885, "episode/length": 324.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 680552, "time": 31513.24238038063, "episode/length": 222.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 680784, "time": 31522.714630126953, "episode/length": 245.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 681048, "time": 31532.678153038025, "episode/length": 317.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9874213836477987, "episode/intrinsic_return": 0.0}
{"step": 681344, "time": 31544.43453860283, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 681488, "time": 31551.322402000427, "episode/length": 54.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 681656, "time": 31558.986609458923, "episode/length": 246.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 681672, "time": 31561.654430627823, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 681808, "time": 31568.52977371216, "episode/length": 204.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 682120, "time": 31580.929008960724, "episode/length": 207.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 682376, "time": 31590.944238185883, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 682512, "time": 31597.137913942337, "episode/length": 244.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 682728, "time": 31605.654186964035, "episode/length": 172.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 683200, "time": 31624.210659742355, "episode/length": 173.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 683240, "time": 31627.308393239975, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 683312, "time": 31632.092401266098, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 683344, "time": 31635.217385053635, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 683840, "time": 31654.29136109352, "episode/length": 165.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 684168, "time": 31667.077568769455, "episode/length": 223.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 684224, "time": 31671.23879313469, "episode/length": 262.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 684264, "time": 31674.414398908615, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 684768, "time": 31693.36502623558, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 685032, "time": 31703.499495983124, "episode/length": 210.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 685040, "time": 31705.705597400665, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 685496, "time": 31722.296170949936, "episode/length": 206.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 685728, "time": 31731.629952430725, "episode/length": 194.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 686152, "time": 31747.455155849457, "episode/length": 240.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 686768, "time": 31770.753752470016, "episode/length": 312.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 686848, "time": 31775.38621854782, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 686944, "time": 31780.05786371231, "episode/length": 237.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 687232, "time": 31791.13122868538, "episode/length": 134.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 687384, "time": 31797.566660404205, "episode/length": 235.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 688072, "time": 31821.59553050995, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 688104, "time": 31824.18833041191, "episode/length": 416.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 688128, "time": 31827.021955251694, "episode/length": 299.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 688552, "time": 31844.10511493683, "episode/length": 654.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9969465648854962, "episode/intrinsic_return": 0.0}
{"step": 688568, "time": 31846.293812274933, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 688840, "time": 31856.890484809875, "episode/length": 248.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 688952, "time": 31862.19723391533, "episode/length": 250.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 689344, "time": 31876.840255975723, "episode/length": 158.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9874213836477987, "episode/intrinsic_return": 0.0}
{"step": 689400, "time": 31880.032836914062, "episode/length": 105.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 689888, "time": 31897.824411392212, "episode/length": 312.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9776357827476039, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 31923.30766749382, "eval_episode/length": 163.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 690040, "time": 31925.67837381363, "eval_episode/length": 183.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.967391304347826}
{"step": 690040, "time": 31927.35970377922, "eval_episode/length": 188.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 690040, "time": 31929.745238542557, "eval_episode/length": 206.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 690040, "time": 31932.032201051712, "eval_episode/length": 226.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 690040, "time": 31934.085866212845, "eval_episode/length": 237.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9789915966386554}
{"step": 690040, "time": 31936.259742498398, "eval_episode/length": 251.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.996031746031746}
{"step": 690040, "time": 31938.811773777008, "eval_episode/length": 90.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.989010989010989}
{"step": 690216, "time": 31944.63667702675, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 690600, "time": 31958.939784288406, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 690656, "time": 31962.550665140152, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 690720, "time": 31966.17173099518, "episode/length": 268.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 690968, "time": 31975.62256360054, "episode/length": 357.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9916201117318436, "episode/intrinsic_return": 0.0}
{"step": 691016, "time": 31978.922065496445, "episode/length": 201.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 691248, "time": 31988.356921434402, "episode/length": 128.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9689922480620154, "episode/intrinsic_return": 0.0}
{"step": 691408, "time": 31995.190935134888, "episode/length": 189.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 691672, "time": 32005.140949964523, "episode/length": 442.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9887133182844243, "episode/intrinsic_return": 0.0}
{"step": 691944, "time": 32015.646619319916, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 692480, "time": 32035.2244079113, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 692704, "time": 32044.281749010086, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 692912, "time": 32052.717914819717, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 692968, "time": 32055.839685678482, "episode/length": 295.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 693608, "time": 32078.457170009613, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 693832, "time": 32087.493268966675, "episode/length": 235.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 693832, "time": 32087.501944065094, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 693944, "time": 32094.469494104385, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 693952, "time": 32096.62989974022, "episode/length": 366.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.989100817438692, "episode/intrinsic_return": 0.0}
{"step": 694016, "time": 32100.3078892231, "episode/length": 411.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 694056, "time": 32102.93557524681, "episode/length": 135.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 694464, "time": 32118.163047790527, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 695016, "time": 32137.66971206665, "episode/length": 175.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 695272, "time": 32147.820681333542, "episode/length": 164.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 695312, "time": 32150.94520831108, "episode/length": 161.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 695368, "time": 32154.13135457039, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 695424, "time": 32157.85901093483, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 695584, "time": 32164.700351953506, "episode/length": 190.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 695712, "time": 32170.518193244934, "episode/length": 234.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 695776, "time": 32174.32466840744, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 696376, "time": 32198.05468273163, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 696760, "time": 32213.30743074417, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 696768, "time": 32215.762860536575, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 697176, "time": 32231.70024037361, "episode/length": 198.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 697288, "time": 32237.564193964005, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 697312, "time": 32240.134197235107, "episode/length": 235.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 697432, "time": 32245.41191983223, "episode/length": 257.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 697568, "time": 32251.839024305344, "episode/length": 148.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 697992, "time": 32267.136583566666, "episode/length": 152.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 698024, "time": 32269.745030641556, "episode/length": 157.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 698040, "time": 32271.872069358826, "episode/length": 282.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 698336, "time": 32283.418539762497, "episode/length": 38.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 698552, "time": 32291.878472089767, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 698816, "time": 32302.431819677353, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 698928, "time": 32308.260225772858, "episode/length": 201.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 699024, "time": 32313.529695272446, "episode/length": 128.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 699192, "time": 32320.39667248726, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 699280, "time": 32325.133873701096, "episode/length": 248.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 699584, "time": 32336.794316768646, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 700016, "time": 32352.571808576584, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 32370.7322473526, "eval_episode/length": 96.0, "eval_episode/score": 7.1000000461936, "eval_episode/reward_rate": 0.9896907216494846}
{"step": 700024, "time": 32372.605649232864, "eval_episode/length": 105.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9905660377358491}
{"step": 700024, "time": 32376.5749399662, "eval_episode/length": 163.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 700024, "time": 32380.16184091568, "eval_episode/length": 213.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 700024, "time": 32381.953315019608, "eval_episode/length": 219.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 700024, "time": 32384.763069868088, "eval_episode/length": 144.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 700024, "time": 32388.360599279404, "eval_episode/length": 301.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9801324503311258}
{"step": 700024, "time": 32390.364503383636, "eval_episode/length": 309.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9774193548387097}
{"step": 700025, "time": 32391.38835144043, "train_stats/sum_log_reward": 8.407692469083345, "train_stats/max_log_achievement_collect_coal": 0.3942307692307692, "train_stats/max_log_achievement_collect_drink": 4.730769230769231, "train_stats/max_log_achievement_collect_sapling": 1.7884615384615385, "train_stats/max_log_achievement_collect_stone": 5.240384615384615, "train_stats/max_log_achievement_collect_wood": 12.798076923076923, "train_stats/max_log_achievement_defeat_skeleton": 0.019230769230769232, "train_stats/max_log_achievement_defeat_zombie": 0.9134615384615384, "train_stats/max_log_achievement_eat_cow": 0.125, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6634615384615385, "train_stats/max_log_achievement_make_wood_sword": 1.2596153846153846, "train_stats/max_log_achievement_place_furnace": 0.009615384615384616, "train_stats/max_log_achievement_place_plant": 1.7692307692307692, "train_stats/max_log_achievement_place_stone": 0.057692307692307696, "train_stats/max_log_achievement_place_table": 3.7211538461538463, "train_stats/max_log_achievement_wake_up": 1.3557692307692308, "train_stats/mean_log_entropy": 0.5341524007515266, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.507073052495503, "train/action_min": 0.0, "train/action_std": 3.4051205786012058, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04109005487972884, "train/actor_opt_grad_steps": 42960.0, "train/actor_opt_loss": -5.248469230832813, "train/adv_mag": 0.5051417638072007, "train/adv_max": 0.4718839772742429, "train/adv_mean": 0.003342560713613664, "train/adv_min": -0.4060233083131502, "train/adv_std": 0.05855343289834132, "train/cont_avg": 0.9949274955035972, "train/cont_loss_mean": 0.00018551009227523206, "train/cont_loss_std": 0.005620479001694705, "train/cont_neg_acc": 0.9924258127592612, "train/cont_neg_loss": 0.015903596168669352, "train/cont_pos_acc": 0.9999575657810239, "train/cont_pos_loss": 9.369713364193695e-05, "train/cont_pred": 0.9949250650062835, "train/cont_rate": 0.9949274955035972, "train/dyn_loss_mean": 13.56993843325608, "train/dyn_loss_std": 9.14020384644433, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8426235348200627, "train/extr_critic_critic_opt_grad_steps": 42960.0, "train/extr_critic_critic_opt_loss": 16090.246178057554, "train/extr_critic_mag": 7.7363009315600495, "train/extr_critic_max": 7.7363009315600495, "train/extr_critic_mean": 2.176152815921701, "train/extr_critic_min": -0.2262775486321758, "train/extr_critic_std": 1.7637535402243085, "train/extr_return_normed_mag": 1.5822329589788862, "train/extr_return_normed_max": 1.5822329589788862, "train/extr_return_normed_mean": 0.3871737875097947, "train/extr_return_normed_min": -0.11242974895260317, "train/extr_return_normed_std": 0.32546763132802015, "train/extr_return_rate": 0.7891084436032412, "train/extr_return_raw_mag": 8.790198216335378, "train/extr_return_raw_max": 8.790198216335378, "train/extr_return_raw_mean": 2.1945978128652777, "train/extr_return_raw_min": -0.563383091267922, "train/extr_return_raw_std": 1.7963968695496484, "train/extr_reward_mag": 1.0356944653627684, "train/extr_reward_max": 1.0356944653627684, "train/extr_reward_mean": 0.04211315393394275, "train/extr_reward_min": -0.4117542736821895, "train/extr_reward_std": 0.19313305423414107, "train/image_loss_mean": 6.323123473915265, "train/image_loss_std": 11.159517535202795, "train/model_loss_mean": 14.523182450438576, "train/model_loss_std": 14.89560559499178, "train/model_opt_grad_norm": 54.79532893613088, "train/model_opt_grad_steps": 42920.23021582734, "train/model_opt_loss": 14746.730416057779, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1011.6906474820144, "train/policy_entropy_mag": 2.4116532270856896, "train/policy_entropy_max": 2.4116532270856896, "train/policy_entropy_mean": 0.5020778189888961, "train/policy_entropy_min": 0.07937505385644145, "train/policy_entropy_std": 0.580119279434355, "train/policy_logprob_mag": 7.438383637572364, "train/policy_logprob_max": -0.009455659265944855, "train/policy_logprob_mean": -0.5025989503311596, "train/policy_logprob_min": -7.438383637572364, "train/policy_logprob_std": 1.063567512326961, "train/policy_randomness_mag": 0.8512077584541101, "train/policy_randomness_max": 0.8512077584541101, "train/policy_randomness_mean": 0.17721143675793846, "train/policy_randomness_min": 0.028015910708110967, "train/policy_randomness_std": 0.2047566495996585, "train/post_ent_mag": 60.055021244844944, "train/post_ent_max": 60.055021244844944, "train/post_ent_mean": 42.615622074483966, "train/post_ent_min": 20.44787365755589, "train/post_ent_std": 7.530784061486773, "train/prior_ent_mag": 69.16355742310448, "train/prior_ent_max": 69.16355742310448, "train/prior_ent_mean": 56.243957656750574, "train/prior_ent_min": 40.28910240338003, "train/prior_ent_std": 4.3740606839708285, "train/rep_loss_mean": 13.56993843325608, "train/rep_loss_std": 9.14020384644433, "train/reward_avg": 0.03223358788829055, "train/reward_loss_mean": 0.057910373555027324, "train/reward_loss_std": 0.24979070557964791, "train/reward_max_data": 1.015827341903028, "train/reward_max_pred": 1.0130941156003115, "train/reward_neg_acc": 0.9929337441492424, "train/reward_neg_loss": 0.028655691869664105, "train/reward_pos_acc": 0.9716196467550539, "train/reward_pos_loss": 0.822967750134228, "train/reward_pred": 0.031460876730706196, "train/reward_rate": 0.03683537544964029, "eval_stats/sum_log_reward": 8.183333476384481, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 3.1666666666666665, "eval_stats/max_log_achievement_collect_sapling": 1.6666666666666667, "eval_stats/max_log_achievement_collect_stone": 4.291666666666667, "eval_stats/max_log_achievement_collect_wood": 12.208333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0416666666666667, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5833333333333333, "eval_stats/max_log_achievement_make_wood_sword": 1.0416666666666667, "eval_stats/max_log_achievement_place_furnace": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 1.6666666666666667, "eval_stats/max_log_achievement_place_stone": 0.125, "eval_stats/max_log_achievement_place_table": 3.7083333333333335, "eval_stats/max_log_achievement_wake_up": 0.9583333333333334, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 9.076012065634131e-05, "report/cont_loss_std": 0.0019761216826736927, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.730765042244457e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.08584042917937e-05, "report/cont_pred": 0.9969818592071533, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 11.762147903442383, "report/dyn_loss_std": 8.35839557647705, "report/image_loss_mean": 4.7502665519714355, "report/image_loss_std": 9.242921829223633, "report/model_loss_mean": 11.852462768554688, "report/model_loss_std": 12.712865829467773, "report/post_ent_mag": 59.68149185180664, "report/post_ent_max": 59.68149185180664, "report/post_ent_mean": 44.36486053466797, "report/post_ent_min": 22.23828887939453, "report/post_ent_std": 7.330583095550537, "report/prior_ent_mag": 69.38162231445312, "report/prior_ent_max": 69.38162231445312, "report/prior_ent_mean": 56.43387985229492, "report/prior_ent_min": 42.19133758544922, "report/prior_ent_std": 4.232685089111328, "report/rep_loss_mean": 11.762147903442383, "report/rep_loss_std": 8.35839557647705, "report/reward_avg": 0.033203125, "report/reward_loss_mean": 0.04481758922338486, "report/reward_loss_std": 0.17173363268375397, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023889541625977, "report/reward_neg_acc": 0.9969573616981506, "report/reward_neg_loss": 0.01837509498000145, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.730930745601654, "report/reward_pred": 0.031720876693725586, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00041062477976083755, "eval/cont_loss_std": 0.012899726629257202, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.10508830100297928, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.2406006533183245e-07, "eval/cont_pred": 0.9964312314987183, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.527217864990234, "eval/dyn_loss_std": 10.921839714050293, "eval/image_loss_mean": 9.712936401367188, "eval/image_loss_std": 17.26070785522461, "eval/model_loss_mean": 20.332889556884766, "eval/model_loss_std": 21.42365074157715, "eval/post_ent_mag": 57.817283630371094, "eval/post_ent_max": 57.817283630371094, "eval/post_ent_mean": 41.11912155151367, "eval/post_ent_min": 22.07136344909668, "eval/post_ent_std": 7.493365287780762, "eval/prior_ent_mag": 69.38162231445312, "eval/prior_ent_max": 69.38162231445312, "eval/prior_ent_mean": 56.2244873046875, "eval/prior_ent_min": 39.92210388183594, "eval/prior_ent_std": 4.0235114097595215, "eval/rep_loss_mean": 17.527217864990234, "eval/rep_loss_std": 10.921839714050293, "eval/reward_avg": 0.04453124850988388, "eval/reward_loss_mean": 0.10321125388145447, "eval/reward_loss_std": 0.5776005387306213, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0119845867156982, "eval/reward_neg_acc": 0.9948770999908447, "eval/reward_neg_loss": 0.033730171620845795, "eval/reward_pos_acc": 0.875, "eval/reward_pos_loss": 1.515993595123291, "eval/reward_pred": 0.03589458018541336, "eval/reward_rate": 0.046875, "replay/size": 699521.0, "replay/inserts": 22240.0, "replay/samples": 22240.0, "replay/insert_wait_avg": 1.3791292691402297e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.456784186603354e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6968.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1863787877710213e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1027.39155960083, "timer/env.step_count": 2780.0, "timer/env.step_total": 249.529198884964, "timer/env.step_frac": 0.24287643455228788, "timer/env.step_avg": 0.08975870463487913, "timer/env.step_min": 0.02244877815246582, "timer/env.step_max": 3.4156832695007324, "timer/replay._sample_count": 22240.0, "timer/replay._sample_total": 11.025717496871948, "timer/replay._sample_frac": 0.010731757910446279, "timer/replay._sample_avg": 0.0004957606788161847, "timer/replay._sample_min": 0.0004177093505859375, "timer/replay._sample_max": 0.025084733963012695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3651.0, "timer/agent.policy_total": 57.419405698776245, "timer/agent.policy_frac": 0.055888531653000215, "timer/agent.policy_avg": 0.015727035250281084, "timer/agent.policy_min": 0.009288787841796875, "timer/agent.policy_max": 0.10013294219970703, "timer/dataset_train_count": 1390.0, "timer/dataset_train_total": 0.14875555038452148, "timer/dataset_train_frac": 0.00014478953909482877, "timer/dataset_train_avg": 0.0001070183815715982, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.00048160552978515625, "timer/agent.train_count": 1390.0, "timer/agent.train_total": 622.0601415634155, "timer/agent.train_frac": 0.6054752306950069, "timer/agent.train_avg": 0.4475252817002989, "timer/agent.train_min": 0.4345273971557617, "timer/agent.train_max": 1.6327450275421143, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47000980377197266, "timer/agent.report_frac": 0.00045747874739654704, "timer/agent.report_avg": 0.23500490188598633, "timer/agent.report_min": 0.22928977012634277, "timer/agent.report_max": 0.24072003364562988, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.64550723271838e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 21.646770844306218}
{"step": 700448, "time": 32405.78278374672, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 700832, "time": 32420.606155633926, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 701144, "time": 32432.267702817917, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 701344, "time": 32440.909493923187, "episode/length": 315.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 701456, "time": 32446.0615837574, "episode/length": 179.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 701640, "time": 32454.185131072998, "episode/length": 148.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 701832, "time": 32462.78725218773, "episode/length": 409.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 701904, "time": 32466.938771247864, "episode/length": 289.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 702192, "time": 32477.974443674088, "episode/length": 395.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 702584, "time": 32492.370980978012, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 702856, "time": 32503.160232543945, "episode/length": 174.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 702984, "time": 32509.416247844696, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 703048, "time": 32513.063207149506, "episode/length": 175.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 703208, "time": 32520.04221725464, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 703440, "time": 32529.431969881058, "episode/length": 325.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.99079754601227, "episode/intrinsic_return": 0.0}
{"step": 703808, "time": 32543.204874515533, "episode/length": 201.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 703896, "time": 32547.481323719025, "episode/length": 257.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 703896, "time": 32547.49015069008, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 704744, "time": 32581.118486881256, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 704760, "time": 32583.201177597046, "episode/length": 237.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 704936, "time": 32590.53144621849, "episode/length": 186.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 705064, "time": 32596.46647787094, "episode/length": 156.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 705080, "time": 32598.55015683174, "episode/length": 233.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 705408, "time": 32611.025987625122, "episode/length": 58.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 705648, "time": 32620.981078624725, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 705800, "time": 32627.68510222435, "episode/length": 237.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 706136, "time": 32640.533805847168, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 706248, "time": 32646.347536802292, "episode/length": 407.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 706648, "time": 32662.05520915985, "episode/length": 195.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 706968, "time": 32674.118467092514, "episode/length": 277.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 707048, "time": 32678.39666223526, "episode/length": 204.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 707192, "time": 32684.734728336334, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 707432, "time": 32694.219222068787, "episode/length": 147.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 707600, "time": 32701.681119918823, "episode/length": 316.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9936908517350158, "episode/intrinsic_return": 0.0}
{"step": 707704, "time": 32706.91162443161, "episode/length": 195.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 708408, "time": 32732.48007464409, "episode/length": 219.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 708552, "time": 32738.77757048607, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 708608, "time": 32742.345693588257, "episode/length": 194.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 708784, "time": 32749.80696463585, "episode/length": 168.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 709016, "time": 32758.94922375679, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 709616, "time": 32780.71095275879, "episode/length": 238.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 709816, "time": 32788.72160410881, "episode/length": 327.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9847560975609756, "episode/intrinsic_return": 0.0}
{"step": 709824, "time": 32790.71951317787, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 709928, "time": 32795.47487068176, "episode/length": 515.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 709984, "time": 32799.11350798607, "episode/length": 149.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 32801.229624032974, "episode/length": 174.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 32820.69965338707, "eval_episode/length": 112.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9911504424778761}
{"step": 710008, "time": 32823.86077451706, "eval_episode/length": 150.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9536423841059603}
{"step": 710008, "time": 32827.148387908936, "eval_episode/length": 190.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 710008, "time": 32827.15685462952, "eval_episode/length": 190.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9685863874345549}
{"step": 710008, "time": 32831.52638888359, "eval_episode/length": 216.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 710008, "time": 32835.076479911804, "eval_episode/length": 263.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9962121212121212}
{"step": 710008, "time": 32839.21899104118, "eval_episode/length": 213.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 710008, "time": 32842.22891688347, "eval_episode/length": 170.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 710240, "time": 32851.78445124626, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 710616, "time": 32865.46015262604, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 711200, "time": 32886.65938782692, "episode/length": 197.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 711336, "time": 32892.469130039215, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 711448, "time": 32897.672891139984, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 711728, "time": 32908.77988266945, "episode/length": 237.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 712080, "time": 32922.01582837105, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 712184, "time": 32926.8088452816, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 712240, "time": 32930.46781182289, "episode/length": 278.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 712304, "time": 32934.27695822716, "episode/length": 296.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9764309764309764, "episode/intrinsic_return": 0.0}
{"step": 712872, "time": 32956.419400691986, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 712888, "time": 32958.860728263855, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 713312, "time": 32975.29924726486, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 713448, "time": 32981.16461277008, "episode/length": 214.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 713728, "time": 32992.24772596359, "episode/length": 177.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9831460674157303, "episode/intrinsic_return": 0.0}
{"step": 713768, "time": 32994.98889875412, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 713824, "time": 32998.778760910034, "episode/length": 197.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 713904, "time": 33002.92865228653, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 714128, "time": 33011.76056146622, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 714456, "time": 33023.81119298935, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 714712, "time": 33033.80865740776, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 714920, "time": 33042.22580623627, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 715448, "time": 33061.76050066948, "episode/length": 214.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 715456, "time": 33064.24684906006, "episode/length": 267.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 715904, "time": 33081.4649579525, "episode/length": 266.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 715968, "time": 33085.71373820305, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 716352, "time": 33100.98575878143, "episode/length": 111.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 716840, "time": 33119.026460170746, "episode/length": 60.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 716888, "time": 33122.15466117859, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 716904, "time": 33124.29791045189, "episode/length": 247.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 717136, "time": 33133.924746751785, "episode/length": 36.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 717368, "time": 33143.52224898338, "episode/length": 239.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 717424, "time": 33147.87097144127, "episode/length": 411.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9975728155339806, "episode/intrinsic_return": 0.0}
{"step": 717608, "time": 33155.82283306122, "episode/length": 204.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 717776, "time": 33163.0663626194, "episode/length": 483.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 718032, "time": 33172.983572006226, "episode/length": 265.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 718600, "time": 33193.13169503212, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 718744, "time": 33199.39570975304, "episode/length": 231.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 718776, "time": 33202.09114956856, "episode/length": 233.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 718944, "time": 33209.43014073372, "episode/length": 196.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 718976, "time": 33212.11107444763, "episode/length": 170.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 719104, "time": 33217.97989106178, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 719616, "time": 33236.561584711075, "episode/length": 229.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 719976, "time": 33249.77850675583, "episode/length": 153.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 719984, "time": 33251.87810301781, "episode/length": 243.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 720056, "time": 33255.502771139145, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 33276.535633802414, "eval_episode/length": 131.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 720096, "time": 33280.748036623, "eval_episode/length": 195.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 720096, "time": 33282.95133972168, "eval_episode/length": 210.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9715639810426541}
{"step": 720096, "time": 33284.78853392601, "eval_episode/length": 217.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 720096, "time": 33286.90423536301, "eval_episode/length": 227.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 720096, "time": 33290.67136478424, "eval_episode/length": 283.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.971830985915493}
{"step": 720096, "time": 33292.62187886238, "eval_episode/length": 292.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9863481228668942}
{"step": 720096, "time": 33294.727840423584, "eval_episode/length": 77.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9358974358974359}
{"step": 720240, "time": 33299.8042037487, "episode/length": 157.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 720480, "time": 33310.08999919891, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 721304, "time": 33340.357172966, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 721448, "time": 33346.66211295128, "episode/length": 183.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 721456, "time": 33348.76300907135, "episode/length": 293.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.0}
{"step": 721472, "time": 33350.824182510376, "episode/length": 315.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 721704, "time": 33360.028136491776, "episode/length": 214.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.986046511627907, "episode/intrinsic_return": 0.0}
{"step": 721960, "time": 33370.04354786873, "episode/length": 214.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 721976, "time": 33372.08326983452, "episode/length": 294.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 722489, "time": 33391.565494060516, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.540453229631696, "train/action_min": 0.0, "train/action_std": 3.4386816586766926, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.042090973603938306, "train/actor_opt_grad_steps": 44355.0, "train/actor_opt_loss": -5.238722862941878, "train/adv_mag": 0.5116973091449056, "train/adv_max": 0.4693811808313642, "train/adv_mean": 0.0032230277595837313, "train/adv_min": -0.4188309654593468, "train/adv_std": 0.0591738778299519, "train/cont_avg": 0.9946498325892857, "train/cont_loss_mean": 0.0001360415241599863, "train/cont_loss_std": 0.004075314404859195, "train/cont_neg_acc": 0.9933367603116756, "train/cont_neg_loss": 0.013729023700117401, "train/cont_pos_acc": 0.9999789680753436, "train/cont_pos_loss": 6.232182478788571e-05, "train/cont_pred": 0.9946550684315818, "train/cont_rate": 0.9946498325892857, "train/dyn_loss_mean": 13.540066153662545, "train/dyn_loss_std": 9.093270717348371, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8426215840237481, "train/extr_critic_critic_opt_grad_steps": 44355.0, "train/extr_critic_critic_opt_loss": 16110.276743861607, "train/extr_critic_mag": 7.782788072313581, "train/extr_critic_max": 7.782788072313581, "train/extr_critic_mean": 2.229925685269492, "train/extr_critic_min": -0.2156172445842198, "train/extr_critic_std": 1.7847566774913244, "train/extr_return_normed_mag": 1.5853279905659812, "train/extr_return_normed_max": 1.5853279905659812, "train/extr_return_normed_mean": 0.3905417229448046, "train/extr_return_normed_min": -0.1032941925738539, "train/extr_return_normed_std": 0.3239847061889512, "train/extr_return_rate": 0.7845373349530357, "train/extr_return_raw_mag": 8.956765978676932, "train/extr_return_raw_max": 8.956765978676932, "train/extr_return_raw_mean": 2.2480020318712506, "train/extr_return_raw_min": -0.5244091842855726, "train/extr_return_raw_std": 1.8193215685231345, "train/extr_reward_mag": 1.0353210517338345, "train/extr_reward_max": 1.0353210517338345, "train/extr_reward_mean": 0.04260480904153415, "train/extr_reward_min": -0.4216772334916251, "train/extr_reward_std": 0.19427025573594228, "train/image_loss_mean": 6.20590376172747, "train/image_loss_std": 11.17395748070308, "train/model_loss_mean": 14.388793672834124, "train/model_loss_std": 14.892398493630546, "train/model_opt_grad_norm": 50.05720954622541, "train/model_opt_grad_steps": 44314.0, "train/model_opt_loss": 14963.947119140625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1040.1785714285713, "train/policy_entropy_mag": 2.394478986944471, "train/policy_entropy_max": 2.394478986944471, "train/policy_entropy_mean": 0.5309475828494344, "train/policy_entropy_min": 0.07937505170702934, "train/policy_entropy_std": 0.6085775758538927, "train/policy_logprob_mag": 7.438383671215602, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5319411788667952, "train/policy_logprob_min": -7.438383671215602, "train/policy_logprob_std": 1.082908443893705, "train/policy_randomness_mag": 0.845145999959537, "train/policy_randomness_max": 0.845145999959537, "train/policy_randomness_mean": 0.18740119593484061, "train/policy_randomness_min": 0.028015909982579097, "train/policy_randomness_std": 0.21480117961764336, "train/post_ent_mag": 60.351801245553155, "train/post_ent_max": 60.351801245553155, "train/post_ent_mean": 42.70452006203788, "train/post_ent_min": 20.35603186062404, "train/post_ent_std": 7.554105179650443, "train/prior_ent_mag": 69.20333360944475, "train/prior_ent_max": 69.20333360944475, "train/prior_ent_mean": 56.34438225882394, "train/prior_ent_min": 40.52615727015904, "train/prior_ent_std": 4.406743817670005, "train/rep_loss_mean": 13.540066153662545, "train/rep_loss_std": 9.093270717348371, "train/reward_avg": 0.03180664023384452, "train/reward_loss_mean": 0.0587141168702926, "train/reward_loss_std": 0.25042580515146257, "train/reward_max_data": 1.019285718883787, "train/reward_max_pred": 1.012701427936554, "train/reward_neg_acc": 0.9928926931960242, "train/reward_neg_loss": 0.029842656651245695, "train/reward_pos_acc": 0.9751878580876759, "train/reward_pos_loss": 0.8178656807967595, "train/reward_pred": 0.030902609056127923, "train/reward_rate": 0.036586216517857144, "train_stats/sum_log_reward": 8.565346746161433, "train_stats/max_log_achievement_collect_coal": 0.42574257425742573, "train_stats/max_log_achievement_collect_drink": 3.7524752475247523, "train_stats/max_log_achievement_collect_sapling": 1.6534653465346534, "train_stats/max_log_achievement_collect_stone": 4.524752475247524, "train_stats/max_log_achievement_collect_wood": 13.683168316831683, "train_stats/max_log_achievement_defeat_skeleton": 0.04950495049504951, "train_stats/max_log_achievement_defeat_zombie": 0.9306930693069307, "train_stats/max_log_achievement_eat_cow": 0.09900990099009901, "train_stats/max_log_achievement_make_stone_pickaxe": 0.07920792079207921, "train_stats/max_log_achievement_make_stone_sword": 0.009900990099009901, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7326732673267327, "train_stats/max_log_achievement_make_wood_sword": 1.613861386138614, "train_stats/max_log_achievement_place_furnace": 0.0891089108910891, "train_stats/max_log_achievement_place_plant": 1.6237623762376239, "train_stats/max_log_achievement_place_stone": 0.27722772277227725, "train_stats/max_log_achievement_place_table": 4.02970297029703, "train_stats/max_log_achievement_wake_up": 1.306930693069307, "train_stats/mean_log_entropy": 0.5891049412807615, "eval_stats/sum_log_reward": 8.66250029206276, "eval_stats/max_log_achievement_collect_coal": 0.4375, "eval_stats/max_log_achievement_collect_drink": 3.25, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 5.4375, "eval_stats/max_log_achievement_collect_wood": 11.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.6875, "eval_stats/max_log_achievement_make_wood_sword": 1.3125, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_stone": 0.375, "eval_stats/max_log_achievement_place_table": 3.5, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 5.977723412797786e-05, "report/cont_loss_std": 0.0016748592024669051, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.7003228499088436e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.9933980082860216e-05, "report/cont_pred": 0.9931061863899231, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.223830223083496, "report/dyn_loss_std": 9.040679931640625, "report/image_loss_mean": 6.447354316711426, "report/image_loss_std": 8.57213306427002, "report/model_loss_mean": 14.435304641723633, "report/model_loss_std": 12.376701354980469, "report/post_ent_mag": 59.76342010498047, "report/post_ent_max": 59.76342010498047, "report/post_ent_mean": 43.636268615722656, "report/post_ent_min": 19.240089416503906, "report/post_ent_std": 7.7829461097717285, "report/prior_ent_mag": 69.28398895263672, "report/prior_ent_max": 69.28398895263672, "report/prior_ent_mean": 57.495872497558594, "report/prior_ent_min": 41.180538177490234, "report/prior_ent_std": 4.095859050750732, "report/rep_loss_mean": 13.223830223083496, "report/rep_loss_std": 9.040679931640625, "report/reward_avg": 0.021484375, "report/reward_loss_mean": 0.05359159782528877, "report/reward_loss_std": 0.30887869000434875, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005695819854736, "report/reward_neg_acc": 0.994979977607727, "report/reward_neg_loss": 0.02803938277065754, "report/reward_pos_acc": 0.9642857313156128, "report/reward_pos_loss": 0.9625204205513, "report/reward_pred": 0.02079913020133972, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0003122563357464969, "eval/cont_loss_std": 0.008432853035628796, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 9.572397175361402e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00031404037144966424, "eval/cont_pred": 0.9938611388206482, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.887283325195312, "eval/dyn_loss_std": 9.963991165161133, "eval/image_loss_mean": 11.423002243041992, "eval/image_loss_std": 16.96478843688965, "eval/model_loss_mean": 22.290254592895508, "eval/model_loss_std": 20.396541595458984, "eval/post_ent_mag": 60.24235534667969, "eval/post_ent_max": 60.24235534667969, "eval/post_ent_mean": 40.96072769165039, "eval/post_ent_min": 21.89514923095703, "eval/post_ent_std": 7.233409404754639, "eval/prior_ent_mag": 69.28398895263672, "eval/prior_ent_max": 69.28398895263672, "eval/prior_ent_mean": 56.759521484375, "eval/prior_ent_min": 42.79939270019531, "eval/prior_ent_std": 4.211134433746338, "eval/rep_loss_mean": 17.887283325195312, "eval/rep_loss_std": 9.963991165161133, "eval/reward_avg": 0.03486327826976776, "eval/reward_loss_mean": 0.13457027077674866, "eval/reward_loss_std": 0.8174417018890381, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011181831359863, "eval/reward_neg_acc": 0.9908537268638611, "eval/reward_neg_loss": 0.07339795678853989, "eval/reward_pos_acc": 0.8500000238418579, "eval/reward_pos_loss": 1.6394093036651611, "eval/reward_pred": 0.03236013278365135, "eval/reward_rate": 0.0390625, "replay/size": 721985.0, "replay/inserts": 22464.0, "replay/samples": 22464.0, "replay/insert_wait_avg": 1.3896606416783782e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.830308775616506e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5344.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2264012576577192e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1625962257385, "timer/env.step_count": 2808.0, "timer/env.step_total": 243.22300839424133, "timer/env.step_frac": 0.24318346768023452, "timer/env.step_avg": 0.08661788048227968, "timer/env.step_min": 0.02218937873840332, "timer/env.step_max": 3.3212761878967285, "timer/replay._sample_count": 22464.0, "timer/replay._sample_total": 11.164001941680908, "timer/replay._sample_frac": 0.011162187012201737, "timer/replay._sample_avg": 0.0004969730209081601, "timer/replay._sample_min": 0.00040411949157714844, "timer/replay._sample_max": 0.011406898498535156, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3476.0, "timer/agent.policy_total": 56.880871295928955, "timer/agent.policy_frac": 0.05687162418448494, "timer/agent.policy_avg": 0.01636388702414527, "timer/agent.policy_min": 0.009190797805786133, "timer/agent.policy_max": 0.11787152290344238, "timer/dataset_train_count": 1404.0, "timer/dataset_train_total": 0.14908218383789062, "timer/dataset_train_frac": 0.00014905794757819808, "timer/dataset_train_avg": 0.00010618389162242922, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.00039315223693847656, "timer/agent.train_count": 1404.0, "timer/agent.train_total": 629.801548242569, "timer/agent.train_frac": 0.6296991615355526, "timer/agent.train_avg": 0.44857660131237104, "timer/agent.train_min": 0.4333655834197998, "timer/agent.train_max": 1.7443432807922363, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47351598739624023, "timer/agent.report_frac": 0.00047343900800042197, "timer/agent.report_avg": 0.23675799369812012, "timer/agent.report_min": 0.22901463508605957, "timer/agent.report_max": 0.24450135231018066, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.789043887478758e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 22.46002461209973}
{"step": 722512, "time": 33392.2828476429, "episode/length": 131.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 722552, "time": 33395.08759212494, "episode/length": 258.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 722752, "time": 33403.46881866455, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 722776, "time": 33405.57906317711, "episode/length": 133.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 722792, "time": 33407.70155930519, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 723024, "time": 33417.292432546616, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 723064, "time": 33419.905950307846, "episode/length": 63.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 723488, "time": 33435.60455060005, "episode/length": 188.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 723520, "time": 33438.099142313, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 724040, "time": 33456.59815573692, "episode/length": 190.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 724312, "time": 33467.13427090645, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 724496, "time": 33474.91886973381, "episode/length": 212.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 724536, "time": 33477.731251478195, "episode/length": 222.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 724776, "time": 33487.12026500702, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 724976, "time": 33495.55954480171, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 725056, "time": 33499.80113863945, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 725152, "time": 33504.53897666931, "episode/length": 46.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 725592, "time": 33520.63038110733, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 725944, "time": 33534.479398965836, "episode/length": 364.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945205479452055, "episode/intrinsic_return": 0.0}
{"step": 726056, "time": 33539.78454518318, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 726312, "time": 33549.77206325531, "episode/length": 226.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 726472, "time": 33556.63690114021, "episode/length": 164.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 726520, "time": 33559.752094745636, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 726616, "time": 33564.43288373947, "episode/length": 194.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 727352, "time": 33590.29288601875, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 727688, "time": 33604.937749385834, "episode/length": 203.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 727736, "time": 33608.748856306076, "episode/length": 223.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 727952, "time": 33618.43968081474, "episode/length": 426.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953161592505855, "episode/intrinsic_return": 0.0}
{"step": 727968, "time": 33620.992844581604, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 728040, "time": 33625.29664492607, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 728120, "time": 33630.10056805611, "episode/length": 53.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9074074074074074, "episode/intrinsic_return": 0.0}
{"step": 728184, "time": 33633.705102443695, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 728968, "time": 33661.06523299217, "episode/length": 153.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 729208, "time": 33671.92365193367, "episode/length": 231.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 729240, "time": 33674.521637916565, "episode/length": 345.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9971098265895953, "episode/intrinsic_return": 0.0}
{"step": 729392, "time": 33681.20308184624, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 729632, "time": 33690.67210316658, "episode/length": 82.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 729728, "time": 33695.3343629837, "episode/length": 221.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 730056, "time": 33707.499081373215, "episode/length": 251.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 33731.96666407585, "eval_episode/length": 157.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 730080, "time": 33735.75856137276, "eval_episode/length": 191.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 730080, "time": 33739.08407855034, "eval_episode/length": 217.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9724770642201835}
{"step": 730080, "time": 33739.10602116585, "eval_episode/length": 217.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 730080, "time": 33746.55852341652, "eval_episode/length": 284.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9719298245614035}
{"step": 730080, "time": 33749.17392683029, "eval_episode/length": 105.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9528301886792453}
{"step": 730080, "time": 33753.02518057823, "eval_episode/length": 334.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.991044776119403}
{"step": 730080, "time": 33757.14280438423, "eval_episode/length": 376.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9946949602122016}
{"step": 730496, "time": 33770.93765091896, "episode/length": 288.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 730856, "time": 33784.22529387474, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 731096, "time": 33793.57937121391, "episode/length": 212.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 731160, "time": 33797.278675317764, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 731320, "time": 33804.06301903725, "episode/length": 399.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 731344, "time": 33806.721491098404, "episode/length": 105.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.0}
{"step": 731352, "time": 33808.29957675934, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 731656, "time": 33819.871301174164, "episode/length": 199.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 732320, "time": 33844.38044977188, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 732784, "time": 33862.12104868889, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 732832, "time": 33865.266315698624, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 732848, "time": 33867.43039274216, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 733144, "time": 33878.48266029358, "episode/length": 185.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 733200, "time": 33882.05349111557, "episode/length": 231.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 733512, "time": 33893.5938770771, "episode/length": 301.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9900662251655629, "episode/intrinsic_return": 0.0}
{"step": 733536, "time": 33896.19735312462, "episode/length": 475.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9894957983193278, "episode/intrinsic_return": 0.0}
{"step": 734168, "time": 33918.8527405262, "episode/length": 230.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 734288, "time": 33925.146302461624, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 734464, "time": 33932.53494501114, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 734832, "time": 33946.18650221825, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 735216, "time": 33960.534276008606, "episode/length": 212.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 735424, "time": 33968.93094778061, "episode/length": 156.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 735608, "time": 33976.256494522095, "episode/length": 346.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942363112391931, "episode/intrinsic_return": 0.0}
{"step": 735880, "time": 33986.67812204361, "episode/length": 198.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 735880, "time": 33986.68688559532, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 736224, "time": 34001.442818164825, "episode/length": 377.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 736696, "time": 34018.75179409981, "episode/length": 184.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 736984, "time": 34029.866958618164, "episode/length": 94.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9578947368421052, "episode/intrinsic_return": 0.0}
{"step": 737320, "time": 34044.0877468586, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 737488, "time": 34051.707137823105, "episode/length": 587.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9914965986394558, "episode/intrinsic_return": 0.0}
{"step": 737656, "time": 34059.28772306442, "episode/length": 278.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 737920, "time": 34070.514364242554, "episode/length": 385.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9896373056994818, "episode/intrinsic_return": 0.0}
{"step": 738096, "time": 34078.43956899643, "episode/length": 276.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 738296, "time": 34086.30127477646, "episode/length": 335.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 738536, "time": 34095.85038113594, "episode/length": 193.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 738552, "time": 34097.842365026474, "episode/length": 231.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 738816, "time": 34108.54452943802, "episode/length": 165.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 738976, "time": 34115.54305648804, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 739120, "time": 34121.946444272995, "episode/length": 224.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 739640, "time": 34140.59651398659, "episode/length": 135.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 739896, "time": 34150.576078891754, "episode/length": 169.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 739904, "time": 34152.58873772621, "episode/length": 225.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 740056, "time": 34158.96248340607, "episode/length": 266.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 34174.88119292259, "eval_episode/length": 29.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8666666666666667}
{"step": 740064, "time": 34181.17054653168, "eval_episode/length": 51.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 740064, "time": 34186.73487377167, "eval_episode/length": 158.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 740064, "time": 34189.18008565903, "eval_episode/length": 166.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 740064, "time": 34191.832114219666, "eval_episode/length": 178.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 740064, "time": 34193.923956394196, "eval_episode/length": 179.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 740064, "time": 34196.87495517731, "eval_episode/length": 205.0, "eval_episode/score": 8.100000031292439, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 740064, "time": 34198.42351293564, "eval_episode/length": 206.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 740504, "time": 34212.78964805603, "episode/length": 210.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 740640, "time": 34219.11152267456, "episode/length": 207.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 741032, "time": 34233.48323345184, "episode/length": 341.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 741080, "time": 34236.67073750496, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 741368, "time": 34247.758746147156, "episode/length": 182.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 741424, "time": 34251.424228429794, "episode/length": 170.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 741768, "time": 34264.41586279869, "episode/length": 330.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9879154078549849, "episode/intrinsic_return": 0.0}
{"step": 741840, "time": 34269.05202651024, "episode/length": 242.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 741880, "time": 34272.200093746185, "episode/length": 171.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 742752, "time": 34302.906389951706, "episode/length": 214.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 742920, "time": 34309.861580848694, "episode/length": 229.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 743248, "time": 34322.54349446297, "episode/length": 234.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 743408, "time": 34329.437264204025, "episode/length": 345.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9913294797687862, "episode/intrinsic_return": 0.0}
{"step": 743688, "time": 34340.07859659195, "episode/length": 282.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752650176678446, "episode/intrinsic_return": 0.0}
{"step": 743792, "time": 34345.25179719925, "episode/length": 238.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 744016, "time": 34354.372192144394, "episode/length": 271.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 744224, "time": 34362.737015247345, "episode/length": 162.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 744408, "time": 34370.16518354416, "episode/length": 329.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 744464, "time": 34373.795184612274, "episode/length": 213.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 744672, "time": 34382.29676389694, "episode/length": 177.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9831460674157303, "episode/intrinsic_return": 0.0}
{"step": 744889, "time": 34391.82619071007, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.587574114118303, "train/action_min": 0.0, "train/action_std": 3.3978316392217365, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04152001866272518, "train/actor_opt_grad_steps": 45755.0, "train/actor_opt_loss": -2.188506165572575, "train/adv_mag": 0.5117065340280533, "train/adv_max": 0.46568787736552103, "train/adv_mean": 0.003541634622287607, "train/adv_min": -0.415424156082528, "train/adv_std": 0.058596671665353435, "train/cont_avg": 0.9946149553571428, "train/cont_loss_mean": 0.00023766840080602846, "train/cont_loss_std": 0.0070827977158823986, "train/cont_neg_acc": 0.9966581638370241, "train/cont_neg_loss": 0.02193082861315036, "train/cont_pos_acc": 0.9999508819409779, "train/cont_pos_loss": 0.0001158059276186967, "train/cont_pred": 0.9946125226361411, "train/cont_rate": 0.9946149553571428, "train/dyn_loss_mean": 13.348797260011946, "train/dyn_loss_std": 9.158449840545654, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8868461068187441, "train/extr_critic_critic_opt_grad_steps": 45755.0, "train/extr_critic_critic_opt_loss": 16033.431961495537, "train/extr_critic_mag": 7.827407911845616, "train/extr_critic_max": 7.827407911845616, "train/extr_critic_mean": 2.2470952085086275, "train/extr_critic_min": -0.19599150844982693, "train/extr_critic_std": 1.7678618371486663, "train/extr_return_normed_mag": 1.589404900584902, "train/extr_return_normed_max": 1.589404900584902, "train/extr_return_normed_mean": 0.3892417814050402, "train/extr_return_normed_min": -0.11064901335963181, "train/extr_return_normed_std": 0.32332097302590096, "train/extr_return_rate": 0.8085612373692649, "train/extr_return_raw_mag": 8.943392058781216, "train/extr_return_raw_max": 8.943392058781216, "train/extr_return_raw_mean": 2.2667719066143035, "train/extr_return_raw_min": -0.5146410346031189, "train/extr_return_raw_std": 1.7990691661834717, "train/extr_reward_mag": 1.0377966114452908, "train/extr_reward_max": 1.0377966114452908, "train/extr_reward_mean": 0.04251847465389541, "train/extr_reward_min": -0.42327589307512553, "train/extr_reward_std": 0.19374574135456765, "train/image_loss_mean": 6.204715159961156, "train/image_loss_std": 11.214041294370379, "train/model_loss_mean": 14.271888569423131, "train/model_loss_std": 14.945527035849436, "train/model_opt_grad_norm": 53.57510858263288, "train/model_opt_grad_steps": 45712.885714285716, "train/model_opt_loss": 18503.644733537945, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1294.642857142857, "train/policy_entropy_mag": 2.4216571637562345, "train/policy_entropy_max": 2.4216571637562345, "train/policy_entropy_mean": 0.5338524501238551, "train/policy_entropy_min": 0.07937503542218889, "train/policy_entropy_std": 0.602267789202077, "train/policy_logprob_mag": 7.438383657591683, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5334657026188714, "train/policy_logprob_min": -7.438383657591683, "train/policy_logprob_std": 1.088714428458895, "train/policy_randomness_mag": 0.8547387072018214, "train/policy_randomness_max": 0.8547387072018214, "train/policy_randomness_mean": 0.1884264886379242, "train/policy_randomness_min": 0.02801590420837913, "train/policy_randomness_std": 0.2125741010265691, "train/post_ent_mag": 60.2186007635934, "train/post_ent_max": 60.2186007635934, "train/post_ent_mean": 42.89986951010568, "train/post_ent_min": 20.247585787091936, "train/post_ent_std": 7.579784798622131, "train/prior_ent_mag": 69.33725068228586, "train/prior_ent_max": 69.33725068228586, "train/prior_ent_mean": 56.329780387878415, "train/prior_ent_min": 40.22936060769217, "train/prior_ent_std": 4.426057595866067, "train/rep_loss_mean": 13.348797260011946, "train/rep_loss_std": 9.158449840545654, "train/reward_avg": 0.031406947411596775, "train/reward_loss_mean": 0.057657459431460924, "train/reward_loss_std": 0.24670616164803505, "train/reward_max_data": 1.0157142894608633, "train/reward_max_pred": 1.0120939918926783, "train/reward_neg_acc": 0.9926721619708198, "train/reward_neg_loss": 0.02930312022300703, "train/reward_pos_acc": 0.9753134259155818, "train/reward_pos_loss": 0.8151482169117247, "train/reward_pred": 0.030670626062367645, "train/reward_rate": 0.036111886160714285, "train_stats/sum_log_reward": 8.864706106045666, "train_stats/max_log_achievement_collect_coal": 0.23529411764705882, "train_stats/max_log_achievement_collect_drink": 3.5980392156862746, "train_stats/max_log_achievement_collect_sapling": 1.911764705882353, "train_stats/max_log_achievement_collect_stone": 5.068627450980392, "train_stats/max_log_achievement_collect_wood": 12.450980392156863, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 1.0784313725490196, "train_stats/max_log_achievement_eat_cow": 0.16666666666666666, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0196078431372549, "train_stats/max_log_achievement_make_stone_sword": 0.00980392156862745, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4803921568627452, "train_stats/max_log_achievement_make_wood_sword": 1.2941176470588236, "train_stats/max_log_achievement_place_furnace": 0.08823529411764706, "train_stats/max_log_achievement_place_plant": 1.8725490196078431, "train_stats/max_log_achievement_place_stone": 2.0098039215686274, "train_stats/max_log_achievement_place_table": 3.6176470588235294, "train_stats/max_log_achievement_wake_up": 1.2745098039215685, "train_stats/mean_log_entropy": 0.6256885867492825, "eval_stats/sum_log_reward": 7.850000128149986, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 3.4375, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 3.1875, "eval_stats/max_log_achievement_collect_wood": 11.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3125, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 1.9375, "eval_stats/max_log_achievement_place_table": 3.1875, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 5.2632713050115854e-05, "report/cont_loss_std": 0.0015108719235286117, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.709320016147103e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.280887853587046e-05, "report/cont_pred": 0.9960423707962036, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 15.649720191955566, "report/dyn_loss_std": 9.436849594116211, "report/image_loss_mean": 7.70591402053833, "report/image_loss_std": 14.685333251953125, "report/model_loss_mean": 17.150646209716797, "report/model_loss_std": 18.229320526123047, "report/post_ent_mag": 60.11511993408203, "report/post_ent_max": 60.11511993408203, "report/post_ent_mean": 42.14916229248047, "report/post_ent_min": 18.720043182373047, "report/post_ent_std": 7.6989054679870605, "report/prior_ent_mag": 69.22801208496094, "report/prior_ent_max": 69.22801208496094, "report/prior_ent_mean": 57.433372497558594, "report/prior_ent_min": 45.87659454345703, "report/prior_ent_std": 4.061502933502197, "report/rep_loss_mean": 15.649720191955566, "report/rep_loss_std": 9.436849594116211, "report/reward_avg": 0.02773437649011612, "report/reward_loss_mean": 0.05484750121831894, "report/reward_loss_std": 0.3000420928001404, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018057823181152, "report/reward_neg_acc": 0.9979878664016724, "report/reward_neg_loss": 0.0252592284232378, "report/reward_pos_acc": 0.9333333969116211, "report/reward_pos_loss": 1.0352057218551636, "report/reward_pred": 0.025647811591625214, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 2.5029114567587385e-06, "eval/cont_loss_std": 7.003523933235556e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00033307753619737923, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.2756998419026786e-07, "eval/cont_pred": 0.9931662082672119, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 18.045732498168945, "eval/dyn_loss_std": 10.364368438720703, "eval/image_loss_mean": 9.27574348449707, "eval/image_loss_std": 12.095926284790039, "eval/model_loss_mean": 20.224512100219727, "eval/model_loss_std": 16.011674880981445, "eval/post_ent_mag": 62.81328582763672, "eval/post_ent_max": 62.81328582763672, "eval/post_ent_mean": 41.68135070800781, "eval/post_ent_min": 19.81231117248535, "eval/post_ent_std": 7.875334739685059, "eval/prior_ent_mag": 69.22801208496094, "eval/prior_ent_max": 69.22801208496094, "eval/prior_ent_mean": 57.1003303527832, "eval/prior_ent_min": 39.741943359375, "eval/prior_ent_std": 4.0837907791137695, "eval/rep_loss_mean": 18.045732498168945, "eval/rep_loss_std": 10.364368438720703, "eval/reward_avg": 0.04511718824505806, "eval/reward_loss_mean": 0.12132534384727478, "eval/reward_loss_std": 0.6200785636901855, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018181800842285, "eval/reward_neg_acc": 0.9845679998397827, "eval/reward_neg_loss": 0.044150568544864655, "eval/reward_pos_acc": 0.826923131942749, "eval/reward_pos_loss": 1.5638999938964844, "eval/reward_pred": 0.043274588882923126, "eval/reward_rate": 0.05078125, "replay/size": 744385.0, "replay/inserts": 22400.0, "replay/samples": 22400.0, "replay/insert_wait_avg": 1.514607242175511e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.456941161836896e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3153846949747165e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2455503940582, "timer/env.step_count": 2800.0, "timer/env.step_total": 239.23507142066956, "timer/env.step_frac": 0.23917634157574622, "timer/env.step_avg": 0.0854410969359534, "timer/env.step_min": 0.022275209426879883, "timer/env.step_max": 3.284505844116211, "timer/replay._sample_count": 22400.0, "timer/replay._sample_total": 11.22013783454895, "timer/replay._sample_frac": 0.011217383401634376, "timer/replay._sample_avg": 0.0005008990104709353, "timer/replay._sample_min": 0.0004181861877441406, "timer/replay._sample_max": 0.01078486442565918, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3384.0, "timer/agent.policy_total": 55.62953758239746, "timer/agent.policy_frac": 0.055615881080882154, "timer/agent.policy_avg": 0.016438988647280574, "timer/agent.policy_min": 0.009221315383911133, "timer/agent.policy_max": 0.13748764991760254, "timer/dataset_train_count": 1400.0, "timer/dataset_train_total": 0.16860723495483398, "timer/dataset_train_frac": 0.0001685658435455266, "timer/dataset_train_avg": 0.00012043373925345285, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.020674943923950195, "timer/agent.train_count": 1400.0, "timer/agent.train_total": 627.1434786319733, "timer/agent.train_frac": 0.6269895211079948, "timer/agent.train_avg": 0.4479596275942666, "timer/agent.train_min": 0.42583608627319336, "timer/agent.train_max": 2.234342336654663, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4751749038696289, "timer/agent.report_frac": 0.00047505825312837264, "timer/agent.report_avg": 0.23758745193481445, "timer/agent.report_min": 0.23096394538879395, "timer/agent.report_max": 0.24421095848083496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.788812581459949e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 22.394192011534518}
{"step": 744904, "time": 34391.90707159042, "episode/length": 186.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 745400, "time": 34410.403589487076, "episode/length": 213.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 745560, "time": 34418.97636651993, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 745664, "time": 34424.09968209267, "episode/length": 156.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 745744, "time": 34428.25943350792, "episode/length": 133.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 746912, "time": 34469.25853395462, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 746936, "time": 34471.47473549843, "episode/length": 308.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 746952, "time": 34473.56404352188, "episode/length": 255.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 746960, "time": 34475.66516852379, "episode/length": 395.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 746976, "time": 34477.760219573975, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 747216, "time": 34487.344078063965, "episode/length": 193.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 747216, "time": 34487.35358381271, "episode/length": 206.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 747256, "time": 34491.68066740036, "episode/length": 378.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9973614775725593, "episode/intrinsic_return": 0.0}
{"step": 748440, "time": 34532.72584605217, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 748488, "time": 34535.93759202957, "episode/length": 153.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 748576, "time": 34540.70073056221, "episode/length": 204.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 748728, "time": 34547.13422989845, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 748776, "time": 34550.30371284485, "episode/length": 227.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 748968, "time": 34558.266406297684, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 749048, "time": 34562.43272161484, "episode/length": 228.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 749376, "time": 34574.99890065193, "episode/length": 299.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 749984, "time": 34596.81574511528, "episode/length": 186.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 750024, "time": 34599.442893743515, "episode/length": 197.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 34622.90419507027, "eval_episode/length": 196.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9898477157360406}
{"step": 750048, "time": 34624.82073307037, "eval_episode/length": 205.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 750048, "time": 34627.36527991295, "eval_episode/length": 228.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9781659388646288}
{"step": 750048, "time": 34630.96772623062, "eval_episode/length": 278.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.974910394265233}
{"step": 750048, "time": 34632.96969747543, "eval_episode/length": 292.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9863481228668942}
{"step": 750048, "time": 34635.648109674454, "eval_episode/length": 319.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9875}
{"step": 750048, "time": 34640.11184048653, "eval_episode/length": 390.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9948849104859335}
{"step": 750048, "time": 34641.66555261612, "eval_episode/length": 72.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9315068493150684}
{"step": 750096, "time": 34643.254469394684, "episode/length": 140.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 750264, "time": 34650.14277791977, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 750272, "time": 34652.13546895981, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 750640, "time": 34665.893637657166, "episode/length": 257.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 750912, "time": 34676.55677127838, "episode/length": 33.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8823529411764706, "episode/intrinsic_return": 0.0}
{"step": 750920, "time": 34678.04623389244, "episode/length": 192.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9844559585492227, "episode/intrinsic_return": 0.0}
{"step": 751160, "time": 34687.46401834488, "episode/length": 263.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 751536, "time": 34701.73181629181, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 751680, "time": 34708.09464430809, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 751744, "time": 34711.66961193085, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 752080, "time": 34724.28833985329, "episode/length": 225.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 752168, "time": 34728.555480241776, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 752512, "time": 34741.79471325874, "episode/length": 42.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 752776, "time": 34751.8617272377, "episode/length": 231.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 752944, "time": 34759.25279903412, "episode/length": 364.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9917808219178083, "episode/intrinsic_return": 0.0}
{"step": 752976, "time": 34761.947404146194, "episode/length": 226.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 753184, "time": 34770.487180233, "episode/length": 179.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 753184, "time": 34770.49656867981, "episode/length": 205.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 753496, "time": 34783.948081731796, "episode/length": 38.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 753648, "time": 34790.675907850266, "episode/length": 195.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 753888, "time": 34801.84331488609, "episode/length": 171.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 754192, "time": 34813.462589502335, "episode/length": 313.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 754320, "time": 34819.261063337326, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 754552, "time": 34828.33466768265, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 754632, "time": 34832.637362957, "episode/length": 231.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 755184, "time": 34852.73321533203, "episode/length": 210.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 755600, "time": 34868.041903972626, "episode/length": 213.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 755680, "time": 34872.372289180756, "episode/length": 311.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 755728, "time": 34875.53041577339, "episode/length": 259.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 756016, "time": 34886.740015268326, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 756032, "time": 34888.88680052757, "episode/length": 174.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 756144, "time": 34894.229664325714, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 756688, "time": 34914.237627506256, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 756808, "time": 34919.76276183128, "episode/length": 150.0, "episode/score": 9.10000005364418, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 757216, "time": 34934.931960344315, "episode/length": 377.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9894179894179894, "episode/intrinsic_return": 0.0}
{"step": 757416, "time": 34942.94376015663, "episode/length": 216.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 757632, "time": 34951.870588064194, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 757872, "time": 34961.345319509506, "episode/length": 215.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 758272, "time": 34976.064218997955, "episode/length": 279.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 759000, "time": 35002.193895578384, "episode/length": 170.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 759008, "time": 35004.67196440697, "episode/length": 289.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 759200, "time": 35012.61698961258, "episode/length": 222.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 759208, "time": 35014.20166349411, "episode/length": 299.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 759256, "time": 35017.25694274902, "episode/length": 254.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 759320, "time": 35020.92753410339, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 759560, "time": 35030.41487598419, "episode/length": 478.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9791231732776617, "episode/intrinsic_return": 0.0}
{"step": 759784, "time": 35039.47494101524, "episode/length": 188.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 759864, "time": 35043.73256254196, "episode/length": 248.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 759968, "time": 35048.813237428665, "episode/length": 50.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 35067.112704753876, "eval_episode/length": 49.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.98}
{"step": 760032, "time": 35073.04933929443, "eval_episode/length": 165.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.963855421686747}
{"step": 760032, "time": 35074.74004459381, "eval_episode/length": 167.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 760032, "time": 35076.6394701004, "eval_episode/length": 175.0, "eval_episode/score": 7.1000000461936, "eval_episode/reward_rate": 0.9659090909090909}
{"step": 760032, "time": 35078.452973365784, "eval_episode/length": 180.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 760032, "time": 35080.46086573601, "eval_episode/length": 190.0, "eval_episode/score": 11.100000016391277, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 760032, "time": 35083.3362827301, "eval_episode/length": 221.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 760032, "time": 35085.37619185448, "eval_episode/length": 234.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9957446808510638}
{"step": 760720, "time": 35108.305344581604, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 760952, "time": 35117.35000658035, "episode/length": 218.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 761016, "time": 35121.10854482651, "episode/length": 250.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 761176, "time": 35128.219945430756, "episode/length": 245.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 761400, "time": 35137.32049012184, "episode/length": 84.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 761472, "time": 35141.376453876495, "episode/length": 210.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 761800, "time": 35153.54327440262, "episode/length": 228.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 761840, "time": 35156.68492078781, "episode/length": 314.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9746031746031746, "episode/intrinsic_return": 0.0}
{"step": 762192, "time": 35171.49416399002, "episode/length": 290.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9828178694158075, "episode/intrinsic_return": 0.0}
{"step": 762472, "time": 35182.004823446274, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 762920, "time": 35198.56251955032, "episode/length": 189.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 762936, "time": 35200.65578174591, "episode/length": 247.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 762992, "time": 35204.32586288452, "episode/length": 226.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 763144, "time": 35211.41374850273, "episode/length": 167.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 763208, "time": 35215.43993806839, "episode/length": 216.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 763840, "time": 35239.553265333176, "episode/length": 205.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 764024, "time": 35247.72708272934, "episode/length": 193.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 764160, "time": 35254.65744948387, "episode/length": 289.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 764424, "time": 35265.57196354866, "episode/length": 187.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 764520, "time": 35270.862191438675, "episode/length": 190.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 764536, "time": 35273.461146354675, "episode/length": 173.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 764616, "time": 35278.36070108414, "episode/length": 209.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 765048, "time": 35295.21768927574, "episode/length": 150.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 765096, "time": 35298.732125520706, "episode/length": 235.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 765344, "time": 35309.53342437744, "episode/length": 164.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 765480, "time": 35315.91992878914, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 765496, "time": 35318.01190543175, "episode/length": 49.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 765544, "time": 35321.19056200981, "episode/length": 139.0, "episode/score": 7.100000038743019, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 765768, "time": 35330.258815288544, "episode/length": 143.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 765968, "time": 35338.73161482811, "episode/length": 180.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 766184, "time": 35347.292481184006, "episode/length": 205.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 766592, "time": 35362.86501288414, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 766936, "time": 35376.48779964447, "episode/length": 145.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 767096, "time": 35383.425877571106, "episode/length": 199.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 767273, "time": 35391.92402791977, "train_stats/sum_log_reward": 8.949056843541703, "train_stats/max_log_achievement_collect_coal": 0.2641509433962264, "train_stats/max_log_achievement_collect_drink": 3.1792452830188678, "train_stats/max_log_achievement_collect_sapling": 1.4811320754716981, "train_stats/max_log_achievement_collect_stone": 6.556603773584905, "train_stats/max_log_achievement_collect_wood": 11.141509433962264, "train_stats/max_log_achievement_defeat_skeleton": 0.018867924528301886, "train_stats/max_log_achievement_defeat_zombie": 0.839622641509434, "train_stats/max_log_achievement_eat_cow": 0.1509433962264151, "train_stats/max_log_achievement_make_stone_pickaxe": 0.009433962264150943, "train_stats/max_log_achievement_make_stone_sword": 0.04716981132075472, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3867924528301887, "train_stats/max_log_achievement_make_wood_sword": 1.0660377358490567, "train_stats/max_log_achievement_place_furnace": 0.05660377358490566, "train_stats/max_log_achievement_place_plant": 1.471698113207547, "train_stats/max_log_achievement_place_stone": 4.415094339622642, "train_stats/max_log_achievement_place_table": 3.311320754716981, "train_stats/max_log_achievement_wake_up": 1.2735849056603774, "train_stats/mean_log_entropy": 0.6386787597582025, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.656890869140625, "train/action_min": 0.0, "train/action_std": 3.4294635704585485, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04195828017379556, "train/actor_opt_grad_steps": 47155.0, "train/actor_opt_loss": -2.0897684535809926, "train/adv_mag": 0.5092105501464435, "train/adv_max": 0.4609950031552996, "train/adv_mean": 0.0038603862981420075, "train/adv_min": -0.42042655934180534, "train/adv_std": 0.059160856157541276, "train/cont_avg": 0.99462890625, "train/cont_loss_mean": 0.00015943190518457684, "train/cont_loss_std": 0.0047086828738279966, "train/cont_neg_acc": 0.9942857146263122, "train/cont_neg_loss": 0.009157435242424785, "train/cont_pos_acc": 0.9999649362904685, "train/cont_pos_loss": 0.00011229666162283967, "train/cont_pred": 0.9946037956646511, "train/cont_rate": 0.99462890625, "train/dyn_loss_mean": 13.468945373807635, "train/dyn_loss_std": 9.21119956970215, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8675986153738839, "train/extr_critic_critic_opt_grad_steps": 47155.0, "train/extr_critic_critic_opt_loss": 16088.55886579241, "train/extr_critic_mag": 7.962462793077742, "train/extr_critic_max": 7.962462793077742, "train/extr_critic_mean": 2.404723938022341, "train/extr_critic_min": -0.20923178366252354, "train/extr_critic_std": 1.828991710288184, "train/extr_return_normed_mag": 1.572363305091858, "train/extr_return_normed_max": 1.572363305091858, "train/extr_return_normed_mean": 0.40369993852717534, "train/extr_return_normed_min": -0.11681970355233975, "train/extr_return_normed_std": 0.32655178074325836, "train/extr_return_rate": 0.8320843057973044, "train/extr_return_raw_mag": 9.08879087993077, "train/extr_return_raw_max": 9.08879087993077, "train/extr_return_raw_mean": 2.4267505526542665, "train/extr_return_raw_min": -0.5410283925277847, "train/extr_return_raw_std": 1.8619059639317648, "train/extr_reward_mag": 1.0423277139663696, "train/extr_reward_max": 1.0423277139663696, "train/extr_reward_mean": 0.04505004503631166, "train/extr_reward_min": -0.4433905099119459, "train/extr_reward_std": 0.19906672611832618, "train/image_loss_mean": 6.311205465453011, "train/image_loss_std": 11.29245411668505, "train/model_loss_mean": 14.452055025100709, "train/model_loss_std": 15.084429570606776, "train/model_opt_grad_norm": 55.86856867926461, "train/model_opt_grad_steps": 47111.52142857143, "train/model_opt_loss": 18213.98201032366, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.9285714285713, "train/policy_entropy_mag": 2.419528545652117, "train/policy_entropy_max": 2.419528545652117, "train/policy_entropy_mean": 0.5223244341356413, "train/policy_entropy_min": 0.07937502509781293, "train/policy_entropy_std": 0.5935662916728428, "train/policy_logprob_mag": 7.438383735929217, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5213590828435761, "train/policy_logprob_min": -7.438383735929217, "train/policy_logprob_std": 1.0772119513579776, "train/policy_randomness_mag": 0.8539873978921345, "train/policy_randomness_max": 0.8539873978921345, "train/policy_randomness_mean": 0.18435760449085917, "train/policy_randomness_min": 0.02801590050969805, "train/policy_randomness_std": 0.20950285462396487, "train/post_ent_mag": 60.53007981436593, "train/post_ent_max": 60.53007981436593, "train/post_ent_mean": 42.86173801422119, "train/post_ent_min": 20.100379746300835, "train/post_ent_std": 7.60029057094029, "train/prior_ent_mag": 69.33727771214076, "train/prior_ent_max": 69.33727771214076, "train/prior_ent_mean": 56.40045334952218, "train/prior_ent_min": 39.82351123264858, "train/prior_ent_std": 4.472289170537676, "train/rep_loss_mean": 13.468945373807635, "train/rep_loss_std": 9.21119956970215, "train/reward_avg": 0.031918945123574564, "train/reward_loss_mean": 0.05932289127792631, "train/reward_loss_std": 0.2544411333543914, "train/reward_max_data": 1.021428576537541, "train/reward_max_pred": 1.0126017842973982, "train/reward_neg_acc": 0.9923280822379249, "train/reward_neg_loss": 0.029939354091350522, "train/reward_pos_acc": 0.9682902021067483, "train/reward_pos_loss": 0.833549325806754, "train/reward_pred": 0.03107445619867316, "train/reward_rate": 0.03664899553571429, "eval_stats/sum_log_reward": 8.412500023841858, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 1.1875, "eval_stats/max_log_achievement_collect_stone": 5.125, "eval_stats/max_log_achievement_collect_wood": 11.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.75, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 3.8125, "eval_stats/max_log_achievement_place_table": 3.5, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00020271138055250049, "report/cont_loss_std": 0.005284730810672045, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00028891031979583204, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00020220332953613251, "report/cont_pred": 0.9939545392990112, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.844354629516602, "report/dyn_loss_std": 9.140523910522461, "report/image_loss_mean": 6.97089958190918, "report/image_loss_std": 10.763097763061523, "report/model_loss_mean": 14.137027740478516, "report/model_loss_std": 14.458283424377441, "report/post_ent_mag": 60.85032272338867, "report/post_ent_max": 60.85032272338867, "report/post_ent_mean": 44.72499084472656, "report/post_ent_min": 19.886886596679688, "report/post_ent_std": 8.105883598327637, "report/prior_ent_mag": 69.30863952636719, "report/prior_ent_max": 69.30863952636719, "report/prior_ent_mean": 56.903289794921875, "report/prior_ent_min": 40.8047981262207, "report/prior_ent_std": 4.872828483581543, "report/rep_loss_mean": 11.844354629516602, "report/rep_loss_std": 9.140523910522461, "report/reward_avg": 0.03281249850988388, "report/reward_loss_mean": 0.05931086093187332, "report/reward_loss_std": 0.18729181587696075, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.007195234298706, "report/reward_neg_acc": 0.9939025044441223, "report/reward_neg_loss": 0.03337090462446213, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6974337697029114, "report/reward_pred": 0.033419154584407806, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 4.6396231482503936e-05, "eval/cont_loss_std": 0.0014720263425260782, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.000172958621988073, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.6148554247338325e-05, "eval/cont_pred": 0.9980022311210632, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.601604461669922, "eval/dyn_loss_std": 11.029115676879883, "eval/image_loss_mean": 7.523193359375, "eval/image_loss_std": 12.095002174377441, "eval/model_loss_mean": 17.604860305786133, "eval/model_loss_std": 16.654260635375977, "eval/post_ent_mag": 59.49095153808594, "eval/post_ent_max": 59.49095153808594, "eval/post_ent_mean": 41.784210205078125, "eval/post_ent_min": 19.044612884521484, "eval/post_ent_std": 7.427650451660156, "eval/prior_ent_mag": 69.30863952636719, "eval/prior_ent_max": 69.30863952636719, "eval/prior_ent_mean": 56.01653289794922, "eval/prior_ent_min": 41.26145553588867, "eval/prior_ent_std": 4.159402370452881, "eval/rep_loss_mean": 16.601604461669922, "eval/rep_loss_std": 11.029115676879883, "eval/reward_avg": 0.05849609524011612, "eval/reward_loss_mean": 0.12065709382295609, "eval/reward_loss_std": 0.6088748574256897, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0047247409820557, "eval/reward_neg_acc": 0.9833853244781494, "eval/reward_neg_loss": 0.04445609077811241, "eval/reward_pos_acc": 0.9016394019126892, "eval/reward_pos_loss": 1.3236336708068848, "eval/reward_pred": 0.05393633618950844, "eval/reward_rate": 0.0595703125, "replay/size": 766769.0, "replay/inserts": 22384.0, "replay/samples": 22384.0, "replay/insert_wait_avg": 1.3821013404949807e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.495046548795666e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5024.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1621482053380103e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.08407330513, "timer/env.step_count": 2798.0, "timer/env.step_total": 247.04492163658142, "timer/env.step_frac": 0.24702415349954976, "timer/env.step_avg": 0.0882933958672557, "timer/env.step_min": 0.02219843864440918, "timer/env.step_max": 3.3836376667022705, "timer/replay._sample_count": 22384.0, "timer/replay._sample_total": 11.226692914962769, "timer/replay._sample_frac": 0.011225749129130921, "timer/replay._sample_avg": 0.0005015498979164925, "timer/replay._sample_min": 0.0004146099090576172, "timer/replay._sample_max": 0.02487325668334961, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3426.0, "timer/agent.policy_total": 54.395312786102295, "timer/agent.policy_frac": 0.054390739976823976, "timer/agent.policy_avg": 0.01587720746821433, "timer/agent.policy_min": 0.009417295455932617, "timer/agent.policy_max": 0.13654065132141113, "timer/dataset_train_count": 1399.0, "timer/dataset_train_total": 0.15013575553894043, "timer/dataset_train_frac": 0.00015012313419087252, "timer/dataset_train_avg": 0.00010731648001353855, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.002644777297973633, "timer/agent.train_count": 1399.0, "timer/agent.train_total": 630.4187860488892, "timer/agent.train_frac": 0.6303657891135575, "timer/agent.train_avg": 0.45062100503851976, "timer/agent.train_min": 0.4353525638580322, "timer/agent.train_max": 1.645601749420166, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4749948978424072, "timer/agent.report_frac": 0.00047495496680855973, "timer/agent.report_avg": 0.2374974489212036, "timer/agent.report_min": 0.2314901351928711, "timer/agent.report_max": 0.24350476264953613, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.932301994628891e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 22.3818016142949}
{"step": 767320, "time": 35393.333087444305, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 767712, "time": 35408.24373483658, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 768000, "time": 35419.439369916916, "episode/length": 368.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.986449864498645, "episode/intrinsic_return": 0.0}
{"step": 768256, "time": 35429.47777915001, "episode/length": 258.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 768320, "time": 35433.214317560196, "episode/length": 354.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 768352, "time": 35435.79725384712, "episode/length": 219.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 768512, "time": 35442.624156951904, "episode/length": 99.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 768520, "time": 35444.187960386276, "episode/length": 149.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 768600, "time": 35448.44736838341, "episode/length": 207.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 768760, "time": 35455.341776371, "episode/length": 207.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 769416, "time": 35479.9458861351, "episode/length": 144.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 769800, "time": 35494.50816106796, "episode/length": 224.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 769848, "time": 35498.01529455185, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 769920, "time": 35502.81738972664, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 769952, "time": 35505.881140470505, "episode/length": 168.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 35529.145864486694, "eval_episode/length": 47.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 770016, "time": 35531.368653297424, "eval_episode/length": 53.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 770016, "time": 35538.860051870346, "eval_episode/length": 168.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 770016, "time": 35540.9349322319, "eval_episode/length": 169.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 770016, "time": 35544.20425248146, "eval_episode/length": 195.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9693877551020408}
{"step": 770016, "time": 35546.67815947533, "eval_episode/length": 203.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 770016, "time": 35548.670659303665, "eval_episode/length": 209.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 770016, "time": 35550.38484334946, "eval_episode/length": 213.0, "eval_episode/score": 10.100000031292439, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 770040, "time": 35550.99021363258, "episode/length": 189.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 770064, "time": 35555.044830322266, "episode/length": 32.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8484848484848485, "episode/intrinsic_return": 0.0}
{"step": 770336, "time": 35565.44891142845, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 770736, "time": 35580.32766318321, "episode/length": 164.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 771200, "time": 35597.339153289795, "episode/length": 57.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 771320, "time": 35602.774528265, "episode/length": 156.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 771328, "time": 35604.743800878525, "episode/length": 351.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9914772727272727, "episode/intrinsic_return": 0.0}
{"step": 771640, "time": 35616.5914607048, "episode/length": 199.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 772248, "time": 35639.29480481148, "episode/length": 286.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 772328, "time": 35643.55435824394, "episode/length": 248.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 772432, "time": 35648.89307618141, "episode/length": 137.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 772624, "time": 35656.998358011246, "episode/length": 346.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9769452449567724, "episode/intrinsic_return": 0.0}
{"step": 772704, "time": 35661.88333082199, "episode/length": 347.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 772832, "time": 35668.3527469635, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 772872, "time": 35671.50690984726, "episode/length": 208.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 773272, "time": 35686.879319667816, "episode/length": 203.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 773632, "time": 35700.61297559738, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 773688, "time": 35703.78858470917, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 774024, "time": 35716.50241160393, "episode/length": 148.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 774152, "time": 35722.21353173256, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 774376, "time": 35731.333013772964, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 774552, "time": 35738.668013334274, "episode/length": 114.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 775000, "time": 35755.11180186272, "episode/length": 215.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 775032, "time": 35758.003271102905, "episode/length": 109.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 775072, "time": 35761.1585290432, "episode/length": 130.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9465648854961832, "episode/intrinsic_return": 0.0}
{"step": 775104, "time": 35763.78494977951, "episode/length": 176.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 775120, "time": 35765.89550971985, "episode/length": 311.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9967948717948718, "episode/intrinsic_return": 0.0}
{"step": 775560, "time": 35781.99269032478, "episode/length": 390.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9948849104859335, "episode/intrinsic_return": 0.0}
{"step": 775752, "time": 35790.02824282646, "episode/length": 89.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 776040, "time": 35801.32956171036, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 776672, "time": 35825.19939804077, "episode/length": 208.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 776744, "time": 35828.80803656578, "episode/length": 202.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 776848, "time": 35834.09995388985, "episode/length": 217.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 777032, "time": 35841.53370761871, "episode/length": 183.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 777432, "time": 35856.44526433945, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 777624, "time": 35865.014914274216, "episode/length": 318.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9937304075235109, "episode/intrinsic_return": 0.0}
{"step": 777712, "time": 35870.09925246239, "episode/length": 208.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 777880, "time": 35877.700701236725, "episode/length": 415.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9783653846153846, "episode/intrinsic_return": 0.0}
{"step": 778104, "time": 35886.58974289894, "episode/length": 156.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 778160, "time": 35890.19152903557, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 778328, "time": 35898.66724610329, "episode/length": 161.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 778608, "time": 35909.83271551132, "episode/length": 241.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 778904, "time": 35921.019845962524, "episode/length": 159.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 779192, "time": 35932.36019706726, "episode/length": 107.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 779368, "time": 35940.77535367012, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 779400, "time": 35944.04983854294, "episode/length": 189.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 779656, "time": 35954.918075323105, "episode/length": 242.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 779752, "time": 35960.273050785065, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 779760, "time": 35962.744713544846, "episode/length": 70.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 35997.49679541588, "eval_episode/length": 173.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 780000, "time": 35999.62834596634, "eval_episode/length": 186.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 780000, "time": 36001.73585534096, "eval_episode/length": 200.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 780000, "time": 36004.604895830154, "eval_episode/length": 230.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 780000, "time": 36006.87988996506, "eval_episode/length": 248.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 780000, "time": 36009.9689142704, "eval_episode/length": 284.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9754385964912281}
{"step": 780000, "time": 36013.604404211044, "eval_episode/length": 335.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 780000, "time": 36016.23808693886, "eval_episode/length": 176.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 780112, "time": 36019.97238087654, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 780208, "time": 36024.68287396431, "episode/length": 162.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 780656, "time": 36041.12229347229, "episode/length": 160.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 780712, "time": 36044.31296253204, "episode/length": 409.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 780784, "time": 36048.51821374893, "episode/length": 140.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 781056, "time": 36059.98330760002, "episode/length": 206.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 781160, "time": 36065.41664862633, "episode/length": 130.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 781312, "time": 36072.81305503845, "episode/length": 137.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 781744, "time": 36089.23734354973, "episode/length": 119.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 781920, "time": 36096.62207484245, "episode/length": 270.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 781984, "time": 36100.17901611328, "episode/length": 115.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 782088, "time": 36105.01827073097, "episode/length": 290.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9828178694158075, "episode/intrinsic_return": 0.0}
{"step": 782744, "time": 36128.433233737946, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 782808, "time": 36132.221158742905, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 783184, "time": 36146.55323815346, "episode/length": 308.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 783664, "time": 36164.08514714241, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 783680, "time": 36166.28069281578, "episode/length": 241.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 784120, "time": 36182.33715558052, "episode/length": 350.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9886039886039886, "episode/intrinsic_return": 0.0}
{"step": 784192, "time": 36186.57527947426, "episode/length": 283.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 784560, "time": 36200.35748791695, "episode/length": 308.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9838187702265372, "episode/intrinsic_return": 0.0}
{"step": 784680, "time": 36205.54322886467, "episode/length": 186.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 784880, "time": 36213.92592835426, "episode/length": 151.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 785200, "time": 36226.02807402611, "episode/length": 39.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 785296, "time": 36230.83056330681, "episode/length": 310.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9807073954983923, "episode/intrinsic_return": 0.0}
{"step": 785376, "time": 36235.11069202423, "episode/length": 156.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 785424, "time": 36238.44088387489, "episode/length": 153.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 785728, "time": 36250.08246088028, "episode/length": 145.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 785760, "time": 36252.632813215256, "episode/length": 376.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9973474801061007, "episode/intrinsic_return": 0.0}
{"step": 785888, "time": 36258.50039148331, "episode/length": 150.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 786680, "time": 36287.823681116104, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 786696, "time": 36289.878380060196, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 786712, "time": 36291.986270427704, "episode/length": 378.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9920844327176781, "episode/intrinsic_return": 0.0}
{"step": 786848, "time": 36298.4229426384, "episode/length": 205.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 787136, "time": 36309.526990413666, "episode/length": 175.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 787192, "time": 36312.76177930832, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 787928, "time": 36339.605810165405, "episode/length": 254.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 788024, "time": 36344.870633363724, "episode/length": 324.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9876923076923076, "episode/intrinsic_return": 0.0}
{"step": 788360, "time": 36358.633481025696, "episode/length": 209.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 788712, "time": 36372.68319964409, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 788976, "time": 36383.976261138916, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 789129, "time": 36392.09166932106, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.605058878877737, "train/action_min": 0.0, "train/action_std": 3.401291955126463, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04067704078816149, "train/actor_opt_grad_steps": 48540.0, "train/actor_opt_loss": -1.3782793158651703, "train/adv_mag": 0.4873814891724691, "train/adv_max": 0.45777763176138386, "train/adv_mean": 0.004123463499126956, "train/adv_min": -0.3841792293926225, "train/adv_std": 0.05775110374619491, "train/cont_avg": 0.9950031364051095, "train/cont_loss_mean": 0.00028087891985907273, "train/cont_loss_std": 0.008598489685747206, "train/cont_neg_acc": 0.9905345488120528, "train/cont_neg_loss": 0.026633924893300284, "train/cont_pos_acc": 0.9999856470275099, "train/cont_pos_loss": 0.0001347040322908866, "train/cont_pred": 0.9950168006611566, "train/cont_rate": 0.9950031364051095, "train/dyn_loss_mean": 13.325351903038303, "train/dyn_loss_std": 9.190042530533171, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9351146671458752, "train/extr_critic_critic_opt_grad_steps": 48540.0, "train/extr_critic_critic_opt_loss": 16241.788599167427, "train/extr_critic_mag": 8.075108277536657, "train/extr_critic_max": 8.075108277536657, "train/extr_critic_mean": 2.399256905500036, "train/extr_critic_min": -0.19996652028856488, "train/extr_critic_std": 1.849396182672821, "train/extr_return_normed_mag": 1.5447836139776412, "train/extr_return_normed_max": 1.5447836139776412, "train/extr_return_normed_mean": 0.38884685465889257, "train/extr_return_normed_min": -0.11074839191796788, "train/extr_return_normed_std": 0.3204070480853102, "train/extr_return_rate": 0.8309758470876374, "train/extr_return_raw_mag": 9.218347674738752, "train/extr_return_raw_max": 9.218347674738752, "train/extr_return_raw_mean": 2.4235014758840965, "train/extr_return_raw_min": -0.5126000621022969, "train/extr_return_raw_std": 1.8836226054351695, "train/extr_reward_mag": 1.0523738443416402, "train/extr_reward_max": 1.0523738443416402, "train/extr_reward_mean": 0.045952068492226356, "train/extr_reward_min": -0.4147300372158524, "train/extr_reward_std": 0.20094626728635634, "train/image_loss_mean": 6.18541429338664, "train/image_loss_std": 11.18005268765192, "train/model_loss_mean": 14.239535115931156, "train/model_loss_std": 14.937118237906128, "train/model_opt_grad_norm": 49.855891942977905, "train/model_opt_grad_steps": 48495.24087591241, "train/model_opt_loss": 18293.989122376825, "train/model_opt_model_opt_grad_overflow": 0.0072992700729927005, "train/model_opt_model_opt_grad_scale": 1277.3722627737227, "train/policy_entropy_mag": 2.441554118246928, "train/policy_entropy_max": 2.441554118246928, "train/policy_entropy_mean": 0.5140799364469347, "train/policy_entropy_min": 0.07937502132280029, "train/policy_entropy_std": 0.5995375168149488, "train/policy_logprob_mag": 7.4383837463211835, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5145644269285411, "train/policy_logprob_min": -7.4383837463211835, "train/policy_logprob_std": 1.0756990539766575, "train/policy_randomness_mag": 0.8617614633845587, "train/policy_randomness_max": 0.8617614633845587, "train/policy_randomness_mean": 0.18144765800803248, "train/policy_randomness_min": 0.028015899220413535, "train/policy_randomness_std": 0.21161043382909175, "train/post_ent_mag": 60.36538351017193, "train/post_ent_max": 60.36538351017193, "train/post_ent_mean": 42.981605167806585, "train/post_ent_min": 20.440200861353073, "train/post_ent_std": 7.602480884886136, "train/prior_ent_mag": 69.2962826359881, "train/prior_ent_max": 69.2962826359881, "train/prior_ent_mean": 56.39481640558173, "train/prior_ent_min": 40.9590905182553, "train/prior_ent_std": 4.420804375279559, "train/rep_loss_mean": 13.325351903038303, "train/rep_loss_std": 9.190042530533171, "train/reward_avg": 0.03122362531177754, "train/reward_loss_mean": 0.05862875173996835, "train/reward_loss_std": 0.262307744174108, "train/reward_max_data": 1.015328470807876, "train/reward_max_pred": 1.0124501172643507, "train/reward_neg_acc": 0.9924836741746778, "train/reward_neg_loss": 0.029427649283332982, "train/reward_pos_acc": 0.9648284672820655, "train/reward_pos_loss": 0.8491462090589704, "train/reward_pred": 0.030393972231523833, "train/reward_rate": 0.03578353102189781, "train_stats/sum_log_reward": 9.398077144072605, "train_stats/max_log_achievement_collect_coal": 0.6346153846153846, "train_stats/max_log_achievement_collect_drink": 3.0, "train_stats/max_log_achievement_collect_sapling": 1.4615384615384615, "train_stats/max_log_achievement_collect_stone": 11.73076923076923, "train_stats/max_log_achievement_collect_wood": 10.557692307692308, "train_stats/max_log_achievement_defeat_skeleton": 0.07692307692307693, "train_stats/max_log_achievement_defeat_zombie": 0.6442307692307693, "train_stats/max_log_achievement_eat_cow": 0.09615384615384616, "train_stats/max_log_achievement_make_stone_pickaxe": 0.019230769230769232, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4230769230769231, "train_stats/max_log_achievement_make_wood_sword": 1.1057692307692308, "train_stats/max_log_achievement_place_furnace": 0.0673076923076923, "train_stats/max_log_achievement_place_plant": 1.4615384615384615, "train_stats/max_log_achievement_place_stone": 7.346153846153846, "train_stats/max_log_achievement_place_table": 2.8653846153846154, "train_stats/max_log_achievement_wake_up": 1.2211538461538463, "train_stats/mean_log_entropy": 0.6203648551152303, "eval_stats/sum_log_reward": 8.725000262260437, "eval_stats/max_log_achievement_collect_coal": 0.3125, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_sapling": 1.8125, "eval_stats/max_log_achievement_collect_stone": 7.5, "eval_stats/max_log_achievement_collect_wood": 9.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3125, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_stone": 5.5625, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00020333736028987914, "report/cont_loss_std": 0.006216307170689106, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.03330568969249725, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.235097993747331e-06, "report/cont_pred": 0.9943096041679382, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.862242698669434, "report/dyn_loss_std": 9.17811393737793, "report/image_loss_mean": 4.851451396942139, "report/image_loss_std": 8.465526580810547, "report/model_loss_mean": 13.231402397155762, "report/model_loss_std": 12.263229370117188, "report/post_ent_mag": 60.687538146972656, "report/post_ent_max": 60.687538146972656, "report/post_ent_mean": 42.35010528564453, "report/post_ent_min": 21.428749084472656, "report/post_ent_std": 8.099934577941895, "report/prior_ent_mag": 69.66854858398438, "report/prior_ent_max": 69.66854858398438, "report/prior_ent_mean": 56.37698745727539, "report/prior_ent_min": 40.79296875, "report/prior_ent_std": 4.388017654418945, "report/rep_loss_mean": 13.862242698669434, "report/rep_loss_std": 9.17811393737793, "report/reward_avg": 0.03681640326976776, "report/reward_loss_mean": 0.06240295246243477, "report/reward_loss_std": 0.25359782576560974, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0038278102874756, "report/reward_neg_acc": 0.9989805817604065, "report/reward_neg_loss": 0.0324617475271225, "report/reward_pos_acc": 0.9767441749572754, "report/reward_pos_loss": 0.7454801797866821, "report/reward_pred": 0.035705823451280594, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 8.600561159255449e-06, "eval/cont_loss_std": 0.00017373726586811244, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0019846579525619745, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.733520199806662e-06, "eval/cont_pred": 0.9980460405349731, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 19.79167366027832, "eval/dyn_loss_std": 10.542593955993652, "eval/image_loss_mean": 12.134336471557617, "eval/image_loss_std": 13.531200408935547, "eval/model_loss_mean": 24.125782012939453, "eval/model_loss_std": 17.309465408325195, "eval/post_ent_mag": 59.151939392089844, "eval/post_ent_max": 59.151939392089844, "eval/post_ent_mean": 39.83597183227539, "eval/post_ent_min": 21.37883758544922, "eval/post_ent_std": 7.681755065917969, "eval/prior_ent_mag": 69.66854858398438, "eval/prior_ent_max": 69.66854858398438, "eval/prior_ent_mean": 56.77042770385742, "eval/prior_ent_min": 43.25910186767578, "eval/prior_ent_std": 4.231219291687012, "eval/rep_loss_mean": 19.79167366027832, "eval/rep_loss_std": 10.542593955993652, "eval/reward_avg": 0.03896484524011612, "eval/reward_loss_mean": 0.11643210053443909, "eval/reward_loss_std": 0.7659778594970703, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017733573913574, "eval/reward_neg_acc": 0.9898062944412231, "eval/reward_neg_loss": 0.037494808435440063, "eval/reward_pos_acc": 0.8372092843055725, "eval/reward_pos_loss": 1.9173038005828857, "eval/reward_pred": 0.0340908020734787, "eval/reward_rate": 0.0419921875, "replay/size": 788625.0, "replay/inserts": 21856.0, "replay/samples": 21856.0, "replay/insert_wait_avg": 1.399378301807588e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.377267012309889e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2044675622431877e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1544351577759, "timer/env.step_count": 2732.0, "timer/env.step_total": 250.86932587623596, "timer/env.step_frac": 0.25083058881467735, "timer/env.step_avg": 0.0918262539810527, "timer/env.step_min": 0.02243638038635254, "timer/env.step_max": 2.2280972003936768, "timer/replay._sample_count": 21856.0, "timer/replay._sample_total": 10.995810747146606, "timer/replay._sample_frac": 0.010994112869590985, "timer/replay._sample_avg": 0.0005031026147120519, "timer/replay._sample_min": 0.00039649009704589844, "timer/replay._sample_max": 0.010504484176635742, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3310.0, "timer/agent.policy_total": 54.50502800941467, "timer/agent.policy_frac": 0.05449661181657053, "timer/agent.policy_avg": 0.016466775833660022, "timer/agent.policy_min": 0.009212970733642578, "timer/agent.policy_max": 0.12677526473999023, "timer/dataset_train_count": 1366.0, "timer/dataset_train_total": 0.14553093910217285, "timer/dataset_train_frac": 0.00014550846747904, "timer/dataset_train_avg": 0.00010653802276879418, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0002498626708984375, "timer/agent.train_count": 1366.0, "timer/agent.train_total": 617.0736424922943, "timer/agent.train_frac": 0.616978359342025, "timer/agent.train_avg": 0.45173765921837067, "timer/agent.train_min": 0.4377775192260742, "timer/agent.train_max": 1.5738093852996826, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4785017967224121, "timer/agent.report_frac": 0.0004784279106325492, "timer/agent.report_avg": 0.23925089836120605, "timer/agent.report_min": 0.23149466514587402, "timer/agent.report_max": 0.24700713157653809, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8129048219984438e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 21.852333856779495}
{"step": 789264, "time": 36396.827234983444, "episode/length": 320.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9844236760124611, "episode/intrinsic_return": 0.0}
{"step": 789584, "time": 36409.8744122982, "episode/length": 341.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 789592, "time": 36411.98307466507, "episode/length": 359.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 789824, "time": 36422.24562883377, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 789896, "time": 36426.3603913784, "episode/length": 38.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 789968, "time": 36430.54349684715, "episode/length": 46.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 790000, "time": 36433.211547374725, "episode/length": 246.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 36451.98071050644, "eval_episode/length": 41.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 790088, "time": 36458.0950858593, "eval_episode/length": 156.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 790088, "time": 36460.88659477234, "eval_episode/length": 187.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9627659574468085}
{"step": 790088, "time": 36463.99213838577, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 790088, "time": 36465.94672656059, "eval_episode/length": 230.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 790088, "time": 36468.08420228958, "eval_episode/length": 243.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9959016393442623}
{"step": 790088, "time": 36470.68726015091, "eval_episode/length": 265.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9962406015037594}
{"step": 790088, "time": 36473.79708456993, "eval_episode/length": 304.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9770491803278688}
{"step": 790144, "time": 36475.888906002045, "episode/length": 276.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9819494584837545, "episode/intrinsic_return": 0.0}
{"step": 790304, "time": 36482.912009716034, "episode/length": 165.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 790832, "time": 36502.21029424667, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 791296, "time": 36520.23767566681, "episode/length": 165.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 791592, "time": 36532.14711499214, "episode/length": 211.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 791656, "time": 36536.394181489944, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 791856, "time": 36545.52706193924, "episode/length": 392.0, "episode/score": 13.100000038743019, "episode/reward_rate": 0.9974554707379135, "episode/intrinsic_return": 0.0}
{"step": 792088, "time": 36555.033021211624, "episode/length": 242.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 792280, "time": 36563.04320907593, "episode/length": 306.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9869706840390879, "episode/intrinsic_return": 0.0}
{"step": 792320, "time": 36566.099637031555, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 792808, "time": 36584.07795858383, "episode/length": 312.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 793016, "time": 36593.274821043015, "episode/length": 177.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9831460674157303, "episode/intrinsic_return": 0.0}
{"step": 793176, "time": 36600.808755874634, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 793496, "time": 36612.921607494354, "episode/length": 39.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.925, "episode/intrinsic_return": 0.0}
{"step": 793568, "time": 36617.17419743538, "episode/length": 283.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 793600, "time": 36619.73821377754, "episode/length": 242.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 793992, "time": 36634.20014047623, "episode/length": 213.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 794600, "time": 36655.882934331894, "episode/length": 284.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 794960, "time": 36672.23627090454, "episode/length": 358.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9888579387186629, "episode/intrinsic_return": 0.0}
{"step": 794968, "time": 36673.87120318413, "episode/length": 243.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 795080, "time": 36679.2230424881, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 795136, "time": 36682.932267427444, "episode/length": 204.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 795320, "time": 36690.3362660408, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 795456, "time": 36696.48117661476, "episode/length": 330.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9969788519637462, "episode/intrinsic_return": 0.0}
{"step": 796144, "time": 36721.086317777634, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 796184, "time": 36723.72527742386, "episode/length": 273.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9890510948905109, "episode/intrinsic_return": 0.0}
{"step": 796232, "time": 36726.84358429909, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 796472, "time": 36736.43946623802, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 796576, "time": 36741.61838555336, "episode/length": 42.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 796904, "time": 36754.8336956501, "episode/length": 197.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 797600, "time": 36779.882288217545, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 797832, "time": 36788.9967353344, "episode/length": 336.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9851632047477745, "episode/intrinsic_return": 0.0}
{"step": 797840, "time": 36791.00642371178, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 797920, "time": 36795.25976729393, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 798096, "time": 36802.68072772026, "episode/length": 376.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9893899204244032, "episode/intrinsic_return": 0.0}
{"step": 798208, "time": 36807.93972659111, "episode/length": 45.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 798232, "time": 36810.13336634636, "episode/length": 346.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9913544668587896, "episode/intrinsic_return": 0.0}
{"step": 798280, "time": 36813.273659944534, "episode/length": 44.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 798424, "time": 36819.6948723793, "episode/length": 279.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 798456, "time": 36822.21185159683, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 799648, "time": 36863.631571769714, "episode/length": 152.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 799760, "time": 36868.97615098953, "episode/length": 193.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 799800, "time": 36871.62158536911, "episode/length": 245.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 799968, "time": 36879.005878686905, "episode/length": 210.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 36903.91208696365, "eval_episode/length": 182.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 800072, "time": 36905.97346377373, "eval_episode/length": 196.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9695431472081218}
{"step": 800072, "time": 36907.6334605217, "eval_episode/length": 199.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.995}
{"step": 800072, "time": 36909.213452100754, "eval_episode/length": 200.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 800072, "time": 36914.05298161507, "eval_episode/length": 279.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 800072, "time": 36916.81005358696, "eval_episode/length": 307.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9967532467532467}
{"step": 800072, "time": 36918.68073010445, "eval_episode/length": 312.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.987220447284345}
{"step": 800072, "time": 36922.351021528244, "eval_episode/length": 85.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9883720930232558}
{"step": 800432, "time": 36934.53716683388, "episode/length": 291.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.976027397260274, "episode/intrinsic_return": 0.0}
{"step": 800576, "time": 36940.6899600029, "episode/length": 96.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 800648, "time": 36944.38712668419, "episode/length": 273.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 800656, "time": 36946.45102381706, "episode/length": 381.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9973821989528796, "episode/intrinsic_return": 0.0}
{"step": 801064, "time": 36961.38558793068, "episode/length": 353.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 801208, "time": 36967.67257165909, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 801336, "time": 36973.35437679291, "episode/length": 210.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 802072, "time": 36999.265671014786, "episode/length": 288.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792387543252595, "episode/intrinsic_return": 0.0}
{"step": 802168, "time": 37003.98934364319, "episode/length": 188.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 802376, "time": 37012.47305727005, "episode/length": 224.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 802872, "time": 37032.35749864578, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 803616, "time": 37058.912019729614, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 803872, "time": 37068.908158540726, "episode/length": 212.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 803936, "time": 37072.50149703026, "episode/length": 410.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 803952, "time": 37074.55706548691, "episode/length": 196.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 804608, "time": 37097.840984106064, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 804912, "time": 37109.482969760895, "episode/length": 462.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9978401727861771, "episode/intrinsic_return": 0.0}
{"step": 804928, "time": 37111.549808979034, "episode/length": 561.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9928825622775801, "episode/intrinsic_return": 0.0}
{"step": 805168, "time": 37121.119258880615, "episode/length": 478.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9979123173277662, "episode/intrinsic_return": 0.0}
{"step": 805224, "time": 37124.26338148117, "episode/length": 158.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 805304, "time": 37128.52382063866, "episode/length": 210.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 805672, "time": 37142.26662516594, "episode/length": 62.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9206349206349206, "episode/intrinsic_return": 0.0}
{"step": 805712, "time": 37145.28419995308, "episode/length": 221.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 806312, "time": 37166.627583265305, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 806432, "time": 37172.373599767685, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 806992, "time": 37192.63725113869, "episode/length": 210.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 807032, "time": 37195.323680877686, "episode/length": 264.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 807136, "time": 37200.70139336586, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 807352, "time": 37209.14886522293, "episode/length": 434.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954022988505747, "episode/intrinsic_return": 0.0}
{"step": 807928, "time": 37229.788143634796, "episode/length": 111.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 808048, "time": 37235.54250741005, "episode/length": 201.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 808152, "time": 37240.27272248268, "episode/length": 309.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 808448, "time": 37251.787707567215, "episode/length": 136.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 808520, "time": 37255.43117547035, "episode/length": 411.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 808720, "time": 37263.88942694664, "episode/length": 197.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 808824, "time": 37268.70103120804, "episode/length": 313.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 809120, "time": 37280.28668165207, "episode/length": 36.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 809136, "time": 37282.335342645645, "episode/length": 267.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9888059701492538, "episode/intrinsic_return": 0.0}
{"step": 809360, "time": 37291.40250778198, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 809784, "time": 37306.86042571068, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 809792, "time": 37308.91051983833, "episode/length": 217.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 809960, "time": 37315.86684823036, "episode/length": 179.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 37342.73662233353, "eval_episode/length": 183.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 810056, "time": 37344.90570425987, "eval_episode/length": 199.0, "eval_episode/score": 12.100000023841858, "eval_episode/reward_rate": 0.995}
{"step": 810056, "time": 37346.70395541191, "eval_episode/length": 202.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 810056, "time": 37348.89581942558, "eval_episode/length": 216.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 810056, "time": 37350.97290349007, "eval_episode/length": 229.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9826086956521739}
{"step": 810056, "time": 37353.36571931839, "eval_episode/length": 251.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 810056, "time": 37356.683958768845, "eval_episode/length": 41.0, "eval_episode/score": 4.099999964237213, "eval_episode/reward_rate": 0.9047619047619048}
{"step": 810056, "time": 37358.89211845398, "eval_episode/length": 310.0, "eval_episode/score": 12.099999979138374, "eval_episode/reward_rate": 0.9967845659163987}
{"step": 810512, "time": 37374.2284116745, "episode/length": 223.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 810640, "time": 37380.20810222626, "episode/length": 106.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 810648, "time": 37381.74235892296, "episode/length": 311.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9967948717948718, "episode/intrinsic_return": 0.0}
{"step": 810889, "time": 37392.27885246277, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.639937008128447, "train/action_min": 0.0, "train/action_std": 3.374009717913235, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04116978859254981, "train/actor_opt_grad_steps": 49905.0, "train/actor_opt_loss": -5.4494534953333, "train/adv_mag": 0.5297764800488949, "train/adv_max": 0.46010809282169624, "train/adv_mean": 0.0029493297273641954, "train/adv_min": -0.45384918383377437, "train/adv_std": 0.0572121025830069, "train/cont_avg": 0.9948227826286765, "train/cont_loss_mean": 0.00020192693428868497, "train/cont_loss_std": 0.005880509536962443, "train/cont_neg_acc": 0.9942401967504445, "train/cont_neg_loss": 0.02683459570496726, "train/cont_pos_acc": 0.9999782627119738, "train/cont_pos_loss": 7.198015210360838e-05, "train/cont_pred": 0.9948175518828279, "train/cont_rate": 0.9948227826286765, "train/dyn_loss_mean": 13.490492729579701, "train/dyn_loss_std": 9.186491868075203, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9126550419365659, "train/extr_critic_critic_opt_grad_steps": 49905.0, "train/extr_critic_critic_opt_loss": 15886.354736328125, "train/extr_critic_mag": 8.170259861385121, "train/extr_critic_max": 8.170259861385121, "train/extr_critic_mean": 2.5510813488679775, "train/extr_critic_min": -0.1897437844206305, "train/extr_critic_std": 1.8860050080453648, "train/extr_return_normed_mag": 1.533943426083116, "train/extr_return_normed_max": 1.533943426083116, "train/extr_return_normed_mean": 0.3963542635388234, "train/extr_return_normed_min": -0.11771936235291992, "train/extr_return_normed_std": 0.3211412527324522, "train/extr_return_rate": 0.8692459862898377, "train/extr_return_raw_mag": 9.36046929920421, "train/extr_return_raw_max": 9.36046929920421, "train/extr_return_raw_mean": 2.568690349073971, "train/extr_return_raw_min": -0.5012164424611804, "train/extr_return_raw_std": 1.9177516768960392, "train/extr_reward_mag": 1.0412954635479872, "train/extr_reward_max": 1.0412954635479872, "train/extr_reward_mean": 0.047604415661600584, "train/extr_reward_min": -0.42222001973320455, "train/extr_reward_std": 0.20449111490126917, "train/image_loss_mean": 6.233610163716709, "train/image_loss_std": 11.147602260112762, "train/model_loss_mean": 14.387463829096626, "train/model_loss_std": 14.919715727076811, "train/model_opt_grad_norm": 51.417958105311676, "train/model_opt_grad_steps": 49858.80147058824, "train/model_opt_loss": 19171.937162511487, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1332.7205882352941, "train/policy_entropy_mag": 2.4409267762128044, "train/policy_entropy_max": 2.4409267762128044, "train/policy_entropy_mean": 0.5072164204629028, "train/policy_entropy_min": 0.07937502006397527, "train/policy_entropy_std": 0.594176604248145, "train/policy_logprob_mag": 7.438383715994218, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.506802701336496, "train/policy_logprob_min": -7.438383715994218, "train/policy_logprob_std": 1.067566796698991, "train/policy_randomness_mag": 0.8615400357281461, "train/policy_randomness_max": 0.8615400357281461, "train/policy_randomness_mean": 0.17902513878310428, "train/policy_randomness_min": 0.02801589881453444, "train/policy_randomness_std": 0.20971826683072484, "train/post_ent_mag": 60.21398878097534, "train/post_ent_max": 60.21398878097534, "train/post_ent_mean": 42.78484543632059, "train/post_ent_min": 20.44190502166748, "train/post_ent_std": 7.5629633209284615, "train/prior_ent_mag": 69.34848656373866, "train/prior_ent_max": 69.34848656373866, "train/prior_ent_mean": 56.30927111120785, "train/prior_ent_min": 40.565549696193024, "train/prior_ent_std": 4.456971384146634, "train/rep_loss_mean": 13.490492729579701, "train/rep_loss_std": 9.186491868075203, "train/reward_avg": 0.03263872909797903, "train/reward_loss_mean": 0.059356157832285934, "train/reward_loss_std": 0.2532409048255752, "train/reward_max_data": 1.017647063030916, "train/reward_max_pred": 1.01285518618191, "train/reward_neg_acc": 0.9922595550032223, "train/reward_neg_loss": 0.029494356884456733, "train/reward_pos_acc": 0.9692062919630724, "train/reward_pos_loss": 0.8314226129475761, "train/reward_pred": 0.03166030819171711, "train/reward_rate": 0.037353515625, "train_stats/sum_log_reward": 8.954166861716658, "train_stats/max_log_achievement_collect_coal": 0.4791666666666667, "train_stats/max_log_achievement_collect_drink": 3.625, "train_stats/max_log_achievement_collect_sapling": 1.3854166666666667, "train_stats/max_log_achievement_collect_stone": 11.322916666666666, "train_stats/max_log_achievement_collect_wood": 10.802083333333334, "train_stats/max_log_achievement_defeat_skeleton": 0.07291666666666667, "train_stats/max_log_achievement_defeat_zombie": 0.75, "train_stats/max_log_achievement_eat_cow": 0.125, "train_stats/max_log_achievement_make_stone_pickaxe": 0.010416666666666666, "train_stats/max_log_achievement_make_stone_sword": 0.010416666666666666, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2395833333333333, "train_stats/max_log_achievement_make_wood_sword": 1.09375, "train_stats/max_log_achievement_place_furnace": 0.020833333333333332, "train_stats/max_log_achievement_place_plant": 1.375, "train_stats/max_log_achievement_place_stone": 8.822916666666666, "train_stats/max_log_achievement_place_table": 2.9583333333333335, "train_stats/max_log_achievement_wake_up": 1.4375, "train_stats/mean_log_entropy": 0.6153138511193296, "eval_stats/sum_log_reward": 8.766666730244955, "eval_stats/max_log_achievement_collect_coal": 0.8333333333333334, "eval_stats/max_log_achievement_collect_drink": 3.5833333333333335, "eval_stats/max_log_achievement_collect_sapling": 1.0416666666666667, "eval_stats/max_log_achievement_collect_stone": 11.083333333333334, "eval_stats/max_log_achievement_collect_wood": 10.083333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.7083333333333334, "eval_stats/max_log_achievement_eat_cow": 0.20833333333333334, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.2083333333333333, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_furnace": 0.08333333333333333, "eval_stats/max_log_achievement_place_plant": 1.0416666666666667, "eval_stats/max_log_achievement_place_stone": 7.958333333333333, "eval_stats/max_log_achievement_place_table": 2.7083333333333335, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.5738421754795127e-05, "report/cont_loss_std": 0.000551684177480638, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001461031730286777, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.5859312043176033e-05, "report/cont_pred": 0.9931584000587463, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 14.242000579833984, "report/dyn_loss_std": 9.898014068603516, "report/image_loss_mean": 7.910984039306641, "report/image_loss_std": 13.75706958770752, "report/model_loss_mean": 16.517704010009766, "report/model_loss_std": 17.572778701782227, "report/post_ent_mag": 62.608123779296875, "report/post_ent_max": 62.608123779296875, "report/post_ent_mean": 42.8272590637207, "report/post_ent_min": 19.341951370239258, "report/post_ent_std": 7.746225357055664, "report/prior_ent_mag": 69.16889953613281, "report/prior_ent_max": 69.16889953613281, "report/prior_ent_mean": 57.109519958496094, "report/prior_ent_min": 43.046485900878906, "report/prior_ent_std": 4.794539451599121, "report/rep_loss_mean": 14.242000579833984, "report/rep_loss_std": 9.898014068603516, "report/reward_avg": 0.04521483927965164, "report/reward_loss_mean": 0.06149313971400261, "report/reward_loss_std": 0.20870263874530792, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.00286865234375, "report/reward_neg_acc": 0.9928057789802551, "report/reward_neg_loss": 0.024691807106137276, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7636048793792725, "report/reward_pred": 0.04286022484302521, "report/reward_rate": 0.0498046875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.0794756377663361e-07, "eval/cont_loss_std": 1.1910925650227e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.556815707066562e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.812327330545486e-08, "eval/cont_pred": 0.9980469346046448, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.519514083862305, "eval/dyn_loss_std": 10.364277839660645, "eval/image_loss_mean": 9.918806076049805, "eval/image_loss_std": 14.1118803024292, "eval/model_loss_mean": 21.147371292114258, "eval/model_loss_std": 18.155292510986328, "eval/post_ent_mag": 58.951812744140625, "eval/post_ent_max": 58.951812744140625, "eval/post_ent_mean": 40.58319854736328, "eval/post_ent_min": 21.585662841796875, "eval/post_ent_std": 7.44450044631958, "eval/prior_ent_mag": 69.16889953613281, "eval/prior_ent_max": 69.16889953613281, "eval/prior_ent_mean": 57.0405387878418, "eval/prior_ent_min": 41.64874267578125, "eval/prior_ent_std": 4.302011966705322, "eval/rep_loss_mean": 18.519514083862305, "eval/rep_loss_std": 10.364277839660645, "eval/reward_avg": 0.03164062649011612, "eval/reward_loss_mean": 0.11685595661401749, "eval/reward_loss_std": 0.673405647277832, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001105546951294, "eval/reward_neg_acc": 0.9888664484024048, "eval/reward_neg_loss": 0.046031977981328964, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 2.0605807304382324, "eval/reward_pred": 0.025335976853966713, "eval/reward_rate": 0.03515625, "replay/size": 810385.0, "replay/inserts": 21760.0, "replay/samples": 21760.0, "replay/insert_wait_avg": 1.3667980537695042e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.380697930560393e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1876013031316628e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.171902179718, "timer/env.step_count": 2720.0, "timer/env.step_total": 227.50824213027954, "timer/env.step_frac": 0.22746913968934837, "timer/env.step_avg": 0.08364273607730865, "timer/env.step_min": 0.022321224212646484, "timer/env.step_max": 2.2205893993377686, "timer/replay._sample_count": 21760.0, "timer/replay._sample_total": 10.912925243377686, "timer/replay._sample_frac": 0.010911049610166687, "timer/replay._sample_avg": 0.0005015131086111069, "timer/replay._sample_min": 0.0003943443298339844, "timer/replay._sample_max": 0.027765512466430664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3702.0, "timer/agent.policy_total": 60.0284903049469, "timer/agent.policy_frac": 0.06001817305017688, "timer/agent.policy_avg": 0.016215151351957564, "timer/agent.policy_min": 0.009358882904052734, "timer/agent.policy_max": 0.12466788291931152, "timer/dataset_train_count": 1360.0, "timer/dataset_train_total": 0.14434528350830078, "timer/dataset_train_frac": 0.00014432047450415559, "timer/dataset_train_avg": 0.00010613623787375058, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0010590553283691406, "timer/agent.train_count": 1360.0, "timer/agent.train_total": 611.6723005771637, "timer/agent.train_frac": 0.611567170847451, "timer/agent.train_avg": 0.44975904454203214, "timer/agent.train_min": 0.43576979637145996, "timer/agent.train_max": 1.705085039138794, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4683706760406494, "timer/agent.report_frac": 0.000468290175938665, "timer/agent.report_avg": 0.2341853380203247, "timer/agent.report_min": 0.22797918319702148, "timer/agent.report_max": 0.24039149284362793, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027395538697873e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 21.755991175994797}
{"step": 810968, "time": 37394.72086238861, "episode/length": 230.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 811368, "time": 37411.18642115593, "episode/length": 175.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 811536, "time": 37418.4763841629, "episode/length": 217.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 811792, "time": 37428.84623837471, "episode/length": 331.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9969879518072289, "episode/intrinsic_return": 0.0}
{"step": 812400, "time": 37451.6095662117, "episode/length": 235.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 812496, "time": 37456.28426909447, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 812704, "time": 37464.859152793884, "episode/length": 256.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 813200, "time": 37483.01650452614, "episode/length": 228.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9694323144104804, "episode/intrinsic_return": 0.0}
{"step": 813216, "time": 37485.07720065117, "episode/length": 177.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 813456, "time": 37494.72019982338, "episode/length": 239.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 813480, "time": 37496.96266555786, "episode/length": 514.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9922330097087378, "episode/intrinsic_return": 0.0}
{"step": 814216, "time": 37523.735714912415, "episode/length": 405.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975369458128078, "episode/intrinsic_return": 0.0}
{"step": 814224, "time": 37526.224167346954, "episode/length": 189.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 814272, "time": 37529.898446798325, "episode/length": 131.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 814336, "time": 37534.261910676956, "episode/length": 229.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 814760, "time": 37550.694172143936, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 814768, "time": 37552.73796796799, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 814776, "time": 37554.36432647705, "episode/length": 296.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 814928, "time": 37561.10392022133, "episode/length": 180.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 816024, "time": 37598.93722295761, "episode/length": 210.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 816024, "time": 37598.95354938507, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 816216, "time": 37608.96046233177, "episode/length": 249.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.988, "episode/intrinsic_return": 0.0}
{"step": 816440, "time": 37618.223714351654, "episode/length": 270.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 816520, "time": 37622.48153090477, "episode/length": 286.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 817152, "time": 37645.12777543068, "episode/length": 298.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.979933110367893, "episode/intrinsic_return": 0.0}
{"step": 817456, "time": 37656.8945748806, "episode/length": 335.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 817536, "time": 37661.09079742432, "episode/length": 188.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 817552, "time": 37663.26260018349, "episode/length": 327.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9908536585365854, "episode/intrinsic_return": 0.0}
{"step": 817712, "time": 37670.145703315735, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 817952, "time": 37679.777618169785, "episode/length": 240.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 818168, "time": 37688.26489663124, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.0}
{"step": 818704, "time": 37707.839258909225, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 819072, "time": 37721.578145504, "episode/length": 189.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 819120, "time": 37724.712468624115, "episode/length": 334.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9970149253731343, "episode/intrinsic_return": 0.0}
{"step": 819592, "time": 37743.7512421608, "episode/length": 204.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 819664, "time": 37747.82901477814, "episode/length": 243.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 819872, "time": 37756.24544382095, "episode/length": 212.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 819968, "time": 37761.01475358009, "episode/length": 37.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 37785.868925094604, "eval_episode/length": 198.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 820040, "time": 37787.98800897598, "eval_episode/length": 211.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9669811320754716}
{"step": 820040, "time": 37789.89962339401, "eval_episode/length": 220.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.995475113122172}
{"step": 820040, "time": 37791.566893577576, "eval_episode/length": 221.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 820040, "time": 37793.78389787674, "eval_episode/length": 235.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 820040, "time": 37796.74635004997, "eval_episode/length": 265.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9962406015037594}
{"step": 820040, "time": 37800.42588639259, "eval_episode/length": 316.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9842271293375394}
{"step": 820040, "time": 37802.45533370972, "eval_episode/length": 330.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9818731117824774}
{"step": 820104, "time": 37804.571714401245, "episode/length": 320.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9781931464174455, "episode/intrinsic_return": 0.0}
{"step": 820128, "time": 37807.18848156929, "episode/length": 333.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 820464, "time": 37819.92639875412, "episode/length": 219.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 821400, "time": 37852.45195221901, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 821480, "time": 37856.674611091614, "episode/length": 300.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 821656, "time": 37864.081703186035, "episode/length": 222.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 821672, "time": 37866.14673495293, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 822048, "time": 37880.46020030975, "episode/length": 365.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9890710382513661, "episode/intrinsic_return": 0.0}
{"step": 822408, "time": 37893.895235061646, "episode/length": 351.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9971590909090909, "episode/intrinsic_return": 0.0}
{"step": 822864, "time": 37910.83905124664, "episode/length": 299.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 822880, "time": 37912.78508353233, "episode/length": 343.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9912790697674418, "episode/intrinsic_return": 0.0}
{"step": 823200, "time": 37925.077330350876, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 823776, "time": 37945.734681367874, "episode/length": 215.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 824072, "time": 37956.83911204338, "episode/length": 323.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9845679012345679, "episode/intrinsic_return": 0.0}
{"step": 824152, "time": 37961.05465865135, "episode/length": 217.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 824176, "time": 37963.57627749443, "episode/length": 314.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 824544, "time": 37977.41557383537, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 825000, "time": 37994.37438964844, "episode/length": 224.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 825264, "time": 38004.87906742096, "episode/length": 148.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 825848, "time": 38026.371277332306, "episode/length": 370.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9946091644204852, "episode/intrinsic_return": 0.0}
{"step": 825880, "time": 38029.39174962044, "episode/length": 212.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 826000, "time": 38035.60377788544, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 826264, "time": 38046.54272770882, "episode/length": 47.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 826448, "time": 38054.9446978569, "episode/length": 333.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9880239520958084, "episode/intrinsic_return": 0.0}
{"step": 826560, "time": 38060.9143280983, "episode/length": 644.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.993798449612403, "episode/intrinsic_return": 0.0}
{"step": 826600, "time": 38064.125596523285, "episode/length": 199.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 826856, "time": 38075.01463675499, "episode/length": 198.0, "episode/score": 8.099999956786633, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 827448, "time": 38099.00828361511, "episode/length": 411.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 827736, "time": 38110.15504717827, "episode/length": 216.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 827784, "time": 38113.377182245255, "episode/length": 152.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.0}
{"step": 827864, "time": 38117.61584377289, "episode/length": 157.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 828416, "time": 38137.79231095314, "episode/length": 245.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 828464, "time": 38141.01164031029, "episode/length": 200.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 828776, "time": 38152.618136167526, "episode/length": 44.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 828864, "time": 38157.34789848328, "episode/length": 140.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 829128, "time": 38167.37069797516, "episode/length": 357.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 829128, "time": 38167.38251924515, "episode/length": 409.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 38215.16627049446, "eval_episode/length": 42.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9069767441860465}
{"step": 830024, "time": 38221.24171423912, "eval_episode/length": 151.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 830024, "time": 38223.592977523804, "eval_episode/length": 171.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9593023255813954}
{"step": 830024, "time": 38226.81345939636, "eval_episode/length": 211.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 830024, "time": 38229.704319000244, "eval_episode/length": 197.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 830024, "time": 38233.66177082062, "eval_episode/length": 147.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 830024, "time": 38235.35127329826, "eval_episode/length": 304.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9868852459016394}
{"step": 830024, "time": 38238.080793857574, "eval_episode/length": 159.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 830184, "time": 38243.41104507446, "episode/length": 214.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 830200, "time": 38245.639312028885, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 830208, "time": 38247.77538514137, "episode/length": 178.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 830392, "time": 38255.12072658539, "episode/length": 367.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9918478260869565, "episode/intrinsic_return": 0.0}
{"step": 830568, "time": 38262.49352836609, "episode/length": 179.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 830584, "time": 38264.56059861183, "episode/length": 46.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 831504, "time": 38296.97339987755, "episode/length": 464.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9978494623655914, "episode/intrinsic_return": 0.0}
{"step": 831568, "time": 38300.76498746872, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 831672, "time": 38305.68984293938, "episode/length": 317.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 831832, "time": 38312.69538807869, "episode/length": 155.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 831944, "time": 38318.04881262779, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 832192, "time": 38328.096688747406, "episode/length": 224.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 832328, "time": 38333.91767859459, "episode/length": 102.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 832528, "time": 38342.39272618294, "episode/length": 119.0, "episode/score": 10.100000038743019, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 832608, "time": 38346.55660247803, "episode/length": 34.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.8857142857142857, "episode/intrinsic_return": 0.0}
{"step": 832744, "time": 38352.405146598816, "episode/length": 609.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 832968, "time": 38361.39190411568, "episode/length": 345.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 833136, "time": 38368.87175536156, "episode/length": 182.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 833296, "time": 38375.71646142006, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 833448, "time": 38382.11965203285, "episode/length": 201.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 833689, "time": 38392.6606798172, "train_stats/sum_log_reward": 9.257894937615646, "train_stats/max_log_achievement_collect_coal": 0.6210526315789474, "train_stats/max_log_achievement_collect_drink": 3.7473684210526317, "train_stats/max_log_achievement_collect_sapling": 1.6210526315789473, "train_stats/max_log_achievement_collect_stone": 12.031578947368422, "train_stats/max_log_achievement_collect_wood": 10.463157894736842, "train_stats/max_log_achievement_defeat_skeleton": 0.05263157894736842, "train_stats/max_log_achievement_defeat_zombie": 0.7894736842105263, "train_stats/max_log_achievement_eat_cow": 0.17894736842105263, "train_stats/max_log_achievement_make_stone_pickaxe": 0.010526315789473684, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2947368421052632, "train_stats/max_log_achievement_make_wood_sword": 1.063157894736842, "train_stats/max_log_achievement_place_furnace": 0.021052631578947368, "train_stats/max_log_achievement_place_plant": 1.5894736842105264, "train_stats/max_log_achievement_place_stone": 9.021052631578947, "train_stats/max_log_achievement_place_table": 2.768421052631579, "train_stats/max_log_achievement_wake_up": 1.431578947368421, "train_stats/mean_log_entropy": 0.6021239330894068, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.619131168849032, "train/action_min": 0.0, "train/action_std": 3.3413058922324383, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04014091149077449, "train/actor_opt_grad_steps": 51295.0, "train/actor_opt_loss": -5.491086579036152, "train/adv_mag": 0.5129315265467469, "train/adv_max": 0.4605055575219678, "train/adv_mean": 0.00337317682100496, "train/adv_min": -0.43195898809903105, "train/adv_std": 0.05688835971687042, "train/cont_avg": 0.9947664502640845, "train/cont_loss_mean": 0.0003370576365873155, "train/cont_loss_std": 0.010384002262785736, "train/cont_neg_acc": 0.9897132818128022, "train/cont_neg_loss": 0.030920564107629975, "train/cont_pos_acc": 0.9999723551978528, "train/cont_pos_loss": 0.0001299602845318599, "train/cont_pred": 0.9947783611190151, "train/cont_rate": 0.9947664502640845, "train/dyn_loss_mean": 13.460111228513046, "train/dyn_loss_std": 9.231637246172193, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9027728551710156, "train/extr_critic_critic_opt_grad_steps": 51295.0, "train/extr_critic_critic_opt_loss": 16045.784392880721, "train/extr_critic_mag": 8.283935157346054, "train/extr_critic_max": 8.283935157346054, "train/extr_critic_mean": 2.540540722054495, "train/extr_critic_min": -0.1906348038727129, "train/extr_critic_std": 1.924503938413002, "train/extr_return_normed_mag": 1.539122097928759, "train/extr_return_normed_max": 1.539122097928759, "train/extr_return_normed_mean": 0.3931715251274512, "train/extr_return_normed_min": -0.10832600977639077, "train/extr_return_normed_std": 0.3207956799109217, "train/extr_return_rate": 0.8519467518363201, "train/extr_return_raw_mag": 9.562930819014428, "train/extr_return_raw_max": 9.562930819014428, "train/extr_return_raw_mean": 2.5611164754545186, "train/extr_return_raw_min": -0.5028408898014418, "train/extr_return_raw_std": 1.9599739439050916, "train/extr_reward_mag": 1.0451562270312242, "train/extr_reward_max": 1.0451562270312242, "train/extr_reward_mean": 0.0483399784376084, "train/extr_reward_min": -0.4377189261812559, "train/extr_reward_std": 0.20575813571332205, "train/image_loss_mean": 6.247433450860037, "train/image_loss_std": 11.4654102963461, "train/model_loss_mean": 14.38319881869034, "train/model_loss_std": 15.257650549982635, "train/model_opt_grad_norm": 54.2764063821712, "train/model_opt_grad_steps": 51247.535211267605, "train/model_opt_loss": 18399.8867049956, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1276.4084507042253, "train/policy_entropy_mag": 2.4346141596915016, "train/policy_entropy_max": 2.4346141596915016, "train/policy_entropy_mean": 0.483711065540851, "train/policy_entropy_min": 0.07937501528313462, "train/policy_entropy_std": 0.5720857090093721, "train/policy_logprob_mag": 7.43838378073464, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.48413697325847516, "train/policy_logprob_min": -7.43838378073464, "train/policy_logprob_std": 1.0555526786287066, "train/policy_randomness_mag": 0.8593119596931297, "train/policy_randomness_max": 0.8593119596931297, "train/policy_randomness_mean": 0.17072878153601162, "train/policy_randomness_min": 0.028015897150190785, "train/policy_randomness_std": 0.20192115071793676, "train/post_ent_mag": 60.34050243001589, "train/post_ent_max": 60.34050243001589, "train/post_ent_mean": 42.887270940861235, "train/post_ent_min": 20.525532856793472, "train/post_ent_std": 7.646459287321064, "train/prior_ent_mag": 69.3594403334067, "train/prior_ent_max": 69.3594403334067, "train/prior_ent_mean": 56.40906570327114, "train/prior_ent_min": 40.22093356495172, "train/prior_ent_std": 4.523174512554222, "train/rep_loss_mean": 13.460111228513046, "train/rep_loss_std": 9.231637246172193, "train/reward_avg": 0.03172865309293421, "train/reward_loss_mean": 0.059361609144949576, "train/reward_loss_std": 0.2548843672577764, "train/reward_max_data": 1.017605638000327, "train/reward_max_pred": 1.010360643057756, "train/reward_neg_acc": 0.9920061087944139, "train/reward_neg_loss": 0.030452053875885378, "train/reward_pos_acc": 0.9714062377600603, "train/reward_pos_loss": 0.825895369472638, "train/reward_pred": 0.030922818155041044, "train/reward_rate": 0.03644916373239437, "eval_stats/sum_log_reward": 8.850000210106373, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 2.375, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_stone": 11.625, "eval_stats/max_log_achievement_collect_wood": 11.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.875, "eval_stats/max_log_achievement_place_stone": 8.75, "eval_stats/max_log_achievement_place_table": 2.75, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.9615478069899837e-06, "report/cont_loss_std": 7.108872523531318e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005960043054074049, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.162264216096446e-08, "report/cont_pred": 0.9951200485229492, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.577584266662598, "report/dyn_loss_std": 9.3489408493042, "report/image_loss_mean": 6.5321807861328125, "report/image_loss_std": 12.726739883422852, "report/model_loss_mean": 14.74893569946289, "report/model_loss_std": 16.638172149658203, "report/post_ent_mag": 62.53369903564453, "report/post_ent_max": 62.53369903564453, "report/post_ent_mean": 43.11265563964844, "report/post_ent_min": 20.91592788696289, "report/post_ent_std": 7.689090728759766, "report/prior_ent_mag": 69.5438003540039, "report/prior_ent_max": 69.5438003540039, "report/prior_ent_mean": 56.60371398925781, "report/prior_ent_min": 39.901573181152344, "report/prior_ent_std": 4.671595096588135, "report/rep_loss_mean": 13.577584266662598, "report/rep_loss_std": 9.3489408493042, "report/reward_avg": 0.03144531324505806, "report/reward_loss_mean": 0.07020112872123718, "report/reward_loss_std": 0.3878284692764282, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0001296997070312, "report/reward_neg_acc": 0.9888550639152527, "report/reward_neg_loss": 0.03601866960525513, "report/reward_pos_acc": 0.9729729294776917, "report/reward_pos_loss": 0.9820411801338196, "report/reward_pred": 0.031815845519304276, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.251462776963308e-06, "eval/cont_loss_std": 2.5076154997805133e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00021557885338552296, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.9980727472557192e-07, "eval/cont_pred": 0.9951180815696716, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.05607795715332, "eval/dyn_loss_std": 10.490861892700195, "eval/image_loss_mean": 12.10269546508789, "eval/image_loss_std": 16.716537475585938, "eval/model_loss_mean": 23.65234375, "eval/model_loss_std": 20.687023162841797, "eval/post_ent_mag": 59.043617248535156, "eval/post_ent_max": 59.043617248535156, "eval/post_ent_mean": 40.3928337097168, "eval/post_ent_min": 20.862789154052734, "eval/post_ent_std": 7.04628849029541, "eval/prior_ent_mag": 69.5438003540039, "eval/prior_ent_max": 69.5438003540039, "eval/prior_ent_mean": 56.50800323486328, "eval/prior_ent_min": 42.09390640258789, "eval/prior_ent_std": 4.078340530395508, "eval/rep_loss_mean": 19.05607795715332, "eval/rep_loss_std": 10.490861892700195, "eval/reward_avg": 0.04697265475988388, "eval/reward_loss_mean": 0.11600217968225479, "eval/reward_loss_std": 0.5383877158164978, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0008256435394287, "eval/reward_neg_acc": 0.9866117835044861, "eval/reward_neg_loss": 0.05071457475423813, "eval/reward_pos_acc": 0.8867924809455872, "eval/reward_pos_loss": 1.3121203184127808, "eval/reward_pred": 0.04205966368317604, "eval/reward_rate": 0.0517578125, "replay/size": 833185.0, "replay/inserts": 22800.0, "replay/samples": 22800.0, "replay/insert_wait_avg": 1.3584944239833898e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.374870869151333e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5304.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1754611318827036e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3705012798309, "timer/env.step_count": 2850.0, "timer/env.step_total": 231.84542274475098, "timer/env.step_frac": 0.23175955553281302, "timer/env.step_avg": 0.08134927113850911, "timer/env.step_min": 0.02231597900390625, "timer/env.step_max": 3.6022183895111084, "timer/replay._sample_count": 22800.0, "timer/replay._sample_total": 11.335455417633057, "timer/replay._sample_frac": 0.011331257172348608, "timer/replay._sample_avg": 0.0004971690972646077, "timer/replay._sample_min": 0.00041365623474121094, "timer/replay._sample_max": 0.03471255302429199, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3513.0, "timer/agent.policy_total": 55.976003885269165, "timer/agent.policy_frac": 0.05595527238523715, "timer/agent.policy_avg": 0.015933960684676677, "timer/agent.policy_min": 0.009256601333618164, "timer/agent.policy_max": 0.10282683372497559, "timer/dataset_train_count": 1425.0, "timer/dataset_train_total": 0.15058302879333496, "timer/dataset_train_frac": 0.00015052725825150334, "timer/dataset_train_avg": 0.00010567230090760348, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0010526180267333984, "timer/agent.train_count": 1425.0, "timer/agent.train_total": 642.449461221695, "timer/agent.train_frac": 0.6422115210312307, "timer/agent.train_avg": 0.45084172717311927, "timer/agent.train_min": 0.43827342987060547, "timer/agent.train_max": 1.685426950454712, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4749574661254883, "timer/agent.report_frac": 0.0004747815589502571, "timer/agent.report_avg": 0.23747873306274414, "timer/agent.report_min": 0.22989964485168457, "timer/agent.report_max": 0.2450578212738037, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.6931321349449055e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 22.791257099971208}
{"step": 833824, "time": 38397.28287267685, "episode/length": 203.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 834352, "time": 38416.79808998108, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 834384, "time": 38419.819769859314, "episode/length": 221.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 834408, "time": 38422.43680214882, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 835104, "time": 38447.430471897125, "episode/length": 245.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 835600, "time": 38466.74152755737, "episode/length": 287.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 835904, "time": 38478.43221831322, "episode/length": 193.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 835912, "time": 38479.94916033745, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 835952, "time": 38483.13480401039, "episode/length": 265.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 836224, "time": 38493.64873600006, "episode/length": 39.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.925, "episode/intrinsic_return": 0.0}
{"step": 836624, "time": 38508.38340520859, "episode/length": 396.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9924433249370277, "episode/intrinsic_return": 0.0}
{"step": 836760, "time": 38514.180173158646, "episode/length": 206.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 837488, "time": 38540.28540062904, "episode/length": 619.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9854838709677419, "episode/intrinsic_return": 0.0}
{"step": 837616, "time": 38546.195558309555, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 837640, "time": 38548.44275069237, "episode/length": 176.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 837992, "time": 38561.69484782219, "episode/length": 447.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9799107142857143, "episode/intrinsic_return": 0.0}
{"step": 838376, "time": 38577.06926345825, "episode/length": 110.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 838584, "time": 38586.14462518692, "episode/length": 244.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 838800, "time": 38595.67400598526, "episode/length": 254.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 839208, "time": 38610.57248711586, "episode/length": 406.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975429975429976, "episode/intrinsic_return": 0.0}
{"step": 839248, "time": 38613.649970293045, "episode/length": 156.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 839576, "time": 38625.7470266819, "episode/length": 496.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9879275653923542, "episode/intrinsic_return": 0.0}
{"step": 839664, "time": 38630.454312086105, "episode/length": 160.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 839704, "time": 38633.11766076088, "episode/length": 260.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 38666.735216856, "eval_episode/length": 177.0, "eval_episode/score": 9.100000031292439, "eval_episode/reward_rate": 0.9550561797752809}
{"step": 840008, "time": 38668.29641008377, "eval_episode/length": 178.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.994413407821229}
{"step": 840008, "time": 38668.30457830429, "eval_episode/length": 178.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 840008, "time": 38672.25780248642, "eval_episode/length": 192.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 840008, "time": 38673.88262605667, "eval_episode/length": 193.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 840008, "time": 38676.72449684143, "eval_episode/length": 222.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 840008, "time": 38678.61514258385, "eval_episode/length": 231.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 840008, "time": 38682.240829229355, "eval_episode/length": 282.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9717314487632509}
{"step": 840576, "time": 38701.26318049431, "episode/length": 221.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 840592, "time": 38703.2816696167, "episode/length": 368.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.994579945799458, "episode/intrinsic_return": 0.0}
{"step": 840664, "time": 38707.0098426342, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 840704, "time": 38710.176008701324, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 841120, "time": 38725.42445707321, "episode/length": 176.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 841232, "time": 38730.840254068375, "episode/length": 330.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9848942598187311, "episode/intrinsic_return": 0.0}
{"step": 841664, "time": 38747.545857429504, "episode/length": 260.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 842232, "time": 38769.01677823067, "episode/length": 204.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 842424, "time": 38777.80864691734, "episode/length": 162.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 842672, "time": 38788.03768324852, "episode/length": 375.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 842712, "time": 38790.59981799126, "episode/length": 250.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 842880, "time": 38797.91732263565, "episode/length": 151.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 843128, "time": 38807.52581810951, "episode/length": 236.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 843232, "time": 38812.640533447266, "episode/length": 320.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 843752, "time": 38831.08112668991, "episode/length": 189.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 843944, "time": 38840.64969968796, "episode/length": 420.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9928741092636579, "episode/intrinsic_return": 0.0}
{"step": 844600, "time": 38863.960729599, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 844608, "time": 38866.0357542038, "episode/length": 171.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 844864, "time": 38876.0667450428, "episode/length": 304.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 844984, "time": 38881.49433159828, "episode/length": 288.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9757785467128027, "episode/intrinsic_return": 0.0}
{"step": 845040, "time": 38885.09896397591, "episode/length": 238.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 845280, "time": 38894.79568529129, "episode/length": 320.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9844236760124611, "episode/intrinsic_return": 0.0}
{"step": 845800, "time": 38913.80048942566, "episode/length": 231.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 845864, "time": 38917.320645570755, "episode/length": 263.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 845896, "time": 38919.924162864685, "episode/length": 161.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 845928, "time": 38922.46772003174, "episode/length": 164.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 846304, "time": 38936.54696583748, "episode/length": 164.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 846712, "time": 38951.19907236099, "episode/length": 208.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 846888, "time": 38958.68565893173, "episode/length": 200.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 847232, "time": 38972.675300359726, "episode/length": 166.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 847464, "time": 38981.7361600399, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 847536, "time": 38985.79162478447, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 847776, "time": 38995.22849178314, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 847840, "time": 38999.6204726696, "episode/length": 371.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9973118279569892, "episode/intrinsic_return": 0.0}
{"step": 848064, "time": 39009.13921380043, "episode/length": 74.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 848368, "time": 39020.60300445557, "episode/length": 141.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 848672, "time": 39032.34543991089, "episode/length": 350.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9857549857549858, "episode/intrinsic_return": 0.0}
{"step": 848752, "time": 39037.16463088989, "episode/length": 151.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 849024, "time": 39048.44744133949, "episode/length": 266.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 849432, "time": 39063.877734422684, "episode/length": 198.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 849456, "time": 39066.50241589546, "episode/length": 173.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 850048, "time": 39087.76520752907, "episode/length": 209.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 39111.094640016556, "eval_episode/length": 191.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 850096, "time": 39112.99666786194, "eval_episode/length": 197.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 850096, "time": 39115.387417793274, "eval_episode/length": 216.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 850096, "time": 39117.345289468765, "eval_episode/length": 224.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 850096, "time": 39120.01891207695, "eval_episode/length": 52.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 850096, "time": 39121.66416025162, "eval_episode/length": 252.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9723320158102767}
{"step": 850096, "time": 39124.12366652489, "eval_episode/length": 271.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9779411764705882}
{"step": 850096, "time": 39126.13649892807, "eval_episode/length": 282.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9823321554770318}
{"step": 850104, "time": 39126.19296383858, "episode/length": 423.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787735849056604, "episode/intrinsic_return": 0.0}
{"step": 850184, "time": 39130.35832953453, "episode/length": 178.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 850208, "time": 39132.8416121006, "episode/length": 303.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 850952, "time": 39158.742159843445, "episode/length": 189.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 851224, "time": 39169.271132707596, "episode/length": 318.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 851680, "time": 39186.26907444, "episode/length": 183.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 851824, "time": 39192.65143275261, "episode/length": 221.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 851864, "time": 39195.36225652695, "episode/length": 354.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9943661971830986, "episode/intrinsic_return": 0.0}
{"step": 851944, "time": 39199.58745288849, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 852272, "time": 39213.937977552414, "episode/length": 351.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9829545454545454, "episode/intrinsic_return": 0.0}
{"step": 852480, "time": 39223.037653923035, "episode/length": 66.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 852680, "time": 39231.5934920311, "episode/length": 215.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 852696, "time": 39234.192897081375, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 853048, "time": 39247.94539952278, "episode/length": 152.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 853576, "time": 39267.1383895874, "episode/length": 433.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 853696, "time": 39272.864025592804, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 853776, "time": 39277.06014466286, "episode/length": 134.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 854824, "time": 39313.084421396255, "episode/length": 267.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 854872, "time": 39316.30798625946, "episode/length": 227.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 854960, "time": 39321.01750588417, "episode/length": 409.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9975609756097561, "episode/intrinsic_return": 0.0}
{"step": 855008, "time": 39324.235100507736, "episode/length": 163.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 855208, "time": 39332.30350804329, "episode/length": 203.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 855408, "time": 39341.2072327137, "episode/length": 55.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 855496, "time": 39345.99374103546, "episode/length": 376.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9814323607427056, "episode/intrinsic_return": 0.0}
{"step": 855512, "time": 39348.02017903328, "episode/length": 216.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 855848, "time": 39362.838057518005, "episode/length": 127.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 856056, "time": 39371.27214074135, "episode/length": 80.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 856264, "time": 39379.75314164162, "episode/length": 549.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9927272727272727, "episode/intrinsic_return": 0.0}
{"step": 856585, "time": 39392.971189022064, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.420044793023004, "train/action_min": 0.0, "train/action_std": 3.167033068007893, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039392322081969015, "train/actor_opt_grad_steps": 52725.0, "train/actor_opt_loss": -9.01314678022431, "train/adv_mag": 0.49485361493296093, "train/adv_max": 0.4406540286209848, "train/adv_mean": 0.0026948361460578476, "train/adv_min": -0.40677395318117404, "train/adv_std": 0.055832286106629506, "train/cont_avg": 0.9946967230902778, "train/cont_loss_mean": 0.00022097610444612079, "train/cont_loss_std": 0.0061974054629164105, "train/cont_neg_acc": 0.9918595680760013, "train/cont_neg_loss": 0.029141809212711048, "train/cont_pos_acc": 0.9999795138008065, "train/cont_pos_loss": 8.306295401763443e-05, "train/cont_pred": 0.9946974342068037, "train/cont_rate": 0.9946967230902778, "train/dyn_loss_mean": 13.314649615022871, "train/dyn_loss_std": 9.193033013078901, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8537969502309958, "train/extr_critic_critic_opt_grad_steps": 52725.0, "train/extr_critic_critic_opt_loss": 15883.630296495227, "train/extr_critic_mag": 8.460600488715702, "train/extr_critic_max": 8.460600488715702, "train/extr_critic_mean": 2.6548221392763987, "train/extr_critic_min": -0.19173245877027512, "train/extr_critic_std": 1.9958615038130019, "train/extr_return_normed_mag": 1.5417586382892396, "train/extr_return_normed_max": 1.5417586382892396, "train/extr_return_normed_mean": 0.4075805686621202, "train/extr_return_normed_min": -0.10412099287431273, "train/extr_return_normed_std": 0.32546098706209, "train/extr_return_rate": 0.8407340029047595, "train/extr_return_raw_mag": 9.729850550492605, "train/extr_return_raw_max": 9.729850550492605, "train/extr_return_raw_mean": 2.6715973483191595, "train/extr_return_raw_min": -0.5126984020074209, "train/extr_return_raw_std": 2.0257311653759746, "train/extr_reward_mag": 1.0539353556103177, "train/extr_reward_max": 1.0539353556103177, "train/extr_reward_mean": 0.050667509721178144, "train/extr_reward_min": -0.4185727636019389, "train/extr_reward_std": 0.2106209003056089, "train/image_loss_mean": 5.976555549436146, "train/image_loss_std": 10.869112011459139, "train/model_loss_mean": 14.025122119320763, "train/model_loss_std": 14.652460873126984, "train/model_opt_grad_norm": 51.87489406267802, "train/model_opt_grad_steps": 52676.256944444445, "train/model_opt_loss": 18414.658820258246, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1310.763888888889, "train/policy_entropy_mag": 2.470546235640844, "train/policy_entropy_max": 2.470546235640844, "train/policy_entropy_mean": 0.46968845195240444, "train/policy_entropy_min": 0.07937501572693388, "train/policy_entropy_std": 0.5788662460529141, "train/policy_logprob_mag": 7.438383804427253, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.46795713901519775, "train/policy_logprob_min": -7.438383804427253, "train/policy_logprob_std": 1.0413711530466874, "train/policy_randomness_mag": 0.8719944022595882, "train/policy_randomness_max": 0.8719944022595882, "train/policy_randomness_mean": 0.16577941132709384, "train/policy_randomness_min": 0.028015897285917565, "train/policy_randomness_std": 0.20431438233289453, "train/post_ent_mag": 60.29944162898593, "train/post_ent_max": 60.29944162898593, "train/post_ent_mean": 42.99470827314589, "train/post_ent_min": 20.164279500643413, "train/post_ent_std": 7.661827418539259, "train/prior_ent_mag": 69.55330589082506, "train/prior_ent_max": 69.55330589082506, "train/prior_ent_mean": 56.39819365077548, "train/prior_ent_min": 40.444326639175415, "train/prior_ent_std": 4.465721040964127, "train/rep_loss_mean": 13.314649615022871, "train/rep_loss_std": 9.193033013078901, "train/reward_avg": 0.03330010291473526, "train/reward_loss_mean": 0.05955580107143356, "train/reward_loss_std": 0.25186793764846194, "train/reward_max_data": 1.0131944475902452, "train/reward_max_pred": 1.011827427479956, "train/reward_neg_acc": 0.9922239246467749, "train/reward_neg_loss": 0.02932264078925881, "train/reward_pos_acc": 0.9732512616448932, "train/reward_pos_loss": 0.8227656483650208, "train/reward_pred": 0.03236135026155454, "train/reward_rate": 0.038045247395833336, "train_stats/sum_log_reward": 9.153191740208484, "train_stats/max_log_achievement_collect_coal": 0.6914893617021277, "train_stats/max_log_achievement_collect_drink": 5.585106382978723, "train_stats/max_log_achievement_collect_sapling": 1.446808510638298, "train_stats/max_log_achievement_collect_stone": 12.319148936170214, "train_stats/max_log_achievement_collect_wood": 10.712765957446809, "train_stats/max_log_achievement_defeat_skeleton": 0.11702127659574468, "train_stats/max_log_achievement_defeat_zombie": 0.8936170212765957, "train_stats/max_log_achievement_eat_cow": 0.11702127659574468, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5, "train_stats/max_log_achievement_make_wood_sword": 1.127659574468085, "train_stats/max_log_achievement_place_furnace": 0.010638297872340425, "train_stats/max_log_achievement_place_plant": 1.3936170212765957, "train_stats/max_log_achievement_place_stone": 9.361702127659575, "train_stats/max_log_achievement_place_table": 2.9893617021276597, "train_stats/max_log_achievement_wake_up": 1.6914893617021276, "train_stats/mean_log_entropy": 0.5797176592527552, "eval_stats/sum_log_reward": 9.600000232458115, "eval_stats/max_log_achievement_collect_coal": 0.4375, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_sapling": 1.6875, "eval_stats/max_log_achievement_collect_stone": 12.25, "eval_stats/max_log_achievement_collect_wood": 10.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.3125, "eval_stats/max_log_achievement_eat_cow": 0.4375, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_stone": 9.1875, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.0006265416159294546, "report/cont_loss_std": 0.0160362645983696, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.022754844278097153, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0004961194936186075, "report/cont_pred": 0.9938821792602539, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.27152156829834, "report/dyn_loss_std": 9.410327911376953, "report/image_loss_mean": 6.993267059326172, "report/image_loss_std": 12.051091194152832, "report/model_loss_mean": 15.038675308227539, "report/model_loss_std": 15.904550552368164, "report/post_ent_mag": 62.687644958496094, "report/post_ent_max": 62.687644958496094, "report/post_ent_mean": 43.33134460449219, "report/post_ent_min": 17.429603576660156, "report/post_ent_std": 8.25660514831543, "report/prior_ent_mag": 69.15083312988281, "report/prior_ent_max": 69.15083312988281, "report/prior_ent_mean": 56.8890380859375, "report/prior_ent_min": 43.56270980834961, "report/prior_ent_std": 4.637415885925293, "report/rep_loss_mean": 13.27152156829834, "report/rep_loss_std": 9.410327911376953, "report/reward_avg": 0.04169921576976776, "report/reward_loss_mean": 0.08186820149421692, "report/reward_loss_std": 0.3281930685043335, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011720657348633, "report/reward_neg_acc": 0.9856557846069336, "report/reward_neg_loss": 0.04233356565237045, "report/reward_pos_acc": 0.9375, "report/reward_pos_loss": 0.8857393264770508, "report/reward_pred": 0.039846185594797134, "report/reward_rate": 0.046875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 2.1903413653490134e-05, "eval/cont_loss_std": 0.00035037301131524146, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0037166147958487272, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2712024499705876e-07, "eval/cont_pred": 0.9941622614860535, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 18.461074829101562, "eval/dyn_loss_std": 10.721627235412598, "eval/image_loss_mean": 9.817438125610352, "eval/image_loss_std": 10.57097053527832, "eval/model_loss_mean": 20.995018005371094, "eval/model_loss_std": 14.725055694580078, "eval/post_ent_mag": 60.632774353027344, "eval/post_ent_max": 60.632774353027344, "eval/post_ent_mean": 40.83625030517578, "eval/post_ent_min": 20.05120086669922, "eval/post_ent_std": 7.868496417999268, "eval/prior_ent_mag": 69.15083312988281, "eval/prior_ent_max": 69.15083312988281, "eval/prior_ent_mean": 57.147220611572266, "eval/prior_ent_min": 42.00697708129883, "eval/prior_ent_std": 4.369658470153809, "eval/rep_loss_mean": 18.461074829101562, "eval/rep_loss_std": 10.721627235412598, "eval/reward_avg": 0.03115234337747097, "eval/reward_loss_mean": 0.10091380774974823, "eval/reward_loss_std": 0.5472511053085327, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0002567768096924, "eval/reward_neg_acc": 0.9868286848068237, "eval/reward_neg_loss": 0.05165630951523781, "eval/reward_pos_acc": 0.8648648262023926, "eval/reward_pos_loss": 1.4148908853530884, "eval/reward_pred": 0.027500007301568985, "eval/reward_rate": 0.0361328125, "replay/size": 856081.0, "replay/inserts": 22896.0, "replay/samples": 22896.0, "replay/insert_wait_avg": 1.3638050884404105e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.368392160603585e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4528.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1830890136556996e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2931518554688, "timer/env.step_count": 2862.0, "timer/env.step_total": 232.8815734386444, "timer/env.step_frac": 0.23281332378080022, "timer/env.step_avg": 0.08137022132726919, "timer/env.step_min": 0.0223844051361084, "timer/env.step_max": 2.232607841491699, "timer/replay._sample_count": 22896.0, "timer/replay._sample_total": 11.279516220092773, "timer/replay._sample_frac": 0.011276210578039165, "timer/replay._sample_avg": 0.0004926413443436746, "timer/replay._sample_min": 0.0003688335418701172, "timer/replay._sample_max": 0.010622024536132812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3428.0, "timer/agent.policy_total": 56.11594915390015, "timer/agent.policy_frac": 0.056099503480364, "timer/agent.policy_avg": 0.016369880149912527, "timer/agent.policy_min": 0.009236335754394531, "timer/agent.policy_max": 0.10666012763977051, "timer/dataset_train_count": 1431.0, "timer/dataset_train_total": 0.15109729766845703, "timer/dataset_train_frac": 0.0001510530161964849, "timer/dataset_train_avg": 0.00010558860773477081, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0009138584136962891, "timer/agent.train_count": 1431.0, "timer/agent.train_total": 643.8019709587097, "timer/agent.train_frac": 0.6436132945272147, "timer/agent.train_avg": 0.44989655552670144, "timer/agent.train_min": 0.43343377113342285, "timer/agent.train_max": 2.4668469429016113, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4714012145996094, "timer/agent.report_frac": 0.0004712630629582893, "timer/agent.report_avg": 0.2357006072998047, "timer/agent.report_min": 0.22887420654296875, "timer/agent.report_max": 0.24252700805664062, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9793588341991786e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 22.888959541099407}
{"step": 856880, "time": 39402.80707836151, "episode/length": 250.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 857240, "time": 39416.09020066261, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 857384, "time": 39422.45920753479, "episode/length": 233.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9700854700854701, "episode/intrinsic_return": 0.0}
{"step": 857504, "time": 39428.27664256096, "episode/length": 206.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 857544, "time": 39430.99368929863, "episode/length": 316.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 857608, "time": 39434.58513426781, "episode/length": 299.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 857720, "time": 39439.95549917221, "episode/length": 207.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 857888, "time": 39447.40582561493, "episode/length": 202.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 858192, "time": 39458.92273044586, "episode/length": 163.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.0}
{"step": 858232, "time": 39461.57306241989, "episode/length": 77.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9358974358974359, "episode/intrinsic_return": 0.0}
{"step": 858872, "time": 39484.320392131805, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 858872, "time": 39484.32839226723, "episode/length": 84.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 859256, "time": 39500.316440820694, "episode/length": 191.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 859448, "time": 39508.4567592144, "episode/length": 71.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 859648, "time": 39516.98303222656, "episode/length": 219.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 859776, "time": 39522.9708943367, "episode/length": 283.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9753521126760564, "episode/intrinsic_return": 0.0}
{"step": 859856, "time": 39527.82815337181, "episode/length": 202.0, "episode/score": 13.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 860072, "time": 39536.95824980736, "episode/length": 335.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 39562.60434985161, "eval_episode/length": 153.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 860080, "time": 39565.09448552132, "eval_episode/length": 175.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 860080, "time": 39567.34006166458, "eval_episode/length": 189.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 860080, "time": 39569.33656692505, "eval_episode/length": 200.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 860080, "time": 39571.57867407799, "eval_episode/length": 216.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 860080, "time": 39573.41344475746, "eval_episode/length": 222.0, "eval_episode/score": 11.100000031292439, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 860080, "time": 39575.81981420517, "eval_episode/length": 243.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9713114754098361}
{"step": 860080, "time": 39579.44435739517, "eval_episode/length": 288.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9826989619377162}
{"step": 860408, "time": 39591.91421484947, "episode/length": 357.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9972067039106145, "episode/intrinsic_return": 0.0}
{"step": 860688, "time": 39602.987276792526, "episode/length": 226.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 860800, "time": 39608.29556584358, "episode/length": 192.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9844559585492227, "episode/intrinsic_return": 0.0}
{"step": 861736, "time": 39640.84262418747, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 862040, "time": 39652.3620493412, "episode/length": 323.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 862064, "time": 39654.93592596054, "episode/length": 285.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 862480, "time": 39670.49774026871, "episode/length": 300.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 862488, "time": 39672.12609744072, "episode/length": 224.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 862496, "time": 39674.225848674774, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 862544, "time": 39677.336849451065, "episode/length": 335.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 862592, "time": 39680.46969795227, "episode/length": 367.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 863120, "time": 39699.542639017105, "episode/length": 131.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 863240, "time": 39705.442571401596, "episode/length": 149.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 863344, "time": 39711.08724999428, "episode/length": 200.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 863784, "time": 39727.70628905296, "episode/length": 162.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 864032, "time": 39737.87371110916, "episode/length": 191.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 864216, "time": 39745.968838214874, "episode/length": 208.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 864336, "time": 39751.74214863777, "episode/length": 68.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9420289855072463, "episode/intrinsic_return": 0.0}
{"step": 864608, "time": 39762.40470147133, "episode/length": 264.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 864720, "time": 39767.61932396889, "episode/length": 199.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 864984, "time": 39777.78786301613, "episode/length": 217.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 865048, "time": 39781.43413448334, "episode/length": 212.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 865168, "time": 39787.242878198624, "episode/length": 321.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9968944099378882, "episode/intrinsic_return": 0.0}
{"step": 865440, "time": 39798.478296756744, "episode/length": 137.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 865512, "time": 39802.80753803253, "episode/length": 161.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 866368, "time": 39833.56535887718, "episode/length": 205.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 866616, "time": 39843.24791288376, "episode/length": 195.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 866760, "time": 39849.56276798248, "episode/length": 164.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 866840, "time": 39853.757148981094, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 866984, "time": 39860.127467632294, "episode/length": 296.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 867208, "time": 39869.90013694763, "episode/length": 211.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 867304, "time": 39875.18939566612, "episode/length": 408.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9975550122249389, "episode/intrinsic_return": 0.0}
{"step": 867616, "time": 39887.919098854065, "episode/length": 50.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9215686274509803, "episode/intrinsic_return": 0.0}
{"step": 867824, "time": 39897.034126996994, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 868272, "time": 39913.36728525162, "episode/length": 188.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 868456, "time": 39922.514552116394, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 868864, "time": 39938.756898641586, "episode/length": 484.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9979381443298969, "episode/intrinsic_return": 0.0}
{"step": 868992, "time": 39945.15923690796, "episode/length": 296.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 869200, "time": 39954.16363310814, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 869760, "time": 39974.49166607857, "episode/length": 346.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9884726224783862, "episode/intrinsic_return": 0.0}
{"step": 869920, "time": 39981.98371171951, "episode/length": 261.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 869992, "time": 39986.3666036129, "episode/length": 140.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 40017.16674160957, "eval_episode/length": 199.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.995}
{"step": 870064, "time": 40020.28285241127, "eval_episode/length": 220.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9683257918552036}
{"step": 870064, "time": 40022.59061932564, "eval_episode/length": 225.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.995575221238938}
{"step": 870064, "time": 40026.79790830612, "eval_episode/length": 244.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 870064, "time": 40030.16893148422, "eval_episode/length": 256.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9961089494163424}
{"step": 870064, "time": 40034.56185436249, "eval_episode/length": 306.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9804560260586319}
{"step": 870064, "time": 40037.70628666878, "eval_episode/length": 332.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.987987987987988}
{"step": 870064, "time": 40040.46533560753, "eval_episode/length": 347.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9885057471264368}
{"step": 870208, "time": 40045.406339883804, "episode/length": 151.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 870312, "time": 40050.79661989212, "episode/length": 375.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 870504, "time": 40059.42224431038, "episode/length": 36.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.918918918918919, "episode/intrinsic_return": 0.0}
{"step": 870872, "time": 40074.00029158592, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 871280, "time": 40090.283857584, "episode/length": 169.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 871656, "time": 40103.892035484314, "episode/length": 399.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9725, "episode/intrinsic_return": 0.0}
{"step": 871688, "time": 40106.61576581001, "episode/length": 426.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 871800, "time": 40111.82469654083, "episode/length": 254.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 872432, "time": 40134.52785229683, "episode/length": 304.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 872728, "time": 40145.71047949791, "episode/length": 277.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 873016, "time": 40156.81675243378, "episode/length": 169.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 873048, "time": 40159.44035577774, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 873152, "time": 40164.659526348114, "episode/length": 233.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 873568, "time": 40180.03477549553, "episode/length": 64.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 873576, "time": 40181.64459991455, "episode/length": 407.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 873904, "time": 40194.1820333004, "episode/length": 183.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 874240, "time": 40206.8841252327, "episode/length": 304.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770491803278688, "episode/intrinsic_return": 0.0}
{"step": 874352, "time": 40212.21742725372, "episode/length": 202.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 874616, "time": 40222.205305576324, "episode/length": 365.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 874968, "time": 40235.871760845184, "episode/length": 173.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 875160, "time": 40243.72505760193, "episode/length": 198.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 875256, "time": 40248.40956926346, "episode/length": 126.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 875800, "time": 40267.9634847641, "episode/length": 330.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9909365558912386, "episode/intrinsic_return": 0.0}
{"step": 875880, "time": 40272.068303346634, "episode/length": 246.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 875904, "time": 40274.671295404434, "episode/length": 360.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.997229916897507, "episode/intrinsic_return": 0.0}
{"step": 876304, "time": 40289.52191758156, "episode/length": 243.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 876336, "time": 40292.06472206116, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 876400, "time": 40295.69636154175, "episode/length": 222.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 876488, "time": 40299.92807555199, "episode/length": 165.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 876528, "time": 40303.02078151703, "episode/length": 158.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 877400, "time": 40334.7636346817, "episode/length": 132.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 877640, "time": 40344.25937819481, "episode/length": 229.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 877720, "time": 40348.65611958504, "episode/length": 229.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 877928, "time": 40357.090096235275, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 878120, "time": 40364.934603214264, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 878408, "time": 40375.88642144203, "episode/length": 234.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 878624, "time": 40384.918155670166, "episode/length": 289.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 878720, "time": 40389.668701171875, "episode/length": 351.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 878761, "time": 40393.35981583595, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.5400381779325185, "train/action_min": 0.0, "train/action_std": 3.3246079873347627, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03889376290844403, "train/actor_opt_grad_steps": 54135.0, "train/actor_opt_loss": -7.168278759804325, "train/adv_mag": 0.46649533596591675, "train/adv_max": 0.42376764485801477, "train/adv_mean": 0.0027462836663197368, "train/adv_min": -0.39382750692142954, "train/adv_std": 0.05467934452969095, "train/cont_avg": 0.9949756567028986, "train/cont_loss_mean": 0.0001312236966916697, "train/cont_loss_std": 0.003822418192151193, "train/cont_neg_acc": 0.9946993406671677, "train/cont_neg_loss": 0.01659105161550967, "train/cont_pos_acc": 0.9999857683112656, "train/cont_pos_loss": 4.8485059249799797e-05, "train/cont_pred": 0.9949854707372361, "train/cont_rate": 0.9949756567028986, "train/dyn_loss_mean": 13.076370978700941, "train/dyn_loss_std": 9.16015819190205, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8622453916763914, "train/extr_critic_critic_opt_grad_steps": 54135.0, "train/extr_critic_critic_opt_loss": 15893.438872848732, "train/extr_critic_mag": 8.518744575804558, "train/extr_critic_max": 8.518744575804558, "train/extr_critic_mean": 2.6232956423275713, "train/extr_critic_min": -0.19171412008396094, "train/extr_critic_std": 2.023738925871642, "train/extr_return_normed_mag": 1.5331995400829592, "train/extr_return_normed_max": 1.5331995400829592, "train/extr_return_normed_mean": 0.3999885469675064, "train/extr_return_normed_min": -0.1024512394560852, "train/extr_return_normed_std": 0.3263839299696079, "train/extr_return_rate": 0.8188844979673192, "train/extr_return_raw_mag": 9.782383455746416, "train/extr_return_raw_max": 9.782383455746416, "train/extr_return_raw_mean": 2.640566831049712, "train/extr_return_raw_min": -0.5249271508360255, "train/extr_return_raw_std": 2.0566931194153386, "train/extr_reward_mag": 1.0485076731529788, "train/extr_reward_max": 1.0485076731529788, "train/extr_reward_mean": 0.051087606374336327, "train/extr_reward_min": -0.42715889388236444, "train/extr_reward_std": 0.2115160001144893, "train/image_loss_mean": 5.956758582073709, "train/image_loss_std": 11.220290989115618, "train/model_loss_mean": 13.859625567560611, "train/model_loss_std": 14.965242406596309, "train/model_opt_grad_norm": 51.83757582894207, "train/model_opt_grad_steps": 54084.717391304344, "train/model_opt_loss": 17689.277442821556, "train/model_opt_model_opt_grad_overflow": 0.007246376811594203, "train/model_opt_model_opt_grad_scale": 1268.1159420289855, "train/policy_entropy_mag": 2.4848537514175195, "train/policy_entropy_max": 2.4848537514175195, "train/policy_entropy_mean": 0.49059194909489673, "train/policy_entropy_min": 0.07937501565269801, "train/policy_entropy_std": 0.6133813702541849, "train/policy_logprob_mag": 7.438383872958197, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4911514673975931, "train/policy_logprob_min": -7.438383872958197, "train/policy_logprob_std": 1.059976980738018, "train/policy_randomness_mag": 0.8770443309044492, "train/policy_randomness_max": 0.8770443309044492, "train/policy_randomness_mean": 0.17315742978151294, "train/policy_randomness_min": 0.028015897285355175, "train/policy_randomness_std": 0.21649670698072598, "train/post_ent_mag": 60.499182245005734, "train/post_ent_max": 60.499182245005734, "train/post_ent_mean": 43.17290615689927, "train/post_ent_min": 20.324500457100246, "train/post_ent_std": 7.688594244528508, "train/prior_ent_mag": 69.53311721138333, "train/prior_ent_max": 69.53311721138333, "train/prior_ent_mean": 56.346250395843946, "train/prior_ent_min": 40.52713712056478, "train/prior_ent_std": 4.493901638017184, "train/rep_loss_mean": 13.076370978700941, "train/rep_loss_std": 9.16015819190205, "train/reward_avg": 0.03328308958452249, "train/reward_loss_mean": 0.05691331843643085, "train/reward_loss_std": 0.23648919456678888, "train/reward_max_data": 1.0137681192246035, "train/reward_max_pred": 1.0126646377038264, "train/reward_neg_acc": 0.9923467303531758, "train/reward_neg_loss": 0.028226348767192034, "train/reward_pos_acc": 0.979001947503159, "train/reward_pos_loss": 0.7904982765515646, "train/reward_pred": 0.03280798740604002, "train/reward_rate": 0.03775334012681159, "train_stats/sum_log_reward": 9.477551263205859, "train_stats/max_log_achievement_collect_coal": 0.6122448979591837, "train_stats/max_log_achievement_collect_drink": 5.122448979591836, "train_stats/max_log_achievement_collect_sapling": 1.2857142857142858, "train_stats/max_log_achievement_collect_stone": 13.173469387755102, "train_stats/max_log_achievement_collect_wood": 10.346938775510203, "train_stats/max_log_achievement_defeat_skeleton": 0.10204081632653061, "train_stats/max_log_achievement_defeat_zombie": 0.9693877551020408, "train_stats/max_log_achievement_eat_cow": 0.19387755102040816, "train_stats/max_log_achievement_make_stone_pickaxe": 0.01020408163265306, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4795918367346939, "train_stats/max_log_achievement_make_wood_sword": 1.0204081632653061, "train_stats/max_log_achievement_place_furnace": 0.030612244897959183, "train_stats/max_log_achievement_place_plant": 1.2755102040816326, "train_stats/max_log_achievement_place_stone": 10.071428571428571, "train_stats/max_log_achievement_place_table": 2.683673469387755, "train_stats/max_log_achievement_wake_up": 1.683673469387755, "train_stats/mean_log_entropy": 0.582364880764971, "train_stats/max_log_achievement_collect_iron": 0.012195121951219513, "eval_stats/sum_log_reward": 10.100000321865082, "eval_stats/max_log_achievement_collect_coal": 0.5625, "eval_stats/max_log_achievement_collect_drink": 4.5, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 12.1875, "eval_stats/max_log_achievement_collect_wood": 11.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 10.4375, "eval_stats/max_log_achievement_place_table": 3.0, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.1283650565019343e-06, "report/cont_loss_std": 2.0709861928480677e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.215185643057339e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0372087899668259e-06, "report/cont_pred": 0.9970694780349731, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.930864334106445, "report/dyn_loss_std": 9.638179779052734, "report/image_loss_mean": 6.184855937957764, "report/image_loss_std": 10.437566757202148, "report/model_loss_mean": 13.98620319366455, "report/model_loss_std": 14.497631072998047, "report/post_ent_mag": 61.587669372558594, "report/post_ent_max": 61.587669372558594, "report/post_ent_mean": 44.352783203125, "report/post_ent_min": 17.89107894897461, "report/post_ent_std": 8.548724174499512, "report/prior_ent_mag": 69.6170883178711, "report/prior_ent_max": 69.6170883178711, "report/prior_ent_mean": 57.9107666015625, "report/prior_ent_min": 41.037986755371094, "report/prior_ent_std": 4.165194511413574, "report/rep_loss_mean": 12.930864334106445, "report/rep_loss_std": 9.638179779052734, "report/reward_avg": 0.02265625074505806, "report/reward_loss_mean": 0.04282720014452934, "report/reward_loss_std": 0.16806916892528534, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0022921562194824, "report/reward_neg_acc": 0.9959879517555237, "report/reward_neg_loss": 0.02308538928627968, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7718117833137512, "report/reward_pred": 0.021200578659772873, "report/reward_rate": 0.0263671875, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 2.607924898256897e-06, "eval/cont_loss_std": 8.134837116813287e-05, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.607924898256897e-06, "eval/cont_pred": 0.9999974966049194, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 18.949920654296875, "eval/dyn_loss_std": 10.830334663391113, "eval/image_loss_mean": 9.985980987548828, "eval/image_loss_std": 13.207463264465332, "eval/model_loss_mean": 21.485488891601562, "eval/model_loss_std": 17.560131072998047, "eval/post_ent_mag": 57.20263671875, "eval/post_ent_max": 57.20263671875, "eval/post_ent_mean": 39.70817184448242, "eval/post_ent_min": 20.763534545898438, "eval/post_ent_std": 7.463072299957275, "eval/prior_ent_mag": 69.6170883178711, "eval/prior_ent_max": 69.6170883178711, "eval/prior_ent_mean": 56.70831298828125, "eval/prior_ent_min": 43.73366928100586, "eval/prior_ent_std": 4.0112080574035645, "eval/rep_loss_mean": 18.949920654296875, "eval/rep_loss_std": 10.830334663391113, "eval/reward_avg": 0.0458984375, "eval/reward_loss_mean": 0.12955141067504883, "eval/reward_loss_std": 0.8133774399757385, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0039613246917725, "eval/reward_neg_acc": 0.9958974123001099, "eval/reward_neg_loss": 0.035977404564619064, "eval/reward_pos_acc": 0.795918345451355, "eval/reward_pos_loss": 1.9914830923080444, "eval/reward_pred": 0.03654184937477112, "eval/reward_rate": 0.0478515625, "replay/size": 878257.0, "replay/inserts": 22176.0, "replay/samples": 22176.0, "replay/insert_wait_avg": 1.3815505164010183e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.375398696415008e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5096.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2583410721184508e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3792641162872, "timer/env.step_count": 2772.0, "timer/env.step_total": 240.25473403930664, "timer/env.step_frac": 0.2401636485853616, "timer/env.step_avg": 0.08667198197666184, "timer/env.step_min": 0.022517681121826172, "timer/env.step_max": 3.3164477348327637, "timer/replay._sample_count": 22176.0, "timer/replay._sample_total": 11.052352666854858, "timer/replay._sample_frac": 0.011048162495269492, "timer/replay._sample_avg": 0.0004983925264635127, "timer/replay._sample_min": 0.0004184246063232422, "timer/replay._sample_max": 0.02480459213256836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3409.0, "timer/agent.policy_total": 55.4374635219574, "timer/agent.policy_frac": 0.05541644605251751, "timer/agent.policy_avg": 0.016262089622164095, "timer/agent.policy_min": 0.009292364120483398, "timer/agent.policy_max": 0.1066286563873291, "timer/dataset_train_count": 1386.0, "timer/dataset_train_total": 0.14642882347106934, "timer/dataset_train_frac": 0.0001463733093272593, "timer/dataset_train_avg": 0.00010564850178287831, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0004532337188720703, "timer/agent.train_count": 1386.0, "timer/agent.train_total": 621.7433054447174, "timer/agent.train_frac": 0.6215075899178614, "timer/agent.train_avg": 0.4485882434666071, "timer/agent.train_min": 0.43363070487976074, "timer/agent.train_max": 1.6433465480804443, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4714362621307373, "timer/agent.report_frac": 0.00047125753105967626, "timer/agent.report_avg": 0.23571813106536865, "timer/agent.report_min": 0.2290341854095459, "timer/agent.report_max": 0.2424020767211914, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7884398203240058e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 22.16729665820953}
{"step": 879128, "time": 40405.300041913986, "episode/length": 175.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 879528, "time": 40420.5752055645, "episode/length": 199.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 879768, "time": 40430.76908612251, "episode/length": 205.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 879840, "time": 40435.42890572548, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 880040, "time": 40444.16061639786, "episode/length": 299.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 40465.059406518936, "eval_episode/length": 34.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 880048, "time": 40469.42705464363, "eval_episode/length": 48.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 880048, "time": 40471.46901512146, "eval_episode/length": 84.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9529411764705882}
{"step": 880048, "time": 40475.30611753464, "eval_episode/length": 41.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 880048, "time": 40479.19897055626, "eval_episode/length": 165.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 880048, "time": 40483.298201560974, "eval_episode/length": 203.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 880048, "time": 40485.34185004234, "eval_episode/length": 79.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9875}
{"step": 880048, "time": 40488.03710079193, "eval_episode/length": 221.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 880296, "time": 40496.378717660904, "episode/length": 361.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 880296, "time": 40496.40241384506, "episode/length": 208.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 880464, "time": 40506.66830420494, "episode/length": 217.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 880600, "time": 40513.070417165756, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 880696, "time": 40518.12613797188, "episode/length": 49.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 881192, "time": 40537.23569226265, "episode/length": 257.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 881384, "time": 40545.636704683304, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 881784, "time": 40560.57046699524, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 881848, "time": 40564.24139261246, "episode/length": 143.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 882064, "time": 40573.091222286224, "episode/length": 277.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 882120, "time": 40576.33422899246, "episode/length": 293.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 882312, "time": 40584.1174018383, "episode/length": 230.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 882816, "time": 40602.67800831795, "episode/length": 178.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 882832, "time": 40604.93480300903, "episode/length": 204.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 882992, "time": 40611.675706386566, "episode/length": 432.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 883328, "time": 40624.395741701126, "episode/length": 192.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 883520, "time": 40632.45163369179, "episode/length": 208.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 883640, "time": 40638.48088622093, "episode/length": 165.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 883656, "time": 40640.97877764702, "episode/length": 198.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 883672, "time": 40643.573875427246, "episode/length": 193.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 884072, "time": 40659.23591065407, "episode/length": 154.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 884352, "time": 40671.047936439514, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 885064, "time": 40698.59113264084, "episode/length": 216.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 885216, "time": 40705.36251473427, "episode/length": 192.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 885280, "time": 40709.19255280495, "episode/length": 204.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 885640, "time": 40723.20874834061, "episode/length": 44.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 885920, "time": 40734.19914603233, "episode/length": 230.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 886200, "time": 40744.757843494415, "episode/length": 400.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 886424, "time": 40753.64819812775, "episode/length": 345.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 886936, "time": 40772.106166124344, "episode/length": 426.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953161592505855, "episode/intrinsic_return": 0.0}
{"step": 887568, "time": 40794.741567373276, "episode/length": 312.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 887592, "time": 40797.00263643265, "episode/length": 208.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 887792, "time": 40805.36203169823, "episode/length": 321.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.984472049689441, "episode/intrinsic_return": 0.0}
{"step": 887952, "time": 40812.19790029526, "episode/length": 449.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9977777777777778, "episode/intrinsic_return": 0.0}
{"step": 888168, "time": 40820.79470038414, "episode/length": 217.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 888848, "time": 40844.9984126091, "episode/length": 156.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 889016, "time": 40851.816024303436, "episode/length": 259.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9653846153846154, "episode/intrinsic_return": 0.0}
{"step": 889064, "time": 40854.90170311928, "episode/length": 427.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 889432, "time": 40868.72449469566, "episode/length": 184.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 889440, "time": 40870.80426120758, "episode/length": 233.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 889640, "time": 40878.62376642227, "episode/length": 429.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9930232558139535, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 40907.955595731735, "eval_episode/length": 48.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 890032, "time": 40911.654032707214, "eval_episode/length": 103.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9711538461538461}
{"step": 890032, "time": 40915.12573671341, "eval_episode/length": 147.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 890032, "time": 40917.81785607338, "eval_episode/length": 173.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 890032, "time": 40920.1091530323, "eval_episode/length": 191.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 890032, "time": 40922.154853105545, "eval_episode/length": 202.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 890032, "time": 40925.74285721779, "eval_episode/length": 200.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 890032, "time": 40928.398374795914, "eval_episode/length": 275.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 890304, "time": 40937.34670042992, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 890328, "time": 40939.39411234856, "episode/length": 184.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 890992, "time": 40963.59340238571, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 891312, "time": 40976.58902692795, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 891792, "time": 40994.02519202232, "episode/length": 346.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9884726224783862, "episode/intrinsic_return": 0.0}
{"step": 892160, "time": 41008.3418302536, "episode/length": 314.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 892264, "time": 41013.66015648842, "episode/length": 244.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 892440, "time": 41021.70235848427, "episode/length": 263.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 892760, "time": 41034.79909873009, "episode/length": 180.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 892896, "time": 41041.08376431465, "episode/length": 590.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9983079526226735, "episode/intrinsic_return": 0.0}
{"step": 893328, "time": 41058.75610494614, "episode/length": 53.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9074074074074074, "episode/intrinsic_return": 0.0}
{"step": 893784, "time": 41075.3462100029, "episode/length": 748.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9973297730307076, "episode/intrinsic_return": 0.0}
{"step": 893808, "time": 41078.378435373306, "episode/length": 170.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 893904, "time": 41083.66983819008, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 894216, "time": 41096.280244112015, "episode/length": 402.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9875930521091811, "episode/intrinsic_return": 0.0}
{"step": 894360, "time": 41103.34070587158, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 894384, "time": 41106.07198572159, "episode/length": 277.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 895048, "time": 41129.42743372917, "episode/length": 406.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975429975429976, "episode/intrinsic_return": 0.0}
{"step": 895512, "time": 41146.451303482056, "episode/length": 212.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 895520, "time": 41148.55219578743, "episode/length": 273.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 895688, "time": 41155.55032372475, "episode/length": 183.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 896088, "time": 41170.83934402466, "episode/length": 215.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 896144, "time": 41174.96704363823, "episode/length": 279.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 896256, "time": 41180.70041489601, "episode/length": 150.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 896744, "time": 41198.20042514801, "episode/length": 152.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 896928, "time": 41206.367939949036, "episode/length": 104.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 897264, "time": 41219.7581179142, "episode/length": 434.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 897360, "time": 41224.48633646965, "episode/length": 230.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 897840, "time": 41241.87200951576, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9669811320754716, "episode/intrinsic_return": 0.0}
{"step": 897984, "time": 41248.168838739395, "episode/length": 154.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 897992, "time": 41249.686722278595, "episode/length": 450.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9800443458980045, "episode/intrinsic_return": 0.0}
{"step": 898344, "time": 41262.86861419678, "episode/length": 331.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 898592, "time": 41272.90631580353, "episode/length": 207.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 898656, "time": 41276.631261348724, "episode/length": 38.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 899184, "time": 41295.66131854057, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 899688, "time": 41313.719145298004, "episode/length": 212.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 899720, "time": 41316.38803267479, "episode/length": 432.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 41342.66378736496, "eval_episode/length": 43.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 900016, "time": 41345.61495041847, "eval_episode/length": 35.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8888888888888888}
{"step": 900016, "time": 41349.632583618164, "eval_episode/length": 145.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 900016, "time": 41352.141100645065, "eval_episode/length": 167.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 900016, "time": 41353.827268362045, "eval_episode/length": 170.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 900016, "time": 41355.64009928703, "eval_episode/length": 176.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9661016949152542}
{"step": 900016, "time": 41358.262479543686, "eval_episode/length": 202.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 900016, "time": 41361.34940576553, "eval_episode/length": 241.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9958677685950413}
{"step": 900088, "time": 41363.51825475693, "episode/length": 178.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 900224, "time": 41369.89015507698, "episode/length": 297.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9832214765100671, "episode/intrinsic_return": 0.0}
{"step": 900816, "time": 41390.75560760498, "episode/length": 203.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 900833, "time": 41393.372272491455, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.494320192198822, "train/action_min": 0.0, "train/action_std": 3.230658237484918, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03924684395230767, "train/actor_opt_grad_steps": 55515.0, "train/actor_opt_loss": -4.262950854510933, "train/adv_mag": 0.48329141865605896, "train/adv_max": 0.4365254711845647, "train/adv_mean": 0.0034259600105002205, "train/adv_min": -0.38957406558852264, "train/adv_std": 0.05509441472805929, "train/cont_avg": 0.9948412024456522, "train/cont_loss_mean": 0.00018256962711734394, "train/cont_loss_std": 0.005597117822716151, "train/cont_neg_acc": 0.9962474125019019, "train/cont_neg_loss": 0.021678114614801878, "train/cont_pos_acc": 0.9999786140262217, "train/cont_pos_loss": 7.800064420575795e-05, "train/cont_pred": 0.9948477442713751, "train/cont_rate": 0.9948412024456522, "train/dyn_loss_mean": 13.442143046337625, "train/dyn_loss_std": 9.281471231709356, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8798736610274384, "train/extr_critic_critic_opt_grad_steps": 55515.0, "train/extr_critic_critic_opt_loss": 16104.702268738678, "train/extr_critic_mag": 8.764620718748674, "train/extr_critic_max": 8.764620718748674, "train/extr_critic_mean": 2.640676044035649, "train/extr_critic_min": -0.20594503309415735, "train/extr_critic_std": 2.076002900151239, "train/extr_return_normed_mag": 1.5070704886878745, "train/extr_return_normed_max": 1.5070704886878745, "train/extr_return_normed_mean": 0.3962206797323365, "train/extr_return_normed_min": -0.09666955592515676, "train/extr_return_normed_std": 0.3254006520129632, "train/extr_return_rate": 0.8176895051762678, "train/extr_return_raw_mag": 9.850649930428768, "train/extr_return_raw_max": 9.850649930428768, "train/extr_return_raw_mean": 2.662843131500742, "train/extr_return_raw_min": -0.5261074247351591, "train/extr_return_raw_std": 2.10543295784273, "train/extr_reward_mag": 1.0494567587755728, "train/extr_reward_max": 1.0494567587755728, "train/extr_reward_mean": 0.05147370283046494, "train/extr_reward_min": -0.4305998354718305, "train/extr_reward_std": 0.21152940241323, "train/image_loss_mean": 6.182696425396463, "train/image_loss_std": 11.56635602660801, "train/model_loss_mean": 14.306935061579166, "train/model_loss_std": 15.381851106450178, "train/model_opt_grad_norm": 50.29355697355409, "train/model_opt_grad_steps": 55463.5, "train/model_opt_loss": 18713.541956804802, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1313.4057971014493, "train/policy_entropy_mag": 2.4832967053289, "train/policy_entropy_max": 2.4832967053289, "train/policy_entropy_mean": 0.48010601794374164, "train/policy_entropy_min": 0.07937501473487288, "train/policy_entropy_std": 0.5943740815788076, "train/policy_logprob_mag": 7.438383886779564, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4795229249242423, "train/policy_logprob_min": -7.438383886779564, "train/policy_logprob_std": 1.0501350902992745, "train/policy_randomness_mag": 0.8764947605305824, "train/policy_randomness_max": 0.8764947605305824, "train/policy_randomness_mean": 0.16945635613755902, "train/policy_randomness_min": 0.02801589694791946, "train/policy_randomness_std": 0.20978796870812125, "train/post_ent_mag": 60.22781355484672, "train/post_ent_max": 60.22781355484672, "train/post_ent_mean": 42.99966129358264, "train/post_ent_min": 20.0590490811113, "train/post_ent_std": 7.69633079957271, "train/prior_ent_mag": 69.56149291992188, "train/prior_ent_max": 69.56149291992188, "train/prior_ent_mean": 56.51569200598675, "train/prior_ent_min": 40.56113107653632, "train/prior_ent_std": 4.476624112198318, "train/rep_loss_mean": 13.442143046337625, "train/rep_loss_std": 9.281471231709356, "train/reward_avg": 0.03327742820956569, "train/reward_loss_mean": 0.05877025803362114, "train/reward_loss_std": 0.2494560048200082, "train/reward_max_data": 1.0188405842020891, "train/reward_max_pred": 1.0114953085996103, "train/reward_neg_acc": 0.9920919753503108, "train/reward_neg_loss": 0.028933750047091988, "train/reward_pos_acc": 0.974422721327215, "train/reward_pos_loss": 0.8212330354296643, "train/reward_pred": 0.032444237609920296, "train/reward_rate": 0.03775334012681159, "train_stats/sum_log_reward": 9.204651407031125, "train_stats/max_log_achievement_collect_coal": 0.6627906976744186, "train_stats/max_log_achievement_collect_drink": 5.662790697674419, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.4534883720930232, "train_stats/max_log_achievement_collect_stone": 14.511627906976743, "train_stats/max_log_achievement_collect_wood": 10.523255813953488, "train_stats/max_log_achievement_defeat_skeleton": 0.05813953488372093, "train_stats/max_log_achievement_defeat_zombie": 0.6744186046511628, "train_stats/max_log_achievement_eat_cow": 0.18604651162790697, "train_stats/max_log_achievement_make_stone_pickaxe": 0.03488372093023256, "train_stats/max_log_achievement_make_stone_sword": 0.011627906976744186, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5465116279069768, "train_stats/max_log_achievement_make_wood_sword": 0.9534883720930233, "train_stats/max_log_achievement_place_furnace": 0.011627906976744186, "train_stats/max_log_achievement_place_plant": 1.441860465116279, "train_stats/max_log_achievement_place_stone": 11.744186046511627, "train_stats/max_log_achievement_place_table": 2.86046511627907, "train_stats/max_log_achievement_wake_up": 1.8604651162790697, "train_stats/mean_log_entropy": 0.5726489391784335, "eval_stats/sum_log_reward": 7.475000222524007, "eval_stats/max_log_achievement_collect_coal": 0.08333333333333333, "eval_stats/max_log_achievement_collect_drink": 2.9583333333333335, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_stone": 8.125, "eval_stats/max_log_achievement_collect_wood": 7.708333333333333, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.5416666666666666, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_stone": 5.958333333333333, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 8.19103115645703e-06, "report/cont_loss_std": 0.00023732750560157, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0025290027260780334, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.841403544261993e-07, "report/cont_pred": 0.9970769882202148, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.152178764343262, "report/dyn_loss_std": 8.888049125671387, "report/image_loss_mean": 6.087470531463623, "report/image_loss_std": 8.685105323791504, "report/model_loss_mean": 14.036452293395996, "report/model_loss_std": 12.708380699157715, "report/post_ent_mag": 58.197784423828125, "report/post_ent_max": 58.197784423828125, "report/post_ent_mean": 42.55413818359375, "report/post_ent_min": 20.3170166015625, "report/post_ent_std": 7.2478742599487305, "report/prior_ent_mag": 69.86385345458984, "report/prior_ent_max": 69.86385345458984, "report/prior_ent_mean": 55.97467803955078, "report/prior_ent_min": 40.69928741455078, "report/prior_ent_std": 4.776795864105225, "report/rep_loss_mean": 13.152178764343262, "report/rep_loss_std": 8.888049125671387, "report/reward_avg": 0.03896484524011612, "report/reward_loss_mean": 0.057666197419166565, "report/reward_loss_std": 0.2479213923215866, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0893034934997559, "report/reward_neg_acc": 0.996941864490509, "report/reward_neg_loss": 0.024484967812895775, "report/reward_pos_acc": 0.9534883499145508, "report/reward_pos_loss": 0.8146612644195557, "report/reward_pred": 0.03803883120417595, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 2.3003008209343534e-06, "eval/cont_loss_std": 6.829309859313071e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0011076722294092178, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.3714617352889036e-07, "eval/cont_pred": 0.9980489611625671, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.724552154541016, "eval/dyn_loss_std": 10.583423614501953, "eval/image_loss_mean": 8.083745002746582, "eval/image_loss_std": 10.490616798400879, "eval/model_loss_mean": 18.232833862304688, "eval/model_loss_std": 14.86949348449707, "eval/post_ent_mag": 61.252620697021484, "eval/post_ent_max": 61.252620697021484, "eval/post_ent_mean": 42.582054138183594, "eval/post_ent_min": 19.974037170410156, "eval/post_ent_std": 7.91907262802124, "eval/prior_ent_mag": 69.86385345458984, "eval/prior_ent_max": 69.86385345458984, "eval/prior_ent_mean": 57.11220169067383, "eval/prior_ent_min": 42.174476623535156, "eval/prior_ent_std": 4.093105792999268, "eval/rep_loss_mean": 16.724552154541016, "eval/rep_loss_std": 10.583423614501953, "eval/reward_avg": 0.04179687798023224, "eval/reward_loss_mean": 0.11435605585575104, "eval/reward_loss_std": 0.686750054359436, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0288729667663574, "eval/reward_neg_acc": 0.9918200373649597, "eval/reward_neg_loss": 0.04443740472197533, "eval/reward_pos_acc": 0.8260869979858398, "eval/reward_pos_loss": 1.6008875370025635, "eval/reward_pred": 0.03720374032855034, "eval/reward_rate": 0.044921875, "replay/size": 900329.0, "replay/inserts": 22072.0, "replay/samples": 22064.0, "replay/insert_wait_avg": 1.381827506866953e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.248370829658979e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5920.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2013155060845453e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2218952178955078e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0001003742218, "timer/env.step_count": 2759.0, "timer/env.step_total": 223.19529104232788, "timer/env.step_frac": 0.2231952686392765, "timer/env.step_avg": 0.08089716964201808, "timer/env.step_min": 0.022114276885986328, "timer/env.step_max": 4.347667694091797, "timer/replay._sample_count": 22064.0, "timer/replay._sample_total": 11.055945873260498, "timer/replay._sample_frac": 0.011055944763528646, "timer/replay._sample_avg": 0.0005010852915727201, "timer/replay._sample_min": 0.00037384033203125, "timer/replay._sample_max": 0.05391049385070801, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3499.0, "timer/agent.policy_total": 55.98659300804138, "timer/agent.policy_frac": 0.05598658738843124, "timer/agent.policy_avg": 0.016000741071175016, "timer/agent.policy_min": 0.009310007095336914, "timer/agent.policy_max": 0.09666681289672852, "timer/dataset_train_count": 1379.0, "timer/dataset_train_total": 0.15047001838684082, "timer/dataset_train_frac": 0.00015047000328353134, "timer/dataset_train_avg": 0.00010911531427617174, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0039119720458984375, "timer/agent.train_count": 1379.0, "timer/agent.train_total": 617.8031129837036, "timer/agent.train_frac": 0.6178030509722031, "timer/agent.train_avg": 0.44800805872639854, "timer/agent.train_min": 0.43500447273254395, "timer/agent.train_max": 1.605560302734375, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47162604331970215, "timer/agent.report_frac": 0.0004716259959806098, "timer/agent.report_avg": 0.23581302165985107, "timer/agent.report_min": 0.22763466835021973, "timer/agent.report_max": 0.24399137496948242, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.004073795148118e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 22.071712057127872}
{"step": 900856, "time": 41394.06127309799, "episode/length": 282.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9823321554770318, "episode/intrinsic_return": 0.0}
{"step": 900896, "time": 41397.41288113594, "episode/length": 100.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 901224, "time": 41411.287105083466, "episode/length": 494.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.997979797979798, "episode/intrinsic_return": 0.0}
{"step": 901264, "time": 41414.51259279251, "episode/length": 192.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 901272, "time": 41416.107055425644, "episode/length": 409.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975609756097561, "episode/intrinsic_return": 0.0}
{"step": 902512, "time": 41458.970811367035, "episode/length": 201.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 902672, "time": 41465.90186595917, "episode/length": 305.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 902856, "time": 41473.29631137848, "episode/length": 203.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 902976, "time": 41478.98677921295, "episode/length": 269.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 903040, "time": 41482.74877619743, "episode/length": 221.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 903160, "time": 41488.30650663376, "episode/length": 235.0, "episode/score": 8.1000000461936, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 903248, "time": 41493.56983757019, "episode/length": 298.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9665551839464883, "episode/intrinsic_return": 0.0}
{"step": 903408, "time": 41500.954178094864, "episode/length": 464.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9978494623655914, "episode/intrinsic_return": 0.0}
{"step": 903904, "time": 41519.73184490204, "episode/length": 173.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 904072, "time": 41526.63850927353, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 904144, "time": 41530.91128540039, "episode/length": 137.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 904192, "time": 41534.003247499466, "episode/length": 189.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 904328, "time": 41539.801770210266, "episode/length": 168.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 904352, "time": 41542.31442975998, "episode/length": 148.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 904768, "time": 41557.65229821205, "episode/length": 189.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 905408, "time": 41580.57603240013, "episode/length": 249.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 905624, "time": 41589.13490176201, "episode/length": 193.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 905760, "time": 41595.457256793976, "episode/length": 195.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 905808, "time": 41598.62301206589, "episode/length": 207.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 905824, "time": 41600.74453449249, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 905960, "time": 41606.661328315735, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 906752, "time": 41634.44347023964, "episode/length": 167.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 906992, "time": 41644.022585392, "episode/length": 329.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 907160, "time": 41650.94073724747, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 907192, "time": 41653.5217063427, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 907216, "time": 41656.104974746704, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 907344, "time": 41661.95191979408, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 907816, "time": 41678.95862388611, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 907824, "time": 41680.937247276306, "episode/length": 381.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9921465968586387, "episode/intrinsic_return": 0.0}
{"step": 908448, "time": 41703.24849176407, "episode/length": 211.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 908696, "time": 41712.95560216904, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 908768, "time": 41717.06945848465, "episode/length": 39.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 908848, "time": 41721.3281788826, "episode/length": 210.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 908848, "time": 41721.33666849136, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 909128, "time": 41733.77044010162, "episode/length": 241.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 909264, "time": 41739.99185490608, "episode/length": 51.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 909560, "time": 41752.567450761795, "episode/length": 107.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 41787.04630064964, "eval_episode/length": 143.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 910000, "time": 41792.08477163315, "eval_episode/length": 189.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 910000, "time": 41793.87309360504, "eval_episode/length": 195.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9846938775510204}
{"step": 910000, "time": 41795.88704943657, "eval_episode/length": 206.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9855072463768116}
{"step": 910000, "time": 41797.98467731476, "eval_episode/length": 218.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9817351598173516}
{"step": 910000, "time": 41803.79823708534, "eval_episode/length": 182.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 910000, "time": 41806.31581425667, "eval_episode/length": 159.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.99375}
{"step": 910000, "time": 41808.77842926979, "eval_episode/length": 370.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9946091644204852}
{"step": 910000, "time": 41808.78938937187, "eval_episode/length": 370.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9757412398921833}
{"step": 910096, "time": 41811.97389173508, "episode/length": 283.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9894366197183099, "episode/intrinsic_return": 0.0}
{"step": 910520, "time": 41827.85535740852, "episode/length": 412.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9951573849878934, "episode/intrinsic_return": 0.0}
{"step": 910664, "time": 41834.327320575714, "episode/length": 355.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9971910112359551, "episode/intrinsic_return": 0.0}
{"step": 910736, "time": 41838.483350753784, "episode/length": 245.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 910768, "time": 41841.08244752884, "episode/length": 150.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 911200, "time": 41857.01135635376, "episode/length": 258.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 911584, "time": 41871.24448776245, "episode/length": 341.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 911672, "time": 41875.54365539551, "episode/length": 196.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 911712, "time": 41878.74172234535, "episode/length": 305.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 912168, "time": 41895.16535949707, "episode/length": 205.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 912224, "time": 41898.8289809227, "episode/length": 185.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 912816, "time": 41920.03890824318, "episode/length": 201.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 912928, "time": 41925.27681493759, "episode/length": 282.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 912976, "time": 41928.35586357117, "episode/length": 275.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9746376811594203, "episode/intrinsic_return": 0.0}
{"step": 913200, "time": 41937.361015319824, "episode/length": 190.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 913200, "time": 41937.37028622627, "episode/length": 201.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 913696, "time": 41956.911183834076, "episode/length": 247.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 913800, "time": 41961.70511507988, "episode/length": 196.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 914184, "time": 41975.868450164795, "episode/length": 251.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 914824, "time": 41999.106048345566, "episode/length": 236.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 914864, "time": 42002.779915332794, "episode/length": 255.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 915216, "time": 42016.96640062332, "episode/length": 251.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 915280, "time": 42021.17349052429, "episode/length": 259.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9730769230769231, "episode/intrinsic_return": 0.0}
{"step": 915312, "time": 42024.35127329826, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 916408, "time": 42063.20846772194, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953379953379954, "episode/intrinsic_return": 0.0}
{"step": 916552, "time": 42069.48725390434, "episode/length": 343.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 916816, "time": 42079.99122071266, "episode/length": 50.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 916832, "time": 42082.0671916008, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 916968, "time": 42088.10194349289, "episode/length": 267.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 917064, "time": 42092.783849954605, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 917624, "time": 42114.56638765335, "episode/length": 429.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 917768, "time": 42121.037892103195, "episode/length": 362.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9807162534435262, "episode/intrinsic_return": 0.0}
{"step": 918192, "time": 42136.78357553482, "episode/length": 371.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 918304, "time": 42141.92064523697, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 919056, "time": 42168.50379228592, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 919104, "time": 42172.09436535835, "episode/length": 285.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9755244755244755, "episode/intrinsic_return": 0.0}
{"step": 919216, "time": 42177.92639088631, "episode/length": 297.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 919272, "time": 42181.031521081924, "episode/length": 205.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 919512, "time": 42190.502053022385, "episode/length": 317.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9842767295597484, "episode/intrinsic_return": 0.0}
{"step": 919960, "time": 42206.86308670044, "episode/length": 361.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9861878453038674, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 42230.60694217682, "eval_episode/length": 135.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 920088, "time": 42232.857072114944, "eval_episode/length": 149.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 920088, "time": 42234.5700378418, "eval_episode/length": 153.0, "eval_episode/score": 10.100000016391277, "eval_episode/reward_rate": 0.9805194805194806}
{"step": 920088, "time": 42237.098662376404, "eval_episode/length": 175.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 920088, "time": 42239.37202978134, "eval_episode/length": 194.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 920088, "time": 42241.954385757446, "eval_episode/length": 216.0, "eval_episode/score": 11.099999971687794, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 920088, "time": 42248.25262260437, "eval_episode/length": 184.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 920088, "time": 42250.3233165741, "eval_episode/length": 195.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 920512, "time": 42264.94077086449, "episode/length": 175.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 920720, "time": 42273.54209494591, "episode/length": 301.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 920792, "time": 42277.21619462967, "episode/length": 216.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 920824, "time": 42279.81674051285, "episode/length": 193.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 921056, "time": 42289.3489215374, "episode/length": 192.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 921288, "time": 42298.46255946159, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 921304, "time": 42300.5188999176, "episode/length": 260.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 921584, "time": 42311.594727516174, "episode/length": 133.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 921624, "time": 42314.260734796524, "episode/length": 112.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 921672, "time": 42317.37930750847, "episode/length": 434.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 922184, "time": 42335.78202915192, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 922464, "time": 42346.784579992294, "episode/length": 208.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9617224880382775, "episode/intrinsic_return": 0.0}
{"step": 922512, "time": 42349.96270418167, "episode/length": 152.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 922864, "time": 42363.16990375519, "episode/length": 225.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 922864, "time": 42363.17852187157, "episode/length": 154.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 923184, "time": 42377.12149190903, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 923520, "time": 42389.94410228729, "episode/length": 230.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 923561, "time": 42393.50726747513, "train_stats/sum_log_reward": 9.564646671516726, "train_stats/max_log_achievement_collect_coal": 0.6262626262626263, "train_stats/max_log_achievement_collect_drink": 6.7272727272727275, "train_stats/max_log_achievement_collect_iron": 0.010101010101010102, "train_stats/max_log_achievement_collect_sapling": 1.4545454545454546, "train_stats/max_log_achievement_collect_stone": 11.353535353535353, "train_stats/max_log_achievement_collect_wood": 10.626262626262626, "train_stats/max_log_achievement_defeat_skeleton": 0.06060606060606061, "train_stats/max_log_achievement_defeat_zombie": 0.9696969696969697, "train_stats/max_log_achievement_eat_cow": 0.21212121212121213, "train_stats/max_log_achievement_make_stone_pickaxe": 0.020202020202020204, "train_stats/max_log_achievement_make_stone_sword": 0.010101010101010102, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4848484848484849, "train_stats/max_log_achievement_make_wood_sword": 0.9696969696969697, "train_stats/max_log_achievement_place_furnace": 0.010101010101010102, "train_stats/max_log_achievement_place_plant": 1.4444444444444444, "train_stats/max_log_achievement_place_stone": 8.727272727272727, "train_stats/max_log_achievement_place_table": 2.797979797979798, "train_stats/max_log_achievement_wake_up": 1.7171717171717171, "train_stats/mean_log_entropy": 0.5655397324248997, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.538958912164393, "train/action_min": 0.0, "train/action_std": 3.276049232818711, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03795144649248727, "train/actor_opt_grad_steps": 56915.0, "train/actor_opt_loss": -8.970028257427055, "train/adv_mag": 0.47190696546729183, "train/adv_max": 0.42713508282748747, "train/adv_mean": 0.0023385794279356174, "train/adv_min": -0.3831060537150208, "train/adv_std": 0.0540021095215015, "train/cont_avg": 0.9947114326584507, "train/cont_loss_mean": 0.0001653508012454377, "train/cont_loss_std": 0.004525299545476023, "train/cont_neg_acc": 0.99723340088213, "train/cont_neg_loss": 0.016304739317147196, "train/cont_pos_acc": 0.9999585013154527, "train/cont_pos_loss": 9.366369332362513e-05, "train/cont_pred": 0.9946947248888688, "train/cont_rate": 0.9947114326584507, "train/dyn_loss_mean": 13.300378006948552, "train/dyn_loss_std": 9.263502235143957, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8737999255388555, "train/extr_critic_critic_opt_grad_steps": 56915.0, "train/extr_critic_critic_opt_loss": 15945.731720400529, "train/extr_critic_mag": 8.808210386356837, "train/extr_critic_max": 8.808210386356837, "train/extr_critic_mean": 2.597850520006368, "train/extr_critic_min": -0.19964227290220662, "train/extr_critic_std": 2.086071599537218, "train/extr_return_normed_mag": 1.5170128605735134, "train/extr_return_normed_max": 1.5170128605735134, "train/extr_return_normed_mean": 0.3881295089360694, "train/extr_return_normed_min": -0.09408030121154348, "train/extr_return_normed_std": 0.32786761140319665, "train/extr_return_rate": 0.8073439736601332, "train/extr_return_raw_mag": 9.893966930013308, "train/extr_return_raw_max": 9.893966930013308, "train/extr_return_raw_mean": 2.612904349683036, "train/extr_return_raw_min": -0.49690240590085444, "train/extr_return_raw_std": 2.114629866371692, "train/extr_reward_mag": 1.0521422624588013, "train/extr_reward_max": 1.0521422624588013, "train/extr_reward_mean": 0.05049783859769223, "train/extr_reward_min": -0.4079953910599292, "train/extr_reward_std": 0.21046347643288088, "train/image_loss_mean": 6.117277675951031, "train/image_loss_std": 11.342391333109896, "train/model_loss_mean": 14.156404931780319, "train/model_loss_std": 15.135130499450254, "train/model_opt_grad_norm": 50.15419647055612, "train/model_opt_grad_steps": 56862.17605633803, "train/model_opt_loss": 18216.991334727114, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1285.2112676056338, "train/policy_entropy_mag": 2.4765621809892253, "train/policy_entropy_max": 2.4765621809892253, "train/policy_entropy_mean": 0.48366648189618555, "train/policy_entropy_min": 0.07937501423375708, "train/policy_entropy_std": 0.6044548502270605, "train/policy_logprob_mag": 7.43838383446277, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.48392477526631156, "train/policy_logprob_min": -7.43838383446277, "train/policy_logprob_std": 1.0542199586478758, "train/policy_randomness_mag": 0.8741177652083653, "train/policy_randomness_max": 0.8741177652083653, "train/policy_randomness_mean": 0.17071304564744655, "train/policy_randomness_min": 0.028015896848494738, "train/policy_randomness_std": 0.21334603670197475, "train/post_ent_mag": 60.40366559633067, "train/post_ent_max": 60.40366559633067, "train/post_ent_mean": 43.04144980202258, "train/post_ent_min": 20.256384896560455, "train/post_ent_std": 7.657202223656883, "train/prior_ent_mag": 69.64636348670638, "train/prior_ent_max": 69.64636348670638, "train/prior_ent_mean": 56.46912201357559, "train/prior_ent_min": 40.67429518363845, "train/prior_ent_std": 4.587718268515358, "train/rep_loss_mean": 13.300378006948552, "train/rep_loss_std": 9.263502235143957, "train/reward_avg": 0.032484457434587916, "train/reward_loss_mean": 0.058735183558203806, "train/reward_loss_std": 0.2481204199958855, "train/reward_max_data": 1.0183098635203403, "train/reward_max_pred": 1.016200513906882, "train/reward_neg_acc": 0.9923677339520253, "train/reward_neg_loss": 0.029438822202279533, "train/reward_pos_acc": 0.974714007176144, "train/reward_pos_loss": 0.8179229858895423, "train/reward_pred": 0.03166937387325394, "train/reward_rate": 0.03726067341549296, "eval_stats/sum_log_reward": 9.747059120851404, "eval_stats/max_log_achievement_collect_coal": 0.6470588235294118, "eval_stats/max_log_achievement_collect_drink": 3.6470588235294117, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.411764705882353, "eval_stats/max_log_achievement_collect_stone": 10.235294117647058, "eval_stats/max_log_achievement_collect_wood": 10.117647058823529, "eval_stats/max_log_achievement_defeat_skeleton": 0.058823529411764705, "eval_stats/max_log_achievement_defeat_zombie": 0.9411764705882353, "eval_stats/max_log_achievement_eat_cow": 0.11764705882352941, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3529411764705883, "eval_stats/max_log_achievement_make_wood_sword": 0.9411764705882353, "eval_stats/max_log_achievement_place_furnace": 0.058823529411764705, "eval_stats/max_log_achievement_place_plant": 1.411764705882353, "eval_stats/max_log_achievement_place_stone": 8.588235294117647, "eval_stats/max_log_achievement_place_table": 2.7058823529411766, "eval_stats/max_log_achievement_wake_up": 1.411764705882353, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.17112810787512e-05, "report/cont_loss_std": 0.00046091823605820537, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00010289601050317287, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.123278500221204e-05, "report/cont_pred": 0.9941202402114868, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 10.755234718322754, "report/dyn_loss_std": 9.09498119354248, "report/image_loss_mean": 6.740388870239258, "report/image_loss_std": 13.58517837524414, "report/model_loss_mean": 13.26692008972168, "report/model_loss_std": 16.654987335205078, "report/post_ent_mag": 63.42697525024414, "report/post_ent_max": 63.42697525024414, "report/post_ent_mean": 46.762413024902344, "report/post_ent_min": 17.228378295898438, "report/post_ent_std": 8.57256031036377, "report/prior_ent_mag": 69.99446105957031, "report/prior_ent_max": 69.99446105957031, "report/prior_ent_mean": 57.826744079589844, "report/prior_ent_min": 40.88187789916992, "report/prior_ent_std": 4.93673849105835, "report/rep_loss_mean": 10.755234718322754, "report/rep_loss_std": 9.09498119354248, "report/reward_avg": 0.03212890774011612, "report/reward_loss_mean": 0.07336845993995667, "report/reward_loss_std": 0.37119734287261963, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0020506381988525, "report/reward_neg_acc": 0.9847716093063354, "report/reward_neg_loss": 0.047838203608989716, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7181711792945862, "report/reward_pred": 0.03379596024751663, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 3.09015263155743e-06, "eval/cont_loss_std": 8.469130989396945e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.002697549294680357, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.5627251665791846e-07, "eval/cont_pred": 0.9990256428718567, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 18.43090057373047, "eval/dyn_loss_std": 10.756742477416992, "eval/image_loss_mean": 8.45654296875, "eval/image_loss_std": 13.746695518493652, "eval/model_loss_mean": 19.596078872680664, "eval/model_loss_std": 17.974775314331055, "eval/post_ent_mag": 60.08226776123047, "eval/post_ent_max": 60.08226776123047, "eval/post_ent_mean": 40.94699478149414, "eval/post_ent_min": 19.3818416595459, "eval/post_ent_std": 7.228549957275391, "eval/prior_ent_mag": 69.99446105957031, "eval/prior_ent_max": 69.99446105957031, "eval/prior_ent_mean": 57.034847259521484, "eval/prior_ent_min": 45.23236846923828, "eval/prior_ent_std": 4.016186237335205, "eval/rep_loss_mean": 18.43090057373047, "eval/rep_loss_std": 10.756742477416992, "eval/reward_avg": 0.03124999813735485, "eval/reward_loss_mean": 0.08099228143692017, "eval/reward_loss_std": 0.47854992747306824, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0671122074127197, "eval/reward_neg_acc": 0.988877534866333, "eval/reward_neg_loss": 0.04090030863881111, "eval/reward_pos_acc": 0.9428571462631226, "eval/reward_pos_loss": 1.2138768434524536, "eval/reward_pred": 0.031066540628671646, "eval/reward_rate": 0.0341796875, "replay/size": 923057.0, "replay/inserts": 22728.0, "replay/samples": 22736.0, "replay/insert_wait_avg": 1.3716935859688232e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.371705156577296e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5768.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1958956883783644e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1175699234009, "timer/env.step_count": 2841.0, "timer/env.step_total": 235.52558875083923, "timer/env.step_frac": 0.23549790128062462, "timer/env.step_avg": 0.08290235436495573, "timer/env.step_min": 0.0224759578704834, "timer/env.step_max": 3.434920310974121, "timer/replay._sample_count": 22736.0, "timer/replay._sample_total": 11.378465414047241, "timer/replay._sample_frac": 0.011377127806002568, "timer/replay._sample_avg": 0.0005004603014623171, "timer/replay._sample_min": 0.0003533363342285156, "timer/replay._sample_max": 0.03161358833312988, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3562.0, "timer/agent.policy_total": 57.83573317527771, "timer/agent.policy_frac": 0.05782893423190971, "timer/agent.policy_avg": 0.01623687062753445, "timer/agent.policy_min": 0.009231805801391602, "timer/agent.policy_max": 0.10735225677490234, "timer/dataset_train_count": 1421.0, "timer/dataset_train_total": 0.1471233367919922, "timer/dataset_train_frac": 0.00014710604154595581, "timer/dataset_train_avg": 0.00010353507163405503, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0002067089080810547, "timer/agent.train_count": 1421.0, "timer/agent.train_total": 636.2757503986359, "timer/agent.train_frac": 0.6362009523014063, "timer/agent.train_avg": 0.44776618606519064, "timer/agent.train_min": 0.4343414306640625, "timer/agent.train_max": 1.660447120666504, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47545623779296875, "timer/agent.report_frac": 0.0004754003450108211, "timer/agent.report_avg": 0.23772811889648438, "timer/agent.report_min": 0.2326188087463379, "timer/agent.report_max": 0.24283742904663086, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8606866185121376e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 22.72501463496354}
{"step": 923760, "time": 42400.19327330589, "episode/length": 306.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 923896, "time": 42405.99769806862, "episode/length": 213.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 924416, "time": 42425.148975372314, "episode/length": 237.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 924496, "time": 42429.370181560516, "episode/length": 203.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 924496, "time": 42429.38006043434, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 924744, "time": 42440.681465387344, "episode/length": 284.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754385964912281, "episode/intrinsic_return": 0.0}
{"step": 924976, "time": 42450.247381448746, "episode/length": 223.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 925016, "time": 42452.894602537155, "episode/length": 64.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 925264, "time": 42462.87927055359, "episode/length": 170.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 925312, "time": 42466.0143301487, "episode/length": 223.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 925600, "time": 42477.17150115967, "episode/length": 229.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 925792, "time": 42486.66436004639, "episode/length": 171.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 926096, "time": 42498.24320983887, "episode/length": 37.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 926320, "time": 42507.32242155075, "episode/length": 196.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 926328, "time": 42508.88875079155, "episode/length": 126.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 926568, "time": 42518.36997485161, "episode/length": 193.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 926760, "time": 42526.21439623833, "episode/length": 222.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 927136, "time": 42540.42838191986, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 927296, "time": 42547.18045425415, "episode/length": 349.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9828571428571429, "episode/intrinsic_return": 0.0}
{"step": 927856, "time": 42567.35422849655, "episode/length": 323.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9783950617283951, "episode/intrinsic_return": 0.0}
{"step": 927896, "time": 42569.933374643326, "episode/length": 165.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 928128, "time": 42579.39514756203, "episode/length": 224.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9688888888888889, "episode/intrinsic_return": 0.0}
{"step": 928288, "time": 42586.2109773159, "episode/length": 273.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9890510948905109, "episode/intrinsic_return": 0.0}
{"step": 928528, "time": 42595.54778838158, "episode/length": 275.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 928584, "time": 42598.899594545364, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 929040, "time": 42615.836317539215, "episode/length": 217.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 929056, "time": 42617.87222146988, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 929432, "time": 42631.76064777374, "episode/length": 162.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 929456, "time": 42634.25793480873, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 929472, "time": 42636.568882226944, "episode/length": 196.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 929792, "time": 42648.62649965286, "episode/length": 187.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 929856, "time": 42652.21573090553, "episode/length": 165.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 929880, "time": 42654.32132124901, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 42681.67974424362, "eval_episode/length": 60.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9344262295081968}
{"step": 930072, "time": 42690.79771065712, "eval_episode/length": 205.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.970873786407767}
{"step": 930072, "time": 42690.80656814575, "eval_episode/length": 205.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 930072, "time": 42695.571840286255, "eval_episode/length": 218.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9817351598173516}
{"step": 930072, "time": 42697.672579050064, "eval_episode/length": 220.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9683257918552036}
{"step": 930072, "time": 42700.49336218834, "eval_episode/length": 235.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 930072, "time": 42702.61448144913, "eval_episode/length": 240.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.979253112033195}
{"step": 930072, "time": 42705.30112886429, "eval_episode/length": 192.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 930288, "time": 42712.898644924164, "episode/length": 61.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 930528, "time": 42723.257029533386, "episode/length": 185.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 930984, "time": 42740.437552690506, "episode/length": 56.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 931168, "time": 42748.48222446442, "episode/length": 211.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 931592, "time": 42764.82256817818, "episode/length": 216.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 931792, "time": 42773.8459174633, "episode/length": 291.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 931840, "time": 42777.12336611748, "episode/length": 244.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 932424, "time": 42797.81046462059, "episode/length": 373.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 932816, "time": 42813.28012228012, "episode/length": 228.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 932856, "time": 42815.8695499897, "episode/length": 320.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 932936, "time": 42820.093366384506, "episode/length": 220.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 933296, "time": 42833.62694692612, "episode/length": 54.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 933376, "time": 42837.87960553169, "episode/length": 222.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 933608, "time": 42846.88256525993, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 933656, "time": 42850.01839995384, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 933664, "time": 42852.122691869736, "episode/length": 575.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9878472222222222, "episode/intrinsic_return": 0.0}
{"step": 934576, "time": 42885.45016002655, "episode/length": 149.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 935536, "time": 42918.834634542465, "episode/length": 388.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9974293059125964, "episode/intrinsic_return": 0.0}
{"step": 935664, "time": 42924.46990966797, "episode/length": 256.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 935736, "time": 42928.18406701088, "episode/length": 364.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 935840, "time": 42933.39245557785, "episode/length": 272.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 936104, "time": 42943.390639066696, "episode/length": 350.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9943019943019943, "episode/intrinsic_return": 0.0}
{"step": 936152, "time": 42946.519251823425, "episode/length": 310.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9903536977491961, "episode/intrinsic_return": 0.0}
{"step": 936368, "time": 42955.40793514252, "episode/length": 428.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 937120, "time": 42981.9987487793, "episode/length": 197.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 937312, "time": 42990.134236335754, "episode/length": 341.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 937696, "time": 43005.30353426933, "episode/length": 165.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 937760, "time": 43009.43922472, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 937856, "time": 43014.7173306942, "episode/length": 251.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 937896, "time": 43017.919352293015, "episode/length": 217.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 938448, "time": 43038.38971161842, "episode/length": 165.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 938512, "time": 43041.95194005966, "episode/length": 355.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 938864, "time": 43055.25422716141, "episode/length": 43.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 938928, "time": 43058.98631858826, "episode/length": 201.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 939416, "time": 43077.297392606735, "episode/length": 214.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 939512, "time": 43082.00040316582, "episode/length": 206.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 939768, "time": 43092.051844120026, "episode/length": 503.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 939952, "time": 43099.88919210434, "episode/length": 256.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 43124.09862160683, "eval_episode/length": 159.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.975}
{"step": 940056, "time": 43127.62737798691, "eval_episode/length": 206.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 940056, "time": 43130.82828307152, "eval_episode/length": 225.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.995575221238938}
{"step": 940056, "time": 43134.717582941055, "eval_episode/length": 47.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 940056, "time": 43137.99638414383, "eval_episode/length": 294.0, "eval_episode/score": 12.099999956786633, "eval_episode/reward_rate": 0.9966101694915255}
{"step": 940056, "time": 43139.629343271255, "eval_episode/length": 296.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9865319865319865}
{"step": 940056, "time": 43143.357325553894, "eval_episode/length": 191.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 940056, "time": 43144.90907549858, "eval_episode/length": 55.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 940768, "time": 43169.54305934906, "episode/length": 289.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 940904, "time": 43175.336757183075, "episode/length": 246.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 941128, "time": 43184.24466705322, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9752650176678446, "episode/intrinsic_return": 0.0}
{"step": 941200, "time": 43188.376094818115, "episode/length": 429.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 941368, "time": 43195.1641433239, "episode/length": 231.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 941576, "time": 43203.827835559845, "episode/length": 225.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 941600, "time": 43206.42796587944, "episode/length": 205.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 941760, "time": 43213.319689035416, "episode/length": 106.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 942768, "time": 43250.48650932312, "episode/length": 418.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9785202863961814, "episode/intrinsic_return": 0.0}
{"step": 942840, "time": 43254.767900943756, "episode/length": 213.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 943168, "time": 43268.07947850227, "episode/length": 224.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 943192, "time": 43270.237587451935, "episode/length": 198.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 943304, "time": 43275.46339774132, "episode/length": 192.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 943344, "time": 43278.54156112671, "episode/length": 220.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 943512, "time": 43285.462099552155, "episode/length": 42.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 943856, "time": 43299.503571510315, "episode/length": 331.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9969879518072289, "episode/intrinsic_return": 0.0}
{"step": 944216, "time": 43313.42942428589, "episode/length": 180.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 944232, "time": 43315.505350112915, "episode/length": 115.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 944384, "time": 43322.4310901165, "episode/length": 192.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 944864, "time": 43339.71863913536, "episode/length": 208.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 944960, "time": 43344.56383180618, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 945016, "time": 43347.92850995064, "episode/length": 97.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9387755102040817, "episode/intrinsic_return": 0.0}
{"step": 945072, "time": 43351.514688014984, "episode/length": 215.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 945312, "time": 43360.86441230774, "episode/length": 181.0, "episode/score": 11.099999956786633, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 945312, "time": 43360.8776512146, "episode/length": 567.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9841549295774648, "episode/intrinsic_return": 0.0}
{"step": 945728, "time": 43378.21180272102, "episode/length": 95.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 945880, "time": 43385.28985404968, "episode/length": 186.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9572192513368984, "episode/intrinsic_return": 0.0}
{"step": 946041, "time": 43393.8589117527, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.614556062306073, "train/action_min": 0.0, "train/action_std": 3.405903109421967, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03762538526339311, "train/actor_opt_grad_steps": 58330.0, "train/actor_opt_loss": -7.196918236659774, "train/adv_mag": 0.45848631584052496, "train/adv_max": 0.42185258062173286, "train/adv_mean": 0.002564179884170344, "train/adv_min": -0.3657849283083111, "train/adv_std": 0.053024172228067476, "train/cont_avg": 0.9949925199468085, "train/cont_loss_mean": 0.0003008541323939064, "train/cont_loss_std": 0.009177856941310403, "train/cont_neg_acc": 0.9895896670666147, "train/cont_neg_loss": 0.031742425878092166, "train/cont_pos_acc": 0.999951256927869, "train/cont_pos_loss": 0.00012463931557173862, "train/cont_pred": 0.9950035324333407, "train/cont_rate": 0.9949925199468085, "train/dyn_loss_mean": 13.271141762429096, "train/dyn_loss_std": 9.290095606594221, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8692812133342662, "train/extr_critic_critic_opt_grad_steps": 58330.0, "train/extr_critic_critic_opt_loss": 15883.635375110816, "train/extr_critic_mag": 8.86466138582703, "train/extr_critic_max": 8.86466138582703, "train/extr_critic_mean": 2.5792580234243516, "train/extr_critic_min": -0.19369306124693958, "train/extr_critic_std": 2.086571717093177, "train/extr_return_normed_mag": 1.4979246093871745, "train/extr_return_normed_max": 1.4979246093871745, "train/extr_return_normed_mean": 0.38425520400628976, "train/extr_return_normed_min": -0.08823883190011302, "train/extr_return_normed_std": 0.3245800844532378, "train/extr_return_rate": 0.8010070767808468, "train/extr_return_raw_mag": 9.85551637960664, "train/extr_return_raw_max": 9.85551637960664, "train/extr_return_raw_mean": 2.5959757887725288, "train/extr_return_raw_min": -0.48463799069959224, "train/extr_return_raw_std": 2.1162006297010056, "train/extr_reward_mag": 1.0595949254137405, "train/extr_reward_max": 1.0595949254137405, "train/extr_reward_mean": 0.05049573875805165, "train/extr_reward_min": -0.4042968631636166, "train/extr_reward_std": 0.2101764348170436, "train/image_loss_mean": 6.114495385623147, "train/image_loss_std": 11.183666354375529, "train/model_loss_mean": 14.136272518347342, "train/model_loss_std": 15.00802199045817, "train/model_opt_grad_norm": 48.545166624353286, "train/model_opt_grad_steps": 58275.7304964539, "train/model_opt_loss": 18985.31464012633, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1338.6524822695035, "train/policy_entropy_mag": 2.4960814722886324, "train/policy_entropy_max": 2.4960814722886324, "train/policy_entropy_mean": 0.5089408097960425, "train/policy_entropy_min": 0.07937501450168326, "train/policy_entropy_std": 0.639331930918051, "train/policy_logprob_mag": 7.43838380921817, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5096002369062275, "train/policy_logprob_min": -7.43838380921817, "train/policy_logprob_std": 1.0732598740158352, "train/policy_randomness_mag": 0.8810072219963615, "train/policy_randomness_max": 0.8810072219963615, "train/policy_randomness_mean": 0.1796337734934286, "train/policy_randomness_min": 0.02801589692896562, "train/policy_randomness_std": 0.2256561133032995, "train/post_ent_mag": 60.76123544679466, "train/post_ent_max": 60.76123544679466, "train/post_ent_mean": 43.140406885891096, "train/post_ent_min": 20.443944322301988, "train/post_ent_std": 7.728859566627665, "train/prior_ent_mag": 69.6082689001205, "train/prior_ent_max": 69.6082689001205, "train/prior_ent_mean": 56.49799961063033, "train/prior_ent_min": 40.53528753240058, "train/prior_ent_std": 4.563750527429242, "train/rep_loss_mean": 13.271141762429096, "train/rep_loss_std": 9.290095606594221, "train/reward_avg": 0.03352379748690213, "train/reward_loss_mean": 0.058791227955767446, "train/reward_loss_std": 0.24770543074354212, "train/reward_max_data": 1.0212766008174166, "train/reward_max_pred": 1.0132145670288843, "train/reward_neg_acc": 0.9917547411107003, "train/reward_neg_loss": 0.028846452402360473, "train/reward_pos_acc": 0.9734552380041028, "train/reward_pos_loss": 0.8188371518824963, "train/reward_pred": 0.03260846881209113, "train/reward_rate": 0.03787123226950355, "train_stats/sum_log_reward": 9.344898199548526, "train_stats/max_log_achievement_collect_coal": 0.45918367346938777, "train_stats/max_log_achievement_collect_drink": 5.928571428571429, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.4387755102040816, "train_stats/max_log_achievement_collect_stone": 11.010204081632653, "train_stats/max_log_achievement_collect_wood": 11.520408163265307, "train_stats/max_log_achievement_defeat_skeleton": 0.08163265306122448, "train_stats/max_log_achievement_defeat_zombie": 1.0408163265306123, "train_stats/max_log_achievement_eat_cow": 0.15306122448979592, "train_stats/max_log_achievement_make_stone_pickaxe": 0.01020408163265306, "train_stats/max_log_achievement_make_stone_sword": 0.01020408163265306, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4081632653061225, "train_stats/max_log_achievement_make_wood_sword": 1.0714285714285714, "train_stats/max_log_achievement_place_furnace": 0.01020408163265306, "train_stats/max_log_achievement_place_plant": 1.4183673469387754, "train_stats/max_log_achievement_place_stone": 8.63265306122449, "train_stats/max_log_achievement_place_table": 2.9489795918367347, "train_stats/max_log_achievement_wake_up": 1.7244897959183674, "train_stats/mean_log_entropy": 0.5718829421972742, "eval_stats/sum_log_reward": 9.16250029206276, "eval_stats/max_log_achievement_collect_coal": 0.4375, "eval_stats/max_log_achievement_collect_drink": 2.875, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 11.5625, "eval_stats/max_log_achievement_collect_wood": 9.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 8.1875, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0022927122190594673, "report/cont_loss_std": 0.07263579219579697, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 0.7751733660697937, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.176024099753704e-05, "report/cont_pred": 0.9979297518730164, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 11.879254341125488, "report/dyn_loss_std": 9.132810592651367, "report/image_loss_mean": 4.822939872741699, "report/image_loss_std": 12.667314529418945, "report/model_loss_mean": 11.999678611755371, "report/model_loss_std": 16.644607543945312, "report/post_ent_mag": 58.36601257324219, "report/post_ent_max": 58.36601257324219, "report/post_ent_mean": 43.625057220458984, "report/post_ent_min": 18.790027618408203, "report/post_ent_std": 7.922281265258789, "report/prior_ent_mag": 69.82331848144531, "report/prior_ent_max": 69.82331848144531, "report/prior_ent_mean": 55.943702697753906, "report/prior_ent_min": 39.527870178222656, "report/prior_ent_std": 4.628575801849365, "report/rep_loss_mean": 11.879254341125488, "report/rep_loss_std": 9.132810592651367, "report/reward_avg": 0.03017578274011612, "report/reward_loss_mean": 0.04689323902130127, "report/reward_loss_std": 0.24196283519268036, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0035765171051025, "report/reward_neg_acc": 0.9969696402549744, "report/reward_neg_loss": 0.018072834238409996, "report/reward_pos_acc": 0.9411764740943909, "report/reward_pos_loss": 0.8860756754875183, "report/reward_pred": 0.02755715698003769, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0002884067362174392, "eval/cont_loss_std": 0.005020268261432648, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00010180785466218367, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.000289322342723608, "eval/cont_pred": 0.9948418140411377, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.705034255981445, "eval/dyn_loss_std": 10.137373924255371, "eval/image_loss_mean": 8.12234115600586, "eval/image_loss_std": 11.61135196685791, "eval/model_loss_mean": 19.49923324584961, "eval/model_loss_std": 15.463516235351562, "eval/post_ent_mag": 56.85060119628906, "eval/post_ent_max": 56.85060119628906, "eval/post_ent_mean": 40.370887756347656, "eval/post_ent_min": 21.562362670898438, "eval/post_ent_std": 6.848193645477295, "eval/prior_ent_mag": 69.82331848144531, "eval/prior_ent_max": 69.82331848144531, "eval/prior_ent_mean": 56.96063995361328, "eval/prior_ent_min": 43.97483825683594, "eval/prior_ent_std": 4.631745338439941, "eval/rep_loss_mean": 18.705034255981445, "eval/rep_loss_std": 10.137373924255371, "eval/reward_avg": 0.04912109673023224, "eval/reward_loss_mean": 0.15358269214630127, "eval/reward_loss_std": 0.7884222269058228, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0053582191467285, "eval/reward_neg_acc": 0.9896801114082336, "eval/reward_neg_loss": 0.06028925999999046, "eval/reward_pos_acc": 0.8181818127632141, "eval/reward_pos_loss": 1.797243356704712, "eval/reward_pred": 0.039843931794166565, "eval/reward_rate": 0.0537109375, "replay/size": 945537.0, "replay/inserts": 22480.0, "replay/samples": 22480.0, "replay/insert_wait_avg": 1.3947592935528194e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.428966447551903e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2720730984230607e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.340030670166, "timer/env.step_count": 2810.0, "timer/env.step_total": 236.57148838043213, "timer/env.step_frac": 0.23649107416199655, "timer/env.step_avg": 0.08418914177239578, "timer/env.step_min": 0.021995067596435547, "timer/env.step_max": 3.336054801940918, "timer/replay._sample_count": 22480.0, "timer/replay._sample_total": 11.322543382644653, "timer/replay._sample_frac": 0.011318694679307444, "timer/replay._sample_avg": 0.0005036718586585699, "timer/replay._sample_min": 0.0004184246063232422, "timer/replay._sample_max": 0.026026010513305664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3417.0, "timer/agent.policy_total": 55.72298502922058, "timer/agent.policy_frac": 0.055704043945826724, "timer/agent.policy_avg": 0.01630757536705314, "timer/agent.policy_min": 0.009433984756469727, "timer/agent.policy_max": 0.10447955131530762, "timer/dataset_train_count": 1405.0, "timer/dataset_train_total": 0.1512453556060791, "timer/dataset_train_frac": 0.00015119394502762632, "timer/dataset_train_avg": 0.00010764793993315238, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.0039708614349365234, "timer/agent.train_count": 1405.0, "timer/agent.train_total": 630.158299446106, "timer/agent.train_frac": 0.629944099131911, "timer/agent.train_avg": 0.4485112451573708, "timer/agent.train_min": 0.43323755264282227, "timer/agent.train_max": 1.8326420783996582, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4778273105621338, "timer/agent.report_frac": 0.0004776648898495235, "timer/agent.report_avg": 0.2389136552810669, "timer/agent.report_min": 0.23343110084533691, "timer/agent.report_max": 0.24439620971679688, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.169889242487306e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 22.47203266663516}
{"step": 946184, "time": 43398.41749548912, "episode/length": 145.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 946384, "time": 43406.84130978584, "episode/length": 189.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9578947368421052, "episode/intrinsic_return": 0.0}
{"step": 946456, "time": 43410.55563092232, "episode/length": 33.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 946568, "time": 43415.782591342926, "episode/length": 293.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 946816, "time": 43425.653898477554, "episode/length": 217.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 946920, "time": 43430.35084652901, "episode/length": 200.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 947104, "time": 43438.81085419655, "episode/length": 152.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 947192, "time": 43443.555349349976, "episode/length": 234.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 947560, "time": 43458.01718854904, "episode/length": 137.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 947760, "time": 43467.046405792236, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 947984, "time": 43476.627145290375, "episode/length": 199.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 948168, "time": 43484.06466627121, "episode/length": 155.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 948288, "time": 43489.7654440403, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 948936, "time": 43513.26896190643, "episode/length": 217.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 948992, "time": 43516.87461566925, "episode/length": 235.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 949200, "time": 43525.28714489937, "episode/length": 433.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9930875576036866, "episode/intrinsic_return": 0.0}
{"step": 949360, "time": 43532.21851325035, "episode/length": 224.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 949592, "time": 43541.257564783096, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 949976, "time": 43555.527567863464, "episode/length": 210.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.985781990521327, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 43574.362412691116, "eval_episode/length": 52.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 950040, "time": 43578.776403188705, "eval_episode/length": 124.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.992}
{"step": 950040, "time": 43582.7801322937, "eval_episode/length": 185.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.967741935483871}
{"step": 950040, "time": 43584.57438850403, "eval_episode/length": 190.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 950040, "time": 43586.50398564339, "eval_episode/length": 197.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 950040, "time": 43589.687108278275, "eval_episode/length": 236.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 950040, "time": 43591.26759672165, "eval_episode/length": 185.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.978494623655914}
{"step": 950040, "time": 43598.76756095886, "eval_episode/length": 145.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.958904109589041}
{"step": 950056, "time": 43599.30887675285, "episode/length": 258.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 950088, "time": 43601.92540597916, "episode/length": 239.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 950632, "time": 43622.91233730316, "episode/length": 178.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 950840, "time": 43631.322910785675, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 950864, "time": 43633.80962896347, "episode/length": 187.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 951384, "time": 43652.43646001816, "episode/length": 305.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 951672, "time": 43663.64371800423, "episode/length": 197.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 952424, "time": 43691.438945531845, "episode/length": 197.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 952424, "time": 43691.449709415436, "episode/length": 295.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 952448, "time": 43696.71768498421, "episode/length": 197.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 953608, "time": 43737.4337952137, "episode/length": 576.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9861351819757366, "episode/intrinsic_return": 0.0}
{"step": 953616, "time": 43739.532136917114, "episode/length": 454.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9978021978021978, "episode/intrinsic_return": 0.0}
{"step": 953704, "time": 43743.83750605583, "episode/length": 383.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 954048, "time": 43757.95417404175, "episode/length": 202.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 954160, "time": 43763.818283081055, "episode/length": 346.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9855907780979827, "episode/intrinsic_return": 0.0}
{"step": 954168, "time": 43765.48730683327, "episode/length": 214.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 954952, "time": 43792.85609984398, "episode/length": 315.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 955080, "time": 43799.35277724266, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 955096, "time": 43801.88078069687, "episode/length": 427.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 955392, "time": 43813.98333191872, "episode/length": 153.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 955632, "time": 43823.54902076721, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 955640, "time": 43825.08624410629, "episode/length": 253.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 955704, "time": 43828.82546758652, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 956040, "time": 43841.46771097183, "episode/length": 135.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 956224, "time": 43849.33895397186, "episode/length": 314.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 956520, "time": 43860.56465315819, "episode/length": 140.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 956568, "time": 43863.692190647125, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 956984, "time": 43878.966582775116, "episode/length": 159.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 957312, "time": 43891.63971447945, "episode/length": 208.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 957488, "time": 43899.02620387077, "episode/length": 300.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 957712, "time": 43907.979538202286, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 957760, "time": 43911.15513896942, "episode/length": 154.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 958024, "time": 43921.42831516266, "episode/length": 247.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 958200, "time": 43929.61036539078, "episode/length": 203.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9558823529411765, "episode/intrinsic_return": 0.0}
{"step": 958656, "time": 43948.82495188713, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 959008, "time": 43961.954964637756, "episode/length": 421.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9976303317535545, "episode/intrinsic_return": 0.0}
{"step": 959040, "time": 43964.58920645714, "episode/length": 256.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 959288, "time": 43974.11169242859, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 959864, "time": 43994.94495224953, "episode/length": 296.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 959920, "time": 43998.55155086517, "episode/length": 78.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 44017.76161766052, "eval_episode/length": 41.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8809523809523809}
{"step": 960024, "time": 44024.872973918915, "eval_episode/length": 179.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 960024, "time": 44027.695722818375, "eval_episode/length": 209.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 960024, "time": 44029.76542639732, "eval_episode/length": 222.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 960024, "time": 44031.71753072739, "eval_episode/length": 189.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 960024, "time": 44033.39041304588, "eval_episode/length": 235.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 960024, "time": 44035.298771858215, "eval_episode/length": 243.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9959016393442623}
{"step": 960024, "time": 44043.075278759, "eval_episode/length": 396.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9899244332493703}
{"step": 960240, "time": 44050.45681262016, "episode/length": 197.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 960264, "time": 44052.58063840866, "episode/length": 49.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 960280, "time": 44054.76089882851, "episode/length": 44.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 960512, "time": 44064.155517578125, "episode/length": 343.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.997093023255814, "episode/intrinsic_return": 0.0}
{"step": 960808, "time": 44075.33994317055, "episode/length": 386.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974160206718347, "episode/intrinsic_return": 0.0}
{"step": 960960, "time": 44082.24136304855, "episode/length": 239.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 961360, "time": 44096.99412059784, "episode/length": 394.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9924050632911392, "episode/intrinsic_return": 0.0}
{"step": 961584, "time": 44105.95231342316, "episode/length": 321.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9875776397515528, "episode/intrinsic_return": 0.0}
{"step": 961840, "time": 44116.07164335251, "episode/length": 199.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 961992, "time": 44122.48292374611, "episode/length": 215.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 962648, "time": 44146.950803518295, "episode/length": 266.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9700374531835206, "episode/intrinsic_return": 0.0}
{"step": 962928, "time": 44158.85634016991, "episode/length": 195.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 963000, "time": 44163.092386484146, "episode/length": 254.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 963056, "time": 44167.2236597538, "episode/length": 280.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9786476868327402, "episode/intrinsic_return": 0.0}
{"step": 963112, "time": 44170.99344420433, "episode/length": 139.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 963240, "time": 44176.89713263512, "episode/length": 369.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9972972972972973, "episode/intrinsic_return": 0.0}
{"step": 963264, "time": 44179.47273159027, "episode/length": 209.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 963440, "time": 44186.93528723717, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 964560, "time": 44225.44180583954, "episode/length": 203.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 964584, "time": 44227.63539934158, "episode/length": 190.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 964648, "time": 44231.394456624985, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 964928, "time": 44242.479244470596, "episode/length": 284.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 965024, "time": 44247.25951957703, "episode/length": 252.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9920948616600791, "episode/intrinsic_return": 0.0}
{"step": 965200, "time": 44254.59203290939, "episode/length": 219.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 965504, "time": 44266.242765665054, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 965912, "time": 44281.10835123062, "episode/length": 349.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 965920, "time": 44283.15214538574, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 966264, "time": 44295.9264588356, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 966312, "time": 44298.91877770424, "episode/length": 207.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 966496, "time": 44306.829693078995, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 966520, "time": 44309.02209019661, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 966624, "time": 44314.173431158066, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 967504, "time": 44347.145149469376, "episode/length": 249.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 967608, "time": 44352.492901325226, "episode/length": 167.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 967760, "time": 44359.98349118233, "episode/length": 180.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 967856, "time": 44365.240858078, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 967896, "time": 44368.6725859642, "episode/length": 171.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 967936, "time": 44372.00584888458, "episode/length": 251.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 968208, "time": 44382.56156158447, "episode/length": 286.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 968489, "time": 44394.053055524826, "train_stats/sum_log_reward": 9.548979817604533, "train_stats/max_log_achievement_collect_coal": 0.6122448979591837, "train_stats/max_log_achievement_collect_drink": 5.653061224489796, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.3265306122448979, "train_stats/max_log_achievement_collect_stone": 13.418367346938776, "train_stats/max_log_achievement_collect_wood": 10.428571428571429, "train_stats/max_log_achievement_defeat_skeleton": 0.02040816326530612, "train_stats/max_log_achievement_defeat_zombie": 1.163265306122449, "train_stats/max_log_achievement_eat_cow": 0.17346938775510204, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.02040816326530612, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2755102040816326, "train_stats/max_log_achievement_make_wood_sword": 1.153061224489796, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.3265306122448979, "train_stats/max_log_achievement_place_stone": 11.23469387755102, "train_stats/max_log_achievement_place_table": 2.663265306122449, "train_stats/max_log_achievement_wake_up": 1.6224489795918366, "train_stats/mean_log_entropy": 0.5793102134247216, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.669796752929687, "train/action_min": 0.0, "train/action_std": 3.401360557760511, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.038604482728987935, "train/actor_opt_grad_steps": 59735.0, "train/actor_opt_loss": -5.206128922397537, "train/adv_mag": 0.4553406183208738, "train/adv_max": 0.43265863827296663, "train/adv_mean": 0.003051166542770391, "train/adv_min": -0.35661581243787494, "train/adv_std": 0.05438797255711896, "train/cont_avg": 0.9950334821428571, "train/cont_loss_mean": 0.00014004455768891992, "train/cont_loss_std": 0.00410499342760074, "train/cont_neg_acc": 0.992380952835083, "train/cont_neg_loss": 0.01906702015771121, "train/cont_pos_acc": 0.999971911736897, "train/cont_pos_loss": 5.313867878606564e-05, "train/cont_pred": 0.9950388512441091, "train/cont_rate": 0.9950334821428571, "train/dyn_loss_mean": 13.35044961656843, "train/dyn_loss_std": 9.359422881262644, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.919760850071907, "train/extr_critic_critic_opt_grad_steps": 59735.0, "train/extr_critic_critic_opt_loss": 16106.496428571429, "train/extr_critic_mag": 8.95115362576076, "train/extr_critic_max": 8.95115362576076, "train/extr_critic_mean": 2.5474628712449756, "train/extr_critic_min": -0.1990048246724265, "train/extr_critic_std": 2.100711123432432, "train/extr_return_normed_mag": 1.5134069034031459, "train/extr_return_normed_max": 1.5134069034031459, "train/extr_return_normed_mean": 0.37986866576331, "train/extr_return_normed_min": -0.09025295238409724, "train/extr_return_normed_std": 0.3246359437704086, "train/extr_return_rate": 0.7888649025133678, "train/extr_return_raw_mag": 10.012458617346628, "train/extr_return_raw_max": 10.012458617346628, "train/extr_return_raw_mean": 2.5675192356109617, "train/extr_return_raw_min": -0.5198738886841706, "train/extr_return_raw_std": 2.132283173288618, "train/extr_reward_mag": 1.0502151046480452, "train/extr_reward_max": 1.0502151046480452, "train/extr_reward_mean": 0.05152216495147773, "train/extr_reward_min": -0.4232254079410008, "train/extr_reward_std": 0.21224951818585397, "train/image_loss_mean": 6.136834023680006, "train/image_loss_std": 11.289925333431789, "train/model_loss_mean": 14.206300517490932, "train/model_loss_std": 15.153743839263916, "train/model_opt_grad_norm": 53.73682577950614, "train/model_opt_grad_steps": 59679.50714285715, "train/model_opt_loss": 18940.579303850445, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1330.357142857143, "train/policy_entropy_mag": 2.5037897706031798, "train/policy_entropy_max": 2.5037897706031798, "train/policy_entropy_mean": 0.511215387923377, "train/policy_entropy_min": 0.07937501546527659, "train/policy_entropy_std": 0.6438609921506473, "train/policy_logprob_mag": 7.438383793830871, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5114923230239323, "train/policy_logprob_min": -7.438383793830871, "train/policy_logprob_std": 1.0744461004223143, "train/policy_randomness_mag": 0.8837279162236622, "train/policy_randomness_max": 0.8837279162236622, "train/policy_randomness_mean": 0.1804365994674819, "train/policy_randomness_min": 0.028015897236764432, "train/policy_randomness_std": 0.22725467532873153, "train/post_ent_mag": 60.45357614244733, "train/post_ent_max": 60.45357614244733, "train/post_ent_mean": 43.086122267586845, "train/post_ent_min": 20.232350363050188, "train/post_ent_std": 7.763878066199166, "train/prior_ent_mag": 69.66714085170202, "train/prior_ent_max": 69.66714085170202, "train/prior_ent_mean": 56.49313956669399, "train/prior_ent_min": 40.464867564610074, "train/prior_ent_std": 4.561267180102212, "train/rep_loss_mean": 13.35044961656843, "train/rep_loss_std": 9.359422881262644, "train/reward_avg": 0.03372558590157756, "train/reward_loss_mean": 0.05905674501721348, "train/reward_loss_std": 0.2518866830638477, "train/reward_max_data": 1.0228571483067104, "train/reward_max_pred": 1.014671117067337, "train/reward_neg_acc": 0.9927320416484561, "train/reward_neg_loss": 0.02899767646033849, "train/reward_pos_acc": 0.9731124771492822, "train/reward_pos_loss": 0.8185629189014435, "train/reward_pred": 0.032894341434751236, "train/reward_rate": 0.03818359375, "eval_stats/sum_log_reward": 8.912500277161598, "eval_stats/max_log_achievement_collect_coal": 0.4375, "eval_stats/max_log_achievement_collect_drink": 3.75, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 7.625, "eval_stats/max_log_achievement_collect_wood": 8.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 1.1875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.9375, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 6.5, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 8.492918823321816e-06, "report/cont_loss_std": 0.0001503718231106177, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0010157030774280429, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.5603012570863939e-06, "report/cont_pred": 0.9931695461273193, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.966211318969727, "report/dyn_loss_std": 9.682852745056152, "report/image_loss_mean": 5.409340858459473, "report/image_loss_std": 11.192264556884766, "report/model_loss_mean": 13.253711700439453, "report/model_loss_std": 15.496459007263184, "report/post_ent_mag": 58.86273193359375, "report/post_ent_max": 58.86273193359375, "report/post_ent_mean": 43.08433532714844, "report/post_ent_min": 23.44283676147461, "report/post_ent_std": 7.241976261138916, "report/prior_ent_mag": 69.62849426269531, "report/prior_ent_max": 69.62849426269531, "report/prior_ent_mean": 55.910057067871094, "report/prior_ent_min": 37.63361358642578, "report/prior_ent_std": 4.837430953979492, "report/rep_loss_mean": 12.966211318969727, "report/rep_loss_std": 9.682852745056152, "report/reward_avg": 0.03662109375, "report/reward_loss_mean": 0.06463618576526642, "report/reward_loss_std": 0.23595592379570007, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002425193786621, "report/reward_neg_acc": 0.9908162951469421, "report/reward_neg_loss": 0.03506835177540779, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7231923937797546, "report/reward_pred": 0.037703756242990494, "report/reward_rate": 0.04296875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.00033716694451868534, "eval/cont_loss_std": 0.010674413293600082, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.17166687548160553, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.8837232573787333e-06, "eval/cont_pred": 0.9983292818069458, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.279787063598633, "eval/dyn_loss_std": 10.520307540893555, "eval/image_loss_mean": 11.59280776977539, "eval/image_loss_std": 16.653398513793945, "eval/model_loss_mean": 22.671188354492188, "eval/model_loss_std": 20.680374145507812, "eval/post_ent_mag": 62.911399841308594, "eval/post_ent_max": 62.911399841308594, "eval/post_ent_mean": 41.864540100097656, "eval/post_ent_min": 18.841583251953125, "eval/post_ent_std": 7.732283115386963, "eval/prior_ent_mag": 69.62849426269531, "eval/prior_ent_max": 69.62849426269531, "eval/prior_ent_mean": 57.77165603637695, "eval/prior_ent_min": 37.21508026123047, "eval/prior_ent_std": 4.650893211364746, "eval/rep_loss_mean": 18.279787063598633, "eval/rep_loss_std": 10.520307540893555, "eval/reward_avg": 0.02636718563735485, "eval/reward_loss_mean": 0.1101728081703186, "eval/reward_loss_std": 0.6930096745491028, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0018019676208496, "eval/reward_neg_acc": 0.9879153966903687, "eval/reward_neg_loss": 0.05351819843053818, "eval/reward_pos_acc": 0.774193525314331, "eval/reward_pos_loss": 1.92494797706604, "eval/reward_pred": 0.022777043282985687, "eval/reward_rate": 0.0302734375, "replay/size": 967985.0, "replay/inserts": 22448.0, "replay/samples": 22448.0, "replay/insert_wait_avg": 1.3819101106585218e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.314168206811037e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6256.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1779920524343506e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1806018352509, "timer/env.step_count": 2806.0, "timer/env.step_total": 241.5925874710083, "timer/env.step_frac": 0.2415489632849361, "timer/env.step_avg": 0.08609857001817829, "timer/env.step_min": 0.022400617599487305, "timer/env.step_max": 4.23696494102478, "timer/replay._sample_count": 22448.0, "timer/replay._sample_total": 11.274709224700928, "timer/replay._sample_frac": 0.011272673359204071, "timer/replay._sample_avg": 0.0005022589640369266, "timer/replay._sample_min": 0.0003883838653564453, "timer/replay._sample_max": 0.024942874908447266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3588.0, "timer/agent.policy_total": 57.225301027297974, "timer/agent.policy_frac": 0.05721496789909158, "timer/agent.policy_avg": 0.01594908055387346, "timer/agent.policy_min": 0.009356260299682617, "timer/agent.policy_max": 0.1476290225982666, "timer/dataset_train_count": 1403.0, "timer/dataset_train_total": 0.14967894554138184, "timer/dataset_train_frac": 0.0001496519181303187, "timer/dataset_train_avg": 0.0001066849219824532, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.0009098052978515625, "timer/agent.train_count": 1403.0, "timer/agent.train_total": 629.2909202575684, "timer/agent.train_frac": 0.6291772896843532, "timer/agent.train_avg": 0.4485323736689725, "timer/agent.train_min": 0.4313375949859619, "timer/agent.train_max": 1.6296088695526123, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4759833812713623, "timer/agent.report_frac": 0.00047589743332151325, "timer/agent.report_avg": 0.23799169063568115, "timer/agent.report_min": 0.23228931427001953, "timer/agent.report_max": 0.24369406700134277, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.122719417372718e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 22.443623077621954}
{"step": 969200, "time": 44417.78262209892, "episode/length": 211.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 969216, "time": 44419.925726652145, "episode/length": 200.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 969384, "time": 44426.89475464821, "episode/length": 180.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 969392, "time": 44428.977455854416, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 969408, "time": 44430.993755340576, "episode/length": 149.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9533333333333334, "episode/intrinsic_return": 0.0}
{"step": 969448, "time": 44433.76392054558, "episode/length": 352.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9886685552407932, "episode/intrinsic_return": 0.0}
{"step": 969808, "time": 44447.35219025612, "episode/length": 238.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 969832, "time": 44449.388360500336, "episode/length": 246.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 44473.313334941864, "eval_episode/length": 90.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.945054945054945}
{"step": 970008, "time": 44478.69609999657, "eval_episode/length": 134.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9555555555555556}
{"step": 970008, "time": 44480.95316505432, "eval_episode/length": 151.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 970008, "time": 44482.95982003212, "eval_episode/length": 163.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9634146341463414}
{"step": 970008, "time": 44484.93668293953, "eval_episode/length": 173.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 970008, "time": 44487.61405134201, "eval_episode/length": 194.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 970008, "time": 44490.49129962921, "eval_episode/length": 227.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9780701754385965}
{"step": 970008, "time": 44494.35334229469, "eval_episode/length": 147.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9662162162162162}
{"step": 970688, "time": 44517.10560798645, "episode/length": 162.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 970952, "time": 44527.296072006226, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 970952, "time": 44527.30606985092, "episode/length": 218.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 971016, "time": 44532.671283721924, "episode/length": 224.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 971224, "time": 44541.05987453461, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 971352, "time": 44546.865342378616, "episode/length": 237.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 971800, "time": 44563.23911976814, "episode/length": 105.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.0}
{"step": 971992, "time": 44571.116050720215, "episode/length": 324.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9907692307692307, "episode/intrinsic_return": 0.0}
{"step": 972032, "time": 44574.290731430054, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 972032, "time": 44574.303018569946, "episode/length": 274.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9781818181818182, "episode/intrinsic_return": 0.0}
{"step": 972608, "time": 44597.01123189926, "episode/length": 71.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 972976, "time": 44611.5845952034, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 973336, "time": 44624.82685446739, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 973440, "time": 44630.12564969063, "episode/length": 260.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 973896, "time": 44646.69120264053, "episode/length": 367.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9972826086956522, "episode/intrinsic_return": 0.0}
{"step": 973976, "time": 44650.94730567932, "episode/length": 242.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 974672, "time": 44675.65416765213, "episode/length": 257.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 974680, "time": 44677.3189535141, "episode/length": 212.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 974872, "time": 44686.70167708397, "episode/length": 481.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9896265560165975, "episode/intrinsic_return": 0.0}
{"step": 975080, "time": 44695.09643578529, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 975232, "time": 44701.973120212555, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9906759906759907, "episode/intrinsic_return": 0.0}
{"step": 975672, "time": 44717.74538779259, "episode/length": 278.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.974910394265233, "episode/intrinsic_return": 0.0}
{"step": 975784, "time": 44722.960163116455, "episode/length": 235.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 975936, "time": 44729.89772129059, "episode/length": 157.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 976448, "time": 44749.24649596214, "episode/length": 220.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 976568, "time": 44754.57468509674, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 976728, "time": 44761.61841058731, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 976904, "time": 44769.01729130745, "episode/length": 365.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 977216, "time": 44781.17203164101, "episode/length": 247.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 977760, "time": 44800.8803756237, "episode/length": 246.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 978256, "time": 44819.01909446716, "episode/length": 225.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 978312, "time": 44822.23210835457, "episode/length": 296.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 978576, "time": 44832.82764029503, "episode/length": 208.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 978640, "time": 44836.571155786514, "episode/length": 238.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 979056, "time": 44852.65146422386, "episode/length": 422.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9952718676122931, "episode/intrinsic_return": 0.0}
{"step": 979440, "time": 44866.76142644882, "episode/length": 277.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9748201438848921, "episode/intrinsic_return": 0.0}
{"step": 979728, "time": 44877.85806393623, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 980032, "time": 44889.59877872467, "episode/length": 181.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 44911.45000433922, "eval_episode/length": 29.0, "eval_episode/score": 1.1000000163912773, "eval_episode/reward_rate": 0.9}
{"step": 980096, "time": 44911.457528829575, "eval_episode/length": 29.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.8666666666666667}
{"step": 980096, "time": 44918.6684653759, "eval_episode/length": 65.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9848484848484849}
{"step": 980096, "time": 44924.76635766029, "eval_episode/length": 181.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 980096, "time": 44927.145277023315, "eval_episode/length": 186.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 980096, "time": 44929.562935590744, "eval_episode/length": 196.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 980096, "time": 44932.11494684219, "eval_episode/length": 207.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 980096, "time": 44934.95096874237, "eval_episode/length": 226.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 980232, "time": 44939.28678512573, "episode/length": 457.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9847161572052402, "episode/intrinsic_return": 0.0}
{"step": 980264, "time": 44941.87585091591, "episode/length": 202.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 980648, "time": 44955.83958172798, "episode/length": 198.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 980920, "time": 44966.352613687515, "episode/length": 394.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9848101265822785, "episode/intrinsic_return": 0.0}
{"step": 981096, "time": 44973.66742038727, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 981152, "time": 44977.827755212784, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 981784, "time": 45000.596416950226, "episode/length": 218.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 982104, "time": 45012.73709774017, "episode/length": 229.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 982216, "time": 45017.91552615166, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 982232, "time": 45020.01540231705, "episode/length": 496.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9979879275653923, "episode/intrinsic_return": 0.0}
{"step": 982504, "time": 45030.495413303375, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 982560, "time": 45034.21821641922, "episode/length": 182.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 982640, "time": 45038.39809823036, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 983624, "time": 45074.39582514763, "episode/length": 175.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 983872, "time": 45084.471237659454, "episode/length": 220.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 983984, "time": 45089.74592804909, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 984040, "time": 45093.04865312576, "episode/length": 281.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.975177304964539, "episode/intrinsic_return": 0.0}
{"step": 984272, "time": 45102.63497591019, "episode/length": 49.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 984352, "time": 45106.75522041321, "episode/length": 213.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 984800, "time": 45123.366106987, "episode/length": 320.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 984944, "time": 45129.722157001495, "episode/length": 297.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 985256, "time": 45141.08058667183, "episode/length": 627.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9904458598726115, "episode/intrinsic_return": 0.0}
{"step": 985288, "time": 45143.63371348381, "episode/length": 155.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 985512, "time": 45152.618307352066, "episode/length": 190.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 986048, "time": 45172.14326667786, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 986144, "time": 45176.90009903908, "episode/length": 314.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 986160, "time": 45179.067203998566, "episode/length": 235.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 986616, "time": 45195.45163202286, "episode/length": 165.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 986656, "time": 45198.49158382416, "episode/length": 142.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 986856, "time": 45206.52156448364, "episode/length": 199.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 987256, "time": 45221.248700380325, "episode/length": 288.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 987416, "time": 45228.17372751236, "episode/length": 156.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 987664, "time": 45238.201580524445, "episode/length": 201.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 987704, "time": 45240.93183231354, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 988392, "time": 45265.71443653107, "episode/length": 504.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.998019801980198, "episode/intrinsic_return": 0.0}
{"step": 988920, "time": 45284.76385521889, "episode/length": 282.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9681978798586572, "episode/intrinsic_return": 0.0}
{"step": 988952, "time": 45287.37179517746, "episode/length": 191.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 989000, "time": 45290.37121319771, "episode/length": 217.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 989136, "time": 45296.74959945679, "episode/length": 178.0, "episode/score": 11.100000038743019, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 989448, "time": 45308.38065767288, "episode/length": 222.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 989480, "time": 45310.91230893135, "episode/length": 357.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9860335195530726, "episode/intrinsic_return": 0.0}
{"step": 990000, "time": 45329.97248625755, "episode/length": 392.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.989821882951654, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 45353.72459769249, "eval_episode/length": 160.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 990080, "time": 45355.8809132576, "eval_episode/length": 173.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 990080, "time": 45359.080246686935, "eval_episode/length": 210.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.966824644549763}
{"step": 990080, "time": 45360.80285859108, "eval_episode/length": 215.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 990080, "time": 45363.23217225075, "eval_episode/length": 237.0, "eval_episode/score": 10.100000061094761, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 990080, "time": 45367.1956140995, "eval_episode/length": 297.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9731543624161074}
{"step": 990080, "time": 45370.512706279755, "eval_episode/length": 339.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9852941176470589}
{"step": 990080, "time": 45372.345687389374, "eval_episode/length": 180.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 990376, "time": 45382.00141787529, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 990448, "time": 45386.24004864693, "episode/length": 180.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 990584, "time": 45392.096361637115, "episode/length": 137.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 990585, "time": 45394.5484919548, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.634827987007473, "train/action_min": 0.0, "train/action_std": 3.42962544379027, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.037992144138484764, "train/actor_opt_grad_steps": 61125.0, "train/actor_opt_loss": -9.87987797934076, "train/adv_mag": 0.46441794348799664, "train/adv_max": 0.430076507554538, "train/adv_mean": 0.0020368380744490633, "train/adv_min": -0.38094834756592044, "train/adv_std": 0.05290763142208258, "train/cont_avg": 0.9949402740036232, "train/cont_loss_mean": 0.00010671441414506657, "train/cont_loss_std": 0.0031770194847434013, "train/cont_neg_acc": 0.9969806766164475, "train/cont_neg_loss": 0.014530589973212731, "train/cont_pos_acc": 0.999985713025798, "train/cont_pos_loss": 4.366212530510191e-05, "train/cont_pred": 0.994946934606718, "train/cont_rate": 0.9949402740036232, "train/dyn_loss_mean": 13.33535085208174, "train/dyn_loss_std": 9.308426532192506, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.875238378410754, "train/extr_critic_critic_opt_grad_steps": 61125.0, "train/extr_critic_critic_opt_loss": 15938.773076596468, "train/extr_critic_mag": 9.006014409272566, "train/extr_critic_max": 9.006014409272566, "train/extr_critic_mean": 2.5639873691227124, "train/extr_critic_min": -0.1895677291828653, "train/extr_critic_std": 2.1167483485263325, "train/extr_return_normed_mag": 1.499309563982314, "train/extr_return_normed_max": 1.499309563982314, "train/extr_return_normed_mean": 0.3792189091875933, "train/extr_return_normed_min": -0.08321320597568284, "train/extr_return_normed_std": 0.3245096329761588, "train/extr_return_rate": 0.793258459671684, "train/extr_return_raw_mag": 9.98188150792882, "train/extr_return_raw_max": 9.98188150792882, "train/extr_return_raw_mean": 2.5774746900019436, "train/extr_return_raw_min": -0.4790743249266044, "train/extr_return_raw_std": 2.1452319319697395, "train/extr_reward_mag": 1.0463150791499927, "train/extr_reward_max": 1.0463150791499927, "train/extr_reward_mean": 0.05031153343725896, "train/extr_reward_min": -0.399867398151453, "train/extr_reward_std": 0.20980347196261087, "train/image_loss_mean": 6.172768943551658, "train/image_loss_std": 11.790715117385423, "train/model_loss_mean": 14.23339665454367, "train/model_loss_std": 15.567266844320988, "train/model_opt_grad_norm": 50.41257932064307, "train/model_opt_grad_steps": 61067.55072463768, "train/model_opt_loss": 12016.727744282156, "train/model_opt_model_opt_grad_overflow": 0.007246376811594203, "train/model_opt_model_opt_grad_scale": 833.3333333333334, "train/policy_entropy_mag": 2.5153098417365034, "train/policy_entropy_max": 2.5153098417365034, "train/policy_entropy_mean": 0.5136219606451367, "train/policy_entropy_min": 0.07937501468088316, "train/policy_entropy_std": 0.6392707675695419, "train/policy_logprob_mag": 7.438383831494097, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5134907684464386, "train/policy_logprob_min": -7.438383831494097, "train/policy_logprob_std": 1.0776651903339054, "train/policy_randomness_mag": 0.887793990580932, "train/policy_randomness_max": 0.887793990580932, "train/policy_randomness_mean": 0.18128601472446884, "train/policy_randomness_min": 0.028015896988411743, "train/policy_randomness_std": 0.22563452532757883, "train/post_ent_mag": 60.376058771990344, "train/post_ent_max": 60.376058771990344, "train/post_ent_mean": 43.08851219951243, "train/post_ent_min": 19.945832819178484, "train/post_ent_std": 7.7540983531786045, "train/prior_ent_mag": 69.73322970625283, "train/prior_ent_max": 69.73322970625283, "train/prior_ent_mean": 56.49793779677239, "train/prior_ent_min": 40.55133436728215, "train/prior_ent_std": 4.557696361472641, "train/rep_loss_mean": 13.33535085208174, "train/rep_loss_std": 9.308426532192506, "train/reward_avg": 0.03267804569686237, "train/reward_loss_mean": 0.059310624834851944, "train/reward_loss_std": 0.2538436952492465, "train/reward_max_data": 1.0268116005952808, "train/reward_max_pred": 1.0185124148493228, "train/reward_neg_acc": 0.9921402404273766, "train/reward_neg_loss": 0.02979769405193519, "train/reward_pos_acc": 0.9751663510350214, "train/reward_pos_loss": 0.8228772070960723, "train/reward_pred": 0.03181964468777827, "train/reward_rate": 0.03710229846014493, "train_stats/sum_log_reward": 9.605494750725043, "train_stats/max_log_achievement_collect_coal": 0.4725274725274725, "train_stats/max_log_achievement_collect_drink": 5.175824175824176, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.7362637362637363, "train_stats/max_log_achievement_collect_stone": 12.0, "train_stats/max_log_achievement_collect_wood": 11.087912087912088, "train_stats/max_log_achievement_defeat_skeleton": 0.08791208791208792, "train_stats/max_log_achievement_defeat_zombie": 1.3186813186813187, "train_stats/max_log_achievement_eat_cow": 0.18681318681318682, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.01098901098901099, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3406593406593406, "train_stats/max_log_achievement_make_wood_sword": 1.1318681318681318, "train_stats/max_log_achievement_place_furnace": 0.03296703296703297, "train_stats/max_log_achievement_place_plant": 1.7362637362637363, "train_stats/max_log_achievement_place_stone": 9.87912087912088, "train_stats/max_log_achievement_place_table": 3.2857142857142856, "train_stats/max_log_achievement_wake_up": 1.5604395604395604, "train_stats/mean_log_entropy": 0.5776485055685043, "eval_stats/sum_log_reward": 8.850000212589899, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 3.2083333333333335, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.0416666666666667, "eval_stats/max_log_achievement_collect_stone": 7.583333333333333, "eval_stats/max_log_achievement_collect_wood": 9.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 1.1666666666666667, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.0416666666666667, "eval_stats/max_log_achievement_place_stone": 6.25, "eval_stats/max_log_achievement_place_table": 2.5833333333333335, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 3.690233643283136e-05, "report/cont_loss_std": 0.0011478941887617111, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.1912401532754302e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.697576903505251e-05, "report/cont_pred": 0.9970341324806213, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.846116065979004, "report/dyn_loss_std": 9.62621784210205, "report/image_loss_mean": 7.435080528259277, "report/image_loss_std": 11.429302215576172, "report/model_loss_mean": 15.818265914916992, "report/model_loss_std": 15.704322814941406, "report/post_ent_mag": 59.807796478271484, "report/post_ent_max": 59.807796478271484, "report/post_ent_mean": 42.493499755859375, "report/post_ent_min": 18.914257049560547, "report/post_ent_std": 7.337088584899902, "report/prior_ent_mag": 69.79045867919922, "report/prior_ent_max": 69.79045867919922, "report/prior_ent_mean": 56.438758850097656, "report/prior_ent_min": 39.88262176513672, "report/prior_ent_std": 4.84235954284668, "report/rep_loss_mean": 13.846116065979004, "report/rep_loss_std": 9.62621784210205, "report/reward_avg": 0.02978515625, "report/reward_loss_mean": 0.07548016309738159, "report/reward_loss_std": 0.33876365423202515, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.005392074584961, "report/reward_neg_acc": 0.996966540813446, "report/reward_neg_loss": 0.03436840698122978, "report/reward_pos_acc": 0.8571428656578064, "report/reward_pos_loss": 1.2371808290481567, "report/reward_pred": 0.021653130650520325, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 5.66642256671912e-06, "eval/cont_loss_std": 0.0001333961117779836, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004191265441477299, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.5749284330013325e-06, "eval/cont_pred": 0.9990260004997253, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 18.432153701782227, "eval/dyn_loss_std": 10.606980323791504, "eval/image_loss_mean": 11.479257583618164, "eval/image_loss_std": 16.760501861572266, "eval/model_loss_mean": 22.639225006103516, "eval/model_loss_std": 21.009639739990234, "eval/post_ent_mag": 58.567481994628906, "eval/post_ent_max": 58.567481994628906, "eval/post_ent_mean": 40.71812438964844, "eval/post_ent_min": 20.519994735717773, "eval/post_ent_std": 7.297563076019287, "eval/prior_ent_mag": 69.79045867919922, "eval/prior_ent_max": 69.79045867919922, "eval/prior_ent_mean": 56.873416900634766, "eval/prior_ent_min": 42.92265319824219, "eval/prior_ent_std": 4.376800537109375, "eval/rep_loss_mean": 18.432153701782227, "eval/rep_loss_std": 10.606980323791504, "eval/reward_avg": 0.03603515774011612, "eval/reward_loss_mean": 0.10067062824964523, "eval/reward_loss_std": 0.6221559643745422, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012319087982178, "eval/reward_neg_acc": 0.992893397808075, "eval/reward_neg_loss": 0.04365982487797737, "eval/reward_pos_acc": 0.8974359035491943, "eval/reward_pos_loss": 1.540558934211731, "eval/reward_pred": 0.03330018371343613, "eval/reward_rate": 0.0380859375, "replay/size": 990081.0, "replay/inserts": 22096.0, "replay/samples": 22096.0, "replay/insert_wait_avg": 1.3674755704135329e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.466039163146133e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.251592602528317e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4767434597015, "timer/env.step_count": 2762.0, "timer/env.step_total": 217.99637460708618, "timer/env.step_frac": 0.21789249578480274, "timer/env.step_avg": 0.07892700021979948, "timer/env.step_min": 0.022507905960083008, "timer/env.step_max": 3.53417706489563, "timer/replay._sample_count": 22096.0, "timer/replay._sample_total": 11.067296266555786, "timer/replay._sample_frac": 0.011062022519668462, "timer/replay._sample_avg": 0.0005008732922952473, "timer/replay._sample_min": 0.0004200935363769531, "timer/replay._sample_max": 0.02528834342956543, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3614.0, "timer/agent.policy_total": 58.987266540527344, "timer/agent.policy_frac": 0.05895915814749102, "timer/agent.policy_avg": 0.01632187784740657, "timer/agent.policy_min": 0.009294748306274414, "timer/agent.policy_max": 0.10218667984008789, "timer/dataset_train_count": 1381.0, "timer/dataset_train_total": 0.14488911628723145, "timer/dataset_train_frac": 0.0001448200742639926, "timer/dataset_train_avg": 0.00010491608710154341, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0005369186401367188, "timer/agent.train_count": 1381.0, "timer/agent.train_total": 616.8549392223358, "timer/agent.train_frac": 0.616560997799128, "timer/agent.train_avg": 0.4466726569314524, "timer/agent.train_min": 0.433300256729126, "timer/agent.train_max": 1.6215178966522217, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4721062183380127, "timer/agent.report_frac": 0.00047188125203734814, "timer/agent.report_avg": 0.23605310916900635, "timer/agent.report_min": 0.2293853759765625, "timer/agent.report_max": 0.2427208423614502, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.217117078344899e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 22.085144490219403}
{"step": 990800, "time": 45401.696472644806, "episode/length": 300.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 991112, "time": 45413.473901987076, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 991208, "time": 45418.305990219116, "episode/length": 281.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975177304964539, "episode/intrinsic_return": 0.0}
{"step": 991704, "time": 45437.828754901886, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 992056, "time": 45451.24005103111, "episode/length": 183.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 992120, "time": 45454.874827861786, "episode/length": 217.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 992392, "time": 45465.39721727371, "episode/length": 198.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 992568, "time": 45472.73296380043, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 992608, "time": 45475.73626422882, "episode/length": 433.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 993016, "time": 45490.64453101158, "episode/length": 237.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 993104, "time": 45495.34726715088, "episode/length": 174.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 993288, "time": 45502.73064374924, "episode/length": 153.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 993344, "time": 45506.40690588951, "episode/length": 152.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 993896, "time": 45525.96910357475, "episode/length": 430.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9976798143851509, "episode/intrinsic_return": 0.0}
{"step": 993896, "time": 45525.9785220623, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 994568, "time": 45551.72750377655, "episode/length": 182.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 994912, "time": 45565.023012161255, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 995360, "time": 45582.14931201935, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 995544, "time": 45589.4912045002, "episode/length": 205.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 995720, "time": 45596.856610536575, "episode/length": 337.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.985207100591716, "episode/intrinsic_return": 0.0}
{"step": 995744, "time": 45599.4372215271, "episode/length": 306.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.990228013029316, "episode/intrinsic_return": 0.0}
{"step": 996208, "time": 45616.32004213333, "episode/length": 449.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 996448, "time": 45625.904557943344, "episode/length": 484.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9979381443298969, "episode/intrinsic_return": 0.0}
{"step": 996592, "time": 45632.39792227745, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 996776, "time": 45639.84354805946, "episode/length": 153.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 997368, "time": 45661.06746196747, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 997400, "time": 45663.70294737816, "episode/length": 206.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 997912, "time": 45682.280445337296, "episode/length": 164.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 998120, "time": 45690.84584403038, "episode/length": 208.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 998328, "time": 45699.28940629959, "episode/length": 264.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 998584, "time": 45709.235090494156, "episode/length": 501.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.99800796812749, "episode/intrinsic_return": 0.0}
{"step": 998720, "time": 45715.5881652832, "episode/length": 242.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 999016, "time": 45727.28576040268, "episode/length": 205.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 999416, "time": 45742.49929904938, "episode/length": 187.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 999752, "time": 45760.09069800377, "episode/length": 293.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 999792, "time": 45763.75329709053, "episode/length": 208.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 999872, "time": 45768.47277712822, "episode/length": 160.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 999992, "time": 45773.87038755417, "episode/length": 578.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9930915371329879, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 45796.75838446617, "eval_episode/length": 144.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9724137931034482}
{"step": 1000064, "time": 45799.47231268883, "eval_episode/length": 170.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 1000064, "time": 45802.150910139084, "eval_episode/length": 195.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 1000064, "time": 45803.79064798355, "eval_episode/length": 197.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 1000064, "time": 45805.56222987175, "eval_episode/length": 201.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 1000064, "time": 45807.416517972946, "eval_episode/length": 204.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9707317073170731}
{"step": 1000064, "time": 45809.05347585678, "eval_episode/length": 205.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 1000064, "time": 45812.385875463486, "eval_episode/length": 246.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 1000416, "time": 45824.071536779404, "episode/length": 211.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1000488, "time": 45827.846722364426, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 1000896, "time": 45843.17620873451, "episode/length": 184.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 1001664, "time": 45870.512483119965, "episode/length": 155.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 1001704, "time": 45873.1247484684, "episode/length": 238.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 1002352, "time": 45896.523248910904, "episode/length": 294.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 1002808, "time": 45912.96920657158, "episode/length": 289.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 1003128, "time": 45925.12036204338, "episode/length": 421.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9881516587677726, "episode/intrinsic_return": 0.0}
{"step": 1003208, "time": 45929.388660907745, "episode/length": 288.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9896193771626297, "episode/intrinsic_return": 0.0}
{"step": 1003320, "time": 45934.72814822197, "episode/length": 206.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1003600, "time": 45945.647587537766, "episode/length": 465.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 1003712, "time": 45950.85847234726, "episode/length": 250.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 1003880, "time": 45957.890817165375, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 1003928, "time": 45960.98066020012, "episode/length": 699.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 1004792, "time": 45991.59119081497, "episode/length": 197.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 1004888, "time": 45996.37333488464, "episode/length": 219.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 1004976, "time": 46001.03905797005, "episode/length": 206.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1005112, "time": 46006.91710996628, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 1005768, "time": 46030.32246351242, "episode/length": 235.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1006096, "time": 46042.85784292221, "episode/length": 410.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9878345498783455, "episode/intrinsic_return": 0.0}
{"step": 1006184, "time": 46047.13765859604, "episode/length": 308.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9838187702265372, "episode/intrinsic_return": 0.0}
{"step": 1006232, "time": 46050.31160378456, "episode/length": 287.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9756944444444444, "episode/intrinsic_return": 0.0}
{"step": 1006392, "time": 46057.191855192184, "episode/length": 199.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 1006600, "time": 46065.70130968094, "episode/length": 51.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 1006928, "time": 46078.43057656288, "episode/length": 243.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 1007120, "time": 46086.238963365555, "episode/length": 168.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 1007856, "time": 46114.02263832092, "episode/length": 342.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9883381924198251, "episode/intrinsic_return": 0.0}
{"step": 1008048, "time": 46121.93340587616, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 1008176, "time": 46127.68035912514, "episode/length": 196.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 1008200, "time": 46129.75660777092, "episode/length": 413.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9879227053140096, "episode/intrinsic_return": 0.0}
{"step": 1008400, "time": 46138.2463350296, "episode/length": 287.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9826388888888888, "episode/intrinsic_return": 0.0}
{"step": 1008600, "time": 46146.20030903816, "episode/length": 295.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9898648648648649, "episode/intrinsic_return": 0.0}
{"step": 1008600, "time": 46146.20967197418, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 1008624, "time": 46150.554180145264, "episode/length": 211.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1009464, "time": 46179.62126994133, "episode/length": 200.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 1009576, "time": 46184.91326189041, "episode/length": 190.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 1009672, "time": 46189.733338832855, "episode/length": 186.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 1009688, "time": 46191.75186562538, "episode/length": 132.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 1009792, "time": 46196.9822473526, "episode/length": 173.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 46207.0651473999, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 46228.34967970848, "eval_episode/length": 159.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 1010048, "time": 46230.714270830154, "eval_episode/length": 177.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 1010048, "time": 46232.91404414177, "eval_episode/length": 189.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 1010048, "time": 46234.92626261711, "eval_episode/length": 198.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 1010048, "time": 46236.95155739784, "eval_episode/length": 208.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 1010048, "time": 46239.51714468002, "eval_episode/length": 233.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 1010048, "time": 46243.85567378998, "eval_episode/length": 301.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9966887417218543}
{"step": 1010048, "time": 46247.578943014145, "eval_episode/length": 348.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9828080229226361}
{"step": 1010088, "time": 46250.2392449379, "episode/length": 36.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 1010264, "time": 46257.86637377739, "episode/length": 207.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 1010656, "time": 46272.50107526779, "episode/length": 148.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 1010720, "time": 46276.288237571716, "episode/length": 314.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 1011152, "time": 46292.12270140648, "episode/length": 182.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 1011224, "time": 46295.92035508156, "episode/length": 205.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1011384, "time": 46302.74714446068, "episode/length": 161.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 1011880, "time": 46321.00336050987, "episode/length": 201.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 1011928, "time": 46324.182278871536, "episode/length": 158.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 1011968, "time": 46327.334743499756, "episode/length": 239.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1012280, "time": 46338.881870269775, "episode/length": 325.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.0}
{"step": 1012288, "time": 46340.81968379021, "episode/length": 195.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1012720, "time": 46356.704718351364, "episode/length": 186.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 1012816, "time": 46361.45064687729, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 1013400, "time": 46382.19206380844, "episode/length": 178.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 1013424, "time": 46384.82068610191, "episode/length": 142.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 1013657, "time": 46394.803626298904, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.544635772705078, "train/action_min": 0.0, "train/action_std": 3.3015108274088965, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03854611027054489, "train/actor_opt_grad_steps": 62535.0, "train/actor_opt_loss": -5.689167068702066, "train/adv_mag": 0.48511070385575294, "train/adv_max": 0.4457418146646685, "train/adv_mean": 0.0032294853239768096, "train/adv_min": -0.3951225325258242, "train/adv_std": 0.05433103675022721, "train/cont_avg": 0.99505615234375, "train/cont_loss_mean": 0.00011097153201708763, "train/cont_loss_std": 0.003297451494154934, "train/cont_neg_acc": 0.9953379956158724, "train/cont_neg_loss": 0.007491051941160931, "train/cont_pos_acc": 0.9999658680624433, "train/cont_pos_loss": 7.394656821190103e-05, "train/cont_pred": 0.99503618106246, "train/cont_rate": 0.99505615234375, "train/dyn_loss_mean": 13.07638492849138, "train/dyn_loss_std": 9.312063965532515, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8332746869160069, "train/extr_critic_critic_opt_grad_steps": 62535.0, "train/extr_critic_critic_opt_loss": 15891.151380750867, "train/extr_critic_mag": 9.051048345035976, "train/extr_critic_max": 9.051048345035976, "train/extr_critic_mean": 2.5717752940124936, "train/extr_critic_min": -0.17964691006475025, "train/extr_critic_std": 2.1181917670700283, "train/extr_return_normed_mag": 1.5081771686673164, "train/extr_return_normed_max": 1.5081771686673164, "train/extr_return_normed_mean": 0.3828575750812888, "train/extr_return_normed_min": -0.0862144225070046, "train/extr_return_normed_std": 0.3282625509632958, "train/extr_return_rate": 0.7981712478730414, "train/extr_return_raw_mag": 9.960505187511444, "train/extr_return_raw_max": 9.960505187511444, "train/extr_return_raw_mean": 2.5929073376788034, "train/extr_return_raw_min": -0.4786363121949964, "train/extr_return_raw_std": 2.1492945924401283, "train/extr_reward_mag": 1.0413870910803478, "train/extr_reward_max": 1.0413870910803478, "train/extr_reward_mean": 0.05087612278293818, "train/extr_reward_min": -0.41076041840844685, "train/extr_reward_std": 0.2113659374622835, "train/image_loss_mean": 5.999585229489538, "train/image_loss_std": 11.49364987346861, "train/model_loss_mean": 13.905494497881996, "train/model_loss_std": 15.316127359867096, "train/model_opt_grad_norm": 47.91726979944441, "train/model_opt_grad_steps": 62476.75, "train/model_opt_loss": 17215.1800910102, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1241.3194444444443, "train/policy_entropy_mag": 2.558203866084417, "train/policy_entropy_max": 2.558203866084417, "train/policy_entropy_mean": 0.5081999699274699, "train/policy_entropy_min": 0.07937501381254858, "train/policy_entropy_std": 0.6405109622412257, "train/policy_logprob_mag": 7.438383873966005, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5076911068624921, "train/policy_logprob_min": -7.438383873966005, "train/policy_logprob_std": 1.07661771774292, "train/policy_randomness_mag": 0.9029337014589045, "train/policy_randomness_max": 0.9029337014589045, "train/policy_randomness_mean": 0.17937228756232393, "train/policy_randomness_min": 0.028015896703840956, "train/policy_randomness_std": 0.22607226317955387, "train/post_ent_mag": 60.71691166030036, "train/post_ent_max": 60.71691166030036, "train/post_ent_mean": 43.29988964398702, "train/post_ent_min": 20.282582892311943, "train/post_ent_std": 7.775570584668054, "train/prior_ent_mag": 69.8492079840766, "train/prior_ent_max": 69.8492079840766, "train/prior_ent_mean": 56.44087526533339, "train/prior_ent_min": 40.17846526039971, "train/prior_ent_std": 4.582141502035989, "train/rep_loss_mean": 13.07638492849138, "train/rep_loss_std": 9.312063965532515, "train/reward_avg": 0.0343180336834242, "train/reward_loss_mean": 0.05996739103769263, "train/reward_loss_std": 0.2515399566748076, "train/reward_max_data": 1.0194444490803614, "train/reward_max_pred": 1.0136926828159227, "train/reward_neg_acc": 0.9918411916328801, "train/reward_neg_loss": 0.029440887621603906, "train/reward_pos_acc": 0.9743681463102499, "train/reward_pos_loss": 0.8149129272335105, "train/reward_pred": 0.03353675577737805, "train/reward_rate": 0.03900146484375, "train_stats/sum_log_reward": 9.802127919298536, "train_stats/max_log_achievement_collect_coal": 0.425531914893617, "train_stats/max_log_achievement_collect_drink": 5.691489361702128, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.351063829787234, "train_stats/max_log_achievement_collect_stone": 10.329787234042554, "train_stats/max_log_achievement_collect_wood": 11.47872340425532, "train_stats/max_log_achievement_defeat_skeleton": 0.06382978723404255, "train_stats/max_log_achievement_defeat_zombie": 1.2234042553191489, "train_stats/max_log_achievement_eat_cow": 0.2553191489361702, "train_stats/max_log_achievement_make_stone_pickaxe": 0.010638297872340425, "train_stats/max_log_achievement_make_stone_sword": 0.02127659574468085, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2234042553191489, "train_stats/max_log_achievement_make_wood_sword": 1.3829787234042554, "train_stats/max_log_achievement_place_furnace": 0.010638297872340425, "train_stats/max_log_achievement_place_plant": 1.3404255319148937, "train_stats/max_log_achievement_place_stone": 9.095744680851064, "train_stats/max_log_achievement_place_table": 3.372340425531915, "train_stats/max_log_achievement_wake_up": 1.7872340425531914, "train_stats/mean_log_entropy": 0.5846561402716535, "eval_stats/sum_log_reward": 10.037500232458115, "eval_stats/max_log_achievement_collect_coal": 0.75, "eval_stats/max_log_achievement_collect_drink": 4.25, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_stone": 11.0, "eval_stats/max_log_achievement_collect_wood": 11.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.3125, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 1.3125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_stone": 9.3125, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 5.8551686379360035e-05, "report/cont_loss_std": 0.0018600203329697251, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.029789673164486885, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.694479175919696e-07, "report/cont_pred": 0.9981030225753784, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 13.97921371459961, "report/dyn_loss_std": 9.90776252746582, "report/image_loss_mean": 6.569497108459473, "report/image_loss_std": 11.405445098876953, "report/model_loss_mean": 15.020452499389648, "report/model_loss_std": 15.681341171264648, "report/post_ent_mag": 60.157012939453125, "report/post_ent_max": 60.157012939453125, "report/post_ent_mean": 42.41410446166992, "report/post_ent_min": 21.231945037841797, "report/post_ent_std": 7.669210910797119, "report/prior_ent_mag": 69.92387390136719, "report/prior_ent_max": 69.92387390136719, "report/prior_ent_mean": 56.2523307800293, "report/prior_ent_min": 38.190040588378906, "report/prior_ent_std": 4.402157306671143, "report/rep_loss_mean": 13.97921371459961, "report/rep_loss_std": 9.90776252746582, "report/reward_avg": 0.04736328125, "report/reward_loss_mean": 0.06336988508701324, "report/reward_loss_std": 0.28678083419799805, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.118636131286621, "report/reward_neg_acc": 0.9928057789802551, "report/reward_neg_loss": 0.01867697201669216, "report/reward_pos_acc": 0.960784375667572, "report/reward_pos_loss": 0.9160406589508057, "report/reward_pred": 0.043752364814281464, "report/reward_rate": 0.0498046875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 8.443119440926239e-06, "eval/cont_loss_std": 0.00017320321057923138, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0010221742559224367, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.4682794901309535e-06, "eval/cont_pred": 0.9941442012786865, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.70679473876953, "eval/dyn_loss_std": 10.490102767944336, "eval/image_loss_mean": 10.44465446472168, "eval/image_loss_std": 14.007341384887695, "eval/model_loss_mean": 21.167072296142578, "eval/model_loss_std": 18.295434951782227, "eval/post_ent_mag": 60.834590911865234, "eval/post_ent_max": 60.834590911865234, "eval/post_ent_mean": 42.43482208251953, "eval/post_ent_min": 19.748580932617188, "eval/post_ent_std": 7.645024299621582, "eval/prior_ent_mag": 69.92387390136719, "eval/prior_ent_max": 69.92387390136719, "eval/prior_ent_mean": 57.92231369018555, "eval/prior_ent_min": 42.47553253173828, "eval/prior_ent_std": 4.85616397857666, "eval/rep_loss_mean": 17.70679473876953, "eval/rep_loss_std": 10.490102767944336, "eval/reward_avg": 0.0361328125, "eval/reward_loss_mean": 0.09833364933729172, "eval/reward_loss_std": 0.5673037767410278, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001824140548706, "eval/reward_neg_acc": 0.9888097643852234, "eval/reward_neg_loss": 0.03808588534593582, "eval/reward_pos_acc": 0.8536584973335266, "eval/reward_pos_loss": 1.5428105592727661, "eval/reward_pred": 0.03381401300430298, "eval/reward_rate": 0.0400390625, "replay/size": 1000000.0, "replay/inserts": 23072.0, "replay/samples": 23072.0, "replay/insert_wait_avg": 1.3502498109529153e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.420499452440153e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4768.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2524976026291814e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2169291973114, "timer/env.step_count": 2884.0, "timer/env.step_total": 225.33698201179504, "timer/env.step_frac": 0.22528811044283287, "timer/env.step_avg": 0.0781334889083894, "timer/env.step_min": 0.02213120460510254, "timer/env.step_max": 3.3873236179351807, "timer/replay._sample_count": 23072.0, "timer/replay._sample_total": 11.585152626037598, "timer/replay._sample_frac": 0.01158264001323678, "timer/replay._sample_avg": 0.0005021304016139736, "timer/replay._sample_min": 0.0003998279571533203, "timer/replay._sample_max": 0.027820587158203125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3480.0, "timer/agent.policy_total": 57.132888317108154, "timer/agent.policy_frac": 0.0571204972134976, "timer/agent.policy_avg": 0.01641749664284717, "timer/agent.policy_min": 0.00943446159362793, "timer/agent.policy_max": 0.12010979652404785, "timer/dataset_train_count": 1442.0, "timer/dataset_train_total": 0.15167760848999023, "timer/dataset_train_frac": 0.00015164471232426922, "timer/dataset_train_avg": 0.00010518558147710834, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0008838176727294922, "timer/agent.train_count": 1442.0, "timer/agent.train_total": 648.6822335720062, "timer/agent.train_frac": 0.6485415459750148, "timer/agent.train_avg": 0.4498489830596437, "timer/agent.train_min": 0.43473291397094727, "timer/agent.train_max": 2.7635245323181152, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4719059467315674, "timer/agent.report_frac": 0.0004718035987556007, "timer/agent.report_avg": 0.2359529733657837, "timer/agent.report_min": 0.2294759750366211, "timer/agent.report_max": 0.2424299716949463, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.003422566633121e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 23.06664877686677}
{"step": 1013752, "time": 46397.79552102089, "episode/length": 227.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1013760, "time": 46399.823561668396, "episode/length": 296.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 1014064, "time": 46411.54237699509, "episode/length": 221.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 1014240, "time": 46418.755888938904, "episode/length": 294.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 1014720, "time": 46436.05539274216, "episode/length": 249.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 1015400, "time": 46459.9732093811, "episode/length": 204.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 1015408, "time": 46462.05726361275, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 1015872, "time": 46480.62308907509, "episode/length": 225.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 1015928, "time": 46483.75560426712, "episode/length": 210.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1016160, "time": 46493.147742033005, "episode/length": 179.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1016192, "time": 46495.798959732056, "episode/length": 348.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9828080229226361, "episode/intrinsic_return": 0.0}
{"step": 1016240, "time": 46499.053247213364, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9929906542056075, "episode/intrinsic_return": 0.0}
{"step": 1016456, "time": 46507.44686746597, "episode/length": 378.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9973614775725593, "episode/intrinsic_return": 0.0}
{"step": 1017120, "time": 46531.336874723434, "episode/length": 214.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 1017464, "time": 46544.073820114136, "episode/length": 198.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1017648, "time": 46551.93872952461, "episode/length": 279.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 1017672, "time": 46554.10180282593, "episode/length": 184.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 1017984, "time": 46566.361214637756, "episode/length": 217.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1018136, "time": 46572.769668102264, "episode/length": 275.0, "episode/score": 10.100000061094761, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 1018504, "time": 46586.586465358734, "episode/length": 292.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9829351535836177, "episode/intrinsic_return": 0.0}
{"step": 1018864, "time": 46600.36153578758, "episode/length": 300.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9800664451827242, "episode/intrinsic_return": 0.0}
{"step": 1019040, "time": 46607.69735074043, "episode/length": 173.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 1019136, "time": 46612.44408631325, "episode/length": 251.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 1019496, "time": 46625.849794626236, "episode/length": 227.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 1019680, "time": 46633.90013432503, "episode/length": 192.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 1020008, "time": 46646.29886817932, "episode/length": 252.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
