{"step": 384, "time": 142.97124814987183, "episode/length": 47.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 1016, "time": 146.51514673233032, "episode/length": 126.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9448818897637795, "episode/intrinsic_return": 0.0}
{"step": 1152, "time": 148.5161006450653, "episode/length": 143.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 1160, "time": 149.95900988578796, "episode/length": 144.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 1224, "time": 151.5586438179016, "episode/length": 152.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 1280, "time": 153.0658893585205, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 167.68432188034058, "eval_episode/length": 43.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 1560, "time": 171.4153277873993, "eval_episode/length": 131.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 1560, "time": 173.07276964187622, "eval_episode/length": 140.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 1560, "time": 174.57126140594482, "eval_episode/length": 141.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 1560, "time": 176.1031322479248, "eval_episode/length": 149.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 1560, "time": 177.61090397834778, "eval_episode/length": 154.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.967741935483871}
{"step": 1560, "time": 179.3117311000824, "eval_episode/length": 159.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.99375}
{"step": 1560, "time": 180.98098993301392, "eval_episode/length": 166.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 1560, "time": 183.12251043319702, "train_stats/sum_log_reward": 0.6000000337759653, "train_stats/max_log_achievement_collect_wood": 0.4, "train_stats/max_log_achievement_wake_up": 1.6, "train_stats/max_log_achievement_collect_sapling": 2.0, "train_stats/max_log_achievement_place_plant": 2.0, "eval_stats/sum_log_reward": 0.9749999549239874, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_wake_up": 1.625}
{"step": 1560, "time": 224.4135284423828, "eval_episode/length": 128.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9922480620155039}
{"step": 1560, "time": 226.72541546821594, "eval_episode/length": 142.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.993006993006993}
{"step": 1560, "time": 229.53194069862366, "eval_episode/length": 167.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 1560, "time": 232.46405172348022, "eval_episode/length": 194.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 1560, "time": 234.87650394439697, "eval_episode/length": 211.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 1560, "time": 237.13350629806519, "eval_episode/length": 226.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9823788546255506}
{"step": 1560, "time": 238.96774888038635, "eval_episode/length": 32.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8484848484848485}
{"step": 1560, "time": 241.06159281730652, "eval_episode/length": 236.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 1561, "time": 366.2696006298065, "eval_stats/sum_log_reward": 0.9749999418854713, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_wake_up": 2.25, "eval_stats/max_log_achievement_collect_drink": 7.0, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.84613037109375, "train/action_min": 0.0, "train/action_std": 4.761609077453613, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0004337963182479143, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -4.070589065551758, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.994140625, "train/cont_loss_mean": 0.49159327149391174, "train/cont_loss_std": 0.2336612045764923, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 1.1888378858566284, "train/cont_pos_acc": 0.8231827616691589, "train/cont_pos_loss": 0.48748379945755005, "train/cont_pred": 0.629164457321167, "train/cont_rate": 0.994140625, "train/dyn_loss_mean": 10.58645248413086, "train/dyn_loss_std": 0.47736823558807373, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 14.442654609680176, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 57105.35546875, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3796.907470703125, "train/image_loss_std": 159.44493103027344, "train/model_loss_mean": 3809.2919921875, "train/model_loss_std": 159.4791717529297, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 38092920.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.7999589443206787, "train/policy_entropy_max": 2.7999589443206787, "train/policy_entropy_mean": 2.6313254833221436, "train/policy_entropy_min": 1.9845688343048096, "train/policy_entropy_std": 0.08548670262098312, "train/policy_logprob_mag": 5.265414237976074, "train/policy_logprob_max": -0.6971337199211121, "train/policy_logprob_mean": -2.6339004039764404, "train/policy_logprob_min": -5.265414237976074, "train/policy_logprob_std": 0.6249178647994995, "train/policy_randomness_mag": 0.9882626533508301, "train/policy_randomness_max": 0.9882626533508301, "train/policy_randomness_mean": 0.9287424087524414, "train/policy_randomness_min": 0.7004656791687012, "train/policy_randomness_std": 0.030173052102327347, "train/post_ent_mag": 106.18155670166016, "train/post_ent_max": 106.18155670166016, "train/post_ent_mean": 105.59030151367188, "train/post_ent_min": 105.01449584960938, "train/post_ent_std": 0.20933672785758972, "train/prior_ent_mag": 106.8074951171875, "train/prior_ent_max": 106.8074951171875, "train/prior_ent_mean": 105.98622131347656, "train/prior_ent_min": 105.00214385986328, "train/prior_ent_std": 0.3003053069114685, "train/rep_loss_mean": 10.58645248413086, "train/rep_loss_std": 0.47736823558807373, "train/reward_avg": 0.00644531287252903, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.565802656652522e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 0.9999999403953552, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.0126953125, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.5046238303184509, "report/cont_loss_std": 0.24594594538211823, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 1.1668970584869385, "report/cont_pos_acc": 0.8045186996459961, "report/cont_pos_loss": 0.5007205009460449, "report/cont_pred": 0.6229472160339355, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 10.671947479248047, "report/dyn_loss_std": 0.4376072585582733, "report/image_loss_mean": 3801.9775390625, "report/image_loss_std": 157.9071807861328, "report/model_loss_mean": 3814.4267578125, "report/model_loss_std": 157.92982482910156, "report/post_ent_mag": 106.185546875, "report/post_ent_max": 106.185546875, "report/post_ent_mean": 105.58151245117188, "report/post_ent_min": 104.97657775878906, "report/post_ent_std": 0.2205415517091751, "report/prior_ent_mag": 106.70288848876953, "report/prior_ent_max": 106.70288848876953, "report/prior_ent_mean": 105.99270629882812, "report/prior_ent_min": 105.05682373046875, "report/prior_ent_std": 0.3042563199996948, "report/rep_loss_mean": 10.671947479248047, "report/rep_loss_std": 0.4376072585582733, "report/reward_avg": 0.00644531287252903, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.565802656652522e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.0126953125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.4921402037143707, "eval/cont_loss_std": 0.24612747132778168, "eval/cont_neg_acc": 0.2857142984867096, "eval/cont_neg_loss": 1.130944013595581, "eval/cont_pos_acc": 0.8220254778862, "eval/cont_pos_loss": 0.4877432882785797, "eval/cont_pred": 0.6303147077560425, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 10.625615119934082, "eval/dyn_loss_std": 0.4525984227657318, "eval/image_loss_mean": 3793.846923828125, "eval/image_loss_std": 149.71597290039062, "eval/model_loss_mean": 3806.255859375, "eval/model_loss_std": 149.75289916992188, "eval/post_ent_mag": 106.18733215332031, "eval/post_ent_max": 106.18733215332031, "eval/post_ent_mean": 105.63812255859375, "eval/post_ent_min": 105.16921997070312, "eval/post_ent_std": 0.19453692436218262, "eval/prior_ent_mag": 106.90536499023438, "eval/prior_ent_max": 106.90536499023438, "eval/prior_ent_mean": 105.97200012207031, "eval/prior_ent_min": 104.50613403320312, "eval/prior_ent_std": 0.3234170377254486, "eval/rep_loss_mean": 10.625615119934082, "eval/rep_loss_std": 0.4525984227657318, "eval/reward_avg": 0.006152344401925802, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.559997806718457e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0126953125, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.7717861294633619e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.110489164079939e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2952.0, "eval_replay/inserts": 2952.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.5502053547680862e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 236.04956126213074, "timer/env.step_count": 196.0, "timer/env.step_total": 24.845168590545654, "timer/env.step_frac": 0.10525403418545369, "timer/env.step_avg": 0.12676106423747782, "timer/env.step_min": 0.022497177124023438, "timer/env.step_max": 11.482197999954224, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.11291146278381348, "timer/replay._sample_frac": 0.0004783379480990706, "timer/replay._sample_avg": 0.0010081380605697632, "timer/replay._sample_min": 0.0003733634948730469, "timer/replay._sample_max": 0.009967565536499023, "timer/agent.save_count": 1.0, "timer/agent.save_total": 8.925558090209961, "timer/agent.save_frac": 0.03781222063064212, "timer/agent.save_avg": 8.925558090209961, "timer/agent.save_min": 8.925558090209961, "timer/agent.save_max": 8.925558090209961, "timer/agent.policy_count": 238.0, "timer/agent.policy_total": 25.10807704925537, "timer/agent.policy_frac": 0.10636781917748661, "timer/agent.policy_avg": 0.10549612205569484, "timer/agent.policy_min": 0.010035991668701172, "timer/agent.policy_max": 18.479593753814697, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.790855407714844e-05, "timer/dataset_train_frac": 1.605957404642297e-07, "timer/dataset_train_avg": 3.790855407714844e-05, "timer/dataset_train_min": 3.790855407714844e-05, "timer/dataset_train_max": 3.790855407714844e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 96.63039374351501, "timer/agent.train_frac": 0.40936485213886037, "timer/agent.train_avg": 96.63039374351501, "timer/agent.train_min": 96.63039374351501, "timer/agent.train_max": 96.63039374351501, "timer/agent.report_count": 2.0, "timer/agent.report_total": 26.09477162361145, "timer/agent.report_frac": 0.11054785056191424, "timer/agent.report_avg": 13.047385811805725, "timer/agent.report_min": 0.24509310722351074, "timer/agent.report_max": 25.84967851638794, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.7670135498046875e-05, "timer/dataset_eval_frac": 1.5958570436068108e-07, "timer/dataset_eval_avg": 3.7670135498046875e-05, "timer/dataset_eval_min": 3.7670135498046875e-05, "timer/dataset_eval_max": 3.7670135498046875e-05}
{"step": 1600, "time": 367.6485960483551, "episode/length": 151.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 1688, "time": 371.9815731048584, "episode/length": 210.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1800, "time": 377.5328142642975, "episode/length": 224.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 2208, "time": 393.4475998878479, "episode/length": 75.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 2400, "time": 401.669105052948, "episode/length": 154.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 2432, "time": 404.3516294956207, "episode/length": 176.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 2544, "time": 409.9151725769043, "episode/length": 173.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 2824, "time": 420.98262786865234, "episode/length": 199.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 2856, "time": 423.7037556171417, "episode/length": 56.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9122807017543859, "episode/intrinsic_return": 0.0}
{"step": 3168, "time": 436.1410975456238, "episode/length": 235.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 3288, "time": 441.57849073410034, "episode/length": 134.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 3528, "time": 451.56635642051697, "episode/length": 215.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 3600, "time": 455.8496391773224, "episode/length": 238.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9665271966527197, "episode/intrinsic_return": 0.0}
{"step": 3728, "time": 461.85371017456055, "episode/length": 147.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 3752, "time": 464.1946268081665, "episode/length": 164.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 4128, "time": 478.98369789123535, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 4416, "time": 490.3661558628082, "episode/length": 194.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 4472, "time": 493.6452329158783, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 4752, "time": 504.9998445510864, "episode/length": 182.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 4808, "time": 508.41708731651306, "episode/length": 84.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 4840, "time": 511.07435941696167, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 5080, "time": 520.9571816921234, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 5504, "time": 537.293377161026, "episode/length": 218.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 5728, "time": 546.7729787826538, "episode/length": 156.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 5792, "time": 550.556214094162, "episode/length": 171.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 5864, "time": 554.4056503772736, "episode/length": 131.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 6176, "time": 566.8512575626373, "episode/length": 177.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 6192, "time": 569.2718646526337, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 6312, "time": 574.7888243198395, "episode/length": 72.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9452054794520548, "episode/intrinsic_return": 0.0}
{"step": 6608, "time": 586.5288937091827, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 6944, "time": 599.5368778705597, "episode/length": 401.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 7176, "time": 608.9627377986908, "episode/length": 172.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 7280, "time": 614.3942453861237, "episode/length": 176.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 7400, "time": 619.9439022541046, "episode/length": 135.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 7552, "time": 627.000896692276, "episode/length": 169.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 7592, "time": 629.8926391601562, "episode/length": 38.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.0}
{"step": 7640, "time": 633.1530947685242, "episode/length": 182.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 7824, "time": 641.1980738639832, "episode/length": 289.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 7896, "time": 644.9982631206512, "episode/length": 61.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 7936, "time": 648.124653339386, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 8240, "time": 661.7358620166779, "episode/length": 161.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 8488, "time": 671.6722824573517, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 9016, "time": 691.3482754230499, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 9120, "time": 696.7469613552094, "episode/length": 195.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 9352, "time": 706.0768330097198, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 9424, "time": 710.5009417533875, "episode/length": 199.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 9504, "time": 714.7605247497559, "episode/length": 195.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 9520, "time": 716.929468870163, "episode/length": 240.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9875518672199171, "episode/intrinsic_return": 0.0}
{"step": 9928, "time": 732.3707263469696, "episode/length": 210.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 754.919182062149, "eval_episode/length": 39.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9}
{"step": 10088, "time": 757.1082763671875, "eval_episode/length": 50.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9215686274509803}
{"step": 10088, "time": 761.1537742614746, "eval_episode/length": 106.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9532710280373832}
{"step": 10088, "time": 765.1901757717133, "eval_episode/length": 157.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 10088, "time": 767.7022619247437, "eval_episode/length": 177.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 10088, "time": 769.7898178100586, "eval_episode/length": 187.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.973404255319149}
{"step": 10088, "time": 772.2522439956665, "eval_episode/length": 167.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 10088, "time": 774.1574351787567, "eval_episode/length": 212.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9812206572769953}
{"step": 10456, "time": 786.7168729305267, "episode/length": 179.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 10608, "time": 793.7323517799377, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 10744, "time": 799.7134351730347, "episode/length": 154.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 10784, "time": 802.929878950119, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 10880, "time": 807.7164299488068, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 10912, "time": 810.5585162639618, "episode/length": 302.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 11080, "time": 817.8827078342438, "episode/length": 206.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 11144, "time": 821.7212233543396, "episode/length": 151.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 11960, "time": 851.1903200149536, "episode/length": 101.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 12160, "time": 859.7621023654938, "episode/length": 212.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 12200, "time": 862.5021262168884, "episode/length": 176.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 12216, "time": 864.6655559539795, "episode/length": 162.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 12320, "time": 870.1021630764008, "episode/length": 154.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 12448, "time": 876.0808572769165, "episode/length": 195.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 12512, "time": 880.435955286026, "episode/length": 237.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 12688, "time": 888.5789289474487, "episode/length": 242.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 12816, "time": 894.5335118770599, "episode/length": 81.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9390243902439024, "episode/intrinsic_return": 0.0}
{"step": 13320, "time": 913.183343410492, "episode/length": 169.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 13536, "time": 922.3841366767883, "episode/length": 164.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 13536, "time": 922.3927888870239, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 13888, "time": 937.8726825714111, "episode/length": 43.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 13896, "time": 940.0093245506287, "episode/length": 71.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 13992, "time": 945.3390650749207, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 14152, "time": 952.5752685070038, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 14320, "time": 960.4022588729858, "episode/length": 249.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.988, "episode/intrinsic_return": 0.0}
{"step": 14384, "time": 964.2005560398102, "episode/length": 241.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.987603305785124, "episode/intrinsic_return": 0.0}
{"step": 14448, "time": 968.0000886917114, "episode/length": 56.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9298245614035088, "episode/intrinsic_return": 0.0}
{"step": 14488, "time": 970.7930912971497, "episode/length": 41.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 14624, "time": 977.2302398681641, "episode/length": 241.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.987603305785124, "episode/intrinsic_return": 0.0}
{"step": 14992, "time": 991.4577231407166, "episode/length": 181.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 15448, "time": 1008.2650625705719, "episode/length": 194.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 15472, "time": 1010.8957719802856, "episode/length": 127.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 15496, "time": 1013.1314213275909, "episode/length": 146.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 15672, "time": 1020.9260082244873, "episode/length": 221.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 15688, "time": 1023.1079483032227, "episode/length": 162.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 15760, "time": 1027.4162187576294, "episode/length": 141.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 15968, "time": 1036.2196595668793, "episode/length": 64.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 16040, "time": 1040.02800822258, "episode/length": 193.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 16208, "time": 1047.6294078826904, "episode/length": 151.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 16512, "time": 1060.9918766021729, "episode/length": 93.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.0}
{"step": 16648, "time": 1066.9080002307892, "episode/length": 75.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 16752, "time": 1072.3805441856384, "episode/length": 159.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 16920, "time": 1079.5673356056213, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 16976, "time": 1083.2934250831604, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 17120, "time": 1089.7322402000427, "episode/length": 202.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 17184, "time": 1093.4634130001068, "episode/length": 151.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 17624, "time": 1109.881412267685, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 17856, "time": 1119.669132232666, "episode/length": 150.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 18272, "time": 1135.572227716446, "episode/length": 189.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 18400, "time": 1141.7399413585663, "episode/length": 235.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9872881355932204, "episode/intrinsic_return": 0.0}
{"step": 18408, "time": 1143.5110914707184, "episode/length": 152.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 18520, "time": 1149.0994987487793, "episode/length": 199.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 18752, "time": 1158.8268711566925, "episode/length": 221.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 18808, "time": 1162.066578388214, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 18808, "time": 1162.075650215149, "episode/length": 147.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 18976, "time": 1171.4470241069794, "episode/length": 70.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9436619718309859, "episode/intrinsic_return": 0.0}
{"step": 19488, "time": 1190.244250535965, "episode/length": 63.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 19568, "time": 1194.5332746505737, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 19600, "time": 1197.241649389267, "episode/length": 217.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 19728, "time": 1203.3815536499023, "episode/length": 150.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 19808, "time": 1207.7456068992615, "episode/length": 124.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.968, "episode/intrinsic_return": 0.0}
{"step": 19992, "time": 1215.3025677204132, "episode/length": 154.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 1240.3846683502197, "eval_episode/length": 153.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.974025974025974}
{"step": 20072, "time": 1242.268964290619, "eval_episode/length": 159.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 20072, "time": 1244.0140688419342, "eval_episode/length": 161.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 20072, "time": 1245.850361585617, "eval_episode/length": 163.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.975609756097561}
{"step": 20072, "time": 1248.0347583293915, "eval_episode/length": 175.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 20072, "time": 1249.8795449733734, "eval_episode/length": 178.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 20072, "time": 1251.6884469985962, "eval_episode/length": 182.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 20072, "time": 1253.675894021988, "eval_episode/length": 188.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 20392, "time": 1264.6862163543701, "episode/length": 72.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9452054794520548, "episode/intrinsic_return": 0.0}
{"step": 20408, "time": 1266.8921566009521, "episode/length": 250.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9880478087649402, "episode/intrinsic_return": 0.0}
{"step": 20512, "time": 1272.3827390670776, "episode/length": 212.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 20712, "time": 1280.5142939090729, "episode/length": 152.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 20936, "time": 1289.917943239212, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 21040, "time": 1295.3254318237305, "episode/length": 183.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 21272, "time": 1304.6667749881744, "episode/length": 192.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 21440, "time": 1312.224065065384, "episode/length": 180.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 21672, "time": 1321.6852383613586, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 21920, "time": 1331.9834716320038, "episode/length": 188.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 22105, "time": 1340.8123474121094, "train_stats/sum_log_reward": 0.9099173237962171, "train_stats/max_log_achievement_collect_drink": 0.19008264462809918, "train_stats/max_log_achievement_collect_sapling": 9.396694214876034, "train_stats/max_log_achievement_collect_wood": 0.10743801652892562, "train_stats/max_log_achievement_place_plant": 0.5289256198347108, "train_stats/max_log_achievement_wake_up": 0.4380165289256198, "train_stats/mean_log_entropy": 0.9892555196915777, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.482082366943359, "train/action_min": 0.0, "train/action_std": 2.4391139205545187, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009360802672858881, "train/actor_opt_grad_steps": 645.0, "train/actor_opt_loss": 134.82689158176072, "train/adv_mag": 1.6138504349801224, "train/adv_max": 1.6059727483370807, "train/adv_mean": 0.01597246259081024, "train/adv_min": -0.4055676489896085, "train/adv_std": 0.12109390261713437, "train/cont_avg": 0.9944992065429688, "train/cont_loss_mean": 0.02702268503708183, "train/cont_loss_std": 0.2528272233903408, "train/cont_neg_acc": 0.05662512476556003, "train/cont_neg_loss": 3.234966474585235, "train/cont_pos_acc": 0.9985395111143589, "train/cont_pos_loss": 0.009131731264687915, "train/cont_pred": 0.9913978008553386, "train/cont_rate": 0.9944992065429688, "train/dyn_loss_mean": 5.339525951072574, "train/dyn_loss_std": 7.762436984630767, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.528074004221708, "train/extr_critic_critic_opt_grad_steps": 645.0, "train/extr_critic_critic_opt_loss": 21226.94393157959, "train/extr_critic_mag": 0.1963674919679761, "train/extr_critic_max": 0.19636749010533094, "train/extr_critic_mean": 0.05903261499979254, "train/extr_critic_min": -0.04542918689548969, "train/extr_critic_std": 0.06457618915045832, "train/extr_return_normed_mag": 1.8634752910354768, "train/extr_return_normed_max": 1.8624164246894703, "train/extr_return_normed_mean": 0.17444540443842976, "train/extr_return_normed_min": -0.3119266946403262, "train/extr_return_normed_std": 0.16062416125356627, "train/extr_return_rate": 0.02375132360441512, "train/extr_return_raw_mag": 1.7636742686680462, "train/extr_return_raw_max": 1.7629759472911246, "train/extr_return_raw_mean": 0.07500491725755909, "train/extr_return_raw_min": -0.41136717614958784, "train/extr_return_raw_std": 0.16062416155915646, "train/extr_reward_mag": 0.4951775558292866, "train/extr_reward_max": 0.49475406017154455, "train/extr_reward_mean": 0.004533920048803708, "train/extr_reward_min": -0.08598572108894587, "train/extr_reward_std": 0.026582873289982878, "train/image_loss_mean": 95.85751259326935, "train/image_loss_std": 52.433516934514046, "train/model_loss_mean": 99.41645912826061, "train/model_loss_std": 53.924321569502354, "train/model_opt_grad_norm": 298.03208929347244, "train/model_opt_grad_steps": 635.0, "train/model_opt_loss": 1320.8193694353104, "train/model_opt_model_opt_grad_overflow": 0.0078125, "train/model_opt_model_opt_grad_scale": 11.8255615234375, "train/policy_entropy_mag": 1.4911607606336474, "train/policy_entropy_max": 1.4911607606336474, "train/policy_entropy_mean": 0.9237211567815393, "train/policy_entropy_min": 0.7533931229845621, "train/policy_entropy_std": 0.098419977544836, "train/policy_logprob_mag": 6.790417551994324, "train/policy_logprob_max": -0.355539234362368, "train/policy_logprob_mean": -0.9248915981152095, "train/policy_logprob_min": -6.790417551994324, "train/policy_logprob_std": 0.7872115143109113, "train/policy_randomness_mag": 0.5263143091724487, "train/policy_randomness_max": 0.5263143091724487, "train/policy_randomness_mean": 0.326033026794903, "train/policy_randomness_min": 0.2659147084632423, "train/policy_randomness_std": 0.034737932876112154, "train/post_ent_mag": 53.20056587457657, "train/post_ent_max": 53.20056587457657, "train/post_ent_mean": 33.972102239727974, "train/post_ent_min": 16.874120447784662, "train/post_ent_std": 6.8988880342803895, "train/prior_ent_mag": 58.484492510557175, "train/prior_ent_max": 58.484492510557175, "train/prior_ent_mean": 39.92756827175617, "train/prior_ent_min": 21.85965023934841, "train/prior_ent_std": 6.238840251113288, "train/rep_loss_mean": 5.339525951072574, "train/rep_loss_std": 7.762436984630767, "train/reward_avg": 0.007100677474227268, "train/reward_loss_mean": 0.3282062868529465, "train/reward_loss_std": 0.6508114515008732, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.6879469687119126, "train/reward_neg_acc": 0.9975350522436202, "train/reward_neg_loss": 0.2930483029340394, "train/reward_pos_acc": 0.46186558331828564, "train/reward_pos_loss": 3.162633112631738, "train/reward_pred": 0.004985686253348831, "train/reward_rate": 0.01206207275390625, "train_stats/max_log_achievement_place_table": 0.02, "train_stats/max_log_achievement_eat_cow": 0.2159090909090909, "train_stats/max_log_achievement_defeat_zombie": 0.15584415584415584, "eval_stats/sum_log_reward": 0.41249998891726136, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 13.5625, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_place_plant": 0.0625, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.01950044184923172, "report/cont_loss_std": 0.20117691159248352, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.027639865875244, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0036883209832012653, "report/cont_pred": 0.9951981902122498, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 6.282878875732422, "report/dyn_loss_std": 5.615083694458008, "report/image_loss_mean": 19.14303207397461, "report/image_loss_std": 13.082918167114258, "report/model_loss_mean": 23.041563034057617, "report/model_loss_std": 14.936201095581055, "report/post_ent_mag": 44.23760223388672, "report/post_ent_max": 44.23760223388672, "report/post_ent_mean": 30.794349670410156, "report/post_ent_min": 12.592558860778809, "report/post_ent_std": 3.881714105606079, "report/prior_ent_mag": 52.64929962158203, "report/prior_ent_max": 52.64929962158203, "report/prior_ent_mean": 38.1118049621582, "report/prior_ent_min": 17.45984649658203, "report/prior_ent_std": 4.056463241577148, "report/rep_loss_mean": 6.282878875732422, "report/rep_loss_std": 5.615083694458008, "report/reward_avg": 0.008105468936264515, "report/reward_loss_mean": 0.10930195450782776, "report/reward_loss_std": 0.42123648524284363, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9876183271408081, "report/reward_neg_acc": 0.9990089535713196, "report/reward_neg_loss": 0.09391973912715912, "report/reward_pos_acc": 0.9333333969116211, "report/reward_pos_loss": 1.1440130472183228, "report/reward_pred": 0.007040172815322876, "report/reward_rate": 0.0146484375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.04660302400588989, "eval/cont_loss_std": 0.6522731781005859, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.908647060394287, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00026484925183467567, "eval/cont_pred": 0.9996809959411621, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 9.000314712524414, "eval/dyn_loss_std": 9.806655883789062, "eval/image_loss_mean": 24.083473205566406, "eval/image_loss_std": 21.95844078063965, "eval/model_loss_mean": 29.651084899902344, "eval/model_loss_std": 25.515277862548828, "eval/post_ent_mag": 41.82413864135742, "eval/post_ent_max": 41.82413864135742, "eval/post_ent_mean": 27.962890625, "eval/post_ent_min": 10.523147583007812, "eval/post_ent_std": 5.546576976776123, "eval/prior_ent_mag": 51.162418365478516, "eval/prior_ent_max": 51.162418365478516, "eval/prior_ent_mean": 35.82825469970703, "eval/prior_ent_min": 17.608224868774414, "eval/prior_ent_std": 6.398529529571533, "eval/rep_loss_mean": 9.000314712524414, "eval/rep_loss_std": 9.806655883789062, "eval/reward_avg": 0.005664062686264515, "eval/reward_loss_mean": 0.12081974744796753, "eval/reward_loss_std": 0.7199366688728333, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9891602993011475, "eval/reward_neg_acc": 0.9960474967956543, "eval/reward_neg_loss": 0.11367958039045334, "eval/reward_pos_acc": 1.0, "eval/reward_pos_loss": 0.7229752540588379, "eval/reward_pred": 0.012546155601739883, "eval/reward_rate": 0.01171875, "replay/size": 21601.0, "replay/inserts": 20544.0, "replay/samples": 20544.0, "replay/insert_wait_avg": 1.5136632035454486e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.037832790446059e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6168.0, "eval_replay/inserts": 3216.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3050748341119112e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 974.5325183868408, "timer/env.step_count": 2568.0, "timer/env.step_total": 272.7020671367645, "timer/env.step_frac": 0.2798285967800978, "timer/env.step_avg": 0.106192393744846, "timer/env.step_min": 0.02411651611328125, "timer/env.step_max": 3.456007957458496, "timer/replay._sample_count": 20544.0, "timer/replay._sample_total": 11.370323419570923, "timer/replay._sample_frac": 0.011667464353464982, "timer/replay._sample_avg": 0.0005534620044573074, "timer/replay._sample_min": 0.0003666877746582031, "timer/replay._sample_max": 0.025373220443725586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2970.0, "timer/agent.policy_total": 52.80935454368591, "timer/agent.policy_frac": 0.054189422669139946, "timer/agent.policy_avg": 0.017780927455786504, "timer/agent.policy_min": 0.009758472442626953, "timer/agent.policy_max": 0.11050939559936523, "timer/dataset_train_count": 1284.0, "timer/dataset_train_total": 0.15699458122253418, "timer/dataset_train_frac": 0.00016109732436882641, "timer/dataset_train_avg": 0.00012226992307050948, "timer/dataset_train_min": 7.939338684082031e-05, "timer/dataset_train_max": 0.00036072731018066406, "timer/agent.train_count": 1284.0, "timer/agent.train_total": 581.6221520900726, "timer/agent.train_frac": 0.5968216977026493, "timer/agent.train_avg": 0.45297675396423104, "timer/agent.train_min": 0.43880701065063477, "timer/agent.train_max": 1.3182940483093262, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4719984531402588, "timer/agent.report_frac": 0.00048433320000605554, "timer/agent.report_avg": 0.2359992265701294, "timer/agent.report_min": 0.22910714149475098, "timer/agent.report_max": 0.2428913116455078, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.547413074214494e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 21.080621827577232}
{"step": 22176, "time": 1343.3090689182281, "episode/length": 182.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 22208, "time": 1346.0444626808167, "episode/length": 66.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9253731343283582, "episode/intrinsic_return": 0.0}
{"step": 22328, "time": 1351.6006028652191, "episode/length": 160.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 22456, "time": 1357.5850837230682, "episode/length": 242.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 22560, "time": 1362.9986538887024, "episode/length": 160.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 22624, "time": 1366.7752561569214, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 22960, "time": 1379.9916367530823, "episode/length": 49.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 23016, "time": 1383.308542251587, "episode/length": 85.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 23384, "time": 1397.3891406059265, "episode/length": 242.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 23392, "time": 1399.5039973258972, "episode/length": 183.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 23424, "time": 1402.1539325714111, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 23496, "time": 1406.056298494339, "episode/length": 164.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 23848, "time": 1419.5818305015564, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 23896, "time": 1422.8680584430695, "episode/length": 109.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 24136, "time": 1432.73939204216, "episode/length": 88.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 24216, "time": 1437.0293550491333, "episode/length": 45.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 24712, "time": 1456.7842078208923, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 24752, "time": 1460.0916180610657, "episode/length": 223.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 24912, "time": 1467.055150270462, "episode/length": 176.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 25072, "time": 1474.2340741157532, "episode/length": 210.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 25168, "time": 1479.1490750312805, "episode/length": 338.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 25200, "time": 1481.8911395072937, "episode/length": 162.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 25288, "time": 1486.2982110977173, "episode/length": 143.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 25672, "time": 1501.1381304264069, "episode/length": 181.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 25928, "time": 1511.393489599228, "episode/length": 126.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 25984, "time": 1515.0322058200836, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 26440, "time": 1532.0552206039429, "episode/length": 210.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 26448, "time": 1534.2841548919678, "episode/length": 171.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 26712, "time": 1544.6438856124878, "episode/length": 192.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 26752, "time": 1547.8210458755493, "episode/length": 182.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 26824, "time": 1551.6354358196259, "episode/length": 202.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 27168, "time": 1565.3106961250305, "episode/length": 186.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 27248, "time": 1569.5746228694916, "episode/length": 157.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 27536, "time": 1580.955231666565, "episode/length": 200.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 27672, "time": 1587.0488066673279, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 27672, "time": 1587.0560929775238, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 28096, "time": 1605.159422159195, "episode/length": 172.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 28160, "time": 1608.9059834480286, "episode/length": 166.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 28464, "time": 1620.9792516231537, "episode/length": 151.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 28488, "time": 1623.2061221599579, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 28728, "time": 1632.9188911914825, "episode/length": 246.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9878542510121457, "episode/intrinsic_return": 0.0}
{"step": 28864, "time": 1639.3188049793243, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 28912, "time": 1642.4517331123352, "episode/length": 93.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.0}
{"step": 28952, "time": 1645.1513195037842, "episode/length": 106.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 28968, "time": 1647.2103126049042, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 29152, "time": 1655.3574714660645, "episode/length": 184.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 29696, "time": 1675.1873450279236, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 29712, "time": 1677.4746885299683, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1711.3313355445862, "eval_episode/length": 149.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 30056, "time": 1713.5169100761414, "eval_episode/length": 159.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 30056, "time": 1715.6769008636475, "eval_episode/length": 169.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 30056, "time": 1717.8935408592224, "eval_episode/length": 181.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 30056, "time": 1719.6192169189453, "eval_episode/length": 185.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 30056, "time": 1721.5803201198578, "eval_episode/length": 189.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 30056, "time": 1726.7566192150116, "eval_episode/length": 238.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9832635983263598}
{"step": 30056, "time": 1729.5472619533539, "eval_episode/length": 263.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9886363636363636}
{"step": 30064, "time": 1730.0461752414703, "episode/length": 166.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 30144, "time": 1734.4017770290375, "episode/length": 148.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 30200, "time": 1737.8296568393707, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 30544, "time": 1751.3284120559692, "episode/length": 103.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 30616, "time": 1755.2600409984589, "episode/length": 218.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 30728, "time": 1760.5766251087189, "episode/length": 226.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 30840, "time": 1766.0293452739716, "episode/length": 210.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 30904, "time": 1769.9525554180145, "episode/length": 94.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9578947368421052, "episode/intrinsic_return": 0.0}
{"step": 31360, "time": 1787.2268509864807, "episode/length": 207.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 31448, "time": 1791.667345046997, "episode/length": 172.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 31464, "time": 1793.7659685611725, "episode/length": 157.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 31752, "time": 1805.6696090698242, "episode/length": 127.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 32000, "time": 1815.9183912277222, "episode/length": 181.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 32424, "time": 1831.7426490783691, "episode/length": 225.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 32688, "time": 1842.597084760666, "episode/length": 154.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 32792, "time": 1848.821492433548, "episode/length": 235.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9872881355932204, "episode/intrinsic_return": 0.0}
{"step": 32872, "time": 1853.242113351822, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 33048, "time": 1861.095162153244, "episode/length": 275.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 33056, "time": 1863.2041912078857, "episode/length": 198.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 33144, "time": 1867.592042207718, "episode/length": 173.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 33440, "time": 1879.6817870140076, "episode/length": 179.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 33576, "time": 1885.745875120163, "episode/length": 64.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 33664, "time": 1890.6861958503723, "episode/length": 154.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 33960, "time": 1902.0661227703094, "episode/length": 145.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 34312, "time": 1915.6819882392883, "episode/length": 179.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 34360, "time": 1919.0598888397217, "episode/length": 151.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 34712, "time": 1932.5947597026825, "episode/length": 141.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 34736, "time": 1935.2626609802246, "episode/length": 255.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.98828125, "episode/intrinsic_return": 0.0}
{"step": 34776, "time": 1937.965086698532, "episode/length": 166.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 34896, "time": 1943.9162046909332, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 35144, "time": 1953.6987392902374, "episode/length": 261.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 35520, "time": 1968.128088235855, "episode/length": 150.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 35776, "time": 1978.5538530349731, "episode/length": 176.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 35944, "time": 1985.5659148693085, "episode/length": 153.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 36000, "time": 1989.3884115219116, "episode/length": 254.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 36384, "time": 2004.0146296024323, "episode/length": 200.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 36440, "time": 2007.3034286499023, "episode/length": 192.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 36536, "time": 2012.405846118927, "episode/length": 173.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 36680, "time": 2018.9350023269653, "episode/length": 242.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 37016, "time": 2031.9513356685638, "episode/length": 186.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 37192, "time": 2039.6419763565063, "episode/length": 176.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 37296, "time": 2044.965904712677, "episode/length": 168.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 37392, "time": 2049.9554092884064, "episode/length": 173.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 37688, "time": 2061.3087277412415, "episode/length": 155.0, "episode/score": -0.9000000208616257, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 37848, "time": 2068.3986213207245, "episode/length": 182.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 38200, "time": 2081.874400615692, "episode/length": 189.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 38232, "time": 2084.52548289299, "episode/length": 116.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9572649572649573, "episode/intrinsic_return": 0.0}
{"step": 38392, "time": 2091.5066525936127, "episode/length": 149.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 38408, "time": 2093.7313635349274, "episode/length": 173.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 38984, "time": 2115.0835976600647, "episode/length": 161.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 39080, "time": 2119.89479804039, "episode/length": 210.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 39144, "time": 2123.7516765594482, "episode/length": 161.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 39248, "time": 2129.218199491501, "episode/length": 338.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 39496, "time": 2139.036132335663, "episode/length": 161.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 39536, "time": 2142.3219137191772, "episode/length": 162.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 39608, "time": 2146.228547811508, "episode/length": 151.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 2180.6837582588196, "eval_episode/length": 63.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.921875}
{"step": 40040, "time": 2186.418833255768, "eval_episode/length": 143.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 40040, "time": 2188.5720682144165, "eval_episode/length": 88.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9438202247191011}
{"step": 40040, "time": 2190.8286328315735, "eval_episode/length": 167.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 40040, "time": 2192.5901622772217, "eval_episode/length": 169.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 40040, "time": 2194.3933506011963, "eval_episode/length": 172.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 40040, "time": 2196.7608301639557, "eval_episode/length": 35.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8888888888888888}
{"step": 40040, "time": 2198.828266620636, "eval_episode/length": 198.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 40080, "time": 2200.3841190338135, "episode/length": 208.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 40184, "time": 2205.33709526062, "episode/length": 149.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 40296, "time": 2210.6804893016815, "episode/length": 130.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 40384, "time": 2215.5835270881653, "episode/length": 154.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 40472, "time": 2220.0760946273804, "episode/length": 173.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 40912, "time": 2236.7427866458893, "episode/length": 65.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 40928, "time": 2238.963529586792, "episode/length": 164.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 40984, "time": 2243.483931541443, "episode/length": 185.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 41280, "time": 2255.351430416107, "episode/length": 149.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 41512, "time": 2264.555958509445, "episode/length": 151.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 41664, "time": 2271.4797053337097, "episode/length": 184.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 41752, "time": 2275.740123987198, "episode/length": 159.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 42152, "time": 2291.0408523082733, "episode/length": 152.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 42248, "time": 2295.906131505966, "episode/length": 338.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 42528, "time": 2307.1988201141357, "episode/length": 155.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 42616, "time": 2311.7282795906067, "episode/length": 212.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 42712, "time": 2316.5259714126587, "episode/length": 215.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 42848, "time": 2322.999976158142, "episode/length": 166.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 43016, "time": 2330.117888689041, "episode/length": 168.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 43257, "time": 2340.849705696106, "train_stats/sum_log_reward": 0.04308941736211622, "train_stats/max_log_achievement_collect_drink": 0.0, "train_stats/max_log_achievement_collect_sapling": 8.203252032520325, "train_stats/max_log_achievement_collect_wood": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.13821138211382114, "train_stats/max_log_achievement_eat_cow": 0.0975609756097561, "train_stats/max_log_achievement_place_plant": 0.2601626016260163, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 0.07317073170731707, "train_stats/mean_log_entropy": 0.08246409244895951, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.610840768525095, "train/action_min": 0.0, "train/action_std": 0.567131983962926, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0018262210837747261, "train/actor_opt_grad_steps": 1945.0, "train/actor_opt_loss": 11.977383795899875, "train/adv_mag": 3.158190445466475, "train/adv_max": 3.1507912905830326, "train/adv_mean": 0.021474809551088554, "train/adv_min": -0.7221461076176527, "train/adv_std": 0.22277027424989324, "train/cont_avg": 0.9941258285984849, "train/cont_loss_mean": 0.0035710218114948502, "train/cont_loss_std": 0.05293278127890682, "train/cont_neg_acc": 0.8377104437712467, "train/cont_neg_loss": 0.3750674047962203, "train/cont_pos_acc": 0.9996498254212466, "train/cont_pos_loss": 0.0013582505742523278, "train/cont_pred": 0.9941022468335701, "train/cont_rate": 0.9941258285984849, "train/dyn_loss_mean": 6.37766306328051, "train/dyn_loss_std": 5.779145208272067, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4161770219604175, "train/extr_critic_critic_opt_grad_steps": 1945.0, "train/extr_critic_critic_opt_loss": 15605.909113103693, "train/extr_critic_mag": 0.8178952507900469, "train/extr_critic_max": 0.8178952507900469, "train/extr_critic_mean": -0.01232221579553108, "train/extr_critic_min": -0.37175710092891345, "train/extr_critic_std": 0.24892117895863272, "train/extr_return_normed_mag": 3.9302488764127097, "train/extr_return_normed_max": 3.9302488764127097, "train/extr_return_normed_mean": 0.3450336422432553, "train/extr_return_normed_min": -0.45234703306447377, "train/extr_return_normed_std": 0.3491623337295922, "train/extr_return_rate": 0.08960158690443319, "train/extr_return_raw_mag": 4.089281857013702, "train/extr_return_raw_max": 4.087887992461522, "train/extr_return_raw_mean": 0.013627113835272294, "train/extr_return_raw_min": -0.8765353492715142, "train/extr_return_raw_std": 0.3982971345610691, "train/extr_reward_mag": 0.9783266665357532, "train/extr_reward_max": 0.9783266665357532, "train/extr_reward_mean": 0.011584971687267225, "train/extr_reward_min": -0.30093640901825647, "train/extr_reward_std": 0.06774098083913101, "train/image_loss_mean": 14.805762962861495, "train/image_loss_std": 12.427263635577578, "train/model_loss_mean": 18.70667669989846, "train/model_loss_std": 14.202715100664081, "train/model_opt_grad_norm": 120.24876542524858, "train/model_opt_grad_steps": 1935.0, "train/model_opt_loss": 508.6224362922437, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 28.261126893939394, "train/policy_entropy_mag": 0.17345386037998128, "train/policy_entropy_max": 0.17345386037998128, "train/policy_entropy_mean": 0.08395557370827053, "train/policy_entropy_min": 0.07952238258087274, "train/policy_entropy_std": 0.006369785492510841, "train/policy_logprob_mag": 7.437646681612188, "train/policy_logprob_max": -0.009476325848619595, "train/policy_logprob_mean": -0.08295459159170136, "train/policy_logprob_min": -7.437646681612188, "train/policy_logprob_std": 0.7207613293871735, "train/policy_randomness_mag": 0.061221601272171196, "train/policy_randomness_max": 0.061221601272171196, "train/policy_randomness_mean": 0.02963263321329247, "train/policy_randomness_min": 0.028067911297760227, "train/policy_randomness_std": 0.0022482547916352455, "train/post_ent_mag": 43.342303882945664, "train/post_ent_max": 43.342303882945664, "train/post_ent_mean": 31.465615836056795, "train/post_ent_min": 17.06465983390808, "train/post_ent_std": 3.596206511511947, "train/prior_ent_mag": 52.57754086003159, "train/prior_ent_max": 52.57754086003159, "train/prior_ent_mean": 38.01936120697946, "train/prior_ent_min": 22.38644078283599, "train/prior_ent_std": 3.9017999985001306, "train/rep_loss_mean": 6.37766306328051, "train/rep_loss_std": 5.779145208272067, "train/reward_avg": 0.004082327111311976, "train/reward_loss_mean": 0.0707448686077965, "train/reward_loss_std": 0.3457870844638709, "train/reward_max_data": 1.0015151518763918, "train/reward_max_pred": 0.99378220149965, "train/reward_neg_acc": 0.9971837324626518, "train/reward_neg_loss": 0.057481055281999885, "train/reward_pos_acc": 0.8402751336495081, "train/reward_pos_loss": 1.4872947497801348, "train/reward_pred": 0.0035073411426944376, "train/reward_rate": 0.009477095170454546, "eval_stats/sum_log_reward": 0.22499998286366463, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 8.625, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00014250684762373567, "report/cont_loss_std": 0.003416690044105053, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.020291417837142944, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.822107828455046e-06, "report/cont_pred": 0.993293285369873, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 5.40994930267334, "report/dyn_loss_std": 5.36578893661499, "report/image_loss_mean": 10.566069602966309, "report/image_loss_std": 9.805212020874023, "report/model_loss_mean": 13.85496711730957, "report/model_loss_std": 11.508973121643066, "report/post_ent_mag": 39.188133239746094, "report/post_ent_max": 39.188133239746094, "report/post_ent_mean": 31.40576171875, "report/post_ent_min": 15.161593437194824, "report/post_ent_std": 3.69248628616333, "report/prior_ent_mag": 49.400482177734375, "report/prior_ent_max": 49.400482177734375, "report/prior_ent_mean": 37.72941589355469, "report/prior_ent_min": 21.49538803100586, "report/prior_ent_std": 3.7042272090911865, "report/rep_loss_mean": 5.40994930267334, "report/rep_loss_std": 5.36578893661499, "report/reward_avg": -0.00205078162252903, "report/reward_loss_mean": 0.04278568550944328, "report/reward_loss_std": 0.19769661128520966, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9952040910720825, "report/reward_neg_acc": 0.9970559477806091, "report/reward_neg_loss": 0.03920815885066986, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7718855142593384, "report/reward_pred": -0.0017173053929582238, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.0005310294800437987, "eval/cont_loss_std": 0.015172054059803486, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004062615800648928, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0005032217595726252, "eval/cont_pred": 0.9918184876441956, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 9.852839469909668, "eval/dyn_loss_std": 7.966443061828613, "eval/image_loss_mean": 17.271387100219727, "eval/image_loss_std": 18.64767074584961, "eval/model_loss_mean": 23.29379653930664, "eval/model_loss_std": 21.21576690673828, "eval/post_ent_mag": 39.10448455810547, "eval/post_ent_max": 39.10448455810547, "eval/post_ent_mean": 28.028038024902344, "eval/post_ent_min": 13.336322784423828, "eval/post_ent_std": 4.604481220245361, "eval/prior_ent_mag": 57.469215393066406, "eval/prior_ent_max": 57.469215393066406, "eval/prior_ent_mean": 36.884742736816406, "eval/prior_ent_min": 19.421009063720703, "eval/prior_ent_std": 6.582946300506592, "eval/rep_loss_mean": 9.852839469909668, "eval/rep_loss_std": 7.966443061828613, "eval/reward_avg": 0.003808593610301614, "eval/reward_loss_mean": 0.11017534136772156, "eval/reward_loss_std": 0.6629078388214111, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9922916889190674, "eval/reward_neg_acc": 0.9940770268440247, "eval/reward_neg_loss": 0.08738013356924057, "eval/reward_pos_acc": 0.6363636255264282, "eval/reward_pos_loss": 2.2094078063964844, "eval/reward_pred": 0.005293922498822212, "eval/reward_rate": 0.0107421875, "replay/size": 42753.0, "replay/inserts": 21152.0, "replay/samples": 21152.0, "replay/insert_wait_avg": 1.536093302826297e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.926381682483944e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9872.0, "eval_replay/inserts": 3704.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3149711534734935e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3709068298339844e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0278902053833, "timer/env.step_count": 2644.0, "timer/env.step_total": 275.75598311424255, "timer/env.step_frac": 0.27574829243773236, "timer/env.step_avg": 0.1042950011778527, "timer/env.step_min": 0.024137496948242188, "timer/env.step_max": 3.6634950637817383, "timer/replay._sample_count": 21152.0, "timer/replay._sample_total": 11.424511909484863, "timer/replay._sample_frac": 0.011424193286387767, "timer/replay._sample_avg": 0.0005401149730278396, "timer/replay._sample_min": 0.00037741661071777344, "timer/replay._sample_max": 0.012544870376586914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3107.0, "timer/agent.policy_total": 54.876705169677734, "timer/agent.policy_frac": 0.05487517468978519, "timer/agent.policy_avg": 0.01766228038933947, "timer/agent.policy_min": 0.009665966033935547, "timer/agent.policy_max": 0.11781454086303711, "timer/dataset_train_count": 1322.0, "timer/dataset_train_total": 0.15817689895629883, "timer/dataset_train_frac": 0.00015817248749313667, "timer/dataset_train_avg": 0.00011964969663865267, "timer/dataset_train_min": 0.00010061264038085938, "timer/dataset_train_max": 0.0010657310485839844, "timer/agent.train_count": 1322.0, "timer/agent.train_total": 597.0112104415894, "timer/agent.train_frac": 0.5969945601406943, "timer/agent.train_avg": 0.4515969821797196, "timer/agent.train_min": 0.4367830753326416, "timer/agent.train_max": 1.255218505859375, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46924495697021484, "timer/agent.report_frac": 0.00046923186999698826, "timer/agent.report_avg": 0.23462247848510742, "timer/agent.report_min": 0.22449135780334473, "timer/agent.report_max": 0.24475359916687012, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.4345855712890625e-05, "timer/dataset_eval_frac": 4.434461893236096e-08, "timer/dataset_eval_avg": 4.4345855712890625e-05, "timer/dataset_eval_min": 4.4345855712890625e-05, "timer/dataset_eval_max": 4.4345855712890625e-05, "fps": 21.15115504385602}
{"step": 43456, "time": 2347.642215013504, "episode/length": 104.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 43712, "time": 2357.9056918621063, "episode/length": 194.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 43760, "time": 2361.107610464096, "episode/length": 188.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 43776, "time": 2363.2395589351654, "episode/length": 252.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9881422924901185, "episode/intrinsic_return": 0.0}
{"step": 43920, "time": 2369.8633036613464, "episode/length": 57.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.0}
{"step": 44216, "time": 2381.3518373966217, "episode/length": 170.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 44328, "time": 2386.7874841690063, "episode/length": 76.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.948051948051948, "episode/intrinsic_return": 0.0}
{"step": 44336, "time": 2388.8889570236206, "episode/length": 225.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 44376, "time": 2391.585258960724, "episode/length": 207.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 44392, "time": 2393.701016187668, "episode/length": 171.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 44992, "time": 2416.0357291698456, "episode/length": 153.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 45416, "time": 2432.0137901306152, "episode/length": 204.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 45504, "time": 2436.8534772396088, "episode/length": 145.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 45568, "time": 2440.611343860626, "episode/length": 205.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 45592, "time": 2442.907814502716, "episode/length": 151.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 45664, "time": 2447.1822006702423, "episode/length": 180.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 45808, "time": 2453.8404121398926, "episode/length": 184.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 46032, "time": 2463.332544326782, "episode/length": 204.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 46296, "time": 2473.6774756908417, "episode/length": 162.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 46520, "time": 2482.9634511470795, "episode/length": 60.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 46640, "time": 2489.021209001541, "episode/length": 152.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 46816, "time": 2496.718073606491, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 46944, "time": 2502.8576498031616, "episode/length": 171.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 46976, "time": 2505.5114023685455, "episode/length": 163.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 47464, "time": 2523.685616016388, "episode/length": 233.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 47736, "time": 2534.522340774536, "episode/length": 179.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 47776, "time": 2537.7704441547394, "episode/length": 119.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 47784, "time": 2539.54763174057, "episode/length": 157.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 47904, "time": 2545.4716997146606, "episode/length": 157.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 48032, "time": 2551.4649908542633, "episode/length": 135.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 48168, "time": 2557.4662413597107, "episode/length": 294.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 48360, "time": 2565.580585718155, "episode/length": 172.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 48960, "time": 2587.839327096939, "episode/length": 186.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 49088, "time": 2593.821588754654, "episode/length": 168.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 49144, "time": 2597.047264099121, "episode/length": 170.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 49208, "time": 2602.0492448806763, "episode/length": 162.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 49336, "time": 2608.2452273368835, "episode/length": 145.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 49456, "time": 2614.172788143158, "episode/length": 177.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 49472, "time": 2616.3099253177643, "episode/length": 210.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 49840, "time": 2630.296932220459, "episode/length": 184.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 49856, "time": 2632.407011985779, "episode/length": 88.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 2654.7504732608795, "eval_episode/length": 36.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8648648648648649}
{"step": 50024, "time": 2658.6212379932404, "eval_episode/length": 82.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9397590361445783}
{"step": 50024, "time": 2661.7799773216248, "eval_episode/length": 115.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 50024, "time": 2665.3890092372894, "eval_episode/length": 160.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 50024, "time": 2667.9631690979004, "eval_episode/length": 174.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 50024, "time": 2669.735051393509, "eval_episode/length": 178.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.994413407821229}
{"step": 50024, "time": 2672.12886428833, "eval_episode/length": 158.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 50024, "time": 2673.82213139534, "eval_episode/length": 196.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 50368, "time": 2685.6911771297455, "episode/length": 175.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 50480, "time": 2691.1262485980988, "episode/length": 127.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 50488, "time": 2692.8318462371826, "episode/length": 143.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 50784, "time": 2704.9699952602386, "episode/length": 37.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 50816, "time": 2707.7057597637177, "episode/length": 200.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 50936, "time": 2713.2040343284607, "episode/length": 182.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 50968, "time": 2715.7828924655914, "episode/length": 234.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 51104, "time": 2722.295296192169, "episode/length": 155.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 51288, "time": 2730.2365679740906, "episode/length": 180.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 51784, "time": 2748.751019716263, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 51864, "time": 2753.570023536682, "episode/length": 186.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 51864, "time": 2753.587605237961, "episode/length": 134.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 52104, "time": 2765.9953694343567, "episode/length": 160.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 52176, "time": 2770.251993894577, "episode/length": 154.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 52184, "time": 2772.03941655159, "episode/length": 151.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 52360, "time": 2779.6541833877563, "episode/length": 156.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 52664, "time": 2791.8581068515778, "episode/length": 60.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9344262295081968, "episode/intrinsic_return": 0.0}
{"step": 52760, "time": 2796.69491314888, "episode/length": 183.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 53168, "time": 2812.259580373764, "episode/length": 162.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 53224, "time": 2815.525210618973, "episode/length": 179.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 53288, "time": 2819.582704305649, "episode/length": 147.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 53592, "time": 2831.653354406357, "episode/length": 175.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 53816, "time": 2840.9029891490936, "episode/length": 181.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 53832, "time": 2843.0626373291016, "episode/length": 133.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 53880, "time": 2846.337492465973, "episode/length": 151.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 53936, "time": 2850.3085963726044, "episode/length": 258.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9884169884169884, "episode/intrinsic_return": 0.0}
{"step": 54504, "time": 2870.857829809189, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 54752, "time": 2881.31312084198, "episode/length": 182.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 54792, "time": 2884.027023792267, "episode/length": 202.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 54880, "time": 2888.7500190734863, "episode/length": 132.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 54992, "time": 2894.2816348075867, "episode/length": 131.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 55112, "time": 2899.641229391098, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 55176, "time": 2903.3176834583282, "episode/length": 197.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 55192, "time": 2905.603768825531, "episode/length": 49.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 55240, "time": 2908.969530105591, "episode/length": 169.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 56080, "time": 2939.2968871593475, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 56144, "time": 2943.163964033127, "episode/length": 204.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 56224, "time": 2947.523671388626, "episode/length": 167.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 56296, "time": 2951.3558728694916, "episode/length": 131.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 56472, "time": 2958.9404356479645, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 56496, "time": 2961.653836250305, "episode/length": 172.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 56824, "time": 2974.3849353790283, "episode/length": 228.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 56944, "time": 2980.313048839569, "episode/length": 218.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 57240, "time": 2991.752925157547, "episode/length": 144.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 57400, "time": 3000.0782301425934, "episode/length": 156.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 57400, "time": 3000.0879697799683, "episode/length": 137.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 57568, "time": 3009.5059258937836, "episode/length": 167.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 57712, "time": 3015.9678025245667, "episode/length": 110.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.963963963963964, "episode/intrinsic_return": 0.0}
{"step": 57872, "time": 3023.0984687805176, "episode/length": 174.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 58088, "time": 3032.015503883362, "episode/length": 198.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 58280, "time": 3040.1090693473816, "episode/length": 88.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 58544, "time": 3050.868983745575, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 58632, "time": 3055.2377173900604, "episode/length": 210.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 58752, "time": 3061.3576769828796, "episode/length": 168.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 58864, "time": 3066.757166624069, "episode/length": 182.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 58960, "time": 3071.690932750702, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 59368, "time": 3086.9448187351227, "episode/length": 186.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 59384, "time": 3089.235939979553, "episode/length": 78.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 59456, "time": 3093.5291740894318, "episode/length": 170.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 59544, "time": 3097.8704838752747, "episode/length": 157.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 59736, "time": 3106.0772240161896, "episode/length": 137.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 59792, "time": 3109.7978734970093, "episode/length": 50.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 59976, "time": 3117.2923612594604, "episode/length": 53.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9074074074074074, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 3137.9008746147156, "eval_episode/length": 94.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9368421052631579}
{"step": 60008, "time": 3142.5279397964478, "eval_episode/length": 157.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 60008, "time": 3144.350614786148, "eval_episode/length": 162.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 60008, "time": 3146.012610912323, "eval_episode/length": 163.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 60008, "time": 3149.0773923397064, "eval_episode/length": 190.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 60008, "time": 3151.6522443294525, "eval_episode/length": 212.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 60008, "time": 3153.883526802063, "eval_episode/length": 224.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9822222222222222}
{"step": 60008, "time": 3156.798497200012, "eval_episode/length": 157.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 60232, "time": 3164.3593168258667, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 60296, "time": 3168.2089323997498, "episode/length": 218.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 60432, "time": 3174.6375665664673, "episode/length": 132.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 60448, "time": 3176.7417397499084, "episode/length": 197.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 60704, "time": 3187.334450483322, "episode/length": 50.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 60936, "time": 3196.624819278717, "episode/length": 142.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 60944, "time": 3198.8379831314087, "episode/length": 185.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 61064, "time": 3204.275679588318, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 61432, "time": 3218.440325498581, "episode/length": 181.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 61536, "time": 3223.7684075832367, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 61656, "time": 3229.2954154014587, "episode/length": 150.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 61768, "time": 3234.937629699707, "episode/length": 132.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 62024, "time": 3245.486392021179, "episode/length": 135.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 62392, "time": 3259.511101961136, "episode/length": 244.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9877551020408163, "episode/intrinsic_return": 0.0}
{"step": 62392, "time": 3259.55171084404, "episode/length": 180.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 62576, "time": 3269.5812001228333, "episode/length": 142.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 62688, "time": 3274.9968070983887, "episode/length": 202.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 62888, "time": 3283.140589237213, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 63080, "time": 3291.3132584095, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 63864, "time": 3319.5791203975677, "episode/length": 146.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 63904, "time": 3322.8631031513214, "episode/length": 188.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 63912, "time": 3324.5418667793274, "episode/length": 189.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 63928, "time": 3326.7518105506897, "episode/length": 298.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9933110367892977, "episode/intrinsic_return": 0.0}
{"step": 64008, "time": 3331.3394033908844, "episode/length": 247.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 64040, "time": 3333.9806835651398, "episode/length": 182.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 64169, "time": 3341.0219600200653, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 9.621316924349951, "train/action_min": 0.0, "train/action_std": 1.134053986946135, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.017930945885257274, "train/actor_opt_grad_steps": 3260.0, "train/actor_opt_loss": 14.502739438573823, "train/adv_mag": 2.382279997108547, "train/adv_max": 2.3800781410159044, "train/adv_mean": 0.018388846664027868, "train/adv_min": -0.6578888915877306, "train/adv_std": 0.1750219522882964, "train/cont_avg": 0.9941033516221374, "train/cont_loss_mean": 0.0006221219191537028, "train/cont_loss_std": 0.016729232741655664, "train/cont_neg_acc": 0.9811671808475756, "train/cont_neg_loss": 0.06832380738485201, "train/cont_pos_acc": 0.9999325589369271, "train/cont_pos_loss": 0.000226376256121352, "train/cont_pred": 0.9941166930526267, "train/cont_rate": 0.9941033516221374, "train/dyn_loss_mean": 6.0760718010764085, "train/dyn_loss_std": 5.813502013228322, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4674209847705055, "train/extr_critic_critic_opt_grad_steps": 3260.0, "train/extr_critic_critic_opt_loss": 16848.83164360687, "train/extr_critic_mag": 1.9670899241935207, "train/extr_critic_max": 1.9670899241935207, "train/extr_critic_mean": 0.3384869999842334, "train/extr_critic_min": -0.3189396803615657, "train/extr_critic_std": 0.5691381871472788, "train/extr_return_normed_mag": 3.4347695512626006, "train/extr_return_normed_max": 3.4347695512626006, "train/extr_return_normed_mean": 0.3315139613078751, "train/extr_return_normed_min": -0.26780935109571646, "train/extr_return_normed_std": 0.3815834083174931, "train/extr_return_rate": 0.2979614102487801, "train/extr_return_raw_mag": 6.014811301049385, "train/extr_return_raw_max": 6.014811301049385, "train/extr_return_raw_mean": 0.3715841205729432, "train/extr_return_raw_min": -0.7485577309404621, "train/extr_return_raw_std": 0.7110164254221297, "train/extr_reward_mag": 1.0009992068050473, "train/extr_reward_max": 1.0009992068050473, "train/extr_reward_mean": 0.01852009517499708, "train/extr_reward_min": -0.4170300114245815, "train/extr_reward_std": 0.10931748916743365, "train/image_loss_mean": 9.54525214115172, "train/image_loss_std": 9.30712037050087, "train/model_loss_mean": 13.23070764177628, "train/model_loss_std": 11.266803956213797, "train/model_opt_grad_norm": 94.3945687854563, "train/model_opt_grad_steps": 3250.0, "train/model_opt_loss": 858.1178935975519, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 65.8993320610687, "train/policy_entropy_mag": 0.6544435341053336, "train/policy_entropy_max": 0.6544435341053336, "train/policy_entropy_mean": 0.1261642575263977, "train/policy_entropy_min": 0.07943195332097643, "train/policy_entropy_std": 0.1092733470043203, "train/policy_logprob_mag": 7.438365393922529, "train/policy_logprob_max": -0.009463972632439081, "train/policy_logprob_mean": -0.12656926153270343, "train/policy_logprob_min": -7.438365393922529, "train/policy_logprob_std": 0.7624608833371228, "train/policy_randomness_mag": 0.2309898477587991, "train/policy_randomness_max": 0.2309898477587991, "train/policy_randomness_mean": 0.044530445979979204, "train/policy_randomness_min": 0.028035993794448502, "train/policy_randomness_std": 0.0385686958837745, "train/post_ent_mag": 41.29104093012919, "train/post_ent_max": 41.29104093012919, "train/post_ent_mean": 32.13797608586668, "train/post_ent_min": 16.441532775645946, "train/post_ent_std": 4.137799472299241, "train/prior_ent_mag": 52.62016008100437, "train/prior_ent_max": 52.62016008100437, "train/prior_ent_mean": 38.349472890373406, "train/prior_ent_min": 20.37761066524127, "train/prior_ent_std": 4.243394220148334, "train/rep_loss_mean": 6.0760718010764085, "train/rep_loss_std": 5.813502013228322, "train/reward_avg": 0.00171830267369932, "train/reward_loss_mean": 0.039190184765758404, "train/reward_loss_std": 0.22743670682188208, "train/reward_max_data": 1.0038167948031242, "train/reward_max_pred": 0.9992406695853663, "train/reward_neg_acc": 0.9967018461409416, "train/reward_neg_loss": 0.031647603674471836, "train/reward_pos_acc": 0.9241567058417633, "train/reward_pos_loss": 1.0865137945604688, "train/reward_pred": 0.0016381290184959542, "train/reward_rate": 0.007096851145038168, "train_stats/sum_log_reward": -0.21007752441620642, "train_stats/max_log_achievement_collect_drink": 0.0, "train_stats/max_log_achievement_collect_sapling": 0.007751937984496124, "train_stats/max_log_achievement_collect_wood": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_place_plant": 0.007751937984496124, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 1.7751937984496124, "train_stats/mean_log_entropy": 0.14938907244408778, "eval_stats/sum_log_reward": 0.03750000614672899, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 2.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.3407194021274336e-05, "report/cont_loss_std": 0.0002915616787504405, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002871948527172208, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.430053069081623e-06, "report/cont_pred": 0.9951217770576477, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 5.901578903198242, "report/dyn_loss_std": 6.036806583404541, "report/image_loss_mean": 6.686049461364746, "report/image_loss_std": 8.995861053466797, "report/model_loss_mean": 10.261795043945312, "report/model_loss_std": 11.301934242248535, "report/post_ent_mag": 41.11534118652344, "report/post_ent_max": 41.11534118652344, "report/post_ent_mean": 31.206085205078125, "report/post_ent_min": 13.878451347351074, "report/post_ent_std": 4.8060102462768555, "report/prior_ent_mag": 52.2894287109375, "report/prior_ent_max": 52.2894287109375, "report/prior_ent_mean": 37.98773193359375, "report/prior_ent_min": 14.218238830566406, "report/prior_ent_std": 5.668455600738525, "report/rep_loss_mean": 5.901578903198242, "report/rep_loss_std": 6.036806583404541, "report/reward_avg": 0.004199218936264515, "report/reward_loss_mean": 0.03477519005537033, "report/reward_loss_std": 0.21548041701316833, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9986686706542969, "report/reward_neg_acc": 0.9990147948265076, "report/reward_neg_loss": 0.02889852784574032, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6975319981575012, "report/reward_pred": 0.003821158781647682, "report/reward_rate": 0.0087890625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00022281365818344057, "eval/cont_loss_std": 0.006068277172744274, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.005618629045784473, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00019633762713056058, "eval/cont_pred": 0.9949661493301392, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 12.056838989257812, "eval/dyn_loss_std": 7.851968288421631, "eval/image_loss_mean": 25.94446563720703, "eval/image_loss_std": 33.06282424926758, "eval/model_loss_mean": 33.26438903808594, "eval/model_loss_std": 34.270286560058594, "eval/post_ent_mag": 38.13188171386719, "eval/post_ent_max": 38.13188171386719, "eval/post_ent_mean": 28.76707649230957, "eval/post_ent_min": 14.426151275634766, "eval/post_ent_std": 4.396724700927734, "eval/prior_ent_mag": 59.505271911621094, "eval/prior_ent_max": 59.505271911621094, "eval/prior_ent_mean": 38.45426559448242, "eval/prior_ent_min": 16.454898834228516, "eval/prior_ent_std": 7.361340045928955, "eval/rep_loss_mean": 12.056838989257812, "eval/rep_loss_std": 7.851968288421631, "eval/reward_avg": 0.00859374925494194, "eval/reward_loss_mean": 0.0855993777513504, "eval/reward_loss_std": 0.5809940695762634, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9997323751449585, "eval/reward_neg_acc": 0.996039628982544, "eval/reward_neg_loss": 0.05902915820479393, "eval/reward_pos_acc": 0.785714328289032, "eval/reward_pos_loss": 2.002451181411743, "eval/reward_pred": 0.007687103934586048, "eval/reward_rate": 0.013671875, "replay/size": 63665.0, "replay/inserts": 20912.0, "replay/samples": 20912.0, "replay/insert_wait_avg": 1.5758747532792738e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.023354266924811e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 13472.0, "eval_replay/inserts": 3600.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3273954391479492e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1592833995819, "timer/env.step_count": 2614.0, "timer/env.step_total": 284.37432384490967, "timer/env.step_frac": 0.284329034949623, "timer/env.step_avg": 0.10878895326890194, "timer/env.step_min": 0.024016618728637695, "timer/env.step_max": 4.1192872524261475, "timer/replay._sample_count": 20912.0, "timer/replay._sample_total": 11.648216247558594, "timer/replay._sample_frac": 0.011646361175557791, "timer/replay._sample_avg": 0.0005570111059467575, "timer/replay._sample_min": 0.0003840923309326172, "timer/replay._sample_max": 0.010753154754638672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3064.0, "timer/agent.policy_total": 55.29048991203308, "timer/agent.policy_frac": 0.05528168445739809, "timer/agent.policy_avg": 0.01804519905745205, "timer/agent.policy_min": 0.009911775588989258, "timer/agent.policy_max": 0.0962672233581543, "timer/dataset_train_count": 1307.0, "timer/dataset_train_total": 0.1584155559539795, "timer/dataset_train_frac": 0.00015839032700423338, "timer/dataset_train_avg": 0.00012120547509868362, "timer/dataset_train_min": 0.00010371208190917969, "timer/dataset_train_max": 0.0004961490631103516, "timer/agent.train_count": 1307.0, "timer/agent.train_total": 591.91601395607, "timer/agent.train_frac": 0.5918217465763288, "timer/agent.train_avg": 0.4528814184820734, "timer/agent.train_min": 0.44002795219421387, "timer/agent.train_max": 1.281935214996338, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48111844062805176, "timer/agent.report_frac": 0.0004810418186518358, "timer/agent.report_avg": 0.24055922031402588, "timer/agent.report_min": 0.23174262046813965, "timer/agent.report_max": 0.2493758201599121, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.194300160972013e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 20.908416938928298}
{"step": 64192, "time": 3341.742828130722, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 64616, "time": 3357.9319307804108, "episode/length": 75.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 64640, "time": 3360.5828037261963, "episode/length": 194.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 3365.5208570957184, "episode/length": 67.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 65056, "time": 3378.0918712615967, "episode/length": 142.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 65104, "time": 3381.2999386787415, "episode/length": 149.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 65256, "time": 3387.9301464557648, "episode/length": 173.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 65448, "time": 3396.1190440654755, "episode/length": 175.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 65696, "time": 3407.4989693164825, "episode/length": 220.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 66016, "time": 3420.117326259613, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 66072, "time": 3423.456855535507, "episode/length": 46.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 66240, "time": 3431.055727005005, "episode/length": 199.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 66248, "time": 3432.776062965393, "episode/length": 203.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 66336, "time": 3437.6153903007507, "episode/length": 159.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 66456, "time": 3443.131228685379, "episode/length": 168.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 66560, "time": 3448.675230741501, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 66792, "time": 3457.92400431633, "episode/length": 167.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 67112, "time": 3470.5554127693176, "episode/length": 136.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 67256, "time": 3477.192073583603, "episode/length": 147.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 67480, "time": 3486.6590337753296, "episode/length": 142.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.951048951048951, "episode/intrinsic_return": 0.0}
{"step": 67552, "time": 3490.8886868953705, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 67584, "time": 3493.540728330612, "episode/length": 167.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 67744, "time": 3500.593616247177, "episode/length": 147.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 67944, "time": 3508.824672937393, "episode/length": 185.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 68264, "time": 3521.218929052353, "episode/length": 143.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 68304, "time": 3524.4265592098236, "episode/length": 69.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9142857142857143, "episode/intrinsic_return": 0.0}
{"step": 68504, "time": 3532.632572889328, "episode/length": 213.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 68720, "time": 3541.876736164093, "episode/length": 182.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 68728, "time": 3543.6104373931885, "episode/length": 142.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 68824, "time": 3548.538897752762, "episode/length": 158.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 68880, "time": 3552.202689409256, "episode/length": 174.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 69080, "time": 3560.4718255996704, "episode/length": 141.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 69496, "time": 3576.311021089554, "episode/length": 153.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 69904, "time": 3591.997800350189, "episode/length": 199.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 69992, "time": 3596.2840299606323, "episode/length": 145.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 70088, "time": 3601.481009244919, "episode/length": 170.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3620.433896303177, "eval_episode/length": 67.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9411764705882353}
{"step": 70096, "time": 3625.206140756607, "eval_episode/length": 138.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 70096, "time": 3626.9690334796906, "eval_episode/length": 140.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9645390070921985}
{"step": 70096, "time": 3628.884326696396, "eval_episode/length": 145.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 70096, "time": 3630.6468255519867, "eval_episode/length": 149.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 70096, "time": 3632.3858239650726, "eval_episode/length": 150.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 70096, "time": 3634.1276228427887, "eval_episode/length": 151.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 70096, "time": 3638.530901670456, "eval_episode/length": 146.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 70160, "time": 3640.690081834793, "episode/length": 206.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 70240, "time": 3644.970052242279, "episode/length": 144.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 70384, "time": 3651.5825226306915, "episode/length": 187.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 70640, "time": 3662.08180642128, "episode/length": 238.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 70712, "time": 3665.91579413414, "episode/length": 40.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 70896, "time": 3674.028648853302, "episode/length": 174.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 71232, "time": 3687.1117086410522, "episode/length": 142.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 71312, "time": 3691.684794664383, "episode/length": 143.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 71824, "time": 3711.019620656967, "episode/length": 138.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 71968, "time": 3717.4860339164734, "episode/length": 257.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 72032, "time": 3721.4773683547974, "episode/length": 173.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 72320, "time": 3732.9617018699646, "episode/length": 290.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 72328, "time": 3734.6630301475525, "episode/length": 260.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 72408, "time": 3738.960268497467, "episode/length": 188.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 72720, "time": 3751.375547647476, "episode/length": 185.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 72752, "time": 3754.073620080948, "episode/length": 97.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9387755102040817, "episode/intrinsic_return": 0.0}
{"step": 73192, "time": 3770.4039812088013, "episode/length": 234.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 73336, "time": 3776.804835796356, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 73640, "time": 3788.93021440506, "episode/length": 153.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 73768, "time": 3795.982202768326, "episode/length": 126.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 73896, "time": 3802.1147911548615, "episode/length": 146.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 74008, "time": 3807.5715975761414, "episode/length": 272.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 74096, "time": 3812.544958591461, "episode/length": 221.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 74128, "time": 3815.235979795456, "episode/length": 224.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 74656, "time": 3834.8234045505524, "episode/length": 69.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 74672, "time": 3836.9442994594574, "episode/length": 166.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 74728, "time": 3840.3885867595673, "episode/length": 191.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 75168, "time": 3857.0958709716797, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 75264, "time": 3861.9116237163544, "episode/length": 202.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 75456, "time": 3870.1040556430817, "episode/length": 180.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 75456, "time": 3870.1119616031647, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 75896, "time": 3888.2626481056213, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 75928, "time": 3891.0160522460938, "episode/length": 149.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 76240, "time": 3903.627545118332, "episode/length": 197.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 76376, "time": 3909.5561861991882, "episode/length": 138.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 76648, "time": 3920.376589536667, "episode/length": 148.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 76672, "time": 3922.92986536026, "episode/length": 362.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 76720, "time": 3926.065422773361, "episode/length": 157.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 76880, "time": 3933.064088344574, "episode/length": 213.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 77384, "time": 3951.4831392765045, "episode/length": 142.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 77400, "time": 3953.564917087555, "episode/length": 187.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 77504, "time": 3959.0500304698944, "episode/length": 77.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 77544, "time": 3962.1732082366943, "episode/length": 201.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 77936, "time": 3977.2000753879547, "episode/length": 160.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 78008, "time": 3980.984402656555, "episode/length": 203.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 78408, "time": 3996.3022310733795, "episode/length": 210.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 78552, "time": 4002.784603834152, "episode/length": 234.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 78696, "time": 4009.26496553421, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 78784, "time": 4014.1319279670715, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 78816, "time": 4016.809654712677, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 79288, "time": 4034.469975709915, "episode/length": 237.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 79368, "time": 4038.7778854370117, "episode/length": 178.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 79552, "time": 4046.90003991127, "episode/length": 142.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 79600, "time": 4050.2852745056152, "episode/length": 198.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 79840, "time": 4060.135220527649, "episode/length": 127.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 4069.7976262569427, "episode/length": 190.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 4086.960216999054, "eval_episode/length": 82.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9879518072289156}
{"step": 80080, "time": 4092.825356245041, "eval_episode/length": 151.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.993421052631579}
{"step": 80080, "time": 4094.6165080070496, "eval_episode/length": 155.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 80080, "time": 4096.825083494186, "eval_episode/length": 165.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 80080, "time": 4098.4944024086, "eval_episode/length": 166.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 80080, "time": 4102.266147375107, "eval_episode/length": 215.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 80080, "time": 4104.656587600708, "eval_episode/length": 228.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.982532751091703}
{"step": 80080, "time": 4107.914182186127, "eval_episode/length": 258.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9961389961389961}
{"step": 80168, "time": 4112.369264364243, "episode/length": 172.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 80536, "time": 4126.3309025764465, "episode/length": 229.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 80816, "time": 4137.638128519058, "episode/length": 157.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 80832, "time": 4140.0868268013, "episode/length": 182.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 81000, "time": 4147.220409393311, "episode/length": 114.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 81080, "time": 4151.439497232437, "episode/length": 223.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 81136, "time": 4155.1462569236755, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 81144, "time": 4156.73605632782, "episode/length": 192.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 81552, "time": 4172.469087123871, "episode/length": 172.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 81576, "time": 4174.623586893082, "episode/length": 92.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.946236559139785, "episode/intrinsic_return": 0.0}
{"step": 82152, "time": 4196.853724718094, "episode/length": 166.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 82224, "time": 4201.352682828903, "episode/length": 210.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 82320, "time": 4206.166783571243, "episode/length": 147.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 82344, "time": 4208.433649301529, "episode/length": 149.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 82432, "time": 4213.231793642044, "episode/length": 168.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 82744, "time": 4225.186655759811, "episode/length": 217.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 82872, "time": 4231.165059089661, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 83264, "time": 4246.311233758926, "episode/length": 138.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 83344, "time": 4250.587375640869, "episode/length": 223.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 83416, "time": 4254.376690387726, "episode/length": 67.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 83536, "time": 4260.408826589584, "episode/length": 98.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9595959595959596, "episode/intrinsic_return": 0.0}
{"step": 83608, "time": 4264.316242218018, "episode/length": 172.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 83664, "time": 4268.064454317093, "episode/length": 167.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 83688, "time": 4270.2399315834045, "episode/length": 167.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 83984, "time": 4282.130924940109, "episode/length": 70.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9154929577464789, "episode/intrinsic_return": 0.0}
{"step": 84120, "time": 4288.346371889114, "episode/length": 210.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 84400, "time": 4299.547197818756, "episode/length": 34.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 84608, "time": 4308.19898891449, "episode/length": 117.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9576271186440678, "episode/intrinsic_return": 0.0}
{"step": 84624, "time": 4310.326702833176, "episode/length": 169.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 84760, "time": 4316.471267938614, "episode/length": 176.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 85152, "time": 4331.751916646957, "episode/length": 201.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 85208, "time": 4335.068031787872, "episode/length": 199.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 85321, "time": 4341.48298573494, "train_stats/sum_log_reward": 0.10806451395394341, "train_stats/max_log_achievement_collect_drink": 0.024193548387096774, "train_stats/max_log_achievement_collect_sapling": 0.008064516129032258, "train_stats/max_log_achievement_collect_wood": 0.008064516129032258, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_place_plant": 0.008064516129032258, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 2.064516129032258, "train_stats/mean_log_entropy": 0.29549056237503407, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.378002282344934, "train/action_min": 0.0, "train/action_std": 2.9539378411842114, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.030495597818640596, "train/actor_opt_grad_steps": 4575.0, "train/actor_opt_loss": 4.326070264659145, "train/adv_mag": 2.019583553978891, "train/adv_max": 2.005817332051017, "train/adv_mean": 0.006206443051331173, "train/adv_min": -0.8058068226232673, "train/adv_std": 0.13279135211963544, "train/cont_avg": 0.9942663944128788, "train/cont_loss_mean": 0.0005343735207120379, "train/cont_loss_std": 0.013566076226025512, "train/cont_neg_acc": 0.9858104889139985, "train/cont_neg_loss": 0.04035381865425465, "train/cont_pos_acc": 0.9998660543651292, "train/cont_pos_loss": 0.0002964330837282129, "train/cont_pred": 0.9942048837741216, "train/cont_rate": 0.9942663944128788, "train/dyn_loss_mean": 7.125465779593497, "train/dyn_loss_std": 6.402286305572048, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1848752769556912, "train/extr_critic_critic_opt_grad_steps": 4575.0, "train/extr_critic_critic_opt_loss": 13918.264803799715, "train/extr_critic_mag": 2.638173267696843, "train/extr_critic_max": 2.638173267696843, "train/extr_critic_mean": 0.32720641955507523, "train/extr_critic_min": -0.288059213847825, "train/extr_critic_std": 0.5582279793240807, "train/extr_return_normed_mag": 3.3855730493863425, "train/extr_return_normed_max": 3.3855730493863425, "train/extr_return_normed_mean": 0.36144662174311554, "train/extr_return_normed_min": -0.31550364563185157, "train/extr_return_normed_std": 0.3956426619128747, "train/extr_return_rate": 0.3331104183964657, "train/extr_return_raw_mag": 4.98444283731056, "train/extr_return_raw_max": 4.98444283731056, "train/extr_return_raw_mean": 0.3364442065358162, "train/extr_return_raw_min": -0.7064819372061527, "train/extr_return_raw_std": 0.6104110061670794, "train/extr_reward_mag": 1.0055474575721857, "train/extr_reward_max": 1.0055474575721857, "train/extr_reward_mean": 0.012966928876597773, "train/extr_reward_min": -0.4209714053255139, "train/extr_reward_std": 0.10212582476775754, "train/image_loss_mean": 9.156680540605025, "train/image_loss_std": 14.578497008843856, "train/model_loss_mean": 13.46709856120023, "train/model_loss_std": 16.66628175432032, "train/model_opt_grad_norm": 101.38191528031321, "train/model_opt_grad_steps": 4565.0, "train/model_opt_loss": 2444.0322801994553, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 176.37310606060606, "train/policy_entropy_mag": 1.9386855007121058, "train/policy_entropy_max": 1.9386855007121058, "train/policy_entropy_mean": 0.31654691075285274, "train/policy_entropy_min": 0.07942788285965269, "train/policy_entropy_std": 0.3331327254347729, "train/policy_logprob_mag": 7.438307552626639, "train/policy_logprob_max": -0.009463427115626859, "train/policy_logprob_mean": -0.31637801252531284, "train/policy_logprob_min": -7.438307552626639, "train/policy_logprob_std": 0.9727101307926755, "train/policy_randomness_mag": 0.6842709066289844, "train/policy_randomness_max": 0.6842709066289844, "train/policy_randomness_mean": 0.11172716776755723, "train/policy_randomness_min": 0.028034557023960533, "train/policy_randomness_std": 0.11758123225334918, "train/post_ent_mag": 42.44671217600504, "train/post_ent_max": 42.44671217600504, "train/post_ent_mean": 32.18074759570035, "train/post_ent_min": 14.825871113574866, "train/post_ent_std": 5.207372533552574, "train/prior_ent_mag": 53.7258280840787, "train/prior_ent_max": 53.7258280840787, "train/prior_ent_mean": 39.11210811499393, "train/prior_ent_min": 15.996865099126643, "train/prior_ent_std": 5.809119365432045, "train/rep_loss_mean": 7.125465779593497, "train/rep_loss_std": 6.402286305572048, "train/reward_avg": 0.0011104698739169787, "train/reward_loss_mean": 0.034604200161993504, "train/reward_loss_std": 0.20810992163464878, "train/reward_max_data": 1.0030303037527837, "train/reward_max_pred": 0.9971042266397765, "train/reward_neg_acc": 0.9972150863120051, "train/reward_neg_loss": 0.02828131737469724, "train/reward_pos_acc": 0.9384891174056313, "train/reward_pos_loss": 1.03308395680153, "train/reward_pred": 0.0009296026087902261, "train/reward_rate": 0.006310665246212121, "eval_stats/sum_log_reward": 0.0999999986961484, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0005614475230686367, "report/cont_loss_std": 0.01791926845908165, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.676978495714138e-07, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.000563094625249505, "report/cont_pred": 0.9966428279876709, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 6.718947410583496, "report/dyn_loss_std": 6.980992794036865, "report/image_loss_mean": 13.912437438964844, "report/image_loss_std": 19.275733947753906, "report/model_loss_mean": 17.95856475830078, "report/model_loss_std": 21.145248413085938, "report/post_ent_mag": 43.41316223144531, "report/post_ent_max": 43.41316223144531, "report/post_ent_mean": 32.10100555419922, "report/post_ent_min": 16.29012680053711, "report/post_ent_std": 5.67755651473999, "report/prior_ent_mag": 54.29214096069336, "report/prior_ent_max": 54.29214096069336, "report/prior_ent_mean": 38.26793670654297, "report/prior_ent_min": 14.053729057312012, "report/prior_ent_std": 6.972769260406494, "report/rep_loss_mean": 6.718947410583496, "report/rep_loss_std": 6.980992794036865, "report/reward_avg": 0.0024414064828306437, "report/reward_loss_mean": 0.014196774922311306, "report/reward_loss_std": 0.09135095030069351, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9979190826416016, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01094965822994709, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6759594082832336, "report/reward_pred": 0.002580922096967697, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.0068949601845816e-05, "eval/cont_loss_std": 0.0006318508530966938, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.77200126927346e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.013461511931382e-05, "eval/cont_pred": 0.9970306158065796, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 12.272229194641113, "eval/dyn_loss_std": 8.725042343139648, "eval/image_loss_mean": 19.657299041748047, "eval/image_loss_std": 24.374372482299805, "eval/model_loss_mean": 27.100915908813477, "eval/model_loss_std": 26.62937355041504, "eval/post_ent_mag": 39.165863037109375, "eval/post_ent_max": 39.165863037109375, "eval/post_ent_mean": 28.138168334960938, "eval/post_ent_min": 14.75373649597168, "eval/post_ent_std": 5.692323207855225, "eval/prior_ent_mag": 54.29214096069336, "eval/prior_ent_max": 54.29214096069336, "eval/prior_ent_mean": 37.41766357421875, "eval/prior_ent_min": 14.695985794067383, "eval/prior_ent_std": 9.92387580871582, "eval/rep_loss_mean": 12.272229194641113, "eval/rep_loss_std": 8.725042343139648, "eval/reward_avg": 0.008007812313735485, "eval/reward_loss_mean": 0.08024102449417114, "eval/reward_loss_std": 0.5916696190834045, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9924677610397339, "eval/reward_neg_acc": 0.9990108609199524, "eval/reward_neg_loss": 0.039651330560445786, "eval/reward_pos_acc": 0.46153849363327026, "eval/reward_pos_loss": 3.236870527267456, "eval/reward_pred": 0.0005742417415603995, "eval/reward_rate": 0.0126953125, "replay/size": 84817.0, "replay/inserts": 21152.0, "replay/samples": 21152.0, "replay/insert_wait_avg": 1.490781148515202e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.740173525961733e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17264.0, "eval_replay/inserts": 3792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2794250174413753e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4501571655273, "timer/env.step_count": 2644.0, "timer/env.step_total": 276.2646346092224, "timer/env.step_frac": 0.2761403280618543, "timer/env.step_avg": 0.10448738071453192, "timer/env.step_min": 0.023874998092651367, "timer/env.step_max": 3.4692699909210205, "timer/replay._sample_count": 21152.0, "timer/replay._sample_total": 11.728478908538818, "timer/replay._sample_frac": 0.011723201625324257, "timer/replay._sample_avg": 0.0005544855762357611, "timer/replay._sample_min": 0.0003993511199951172, "timer/replay._sample_max": 0.028505802154541016, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3118.0, "timer/agent.policy_total": 55.82976031303406, "timer/agent.policy_frac": 0.055804639454713846, "timer/agent.policy_avg": 0.017905631915661982, "timer/agent.policy_min": 0.009987354278564453, "timer/agent.policy_max": 0.12313222885131836, "timer/dataset_train_count": 1322.0, "timer/dataset_train_total": 0.14894795417785645, "timer/dataset_train_frac": 0.0001488809343584446, "timer/dataset_train_avg": 0.00011266864915117734, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.00037026405334472656, "timer/agent.train_count": 1322.0, "timer/agent.train_total": 598.4497249126434, "timer/agent.train_frac": 0.598180449696934, "timer/agent.train_avg": 0.45268511718051696, "timer/agent.train_min": 0.4395594596862793, "timer/agent.train_max": 1.2980983257293701, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46802234649658203, "timer/agent.report_frac": 0.0004678117576817437, "timer/agent.report_avg": 0.23401117324829102, "timer/agent.report_min": 0.22326087951660156, "timer/agent.report_max": 0.24476146697998047, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0503846599876916e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 21.142229444259314}
{"step": 85328, "time": 4341.495887994766, "episode/length": 204.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 85680, "time": 4355.630005598068, "episode/length": 211.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 85776, "time": 4360.460115671158, "episode/length": 171.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 85936, "time": 4367.518380641937, "episode/length": 165.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 85984, "time": 4370.671704292297, "episode/length": 169.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 86280, "time": 4382.148666858673, "episode/length": 189.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 86432, "time": 4389.109861373901, "episode/length": 152.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 86584, "time": 4395.55432343483, "episode/length": 80.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9382716049382716, "episode/intrinsic_return": 0.0}
{"step": 87200, "time": 4418.32927942276, "episode/length": 189.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 87312, "time": 4423.731315851212, "episode/length": 191.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 87376, "time": 4427.407293796539, "episode/length": 136.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 87496, "time": 4432.849246025085, "episode/length": 188.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 87640, "time": 4439.505340576172, "episode/length": 310.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9935691318327974, "episode/intrinsic_return": 0.0}
{"step": 88032, "time": 4454.518959522247, "episode/length": 199.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 88400, "time": 4469.256564617157, "episode/length": 226.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 88528, "time": 4475.284910440445, "episode/length": 165.0, "episode/score": 0.10000003129243851, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 88536, "time": 4476.945992946625, "episode/length": 400.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 88576, "time": 4480.1104872226715, "episode/length": 67.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 88808, "time": 4489.323968887329, "episode/length": 186.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 89128, "time": 4501.964880943298, "episode/length": 203.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 89240, "time": 4507.387960910797, "episode/length": 199.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 89344, "time": 4512.6378972530365, "episode/length": 245.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 89680, "time": 4525.639878749847, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 89680, "time": 4525.647445678711, "episode/length": 143.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 89736, "time": 4530.689788103104, "episode/length": 149.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 89992, "time": 4541.083654642105, "episode/length": 147.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 4562.044772863388, "eval_episode/length": 70.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9154929577464789}
{"step": 90064, "time": 4567.054811239243, "eval_episode/length": 146.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9591836734693877}
{"step": 90064, "time": 4568.745135068893, "eval_episode/length": 147.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 90064, "time": 4571.065339803696, "eval_episode/length": 160.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 90064, "time": 4572.971369504929, "eval_episode/length": 167.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 90064, "time": 4572.9787447452545, "eval_episode/length": 96.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9484536082474226}
{"step": 90064, "time": 4576.980082988739, "eval_episode/length": 176.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 90064, "time": 4581.043572902679, "eval_episode/length": 227.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 90176, "time": 4586.141001462936, "episode/length": 199.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 90280, "time": 4591.1225435733795, "episode/length": 143.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 90712, "time": 4607.383070707321, "episode/length": 183.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 90872, "time": 4614.418216705322, "episode/length": 148.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 90928, "time": 4618.350788593292, "episode/length": 197.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 91112, "time": 4626.544325828552, "episode/length": 171.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 91456, "time": 4640.16513299942, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 91552, "time": 4645.013042211533, "episode/length": 104.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 91552, "time": 4645.021762609482, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 91712, "time": 4654.030601501465, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 91936, "time": 4663.238940954208, "episode/length": 281.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 92216, "time": 4674.171031236649, "episode/length": 160.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 92360, "time": 4680.804533481598, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 92480, "time": 4686.686015367508, "episode/length": 170.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 92704, "time": 4695.872545719147, "episode/length": 143.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 92816, "time": 4701.3271062374115, "episode/length": 157.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 92840, "time": 4703.456959724426, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 92896, "time": 4707.086963891983, "episode/length": 66.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9402985074626866, "episode/intrinsic_return": 0.0}
{"step": 93176, "time": 4718.123347759247, "episode/length": 154.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 93408, "time": 4727.846089839935, "episode/length": 211.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 93984, "time": 4748.932238340378, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 94024, "time": 4751.639842033386, "episode/length": 225.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 94128, "time": 4756.892520189285, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 94408, "time": 4767.575322151184, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 94504, "time": 4772.555441856384, "episode/length": 210.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 94552, "time": 4775.807112693787, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 94576, "time": 4778.336893320084, "episode/length": 145.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 94976, "time": 4793.43247461319, "episode/length": 58.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 95176, "time": 4801.683182477951, "episode/length": 308.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 95336, "time": 4808.721213340759, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 95560, "time": 4817.828139781952, "episode/length": 143.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 95576, "time": 4819.954353570938, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 95696, "time": 4825.810464143753, "episode/length": 142.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 95800, "time": 4830.733566999435, "episode/length": 29.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 95912, "time": 4836.101570606232, "episode/length": 91.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9456521739130435, "episode/intrinsic_return": 0.0}
{"step": 96048, "time": 4842.476678848267, "episode/length": 133.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 96056, "time": 4844.172076463699, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 96064, "time": 4846.276696920395, "episode/length": 60.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9508196721311475, "episode/intrinsic_return": 0.0}
{"step": 96848, "time": 4874.458585977554, "episode/length": 352.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9971671388101983, "episode/intrinsic_return": 0.0}
{"step": 97032, "time": 4882.040642261505, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 97056, "time": 4884.797597885132, "episode/length": 214.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 97176, "time": 4890.406281232834, "episode/length": 138.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 97248, "time": 4894.699916362762, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 97608, "time": 4908.339707136154, "episode/length": 225.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 97864, "time": 4918.705351114273, "episode/length": 225.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 98008, "time": 4925.193197965622, "episode/length": 244.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 98168, "time": 4932.291790485382, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 98480, "time": 4945.844119548798, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 98680, "time": 4954.048577308655, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 98896, "time": 4963.238063573837, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 98968, "time": 4967.206269979477, "episode/length": 35.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 99040, "time": 4971.436639785767, "episode/length": 146.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 99232, "time": 4979.598883867264, "episode/length": 152.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 99264, "time": 4982.293348789215, "episode/length": 206.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 99592, "time": 4994.670266628265, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 5026.9644939899445, "eval_episode/length": 39.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 100048, "time": 5032.5404171943665, "eval_episode/length": 129.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 100048, "time": 5036.391120433807, "eval_episode/length": 178.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 100048, "time": 5038.550785303116, "eval_episode/length": 144.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 100048, "time": 5041.06702709198, "eval_episode/length": 202.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 100048, "time": 5043.5202095508575, "eval_episode/length": 221.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9819819819819819}
{"step": 100048, "time": 5045.2731738090515, "eval_episode/length": 225.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9823008849557522}
{"step": 100048, "time": 5047.033900022507, "eval_episode/length": 226.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9823788546255506}
{"step": 100272, "time": 5054.617876052856, "episode/length": 223.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 100376, "time": 5059.496562957764, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 100424, "time": 5062.692624092102, "episode/length": 396.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9773299748110831, "episode/intrinsic_return": 0.0}
{"step": 100440, "time": 5064.950204849243, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 100568, "time": 5070.977454423904, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 100568, "time": 5070.984892129898, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 100736, "time": 5080.275830030441, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 101080, "time": 5093.265838623047, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 101408, "time": 5106.330535411835, "episode/length": 104.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 101760, "time": 5119.873588085175, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 102024, "time": 5130.222096204758, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 102072, "time": 5133.390461921692, "episode/length": 224.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 102184, "time": 5138.677044868469, "episode/length": 137.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 102216, "time": 5141.364614009857, "episode/length": 221.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 102288, "time": 5145.575553894043, "episode/length": 193.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 102816, "time": 5165.167204856873, "episode/length": 131.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 102984, "time": 5172.205403089523, "episode/length": 95.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9479166666666666, "episode/intrinsic_return": 0.0}
{"step": 103128, "time": 5178.702648162842, "episode/length": 214.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 103328, "time": 5187.2770001888275, "episode/length": 162.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 103584, "time": 5197.606526136398, "episode/length": 394.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9772151898734177, "episode/intrinsic_return": 0.0}
{"step": 103648, "time": 5201.463557481766, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 103968, "time": 5213.782048940659, "episode/length": 236.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 104184, "time": 5222.798792362213, "episode/length": 249.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 104552, "time": 5236.847568035126, "episode/length": 216.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 104712, "time": 5243.901493549347, "episode/length": 215.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 104824, "time": 5249.418741941452, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 105032, "time": 5257.9718363285065, "episode/length": 172.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 105080, "time": 5261.241106271744, "episode/length": 186.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 105312, "time": 5270.916030406952, "episode/length": 94.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 105352, "time": 5273.608865261078, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 105448, "time": 5278.533092021942, "episode/length": 184.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 106024, "time": 5299.571103096008, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 106304, "time": 5311.009505748749, "episode/length": 396.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9773299748110831, "episode/intrinsic_return": 0.0}
{"step": 106488, "time": 5318.606023788452, "episode/length": 181.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 106712, "time": 5329.277099609375, "episode/length": 235.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 106800, "time": 5334.2328045368195, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 106880, "time": 5338.765260696411, "episode/length": 224.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 106905, "time": 5341.9068467617035, "train_stats/sum_log_reward": 1.8627118053451432, "train_stats/max_log_achievement_collect_drink": 3.7033898305084745, "train_stats/max_log_achievement_collect_sapling": 2.3135593220338984, "train_stats/max_log_achievement_collect_wood": 0.2288135593220339, "train_stats/max_log_achievement_defeat_zombie": 0.07627118644067797, "train_stats/max_log_achievement_eat_cow": 0.09322033898305085, "train_stats/max_log_achievement_place_plant": 1.3728813559322033, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 2.635593220338983, "train_stats/mean_log_entropy": 0.4664938644332401, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.660602936921296, "train/action_min": 0.0, "train/action_std": 2.714483164857935, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03995590036114057, "train/actor_opt_grad_steps": 5910.0, "train/actor_opt_loss": 20.841843194652487, "train/adv_mag": 1.451493458836167, "train/adv_max": 1.4439952768661357, "train/adv_mean": 0.012988546004204115, "train/adv_min": -0.6307655685477787, "train/adv_std": 0.11598062570448275, "train/cont_avg": 0.994017650462963, "train/cont_loss_mean": 0.0006999196022206888, "train/cont_loss_std": 0.02025946432359315, "train/cont_neg_acc": 0.9781981220951786, "train/cont_neg_loss": 0.09200892340355553, "train/cont_pos_acc": 0.9999490552478366, "train/cont_pos_loss": 0.00014466012538110607, "train/cont_pred": 0.9940897323467114, "train/cont_rate": 0.994017650462963, "train/dyn_loss_mean": 7.8132390481454355, "train/dyn_loss_std": 7.096420051433422, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2466521082101045, "train/extr_critic_critic_opt_grad_steps": 5910.0, "train/extr_critic_critic_opt_loss": 15494.451019965278, "train/extr_critic_mag": 2.90599862381264, "train/extr_critic_max": 2.90599862381264, "train/extr_critic_mean": 0.5427765376038022, "train/extr_critic_min": -0.2939058339154279, "train/extr_critic_std": 0.7036871570127982, "train/extr_return_normed_mag": 2.5075743710553207, "train/extr_return_normed_max": 2.5075743710553207, "train/extr_return_normed_mean": 0.3682774272229936, "train/extr_return_normed_min": -0.2692831001899861, "train/extr_return_normed_std": 0.37289945814344616, "train/extr_return_rate": 0.3935657994614707, "train/extr_return_raw_mag": 4.878272466306333, "train/extr_return_raw_max": 4.878272466306333, "train/extr_return_raw_mean": 0.5695697966549131, "train/extr_return_raw_min": -0.7492610582598933, "train/extr_return_raw_std": 0.7685413042704264, "train/extr_reward_mag": 1.006694797233299, "train/extr_reward_max": 1.006694797233299, "train/extr_reward_mean": 0.01506015247216931, "train/extr_reward_min": -0.4968105051252577, "train/extr_reward_std": 0.11041909420379886, "train/image_loss_mean": 10.234627932089346, "train/image_loss_std": 16.730982413115324, "train/model_loss_mean": 14.958432451883953, "train/model_loss_std": 19.075086077937375, "train/model_opt_grad_norm": 85.51846525404189, "train/model_opt_grad_steps": 5900.0, "train/model_opt_loss": 6654.56599573206, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 444.44444444444446, "train/policy_entropy_mag": 1.965179204940796, "train/policy_entropy_max": 1.965179204940796, "train/policy_entropy_mean": 0.45874490053565414, "train/policy_entropy_min": 0.07940832001191599, "train/policy_entropy_std": 0.3692156874471241, "train/policy_logprob_mag": 7.438169917353878, "train/policy_logprob_max": -0.009460817505088117, "train/policy_logprob_mean": -0.45927298367023467, "train/policy_logprob_min": -7.438169917353878, "train/policy_logprob_std": 1.035554599320447, "train/policy_randomness_mag": 0.6936220177897701, "train/policy_randomness_max": 0.6936220177897701, "train/policy_randomness_mean": 0.16191681954595777, "train/policy_randomness_min": 0.028027652148847226, "train/policy_randomness_std": 0.13031693426547228, "train/post_ent_mag": 43.79384030942564, "train/post_ent_max": 43.79384030942564, "train/post_ent_mean": 32.26764838607223, "train/post_ent_min": 14.47709420522054, "train/post_ent_std": 5.548638008258961, "train/prior_ent_mag": 56.663366134078416, "train/prior_ent_max": 56.663366134078416, "train/prior_ent_mean": 40.12198963871709, "train/prior_ent_min": 15.512974004392271, "train/prior_ent_std": 6.6894216996652105, "train/rep_loss_mean": 7.8132390481454355, "train/rep_loss_std": 7.096420051433422, "train/reward_avg": 0.002058015022797648, "train/reward_loss_mean": 0.03516121071383909, "train/reward_loss_std": 0.20516687780618667, "train/reward_max_data": 1.0029629636693884, "train/reward_max_pred": 0.9980762472859135, "train/reward_neg_acc": 0.9965874137701811, "train/reward_neg_loss": 0.027775427512824535, "train/reward_pos_acc": 0.9384422461191814, "train/reward_pos_loss": 1.0260374974321436, "train/reward_pred": 0.0019742404929948628, "train/reward_rate": 0.007371238425925926, "eval_stats/sum_log_reward": 1.474999949336052, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_eat_plant": 0.02857142857142857, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0002201393072027713, "report/cont_loss_std": 0.0033718119375407696, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.015708601102232933, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00014414096949622035, "report/cont_pred": 0.9950502514839172, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 8.189214706420898, "report/dyn_loss_std": 7.029102325439453, "report/image_loss_mean": 9.337099075317383, "report/image_loss_std": 18.690275192260742, "report/model_loss_mean": 14.275731086730957, "report/model_loss_std": 20.94463539123535, "report/post_ent_mag": 44.546539306640625, "report/post_ent_max": 44.546539306640625, "report/post_ent_mean": 31.702083587646484, "report/post_ent_min": 13.79604721069336, "report/post_ent_std": 6.407773494720459, "report/prior_ent_mag": 56.88756561279297, "report/prior_ent_max": 56.88756561279297, "report/prior_ent_mean": 40.38399887084961, "report/prior_ent_min": 15.458196640014648, "report/prior_ent_std": 7.951554775238037, "report/rep_loss_mean": 8.189214706420898, "report/rep_loss_std": 7.029102325439453, "report/reward_avg": 0.0022460937034338713, "report/reward_loss_mean": 0.024882979691028595, "report/reward_loss_std": 0.1368497759103775, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0004510879516602, "report/reward_neg_acc": 0.9990166425704956, "report/reward_neg_loss": 0.019129876047372818, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8607265949249268, "report/reward_pred": 0.001822775462642312, "report/reward_rate": 0.0068359375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 2.6885340048465878e-05, "eval/cont_loss_std": 0.0001241789577761665, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.0217349881713744e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.6983580028172582e-05, "eval/cont_pred": 0.9941138625144958, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 12.774285316467285, "eval/dyn_loss_std": 8.789158821105957, "eval/image_loss_mean": 12.798063278198242, "eval/image_loss_std": 15.404864311218262, "eval/model_loss_mean": 20.506969451904297, "eval/model_loss_std": 18.59921646118164, "eval/post_ent_mag": 40.53831481933594, "eval/post_ent_max": 40.53831481933594, "eval/post_ent_mean": 28.08316421508789, "eval/post_ent_min": 12.275493621826172, "eval/post_ent_std": 5.364517688751221, "eval/prior_ent_mag": 54.944068908691406, "eval/prior_ent_max": 54.944068908691406, "eval/prior_ent_mean": 38.96307373046875, "eval/prior_ent_min": 15.553428649902344, "eval/prior_ent_std": 8.708724021911621, "eval/rep_loss_mean": 12.774285316467285, "eval/rep_loss_std": 8.789158821105957, "eval/reward_avg": 0.0021484375465661287, "eval/reward_loss_mean": 0.04430874437093735, "eval/reward_loss_std": 0.3524426519870758, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0046617984771729, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.02940470539033413, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 1.9371213912963867, "eval/reward_pred": -0.0007523298263549805, "eval/reward_rate": 0.0078125, "replay/size": 106401.0, "replay/inserts": 21584.0, "replay/samples": 21584.0, "replay/insert_wait_avg": 1.4470585016430174e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.866687983915133e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20904.0, "eval_replay/inserts": 3640.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3611473879971346e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4007670879364, "timer/env.step_count": 2698.0, "timer/env.step_total": 264.4714262485504, "timer/env.step_frac": 0.26436547726607557, "timer/env.step_avg": 0.09802499119664582, "timer/env.step_min": 0.023502588272094727, "timer/env.step_max": 3.5436573028564453, "timer/replay._sample_count": 21584.0, "timer/replay._sample_total": 12.05452823638916, "timer/replay._sample_frac": 0.012049699113564906, "timer/replay._sample_avg": 0.0005584937099883784, "timer/replay._sample_min": 0.00035572052001953125, "timer/replay._sample_max": 0.031231164932250977, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3153.0, "timer/agent.policy_total": 55.51637268066406, "timer/agent.policy_frac": 0.05549413245880099, "timer/agent.policy_avg": 0.017607476270429454, "timer/agent.policy_min": 0.009865522384643555, "timer/agent.policy_max": 0.11131620407104492, "timer/dataset_train_count": 1349.0, "timer/dataset_train_total": 0.15344667434692383, "timer/dataset_train_frac": 0.0001533852026059429, "timer/dataset_train_avg": 0.00011374846133945428, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.0002384185791015625, "timer/agent.train_count": 1349.0, "timer/agent.train_total": 610.997419834137, "timer/agent.train_frac": 0.6107526502730376, "timer/agent.train_avg": 0.4529261822343491, "timer/agent.train_min": 0.4387233257293701, "timer/agent.train_max": 1.499563455581665, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4689903259277344, "timer/agent.report_frac": 0.00046880244533689924, "timer/agent.report_avg": 0.2344951629638672, "timer/agent.report_min": 0.22211027145385742, "timer/agent.report_max": 0.24688005447387695, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098199871779854e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 21.57505882535556}
{"step": 106968, "time": 5343.959688663483, "episode/length": 206.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 107432, "time": 5361.274569988251, "episode/length": 259.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 107656, "time": 5370.644918680191, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 107888, "time": 5380.458182811737, "episode/length": 232.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 107912, "time": 5382.73534154892, "episode/length": 149.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 108000, "time": 5387.455716609955, "episode/length": 139.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 108144, "time": 5393.891338348389, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 108152, "time": 5395.492829799652, "episode/length": 61.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9354838709677419, "episode/intrinsic_return": 0.0}
{"step": 108224, "time": 5399.915735960007, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 108416, "time": 5407.906765699387, "episode/length": 32.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 108680, "time": 5418.183877229691, "episode/length": 213.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 108752, "time": 5422.476153612137, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 109200, "time": 5439.249897956848, "episode/length": 160.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 109256, "time": 5442.60763335228, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 109272, "time": 5444.834486246109, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 109504, "time": 5454.593133449554, "episode/length": 135.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 109512, "time": 5456.350034713745, "episode/length": 103.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9423076923076923, "episode/intrinsic_return": 0.0}
{"step": 109632, "time": 5462.474320411682, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 109648, "time": 5464.590071439743, "episode/length": 187.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 5499.502423286438, "eval_episode/length": 152.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 110032, "time": 5501.706020116806, "eval_episode/length": 166.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 110032, "time": 5503.367785453796, "eval_episode/length": 167.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 110032, "time": 5505.333503484726, "eval_episode/length": 170.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 110032, "time": 5507.454396486282, "eval_episode/length": 182.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.994535519125683}
{"step": 110032, "time": 5509.411730051041, "eval_episode/length": 187.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 110032, "time": 5511.830193996429, "eval_episode/length": 206.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 110032, "time": 5513.58465719223, "eval_episode/length": 39.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 110648, "time": 5534.429219961166, "episode/length": 180.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 110680, "time": 5537.178609371185, "episode/length": 240.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 110736, "time": 5540.841815948486, "episode/length": 137.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 110800, "time": 5544.66343665123, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 111104, "time": 5556.763970851898, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 111112, "time": 5558.440219163895, "episode/length": 231.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 111176, "time": 5562.236939430237, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 111328, "time": 5569.175937414169, "episode/length": 227.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9692982456140351, "episode/intrinsic_return": 0.0}
{"step": 111560, "time": 5578.457082033157, "episode/length": 55.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9107142857142857, "episode/intrinsic_return": 0.0}
{"step": 111952, "time": 5593.40806889534, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 112088, "time": 5599.374229431152, "episode/length": 175.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 112208, "time": 5605.249174833298, "episode/length": 175.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 112320, "time": 5610.8194308280945, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 112720, "time": 5625.974944591522, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 112888, "time": 5632.9267320632935, "episode/length": 222.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 112912, "time": 5635.647557020187, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 113000, "time": 5640.119333744049, "episode/length": 98.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9393939393939394, "episode/intrinsic_return": 0.0}
{"step": 113600, "time": 5662.261121749878, "episode/length": 205.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 113664, "time": 5666.049420595169, "episode/length": 310.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 113712, "time": 5669.62754368782, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 113936, "time": 5678.857395648956, "episode/length": 230.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 113944, "time": 5680.523702383041, "episode/length": 34.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 114168, "time": 5689.65106844902, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 114400, "time": 5699.6170337200165, "episode/length": 85.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 114544, "time": 5706.086112499237, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 114576, "time": 5708.744158029556, "episode/length": 231.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 115248, "time": 5734.719004869461, "episode/length": 205.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 115296, "time": 5737.964006185532, "episode/length": 168.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 115296, "time": 5737.973013877869, "episode/length": 286.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9895470383275261, "episode/intrinsic_return": 0.0}
{"step": 115400, "time": 5744.539988040924, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 115520, "time": 5750.40137553215, "episode/length": 121.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 116072, "time": 5770.606693267822, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 116128, "time": 5774.388046979904, "episode/length": 244.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673469387755103, "episode/intrinsic_return": 0.0}
{"step": 116360, "time": 5783.699126243591, "episode/length": 244.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 116672, "time": 5796.325390338898, "episode/length": 177.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 116768, "time": 5801.20699763298, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 116856, "time": 5805.500349283218, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 117000, "time": 5812.058651924133, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 117144, "time": 5818.773171424866, "episode/length": 230.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 117256, "time": 5824.221172571182, "episode/length": 72.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 117400, "time": 5830.80702662468, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 117544, "time": 5837.172374248505, "episode/length": 147.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 117832, "time": 5848.696692705154, "episode/length": 212.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 118176, "time": 5862.2584109306335, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 118416, "time": 5872.003650188446, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 118616, "time": 5880.331950426102, "episode/length": 151.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 118656, "time": 5883.536020517349, "episode/length": 206.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 118792, "time": 5889.474134206772, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 118832, "time": 5892.703418254852, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 119256, "time": 5908.427537918091, "episode/length": 263.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 119568, "time": 5920.757747888565, "episode/length": 38.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 119808, "time": 5930.455452919006, "episode/length": 246.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 119912, "time": 5935.529020309448, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 119944, "time": 5938.282498836517, "episode/length": 138.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 5957.320437431335, "eval_episode/length": 35.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 120016, "time": 5962.502749204636, "eval_episode/length": 117.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9661016949152542}
{"step": 120016, "time": 5964.871862411499, "eval_episode/length": 135.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 120016, "time": 5966.884282827377, "eval_episode/length": 144.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.993103448275862}
{"step": 120016, "time": 5968.777022123337, "eval_episode/length": 146.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 120016, "time": 5971.728633642197, "eval_episode/length": 174.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 120016, "time": 5973.4872715473175, "eval_episode/length": 177.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 120016, "time": 5978.324568986893, "eval_episode/length": 181.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 120056, "time": 5979.463629484177, "episode/length": 234.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 120088, "time": 5982.135170459747, "episode/length": 183.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 120136, "time": 5985.301917552948, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 120264, "time": 5991.21812915802, "episode/length": 183.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 120400, "time": 5997.612440109253, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 121096, "time": 6022.609863042831, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 121280, "time": 6030.819486141205, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 121544, "time": 6041.178183794022, "episode/length": 199.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 121568, "time": 6043.784501075745, "episode/length": 188.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 121648, "time": 6048.004707336426, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 121672, "time": 6050.191887617111, "episode/length": 262.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 121824, "time": 6057.142518281937, "episode/length": 34.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 121928, "time": 6062.26443195343, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 122288, "time": 6076.311497449875, "episode/length": 235.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 122480, "time": 6084.360873937607, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 122648, "time": 6091.600638628006, "episode/length": 134.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 122984, "time": 6105.909632444382, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 123080, "time": 6110.802623271942, "episode/length": 224.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 123112, "time": 6113.532438516617, "episode/length": 102.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.941747572815534, "episode/intrinsic_return": 0.0}
{"step": 123248, "time": 6120.067670822144, "episode/length": 164.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 123256, "time": 6121.750376701355, "episode/length": 200.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 123824, "time": 6142.730124235153, "episode/length": 146.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 124056, "time": 6152.040545701981, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 124280, "time": 6161.206816196442, "episode/length": 325.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.99079754601227, "episode/intrinsic_return": 0.0}
{"step": 124376, "time": 6166.004944562912, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 124616, "time": 6175.784898996353, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 124648, "time": 6178.69882774353, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 124712, "time": 6182.499431371689, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 124800, "time": 6187.20867729187, "episode/length": 193.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 125216, "time": 6202.750349283218, "episode/length": 144.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 125312, "time": 6207.583318471909, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 125584, "time": 6218.509085178375, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 125728, "time": 6224.92310667038, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 125952, "time": 6234.062122583389, "episode/length": 166.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 126168, "time": 6242.841514110565, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 126232, "time": 6246.646679401398, "episode/length": 189.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 126536, "time": 6258.556641101837, "episode/length": 152.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 126576, "time": 6261.701201677322, "episode/length": 221.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 126600, "time": 6263.808810949326, "episode/length": 80.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 126872, "time": 6274.666363239288, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 127152, "time": 6286.040001153946, "episode/length": 76.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.935064935064935, "episode/intrinsic_return": 0.0}
{"step": 127200, "time": 6289.326411962509, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 127320, "time": 6294.76998925209, "episode/length": 143.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 127336, "time": 6296.922433614731, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 127560, "time": 6306.324451208115, "episode/length": 165.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 127992, "time": 6323.214332342148, "episode/length": 176.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 128144, "time": 6330.274502754211, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 128376, "time": 6339.386500835419, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 128377, "time": 6342.090991973877, "train_stats/sum_log_reward": 2.926446204343118, "train_stats/max_log_achievement_collect_drink": 20.52892561983471, "train_stats/max_log_achievement_collect_sapling": 2.330578512396694, "train_stats/max_log_achievement_collect_wood": 1.421487603305785, "train_stats/max_log_achievement_defeat_zombie": 0.0743801652892562, "train_stats/max_log_achievement_eat_cow": 0.06611570247933884, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_place_plant": 1.9173553719008265, "train_stats/max_log_achievement_place_table": 0.03305785123966942, "train_stats/max_log_achievement_wake_up": 2.7024793388429753, "train_stats/mean_log_entropy": 0.6307189060636789, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.194936723851446, "train/action_min": 0.0, "train/action_std": 2.941305260160076, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03922506684520796, "train/actor_opt_grad_steps": 7255.0, "train/actor_opt_loss": 3.3086250519463376, "train/adv_mag": 1.0606112030904684, "train/adv_max": 1.0530296806524049, "train/adv_mean": 0.003268631002166371, "train/adv_min": -0.5793784423105752, "train/adv_std": 0.085676667933811, "train/cont_avg": 0.9940896105410447, "train/cont_loss_mean": 0.00042719053810818836, "train/cont_loss_std": 0.011758088078917992, "train/cont_neg_acc": 0.9834071006347884, "train/cont_neg_loss": 0.043735242036297674, "train/cont_pos_acc": 0.9999706415987727, "train/cont_pos_loss": 0.00014261272005469712, "train/cont_pred": 0.994153994232861, "train/cont_rate": 0.9940896105410447, "train/dyn_loss_mean": 8.37851605486514, "train/dyn_loss_std": 7.474772254032875, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0666379185754862, "train/extr_critic_critic_opt_grad_steps": 7255.0, "train/extr_critic_critic_opt_loss": 13954.173143073695, "train/extr_critic_mag": 2.919242752132131, "train/extr_critic_max": 2.919242752132131, "train/extr_critic_mean": 0.5670157913396607, "train/extr_critic_min": -0.3190069963682943, "train/extr_critic_std": 0.7270485660923061, "train/extr_return_normed_mag": 2.0760993841868727, "train/extr_return_normed_max": 2.0760993841868727, "train/extr_return_normed_mean": 0.33588574159501206, "train/extr_return_normed_min": -0.29582266214845787, "train/extr_return_normed_std": 0.35465615365042613, "train/extr_return_rate": 0.3581953698129796, "train/extr_return_raw_mag": 4.285962850300233, "train/extr_return_raw_max": 4.285962850300233, "train/extr_return_raw_mean": 0.5739475304066245, "train/extr_return_raw_min": -0.7753456948853251, "train/extr_return_raw_std": 0.7583290458615146, "train/extr_reward_mag": 1.004627085443753, "train/extr_reward_max": 1.004627085443753, "train/extr_reward_mean": 0.01311811945686089, "train/extr_reward_min": -0.527267720272292, "train/extr_reward_std": 0.10673729975276919, "train/image_loss_mean": 10.70408855267425, "train/image_loss_std": 18.147047740309986, "train/model_loss_mean": 15.768193515379037, "train/model_loss_std": 20.810032776932218, "train/model_opt_grad_norm": 87.9620974384137, "train/model_opt_grad_steps": 7244.462686567164, "train/model_opt_loss": 11192.02491327542, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 713.6194029850747, "train/policy_entropy_mag": 2.317804714637016, "train/policy_entropy_max": 2.317804714637016, "train/policy_entropy_mean": 0.7047259918789366, "train/policy_entropy_min": 0.07939549485471711, "train/policy_entropy_std": 0.5074328039564303, "train/policy_logprob_mag": 7.438196043470013, "train/policy_logprob_max": -0.009459058316285485, "train/policy_logprob_mean": -0.7047551645716624, "train/policy_logprob_min": -7.438196043470013, "train/policy_logprob_std": 1.1465791148036273, "train/policy_randomness_mag": 0.8180833498933422, "train/policy_randomness_max": 0.8180833498933422, "train/policy_randomness_mean": 0.24873734854940158, "train/policy_randomness_min": 0.028023125464791684, "train/policy_randomness_std": 0.17910151150244386, "train/post_ent_mag": 45.86172639078169, "train/post_ent_max": 45.86172639078169, "train/post_ent_mean": 33.008165573006245, "train/post_ent_min": 15.97547963128161, "train/post_ent_std": 5.602832217714679, "train/prior_ent_mag": 58.26519741229157, "train/prior_ent_max": 58.26519741229157, "train/prior_ent_mean": 41.387089231121, "train/prior_ent_min": 16.76941317942605, "train/prior_ent_std": 6.999223915498648, "train/rep_loss_mean": 8.37851605486514, "train/rep_loss_std": 7.474772254032875, "train/reward_avg": 0.004029413423050932, "train/reward_loss_mean": 0.03656817523679182, "train/reward_loss_std": 0.21500131404444353, "train/reward_max_data": 1.0014925376692814, "train/reward_max_pred": 1.0017426867983235, "train/reward_neg_acc": 0.9961286516331914, "train/reward_neg_loss": 0.026495758812429746, "train/reward_pos_acc": 0.9260792327460958, "train/reward_pos_loss": 1.106250871473284, "train/reward_pred": 0.0036745565290104095, "train/reward_rate": 0.009357509328358209, "eval_stats/sum_log_reward": 2.412499925121665, "eval_stats/max_log_achievement_collect_drink": 7.75, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_wood": 1.5, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_place_plant": 1.4375, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 2.375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_defeat_skeleton": 0.05714285714285714, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.9939077649032697e-05, "report/cont_loss_std": 0.0005511886556632817, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0024696446489542723, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.796799733710941e-05, "report/cont_pred": 0.9951114058494568, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 8.533997535705566, "report/dyn_loss_std": 7.651306629180908, "report/image_loss_mean": 10.564119338989258, "report/image_loss_std": 17.242713928222656, "report/model_loss_mean": 15.721644401550293, "report/model_loss_std": 20.142200469970703, "report/post_ent_mag": 46.84770965576172, "report/post_ent_max": 46.84770965576172, "report/post_ent_mean": 34.17475891113281, "report/post_ent_min": 15.755194664001465, "report/post_ent_std": 5.649752616882324, "report/prior_ent_mag": 59.49485778808594, "report/prior_ent_max": 59.49485778808594, "report/prior_ent_mean": 42.96906280517578, "report/prior_ent_min": 16.71608543395996, "report/prior_ent_std": 7.464539527893066, "report/rep_loss_mean": 8.533997535705566, "report/rep_loss_std": 7.651306629180908, "report/reward_avg": 0.008203125558793545, "report/reward_loss_mean": 0.03709694743156433, "report/reward_loss_std": 0.2134981006383896, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0010986328125, "report/reward_neg_acc": 0.9901087880134583, "report/reward_neg_loss": 0.02381121553480625, "report/reward_pos_acc": 0.9230769872665405, "report/reward_pos_loss": 1.0703179836273193, "report/reward_pred": 0.009494215250015259, "report/reward_rate": 0.0126953125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 1.2998545571463183e-05, "eval/cont_loss_std": 0.00019500991038512439, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0008358247578144073, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.519599992316216e-06, "eval/cont_pred": 0.9921875596046448, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 13.863445281982422, "eval/dyn_loss_std": 8.359644889831543, "eval/image_loss_mean": 17.270191192626953, "eval/image_loss_std": 21.040184020996094, "eval/model_loss_mean": 25.639324188232422, "eval/model_loss_std": 23.903623580932617, "eval/post_ent_mag": 42.79389190673828, "eval/post_ent_max": 42.79389190673828, "eval/post_ent_mean": 30.241161346435547, "eval/post_ent_min": 15.362358093261719, "eval/post_ent_std": 4.677412033081055, "eval/prior_ent_mag": 57.68453598022461, "eval/prior_ent_max": 57.68453598022461, "eval/prior_ent_mean": 41.725250244140625, "eval/prior_ent_min": 17.40294647216797, "eval/prior_ent_std": 7.744299411773682, "eval/rep_loss_mean": 13.863445281982422, "eval/rep_loss_std": 8.359644889831543, "eval/reward_avg": 0.00791015662252903, "eval/reward_loss_mean": 0.051052629947662354, "eval/reward_loss_std": 0.40146905183792114, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0025873184204102, "eval/reward_neg_acc": 0.9990089535713196, "eval/reward_neg_loss": 0.018580228090286255, "eval/reward_pos_acc": 0.7333333492279053, "eval/reward_pos_loss": 2.235363483428955, "eval/reward_pred": 0.0013109059073030949, "eval/reward_rate": 0.0146484375, "replay/size": 127873.0, "replay/inserts": 21472.0, "replay/samples": 21472.0, "replay/insert_wait_avg": 1.458537205498549e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.058173829148317e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24336.0, "eval_replay/inserts": 3432.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.429677843213915e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1777122020721, "timer/env.step_count": 2684.0, "timer/env.step_total": 268.3258159160614, "timer/env.step_frac": 0.26827813961710223, "timer/env.step_avg": 0.099972360624464, "timer/env.step_min": 0.023586273193359375, "timer/env.step_max": 3.296307325363159, "timer/replay._sample_count": 21472.0, "timer/replay._sample_total": 12.07703971862793, "timer/replay._sample_frac": 0.01207489386264981, "timer/replay._sample_avg": 0.0005624552775068894, "timer/replay._sample_min": 0.0003719329833984375, "timer/replay._sample_max": 0.009273052215576172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3113.0, "timer/agent.policy_total": 55.47549271583557, "timer/agent.policy_frac": 0.055465635795559014, "timer/agent.policy_avg": 0.017820588729789776, "timer/agent.policy_min": 0.009882450103759766, "timer/agent.policy_max": 0.1341400146484375, "timer/dataset_train_count": 1342.0, "timer/dataset_train_total": 0.1614077091217041, "timer/dataset_train_frac": 0.00016137903009889697, "timer/dataset_train_avg": 0.00012027400083584509, "timer/dataset_train_min": 0.00010395050048828125, "timer/dataset_train_max": 0.0003745555877685547, "timer/agent.train_count": 1342.0, "timer/agent.train_total": 609.2319180965424, "timer/agent.train_frac": 0.6091236693879212, "timer/agent.train_avg": 0.45397311333572454, "timer/agent.train_min": 0.44072961807250977, "timer/agent.train_max": 1.5581278800964355, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47590017318725586, "timer/agent.report_frac": 0.0004758156149465434, "timer/agent.report_avg": 0.23795008659362793, "timer/agent.report_min": 0.2305583953857422, "timer/agent.report_max": 0.24534177780151367, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.218078925978716e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 21.467921011885718}
{"step": 128456, "time": 6344.639900445938, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 128664, "time": 6353.1641709804535, "episode/length": 223.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 128800, "time": 6360.0895438194275, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 128840, "time": 6362.851877450943, "episode/length": 187.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 129008, "time": 6370.487675666809, "episode/length": 225.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 129368, "time": 6384.424466609955, "episode/length": 113.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.956140350877193, "episode/intrinsic_return": 0.0}
{"step": 129456, "time": 6389.323137521744, "episode/length": 76.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.935064935064935, "episode/intrinsic_return": 0.0}
{"step": 129528, "time": 6393.2191071510315, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 129688, "time": 6400.336802482605, "episode/length": 163.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 129696, "time": 6402.36650967598, "episode/length": 193.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 129784, "time": 6406.880232095718, "episode/length": 96.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9484536082474226, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 6435.146726369858, "eval_episode/length": 126.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9921259842519685}
{"step": 130000, "time": 6437.84231877327, "eval_episode/length": 149.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 130000, "time": 6440.114483118057, "eval_episode/length": 35.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 130000, "time": 6441.90943646431, "eval_episode/length": 166.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 130000, "time": 6443.825501918793, "eval_episode/length": 171.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9651162790697675}
{"step": 130000, "time": 6446.032108783722, "eval_episode/length": 182.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 130000, "time": 6447.978799581528, "eval_episode/length": 184.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 130000, "time": 6451.411128282547, "eval_episode/length": 224.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 130216, "time": 6458.527190923691, "episode/length": 176.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 130568, "time": 6472.52286195755, "episode/length": 237.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 130704, "time": 6479.155395269394, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 130744, "time": 6481.8568477630615, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 130920, "time": 6489.491611480713, "episode/length": 87.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9318181818181818, "episode/intrinsic_return": 0.0}
{"step": 131096, "time": 6498.328941345215, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 131400, "time": 6510.372146368027, "episode/length": 242.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 131424, "time": 6512.956327676773, "episode/length": 216.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 131680, "time": 6523.1494562625885, "episode/length": 247.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 131840, "time": 6530.205221414566, "episode/length": 141.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 132320, "time": 6548.289857149124, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 132456, "time": 6554.211788892746, "episode/length": 131.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 132520, "time": 6557.9690318107605, "episode/length": 221.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 132560, "time": 6561.055110216141, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 132824, "time": 6571.465948581696, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 133000, "time": 6579.082226514816, "episode/length": 164.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 133288, "time": 6590.488963603973, "episode/length": 180.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 133320, "time": 6593.234887599945, "episode/length": 236.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 133736, "time": 6609.053862571716, "episode/length": 146.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 133976, "time": 6618.804238080978, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 133992, "time": 6620.946772575378, "episode/length": 208.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 134192, "time": 6629.765562772751, "episode/length": 170.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 134464, "time": 6640.604755401611, "episode/length": 250.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 134592, "time": 6646.544726610184, "episode/length": 162.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 134600, "time": 6648.217355012894, "episode/length": 199.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 135192, "time": 6669.81799197197, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 135264, "time": 6674.196758985519, "episode/length": 133.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 135496, "time": 6683.620140790939, "episode/length": 271.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 135624, "time": 6689.672126054764, "episode/length": 203.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 135872, "time": 6699.924134731293, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 135968, "time": 6704.71350812912, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 136056, "time": 6709.0359308719635, "episode/length": 198.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 136336, "time": 6720.5002064704895, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 136448, "time": 6725.852530002594, "episode/length": 156.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 136688, "time": 6735.537024497986, "episode/length": 148.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 136744, "time": 6738.713072061539, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 137040, "time": 6750.667142391205, "episode/length": 145.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 137152, "time": 6756.173120975494, "episode/length": 147.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 137424, "time": 6766.886837720871, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 137432, "time": 6768.681352615356, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 137608, "time": 6776.277728557587, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 138056, "time": 6793.254303693771, "episode/length": 78.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 138192, "time": 6799.702360391617, "episode/length": 217.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 138240, "time": 6802.962264537811, "episode/length": 186.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 138376, "time": 6809.0491507053375, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 138432, "time": 6812.747649669647, "episode/length": 173.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 138576, "time": 6819.373184204102, "episode/length": 41.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 138688, "time": 6824.850132703781, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 138816, "time": 6830.713802099228, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 139064, "time": 6840.606041908264, "episode/length": 181.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 139512, "time": 6858.754721879959, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 139512, "time": 6858.772798299789, "episode/length": 181.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 139712, "time": 6869.113049507141, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 139936, "time": 6878.293973445892, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 6901.172472000122, "eval_episode/length": 35.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 140088, "time": 6907.473832130432, "eval_episode/length": 138.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 140088, "time": 6909.390129327774, "eval_episode/length": 145.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 140088, "time": 6911.375411987305, "eval_episode/length": 153.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.961038961038961}
{"step": 140088, "time": 6913.60399889946, "eval_episode/length": 169.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9647058823529412}
{"step": 140088, "time": 6916.304785251617, "eval_episode/length": 193.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.979381443298969}
{"step": 140088, "time": 6918.42263507843, "eval_episode/length": 204.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 140088, "time": 6923.210882902145, "eval_episode/length": 275.0, "eval_episode/score": 5.099999964237213, "eval_episode/reward_rate": 0.9891304347826086}
{"step": 140152, "time": 6925.391891479492, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 140224, "time": 6929.858557939529, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 140296, "time": 6933.723982095718, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 140352, "time": 6937.435061454773, "episode/length": 221.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 140848, "time": 6955.795299768448, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 140896, "time": 6959.219473361969, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 141040, "time": 6965.723564147949, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 141416, "time": 6979.790023803711, "episode/length": 148.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 141424, "time": 6981.783348321915, "episode/length": 158.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 141848, "time": 6997.616579771042, "episode/length": 186.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 141864, "time": 6999.725666761398, "episode/length": 240.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 142064, "time": 7008.387179374695, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 142104, "time": 7011.068315267563, "episode/length": 132.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 142176, "time": 7015.342056274414, "episode/length": 234.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 142688, "time": 7034.346188783646, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 143024, "time": 7047.408720731735, "episode/length": 265.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 143368, "time": 7060.636678934097, "episode/length": 242.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 143368, "time": 7060.64551782608, "episode/length": 187.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 143440, "time": 7066.500530958176, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 143624, "time": 7074.126535892487, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 143648, "time": 7076.791211366653, "episode/length": 224.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 143752, "time": 7081.76412653923, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 144496, "time": 7108.866957187653, "episode/length": 183.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 144536, "time": 7111.810595750809, "episode/length": 230.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 144856, "time": 7124.2369837760925, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 145064, "time": 7132.867429018021, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 145144, "time": 7137.29246878624, "episode/length": 221.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 145512, "time": 7151.517970323563, "episode/length": 235.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 145608, "time": 7156.498692989349, "episode/length": 244.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 145944, "time": 7169.6967968940735, "episode/length": 135.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 145960, "time": 7171.859720945358, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 145976, "time": 7174.033500909805, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 146176, "time": 7182.545222520828, "episode/length": 138.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 146288, "time": 7187.840940713882, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 146368, "time": 7192.172732830048, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 146384, "time": 7194.3619022369385, "episode/length": 25.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8461538461538461, "episode/intrinsic_return": 0.0}
{"step": 146696, "time": 7206.244308710098, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 146968, "time": 7216.985909938812, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 147024, "time": 7220.682582139969, "episode/length": 447.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9977678571428571, "episode/intrinsic_return": 0.0}
{"step": 147200, "time": 7228.374664068222, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 147616, "time": 7245.364259004593, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 147704, "time": 7249.809059143066, "episode/length": 84.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 147808, "time": 7255.141968250275, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 147824, "time": 7257.277787685394, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 148000, "time": 7265.031619310379, "episode/length": 36.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 148080, "time": 7269.366577625275, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 148544, "time": 7286.683434724808, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 148944, "time": 7302.016469717026, "episode/length": 117.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 149192, "time": 7311.70743393898, "episode/length": 311.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 149288, "time": 7316.57781124115, "episode/length": 208.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 149392, "time": 7322.1211857795715, "episode/length": 163.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 149496, "time": 7327.029161930084, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 149712, "time": 7335.974253416061, "episode/length": 145.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 149833, "time": 7342.384731054306, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.9611925722947765, "train/action_min": 0.0, "train/action_std": 3.460341200899722, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04619396957499323, "train/actor_opt_grad_steps": 8595.0, "train/actor_opt_loss": 8.284997346352286, "train/adv_mag": 1.1412885994163913, "train/adv_max": 1.131777031208152, "train/adv_mean": 0.0049995947794279835, "train/adv_min": -0.6573594917557133, "train/adv_std": 0.09192246568403137, "train/cont_avg": 0.9941333372201493, "train/cont_loss_mean": 0.0005383503696580463, "train/cont_loss_std": 0.014678117957288775, "train/cont_neg_acc": 0.9820095976786827, "train/cont_neg_loss": 0.056929046267736906, "train/cont_pos_acc": 0.9999339767356417, "train/cont_pos_loss": 0.00020301363433684985, "train/cont_pred": 0.9941631564453467, "train/cont_rate": 0.9941333372201493, "train/dyn_loss_mean": 9.268499431325429, "train/dyn_loss_std": 8.052091755084138, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0574023091970985, "train/extr_critic_critic_opt_grad_steps": 8595.0, "train/extr_critic_critic_opt_loss": 14054.169994752798, "train/extr_critic_mag": 3.0412840167088295, "train/extr_critic_max": 3.0412840167088295, "train/extr_critic_mean": 0.5718794104768269, "train/extr_critic_min": -0.3224000503767782, "train/extr_critic_std": 0.6657368556332233, "train/extr_return_normed_mag": 2.3283678097511404, "train/extr_return_normed_max": 2.3283678097511404, "train/extr_return_normed_mean": 0.3703694483682291, "train/extr_return_normed_min": -0.35043230352561866, "train/extr_return_normed_std": 0.3648711064858223, "train/extr_return_rate": 0.38038957463716394, "train/extr_return_raw_mag": 4.309230295579825, "train/extr_return_raw_max": 4.309230295579825, "train/extr_return_raw_mean": 0.5814547654408128, "train/extr_return_raw_min": -0.7909791369491549, "train/extr_return_raw_std": 0.6948142583245662, "train/extr_reward_mag": 1.003639487188254, "train/extr_reward_max": 1.003639487188254, "train/extr_reward_mean": 0.012876853529266569, "train/extr_reward_min": -0.5322888938348684, "train/extr_reward_std": 0.10535430013021427, "train/image_loss_mean": 10.402465517841168, "train/image_loss_std": 15.920155023460957, "train/model_loss_mean": 16.000992461816587, "train/model_loss_std": 19.17005889095477, "train/model_opt_grad_norm": 82.41422177784479, "train/model_opt_grad_steps": 8583.34328358209, "train/model_opt_loss": 11253.661008920242, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 708.955223880597, "train/policy_entropy_mag": 2.41764246883677, "train/policy_entropy_max": 2.41764246883677, "train/policy_entropy_mean": 0.7520550391567287, "train/policy_entropy_min": 0.07939129951062487, "train/policy_entropy_std": 0.552537273337592, "train/policy_logprob_mag": 7.4382203550481085, "train/policy_logprob_max": -0.009458538395032953, "train/policy_logprob_mean": -0.752055299815847, "train/policy_logprob_min": -7.4382203550481085, "train/policy_logprob_std": 1.1767606628474905, "train/policy_randomness_mag": 0.8533216955056832, "train/policy_randomness_max": 0.8533216955056832, "train/policy_randomness_mean": 0.2654424250793101, "train/policy_randomness_min": 0.028021644787001077, "train/policy_randomness_std": 0.19502141204342913, "train/post_ent_mag": 47.88802314872172, "train/post_ent_max": 47.88802314872172, "train/post_ent_mean": 34.008356806057606, "train/post_ent_min": 17.08772931881805, "train/post_ent_std": 5.582730873307185, "train/prior_ent_mag": 60.66529581440029, "train/prior_ent_max": 60.66529581440029, "train/prior_ent_mean": 43.381036815358634, "train/prior_ent_min": 18.618469337918864, "train/prior_ent_std": 7.44859833503837, "train/rep_loss_mean": 9.268499431325429, "train/rep_loss_std": 8.052091755084138, "train/reward_avg": 0.006228136615879806, "train/reward_loss_mean": 0.036888857622311186, "train/reward_loss_std": 0.2125926369161748, "train/reward_max_data": 1.0044776130078443, "train/reward_max_pred": 1.001516629510851, "train/reward_neg_acc": 0.9955809836956993, "train/reward_neg_loss": 0.025142944515196244, "train/reward_pos_acc": 0.934498818507835, "train/reward_pos_loss": 1.0567605913575016, "train/reward_pred": 0.005713080807498642, "train/reward_rate": 0.01136893656716418, "train_stats/sum_log_reward": 3.057627044996973, "train_stats/max_log_achievement_collect_drink": 13.042372881355933, "train_stats/max_log_achievement_collect_sapling": 2.1440677966101696, "train_stats/max_log_achievement_collect_wood": 1.2457627118644068, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.1016949152542373, "train_stats/max_log_achievement_eat_cow": 0.06779661016949153, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_place_plant": 1.9915254237288136, "train_stats/max_log_achievement_place_table": 0.06779661016949153, "train_stats/max_log_achievement_wake_up": 2.593220338983051, "train_stats/mean_log_entropy": 0.7219783087908211, "eval_stats/sum_log_reward": 2.6624999567866325, "eval_stats/max_log_achievement_collect_drink": 9.375, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_wood": 1.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 2.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.00047950693988241255, "report/cont_loss_std": 0.011223171837627888, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.3182630684459582e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0004803999327123165, "report/cont_pred": 0.9976239800453186, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 8.490079879760742, "report/dyn_loss_std": 8.398021697998047, "report/image_loss_mean": 7.290266036987305, "report/image_loss_std": 11.756881713867188, "report/model_loss_mean": 12.417718887329102, "report/model_loss_std": 15.514005661010742, "report/post_ent_mag": 48.186458587646484, "report/post_ent_max": 48.186458587646484, "report/post_ent_mean": 34.44873046875, "report/post_ent_min": 17.603769302368164, "report/post_ent_std": 5.743281841278076, "report/prior_ent_mag": 60.93268966674805, "report/prior_ent_max": 60.93268966674805, "report/prior_ent_mean": 43.37491989135742, "report/prior_ent_min": 18.42706298828125, "report/prior_ent_std": 7.717933654785156, "report/rep_loss_mean": 8.490079879760742, "report/rep_loss_std": 8.398021697998047, "report/reward_avg": 0.014257811941206455, "report/reward_loss_mean": 0.03292497619986534, "report/reward_loss_std": 0.18284112215042114, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0038137435913086, "report/reward_neg_acc": 0.9930486679077148, "report/reward_neg_loss": 0.015957297757267952, "report/reward_pos_acc": 0.9411764740943909, "report/reward_pos_loss": 1.0380104780197144, "report/reward_pred": 0.013140079565346241, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 7.332374707402778e-07, "eval/cont_loss_std": 5.590991804638179e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.74786747872713e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.293130579455465e-07, "eval/cont_pred": 0.9990227818489075, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 10.436071395874023, "eval/dyn_loss_std": 8.623740196228027, "eval/image_loss_mean": 14.110795974731445, "eval/image_loss_std": 28.246522903442383, "eval/model_loss_mean": 20.392757415771484, "eval/model_loss_std": 31.59922981262207, "eval/post_ent_mag": 50.356483459472656, "eval/post_ent_max": 50.356483459472656, "eval/post_ent_mean": 34.099281311035156, "eval/post_ent_min": 19.19211196899414, "eval/post_ent_std": 5.214126110076904, "eval/prior_ent_mag": 60.121490478515625, "eval/prior_ent_max": 60.121490478515625, "eval/prior_ent_mean": 43.14732360839844, "eval/prior_ent_min": 19.514110565185547, "eval/prior_ent_std": 6.3025336265563965, "eval/rep_loss_mean": 10.436071395874023, "eval/rep_loss_std": 8.623740196228027, "eval/reward_avg": 0.0107421875, "eval/reward_loss_mean": 0.020318420603871346, "eval/reward_loss_std": 0.17097584903240204, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000290870666504, "eval/reward_neg_acc": 0.9990118741989136, "eval/reward_neg_loss": 0.006444944534450769, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 1.1903148889541626, "eval/reward_pred": 0.008307449519634247, "eval/reward_rate": 0.01171875, "replay/size": 149329.0, "replay/inserts": 21456.0, "replay/samples": 21456.0, "replay/insert_wait_avg": 1.4820710480168718e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.986366941891527e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28344.0, "eval_replay/inserts": 4008.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.26317827525491e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2798631191254, "timer/env.step_count": 2682.0, "timer/env.step_total": 265.0781078338623, "timer/env.step_frac": 0.26500394300379276, "timer/env.step_avg": 0.09883598353238714, "timer/env.step_min": 0.0241851806640625, "timer/env.step_max": 3.278071641921997, "timer/replay._sample_count": 21456.0, "timer/replay._sample_total": 12.137224912643433, "timer/replay._sample_frac": 0.012133829101384185, "timer/replay._sample_avg": 0.0005656797591649624, "timer/replay._sample_min": 0.00041866302490234375, "timer/replay._sample_max": 0.012404441833496094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3183.0, "timer/agent.policy_total": 55.69457674026489, "timer/agent.policy_frac": 0.05567899424326621, "timer/agent.policy_avg": 0.017497510757230567, "timer/agent.policy_min": 0.009710073471069336, "timer/agent.policy_max": 0.11765336990356445, "timer/dataset_train_count": 1341.0, "timer/dataset_train_total": 0.15480351448059082, "timer/dataset_train_frac": 0.00015476020280751665, "timer/dataset_train_avg": 0.00011543886240163372, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.0005259513854980469, "timer/agent.train_count": 1341.0, "timer/agent.train_total": 608.7383542060852, "timer/agent.train_frac": 0.6085680384566428, "timer/agent.train_avg": 0.4539435900119949, "timer/agent.train_min": 0.44066882133483887, "timer/agent.train_max": 1.4925878047943115, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4683201313018799, "timer/agent.report_frac": 0.0004681891024393307, "timer/agent.report_avg": 0.23416006565093994, "timer/agent.report_min": 0.22275710105895996, "timer/agent.report_max": 0.24556303024291992, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9078928530751184e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 21.44970774397627}
{"step": 150072, "time": 7369.212340116501, "eval_episode/length": 125.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9523809523809523}
{"step": 150072, "time": 7371.190760850906, "eval_episode/length": 133.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 150072, "time": 7373.786694049835, "eval_episode/length": 151.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.993421052631579}
{"step": 150072, "time": 7377.497510433197, "eval_episode/length": 196.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 150072, "time": 7377.504814386368, "eval_episode/length": 196.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 150072, "time": 7381.965850114822, "eval_episode/length": 216.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9815668202764977}
{"step": 150072, "time": 7385.7241978645325, "eval_episode/length": 138.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 150072, "time": 7387.439467191696, "eval_episode/length": 269.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9740740740740741}
{"step": 150232, "time": 7392.8349730968475, "episode/length": 378.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9973614775725593, "episode/intrinsic_return": 0.0}
{"step": 150272, "time": 7396.562910079956, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 150688, "time": 7412.46546459198, "episode/length": 148.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 150768, "time": 7416.637779474258, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 150824, "time": 7419.909745931625, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 150936, "time": 7425.315859079361, "episode/length": 192.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 151456, "time": 7444.884772539139, "episode/length": 217.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 151512, "time": 7448.250043392181, "episode/length": 460.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9804772234273319, "episode/intrinsic_return": 0.0}
{"step": 151912, "time": 7463.5867331027985, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 151936, "time": 7466.244193315506, "episode/length": 212.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 152072, "time": 7472.334151268005, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 152224, "time": 7479.336724758148, "episode/length": 88.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 152248, "time": 7481.575131893158, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 152416, "time": 7489.06964802742, "episode/length": 184.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 152952, "time": 7508.83468914032, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 153192, "time": 7518.462009191513, "episode/length": 302.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 153320, "time": 7524.2705290317535, "episode/length": 155.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 153360, "time": 7527.4736206531525, "episode/length": 180.0, "episode/score": 3.1000000312924385, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 153744, "time": 7542.175529956818, "episode/length": 186.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 153808, "time": 7545.956449270248, "episode/length": 60.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 153848, "time": 7548.779548168182, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 154040, "time": 7557.021504640579, "episode/length": 226.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 154216, "time": 7564.839330673218, "episode/length": 284.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9754385964912281, "episode/intrinsic_return": 0.0}
{"step": 154384, "time": 7572.212985277176, "episode/length": 178.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 154496, "time": 7577.543922662735, "episode/length": 34.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 154640, "time": 7584.051119565964, "episode/length": 180.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 154936, "time": 7595.494113445282, "episode/length": 140.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 154936, "time": 7595.502406358719, "episode/length": 36.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 154944, "time": 7599.2841029167175, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 155192, "time": 7609.015370130539, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 155232, "time": 7612.2841012477875, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 155584, "time": 7626.0181720256805, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 155632, "time": 7629.331820011139, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 155880, "time": 7640.454278230667, "episode/length": 85.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 155968, "time": 7645.284678697586, "episode/length": 183.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 156008, "time": 7648.167350053787, "episode/length": 132.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 156256, "time": 7658.350229501724, "episode/length": 30.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.0}
{"step": 156376, "time": 7663.835958003998, "episode/length": 50.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 156400, "time": 7666.533150911331, "episode/length": 182.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 156760, "time": 7680.150943517685, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 156760, "time": 7680.169827699661, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 156800, "time": 7685.309769153595, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.952054794520548, "episode/intrinsic_return": 0.0}
{"step": 157104, "time": 7697.3206486701965, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9578947368421052, "episode/intrinsic_return": 0.0}
{"step": 157312, "time": 7705.851130247116, "episode/length": 131.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 157392, "time": 7710.298928260803, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 157624, "time": 7719.388498544693, "episode/length": 28.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8620689655172413, "episode/intrinsic_return": 0.0}
{"step": 157632, "time": 7721.461682319641, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 157640, "time": 7723.038891553879, "episode/length": 157.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 157832, "time": 7730.996589422226, "episode/length": 133.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 157912, "time": 7735.519259691238, "episode/length": 33.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 157928, "time": 7737.701337099075, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 158152, "time": 7747.008940219879, "episode/length": 104.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 158400, "time": 7757.115715265274, "episode/length": 199.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 158920, "time": 7776.049733161926, "episode/length": 123.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.0}
{"step": 158968, "time": 7779.13494682312, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 158984, "time": 7781.246374845505, "episode/length": 103.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9519230769230769, "episode/intrinsic_return": 0.0}
{"step": 159032, "time": 7784.431978225708, "episode/length": 174.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 159080, "time": 7787.687134981155, "episode/length": 246.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 159256, "time": 7795.273623466492, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 159280, "time": 7798.011754512787, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 159456, "time": 7805.474428653717, "episode/length": 131.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 159496, "time": 7808.207029342651, "episode/length": 57.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 7846.940712213516, "eval_episode/length": 110.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.990990990990991}
{"step": 160056, "time": 7851.704176425934, "eval_episode/length": 177.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 160056, "time": 7853.492481231689, "eval_episode/length": 178.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 160056, "time": 7855.543494939804, "eval_episode/length": 185.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 160056, "time": 7857.511134147644, "eval_episode/length": 190.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 160056, "time": 7859.2339289188385, "eval_episode/length": 191.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 160056, "time": 7860.892147302628, "eval_episode/length": 193.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 160056, "time": 7862.699268341064, "eval_episode/length": 199.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.965}
{"step": 160408, "time": 7874.598196268082, "episode/length": 140.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 160432, "time": 7877.208130121231, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 160472, "time": 7879.940325260162, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 160488, "time": 7882.187339544296, "episode/length": 153.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 160512, "time": 7884.753097772598, "episode/length": 198.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 160520, "time": 7886.335181713104, "episode/length": 191.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 161248, "time": 7912.780872106552, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 161584, "time": 7925.993723630905, "episode/length": 143.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 161720, "time": 7931.998073816299, "episode/length": 155.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 161816, "time": 7936.7504959106445, "episode/length": 175.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 162048, "time": 7946.356336116791, "episode/length": 194.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 162072, "time": 7948.713027954102, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 162432, "time": 7962.675197839737, "episode/length": 239.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 162664, "time": 7971.907653808594, "episode/length": 134.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 162672, "time": 7974.056135416031, "episode/length": 396.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9949622166246851, "episode/intrinsic_return": 0.0}
{"step": 162720, "time": 7977.235601186752, "episode/length": 183.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 163256, "time": 7996.941012144089, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 163456, "time": 8005.482422113419, "episode/length": 204.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 163496, "time": 8008.362477064133, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 163736, "time": 8018.020091056824, "episode/length": 133.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 163800, "time": 8021.849092960358, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 164368, "time": 8044.274809837341, "episode/length": 205.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 164480, "time": 8049.646411657333, "episode/length": 225.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 164488, "time": 8051.220236301422, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 164632, "time": 8057.735369920731, "episode/length": 146.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 165208, "time": 8078.8321125507355, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 165312, "time": 8084.202491521835, "episode/length": 188.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 165528, "time": 8092.724031686783, "episode/length": 434.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 165904, "time": 8107.402305841446, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 166024, "time": 8112.79420876503, "episode/length": 191.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 166040, "time": 8114.984759807587, "episode/length": 287.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 166344, "time": 8127.003570318222, "episode/length": 213.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9626168224299065, "episode/intrinsic_return": 0.0}
{"step": 166928, "time": 8148.651301622391, "episode/length": 214.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 167048, "time": 8154.044491052628, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 167472, "time": 8170.324558019638, "episode/length": 269.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 167640, "time": 8177.525221824646, "episode/length": 216.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 167704, "time": 8181.308755397797, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 167728, "time": 8183.996746778488, "episode/length": 419.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 167800, "time": 8187.939905643463, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 168368, "time": 8208.979743480682, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 168384, "time": 8211.118810892105, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 168904, "time": 8230.177258729935, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 169120, "time": 8239.285043239594, "episode/length": 184.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 169128, "time": 8240.920239686966, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 169160, "time": 8243.639326572418, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 169360, "time": 8252.411735534668, "episode/length": 235.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 169400, "time": 8255.219002723694, "episode/length": 419.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 169592, "time": 8263.268043518066, "episode/length": 152.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 8296.564215183258, "eval_episode/length": 36.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.972972972972973}
{"step": 170040, "time": 8303.085970640182, "eval_episode/length": 146.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9591836734693877}
{"step": 170040, "time": 8304.904703140259, "eval_episode/length": 149.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 170040, "time": 8306.679781913757, "eval_episode/length": 153.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.961038961038961}
{"step": 170040, "time": 8309.364340782166, "eval_episode/length": 174.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 170040, "time": 8309.373515367508, "eval_episode/length": 174.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 170040, "time": 8313.870147705078, "eval_episode/length": 199.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.995}
{"step": 170040, "time": 8315.872408866882, "eval_episode/length": 34.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 170416, "time": 8328.726011276245, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 170576, "time": 8335.826200962067, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 170600, "time": 8338.19104385376, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 170649, "time": 8342.415767669678, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.61337890625, "train/action_min": 0.0, "train/action_std": 3.2985245778010444, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049033555746651615, "train/actor_opt_grad_steps": 9915.0, "train/actor_opt_loss": 15.12703166099695, "train/adv_mag": 1.1505896206085497, "train/adv_max": 1.1395448923110962, "train/adv_mean": 0.007662031081865559, "train/adv_min": -0.6671698061319498, "train/adv_std": 0.09349332044904049, "train/cont_avg": 0.9942457932692308, "train/cont_loss_mean": 0.00035152776422495873, "train/cont_loss_std": 0.00946661443598574, "train/cont_neg_acc": 0.9868284514317146, "train/cont_neg_loss": 0.02943434903366044, "train/cont_pos_acc": 0.9999546440748068, "train/cont_pos_loss": 0.00017975902919972284, "train/cont_pred": 0.9942408827634958, "train/cont_rate": 0.9942457932692308, "train/dyn_loss_mean": 10.543802345716037, "train/dyn_loss_std": 8.729850636995756, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1010554987650651, "train/extr_critic_critic_opt_grad_steps": 9915.0, "train/extr_critic_critic_opt_loss": 14478.332699819712, "train/extr_critic_mag": 3.43253972530365, "train/extr_critic_max": 3.43253972530365, "train/extr_critic_mean": 0.668292544896786, "train/extr_critic_min": -0.32059754866820117, "train/extr_critic_std": 0.7133018287328573, "train/extr_return_normed_mag": 2.3681238807164706, "train/extr_return_normed_max": 2.3681238807164706, "train/extr_return_normed_mean": 0.3649405714411002, "train/extr_return_normed_min": -0.26977117611811713, "train/extr_return_normed_std": 0.3548948427805534, "train/extr_return_rate": 0.42626754951018553, "train/extr_return_raw_mag": 4.95098780301901, "train/extr_return_raw_max": 4.95098780301901, "train/extr_return_raw_mean": 0.684573950446569, "train/extr_return_raw_min": -0.660781884422669, "train/extr_return_raw_std": 0.7537737557521234, "train/extr_reward_mag": 1.0025845289230346, "train/extr_reward_max": 1.0025845289230346, "train/extr_reward_mean": 0.012990483852963034, "train/extr_reward_min": -0.4561358846150912, "train/extr_reward_std": 0.10268510155952894, "train/image_loss_mean": 11.285095240519597, "train/image_loss_std": 17.067133059868446, "train/model_loss_mean": 17.654671874413122, "train/model_loss_std": 20.776747175363393, "train/model_opt_grad_norm": 77.84930240924541, "train/model_opt_grad_steps": 9902.13076923077, "train/model_opt_loss": 12521.766856971153, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 711.5384615384615, "train/policy_entropy_mag": 2.399656048187843, "train/policy_entropy_max": 2.399656048187843, "train/policy_entropy_mean": 0.64736830500456, "train/policy_entropy_min": 0.07938393491965073, "train/policy_entropy_std": 0.5262604610278057, "train/policy_logprob_mag": 7.43828125, "train/policy_logprob_max": -0.00945747160137846, "train/policy_logprob_mean": -0.649604726754702, "train/policy_logprob_min": -7.43828125, "train/policy_logprob_std": 1.1397817437465374, "train/policy_randomness_mag": 0.8469732807232784, "train/policy_randomness_max": 0.8469732807232784, "train/policy_randomness_mean": 0.22849260190358528, "train/policy_randomness_min": 0.028019045393627425, "train/policy_randomness_std": 0.1857468489270944, "train/post_ent_mag": 49.958884341900166, "train/post_ent_max": 49.958884341900166, "train/post_ent_mean": 35.0450191791241, "train/post_ent_min": 18.679073098989633, "train/post_ent_std": 5.58716370509221, "train/prior_ent_mag": 62.26340675354004, "train/prior_ent_max": 62.26340675354004, "train/prior_ent_mean": 45.59561480008639, "train/prior_ent_min": 20.632920793386607, "train/prior_ent_std": 7.903456317461454, "train/rep_loss_mean": 10.543802345716037, "train/rep_loss_std": 8.729850636995756, "train/reward_avg": 0.008269230684695336, "train/reward_loss_mean": 0.04294355962998592, "train/reward_loss_std": 0.24483984622817773, "train/reward_max_data": 1.0030769238105186, "train/reward_max_pred": 1.000790296151088, "train/reward_neg_acc": 0.9951419614828549, "train/reward_neg_loss": 0.02821651787425463, "train/reward_pos_acc": 0.9185124209293952, "train/reward_pos_loss": 1.1292588128493382, "train/reward_pred": 0.007394106704920817, "train/reward_rate": 0.013431490384615385, "eval_stats/sum_log_reward": 2.933333254108826, "eval_stats/max_log_achievement_collect_drink": 14.833333333333334, "eval_stats/max_log_achievement_collect_sapling": 1.9583333333333333, "eval_stats/max_log_achievement_collect_wood": 2.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.041666666666666664, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "train_stats/sum_log_reward": 3.3566370992138324, "train_stats/max_log_achievement_collect_drink": 16.13274336283186, "train_stats/max_log_achievement_collect_sapling": 1.8495575221238938, "train_stats/max_log_achievement_collect_wood": 1.8672566371681416, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.09734513274336283, "train_stats/max_log_achievement_eat_cow": 0.07079646017699115, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_place_plant": 1.6991150442477876, "train_stats/max_log_achievement_place_table": 0.07964601769911504, "train_stats/max_log_achievement_wake_up": 2.0353982300884956, "train_stats/mean_log_entropy": 0.648435361353697, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00017563503934070468, "report/cont_loss_std": 0.005255610216408968, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.029496993869543076, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.817625500028953e-06, "report/cont_pred": 0.9942976236343384, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.039643287658691, "report/dyn_loss_std": 9.541396141052246, "report/image_loss_mean": 14.999776840209961, "report/image_loss_std": 23.612598419189453, "report/model_loss_mean": 22.260318756103516, "report/model_loss_std": 28.09035301208496, "report/post_ent_mag": 49.07637405395508, "report/post_ent_max": 49.07637405395508, "report/post_ent_mean": 36.63324737548828, "report/post_ent_min": 19.483863830566406, "report/post_ent_std": 5.600326061248779, "report/prior_ent_mag": 62.22045135498047, "report/prior_ent_max": 62.22045135498047, "report/prior_ent_mean": 48.596527099609375, "report/prior_ent_min": 22.711957931518555, "report/prior_ent_std": 8.822731018066406, "report/rep_loss_mean": 12.039643287658691, "report/rep_loss_std": 9.541396141052246, "report/reward_avg": 0.00439453125, "report/reward_loss_mean": 0.03658201918005943, "report/reward_loss_std": 0.2518080770969391, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9981873035430908, "report/reward_neg_acc": 0.9911330342292786, "report/reward_neg_loss": 0.02033851481974125, "report/reward_pos_acc": 0.7777777910232544, "report/reward_pos_loss": 1.8684883117675781, "report/reward_pred": 0.0026132985949516296, "report/reward_rate": 0.0087890625, "eval/cont_avg": 0.9912109375, "eval/cont_loss_mean": 0.0014089473988860846, "eval/cont_loss_std": 0.03335767611861229, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.015909962356090546, "eval/cont_pos_acc": 0.9990147948265076, "eval/cont_pos_loss": 0.0012803671415895224, "eval/cont_pred": 0.9904782772064209, "eval/cont_rate": 0.9912109375, "eval/dyn_loss_mean": 10.060515403747559, "eval/dyn_loss_std": 8.174093246459961, "eval/image_loss_mean": 5.6662821769714355, "eval/image_loss_std": 7.960277080535889, "eval/model_loss_mean": 11.76718521118164, "eval/model_loss_std": 11.675310134887695, "eval/post_ent_mag": 45.3669548034668, "eval/post_ent_max": 45.3669548034668, "eval/post_ent_mean": 35.05634307861328, "eval/post_ent_min": 21.45349884033203, "eval/post_ent_std": 5.064044952392578, "eval/prior_ent_mag": 61.042083740234375, "eval/prior_ent_max": 61.042083740234375, "eval/prior_ent_mean": 43.906368255615234, "eval/prior_ent_min": 24.638473510742188, "eval/prior_ent_std": 4.940364837646484, "eval/rep_loss_mean": 10.060515403747559, "eval/rep_loss_std": 8.174093246459961, "eval/reward_avg": 0.00595703162252903, "eval/reward_loss_mean": 0.0631846934556961, "eval/reward_loss_std": 0.48297497630119324, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017504692077637, "eval/reward_neg_acc": 0.9960435032844543, "eval/reward_neg_loss": 0.03338939696550369, "eval/reward_pos_acc": 0.692307710647583, "eval/reward_pos_loss": 2.3803417682647705, "eval/reward_pred": 0.0028869069647043943, "eval/reward_rate": 0.0126953125, "replay/size": 170145.0, "replay/inserts": 20816.0, "replay/samples": 20816.0, "replay/insert_wait_avg": 1.4329854567906748e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.040343220833171e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33784.0, "eval_replay/inserts": 5440.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2691406642689425e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0199332237244, "timer/env.step_count": 2602.0, "timer/env.step_total": 254.50597047805786, "timer/env.step_frac": 0.25450089745473087, "timer/env.step_avg": 0.09781167197465714, "timer/env.step_min": 0.023397445678710938, "timer/env.step_max": 3.5890774726867676, "timer/replay._sample_count": 20816.0, "timer/replay._sample_total": 11.792296409606934, "timer/replay._sample_frac": 0.011792061355809756, "timer/replay._sample_avg": 0.0005665015569565207, "timer/replay._sample_min": 0.0004146099090576172, "timer/replay._sample_max": 0.014160394668579102, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3282.0, "timer/agent.policy_total": 58.168463945388794, "timer/agent.policy_frac": 0.05816730448349508, "timer/agent.policy_avg": 0.017723480787747957, "timer/agent.policy_min": 0.009780645370483398, "timer/agent.policy_max": 0.12431597709655762, "timer/dataset_train_count": 1301.0, "timer/dataset_train_total": 0.15537810325622559, "timer/dataset_train_frac": 0.00015537500613146718, "timer/dataset_train_avg": 0.00011942974885182597, "timer/dataset_train_min": 0.00010251998901367188, "timer/dataset_train_max": 0.0005888938903808594, "timer/agent.train_count": 1301.0, "timer/agent.train_total": 588.0320539474487, "timer/agent.train_frac": 0.5880203328066004, "timer/agent.train_avg": 0.45198466867597903, "timer/agent.train_min": 0.4404165744781494, "timer/agent.train_max": 1.4438676834106445, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46863889694213867, "timer/agent.report_frac": 0.00046862955564436215, "timer/agent.report_avg": 0.23431944847106934, "timer/agent.report_min": 0.2221682071685791, "timer/agent.report_max": 0.24647068977355957, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.956331451643146e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 20.815324895880966}
{"step": 170720, "time": 8344.935000419617, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 170896, "time": 8352.351439476013, "episode/length": 221.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 170920, "time": 8354.55206823349, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 170968, "time": 8357.69990158081, "episode/length": 257.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 171088, "time": 8363.51484465599, "episode/length": 337.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9970414201183432, "episode/intrinsic_return": 0.0}
{"step": 171576, "time": 8381.438685417175, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 171744, "time": 8388.90045928955, "episode/length": 268.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 172008, "time": 8399.329451084137, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 172336, "time": 8413.770416498184, "episode/length": 179.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 172408, "time": 8417.593136787415, "episode/length": 210.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 172512, "time": 8422.942312717438, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 172640, "time": 8429.103235960007, "episode/length": 208.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 172864, "time": 8438.238061189651, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 172880, "time": 8440.284985542297, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 173240, "time": 8453.710663557053, "episode/length": 186.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 173344, "time": 8459.050921201706, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 173592, "time": 8468.863470554352, "episode/length": 147.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 173640, "time": 8472.084110021591, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 173992, "time": 8485.48306798935, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 174240, "time": 8495.966591358185, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 174248, "time": 8497.668533325195, "episode/length": 170.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 174304, "time": 8501.376219511032, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 174624, "time": 8513.660084724426, "episode/length": 172.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 174680, "time": 8516.948005914688, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 174912, "time": 8526.743704080582, "episode/length": 35.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 174952, "time": 8529.460891246796, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 175232, "time": 8540.724561691284, "episode/length": 154.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 175320, "time": 8545.200223445892, "episode/length": 215.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 175464, "time": 8551.688655853271, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 175544, "time": 8555.99247598648, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 176000, "time": 8573.173092126846, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 176280, "time": 8584.165947437286, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 176440, "time": 8591.094507455826, "episode/length": 219.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 176448, "time": 8593.211663484573, "episode/length": 151.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 176672, "time": 8602.29587507248, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 177120, "time": 8619.139422893524, "episode/length": 270.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 177160, "time": 8622.070628166199, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 177280, "time": 8628.06020617485, "episode/length": 244.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9877551020408163, "episode/intrinsic_return": 0.0}
{"step": 177688, "time": 8643.352257013321, "episode/length": 154.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 177792, "time": 8648.601331233978, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 177928, "time": 8654.513235092163, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 177968, "time": 8657.620339393616, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 178136, "time": 8664.610629796982, "episode/length": 266.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 178392, "time": 8674.903463840485, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 178984, "time": 8696.424590349197, "episode/length": 232.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 179104, "time": 8702.47464466095, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 179224, "time": 8707.966384410858, "episode/length": 161.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 179424, "time": 8716.581727266312, "episode/length": 267.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 179456, "time": 8719.21011853218, "episode/length": 185.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 179528, "time": 8723.115089416504, "episode/length": 216.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 179728, "time": 8731.796498775482, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 179800, "time": 8735.64859867096, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 8764.995195627213, "eval_episode/length": 144.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.993103448275862}
{"step": 180024, "time": 8767.533658266068, "eval_episode/length": 165.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 180024, "time": 8769.381348133087, "eval_episode/length": 169.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 180024, "time": 8771.149623632431, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 180024, "time": 8773.774386167526, "eval_episode/length": 196.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 180024, "time": 8776.107969522476, "eval_episode/length": 213.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 180024, "time": 8777.751329421997, "eval_episode/length": 214.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9813953488372092}
{"step": 180024, "time": 8781.359099626541, "eval_episode/length": 261.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9809160305343512}
{"step": 180288, "time": 8791.890619754791, "episode/length": 147.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 180312, "time": 8794.214038133621, "episode/length": 165.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 180440, "time": 8800.08785033226, "episode/length": 151.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 180792, "time": 8813.465748786926, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 180856, "time": 8817.447885513306, "episode/length": 165.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 180896, "time": 8820.69018483162, "episode/length": 145.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 181080, "time": 8828.325668811798, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 181472, "time": 8843.260821342468, "episode/length": 128.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 181864, "time": 8858.015756130219, "episode/length": 257.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 182176, "time": 8870.373647212982, "episode/length": 235.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 182264, "time": 8874.74738740921, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 182272, "time": 8876.886245965958, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 182376, "time": 8882.061736345291, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 182608, "time": 8891.647493839264, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 182648, "time": 8894.386052131653, "episode/length": 146.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 182664, "time": 8896.547752857208, "episode/length": 35.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 183264, "time": 8918.597709178925, "episode/length": 174.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 183368, "time": 8923.4424700737, "episode/length": 148.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 183504, "time": 8929.798654317856, "episode/length": 153.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 183848, "time": 8942.857847929, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 183880, "time": 8945.667234659195, "episode/length": 445.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9798206278026906, "episode/intrinsic_return": 0.0}
{"step": 184000, "time": 8951.577846288681, "episode/length": 61.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 184192, "time": 8959.630434513092, "episode/length": 192.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 184272, "time": 8963.90982890129, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 184704, "time": 8981.106867551804, "episode/length": 254.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 184840, "time": 8987.204553604126, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 184896, "time": 8990.871124744415, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 184912, "time": 8993.012954473495, "episode/length": 132.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 185408, "time": 9011.54223370552, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 185488, "time": 9015.841218709946, "episode/length": 151.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 185632, "time": 9022.229489803314, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 185720, "time": 9026.549782276154, "episode/length": 100.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9504950495049505, "episode/intrinsic_return": 0.0}
{"step": 185808, "time": 9031.535741329193, "episode/length": 201.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 185928, "time": 9036.953811645508, "episode/length": 152.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 186120, "time": 9044.9425137043, "episode/length": 152.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 186176, "time": 9048.627434968948, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 186952, "time": 9076.234634399414, "episode/length": 142.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 187024, "time": 9080.476197004318, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 187032, "time": 9082.08909034729, "episode/length": 192.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 187216, "time": 9090.28832602501, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 187344, "time": 9096.231180429459, "episode/length": 213.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 187456, "time": 9101.664558410645, "episode/length": 159.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 187488, "time": 9104.326532363892, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 187720, "time": 9113.599976301193, "episode/length": 32.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 188416, "time": 9139.423013448715, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 188416, "time": 9139.444397687912, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 188552, "time": 9148.438047885895, "episode/length": 150.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 188608, "time": 9152.205765008926, "episode/length": 173.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 188856, "time": 9162.503229379654, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 188928, "time": 9166.871762037277, "episode/length": 246.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 189024, "time": 9171.65425658226, "episode/length": 75.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 189168, "time": 9178.371432065964, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 189480, "time": 9190.318000793457, "episode/length": 443.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 189968, "time": 9208.665911197662, "episode/length": 129.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 189976, "time": 9210.311116456985, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 9228.039353847504, "eval_episode/length": 33.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 190008, "time": 9229.729225873947, "eval_episode/length": 35.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 190008, "time": 9231.895859241486, "eval_episode/length": 48.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 190008, "time": 9237.911453485489, "eval_episode/length": 147.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 190008, "time": 9239.617537260056, "eval_episode/length": 148.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9731543624161074}
{"step": 190008, "time": 9241.95549941063, "eval_episode/length": 165.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 190008, "time": 9244.291573762894, "eval_episode/length": 183.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 190008, "time": 9246.386052131653, "eval_episode/length": 193.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 190112, "time": 9250.124647855759, "episode/length": 187.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 190152, "time": 9252.88379573822, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 190272, "time": 9258.755726337433, "episode/length": 155.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 190312, "time": 9261.586275815964, "episode/length": 142.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 190496, "time": 9269.660939216614, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 190704, "time": 9278.25768995285, "episode/length": 91.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 191080, "time": 9292.324922561646, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 191192, "time": 9297.829523563385, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 191368, "time": 9305.491812705994, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 191440, "time": 9309.72152519226, "episode/length": 140.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 191688, "time": 9319.606841087341, "episode/length": 176.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9548022598870056, "episode/intrinsic_return": 0.0}
{"step": 191776, "time": 9324.552632331848, "episode/length": 202.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 192233, "time": 9342.784197807312, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.928505678530093, "train/action_min": 0.0, "train/action_std": 3.5559237356539124, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04768454529069088, "train/actor_opt_grad_steps": 11240.0, "train/actor_opt_loss": 0.8445961262340899, "train/adv_mag": 1.0889241108187924, "train/adv_max": 1.0799292957341229, "train/adv_mean": 0.004858907948450737, "train/adv_min": -0.643413488511686, "train/adv_std": 0.0909851342715599, "train/cont_avg": 0.9940538194444445, "train/cont_loss_mean": 0.00037809280476737314, "train/cont_loss_std": 0.010950831541378893, "train/cont_neg_acc": 0.9826984153853522, "train/cont_neg_loss": 0.047219127114516576, "train/cont_pos_acc": 0.9999563287805628, "train/cont_pos_loss": 0.00010316016537211773, "train/cont_pred": 0.99410149079782, "train/cont_rate": 0.9940538194444445, "train/dyn_loss_mean": 11.103761143154568, "train/dyn_loss_std": 9.06608919567532, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.073744406965044, "train/extr_critic_critic_opt_grad_steps": 11240.0, "train/extr_critic_critic_opt_loss": 14381.203971354167, "train/extr_critic_mag": 3.92598535573041, "train/extr_critic_max": 3.92598535573041, "train/extr_critic_mean": 0.7578664327109301, "train/extr_critic_min": -0.306057612101237, "train/extr_critic_std": 0.7822508564701787, "train/extr_return_normed_mag": 2.309317464298672, "train/extr_return_normed_max": 2.309317464298672, "train/extr_return_normed_mean": 0.3647961140782745, "train/extr_return_normed_min": -0.2599271301869993, "train/extr_return_normed_std": 0.3513281810062903, "train/extr_return_rate": 0.45631368138172007, "train/extr_return_raw_mag": 5.3321535092813, "train/extr_return_raw_max": 5.3321535092813, "train/extr_return_raw_mean": 0.7692533636534655, "train/extr_return_raw_min": -0.6904637003386462, "train/extr_return_raw_std": 0.8234847110730631, "train/extr_reward_mag": 1.0034620788362292, "train/extr_reward_max": 1.0034620788362292, "train/extr_reward_mean": 0.012817416278024515, "train/extr_reward_min": -0.4885135491689046, "train/extr_reward_std": 0.10576970792478985, "train/image_loss_mean": 10.270439893228037, "train/image_loss_std": 14.975131667101826, "train/model_loss_mean": 16.974906730651856, "train/model_loss_std": 18.932535870869955, "train/model_opt_grad_norm": 75.78479943452058, "train/model_opt_grad_steps": 11226.325925925927, "train/model_opt_loss": 14060.61918041088, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 828.7037037037037, "train/policy_entropy_mag": 2.452033509148492, "train/policy_entropy_max": 2.452033509148492, "train/policy_entropy_mean": 0.7477098513532567, "train/policy_entropy_min": 0.07938012182712555, "train/policy_entropy_std": 0.5681131844167356, "train/policy_logprob_mag": 7.438321632809109, "train/policy_logprob_max": -0.009456830658018589, "train/policy_logprob_mean": -0.7458629444793419, "train/policy_logprob_min": -7.438321632809109, "train/policy_logprob_std": 1.1876109335157605, "train/policy_randomness_mag": 0.8654602258293717, "train/policy_randomness_max": 0.8654602258293717, "train/policy_randomness_mean": 0.2639087652718579, "train/policy_randomness_min": 0.02801769952531214, "train/policy_randomness_std": 0.20051902179364806, "train/post_ent_mag": 51.61741674917715, "train/post_ent_max": 51.61741674917715, "train/post_ent_mean": 35.897079411259405, "train/post_ent_min": 19.86600395485207, "train/post_ent_std": 5.638926276454219, "train/prior_ent_mag": 63.05572868629738, "train/prior_ent_max": 63.05572868629738, "train/prior_ent_mean": 47.11718150951244, "train/prior_ent_min": 22.839790471394856, "train/prior_ent_std": 7.857686473705151, "train/rep_loss_mean": 11.103761143154568, "train/rep_loss_std": 9.06608919567532, "train/reward_avg": 0.00919270825020417, "train/reward_loss_mean": 0.04183193217549059, "train/reward_loss_std": 0.2313317546138057, "train/reward_max_data": 1.0066666682561238, "train/reward_max_pred": 1.0019061494756627, "train/reward_neg_acc": 0.9954330572375545, "train/reward_neg_loss": 0.027826433477026444, "train/reward_pos_acc": 0.9386274562941657, "train/reward_pos_loss": 0.9979447969683894, "train/reward_pred": 0.008724037290516275, "train/reward_rate": 0.014482060185185185, "train_stats/sum_log_reward": 3.4277310261205467, "train_stats/max_log_achievement_collect_drink": 9.857142857142858, "train_stats/max_log_achievement_collect_sapling": 1.9831932773109244, "train_stats/max_log_achievement_collect_wood": 2.0672268907563027, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.10084033613445378, "train_stats/max_log_achievement_eat_cow": 0.11764705882352941, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_place_plant": 1.8235294117647058, "train_stats/max_log_achievement_place_table": 0.11764705882352941, "train_stats/max_log_achievement_wake_up": 2.092436974789916, "train_stats/mean_log_entropy": 0.75463772896959, "eval_stats/sum_log_reward": 3.0374999046325684, "eval_stats/max_log_achievement_collect_drink": 5.125, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_wood": 2.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.023809523809523808, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.833590224327054e-05, "report/cont_loss_std": 0.0008856585482135415, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.005789676681160927, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.631665883105597e-08, "report/cont_pred": 0.9951450228691101, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.13637924194336, "report/dyn_loss_std": 9.341409683227539, "report/image_loss_mean": 9.150338172912598, "report/image_loss_std": 11.185413360595703, "report/model_loss_mean": 17.06536293029785, "report/model_loss_std": 15.359943389892578, "report/post_ent_mag": 52.88063049316406, "report/post_ent_max": 52.88063049316406, "report/post_ent_mean": 36.50727462768555, "report/post_ent_min": 20.09406280517578, "report/post_ent_std": 5.278229236602783, "report/prior_ent_mag": 63.46996307373047, "report/prior_ent_max": 63.46996307373047, "report/prior_ent_mean": 49.78941345214844, "report/prior_ent_min": 24.789878845214844, "report/prior_ent_std": 7.294355392456055, "report/rep_loss_mean": 13.13637924194336, "report/rep_loss_std": 9.341409683227539, "report/reward_avg": 0.01123046875, "report/reward_loss_mean": 0.03316905349493027, "report/reward_loss_std": 0.1880977898836136, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0027060508728027, "report/reward_neg_acc": 0.9930556416511536, "report/reward_neg_loss": 0.022218748927116394, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7230383157730103, "report/reward_pred": 0.012355269864201546, "report/reward_rate": 0.015625, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 1.1547939720912836e-05, "eval/cont_loss_std": 0.00028514076257124543, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00036760116927325726, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.744370461499784e-06, "eval/cont_pred": 0.9921817183494568, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 9.697938919067383, "eval/dyn_loss_std": 7.883107662200928, "eval/image_loss_mean": 4.141319274902344, "eval/image_loss_std": 5.63381290435791, "eval/model_loss_mean": 9.995649337768555, "eval/model_loss_std": 8.894704818725586, "eval/post_ent_mag": 51.98444366455078, "eval/post_ent_max": 51.98444366455078, "eval/post_ent_mean": 35.919898986816406, "eval/post_ent_min": 18.452545166015625, "eval/post_ent_std": 5.3599982261657715, "eval/prior_ent_mag": 62.24958038330078, "eval/prior_ent_max": 62.24958038330078, "eval/prior_ent_mean": 43.758995056152344, "eval/prior_ent_min": 22.144254684448242, "eval/prior_ent_std": 5.785848140716553, "eval/rep_loss_mean": 9.697938919067383, "eval/rep_loss_std": 7.883107662200928, "eval/reward_avg": 0.0009765625, "eval/reward_loss_mean": 0.035554952919483185, "eval/reward_loss_std": 0.2304648458957672, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0012545585632324, "eval/reward_neg_acc": 0.9950787425041199, "eval/reward_neg_loss": 0.02553800866007805, "eval/reward_pos_acc": 0.875, "eval/reward_pos_loss": 1.3077064752578735, "eval/reward_pred": 0.0013500626664608717, "eval/reward_rate": 0.0078125, "replay/size": 191729.0, "replay/inserts": 21584.0, "replay/samples": 21584.0, "replay/insert_wait_avg": 1.4274296184395578e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.071371836340631e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 37432.0, "eval_replay/inserts": 3648.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2956821081931132e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3539385795593, "timer/env.step_count": 2698.0, "timer/env.step_total": 268.50711393356323, "timer/env.step_frac": 0.26841211253171726, "timer/env.step_avg": 0.09952079834453789, "timer/env.step_min": 0.023698091506958008, "timer/env.step_max": 4.504291772842407, "timer/replay._sample_count": 21584.0, "timer/replay._sample_total": 12.260559558868408, "timer/replay._sample_frac": 0.012256221609201283, "timer/replay._sample_avg": 0.0005680392679238514, "timer/replay._sample_min": 0.00044345855712890625, "timer/replay._sample_max": 0.010483980178833008, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3154.0, "timer/agent.policy_total": 55.027090072631836, "timer/agent.policy_frac": 0.05500762075347741, "timer/agent.policy_avg": 0.017446762863865515, "timer/agent.policy_min": 0.009643316268920898, "timer/agent.policy_max": 0.09974002838134766, "timer/dataset_train_count": 1349.0, "timer/dataset_train_total": 0.16202449798583984, "timer/dataset_train_frac": 0.00016196717155520434, "timer/dataset_train_avg": 0.00012010711488942909, "timer/dataset_train_min": 0.00010275840759277344, "timer/dataset_train_max": 0.0011067390441894531, "timer/agent.train_count": 1349.0, "timer/agent.train_total": 609.085880279541, "timer/agent.train_frac": 0.6088703775629706, "timer/agent.train_avg": 0.45150917737549373, "timer/agent.train_min": 0.43378734588623047, "timer/agent.train_max": 1.5361082553863525, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48210740089416504, "timer/agent.report_frac": 0.00048193682485893715, "timer/agent.report_avg": 0.24105370044708252, "timer/agent.report_min": 0.23368620872497559, "timer/agent.report_max": 0.24842119216918945, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.336679127950883e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 21.576042294251668}
{"step": 192288, "time": 9344.823306798935, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 192384, "time": 9349.732582569122, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 192488, "time": 9354.647701263428, "episode/length": 248.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 192680, "time": 9363.021184682846, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 192920, "time": 9372.884730100632, "episode/length": 215.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 192968, "time": 9376.111686706543, "episode/length": 35.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 193112, "time": 9382.677931308746, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 193432, "time": 9395.598818540573, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 193432, "time": 9395.608519554138, "episode/length": 142.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 193552, "time": 9403.448786973953, "episode/length": 232.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 193728, "time": 9411.02296090126, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 193784, "time": 9414.317826509476, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 194144, "time": 9428.634631156921, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 194672, "time": 9448.459424972534, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 194776, "time": 9453.483853816986, "episode/length": 152.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 194776, "time": 9453.493549346924, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 195088, "time": 9467.908157587051, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 195168, "time": 9472.374501228333, "episode/length": 274.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 195248, "time": 9476.612639904022, "episode/length": 189.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 195376, "time": 9482.91190481186, "episode/length": 153.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 195584, "time": 9491.601895809174, "episode/length": 224.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 195992, "time": 9506.978762865067, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 196184, "time": 9515.470375061035, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 196192, "time": 9517.64074754715, "episode/length": 176.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 196520, "time": 9530.357460737228, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 196568, "time": 9533.65213561058, "episode/length": 148.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 196672, "time": 9540.646774291992, "episode/length": 197.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 196752, "time": 9545.143340826035, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 196840, "time": 9549.596749305725, "episode/length": 33.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8823529411764706, "episode/intrinsic_return": 0.0}
{"step": 197248, "time": 9565.564153194427, "episode/length": 156.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 197480, "time": 9575.14415550232, "episode/length": 236.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 197640, "time": 9582.253493785858, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 197656, "time": 9584.397505998611, "episode/length": 182.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 197840, "time": 9592.555572748184, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 197960, "time": 9598.250056743622, "episode/length": 150.0, "episode/score": 6.1000000461936, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 198032, "time": 9602.531005859375, "episode/length": 148.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 198096, "time": 9606.241071224213, "episode/length": 105.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 198312, "time": 9615.045677900314, "episode/length": 83.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 198384, "time": 9619.486455917358, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 198920, "time": 9639.529836177826, "episode/length": 134.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 199048, "time": 9645.566989660263, "episode/length": 135.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 199112, "time": 9649.334157466888, "episode/length": 203.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 199400, "time": 9661.076363801956, "episode/length": 217.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 199400, "time": 9661.084089756012, "episode/length": 135.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 199600, "time": 9671.642579555511, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 199632, "time": 9674.388479948044, "episode/length": 155.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 199768, "time": 9680.421303272247, "episode/length": 216.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 199792, "time": 9683.17212677002, "episode/length": 48.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8979591836734694, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 9710.407629966736, "eval_episode/length": 34.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 200096, "time": 9712.21089053154, "eval_episode/length": 36.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8648648648648649}
{"step": 200096, "time": 9713.813687324524, "eval_episode/length": 37.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 200096, "time": 9715.607160568237, "eval_episode/length": 39.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.875}
{"step": 200096, "time": 9722.581293582916, "eval_episode/length": 108.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9908256880733946}
{"step": 200096, "time": 9725.553273439407, "eval_episode/length": 174.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 200096, "time": 9727.475342273712, "eval_episode/length": 182.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.994535519125683}
{"step": 200096, "time": 9729.474224567413, "eval_episode/length": 39.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.875}
{"step": 200520, "time": 9743.797173261642, "episode/length": 183.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 200568, "time": 9747.021876096725, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 200992, "time": 9763.582750082016, "episode/length": 198.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 201048, "time": 9766.890721559525, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 201192, "time": 9773.512851715088, "episode/length": 259.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 201200, "time": 9775.696840286255, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 201248, "time": 9779.11426281929, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 201288, "time": 9781.925816059113, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 201624, "time": 9795.04375743866, "episode/length": 137.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 202232, "time": 9817.872031211853, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 202256, "time": 9820.523683071136, "episode/length": 131.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 202416, "time": 9827.791080713272, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 202472, "time": 9831.094545602798, "episode/length": 177.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 202544, "time": 9835.51505446434, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 202568, "time": 9837.848774909973, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 202656, "time": 9842.88309788704, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 202960, "time": 9855.05843281746, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 203600, "time": 9878.872693538666, "episode/length": 128.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 203728, "time": 9885.019399404526, "episode/length": 156.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 203752, "time": 9887.280401945114, "episode/length": 186.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 203984, "time": 9897.12290930748, "episode/length": 127.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9453125, "episode/intrinsic_return": 0.0}
{"step": 204008, "time": 9899.569815635681, "episode/length": 221.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 204016, "time": 9901.70956158638, "episode/length": 32.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 204024, "time": 9903.293895959854, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 204104, "time": 9907.746146678925, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 204216, "time": 9913.171433448792, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 204776, "time": 9934.227707624435, "episode/length": 146.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 205016, "time": 9945.419491052628, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 205040, "time": 9948.076406478882, "episode/length": 32.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 205128, "time": 9952.463011264801, "episode/length": 138.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 205360, "time": 9962.50357079506, "episode/length": 142.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 205384, "time": 9964.649515628815, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 205584, "time": 9973.44551539421, "episode/length": 184.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 205592, "time": 9975.084932088852, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 205744, "time": 9982.245973110199, "episode/length": 219.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 205904, "time": 9989.51161313057, "episode/length": 38.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 206280, "time": 10003.696434736252, "episode/length": 157.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 206672, "time": 10019.434736728668, "episode/length": 192.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9844559585492227, "episode/intrinsic_return": 0.0}
{"step": 206800, "time": 10025.542363643646, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 206976, "time": 10033.281465768814, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 207008, "time": 10036.087405920029, "episode/length": 137.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 207040, "time": 10038.836398363113, "episode/length": 181.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 207096, "time": 10042.211995124817, "episode/length": 216.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 207216, "time": 10048.41706943512, "episode/length": 183.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 207648, "time": 10064.660116434097, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 208064, "time": 10080.388826847076, "episode/length": 131.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 208104, "time": 10083.19958281517, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 208272, "time": 10090.729446172714, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 208320, "time": 10094.021877527237, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 208584, "time": 10104.363108873367, "episode/length": 38.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 208672, "time": 10109.255967140198, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 208936, "time": 10119.464791536331, "episode/length": 103.0, "episode/score": 2.099999964237213, "episode/reward_rate": 0.9423076923076923, "episode/intrinsic_return": 0.0}
{"step": 208992, "time": 10123.173836946487, "episode/length": 39.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 209432, "time": 10139.706619977951, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 209504, "time": 10144.037841796875, "episode/length": 231.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 209600, "time": 10149.014783143997, "episode/length": 297.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 209752, "time": 10155.48898601532, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 210048, "time": 10167.288387537003, "episode/length": 368.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994579945799458, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 10185.900836467743, "eval_episode/length": 52.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9056603773584906}
{"step": 210080, "time": 10191.189156770706, "eval_episode/length": 133.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9925373134328358}
{"step": 210080, "time": 10194.252737522125, "eval_episode/length": 164.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 210080, "time": 10196.777971744537, "eval_episode/length": 184.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 210080, "time": 10199.227888345718, "eval_episode/length": 190.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 210080, "time": 10202.061493396759, "eval_episode/length": 193.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9690721649484536}
{"step": 210080, "time": 10204.058562517166, "eval_episode/length": 199.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 210080, "time": 10205.799769878387, "eval_episode/length": 203.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 210304, "time": 10213.409046173096, "episode/length": 214.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 210416, "time": 10218.7769947052, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 210592, "time": 10226.284469366074, "episode/length": 35.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 210616, "time": 10228.598428487778, "episode/length": 209.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 210856, "time": 10238.252092123032, "episode/length": 177.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 210872, "time": 10240.43989443779, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 211032, "time": 10247.480382919312, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 211256, "time": 10256.655760288239, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 211576, "time": 10269.233161449432, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 211824, "time": 10279.510609149933, "episode/length": 175.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 211944, "time": 10284.919654369354, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 212200, "time": 10295.330180883408, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 212392, "time": 10303.468462228775, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 212496, "time": 10308.858451128006, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 212728, "time": 10318.153906583786, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 212744, "time": 10320.356173992157, "episode/length": 213.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 213096, "time": 10335.279402017593, "episode/length": 189.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 213241, "time": 10342.799597978592, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.6244150797526045, "train/action_min": 0.0, "train/action_std": 3.0006656285488242, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04658462570020647, "train/actor_opt_grad_steps": 12575.0, "train/actor_opt_loss": -1.2995084605998162, "train/adv_mag": 0.9865670791178038, "train/adv_max": 0.9782245100447626, "train/adv_mean": 0.004481675301301011, "train/adv_min": -0.5579496134411205, "train/adv_std": 0.08551640001436074, "train/cont_avg": 0.9945401278409091, "train/cont_loss_mean": 0.00040785180533419276, "train/cont_loss_std": 0.01156943847895129, "train/cont_neg_acc": 0.9848214311130119, "train/cont_neg_loss": 0.044345784548478186, "train/cont_pos_acc": 0.9999702514121027, "train/cont_pos_loss": 0.00014687989661452548, "train/cont_pred": 0.9945576312867078, "train/cont_rate": 0.9945401278409091, "train/dyn_loss_mean": 11.47540152795387, "train/dyn_loss_std": 9.312249898910522, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0196640423753045, "train/extr_critic_critic_opt_grad_steps": 12575.0, "train/extr_critic_critic_opt_loss": 14273.747196081913, "train/extr_critic_mag": 3.700913125818426, "train/extr_critic_max": 3.700913125818426, "train/extr_critic_mean": 0.7655972267190615, "train/extr_critic_min": -0.29675600655151135, "train/extr_critic_std": 0.7881711676265254, "train/extr_return_normed_mag": 2.1265638380339653, "train/extr_return_normed_max": 2.1265638380339653, "train/extr_return_normed_mean": 0.36935024200515315, "train/extr_return_normed_min": -0.24914528175511144, "train/extr_return_normed_std": 0.3584586956510038, "train/extr_return_rate": 0.45465398399215756, "train/extr_return_raw_mag": 4.7921153632077305, "train/extr_return_raw_max": 4.7921153632077305, "train/extr_return_raw_mean": 0.7758274295113303, "train/extr_return_raw_min": -0.639356407252225, "train/extr_return_raw_std": 0.8208659189668569, "train/extr_reward_mag": 1.004098752231309, "train/extr_reward_max": 1.004098752231309, "train/extr_reward_mean": 0.014966727925859617, "train/extr_reward_min": -0.45923598607381183, "train/extr_reward_std": 0.11079021483998407, "train/image_loss_mean": 9.618702241868684, "train/image_loss_std": 14.22717530077154, "train/model_loss_mean": 16.545213944984205, "train/model_loss_std": 18.289335164156828, "train/model_opt_grad_norm": 66.7018746173743, "train/model_opt_grad_steps": 12560.015151515152, "train/model_opt_loss": 11362.301306522253, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 686.5530303030303, "train/policy_entropy_mag": 2.438060504017454, "train/policy_entropy_max": 2.438060504017454, "train/policy_entropy_mean": 0.7031983782847723, "train/policy_entropy_min": 0.07937910627912391, "train/policy_entropy_std": 0.5603898120197383, "train/policy_logprob_mag": 7.438352812420238, "train/policy_logprob_max": -0.009456650629131631, "train/policy_logprob_mean": -0.7018288527474259, "train/policy_logprob_min": -7.438352812420238, "train/policy_logprob_std": 1.1715714579278773, "train/policy_randomness_mag": 0.8605283665837664, "train/policy_randomness_max": 0.8605283665837664, "train/policy_randomness_mean": 0.24819816648960114, "train/policy_randomness_min": 0.028017341018174633, "train/policy_randomness_std": 0.19779301096092572, "train/post_ent_mag": 52.59860807476622, "train/post_ent_max": 52.59860807476622, "train/post_ent_mean": 36.49751365546024, "train/post_ent_min": 20.357258811141506, "train/post_ent_std": 5.65452080784422, "train/prior_ent_mag": 63.71725411848588, "train/prior_ent_max": 63.71725411848588, "train/prior_ent_mean": 48.08135850501783, "train/prior_ent_min": 24.217508691729922, "train/prior_ent_std": 7.680607564521559, "train/rep_loss_mean": 11.47540152795387, "train/rep_loss_std": 9.312249898910522, "train/reward_avg": 0.009898052706072727, "train/reward_loss_mean": 0.04086284929265579, "train/reward_loss_std": 0.2294908594904524, "train/reward_max_data": 1.0045454556291753, "train/reward_max_pred": 1.0010248747738926, "train/reward_neg_acc": 0.9956946074962616, "train/reward_neg_loss": 0.025958577657795766, "train/reward_pos_acc": 0.9313285088900364, "train/reward_pos_loss": 1.029337142453049, "train/reward_pred": 0.00902650050579034, "train/reward_rate": 0.01478900331439394, "train_stats/sum_log_reward": 3.352032452579436, "train_stats/max_log_achievement_collect_drink": 7.560975609756097, "train_stats/max_log_achievement_collect_sapling": 0.9105691056910569, "train_stats/max_log_achievement_collect_wood": 2.4390243902439024, "train_stats/max_log_achievement_defeat_skeleton": 0.024390243902439025, "train_stats/max_log_achievement_defeat_zombie": 0.032520325203252036, "train_stats/max_log_achievement_eat_cow": 0.04065040650406504, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.008130081300813009, "train_stats/max_log_achievement_place_plant": 0.8373983739837398, "train_stats/max_log_achievement_place_table": 0.7723577235772358, "train_stats/max_log_achievement_wake_up": 2.138211382113821, "train_stats/mean_log_entropy": 0.7609214712449206, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05434782608695652, "eval_stats/sum_log_reward": 2.7249999307096004, "eval_stats/max_log_achievement_collect_drink": 4.4375, "eval_stats/max_log_achievement_collect_sapling": 0.9375, "eval_stats/max_log_achievement_collect_wood": 2.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 0.75, "eval_stats/max_log_achievement_place_table": 1.0625, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.104876658559078e-06, "report/cont_loss_std": 0.0002053962234640494, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0013609365560114384, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.61934718032353e-07, "report/cont_pred": 0.9951233863830566, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.970146179199219, "report/dyn_loss_std": 10.509215354919434, "report/image_loss_mean": 10.797887802124023, "report/image_loss_std": 15.694427490234375, "report/model_loss_mean": 18.012434005737305, "report/model_loss_std": 20.459352493286133, "report/post_ent_mag": 50.57704162597656, "report/post_ent_max": 50.57704162597656, "report/post_ent_mean": 37.9461669921875, "report/post_ent_min": 20.955780029296875, "report/post_ent_std": 5.500791072845459, "report/prior_ent_mag": 64.58000183105469, "report/prior_ent_max": 64.58000183105469, "report/prior_ent_mean": 49.6068000793457, "report/prior_ent_min": 29.416404724121094, "report/prior_ent_std": 7.095671653747559, "report/rep_loss_mean": 11.970146179199219, "report/rep_loss_std": 10.509215354919434, "report/reward_avg": 0.012988281436264515, "report/reward_loss_mean": 0.03245082497596741, "report/reward_loss_std": 0.18417629599571228, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0011794567108154, "report/reward_neg_acc": 0.9980159401893616, "report/reward_neg_loss": 0.018247585743665695, "report/reward_pos_acc": 0.9375, "report/reward_pos_loss": 0.9272546768188477, "report/reward_pred": 0.011214228346943855, "report/reward_rate": 0.015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.833876533259172e-05, "eval/cont_loss_std": 0.0007723398739472032, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.6763053281465545e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.8372778615448624e-05, "eval/cont_pred": 0.9970424175262451, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 11.094456672668457, "eval/dyn_loss_std": 8.828413009643555, "eval/image_loss_mean": 12.406441688537598, "eval/image_loss_std": 24.697696685791016, "eval/model_loss_mean": 19.093502044677734, "eval/model_loss_std": 27.79562759399414, "eval/post_ent_mag": 49.78093719482422, "eval/post_ent_max": 49.78093719482422, "eval/post_ent_mean": 37.688045501708984, "eval/post_ent_min": 21.986408233642578, "eval/post_ent_std": 5.052559852600098, "eval/prior_ent_mag": 64.58000183105469, "eval/prior_ent_max": 64.58000183105469, "eval/prior_ent_mean": 45.632904052734375, "eval/prior_ent_min": 25.82322883605957, "eval/prior_ent_std": 5.640453815460205, "eval/rep_loss_mean": 11.094456672668457, "eval/rep_loss_std": 8.828413009643555, "eval/reward_avg": 0.003710937686264515, "eval/reward_loss_mean": 0.030358025804162025, "eval/reward_loss_std": 0.3456018269062042, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9991903305053711, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.013046306557953358, "eval/reward_pos_acc": 0.7142857313156128, "eval/reward_pos_loss": 2.5455033779144287, "eval/reward_pred": 0.0017656722338870168, "eval/reward_rate": 0.0068359375, "replay/size": 212737.0, "replay/inserts": 21008.0, "replay/samples": 21008.0, "replay/insert_wait_avg": 1.5236181969508267e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.814678760130534e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 40576.0, "eval_replay/inserts": 3144.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3052355545471037e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9965577125549, "timer/env.step_count": 2626.0, "timer/env.step_total": 275.2375855445862, "timer/env.step_frac": 0.2752385329947327, "timer/env.step_avg": 0.10481248497508994, "timer/env.step_min": 0.024164676666259766, "timer/env.step_max": 3.5434658527374268, "timer/replay._sample_count": 21008.0, "timer/replay._sample_total": 12.533578634262085, "timer/replay._sample_frac": 0.012533621778590975, "timer/replay._sample_avg": 0.0005966097978989949, "timer/replay._sample_min": 0.0004324913024902344, "timer/replay._sample_max": 0.02525782585144043, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3019.0, "timer/agent.policy_total": 55.413161516189575, "timer/agent.policy_frac": 0.05541335226487636, "timer/agent.policy_avg": 0.018354806729443382, "timer/agent.policy_min": 0.010086297988891602, "timer/agent.policy_max": 0.12070322036743164, "timer/dataset_train_count": 1313.0, "timer/dataset_train_total": 0.1708974838256836, "timer/dataset_train_frac": 0.0001708980721059716, "timer/dataset_train_avg": 0.00013015802271567676, "timer/dataset_train_min": 0.00011038780212402344, "timer/dataset_train_max": 0.0010943412780761719, "timer/agent.train_count": 1313.0, "timer/agent.train_total": 600.8415813446045, "timer/agent.train_frac": 0.600843649621156, "timer/agent.train_avg": 0.45760973445895237, "timer/agent.train_min": 0.4427468776702881, "timer/agent.train_max": 1.5944488048553467, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47261643409729004, "timer/agent.report_frac": 0.00047261806098450765, "timer/agent.report_avg": 0.23630821704864502, "timer/agent.report_min": 0.22450661659240723, "timer/agent.report_max": 0.2481098175048828, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.552436828613281e-05, "timer/dataset_eval_frac": 3.55244905716407e-08, "timer/dataset_eval_avg": 3.552436828613281e-05, "timer/dataset_eval_min": 3.552436828613281e-05, "timer/dataset_eval_max": 3.552436828613281e-05, "fps": 21.007756810516316}
{"step": 213400, "time": 10348.205109834671, "episode/length": 37.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 213472, "time": 10352.422409296036, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 213616, "time": 10358.91576743126, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 213616, "time": 10358.923949718475, "episode/length": 208.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 213720, "time": 10365.603065490723, "episode/length": 39.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 213744, "time": 10368.268908262253, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 213792, "time": 10371.474344730377, "episode/length": 39.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 213832, "time": 10374.28607916832, "episode/length": 135.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 213936, "time": 10379.757536172867, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 214192, "time": 10390.005020618439, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 214872, "time": 10414.652798175812, "episode/length": 156.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 215176, "time": 10426.617218017578, "episode/length": 181.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 215176, "time": 10426.627422571182, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 215232, "time": 10433.024593114853, "episode/length": 201.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 215288, "time": 10436.352329492569, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 215296, "time": 10438.602217435837, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 215384, "time": 10442.953607797623, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 215808, "time": 10459.187189340591, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 216104, "time": 10470.606464862823, "episode/length": 36.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 216112, "time": 10472.637052059174, "episode/length": 109.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9454545454545454, "episode/intrinsic_return": 0.0}
{"step": 216192, "time": 10477.38353228569, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 216648, "time": 10494.230362653732, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 216680, "time": 10496.939554214478, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 216840, "time": 10504.159237384796, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 216880, "time": 10507.293757200241, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 217272, "time": 10522.070328950882, "episode/length": 247.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 217576, "time": 10534.169935464859, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 217576, "time": 10534.229638576508, "episode/length": 37.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 217784, "time": 10544.640478372574, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 217936, "time": 10551.763327360153, "episode/length": 217.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 218040, "time": 10556.627426862717, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 218080, "time": 10559.97194814682, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 218280, "time": 10568.117059230804, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 218360, "time": 10572.400576114655, "episode/length": 34.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 218456, "time": 10577.182176113129, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 218704, "time": 10587.413429498672, "episode/length": 95.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9479166666666666, "episode/intrinsic_return": 0.0}
{"step": 218960, "time": 10597.885010957718, "episode/length": 146.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 219152, "time": 10606.024960756302, "episode/length": 196.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 219208, "time": 10609.166426420212, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 219696, "time": 10627.664826631546, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 219840, "time": 10634.139236688614, "episode/length": 141.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 220000, "time": 10641.114870786667, "episode/length": 244.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 10659.64360833168, "eval_episode/length": 37.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 220064, "time": 10666.72534275055, "eval_episode/length": 160.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 220064, "time": 10668.401328086853, "eval_episode/length": 161.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 220064, "time": 10670.67657160759, "eval_episode/length": 178.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9608938547486033}
{"step": 220064, "time": 10673.011134386063, "eval_episode/length": 191.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 220064, "time": 10674.981773138046, "eval_episode/length": 200.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 220064, "time": 10676.894916534424, "eval_episode/length": 207.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 220064, "time": 10678.865089893341, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9540229885057471}
{"step": 220328, "time": 10687.634766101837, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 220424, "time": 10692.575204849243, "episode/length": 182.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 220552, "time": 10698.520722389221, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 220592, "time": 10701.865314006805, "episode/length": 278.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 221072, "time": 10719.846020936966, "episode/length": 326.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9877675840978594, "episode/intrinsic_return": 0.0}
{"step": 221208, "time": 10727.257632255554, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 221408, "time": 10735.807304620743, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 221616, "time": 10744.692552566528, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 221680, "time": 10748.474586486816, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 221704, "time": 10750.687735557556, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 221816, "time": 10756.068887710571, "episode/length": 157.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 222168, "time": 10769.885426282883, "episode/length": 196.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 222520, "time": 10783.44384765625, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 222528, "time": 10785.578299760818, "episode/length": 164.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 222576, "time": 10788.719472408295, "episode/length": 145.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 222728, "time": 10795.200613498688, "episode/length": 138.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 222768, "time": 10798.439073324203, "episode/length": 135.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 223000, "time": 10807.616646051407, "episode/length": 161.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 223520, "time": 10827.150341272354, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 223576, "time": 10830.516952514648, "episode/length": 105.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9433962264150944, "episode/intrinsic_return": 0.0}
{"step": 223736, "time": 10837.502754449844, "episode/length": 150.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 223864, "time": 10843.45940732956, "episode/length": 35.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 223872, "time": 10845.569062948227, "episode/length": 43.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 223928, "time": 10848.84089589119, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 224016, "time": 10853.68050122261, "episode/length": 230.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 224248, "time": 10863.11405968666, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 224416, "time": 10870.737360715866, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 224560, "time": 10877.173443078995, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 224736, "time": 10884.692500829697, "episode/length": 21.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8181818181818182, "episode/intrinsic_return": 0.0}
{"step": 224840, "time": 10889.789415836334, "episode/length": 120.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 224912, "time": 10893.98133134842, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 225168, "time": 10904.229598999023, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 225176, "time": 10905.905060052872, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 225816, "time": 10929.216170072556, "episode/length": 134.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 225848, "time": 10931.82942032814, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 225928, "time": 10936.190975904465, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 225984, "time": 10939.888392448425, "episode/length": 256.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 225992, "time": 10941.428843259811, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 226232, "time": 10951.21138715744, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 226304, "time": 10955.435578346252, "episode/length": 38.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 226344, "time": 10958.163003921509, "episode/length": 145.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 226928, "time": 10979.905919075012, "episode/length": 138.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 227080, "time": 10986.333225250244, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 227192, "time": 10991.658883333206, "episode/length": 252.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 227408, "time": 11000.82967042923, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 227792, "time": 11015.493910312653, "episode/length": 180.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 227976, "time": 11023.134815454483, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 228280, "time": 11034.963455915451, "episode/length": 246.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 228280, "time": 11034.973756790161, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 228304, "time": 11039.65196800232, "episode/length": 171.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 228400, "time": 11044.554148435593, "episode/length": 301.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 228624, "time": 11053.685480594635, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 228664, "time": 11056.421841621399, "episode/length": 32.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 228680, "time": 11058.626975536346, "episode/length": 158.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 229288, "time": 11080.845624446869, "episode/length": 163.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 229376, "time": 11085.856232881546, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 229568, "time": 11095.257017612457, "episode/length": 160.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 229840, "time": 11106.199085950851, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 11114.807552814484, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 11134.440740823746, "eval_episode/length": 138.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9568345323741008}
{"step": 230048, "time": 11137.396316289902, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9882352941176471}
{"step": 230048, "time": 11139.224360227585, "eval_episode/length": 173.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 230048, "time": 11141.217772960663, "eval_episode/length": 183.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 230048, "time": 11143.301797151566, "eval_episode/length": 196.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 230048, "time": 11145.157616615295, "eval_episode/length": 198.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 230048, "time": 11147.361097812653, "eval_episode/length": 213.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 230048, "time": 11149.891516208649, "eval_episode/length": 236.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9789029535864979}
{"step": 230208, "time": 11156.853795528412, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 230440, "time": 11166.317705392838, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 230920, "time": 11184.06288766861, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 231104, "time": 11192.41963839531, "episode/length": 111.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9553571428571429, "episode/intrinsic_return": 0.0}
{"step": 231192, "time": 11196.730087518692, "episode/length": 237.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 231232, "time": 11199.897217035294, "episode/length": 320.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 231248, "time": 11201.990411281586, "episode/length": 233.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 231312, "time": 11205.682533502579, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 231496, "time": 11213.14637875557, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 232232, "time": 11239.812337398529, "episode/length": 163.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 232400, "time": 11247.398036956787, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 232560, "time": 11254.646929264069, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 232608, "time": 11257.850907087326, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 233064, "time": 11274.762041807175, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 233120, "time": 11278.599012851715, "episode/length": 240.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.970954356846473, "episode/intrinsic_return": 0.0}
{"step": 233160, "time": 11281.41424703598, "episode/length": 339.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9911764705882353, "episode/intrinsic_return": 0.0}
{"step": 233600, "time": 11298.067007303238, "episode/length": 149.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 233808, "time": 11306.74206995964, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 234272, "time": 11324.169353485107, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 234304, "time": 11326.886677265167, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 234552, "time": 11336.792061805725, "episode/length": 185.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 234624, "time": 11341.080169916153, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 234625, "time": 11343.197217226028, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.261568686119596, "train/action_min": 0.0, "train/action_std": 2.7922770654348503, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04612547381872073, "train/actor_opt_grad_steps": 13900.0, "train/actor_opt_loss": -7.584705844297445, "train/adv_mag": 0.9213844371917552, "train/adv_max": 0.9104244668680922, "train/adv_mean": 0.0028539769421725473, "train/adv_min": -0.5773284415105232, "train/adv_std": 0.08163928271348316, "train/cont_avg": 0.9940818843984962, "train/cont_loss_mean": 0.0003818803416873725, "train/cont_loss_std": 0.010648307100097154, "train/cont_neg_acc": 0.9821577780228808, "train/cont_neg_loss": 0.035221384549886284, "train/cont_pos_acc": 0.9999260297395233, "train/cont_pos_loss": 0.00017921484056666786, "train/cont_pred": 0.9940854019688484, "train/cont_rate": 0.9940818843984962, "train/dyn_loss_mean": 12.204621809765808, "train/dyn_loss_std": 9.597802111977025, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9697426745766088, "train/extr_critic_critic_opt_grad_steps": 13900.0, "train/extr_critic_critic_opt_loss": 14530.357363134399, "train/extr_critic_mag": 3.8199215329679332, "train/extr_critic_max": 3.8199215329679332, "train/extr_critic_mean": 0.7193170481158379, "train/extr_critic_min": -0.3349937245361787, "train/extr_critic_std": 0.8202532462607649, "train/extr_return_normed_mag": 2.0623766309336613, "train/extr_return_normed_max": 2.0623766309336613, "train/extr_return_normed_mean": 0.34278925222561774, "train/extr_return_normed_min": -0.24578468462354258, "train/extr_return_normed_std": 0.35102487260237675, "train/extr_return_rate": 0.4257288965067469, "train/extr_return_raw_mag": 4.891125049806179, "train/extr_return_raw_max": 4.891125049806179, "train/extr_return_raw_mean": 0.7262165454545415, "train/extr_return_raw_min": -0.7002795159368587, "train/extr_return_raw_std": 0.8507309838345176, "train/extr_reward_mag": 1.004779302984252, "train/extr_reward_max": 1.004779302984252, "train/extr_reward_mean": 0.014943759881408144, "train/extr_reward_min": -0.5049062008248236, "train/extr_reward_std": 0.11288029694915715, "train/image_loss_mean": 9.822736345735708, "train/image_loss_std": 14.318673011951876, "train/model_loss_mean": 17.18969908692783, "train/model_loss_std": 18.53972972783827, "train/model_opt_grad_norm": 68.633849767814, "train/model_opt_grad_steps": 13883.699248120301, "train/model_opt_loss": 11001.396139273966, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 639.0977443609023, "train/policy_entropy_mag": 2.457999200749218, "train/policy_entropy_max": 2.457999200749218, "train/policy_entropy_mean": 0.654066717938373, "train/policy_entropy_min": 0.0793776829776011, "train/policy_entropy_std": 0.5469660449745064, "train/policy_logprob_mag": 7.4383651654523115, "train/policy_logprob_max": -0.009456307522224304, "train/policy_logprob_mean": -0.6529696225223685, "train/policy_logprob_min": -7.4383651654523115, "train/policy_logprob_std": 1.1454873855848957, "train/policy_randomness_mag": 0.8675658528069804, "train/policy_randomness_max": 0.8675658528069804, "train/policy_randomness_mean": 0.23085684738212958, "train/policy_randomness_min": 0.02801683868624662, "train/policy_randomness_std": 0.1930550121723261, "train/post_ent_mag": 53.2933301997364, "train/post_ent_max": 53.2933301997364, "train/post_ent_mean": 37.060263812990115, "train/post_ent_min": 20.727985754945223, "train/post_ent_std": 5.7263219087643735, "train/prior_ent_mag": 64.40234483991351, "train/prior_ent_max": 64.40234483991351, "train/prior_ent_mean": 49.33024425076363, "train/prior_ent_min": 26.29811319910494, "train/prior_ent_std": 7.460387710341833, "train/rep_loss_mean": 12.204621809765808, "train/rep_loss_std": 9.597802111977025, "train/reward_avg": 0.011322250833062637, "train/reward_loss_mean": 0.04380792695888899, "train/reward_loss_std": 0.2355319670492545, "train/reward_max_data": 1.0052631591495715, "train/reward_max_pred": 1.0013852728936905, "train/reward_neg_acc": 0.9944968317684374, "train/reward_neg_loss": 0.02830575951340055, "train/reward_pos_acc": 0.9439625619049359, "train/reward_pos_loss": 0.9632162823712915, "train/reward_pred": 0.010910169836798949, "train/reward_rate": 0.01653547932330827, "train_stats/sum_log_reward": 3.856097490625168, "train_stats/max_log_achievement_collect_drink": 6.7560975609756095, "train_stats/max_log_achievement_collect_sapling": 1.3089430894308942, "train_stats/max_log_achievement_collect_wood": 3.83739837398374, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.06504065040650407, "train_stats/max_log_achievement_eat_cow": 0.08943089430894309, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.016260162601626018, "train_stats/max_log_achievement_make_wood_sword": 0.008130081300813009, "train_stats/max_log_achievement_place_plant": 1.2113821138211383, "train_stats/max_log_achievement_place_table": 1.5609756097560976, "train_stats/max_log_achievement_wake_up": 2.105691056910569, "train_stats/mean_log_entropy": 0.6728136243858958, "eval_stats/sum_log_reward": 4.474999874830246, "eval_stats/max_log_achievement_collect_drink": 5.9375, "eval_stats/max_log_achievement_collect_sapling": 1.3125, "eval_stats/max_log_achievement_collect_wood": 4.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.1875, "eval_stats/max_log_achievement_place_table": 1.5625, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 4.681635618908331e-05, "report/cont_loss_std": 0.000712403270881623, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.005464928690344095, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.154058842686936e-06, "report/cont_pred": 0.9922258853912354, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 11.705574035644531, "report/dyn_loss_std": 9.144052505493164, "report/image_loss_mean": 7.640959739685059, "report/image_loss_std": 11.554523468017578, "report/model_loss_mean": 14.696666717529297, "report/model_loss_std": 15.370408058166504, "report/post_ent_mag": 58.90528106689453, "report/post_ent_max": 58.90528106689453, "report/post_ent_mean": 36.85032653808594, "report/post_ent_min": 20.57756805419922, "report/post_ent_std": 6.386132717132568, "report/prior_ent_mag": 65.70578002929688, "report/prior_ent_max": 65.70578002929688, "report/prior_ent_mean": 48.71148681640625, "report/prior_ent_min": 25.472206115722656, "report/prior_ent_std": 8.160902976989746, "report/rep_loss_mean": 11.705574035644531, "report/rep_loss_std": 9.144052505493164, "report/reward_avg": 0.01337890699505806, "report/reward_loss_mean": 0.032315611839294434, "report/reward_loss_std": 0.1444648802280426, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0027852058410645, "report/reward_neg_acc": 0.9980080127716064, "report/reward_neg_loss": 0.017096398398280144, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7963201403617859, "report/reward_pred": 0.011559929698705673, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.007058572489768267, "eval/cont_loss_std": 0.22501088678836823, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 3.6029648780822754, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.1574249331024475e-05, "eval/cont_pred": 0.9990034103393555, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 13.046173095703125, "eval/dyn_loss_std": 10.441792488098145, "eval/image_loss_mean": 21.349811553955078, "eval/image_loss_std": 34.177425384521484, "eval/model_loss_mean": 29.221752166748047, "eval/model_loss_std": 38.09280014038086, "eval/post_ent_mag": 53.293670654296875, "eval/post_ent_max": 53.293670654296875, "eval/post_ent_mean": 37.40969467163086, "eval/post_ent_min": 21.71963882446289, "eval/post_ent_std": 5.68136739730835, "eval/prior_ent_mag": 65.70578002929688, "eval/prior_ent_max": 65.70578002929688, "eval/prior_ent_mean": 47.182167053222656, "eval/prior_ent_min": 25.267900466918945, "eval/prior_ent_std": 7.567726135253906, "eval/rep_loss_mean": 13.046173095703125, "eval/rep_loss_std": 10.441792488098145, "eval/reward_avg": 0.00576171837747097, "eval/reward_loss_mean": 0.037179432809352875, "eval/reward_loss_std": 0.44850388169288635, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0009591579437256, "eval/reward_neg_acc": 0.9970443844795227, "eval/reward_neg_loss": 0.023764964193105698, "eval/reward_pos_acc": 0.8888888955116272, "eval/reward_pos_loss": 1.550033450126648, "eval/reward_pred": 0.004983460530638695, "eval/reward_rate": 0.0087890625, "replay/size": 234121.0, "replay/inserts": 21384.0, "replay/samples": 21376.0, "replay/insert_wait_avg": 1.4122153238281524e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.235262335417514e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44168.0, "eval_replay/inserts": 3592.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2499717933297954e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.38534283638, "timer/env.step_count": 2673.0, "timer/env.step_total": 275.38927936553955, "timer/env.step_frac": 0.2752832009560754, "timer/env.step_avg": 0.10302629231782251, "timer/env.step_min": 0.02413487434387207, "timer/env.step_max": 4.231319427490234, "timer/replay._sample_count": 21376.0, "timer/replay._sample_total": 12.113240003585815, "timer/replay._sample_frac": 0.012108574051316363, "timer/replay._sample_avg": 0.0005666747756168514, "timer/replay._sample_min": 0.00041604042053222656, "timer/replay._sample_max": 0.009477376937866211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3122.0, "timer/agent.policy_total": 54.48550224304199, "timer/agent.policy_frac": 0.05446451473245293, "timer/agent.policy_avg": 0.01745211474793145, "timer/agent.policy_min": 0.009786367416381836, "timer/agent.policy_max": 0.08994388580322266, "timer/dataset_train_count": 1336.0, "timer/dataset_train_total": 0.16792607307434082, "timer/dataset_train_frac": 0.00016786138889062703, "timer/dataset_train_avg": 0.000125693168468818, "timer/dataset_train_min": 0.00010895729064941406, "timer/dataset_train_max": 0.0010597705841064453, "timer/agent.train_count": 1336.0, "timer/agent.train_total": 603.5082647800446, "timer/agent.train_frac": 0.6032757967733965, "timer/agent.train_avg": 0.45172774309883573, "timer/agent.train_min": 0.43970370292663574, "timer/agent.train_max": 1.4457480907440186, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48272109031677246, "timer/agent.report_frac": 0.0004825351488538601, "timer/agent.report_avg": 0.24136054515838623, "timer/agent.report_min": 0.23552703857421875, "timer/agent.report_max": 0.2471940517425537, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.7670135498046875e-05, "timer/dataset_eval_frac": 3.7655625172637186e-08, "timer/dataset_eval_avg": 3.7670135498046875e-05, "timer/dataset_eval_min": 3.7670135498046875e-05, "timer/dataset_eval_max": 3.7670135498046875e-05, "fps": 21.375415421601083}
{"step": 234704, "time": 11346.173721790314, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 234760, "time": 11349.450459003448, "episode/length": 430.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 235176, "time": 11365.036098718643, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 235208, "time": 11367.807327985764, "episode/length": 55.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 235240, "time": 11370.587018966675, "episode/length": 120.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9669421487603306, "episode/intrinsic_return": 0.0}
{"step": 235584, "time": 11384.097897291183, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 235880, "time": 11395.53318309784, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 235896, "time": 11397.570437669754, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 236072, "time": 11405.250420093536, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 236264, "time": 11413.178662538528, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 236304, "time": 11416.417960882187, "episode/length": 140.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 236616, "time": 11428.399428129196, "episode/length": 128.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 236680, "time": 11432.26288485527, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 236712, "time": 11434.964888811111, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 236968, "time": 11445.215545415878, "episode/length": 133.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 237296, "time": 11458.225243330002, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 237424, "time": 11464.03295302391, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 237480, "time": 11467.204147100449, "episode/length": 146.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 237528, "time": 11470.435750246048, "episode/length": 105.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9433962264150944, "episode/intrinsic_return": 0.0}
{"step": 237600, "time": 11476.683977842331, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 237824, "time": 11486.44866490364, "episode/length": 150.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 238192, "time": 11500.619615316391, "episode/length": 264.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 238480, "time": 11511.957406282425, "episode/length": 109.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 238512, "time": 11514.755209207535, "episode/length": 224.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 238544, "time": 11517.450037240982, "episode/length": 155.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 238560, "time": 11519.853016853333, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 238896, "time": 11532.82174873352, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 239080, "time": 11540.367213726044, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 239112, "time": 11543.074247598648, "episode/length": 203.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 239744, "time": 11566.776971817017, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 239936, "time": 11574.853503465652, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 240024, "time": 11579.32710647583, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 11601.658597707748, "eval_episode/length": 158.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 240032, "time": 11603.473010063171, "eval_episode/length": 164.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 240032, "time": 11606.274720907211, "eval_episode/length": 191.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9635416666666666}
{"step": 240032, "time": 11608.76441693306, "eval_episode/length": 205.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 240032, "time": 11610.468176841736, "eval_episode/length": 209.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 240032, "time": 11612.23610830307, "eval_episode/length": 211.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 240032, "time": 11615.281131029129, "eval_episode/length": 242.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9794238683127572}
{"step": 240032, "time": 11618.605412244797, "eval_episode/length": 282.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9964664310954063}
{"step": 240088, "time": 11620.2720785141, "episode/length": 236.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 240320, "time": 11629.907990694046, "episode/length": 229.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 240472, "time": 11636.370116710663, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 240520, "time": 11639.786747932434, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 240824, "time": 11651.659568786621, "episode/length": 213.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 241096, "time": 11662.48439860344, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 241328, "time": 11672.303531646729, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 241400, "time": 11676.185435295105, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 241696, "time": 11688.118036985397, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 241800, "time": 11693.2256128788, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 241840, "time": 11696.294444561005, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 242336, "time": 11714.802125930786, "episode/length": 188.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 242512, "time": 11722.33922123909, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 242640, "time": 11728.36817574501, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 242832, "time": 11736.39215683937, "episode/length": 288.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 242880, "time": 11739.65192604065, "episode/length": 134.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 242992, "time": 11745.054257631302, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 243120, "time": 11751.061491966248, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 243296, "time": 11758.747725248337, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 243824, "time": 11778.211736440659, "episode/length": 147.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 244016, "time": 11786.303748846054, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 244048, "time": 11789.139557600021, "episode/length": 213.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.985981308411215, "episode/intrinsic_return": 0.0}
{"step": 244136, "time": 11793.40336561203, "episode/length": 202.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 244248, "time": 11798.81642627716, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 244304, "time": 11802.99484205246, "episode/length": 183.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 244336, "time": 11805.725483179092, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 244960, "time": 11828.41049695015, "episode/length": 88.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 245000, "time": 11831.132147789001, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 245048, "time": 11834.31282901764, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 245352, "time": 11846.13312959671, "episode/length": 166.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 245432, "time": 11850.570781469345, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 245720, "time": 11861.98874258995, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 245888, "time": 11870.841444015503, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 246040, "time": 11877.38759970665, "episode/length": 85.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 246168, "time": 11883.390314340591, "episode/length": 264.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 246216, "time": 11886.514061927795, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 246272, "time": 11890.21108698845, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 246352, "time": 11894.458810567856, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 246472, "time": 11899.855150222778, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 247368, "time": 11931.739844560623, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 247544, "time": 11939.316560268402, "episode/length": 263.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 247584, "time": 11942.517201662064, "episode/length": 163.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 247632, "time": 11945.796259880066, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 247648, "time": 11948.035765886307, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 247752, "time": 11952.912140130997, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 247984, "time": 11962.5819272995, "episode/length": 49.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 248296, "time": 11974.512615680695, "episode/length": 321.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9968944099378882, "episode/intrinsic_return": 0.0}
{"step": 248464, "time": 11981.879009246826, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 248672, "time": 11990.637195110321, "episode/length": 140.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 248776, "time": 11995.59415435791, "episode/length": 142.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 249016, "time": 12005.435941934586, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 249016, "time": 12005.445472717285, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 249040, "time": 12009.757571220398, "episode/length": 32.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8787878787878788, "episode/intrinsic_return": 0.0}
{"step": 249080, "time": 12012.488819360733, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 249488, "time": 12028.228332281113, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 249824, "time": 12042.016778945923, "episode/length": 190.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 249864, "time": 12044.704232931137, "episode/length": 148.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 249976, "time": 12049.943097114563, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 12068.182636499405, "eval_episode/length": 33.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 250016, "time": 12074.805233240128, "eval_episode/length": 148.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 250016, "time": 12076.424193143845, "eval_episode/length": 149.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 250016, "time": 12079.571098566055, "eval_episode/length": 184.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 250016, "time": 12079.594452857971, "eval_episode/length": 35.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 250016, "time": 12083.091737985611, "eval_episode/length": 151.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.993421052631579}
{"step": 250016, "time": 12084.932198762894, "eval_episode/length": 188.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 250016, "time": 12087.13508105278, "eval_episode/length": 202.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 250160, "time": 12092.142794370651, "episode/length": 41.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 250168, "time": 12093.772373914719, "episode/length": 37.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 250384, "time": 12103.00199842453, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 250448, "time": 12106.77899312973, "episode/length": 178.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 250512, "time": 12110.512564897537, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 250688, "time": 12118.133773565292, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 251256, "time": 12138.729975223541, "episode/length": 135.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 251304, "time": 12141.969348192215, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 251584, "time": 12153.348281621933, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 251696, "time": 12158.685825109482, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 251944, "time": 12168.395110368729, "episode/length": 156.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 252016, "time": 12172.621345043182, "episode/length": 195.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 252264, "time": 12182.518399000168, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 252608, "time": 12195.880630731583, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 252688, "time": 12200.073375701904, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 252920, "time": 12209.462697505951, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 253136, "time": 12218.68821144104, "episode/length": 148.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 253240, "time": 12223.593091011047, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 253464, "time": 12232.696842432022, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 253584, "time": 12238.68800997734, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 253624, "time": 12241.34711766243, "episode/length": 455.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 253928, "time": 12253.115691900253, "episode/length": 238.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 254368, "time": 12271.068857192993, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.950354609929078, "episode/intrinsic_return": 0.0}
{"step": 254520, "time": 12277.487823486328, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 254656, "time": 12283.817715644836, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 254800, "time": 12290.255205869675, "episode/length": 151.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 254888, "time": 12294.588908433914, "episode/length": 157.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 254920, "time": 12297.351814985275, "episode/length": 32.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 255032, "time": 12302.855502128601, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 255312, "time": 12314.244016647339, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 255368, "time": 12317.471180438995, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 255744, "time": 12332.035122156143, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 255928, "time": 12339.584842681885, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 255961, "time": 12343.308943271637, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.219101179891558, "train/action_min": 0.0, "train/action_std": 3.081529362877803, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04717354943503195, "train/actor_opt_grad_steps": 15235.0, "train/actor_opt_loss": -7.669476520325711, "train/adv_mag": 0.9276306629180908, "train/adv_max": 0.9224146662363365, "train/adv_mean": 0.00293313456573579, "train/adv_min": -0.5350079029353697, "train/adv_std": 0.08299720134419292, "train/cont_avg": 0.9942135027985075, "train/cont_loss_mean": 0.00033139975655957125, "train/cont_loss_std": 0.009644221144217634, "train/cont_neg_acc": 0.9871769418467337, "train/cont_neg_loss": 0.028145278863196857, "train/cont_pos_acc": 0.9999193598085375, "train/cont_pos_loss": 0.00016107102074985975, "train/cont_pred": 0.9942174825205732, "train/cont_rate": 0.9942135027985075, "train/dyn_loss_mean": 12.663900802384562, "train/dyn_loss_std": 9.749483450135187, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.927009854298919, "train/extr_critic_critic_opt_grad_steps": 15235.0, "train/extr_critic_critic_opt_loss": 14707.281009503266, "train/extr_critic_mag": 3.7224825620651245, "train/extr_critic_max": 3.7224825620651245, "train/extr_critic_mean": 0.6529089490424341, "train/extr_critic_min": -0.36916729407523996, "train/extr_critic_std": 0.8207432512027114, "train/extr_return_normed_mag": 2.0116752332715846, "train/extr_return_normed_max": 2.0116752332715846, "train/extr_return_normed_mean": 0.3435834766323887, "train/extr_return_normed_min": -0.23909458400570413, "train/extr_return_normed_std": 0.3537064846327056, "train/extr_return_rate": 0.3979540981018721, "train/extr_return_raw_mag": 4.677376503375039, "train/extr_return_raw_max": 4.677376503375039, "train/extr_return_raw_mean": 0.6599683639273715, "train/extr_return_raw_min": -0.7433143160236415, "train/extr_return_raw_std": 0.8518415609402443, "train/extr_reward_mag": 1.0040219025825388, "train/extr_reward_max": 1.0040219025825388, "train/extr_reward_mean": 0.015441985818237733, "train/extr_reward_min": -0.5029960924120092, "train/extr_reward_std": 0.11562921885234206, "train/image_loss_mean": 9.596656560897827, "train/image_loss_std": 14.226342261727176, "train/model_loss_mean": 17.239405696071795, "train/model_loss_std": 18.48255939625982, "train/model_opt_grad_norm": 66.95524908891365, "train/model_opt_grad_steps": 15217.84328358209, "train/model_opt_loss": 15063.129769851912, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 872.2014925373135, "train/policy_entropy_mag": 2.4338784395758783, "train/policy_entropy_max": 2.4338784395758783, "train/policy_entropy_mean": 0.717095334583254, "train/policy_entropy_min": 0.07937692995391675, "train/policy_entropy_std": 0.6184375681983891, "train/policy_logprob_mag": 7.438372273943317, "train/policy_logprob_max": -0.009456114002517354, "train/policy_logprob_mean": -0.7162055368743726, "train/policy_logprob_min": -7.438372273943317, "train/policy_logprob_std": 1.1772584986330858, "train/policy_randomness_mag": 0.8590522813263224, "train/policy_randomness_max": 0.8590522813263224, "train/policy_randomness_mean": 0.25310318461105, "train/policy_randomness_min": 0.028016572859861068, "train/policy_randomness_std": 0.21828132189476668, "train/post_ent_mag": 54.38912551082782, "train/post_ent_max": 54.38912551082782, "train/post_ent_mean": 37.49599516569678, "train/post_ent_min": 20.831887202476388, "train/post_ent_std": 5.778392660084055, "train/prior_ent_mag": 64.96486279501843, "train/prior_ent_max": 64.96486279501843, "train/prior_ent_mean": 50.26734010497136, "train/prior_ent_min": 27.917337460304374, "train/prior_ent_std": 7.1908750213793855, "train/rep_loss_mean": 12.663900802384562, "train/rep_loss_std": 9.749483450135187, "train/reward_avg": 0.01299046746580236, "train/reward_loss_mean": 0.044077193169896285, "train/reward_loss_std": 0.23295870100829139, "train/reward_max_data": 1.0067164195117666, "train/reward_max_pred": 1.0020837579200517, "train/reward_neg_acc": 0.9944237524004125, "train/reward_neg_loss": 0.027614534401626728, "train/reward_pos_acc": 0.9539509891574063, "train/reward_pos_loss": 0.9391508960901801, "train/reward_pred": 0.012631251877208533, "train/reward_rate": 0.018139284048507464, "train_stats/sum_log_reward": 4.238211318426501, "train_stats/max_log_achievement_collect_drink": 7.219512195121951, "train_stats/max_log_achievement_collect_sapling": 1.8455284552845528, "train_stats/max_log_achievement_collect_wood": 4.08130081300813, "train_stats/max_log_achievement_defeat_skeleton": 0.024390243902439025, "train_stats/max_log_achievement_defeat_zombie": 0.08130081300813008, "train_stats/max_log_achievement_eat_cow": 0.0975609756097561, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.016260162601626018, "train_stats/max_log_achievement_make_wood_sword": 0.016260162601626018, "train_stats/max_log_achievement_place_plant": 1.7317073170731707, "train_stats/max_log_achievement_place_table": 1.5528455284552845, "train_stats/max_log_achievement_wake_up": 1.943089430894309, "train_stats/mean_log_entropy": 0.6729172298578712, "eval_stats/sum_log_reward": 3.9749999344348907, "eval_stats/max_log_achievement_collect_drink": 8.25, "eval_stats/max_log_achievement_collect_sapling": 1.4375, "eval_stats/max_log_achievement_collect_wood": 2.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_table": 1.0625, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 3.158223762511625e-06, "report/cont_loss_std": 7.476149767171592e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0010711075738072395, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.0273008161098005e-08, "report/cont_pred": 0.9970734119415283, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.192556381225586, "report/dyn_loss_std": 10.893895149230957, "report/image_loss_mean": 10.075156211853027, "report/image_loss_std": 15.574182510375977, "report/model_loss_mean": 18.02130126953125, "report/model_loss_std": 20.344446182250977, "report/post_ent_mag": 51.743141174316406, "report/post_ent_max": 51.743141174316406, "report/post_ent_mean": 37.27709197998047, "report/post_ent_min": 22.59792709350586, "report/post_ent_std": 5.31852388381958, "report/prior_ent_mag": 65.66596984863281, "report/prior_ent_max": 65.66596984863281, "report/prior_ent_mean": 50.29619216918945, "report/prior_ent_min": 29.56375503540039, "report/prior_ent_std": 7.3546600341796875, "report/rep_loss_mean": 13.192556381225586, "report/rep_loss_std": 10.893895149230957, "report/reward_avg": 0.0146484375, "report/reward_loss_mean": 0.03060811385512352, "report/reward_loss_std": 0.20575033128261566, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001051664352417, "report/reward_neg_acc": 0.9860973358154297, "report/reward_neg_loss": 0.014442775398492813, "report/reward_pos_acc": 0.9411764740943909, "report/reward_pos_loss": 0.9881666898727417, "report/reward_pred": 0.016087204217910767, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.464280325715663e-06, "eval/cont_loss_std": 7.285211904672906e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0007057776674628258, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.0898899038002128e-06, "eval/cont_pred": 0.9980461597442627, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 11.227834701538086, "eval/dyn_loss_std": 9.616737365722656, "eval/image_loss_mean": 13.294811248779297, "eval/image_loss_std": 25.23896026611328, "eval/model_loss_mean": 20.0694580078125, "eval/model_loss_std": 28.874317169189453, "eval/post_ent_mag": 58.27993392944336, "eval/post_ent_max": 58.27993392944336, "eval/post_ent_mean": 38.433170318603516, "eval/post_ent_min": 21.686676025390625, "eval/post_ent_std": 6.248765468597412, "eval/prior_ent_mag": 65.31494140625, "eval/prior_ent_max": 65.31494140625, "eval/prior_ent_mean": 47.644287109375, "eval/prior_ent_min": 27.27718734741211, "eval/prior_ent_std": 6.584289073944092, "eval/rep_loss_mean": 11.227834701538086, "eval/rep_loss_std": 9.616737365722656, "eval/reward_avg": 0.008984374813735485, "eval/reward_loss_mean": 0.037941526621580124, "eval/reward_loss_std": 0.4044867753982544, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9988632202148438, "eval/reward_neg_acc": 0.9960513710975647, "eval/reward_neg_loss": 0.014991172589361668, "eval/reward_pos_acc": 0.8181818723678589, "eval/reward_pos_loss": 2.151460647583008, "eval/reward_pred": 0.008384408429265022, "eval/reward_rate": 0.0107421875, "replay/size": 255457.0, "replay/inserts": 21336.0, "replay/samples": 21344.0, "replay/insert_wait_avg": 1.4238291391058723e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.259384968827689e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 48056.0, "eval_replay/inserts": 3888.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2824810090869543e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0934731960297, "timer/env.step_count": 2667.0, "timer/env.step_total": 273.09630370140076, "timer/env.step_frac": 0.2730707789029544, "timer/env.step_avg": 0.10239831409876293, "timer/env.step_min": 0.02416205406188965, "timer/env.step_max": 3.307521343231201, "timer/replay._sample_count": 21344.0, "timer/replay._sample_total": 11.801033020019531, "timer/replay._sample_frac": 0.0117999300428455, "timer/replay._sample_avg": 0.0005528969743262524, "timer/replay._sample_min": 0.0004286766052246094, "timer/replay._sample_max": 0.010719060897827148, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3153.0, "timer/agent.policy_total": 54.86314606666565, "timer/agent.policy_frac": 0.05485801831236614, "timer/agent.policy_avg": 0.017400300052859387, "timer/agent.policy_min": 0.009868144989013672, "timer/agent.policy_max": 0.10340046882629395, "timer/dataset_train_count": 1334.0, "timer/dataset_train_total": 0.1659228801727295, "timer/dataset_train_frac": 0.00016590737228039756, "timer/dataset_train_avg": 0.00012437997014447488, "timer/dataset_train_min": 0.0001068115234375, "timer/dataset_train_max": 0.00048732757568359375, "timer/agent.train_count": 1334.0, "timer/agent.train_total": 603.7776567935944, "timer/agent.train_frac": 0.6037212250411789, "timer/agent.train_avg": 0.45260693912563293, "timer/agent.train_min": 0.434969425201416, "timer/agent.train_max": 1.527207851409912, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4687016010284424, "timer/agent.report_frac": 0.0004686577940865849, "timer/agent.report_avg": 0.2343508005142212, "timer/agent.report_min": 0.22475838661193848, "timer/agent.report_max": 0.2439432144165039, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0037933225176194e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 21.33370252575191}
{"step": 256152, "time": 12349.60288143158, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 256208, "time": 12353.39868402481, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 256400, "time": 12361.61152100563, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 256552, "time": 12368.139102697372, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 256656, "time": 12373.33715415001, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 256848, "time": 12381.3824903965, "episode/length": 191.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 257080, "time": 12390.67780637741, "episode/length": 143.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 257192, "time": 12395.978889226913, "episode/length": 42.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 257320, "time": 12401.80421257019, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 257464, "time": 12408.252110004425, "episode/length": 100.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 257560, "time": 12413.170113325119, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 257792, "time": 12423.361855506897, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 257952, "time": 12430.368396520615, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 258016, "time": 12434.1124958992, "episode/length": 182.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 258432, "time": 12449.983000278473, "episode/length": 138.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 258568, "time": 12455.948159217834, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 258720, "time": 12462.810259580612, "episode/length": 35.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 258744, "time": 12464.958005905151, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 258816, "time": 12469.199500083923, "episode/length": 156.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 258904, "time": 12473.657949924469, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 259096, "time": 12481.829271316528, "episode/length": 34.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 259104, "time": 12483.949966430664, "episode/length": 44.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 259232, "time": 12489.898467302322, "episode/length": 40.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 259248, "time": 12492.08800983429, "episode/length": 153.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 259696, "time": 12508.990206003189, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 12543.686252117157, "eval_episode/length": 167.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 260000, "time": 12543.695538043976, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 260000, "time": 12547.791158676147, "eval_episode/length": 178.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 260000, "time": 12549.455198049545, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9611111111111111}
{"step": 260000, "time": 12551.54288315773, "eval_episode/length": 191.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 260000, "time": 12553.713863134384, "eval_episode/length": 201.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 260000, "time": 12556.298905849457, "eval_episode/length": 222.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 260000, "time": 12561.255681753159, "eval_episode/length": 132.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9924812030075187}
{"step": 260112, "time": 12565.059106349945, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 260184, "time": 12568.83479809761, "episode/length": 134.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 260488, "time": 12580.656581640244, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 260528, "time": 12583.81587100029, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 260568, "time": 12586.560444116592, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 260680, "time": 12591.943650960922, "episode/length": 244.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 261016, "time": 12605.039278507233, "episode/length": 103.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 261160, "time": 12611.449674129486, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 261232, "time": 12615.696772575378, "episode/length": 139.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 261520, "time": 12626.966877698898, "episode/length": 445.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798206278026906, "episode/intrinsic_return": 0.0}
{"step": 261552, "time": 12629.912183046341, "episode/length": 39.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 261880, "time": 12642.313870191574, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 262040, "time": 12649.463752985, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 262176, "time": 12657.266032934189, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 262192, "time": 12660.117667198181, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 262624, "time": 12676.383383512497, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 262744, "time": 12681.89093542099, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 262864, "time": 12687.85787820816, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 263072, "time": 12696.455821275711, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 263160, "time": 12700.828729629517, "episode/length": 36.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 263256, "time": 12705.757731437683, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 263416, "time": 12712.77408337593, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 263440, "time": 12715.386857509613, "episode/length": 155.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 263616, "time": 12723.095736980438, "episode/length": 216.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 263680, "time": 12726.95105934143, "episode/length": 131.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 264184, "time": 12745.434057235718, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 264296, "time": 12750.950948476791, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 264504, "time": 12759.389560461044, "episode/length": 155.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 264648, "time": 12765.802385091782, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 264656, "time": 12767.870880842209, "episode/length": 129.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9538461538461539, "episode/intrinsic_return": 0.0}
{"step": 265136, "time": 12785.807306528091, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 265248, "time": 12791.328471899033, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 265416, "time": 12798.383321762085, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 265432, "time": 12800.53322839737, "episode/length": 248.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 265712, "time": 12811.923681497574, "episode/length": 36.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 265896, "time": 12819.508675575256, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 265952, "time": 12823.172083377838, "episode/length": 180.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 266104, "time": 12829.742160320282, "episode/length": 180.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 266200, "time": 12834.51780962944, "episode/length": 132.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 266232, "time": 12837.306090593338, "episode/length": 197.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 266760, "time": 12856.916126728058, "episode/length": 188.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 266792, "time": 12859.551884651184, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 267360, "time": 12880.62906050682, "episode/length": 175.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 267360, "time": 12880.648205518723, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 267576, "time": 12891.049169540405, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 267592, "time": 12893.147748470306, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 267736, "time": 12899.776151895523, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 268016, "time": 12911.041660547256, "episode/length": 152.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 268024, "time": 12912.6805934906, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 268320, "time": 12924.582436084747, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 268712, "time": 12939.251045703888, "episode/length": 168.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 268712, "time": 12939.26074719429, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 268728, "time": 12943.186967372894, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 268848, "time": 12949.076606035233, "episode/length": 16.0, "episode/score": -0.8999999761581421, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 269080, "time": 12958.521404266357, "episode/length": 167.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 269272, "time": 12966.573672056198, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 269384, "time": 12971.932872533798, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 269400, "time": 12974.231408596039, "episode/length": 171.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 269648, "time": 12984.47472500801, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 269920, "time": 12995.427593231201, "episode/length": 150.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 13023.164625644684, "eval_episode/length": 140.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 270088, "time": 13025.072527885437, "eval_episode/length": 143.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 270088, "time": 13028.085483551025, "eval_episode/length": 172.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 270088, "time": 13029.93878865242, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 270088, "time": 13029.946443080902, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 270088, "time": 13034.31878566742, "eval_episode/length": 196.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 270088, "time": 13036.82643032074, "eval_episode/length": 218.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 270088, "time": 13038.540830135345, "eval_episode/length": 224.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9822222222222222}
{"step": 270216, "time": 13042.88343667984, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 270384, "time": 13051.858486652374, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 270584, "time": 13059.977546453476, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 270592, "time": 13062.026666402817, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 270728, "time": 13067.942281961441, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 270848, "time": 13074.16226053238, "episode/length": 220.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 270976, "time": 13080.203147172928, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 271136, "time": 13087.184995889664, "episode/length": 35.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 271264, "time": 13093.034848213196, "episode/length": 35.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 271288, "time": 13095.19018816948, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 271544, "time": 13105.370723724365, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 271720, "time": 13113.028674602509, "episode/length": 141.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 271776, "time": 13116.684278964996, "episode/length": 130.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 271896, "time": 13122.044153928757, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 272360, "time": 13139.316772937775, "episode/length": 246.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 272384, "time": 13142.001606702805, "episode/length": 155.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 272552, "time": 13149.08263206482, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 272744, "time": 13157.218962192535, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 273072, "time": 13170.332791566849, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 273080, "time": 13171.990640163422, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 273240, "time": 13179.063848495483, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 273512, "time": 13189.892535924911, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 273568, "time": 13193.646450042725, "episode/length": 208.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 273920, "time": 13207.233711004257, "episode/length": 267.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 273992, "time": 13210.959754943848, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 274000, "time": 13212.985315799713, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 274264, "time": 13223.2241127491, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 274496, "time": 13233.00796866417, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 274576, "time": 13237.264604568481, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 274880, "time": 13249.19840836525, "episode/length": 163.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 275112, "time": 13258.478188037872, "episode/length": 199.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 275400, "time": 13269.719123601913, "episode/length": 174.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 275936, "time": 13289.636305570602, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 276048, "time": 13295.039932250977, "episode/length": 265.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 276048, "time": 13295.049358129501, "episode/length": 256.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 276248, "time": 13304.906435728073, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 276384, "time": 13311.35019159317, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 276424, "time": 13314.06549692154, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 276672, "time": 13324.408663749695, "episode/length": 158.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 277169, "time": 13343.32812333107, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.444558345910274, "train/action_min": 0.0, "train/action_std": 3.467213413932107, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04945940772692362, "train/actor_opt_grad_steps": 16565.0, "train/actor_opt_loss": -5.278435207226059, "train/adv_mag": 0.8655823645266619, "train/adv_max": 0.8619658933444456, "train/adv_mean": 0.0039067609562731705, "train/adv_min": -0.529111241526676, "train/adv_std": 0.08504344737439444, "train/cont_avg": 0.9941036339962122, "train/cont_loss_mean": 0.00028779610802991004, "train/cont_loss_std": 0.007969996457397384, "train/cont_neg_acc": 0.9917333103318251, "train/cont_neg_loss": 0.024000274666027055, "train/cont_pos_acc": 0.9999478892846541, "train/cont_pos_loss": 0.0001392171977707152, "train/cont_pred": 0.9940978988553538, "train/cont_rate": 0.9941036339962122, "train/dyn_loss_mean": 13.092368718349572, "train/dyn_loss_std": 9.847513668464892, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9307760198911031, "train/extr_critic_critic_opt_grad_steps": 16565.0, "train/extr_critic_critic_opt_loss": 15063.023452296402, "train/extr_critic_mag": 3.7128707712346856, "train/extr_critic_max": 3.7128707712346856, "train/extr_critic_mean": 0.6215179698033766, "train/extr_critic_min": -0.36943206461993133, "train/extr_critic_std": 0.8500493250109933, "train/extr_return_normed_mag": 2.045206805973342, "train/extr_return_normed_max": 2.045206805973342, "train/extr_return_normed_mean": 0.3219175984462102, "train/extr_return_normed_min": -0.20998094445376686, "train/extr_return_normed_std": 0.3531608163858905, "train/extr_return_rate": 0.3732126141813668, "train/extr_return_raw_mag": 4.951890096519932, "train/extr_return_raw_max": 4.951890096519932, "train/extr_return_raw_mean": 0.6313267512754961, "train/extr_return_raw_min": -0.701650493072741, "train/extr_return_raw_std": 0.88542202250524, "train/extr_reward_mag": 1.005246995976477, "train/extr_reward_max": 1.005246995976477, "train/extr_reward_mean": 0.016751922208420707, "train/extr_reward_min": -0.45676090410261444, "train/extr_reward_std": 0.12127446117952015, "train/image_loss_mean": 9.237378680344785, "train/image_loss_std": 13.43181932333744, "train/model_loss_mean": 17.13717537215262, "train/model_loss_std": 17.75143556883841, "train/model_opt_grad_norm": 63.505812240369394, "train/model_opt_grad_steps": 16547.0, "train/model_opt_loss": 14893.906116832386, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 875.9469696969697, "train/policy_entropy_mag": 2.480936910166885, "train/policy_entropy_max": 2.480936910166885, "train/policy_entropy_mean": 0.7153696982246457, "train/policy_entropy_min": 0.07937648457785447, "train/policy_entropy_std": 0.6559353001189955, "train/policy_logprob_mag": 7.438375588619348, "train/policy_logprob_max": -0.009456003797381665, "train/policy_logprob_mean": -0.7146163284778595, "train/policy_logprob_min": -7.438375588619348, "train/policy_logprob_std": 1.1739884362076267, "train/policy_randomness_mag": 0.8756618562972907, "train/policy_randomness_max": 0.8756618562972907, "train/policy_randomness_mean": 0.2524941135762316, "train/policy_randomness_min": 0.02801641577741865, "train/policy_randomness_std": 0.23151637681505896, "train/post_ent_mag": 55.17127753749038, "train/post_ent_max": 55.17127753749038, "train/post_ent_mean": 37.98345808549361, "train/post_ent_min": 20.89133661443537, "train/post_ent_std": 6.021708539037993, "train/prior_ent_mag": 65.39423139167555, "train/prior_ent_max": 65.39423139167555, "train/prior_ent_mean": 51.19211873141202, "train/prior_ent_min": 29.35439044778997, "train/prior_ent_std": 6.871305104457971, "train/rep_loss_mean": 13.092368718349572, "train/rep_loss_std": 9.847513668464892, "train/reward_avg": 0.013076319747293988, "train/reward_loss_mean": 0.04408780153784336, "train/reward_loss_std": 0.23548546693090236, "train/reward_max_data": 1.0045454556291753, "train/reward_max_pred": 1.0018953545527025, "train/reward_neg_acc": 0.9947098565824104, "train/reward_neg_loss": 0.027294764471607225, "train/reward_pos_acc": 0.9490661295977506, "train/reward_pos_loss": 0.9592045170791221, "train/reward_pred": 0.012583610914809855, "train/reward_rate": 0.018214370265151516, "train_stats/sum_log_reward": 4.229032194662478, "train_stats/max_log_achievement_collect_drink": 5.862903225806452, "train_stats/max_log_achievement_collect_sapling": 1.9919354838709677, "train_stats/max_log_achievement_collect_wood": 4.887096774193548, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.12096774193548387, "train_stats/max_log_achievement_eat_cow": 0.056451612903225805, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.016129032258064516, "train_stats/max_log_achievement_place_plant": 1.7661290322580645, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 1.717741935483871, "train_stats/mean_log_entropy": 0.6322435032456152, "eval_stats/sum_log_reward": 4.412499934434891, "eval_stats/max_log_achievement_collect_drink": 5.3125, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_wood": 4.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_table": 1.8125, "eval_stats/max_log_achievement_wake_up": 2.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.133808735990897e-05, "report/cont_loss_std": 0.0016161106759682298, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00015360749966930598, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.083627183921635e-05, "report/cont_pred": 0.9950686693191528, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.674084663391113, "report/dyn_loss_std": 9.974699020385742, "report/image_loss_mean": 9.587657928466797, "report/image_loss_std": 13.941350936889648, "report/model_loss_mean": 18.431394577026367, "report/model_loss_std": 18.180728912353516, "report/post_ent_mag": 54.346309661865234, "report/post_ent_max": 54.346309661865234, "report/post_ent_mean": 36.97417449951172, "report/post_ent_min": 20.91686248779297, "report/post_ent_std": 5.523338794708252, "report/prior_ent_mag": 65.3421630859375, "report/prior_ent_max": 65.3421630859375, "report/prior_ent_mean": 51.90869903564453, "report/prior_ent_min": 31.378768920898438, "report/prior_ent_std": 6.397963047027588, "report/rep_loss_mean": 14.674084663391113, "report/rep_loss_std": 9.974699020385742, "report/reward_avg": 0.02001953125, "report/reward_loss_mean": 0.039232928305864334, "report/reward_loss_std": 0.19351379573345184, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001720905303955, "report/reward_neg_acc": 0.9989989995956421, "report/reward_neg_loss": 0.018878057599067688, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.8526136875152588, "report/reward_pred": 0.017966071143746376, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.5123879393286188e-06, "eval/cont_loss_std": 3.3656080631772056e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00037831952795386314, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.4713004026798444e-08, "eval/cont_pred": 0.9960952401161194, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 12.212957382202148, "eval/dyn_loss_std": 10.329090118408203, "eval/image_loss_mean": 10.818869590759277, "eval/image_loss_std": 20.6081485748291, "eval/model_loss_mean": 18.183486938476562, "eval/model_loss_std": 24.699459075927734, "eval/post_ent_mag": 58.119049072265625, "eval/post_ent_max": 58.119049072265625, "eval/post_ent_mean": 38.45136642456055, "eval/post_ent_min": 20.54709243774414, "eval/post_ent_std": 5.8457350730896, "eval/prior_ent_mag": 65.93760681152344, "eval/prior_ent_max": 65.93760681152344, "eval/prior_ent_mean": 48.531410217285156, "eval/prior_ent_min": 29.837810516357422, "eval/prior_ent_std": 6.625593185424805, "eval/rep_loss_mean": 12.212957382202148, "eval/rep_loss_std": 10.329090118408203, "eval/reward_avg": 0.01162109337747097, "eval/reward_loss_mean": 0.036841340363025665, "eval/reward_loss_std": 0.20476363599300385, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002075433731079, "eval/reward_neg_acc": 0.9950397610664368, "eval/reward_neg_loss": 0.020651239901781082, "eval/reward_pos_acc": 1.0, "eval/reward_pos_loss": 1.0568175315856934, "eval/reward_pred": 0.01067774835973978, "eval/reward_rate": 0.015625, "replay/size": 276665.0, "replay/inserts": 21208.0, "replay/samples": 21200.0, "replay/insert_wait_avg": 3.2593915256541976e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.27234595676638e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 52264.0, "eval_replay/inserts": 4208.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2981574344997624e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.007374048233, "timer/env.step_count": 2651.0, "timer/env.step_total": 273.7906606197357, "timer/env.step_frac": 0.27378864168908623, "timer/env.step_avg": 0.10327825749518511, "timer/env.step_min": 0.02413153648376465, "timer/env.step_max": 3.4128448963165283, "timer/replay._sample_count": 21200.0, "timer/replay._sample_total": 11.854727506637573, "timer/replay._sample_frac": 0.011854640089949764, "timer/replay._sample_avg": 0.0005591852597470554, "timer/replay._sample_min": 0.00042438507080078125, "timer/replay._sample_max": 0.025116920471191406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3177.0, "timer/agent.policy_total": 56.73091959953308, "timer/agent.policy_frac": 0.05673050126608046, "timer/agent.policy_avg": 0.017856757821697537, "timer/agent.policy_min": 0.009694099426269531, "timer/agent.policy_max": 0.12897610664367676, "timer/dataset_train_count": 1325.0, "timer/dataset_train_total": 0.16244149208068848, "timer/dataset_train_frac": 0.00016244029423812377, "timer/dataset_train_avg": 0.00012259735251372714, "timer/dataset_train_min": 0.0001049041748046875, "timer/dataset_train_max": 0.00031256675720214844, "timer/agent.train_count": 1325.0, "timer/agent.train_total": 598.3576097488403, "timer/agent.train_frac": 0.5983531974635018, "timer/agent.train_avg": 0.4515906488670493, "timer/agent.train_min": 0.437960147857666, "timer/agent.train_max": 1.4433295726776123, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4806351661682129, "timer/agent.report_frac": 0.00048063162196745017, "timer/agent.report_avg": 0.24031758308410645, "timer/agent.report_min": 0.23067092895507812, "timer/agent.report_max": 0.24996423721313477, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.07557699095708e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 21.207532436623698}
{"step": 277264, "time": 13346.879974126816, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 277264, "time": 13346.889279127121, "episode/length": 151.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 277320, "time": 13352.286992311478, "episode/length": 381.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9921465968586387, "episode/intrinsic_return": 0.0}
{"step": 277384, "time": 13356.155997037888, "episode/length": 180.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 277568, "time": 13364.196989536285, "episode/length": 37.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 277704, "time": 13370.308620214462, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 277936, "time": 13380.067359685898, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 278120, "time": 13387.657342910767, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 278304, "time": 13395.605921030045, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 278584, "time": 13407.917437076569, "episode/length": 34.0, "episode/score": -0.9000000059604645, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 278648, "time": 13411.80391907692, "episode/length": 134.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 278880, "time": 13421.438672065735, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 279112, "time": 13430.655139923096, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 279344, "time": 13440.558827400208, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 279400, "time": 13443.721687078476, "episode/length": 159.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 279840, "time": 13460.376123666763, "episode/length": 148.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 279864, "time": 13462.571869134903, "episode/length": 269.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 279920, "time": 13466.254834413528, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 280064, "time": 13472.791841506958, "episode/length": 349.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 13494.872683286667, "eval_episode/length": 165.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 280072, "time": 13494.893980503082, "eval_episode/length": 165.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 280072, "time": 13498.542510032654, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 280072, "time": 13500.504804372787, "eval_episode/length": 177.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 280072, "time": 13502.39646410942, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 280072, "time": 13505.136714458466, "eval_episode/length": 210.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 280072, "time": 13506.81733751297, "eval_episode/length": 213.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 280072, "time": 13510.183479070663, "eval_episode/length": 252.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9802371541501976}
{"step": 280128, "time": 13512.322587251663, "episode/length": 32.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 280160, "time": 13515.001070022583, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 280440, "time": 13525.964390277863, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 280560, "time": 13531.882095813751, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 280784, "time": 13540.849422931671, "episode/length": 172.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 281336, "time": 13561.468258142471, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 281384, "time": 13564.589160442352, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 281624, "time": 13574.373715639114, "episode/length": 35.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 281728, "time": 13579.744439125061, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 281760, "time": 13582.506473064423, "episode/length": 203.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 281792, "time": 13585.151851415634, "episode/length": 215.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 282176, "time": 13599.769037723541, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 282328, "time": 13606.27882695198, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 282728, "time": 13621.530169725418, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 283088, "time": 13635.688488483429, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 283200, "time": 13641.064835071564, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 283464, "time": 13651.44804763794, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 283544, "time": 13655.72744345665, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 283616, "time": 13659.88678598404, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 283672, "time": 13663.17653298378, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 283936, "time": 13673.874198436737, "episode/length": 436.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 284440, "time": 13692.485673427582, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 284584, "time": 13698.930005550385, "episode/length": 231.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 284680, "time": 13703.73126578331, "episode/length": 184.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 284776, "time": 13708.542318582535, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 284936, "time": 13715.528524398804, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 285240, "time": 13727.411630868912, "episode/length": 195.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 285688, "time": 13744.361006975174, "episode/length": 258.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 285720, "time": 13747.110011100769, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 285944, "time": 13756.231542348862, "episode/length": 157.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 286000, "time": 13759.904444694519, "episode/length": 38.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 286120, "time": 13765.29068160057, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 286176, "time": 13769.071603059769, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 286272, "time": 13774.018373250961, "episode/length": 210.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 286408, "time": 13779.986248016357, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 286816, "time": 13797.152770519257, "episode/length": 234.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9872340425531915, "episode/intrinsic_return": 0.0}
{"step": 287040, "time": 13806.61911725998, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 287152, "time": 13811.998790740967, "episode/length": 143.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 287272, "time": 13817.433836460114, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 287672, "time": 13832.878819704056, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 287944, "time": 13843.778132200241, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 288048, "time": 13849.055324316025, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 288072, "time": 13851.337918043137, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 288176, "time": 13856.713819503784, "episode/length": 220.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 288344, "time": 13863.95319700241, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 288720, "time": 13878.501593112946, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 288792, "time": 13882.317266702652, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 288952, "time": 13889.520649671555, "episode/length": 159.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 289304, "time": 13902.983187437057, "episode/length": 140.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 289400, "time": 13907.941437005997, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 289400, "time": 13907.95243215561, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 289496, "time": 13914.61083483696, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 289688, "time": 13922.948350906372, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 13954.562983512878, "eval_episode/length": 44.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 290056, "time": 13960.753704071045, "eval_episode/length": 139.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 290056, "time": 13963.96184706688, "eval_episode/length": 172.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 290056, "time": 13965.974641799927, "eval_episode/length": 181.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 290056, "time": 13967.621817111969, "eval_episode/length": 182.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 290056, "time": 13969.642436742783, "eval_episode/length": 191.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 290056, "time": 13971.346346855164, "eval_episode/length": 192.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 290056, "time": 13974.55136346817, "eval_episode/length": 183.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 290104, "time": 13976.171729326248, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 290432, "time": 13989.22075510025, "episode/length": 40.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 290536, "time": 13994.00920009613, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 290608, "time": 13998.249263048172, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 290832, "time": 14007.358424663544, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 290920, "time": 14011.758611917496, "episode/length": 245.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 290952, "time": 14014.363056659698, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 290976, "time": 14016.986830234528, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 291432, "time": 14033.629934310913, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 291696, "time": 14044.612332582474, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 291704, "time": 14046.319238424301, "episode/length": 33.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 292048, "time": 14059.849707603455, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 292296, "time": 14069.55840921402, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 292328, "time": 14072.198316812515, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 292496, "time": 14079.609742164612, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 292656, "time": 14086.738471269608, "episode/length": 264.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 292904, "time": 14096.571066141129, "episode/length": 240.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 292992, "time": 14101.62377667427, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 293256, "time": 14111.890994787216, "episode/length": 194.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 293296, "time": 14115.094728946686, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 293592, "time": 14126.566598415375, "episode/length": 157.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 293856, "time": 14137.520240783691, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 293920, "time": 14141.29973077774, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 294216, "time": 14152.656127929688, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 294304, "time": 14157.535604715347, "episode/length": 174.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 294432, "time": 14163.655055046082, "episode/length": 179.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 294624, "time": 14171.745797872543, "episode/length": 50.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 295080, "time": 14190.0211789608, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 295216, "time": 14196.38296508789, "episode/length": 239.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 295512, "time": 14207.884098291397, "episode/length": 206.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 295560, "time": 14211.067631483078, "episode/length": 287.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 295856, "time": 14222.991355895996, "episode/length": 193.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 295880, "time": 14225.290904521942, "episode/length": 244.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 296232, "time": 14238.666887044907, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 296744, "time": 14257.705694198608, "episode/length": 288.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 296768, "time": 14260.344418287277, "episode/length": 156.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 297008, "time": 14270.052904129028, "episode/length": 297.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 297056, "time": 14273.21672129631, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 297088, "time": 14275.932519674301, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 297112, "time": 14278.194343805313, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 297352, "time": 14287.876028776169, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 297384, "time": 14290.519793748856, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 297632, "time": 14300.693492174149, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 298144, "time": 14319.57980966568, "episode/length": 171.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 298168, "time": 14321.852465629578, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 298496, "time": 14334.789597034454, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 298656, "time": 14341.927966594696, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 298657, "time": 14344.130600452423, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.497083521600979, "train/action_min": 0.0, "train/action_std": 3.5244718345243538, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04999582280418766, "train/actor_opt_grad_steps": 17895.0, "train/actor_opt_loss": -2.8830279761285924, "train/adv_mag": 0.8477330875040879, "train/adv_max": 0.8355138777796902, "train/adv_mean": 0.004784309558008725, "train/adv_min": -0.5430508965431754, "train/adv_std": 0.08533309122074896, "train/cont_avg": 0.9942936683768657, "train/cont_loss_mean": 0.00039577496232314207, "train/cont_loss_std": 0.011471944764704194, "train/cont_neg_acc": 0.9864303639956883, "train/cont_neg_loss": 0.06098437403459212, "train/cont_pos_acc": 0.9999559557259973, "train/cont_pos_loss": 0.00013378544336682902, "train/cont_pred": 0.9943106250086827, "train/cont_rate": 0.9942936683768657, "train/dyn_loss_mean": 13.233770811735694, "train/dyn_loss_std": 9.930423359372723, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9543210072303886, "train/extr_critic_critic_opt_grad_steps": 17895.0, "train/extr_critic_critic_opt_loss": 15516.975425606342, "train/extr_critic_mag": 3.872038723817512, "train/extr_critic_max": 3.872038723817512, "train/extr_critic_mean": 0.6673125351098046, "train/extr_critic_min": -0.382577149725672, "train/extr_critic_std": 0.8819230959486606, "train/extr_return_normed_mag": 1.9377877836796775, "train/extr_return_normed_max": 1.9377877836796775, "train/extr_return_normed_mean": 0.3242715180142602, "train/extr_return_normed_min": -0.20976238836770628, "train/extr_return_normed_std": 0.34955336509355855, "train/extr_return_rate": 0.3898170482534081, "train/extr_return_raw_mag": 4.933153193388412, "train/extr_return_raw_max": 4.933153193388412, "train/extr_return_raw_mean": 0.6799339625372816, "train/extr_return_raw_min": -0.7277819318557853, "train/extr_return_raw_std": 0.9215009982016549, "train/extr_reward_mag": 1.0086842081440028, "train/extr_reward_max": 1.0086842081440028, "train/extr_reward_mean": 0.018567785433034844, "train/extr_reward_min": -0.4741543744927022, "train/extr_reward_std": 0.12719462606221882, "train/image_loss_mean": 8.803790725878816, "train/image_loss_std": 13.343646152695612, "train/model_loss_mean": 16.789614734364978, "train/model_loss_std": 17.677750096392277, "train/model_opt_grad_norm": 63.86028590131162, "train/model_opt_grad_steps": 17875.97014925373, "train/model_opt_loss": 11895.105552559467, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 708.955223880597, "train/policy_entropy_mag": 2.4829023382556974, "train/policy_entropy_max": 2.4829023382556974, "train/policy_entropy_mean": 0.7352432435128227, "train/policy_entropy_min": 0.07937596821740492, "train/policy_entropy_std": 0.6682937274228281, "train/policy_logprob_mag": 7.438378141887152, "train/policy_logprob_max": -0.00945592389455927, "train/policy_logprob_mean": -0.7351767082712544, "train/policy_logprob_min": -7.438378141887152, "train/policy_logprob_std": 1.1832861580065828, "train/policy_randomness_mag": 0.8763555684196416, "train/policy_randomness_max": 0.8763555684196416, "train/policy_randomness_mean": 0.2595085998746886, "train/policy_randomness_min": 0.028016233469234472, "train/policy_randomness_std": 0.2358783585811729, "train/post_ent_mag": 55.271579201541726, "train/post_ent_max": 55.271579201541726, "train/post_ent_mean": 38.39791556970397, "train/post_ent_min": 21.29764450130178, "train/post_ent_std": 6.145236243062945, "train/prior_ent_mag": 65.8962116526134, "train/prior_ent_max": 65.8962116526134, "train/prior_ent_mean": 51.75083074996721, "train/prior_ent_min": 30.410201570880947, "train/prior_ent_std": 6.643066100220182, "train/rep_loss_mean": 13.233770811735694, "train/rep_loss_std": 9.930423359372723, "train/reward_avg": 0.014719857615349231, "train/reward_loss_mean": 0.045165745847260776, "train/reward_loss_std": 0.23476053418508216, "train/reward_max_data": 1.011194032519611, "train/reward_max_pred": 1.0029996322162116, "train/reward_neg_acc": 0.9943551327755202, "train/reward_neg_loss": 0.02712915687641101, "train/reward_pos_acc": 0.9521513616860803, "train/reward_pos_loss": 0.937647788827099, "train/reward_pred": 0.013922156915485637, "train/reward_rate": 0.019771746735074626, "train_stats/sum_log_reward": 4.503361278221387, "train_stats/max_log_achievement_collect_drink": 5.857142857142857, "train_stats/max_log_achievement_collect_sapling": 1.8823529411764706, "train_stats/max_log_achievement_collect_wood": 5.445378151260504, "train_stats/max_log_achievement_defeat_skeleton": 0.008403361344537815, "train_stats/max_log_achievement_defeat_zombie": 0.17647058823529413, "train_stats/max_log_achievement_eat_cow": 0.10084033613445378, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.01680672268907563, "train_stats/max_log_achievement_make_wood_sword": 0.04201680672268908, "train_stats/max_log_achievement_place_plant": 1.7142857142857142, "train_stats/max_log_achievement_place_table": 2.310924369747899, "train_stats/max_log_achievement_wake_up": 1.7394957983193278, "train_stats/mean_log_entropy": 0.6966636551528418, "eval_stats/sum_log_reward": 4.287499904632568, "eval_stats/max_log_achievement_collect_drink": 5.75, "eval_stats/max_log_achievement_collect_sapling": 2.375, "eval_stats/max_log_achievement_collect_wood": 3.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.3125, "eval_stats/max_log_achievement_place_table": 1.5, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_stone": 0.023809523809523808, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00010311478399671614, "report/cont_loss_std": 0.002036181977018714, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.005515699274837971, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.586001109099016e-05, "report/cont_pred": 0.9931379556655884, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.160537719726562, "report/dyn_loss_std": 10.34320068359375, "report/image_loss_mean": 9.652509689331055, "report/image_loss_std": 12.571213722229004, "report/model_loss_mean": 17.630380630493164, "report/model_loss_std": 17.258281707763672, "report/post_ent_mag": 54.95355987548828, "report/post_ent_max": 54.95355987548828, "report/post_ent_mean": 38.93641662597656, "report/post_ent_min": 20.78031349182129, "report/post_ent_std": 6.224708557128906, "report/prior_ent_mag": 65.86644744873047, "report/prior_ent_max": 65.86644744873047, "report/prior_ent_mean": 52.11861801147461, "report/prior_ent_min": 33.2171630859375, "report/prior_ent_std": 6.318009376525879, "report/rep_loss_mean": 13.160537719726562, "report/rep_loss_std": 10.34320068359375, "report/reward_avg": 0.02548827975988388, "report/reward_loss_mean": 0.08144591003656387, "report/reward_loss_std": 0.4320753216743469, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005722045898438, "report/reward_neg_acc": 0.9919354319572449, "report/reward_neg_loss": 0.039855606853961945, "report/reward_pos_acc": 0.84375, "report/reward_pos_loss": 1.3707454204559326, "report/reward_pred": 0.022084863856434822, "report/reward_rate": 0.03125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.8278622519574128e-05, "eval/cont_loss_std": 0.00045112636871635914, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.008386335335671902, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.9027785356229288e-06, "eval/cont_pred": 0.9980612397193909, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.113922119140625, "eval/dyn_loss_std": 10.421555519104004, "eval/image_loss_mean": 12.854839324951172, "eval/image_loss_std": 15.07347583770752, "eval/model_loss_mean": 21.951648712158203, "eval/model_loss_std": 19.397846221923828, "eval/post_ent_mag": 57.926063537597656, "eval/post_ent_max": 57.926063537597656, "eval/post_ent_mean": 39.75465774536133, "eval/post_ent_min": 23.120460510253906, "eval/post_ent_std": 6.365039825439453, "eval/prior_ent_mag": 65.86644744873047, "eval/prior_ent_max": 65.86644744873047, "eval/prior_ent_mean": 52.48568344116211, "eval/prior_ent_min": 31.528621673583984, "eval/prior_ent_std": 6.723546504974365, "eval/rep_loss_mean": 15.113922119140625, "eval/rep_loss_std": 10.421555519104004, "eval/reward_avg": 0.008398436941206455, "eval/reward_loss_mean": 0.028438545763492584, "eval/reward_loss_std": 0.2533458173274994, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999085664749146, "eval/reward_neg_acc": 0.9990128874778748, "eval/reward_neg_loss": 0.014310776256024837, "eval/reward_pos_acc": 0.9090909361839294, "eval/reward_pos_loss": 1.3294777870178223, "eval/reward_pred": 0.006726156920194626, "eval/reward_rate": 0.0107421875, "replay/size": 298153.0, "replay/inserts": 21488.0, "replay/samples": 21488.0, "replay/insert_wait_avg": 1.415266355115446e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.21752767072892e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 56120.0, "eval_replay/inserts": 3856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2670315152876604e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.7887487411499, "timer/env.step_count": 2686.0, "timer/env.step_total": 266.09173703193665, "timer/env.step_frac": 0.2658820229210633, "timer/env.step_avg": 0.09906617164256763, "timer/env.step_min": 0.023801803588867188, "timer/env.step_max": 3.7400784492492676, "timer/replay._sample_count": 21488.0, "timer/replay._sample_total": 12.048198938369751, "timer/replay._sample_frac": 0.012038703426197261, "timer/replay._sample_avg": 0.0005606942916218238, "timer/replay._sample_min": 0.0003936290740966797, "timer/replay._sample_max": 0.021669387817382812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3168.0, "timer/agent.policy_total": 55.34726667404175, "timer/agent.policy_frac": 0.055303645992883864, "timer/agent.policy_avg": 0.017470728116806108, "timer/agent.policy_min": 0.009717941284179688, "timer/agent.policy_max": 0.09580683708190918, "timer/dataset_train_count": 1343.0, "timer/dataset_train_total": 0.16618061065673828, "timer/dataset_train_frac": 0.00016604963921284076, "timer/dataset_train_avg": 0.00012373835491938815, "timer/dataset_train_min": 0.00010561943054199219, "timer/dataset_train_max": 0.00044226646423339844, "timer/agent.train_count": 1343.0, "timer/agent.train_total": 608.7329308986664, "timer/agent.train_frac": 0.6082531719749706, "timer/agent.train_avg": 0.45326353752692955, "timer/agent.train_min": 0.4392721652984619, "timer/agent.train_max": 1.5648860931396484, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4774036407470703, "timer/agent.report_frac": 0.0004770273859968713, "timer/agent.report_avg": 0.23870182037353516, "timer/agent.report_min": 0.23151230812072754, "timer/agent.report_max": 0.24589133262634277, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.790855407714844e-05, "timer/dataset_eval_frac": 3.7878677318097364e-08, "timer/dataset_eval_avg": 3.790855407714844e-05, "timer/dataset_eval_min": 3.790855407714844e-05, "timer/dataset_eval_max": 3.790855407714844e-05, "fps": 21.470753682055097}
{"step": 298888, "time": 14352.095718383789, "episode/length": 92.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 299032, "time": 14358.693324804306, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 299072, "time": 14361.884167432785, "episode/length": 247.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 299280, "time": 14370.558935642242, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 299440, "time": 14377.531746149063, "episode/length": 260.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731800766283525, "episode/intrinsic_return": 0.0}
{"step": 299800, "time": 14391.29682636261, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 14417.067237854004, "eval_episode/length": 56.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9122807017543859}
{"step": 300040, "time": 14425.680763483047, "eval_episode/length": 163.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 300040, "time": 14428.122727870941, "eval_episode/length": 175.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 300040, "time": 14428.13368344307, "eval_episode/length": 175.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 300040, "time": 14432.03117799759, "eval_episode/length": 190.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9842931937172775}
{"step": 300040, "time": 14434.39659023285, "eval_episode/length": 148.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 300040, "time": 14437.023537874222, "eval_episode/length": 227.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 300040, "time": 14439.123460769653, "eval_episode/length": 236.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9789029535864979}
{"step": 300208, "time": 14445.065402269363, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 300352, "time": 14451.561883926392, "episode/length": 211.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 300440, "time": 14456.014418363571, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 300656, "time": 14465.210087060928, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 300736, "time": 14469.528745889664, "episode/length": 36.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 300752, "time": 14471.674225330353, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 301072, "time": 14484.194259166718, "episode/length": 223.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 301080, "time": 14485.76237821579, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 301616, "time": 14505.745636940002, "episode/length": 430.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 301768, "time": 14512.361848592758, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 301864, "time": 14517.207467794418, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 302120, "time": 14527.601169109344, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 302152, "time": 14530.309609651566, "episode/length": 186.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 302440, "time": 14541.617930173874, "episode/length": 39.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 302456, "time": 14543.631977081299, "episode/length": 171.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 302960, "time": 14562.61694407463, "episode/length": 275.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 303000, "time": 14565.399819374084, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 303032, "time": 14568.182164430618, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 303112, "time": 14572.832989931107, "episode/length": 254.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 303128, "time": 14576.454260349274, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 303400, "time": 14587.439514875412, "episode/length": 155.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 303536, "time": 14593.882302999496, "episode/length": 134.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 303832, "time": 14605.248468637466, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 304280, "time": 14622.029534816742, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 304296, "time": 14624.146214485168, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 304528, "time": 14633.802927494049, "episode/length": 190.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 304720, "time": 14641.937877893448, "episode/length": 200.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 305096, "time": 14656.090426206589, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 305360, "time": 14666.724735975266, "episode/length": 278.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 305456, "time": 14671.794581651688, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 305496, "time": 14674.524850845337, "episode/length": 207.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 305640, "time": 14680.926150560379, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 305936, "time": 14692.67046046257, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 306032, "time": 14697.452845573425, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 306040, "time": 14699.289014577866, "episode/length": 188.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 306872, "time": 14729.16808795929, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 306936, "time": 14732.936275720596, "episode/length": 229.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 306976, "time": 14736.101940631866, "episode/length": 166.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 307056, "time": 14740.348800897598, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 307344, "time": 14751.668889760971, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 307384, "time": 14754.36912059784, "episode/length": 252.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 307392, "time": 14756.456274271011, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 308112, "time": 14782.738424777985, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 308152, "time": 14785.471234798431, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 308448, "time": 14797.443830490112, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 308712, "time": 14807.779785871506, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 308792, "time": 14812.216720819473, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 308888, "time": 14817.05377626419, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 309136, "time": 14827.49888920784, "episode/length": 274.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 309440, "time": 14839.356634140015, "episode/length": 437.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 309616, "time": 14846.868756771088, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 309640, "time": 14849.196027040482, "episode/length": 148.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 309776, "time": 14855.641433000565, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 14886.347509622574, "eval_episode/length": 160.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 310024, "time": 14888.486892700195, "eval_episode/length": 171.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 310024, "time": 14890.242702245712, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 310024, "time": 14892.1125395298, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 310024, "time": 14894.250856876373, "eval_episode/length": 190.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 310024, "time": 14896.949616909027, "eval_episode/length": 213.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 310024, "time": 14899.33565211296, "eval_episode/length": 231.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.978448275862069}
{"step": 310024, "time": 14901.024552822113, "eval_episode/length": 233.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 310064, "time": 14902.615688800812, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 310176, "time": 14908.120272874832, "episode/length": 129.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 310496, "time": 14920.509011745453, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 310832, "time": 14933.410978078842, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 310856, "time": 14935.638752698898, "episode/length": 245.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 311160, "time": 14947.704645872116, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 311352, "time": 14957.294188976288, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 311448, "time": 14962.251803398132, "episode/length": 158.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 311552, "time": 14968.261125326157, "episode/length": 238.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 312056, "time": 14986.653386116028, "episode/length": 152.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 312056, "time": 14986.664207220078, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 312304, "time": 14998.955883979797, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 312760, "time": 15015.756901741028, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 313160, "time": 15031.133166074753, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 313208, "time": 15034.309183597565, "episode/length": 448.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9977728285077951, "episode/intrinsic_return": 0.0}
{"step": 313240, "time": 15037.058493375778, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 313280, "time": 15040.264867305756, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 313464, "time": 15047.872044801712, "episode/length": 37.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 313728, "time": 15058.968954324722, "episode/length": 64.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 313872, "time": 15065.386429309845, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 313928, "time": 15068.66166472435, "episode/length": 296.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9831649831649831, "episode/intrinsic_return": 0.0}
{"step": 314416, "time": 15087.029468536377, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 314544, "time": 15093.101105690002, "episode/length": 422.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 314672, "time": 15099.083397626877, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 314776, "time": 15103.972520589828, "episode/length": 186.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 314984, "time": 15112.639432907104, "episode/length": 54.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9454545454545454, "episode/intrinsic_return": 0.0}
{"step": 315184, "time": 15121.358624696732, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 315320, "time": 15127.371462583542, "episode/length": 231.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 315440, "time": 15133.205000162125, "episode/length": 56.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 315640, "time": 15141.408829689026, "episode/length": 220.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 315712, "time": 15145.62191939354, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 315824, "time": 15151.075726985931, "episode/length": 261.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732824427480916, "episode/intrinsic_return": 0.0}
{"step": 316216, "time": 15165.61284828186, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 316632, "time": 15181.419038057327, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 316736, "time": 15186.711189985275, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 316736, "time": 15186.724710702896, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 316984, "time": 15198.200648784637, "episode/length": 167.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 316984, "time": 15198.212970495224, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 317072, "time": 15204.7368953228, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 317984, "time": 15237.109345197678, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 318240, "time": 15247.60589647293, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 318272, "time": 15250.297695159912, "episode/length": 35.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 318272, "time": 15250.308296442032, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 318376, "time": 15256.924212694168, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 318400, "time": 15259.565308570862, "episode/length": 220.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 318472, "time": 15263.381843566895, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 318536, "time": 15267.148445129395, "episode/length": 224.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9688888888888889, "episode/intrinsic_return": 0.0}
{"step": 318880, "time": 15280.774783372879, "episode/length": 395.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 319544, "time": 15306.270158290863, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 319680, "time": 15312.681419372559, "episode/length": 159.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 319736, "time": 15315.873000144958, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 319832, "time": 15320.81052684784, "episode/length": 194.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 319880, "time": 15323.94486451149, "episode/length": 167.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 319928, "time": 15327.2318983078, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 15346.60609126091, "eval_episode/length": 34.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 320008, "time": 15352.381606578827, "eval_episode/length": 131.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9621212121212122}
{"step": 320008, "time": 15356.4115524292, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 320008, "time": 15358.315676927567, "eval_episode/length": 160.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 320008, "time": 15360.2165517807, "eval_episode/length": 167.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 320008, "time": 15362.29729962349, "eval_episode/length": 175.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 320008, "time": 15364.017643213272, "eval_episode/length": 179.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 320008, "time": 15367.004667520523, "eval_episode/length": 174.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 320009, "time": 15368.032766580582, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.297729036701259, "train/action_min": 0.0, "train/action_std": 3.1878371790273867, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0493112123891044, "train/actor_opt_grad_steps": 19235.0, "train/actor_opt_loss": 0.47157570113664243, "train/adv_mag": 0.822207407497648, "train/adv_max": 0.8117527234465328, "train/adv_mean": 0.005177634557891105, "train/adv_min": -0.5358915820495406, "train/adv_std": 0.08273708344951494, "train/cont_avg": 0.9942062150186567, "train/cont_loss_mean": 0.00025611940098691936, "train/cont_loss_std": 0.007419704496058656, "train/cont_neg_acc": 0.9923350049140758, "train/cont_neg_loss": 0.0264250216196844, "train/cont_pos_acc": 0.9999560264509115, "train/cont_pos_loss": 0.00011509750864481465, "train/cont_pred": 0.9942103023849317, "train/cont_rate": 0.9942062150186567, "train/dyn_loss_mean": 13.299414784161012, "train/dyn_loss_std": 9.857169806067624, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.923326860168087, "train/extr_critic_critic_opt_grad_steps": 19235.0, "train/extr_critic_critic_opt_loss": 15750.657459771455, "train/extr_critic_mag": 4.038991415678566, "train/extr_critic_max": 4.038991415678566, "train/extr_critic_mean": 0.7082022646469857, "train/extr_critic_min": -0.38190268936441907, "train/extr_critic_std": 0.9389246530942063, "train/extr_return_normed_mag": 1.908945236633073, "train/extr_return_normed_max": 1.908945236633073, "train/extr_return_normed_mean": 0.316035658121109, "train/extr_return_normed_min": -0.1979581092053385, "train/extr_return_normed_std": 0.34890323321321115, "train/extr_return_rate": 0.39857598794485205, "train/extr_return_raw_mag": 5.184808037174282, "train/extr_return_raw_max": 5.184808037174282, "train/extr_return_raw_mean": 0.7227135144952518, "train/extr_return_raw_min": -0.7167172936806038, "train/extr_return_raw_std": 0.9770930765280083, "train/extr_reward_mag": 1.0067376538888733, "train/extr_reward_max": 1.0067376538888733, "train/extr_reward_mean": 0.020428159044805303, "train/extr_reward_min": -0.47533342464646294, "train/extr_reward_std": 0.13345837998968452, "train/image_loss_mean": 8.483796447070677, "train/image_loss_std": 12.377337188863043, "train/model_loss_mean": 16.509935507133825, "train/model_loss_std": 16.680207038993267, "train/model_opt_grad_norm": 59.774064419874506, "train/model_opt_grad_steps": 19214.70895522388, "train/model_opt_loss": 11125.854597860307, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 676.3059701492538, "train/policy_entropy_mag": 2.4712349816934385, "train/policy_entropy_max": 2.4712349816934385, "train/policy_entropy_mean": 0.6982046081059015, "train/policy_entropy_min": 0.07937542337979843, "train/policy_entropy_std": 0.6515373160589987, "train/policy_logprob_mag": 7.438380269861933, "train/policy_logprob_max": -0.00945585174486041, "train/policy_logprob_mean": -0.6988282350461874, "train/policy_logprob_min": -7.438380269861933, "train/policy_logprob_std": 1.17098530548722, "train/policy_randomness_mag": 0.872237501304541, "train/policy_randomness_max": 0.872237501304541, "train/policy_randomness_mean": 0.24643558719709738, "train/policy_randomness_min": 0.02801604113027231, "train/policy_randomness_std": 0.22996408103117302, "train/post_ent_mag": 56.64184345416169, "train/post_ent_max": 56.64184345416169, "train/post_ent_mean": 38.97637139505415, "train/post_ent_min": 21.33303494239921, "train/post_ent_std": 6.414605788330533, "train/prior_ent_mag": 66.26429532179192, "train/prior_ent_max": 66.26429532179192, "train/prior_ent_mean": 52.385996519629636, "train/prior_ent_min": 31.764391500558425, "train/prior_ent_std": 6.378263160363952, "train/rep_loss_mean": 13.299414784161012, "train/rep_loss_std": 9.857169806067624, "train/reward_avg": 0.015616254474439505, "train/reward_loss_mean": 0.046234132138206, "train/reward_loss_std": 0.23949907875772733, "train/reward_max_data": 1.0044776130078443, "train/reward_max_pred": 1.0021245532961034, "train/reward_neg_acc": 0.994251355306426, "train/reward_neg_loss": 0.02742905855012029, "train/reward_pos_acc": 0.9521832648497909, "train/reward_pos_loss": 0.9332498031765667, "train/reward_pred": 0.014964892209243418, "train/reward_rate": 0.02082118703358209, "train_stats/sum_log_reward": 4.675221193153246, "train_stats/max_log_achievement_collect_drink": 7.539823008849558, "train_stats/max_log_achievement_collect_sapling": 1.9380530973451326, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.592920353982301, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.26548672566371684, "train_stats/max_log_achievement_eat_cow": 0.08849557522123894, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.017699115044247787, "train_stats/max_log_achievement_make_wood_sword": 0.017699115044247787, "train_stats/max_log_achievement_place_plant": 1.8141592920353982, "train_stats/max_log_achievement_place_table": 2.4601769911504423, "train_stats/max_log_achievement_wake_up": 2.0353982300884956, "train_stats/mean_log_entropy": 0.6564611675201264, "eval_stats/sum_log_reward": 4.641666596134503, "eval_stats/max_log_achievement_collect_drink": 7.333333333333333, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.2916666666666667, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 2.0416666666666665, "eval_stats/max_log_achievement_place_table": 2.5833333333333335, "eval_stats/max_log_achievement_wake_up": 1.7083333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0005822282982990146, "report/cont_loss_std": 0.018170202150940895, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00037746859015896916, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0005826289998367429, "report/cont_pred": 0.9976036548614502, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 13.177144050598145, "report/dyn_loss_std": 10.183443069458008, "report/image_loss_mean": 8.161150932312012, "report/image_loss_std": 9.695517539978027, "report/model_loss_mean": 16.103761672973633, "report/model_loss_std": 14.602643013000488, "report/post_ent_mag": 63.06343078613281, "report/post_ent_max": 63.06343078613281, "report/post_ent_mean": 39.55850601196289, "report/post_ent_min": 20.22202491760254, "report/post_ent_std": 7.073534965515137, "report/prior_ent_mag": 69.09002685546875, "report/prior_ent_max": 69.09002685546875, "report/prior_ent_mean": 52.55450439453125, "report/prior_ent_min": 29.462295532226562, "report/prior_ent_std": 6.8751702308654785, "report/rep_loss_mean": 13.177144050598145, "report/rep_loss_std": 10.183443069458008, "report/reward_avg": 0.013671874068677425, "report/reward_loss_mean": 0.035742927342653275, "report/reward_loss_std": 0.2505621016025543, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002371072769165, "report/reward_neg_acc": 0.9960318207740784, "report/reward_neg_loss": 0.017485037446022034, "report/reward_pos_acc": 0.875, "report/reward_pos_loss": 1.1859900951385498, "report/reward_pred": 0.01199666503816843, "report/reward_rate": 0.015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 9.419763955520466e-05, "eval/cont_loss_std": 0.0027897797990590334, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001225139363668859, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.976257231552154e-05, "eval/cont_pred": 0.9960130453109741, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 13.978553771972656, "eval/dyn_loss_std": 10.065004348754883, "eval/image_loss_mean": 12.43490982055664, "eval/image_loss_std": 18.572357177734375, "eval/model_loss_mean": 20.885892868041992, "eval/model_loss_std": 22.575044631958008, "eval/post_ent_mag": 54.95713806152344, "eval/post_ent_max": 54.95713806152344, "eval/post_ent_mean": 39.89632034301758, "eval/post_ent_min": 20.723464965820312, "eval/post_ent_std": 5.9108662605285645, "eval/prior_ent_mag": 67.18370056152344, "eval/prior_ent_max": 67.18370056152344, "eval/prior_ent_mean": 51.439205169677734, "eval/prior_ent_min": 32.06590270996094, "eval/prior_ent_std": 5.840001583099365, "eval/rep_loss_mean": 13.978553771972656, "eval/rep_loss_std": 10.065004348754883, "eval/reward_avg": 0.00839843787252903, "eval/reward_loss_mean": 0.06375567615032196, "eval/reward_loss_std": 0.5114058256149292, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000226497650146, "eval/reward_neg_acc": 0.9960474967956543, "eval/reward_neg_loss": 0.04643343389034271, "eval/reward_pos_acc": 0.9166666865348816, "eval/reward_pos_loss": 1.5245981216430664, "eval/reward_pred": 0.00887206569314003, "eval/reward_rate": 0.01171875, "replay/size": 319505.0, "replay/inserts": 21352.0, "replay/samples": 21360.0, "replay/insert_wait_avg": 1.4181171029906633e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.063366200593527e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61568.0, "eval_replay/inserts": 5448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.301499365359851e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1023.8879609107971, "timer/env.step_count": 2669.0, "timer/env.step_total": 259.41816663742065, "timer/env.step_frac": 0.2533657749102312, "timer/env.step_avg": 0.09719676531937829, "timer/env.step_min": 0.02408146858215332, "timer/env.step_max": 3.5519509315490723, "timer/replay._sample_count": 21360.0, "timer/replay._sample_total": 11.939421653747559, "timer/replay._sample_frac": 0.011660867311230883, "timer/replay._sample_avg": 0.0005589616879095299, "timer/replay._sample_min": 0.0004055500030517578, "timer/replay._sample_max": 0.008615732192993164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3350.0, "timer/agent.policy_total": 60.80299687385559, "timer/agent.policy_frac": 0.05938442407289214, "timer/agent.policy_avg": 0.018150148320553908, "timer/agent.policy_min": 0.00969839096069336, "timer/agent.policy_max": 1.0858056545257568, "timer/dataset_train_count": 1335.0, "timer/dataset_train_total": 0.1633760929107666, "timer/dataset_train_frac": 0.00015956442418312624, "timer/dataset_train_avg": 0.0001223790958133083, "timer/dataset_train_min": 0.00010395050048828125, "timer/dataset_train_max": 0.0007123947143554688, "timer/agent.train_count": 1335.0, "timer/agent.train_total": 603.9947216510773, "timer/agent.train_frac": 0.5899031385365594, "timer/agent.train_avg": 0.4524305031094212, "timer/agent.train_min": 0.44069552421569824, "timer/agent.train_max": 1.5712709426879883, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4715714454650879, "timer/agent.report_frac": 0.00046056938206950166, "timer/agent.report_avg": 0.23578572273254395, "timer/agent.report_min": 0.22227859497070312, "timer/agent.report_max": 0.24929285049438477, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.8408446784076153e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 20.853549423839297}
{"step": 320080, "time": 15370.515556573868, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 320256, "time": 15378.21365404129, "episode/length": 88.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9550561797752809, "episode/intrinsic_return": 0.0}
{"step": 320256, "time": 15378.243809461594, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 320560, "time": 15391.921968221664, "episode/length": 78.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9240506329113924, "episode/intrinsic_return": 0.0}
{"step": 321120, "time": 15412.478316783905, "episode/length": 107.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 321224, "time": 15417.37133526802, "episode/length": 173.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 321248, "time": 15420.223265171051, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 321264, "time": 15422.37395620346, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 321496, "time": 15431.638381242752, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 321536, "time": 15434.899098396301, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 322064, "time": 15454.589278936386, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 322472, "time": 15469.913355350494, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 322592, "time": 15475.867401123047, "episode/length": 167.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 322664, "time": 15479.783799409866, "episode/length": 372.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9919571045576407, "episode/intrinsic_return": 0.0}
{"step": 322688, "time": 15482.469616174698, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 322728, "time": 15485.185246944427, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 322856, "time": 15491.163698196411, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 322936, "time": 15495.64708662033, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 322968, "time": 15498.280559778214, "episode/length": 34.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 322968, "time": 15498.289489269257, "episode/length": 37.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 323264, "time": 15512.320394992828, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 323344, "time": 15516.558861017227, "episode/length": 46.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 323960, "time": 15538.827555179596, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 324264, "time": 15550.727641582489, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 324480, "time": 15560.04747581482, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 324560, "time": 15564.388935089111, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 324576, "time": 15566.482213973999, "episode/length": 200.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 324616, "time": 15569.295093536377, "episode/length": 158.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 324808, "time": 15577.335442066193, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 325312, "time": 15596.412871360779, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 325552, "time": 15606.445260286331, "episode/length": 133.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 325752, "time": 15614.58951330185, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 325816, "time": 15618.385575532913, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 325920, "time": 15623.828268527985, "episode/length": 430.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9976798143851509, "episode/intrinsic_return": 0.0}
{"step": 326032, "time": 15629.26473903656, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 326280, "time": 15639.016175031662, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 326504, "time": 15648.261479377747, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 326584, "time": 15652.489960193634, "episode/length": 158.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 326960, "time": 15667.148345470428, "episode/length": 175.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 327008, "time": 15670.382248401642, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 327296, "time": 15681.92310166359, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 327376, "time": 15686.355713367462, "episode/length": 167.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 327504, "time": 15692.449610948563, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 327640, "time": 15698.515531301498, "episode/length": 169.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 327904, "time": 15710.69352030754, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 328216, "time": 15722.787253856659, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 328544, "time": 15735.78366112709, "episode/length": 145.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 328584, "time": 15738.46007180214, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 328632, "time": 15741.750569343567, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 328824, "time": 15749.961950063705, "episode/length": 279.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 328896, "time": 15754.222498893738, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 328920, "time": 15756.441977977753, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 329488, "time": 15777.47901725769, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 329584, "time": 15782.622069835663, "episode/length": 94.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 329712, "time": 15788.524229764938, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 329736, "time": 15790.68855047226, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 329904, "time": 15798.26258444786, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 15826.458159446716, "eval_episode/length": 143.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 330096, "time": 15828.752041816711, "eval_episode/length": 147.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9662162162162162}
{"step": 330096, "time": 15832.31335735321, "eval_episode/length": 176.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 330096, "time": 15834.99426651001, "eval_episode/length": 183.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 330096, "time": 15836.74763083458, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.978494623655914}
{"step": 330096, "time": 15839.336971998215, "eval_episode/length": 199.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.965}
{"step": 330096, "time": 15842.170559167862, "eval_episode/length": 224.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 330096, "time": 15845.412466287613, "eval_episode/length": 261.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9809160305343512}
{"step": 330136, "time": 15846.546239852905, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 330240, "time": 15851.867210149765, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 330424, "time": 15859.40836238861, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 330792, "time": 15873.602454423904, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 330800, "time": 15875.859380960464, "episode/length": 276.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 331152, "time": 15889.439227819443, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 331272, "time": 15894.864429473877, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 331408, "time": 15901.409700632095, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 331608, "time": 15909.543702602386, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 331992, "time": 15924.131399869919, "episode/length": 47.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 332048, "time": 15927.982922077179, "episode/length": 288.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 332064, "time": 15930.129042625427, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 332072, "time": 15931.717212677002, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 332440, "time": 15945.66295671463, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 332616, "time": 15953.332000494003, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 332832, "time": 15963.11649274826, "episode/length": 177.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 333360, "time": 15982.62105846405, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 333432, "time": 15986.48535656929, "episode/length": 172.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 333760, "time": 15999.512424230576, "episode/length": 310.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 333864, "time": 16004.401544809341, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 333880, "time": 16006.57291007042, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 334120, "time": 16016.250881671906, "episode/length": 256.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 334264, "time": 16022.889853715897, "episode/length": 283.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 334552, "time": 16034.294585466385, "episode/length": 35.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 334656, "time": 16039.547919511795, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 334688, "time": 16042.17667722702, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 334792, "time": 16047.083825349808, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 335016, "time": 16056.46624994278, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 335296, "time": 16067.775396823883, "episode/length": 34.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 335416, "time": 16073.312248945236, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 335560, "time": 16080.077902793884, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 335632, "time": 16084.348516702652, "episode/length": 134.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 335640, "time": 16085.948266029358, "episode/length": 221.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 335704, "time": 16089.674673557281, "episode/length": 227.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 336448, "time": 16118.59535908699, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 336560, "time": 16123.96066069603, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 336568, "time": 16125.698620557785, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 336760, "time": 16133.858165979385, "episode/length": 140.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 336760, "time": 16133.86866235733, "episode/length": 131.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 336984, "time": 16145.099641084671, "episode/length": 273.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 337056, "time": 16149.330167531967, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 337128, "time": 16153.136198282242, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 337328, "time": 16161.812568187714, "episode/length": 33.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 337880, "time": 16182.07195019722, "episode/length": 164.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 337880, "time": 16182.079866886139, "episode/length": 139.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 337984, "time": 16189.128525972366, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 338176, "time": 16197.29479932785, "episode/length": 200.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 338192, "time": 16199.668054819107, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 338800, "time": 16221.818500041962, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 338984, "time": 16229.52957034111, "episode/length": 249.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 339192, "time": 16238.184588432312, "episode/length": 124.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 339240, "time": 16241.492989301682, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 339440, "time": 16250.220230102539, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 339592, "time": 16256.812426328659, "episode/length": 43.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 339680, "time": 16261.838143825531, "episode/length": 318.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 339744, "time": 16265.61980175972, "episode/length": 37.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 339744, "time": 16265.643513441086, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 16295.293880462646, "eval_episode/length": 32.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 340080, "time": 16297.004655122757, "eval_episode/length": 35.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 340080, "time": 16303.793698072433, "eval_episode/length": 138.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 340080, "time": 16308.363359212875, "eval_episode/length": 179.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 340080, "time": 16311.350337266922, "eval_episode/length": 198.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 340080, "time": 16313.22268986702, "eval_episode/length": 204.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9658536585365853}
{"step": 340080, "time": 16315.188988924026, "eval_episode/length": 210.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9715639810426541}
{"step": 340080, "time": 16318.216220617294, "eval_episode/length": 204.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 340304, "time": 16325.811375617981, "episode/length": 302.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 340736, "time": 16342.148816347122, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 340856, "time": 16347.754619598389, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 340920, "time": 16351.744673728943, "episode/length": 146.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 341264, "time": 16365.28800535202, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 341289, "time": 16368.515998601913, "train_stats/sum_log_reward": 4.6042016182376555, "train_stats/max_log_achievement_collect_drink": 5.579831932773109, "train_stats/max_log_achievement_collect_sapling": 1.7899159663865547, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 6.352941176470588, "train_stats/max_log_achievement_defeat_skeleton": 0.008403361344537815, "train_stats/max_log_achievement_defeat_zombie": 0.21008403361344538, "train_stats/max_log_achievement_eat_cow": 0.09243697478991597, "train_stats/max_log_achievement_eat_plant": 0.008403361344537815, "train_stats/max_log_achievement_make_wood_pickaxe": 0.01680672268907563, "train_stats/max_log_achievement_make_wood_sword": 0.025210084033613446, "train_stats/max_log_achievement_place_plant": 1.7058823529411764, "train_stats/max_log_achievement_place_table": 2.689075630252101, "train_stats/max_log_achievement_wake_up": 1.8235294117647058, "train_stats/mean_log_entropy": 0.6329249709594149, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.299516491423872, "train/action_min": 0.0, "train/action_std": 3.233801716252377, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048524075600885806, "train/actor_opt_grad_steps": 20570.0, "train/actor_opt_loss": -4.228628560564572, "train/adv_mag": 0.7532286052417038, "train/adv_max": 0.7440058163234166, "train/adv_mean": 0.004323041136524267, "train/adv_min": -0.519989933510472, "train/adv_std": 0.07876160964929968, "train/cont_avg": 0.994133282424812, "train/cont_loss_mean": 0.0003242373920004309, "train/cont_loss_std": 0.008898277317602787, "train/cont_neg_acc": 0.9878565480834559, "train/cont_neg_loss": 0.027832873775526224, "train/cont_pos_acc": 0.9999481699520484, "train/cont_pos_loss": 0.00014819383579182035, "train/cont_pred": 0.9941489396238685, "train/cont_rate": 0.994133282424812, "train/dyn_loss_mean": 13.47476024914505, "train/dyn_loss_std": 9.882006824464726, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8547985795745277, "train/extr_critic_critic_opt_grad_steps": 20570.0, "train/extr_critic_critic_opt_loss": 15523.941560444078, "train/extr_critic_mag": 4.203410223910683, "train/extr_critic_max": 4.203410223910683, "train/extr_critic_mean": 0.7299529737547824, "train/extr_critic_min": -0.3915595497403826, "train/extr_critic_std": 0.9804881501914864, "train/extr_return_normed_mag": 1.8768308431582343, "train/extr_return_normed_max": 1.8768308431582343, "train/extr_return_normed_mean": 0.31326213355799365, "train/extr_return_normed_min": -0.18938148156144566, "train/extr_return_normed_std": 0.3482087429304768, "train/extr_return_rate": 0.41112157343921807, "train/extr_return_raw_mag": 5.31447788647243, "train/extr_return_raw_max": 5.31447788647243, "train/extr_return_raw_mean": 0.7425838258481563, "train/extr_return_raw_min": -0.7272843389134658, "train/extr_return_raw_std": 1.0188080269591253, "train/extr_reward_mag": 1.0096980906966935, "train/extr_reward_max": 1.0096980906966935, "train/extr_reward_mean": 0.020357172495048297, "train/extr_reward_min": -0.5121931778757196, "train/extr_reward_std": 0.13493656927257552, "train/image_loss_mean": 8.201539760245417, "train/image_loss_std": 12.243480517451925, "train/model_loss_mean": 16.33240400758901, "train/model_loss_std": 16.524631973496057, "train/model_opt_grad_norm": 57.30732257438429, "train/model_opt_grad_steps": 20548.812030075187, "train/model_opt_loss": 13841.446270706063, "train/model_opt_model_opt_grad_overflow": 0.007518796992481203, "train/model_opt_model_opt_grad_scale": 845.8646616541354, "train/policy_entropy_mag": 2.5302426151763227, "train/policy_entropy_max": 2.5302426151763227, "train/policy_entropy_mean": 0.724624432567367, "train/policy_entropy_min": 0.07937533212335486, "train/policy_entropy_std": 0.6865859672539216, "train/policy_logprob_mag": 7.4383804385823415, "train/policy_logprob_max": -0.009455831861473564, "train/policy_logprob_mean": -0.7243402810921347, "train/policy_logprob_min": -7.4383804385823415, "train/policy_logprob_std": 1.183103599046406, "train/policy_randomness_mag": 0.8930646100438627, "train/policy_randomness_max": 0.8930646100438627, "train/policy_randomness_mean": 0.25576062466865196, "train/policy_randomness_min": 0.02801600898286902, "train/policy_randomness_std": 0.24233471484560715, "train/post_ent_mag": 56.99872732521, "train/post_ent_max": 56.99872732521, "train/post_ent_mean": 39.421229914615026, "train/post_ent_min": 21.40577385120822, "train/post_ent_std": 6.615963828294797, "train/prior_ent_mag": 66.72495889305172, "train/prior_ent_max": 66.72495889305172, "train/prior_ent_mean": 52.963936253597865, "train/prior_ent_min": 32.46163098614915, "train/prior_ent_std": 6.14400187112335, "train/rep_loss_mean": 13.47476024914505, "train/rep_loss_std": 9.882006824464726, "train/reward_avg": 0.015176368630456185, "train/reward_loss_mean": 0.045684068344701505, "train/reward_loss_std": 0.22715184938414654, "train/reward_max_data": 1.0097744384206326, "train/reward_max_pred": 1.0032442091102887, "train/reward_neg_acc": 0.9943364616623498, "train/reward_neg_loss": 0.02825324985205679, "train/reward_pos_acc": 0.9648666762767878, "train/reward_pos_loss": 0.8796014691654005, "train/reward_pred": 0.014712637735012555, "train/reward_rate": 0.02055186795112782, "eval_stats/sum_log_reward": 4.599999904632568, "eval_stats/max_log_achievement_collect_drink": 5.5625, "eval_stats/max_log_achievement_collect_sapling": 2.0625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 7.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.7450132872909307e-05, "report/cont_loss_std": 0.00048053075443021953, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00015894613170530647, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.6616169887129217e-05, "report/cont_pred": 0.9941251277923584, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.942564010620117, "report/dyn_loss_std": 10.298531532287598, "report/image_loss_mean": 8.806529998779297, "report/image_loss_std": 8.977267265319824, "report/model_loss_mean": 17.215946197509766, "report/model_loss_std": 13.39995002746582, "report/post_ent_mag": 58.654197692871094, "report/post_ent_max": 58.654197692871094, "report/post_ent_mean": 40.95178985595703, "report/post_ent_min": 20.200742721557617, "report/post_ent_std": 7.925417900085449, "report/prior_ent_mag": 66.75096130371094, "report/prior_ent_max": 66.75096130371094, "report/prior_ent_mean": 54.91252899169922, "report/prior_ent_min": 31.706729888916016, "report/prior_ent_std": 5.365261554718018, "report/rep_loss_mean": 13.942564010620117, "report/rep_loss_std": 10.298531532287598, "report/reward_avg": 0.012597656808793545, "report/reward_loss_mean": 0.043859951198101044, "report/reward_loss_std": 0.2407907098531723, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0001142024993896, "report/reward_neg_acc": 0.9960199594497681, "report/reward_neg_loss": 0.024541664868593216, "report/reward_pos_acc": 0.9473684430122375, "report/reward_pos_loss": 1.0656957626342773, "report/reward_pred": 0.010831886902451515, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.00015211536083370447, "eval/cont_loss_std": 0.0037385139148682356, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.01643870212137699, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.0014961996348575e-05, "eval/cont_pred": 0.9932312369346619, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 15.448570251464844, "eval/dyn_loss_std": 10.847413063049316, "eval/image_loss_mean": 11.25361442565918, "eval/image_loss_std": 15.709868431091309, "eval/model_loss_mean": 20.602933883666992, "eval/model_loss_std": 20.235958099365234, "eval/post_ent_mag": 52.64227294921875, "eval/post_ent_max": 52.64227294921875, "eval/post_ent_mean": 39.536895751953125, "eval/post_ent_min": 22.95391845703125, "eval/post_ent_std": 6.084214210510254, "eval/prior_ent_mag": 66.75096130371094, "eval/prior_ent_max": 66.75096130371094, "eval/prior_ent_mean": 53.047332763671875, "eval/prior_ent_min": 33.661949157714844, "eval/prior_ent_std": 5.890205383300781, "eval/rep_loss_mean": 15.448570251464844, "eval/rep_loss_std": 10.847413063049316, "eval/reward_avg": 0.01171875, "eval/reward_loss_mean": 0.08002559095621109, "eval/reward_loss_std": 0.5840621590614319, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0039887428283691, "eval/reward_neg_acc": 0.995029866695404, "eval/reward_neg_loss": 0.03553687036037445, "eval/reward_pos_acc": 0.7222222089767456, "eval/reward_pos_loss": 2.566450834274292, "eval/reward_pred": 0.008150039240717888, "eval/reward_rate": 0.017578125, "replay/size": 340785.0, "replay/inserts": 21280.0, "replay/samples": 21280.0, "replay/insert_wait_avg": 1.426197980579577e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.024949898397116e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 65568.0, "eval_replay/inserts": 4000.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3270974159240723e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4715948104858, "timer/env.step_count": 2660.0, "timer/env.step_total": 267.95128178596497, "timer/env.step_frac": 0.26782497691673257, "timer/env.step_avg": 0.10073356458118983, "timer/env.step_min": 0.02407240867614746, "timer/env.step_max": 3.7000064849853516, "timer/replay._sample_count": 21280.0, "timer/replay._sample_total": 11.894443988800049, "timer/replay._sample_frac": 0.011888837274838525, "timer/replay._sample_avg": 0.0005589494355639121, "timer/replay._sample_min": 0.00038909912109375, "timer/replay._sample_max": 0.025940656661987305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3160.0, "timer/agent.policy_total": 55.799094438552856, "timer/agent.policy_frac": 0.05577279227914771, "timer/agent.policy_avg": 0.017657941278023056, "timer/agent.policy_min": 0.009594917297363281, "timer/agent.policy_max": 0.13234663009643555, "timer/dataset_train_count": 1330.0, "timer/dataset_train_total": 0.16394281387329102, "timer/dataset_train_frac": 0.00016386553573701995, "timer/dataset_train_avg": 0.00012326527358894063, "timer/dataset_train_min": 0.00010657310485839844, "timer/dataset_train_max": 0.001100301742553711, "timer/agent.train_count": 1330.0, "timer/agent.train_total": 604.0351572036743, "timer/agent.train_frac": 0.6037504316332875, "timer/agent.train_avg": 0.45416177233358973, "timer/agent.train_min": 0.44229722023010254, "timer/agent.train_max": 1.5665063858032227, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46985578536987305, "timer/agent.report_frac": 0.00046963430826726807, "timer/agent.report_avg": 0.23492789268493652, "timer/agent.report_min": 0.22381305694580078, "timer/agent.report_max": 0.24604272842407227, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.933906555175781e-05, "timer/dataset_eval_frac": 3.932052219754386e-08, "timer/dataset_eval_avg": 3.933906555175781e-05, "timer/dataset_eval_min": 3.933906555175781e-05, "timer/dataset_eval_max": 3.933906555175781e-05, "fps": 21.26969808330857}
{"step": 341328, "time": 16370.007189512253, "episode/length": 315.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9841772151898734, "episode/intrinsic_return": 0.0}
{"step": 341408, "time": 16374.270362615585, "episode/length": 207.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 341808, "time": 16389.590827465057, "episode/length": 276.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9819494584837545, "episode/intrinsic_return": 0.0}
{"step": 342232, "time": 16405.889738321304, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 342320, "time": 16410.85214328766, "episode/length": 251.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 342560, "time": 16420.730311632156, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 342712, "time": 16427.224180221558, "episode/length": 48.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 342792, "time": 16431.60969567299, "episode/length": 241.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 342848, "time": 16435.440430164337, "episode/length": 197.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 342888, "time": 16438.364765167236, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 343152, "time": 16449.18373274803, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 343360, "time": 16457.752854824066, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 343392, "time": 16460.406597852707, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 343944, "time": 16480.75764107704, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 344048, "time": 16486.08971595764, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 344168, "time": 16492.984360456467, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 344232, "time": 16496.775786161423, "episode/length": 35.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 344536, "time": 16508.918524503708, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 344544, "time": 16510.946419477463, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 344792, "time": 16520.74852347374, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 344984, "time": 16529.101093769073, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 345048, "time": 16532.750866174698, "episode/length": 63.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 345240, "time": 16540.85549235344, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 345544, "time": 16552.738402843475, "episode/length": 37.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 345640, "time": 16557.726952314377, "episode/length": 183.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 346032, "time": 16573.07933282852, "episode/length": 154.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 346144, "time": 16578.480628967285, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 346368, "time": 16587.7781291008, "episode/length": 266.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 346416, "time": 16591.15244412422, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 346520, "time": 16596.508481264114, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 346720, "time": 16605.303122758865, "episode/length": 445.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798206278026906, "episode/intrinsic_return": 0.0}
{"step": 346744, "time": 16607.435978651047, "episode/length": 40.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 347048, "time": 16619.442007303238, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 347408, "time": 16633.816562652588, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 347648, "time": 16643.65779399872, "episode/length": 262.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 347712, "time": 16647.43685722351, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 347952, "time": 16657.345490455627, "episode/length": 178.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 348040, "time": 16661.534714221954, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 348072, "time": 16664.350366830826, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 348368, "time": 16676.27107477188, "episode/length": 36.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 348464, "time": 16681.3719060421, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 348712, "time": 16691.18624973297, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 348800, "time": 16695.96210193634, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 349080, "time": 16706.76208114624, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 349256, "time": 16714.536751031876, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 349672, "time": 16730.210878133774, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 350056, "time": 16745.037697792053, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 16763.671904802322, "eval_episode/length": 76.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.935064935064935}
{"step": 350064, "time": 16768.382340192795, "eval_episode/length": 140.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9716312056737588}
{"step": 350064, "time": 16772.01658129692, "eval_episode/length": 183.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 350064, "time": 16774.29731297493, "eval_episode/length": 195.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 350064, "time": 16777.097489595413, "eval_episode/length": 219.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9727272727272728}
{"step": 350064, "time": 16778.765156507492, "eval_episode/length": 221.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 350064, "time": 16781.30143046379, "eval_episode/length": 242.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9794238683127572}
{"step": 350064, "time": 16783.50186777115, "eval_episode/length": 255.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 350104, "time": 16784.639218330383, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 350192, "time": 16789.5489859581, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 350280, "time": 16794.011105060577, "episode/length": 290.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 350616, "time": 16807.13588309288, "episode/length": 237.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 350616, "time": 16807.1523103714, "episode/length": 41.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 350736, "time": 16814.745636701584, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 351088, "time": 16828.389956235886, "episode/length": 228.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 351360, "time": 16839.220998048782, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 351392, "time": 16841.89057326317, "episode/length": 96.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 351408, "time": 16843.967613220215, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 351768, "time": 16857.56577396393, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 351888, "time": 16863.5692820549, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 351896, "time": 16865.189913749695, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 351976, "time": 16869.432465791702, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 352280, "time": 16882.805104732513, "episode/length": 37.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 352640, "time": 16896.92930984497, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 352720, "time": 16901.219351053238, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 353024, "time": 16913.25938987732, "episode/length": 37.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 353112, "time": 16917.933104515076, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 353120, "time": 16920.132697343826, "episode/length": 213.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 353264, "time": 16926.602640867233, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 353328, "time": 16930.377771615982, "episode/length": 179.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 353368, "time": 16932.953649282455, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 353656, "time": 16944.309923887253, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 353944, "time": 16955.75995516777, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 354600, "time": 16980.25009202957, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 354624, "time": 16982.979692935944, "episode/length": 169.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 354672, "time": 16986.104121685028, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 354696, "time": 16988.317071199417, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 354896, "time": 16996.991788625717, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700854700854701, "episode/intrinsic_return": 0.0}
{"step": 355296, "time": 17012.236995458603, "episode/length": 168.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 355320, "time": 17014.422121286392, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 356112, "time": 17043.404268026352, "episode/length": 306.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 356136, "time": 17045.587708711624, "episode/length": 182.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 356232, "time": 17050.53577399254, "episode/length": 116.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9572649572649573, "episode/intrinsic_return": 0.0}
{"step": 356376, "time": 17057.06216955185, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9684684684684685, "episode/intrinsic_return": 0.0}
{"step": 356384, "time": 17059.141634702682, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 356400, "time": 17061.35204601288, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 356736, "time": 17074.38948583603, "episode/length": 176.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 357120, "time": 17089.01999092102, "episode/length": 91.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9456521739130435, "episode/intrinsic_return": 0.0}
{"step": 357128, "time": 17090.61856508255, "episode/length": 312.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 357400, "time": 17101.580691576004, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 357528, "time": 17107.479330062866, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 357600, "time": 17111.76108622551, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 357744, "time": 17118.40615582466, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 357784, "time": 17121.64907026291, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 358520, "time": 17148.290071487427, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 358640, "time": 17154.03510284424, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 358736, "time": 17159.30609345436, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 358896, "time": 17166.380313396454, "episode/length": 269.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 358936, "time": 17169.123353004456, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 359016, "time": 17173.536616563797, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 359464, "time": 17190.353016138077, "episode/length": 209.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 359600, "time": 17196.71462869644, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 359608, "time": 17198.38214302063, "episode/length": 135.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 17229.739760875702, "eval_episode/length": 34.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 360048, "time": 17236.253254175186, "eval_episode/length": 144.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.993103448275862}
{"step": 360048, "time": 17238.48251390457, "eval_episode/length": 157.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 360048, "time": 17240.53720331192, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 360048, "time": 17243.01167368889, "eval_episode/length": 35.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 360048, "time": 17245.76105737686, "eval_episode/length": 204.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 360048, "time": 17248.116334438324, "eval_episode/length": 216.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 360048, "time": 17250.721816778183, "eval_episode/length": 32.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 360496, "time": 17267.522500276566, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 360544, "time": 17270.736158132553, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 360552, "time": 17272.465902090073, "episode/length": 238.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 360624, "time": 17276.766073942184, "episode/length": 235.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 360776, "time": 17283.56124830246, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 360920, "time": 17290.063930034637, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 360952, "time": 17292.770359039307, "episode/length": 49.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 361232, "time": 17304.020745515823, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 361640, "time": 17319.186213970184, "episode/length": 271.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 362032, "time": 17334.423907756805, "episode/length": 191.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 362080, "time": 17337.628654241562, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 362280, "time": 17346.03424191475, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 362384, "time": 17351.415158748627, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 362632, "time": 17361.235769033432, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 362672, "time": 17364.442925214767, "episode/length": 218.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 362729, "time": 17368.894673109055, "train_stats/sum_log_reward": 5.108546956991538, "train_stats/max_log_achievement_collect_drink": 6.760683760683761, "train_stats/max_log_achievement_collect_sapling": 2.641025641025641, "train_stats/max_log_achievement_collect_stone": 0.02564102564102564, "train_stats/max_log_achievement_collect_wood": 7.47008547008547, "train_stats/max_log_achievement_defeat_skeleton": 0.017094017094017096, "train_stats/max_log_achievement_defeat_zombie": 0.46153846153846156, "train_stats/max_log_achievement_eat_cow": 0.11965811965811966, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05982905982905983, "train_stats/max_log_achievement_make_wood_sword": 0.03418803418803419, "train_stats/max_log_achievement_place_plant": 2.5555555555555554, "train_stats/max_log_achievement_place_table": 2.9401709401709404, "train_stats/max_log_achievement_wake_up": 1.606837606837607, "train_stats/mean_log_entropy": 0.586065423539561, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.216563210558536, "train/action_min": 0.0, "train/action_std": 3.140190798844864, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04914007875234334, "train/actor_opt_grad_steps": 21905.0, "train/actor_opt_loss": -1.6913204080661508, "train/adv_mag": 0.7899926705146904, "train/adv_max": 0.7782831414421992, "train/adv_mean": 0.005138952059279467, "train/adv_min": -0.5165925481870993, "train/adv_std": 0.07938079360816906, "train/cont_avg": 0.9944685750932836, "train/cont_loss_mean": 0.000276435258308708, "train/cont_loss_std": 0.007956078335460753, "train/cont_neg_acc": 0.9878610212411454, "train/cont_neg_loss": 0.03261867973745198, "train/cont_pos_acc": 0.9999706580567715, "train/cont_pos_loss": 0.00011276255915090807, "train/cont_pred": 0.9944807050833061, "train/cont_rate": 0.9944685750932836, "train/dyn_loss_mean": 13.54708180498721, "train/dyn_loss_std": 9.781407669408997, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.903567089296099, "train/extr_critic_critic_opt_grad_steps": 21905.0, "train/extr_critic_critic_opt_loss": 15839.101365729945, "train/extr_critic_mag": 4.308388250977246, "train/extr_critic_max": 4.308388250977246, "train/extr_critic_mean": 0.7599478392903485, "train/extr_critic_min": -0.38931141237714395, "train/extr_critic_std": 0.9868361972161194, "train/extr_return_normed_mag": 1.8706941177595908, "train/extr_return_normed_max": 1.8706941177595908, "train/extr_return_normed_mean": 0.3115594146856621, "train/extr_return_normed_min": -0.175596893917936, "train/extr_return_normed_std": 0.3402534687696998, "train/extr_return_rate": 0.4149229658850983, "train/extr_return_raw_mag": 5.463722022611703, "train/extr_return_raw_max": 5.463722022611703, "train/extr_return_raw_mean": 0.7753983560337949, "train/extr_return_raw_min": -0.6884001555727489, "train/extr_return_raw_std": 1.0230076037236113, "train/extr_reward_mag": 1.0097816043825292, "train/extr_reward_max": 1.0097816043825292, "train/extr_reward_mean": 0.022008491853780267, "train/extr_reward_min": -0.4368987127916137, "train/extr_reward_std": 0.1388527986162634, "train/image_loss_mean": 8.009182994045428, "train/image_loss_std": 12.19578146222812, "train/model_loss_mean": 16.182912684198637, "train/model_loss_std": 16.40556463554724, "train/model_opt_grad_norm": 64.62140451972164, "train/model_opt_grad_steps": 21883.0, "train/model_opt_loss": 14446.081247813667, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 895.5223880597015, "train/policy_entropy_mag": 2.5290966959141974, "train/policy_entropy_max": 2.5290966959141974, "train/policy_entropy_mean": 0.6517276334673611, "train/policy_entropy_min": 0.07937527214413259, "train/policy_entropy_std": 0.6247122883796692, "train/policy_logprob_mag": 7.438382130950244, "train/policy_logprob_max": -0.009455812914269184, "train/policy_logprob_mean": -0.6508289933649462, "train/policy_logprob_min": -7.438382130950244, "train/policy_logprob_std": 1.1481686714869828, "train/policy_randomness_mag": 0.8926601463289403, "train/policy_randomness_max": 0.8926601463289403, "train/policy_randomness_mean": 0.23003125357538906, "train/policy_randomness_min": 0.028015987933682863, "train/policy_randomness_std": 0.22049602332399854, "train/post_ent_mag": 57.405177443774775, "train/post_ent_max": 57.405177443774775, "train/post_ent_mean": 39.757083892822266, "train/post_ent_min": 21.47292411861135, "train/post_ent_std": 6.686231129205049, "train/prior_ent_mag": 66.96628325732786, "train/prior_ent_max": 66.96628325732786, "train/prior_ent_mean": 53.403070762975894, "train/prior_ent_min": 34.23195508700698, "train/prior_ent_std": 5.8324087982747095, "train/rep_loss_mean": 13.54708180498721, "train/rep_loss_std": 9.781407669408997, "train/reward_avg": 0.016079757379979562, "train/reward_loss_mean": 0.04520433993815486, "train/reward_loss_std": 0.22944465768871022, "train/reward_max_data": 1.005970150677126, "train/reward_max_pred": 1.002732478860599, "train/reward_neg_acc": 0.9942345828262728, "train/reward_neg_loss": 0.02659247389563651, "train/reward_pos_acc": 0.9575210369344967, "train/reward_pos_loss": 0.9049606234280031, "train/reward_pred": 0.015331994200041934, "train/reward_rate": 0.02103253264925373, "eval_stats/sum_log_reward": 4.599999971687794, "eval_stats/max_log_achievement_collect_drink": 7.375, "eval_stats/max_log_achievement_collect_sapling": 2.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.3125, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 4.877963874605484e-05, "report/cont_loss_std": 0.0014451815513893962, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005868192529305816, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.613960118149407e-05, "report/cont_pred": 0.9950753450393677, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 10.47745418548584, "report/dyn_loss_std": 9.88165283203125, "report/image_loss_mean": 6.536931991577148, "report/image_loss_std": 10.390061378479004, "report/model_loss_mean": 12.858863830566406, "report/model_loss_std": 14.976372718811035, "report/post_ent_mag": 60.543540954589844, "report/post_ent_max": 60.543540954589844, "report/post_ent_mean": 41.94575500488281, "report/post_ent_min": 18.394737243652344, "report/post_ent_std": 7.577078819274902, "report/prior_ent_mag": 67.06904602050781, "report/prior_ent_max": 67.06904602050781, "report/prior_ent_mean": 52.8105354309082, "report/prior_ent_min": 32.80850601196289, "report/prior_ent_std": 6.811382293701172, "report/rep_loss_mean": 10.47745418548584, "report/rep_loss_std": 9.88165283203125, "report/reward_avg": 0.00761718675494194, "report/reward_loss_mean": 0.0354120209813118, "report/reward_loss_std": 0.1735534518957138, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0020489692687988, "report/reward_neg_acc": 0.9940711855888367, "report/reward_neg_loss": 0.02642550691962242, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7932748794555664, "report/reward_pred": 0.007540442515164614, "report/reward_rate": 0.01171875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 4.5486103772418573e-05, "eval/cont_loss_std": 0.0011743755312636495, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00770746823400259, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.270763784257724e-07, "eval/cont_pred": 0.9941849112510681, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.488080978393555, "eval/dyn_loss_std": 11.348335266113281, "eval/image_loss_mean": 19.020790100097656, "eval/image_loss_std": 33.558746337890625, "eval/model_loss_mean": 29.608882904052734, "eval/model_loss_std": 37.5789680480957, "eval/post_ent_mag": 57.523902893066406, "eval/post_ent_max": 57.523902893066406, "eval/post_ent_mean": 39.15850830078125, "eval/post_ent_min": 21.639636993408203, "eval/post_ent_std": 6.2443413734436035, "eval/prior_ent_mag": 66.72280883789062, "eval/prior_ent_max": 66.72280883789062, "eval/prior_ent_mean": 54.62085723876953, "eval/prior_ent_min": 36.14669418334961, "eval/prior_ent_std": 5.755131244659424, "eval/rep_loss_mean": 17.488080978393555, "eval/rep_loss_std": 11.348335266113281, "eval/reward_avg": 0.02519531175494194, "eval/reward_loss_mean": 0.09519718587398529, "eval/reward_loss_std": 0.5991631746292114, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.999863862991333, "eval/reward_neg_acc": 0.9969818592071533, "eval/reward_neg_loss": 0.04929604008793831, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 1.6160553693771362, "eval/reward_pred": 0.02081703022122383, "eval/reward_rate": 0.029296875, "replay/size": 362225.0, "replay/inserts": 21440.0, "replay/samples": 21440.0, "replay/insert_wait_avg": 1.419624730722228e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.03610862902741e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 69520.0, "eval_replay/inserts": 3952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2664177157135628e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3642144203186, "timer/env.step_count": 2680.0, "timer/env.step_total": 265.48839020729065, "timer/env.step_frac": 0.26539173071193206, "timer/env.step_avg": 0.0990628321668995, "timer/env.step_min": 0.024532794952392578, "timer/env.step_max": 3.3296315670013428, "timer/replay._sample_count": 21440.0, "timer/replay._sample_total": 11.949487924575806, "timer/replay._sample_frac": 0.01194513733330633, "timer/replay._sample_avg": 0.0005573455188701402, "timer/replay._sample_min": 0.0003681182861328125, "timer/replay._sample_max": 0.00943303108215332, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3174.0, "timer/agent.policy_total": 55.655771017074585, "timer/agent.policy_frac": 0.055635507762865605, "timer/agent.policy_avg": 0.01753489950128374, "timer/agent.policy_min": 0.009880781173706055, "timer/agent.policy_max": 0.10583662986755371, "timer/dataset_train_count": 1340.0, "timer/dataset_train_total": 0.16686153411865234, "timer/dataset_train_frac": 0.0001668007828682113, "timer/dataset_train_avg": 0.00012452353292436742, "timer/dataset_train_min": 0.00010538101196289062, "timer/dataset_train_max": 0.00047206878662109375, "timer/agent.train_count": 1340.0, "timer/agent.train_total": 610.4335415363312, "timer/agent.train_frac": 0.6102112937836939, "timer/agent.train_avg": 0.45554741905696355, "timer/agent.train_min": 0.4426248073577881, "timer/agent.train_max": 1.568253517150879, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4663970470428467, "timer/agent.report_frac": 0.00046622724035876267, "timer/agent.report_avg": 0.23319852352142334, "timer/agent.report_min": 0.22196435928344727, "timer/agent.report_max": 0.24443268775939941, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.026813545448976e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 21.431912119246512}
{"step": 362792, "time": 17370.90083050728, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 363504, "time": 17396.736047506332, "episode/length": 232.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 363696, "time": 17404.9374024868, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 363896, "time": 17413.098095178604, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 364000, "time": 17418.447900772095, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 364040, "time": 17421.14531326294, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 364168, "time": 17427.067509651184, "episode/length": 33.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 364272, "time": 17432.54421520233, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 364360, "time": 17436.832097530365, "episode/length": 290.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 364416, "time": 17440.573749780655, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 364744, "time": 17453.144530057907, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 365240, "time": 17471.858632802963, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 365304, "time": 17475.583453655243, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 365544, "time": 17485.407081365585, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 365696, "time": 17492.590605974197, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 365808, "time": 17498.544333696365, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 365840, "time": 17501.73048734665, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 365936, "time": 17507.250253677368, "episode/length": 48.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 365952, "time": 17509.320863962173, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 366536, "time": 17530.4649579525, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 366752, "time": 17539.606265306473, "episode/length": 338.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 367056, "time": 17551.48417043686, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 367184, "time": 17557.395783424377, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 367232, "time": 17560.603579998016, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 367584, "time": 17574.0461704731, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 367712, "time": 17580.00348854065, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 368008, "time": 17591.383795022964, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 368024, "time": 17593.424648046494, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 368464, "time": 17610.32819366455, "episode/length": 213.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.985981308411215, "episode/intrinsic_return": 0.0}
{"step": 368584, "time": 17615.790565490723, "episode/length": 168.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 368872, "time": 17628.664866924286, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 368992, "time": 17634.498358249664, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 369008, "time": 17636.702568531036, "episode/length": 243.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 369176, "time": 17643.96634244919, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 369368, "time": 17652.120263814926, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 369728, "time": 17666.131484508514, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 369752, "time": 17668.527527570724, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 369832, "time": 17672.86406302452, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 17696.723937511444, "eval_episode/length": 35.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 370032, "time": 17703.510120630264, "eval_episode/length": 140.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9645390070921985}
{"step": 370032, "time": 17706.052775144577, "eval_episode/length": 161.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 370032, "time": 17706.060703992844, "eval_episode/length": 161.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 370032, "time": 17710.41056704521, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 370032, "time": 17712.232076644897, "eval_episode/length": 188.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 370032, "time": 17713.988602876663, "eval_episode/length": 190.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 370032, "time": 17713.99767589569, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 370064, "time": 17715.1018178463, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 370560, "time": 17733.687805891037, "episode/length": 195.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 370608, "time": 17736.814524412155, "episode/length": 199.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 370656, "time": 17740.072060585022, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 370832, "time": 17747.75727248192, "episode/length": 33.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 371088, "time": 17758.206316947937, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 371192, "time": 17763.193276405334, "episode/length": 227.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 371216, "time": 17765.75658917427, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 371256, "time": 17768.44008231163, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 371400, "time": 17774.91187286377, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 372176, "time": 17803.06404709816, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 372296, "time": 17808.46160674095, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 372392, "time": 17813.21767258644, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 372416, "time": 17815.892554998398, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 372432, "time": 17818.180442094803, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 372504, "time": 17822.0448949337, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 372720, "time": 17831.12849712372, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 372816, "time": 17835.98714518547, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 372912, "time": 17840.766379117966, "episode/length": 50.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 373288, "time": 17854.90873336792, "episode/length": 70.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9295774647887324, "episode/intrinsic_return": 0.0}
{"step": 373560, "time": 17865.731781482697, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 373824, "time": 17876.491904258728, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 373896, "time": 17880.46192383766, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 373976, "time": 17884.86252474785, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 374064, "time": 17889.70609855652, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 374608, "time": 17909.84557723999, "episode/length": 271.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 374656, "time": 17912.95418405533, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 375048, "time": 17927.726681947708, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 375296, "time": 17937.99294281006, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 375360, "time": 17941.787143707275, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 375864, "time": 17960.460353136063, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 376040, "time": 17968.024401664734, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 376224, "time": 17976.105847597122, "episode/length": 413.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 376288, "time": 17979.869247198105, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 376304, "time": 17982.026465654373, "episode/length": 300.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9900332225913622, "episode/intrinsic_return": 0.0}
{"step": 376400, "time": 17986.875453948975, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 376488, "time": 17991.304547786713, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 376904, "time": 18008.539744138718, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 377440, "time": 18028.77381181717, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 377552, "time": 18034.14940214157, "episode/length": 155.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 377640, "time": 18038.46866583824, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 377656, "time": 18040.51898574829, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 377688, "time": 18043.167746543884, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 377728, "time": 18046.319729328156, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 377944, "time": 18055.117751598358, "episode/length": 37.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 377976, "time": 18058.07269334793, "episode/length": 241.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 378392, "time": 18074.138939142227, "episode/length": 185.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 379184, "time": 18103.084885835648, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 379256, "time": 18106.898968935013, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 379272, "time": 18109.099331617355, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 379288, "time": 18111.278232336044, "episode/length": 216.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 379728, "time": 18128.172317266464, "episode/length": 222.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 379736, "time": 18129.827199220657, "episode/length": 286.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 380000, "time": 18140.69313764572, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 18163.84199142456, "eval_episode/length": 164.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 380016, "time": 18165.808059692383, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 380016, "time": 18167.545211553574, "eval_episode/length": 174.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 380016, "time": 18169.348922252655, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 380016, "time": 18171.55516076088, "eval_episode/length": 191.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 380016, "time": 18173.640998125076, "eval_episode/length": 202.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 380016, "time": 18175.69015645981, "eval_episode/length": 212.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 380016, "time": 18178.116015195847, "eval_episode/length": 38.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 380304, "time": 18187.783451080322, "episode/length": 290.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9828178694158075, "episode/intrinsic_return": 0.0}
{"step": 380536, "time": 18196.937255859375, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 380640, "time": 18202.45574259758, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 380680, "time": 18205.264655828476, "episode/length": 177.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 380984, "time": 18217.129338502884, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 381080, "time": 18221.93234372139, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 381136, "time": 18225.716846704483, "episode/length": 141.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 381952, "time": 18254.89301943779, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 381968, "time": 18257.09205698967, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 382056, "time": 18261.42017173767, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 382216, "time": 18268.548380851746, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 382272, "time": 18272.195913553238, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 382360, "time": 18276.495917081833, "episode/length": 327.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9969512195121951, "episode/intrinsic_return": 0.0}
{"step": 382424, "time": 18280.13258075714, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 382552, "time": 18286.133922100067, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 382688, "time": 18292.469623088837, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 382848, "time": 18299.519755363464, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 383576, "time": 18325.530164003372, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 383648, "time": 18329.870408058167, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 383816, "time": 18336.98902988434, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 383872, "time": 18340.703431367874, "episode/length": 164.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 384024, "time": 18347.28746509552, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 384072, "time": 18350.651907920837, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 384320, "time": 18360.862177610397, "episode/length": 92.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 384376, "time": 18364.073779582977, "episode/length": 190.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 384457, "time": 18369.393589019775, "train_stats/sum_log_reward": 5.159828988914816, "train_stats/max_log_achievement_collect_drink": 5.461538461538462, "train_stats/max_log_achievement_collect_sapling": 2.9401709401709404, "train_stats/max_log_achievement_collect_stone": 0.03418803418803419, "train_stats/max_log_achievement_collect_wood": 7.05982905982906, "train_stats/max_log_achievement_defeat_skeleton": 0.008547008547008548, "train_stats/max_log_achievement_defeat_zombie": 0.36752136752136755, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.1111111111111111, "train_stats/max_log_achievement_make_wood_sword": 0.03418803418803419, "train_stats/max_log_achievement_place_plant": 2.8205128205128207, "train_stats/max_log_achievement_place_table": 2.786324786324786, "train_stats/max_log_achievement_wake_up": 1.3333333333333333, "train_stats/mean_log_entropy": 0.5660175896353192, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.426463407628677, "train/action_min": 0.0, "train/action_std": 3.310258200939964, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04996116777115008, "train/actor_opt_grad_steps": 23255.0, "train/actor_opt_loss": -2.116888236418805, "train/adv_mag": 0.7441259508623796, "train/adv_max": 0.7235322853221613, "train/adv_mean": 0.004336419424041249, "train/adv_min": -0.5402931382550913, "train/adv_std": 0.07929134856471244, "train/cont_avg": 0.9944206686580882, "train/cont_loss_mean": 0.00032176214384971964, "train/cont_loss_std": 0.009345162982257574, "train/cont_neg_acc": 0.9896183496012407, "train/cont_neg_loss": 0.03441137174345787, "train/cont_pos_acc": 0.9999494460575721, "train/cont_pos_loss": 0.00013440639045449095, "train/cont_pred": 0.9944199415690759, "train/cont_rate": 0.9944206686580882, "train/dyn_loss_mean": 13.442164084490608, "train/dyn_loss_std": 9.790013018776389, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9091044541667489, "train/extr_critic_critic_opt_grad_steps": 23255.0, "train/extr_critic_critic_opt_loss": 15682.230569278492, "train/extr_critic_mag": 4.433139587149901, "train/extr_critic_max": 4.433139587149901, "train/extr_critic_mean": 0.83578310950714, "train/extr_critic_min": -0.37626654260298786, "train/extr_critic_std": 0.9797639732851702, "train/extr_return_normed_mag": 1.8660163423594307, "train/extr_return_normed_max": 1.8660163423594307, "train/extr_return_normed_mean": 0.32092554878224344, "train/extr_return_normed_min": -0.18797339608564095, "train/extr_return_normed_std": 0.33464393633253436, "train/extr_return_rate": 0.4514232201173025, "train/extr_return_raw_mag": 5.53421352891361, "train/extr_return_raw_max": 5.53421352891361, "train/extr_return_raw_mean": 0.8489282661501099, "train/extr_return_raw_min": -0.6945497492218718, "train/extr_return_raw_std": 1.014947936815374, "train/extr_reward_mag": 1.0115454039152931, "train/extr_reward_max": 1.0115454039152931, "train/extr_reward_mean": 0.02319382386528613, "train/extr_reward_min": -0.460634824107675, "train/extr_reward_std": 0.142959672574173, "train/image_loss_mean": 7.645575000959284, "train/image_loss_std": 11.879200556698967, "train/model_loss_mean": 15.757250834913815, "train/model_loss_std": 16.06611118597143, "train/model_opt_grad_norm": 56.02139472961426, "train/model_opt_grad_steps": 23232.125, "train/model_opt_loss": 12521.851526596967, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 790.4411764705883, "train/policy_entropy_mag": 2.500931597807828, "train/policy_entropy_max": 2.500931597807828, "train/policy_entropy_mean": 0.6702058302129016, "train/policy_entropy_min": 0.07937524758060188, "train/policy_entropy_std": 0.6551246577325989, "train/policy_logprob_mag": 7.438381861237919, "train/policy_logprob_max": -0.009455773232997778, "train/policy_logprob_mean": -0.6701165404828155, "train/policy_logprob_min": -7.438381861237919, "train/policy_logprob_std": 1.1645270962925518, "train/policy_randomness_mag": 0.8827191043426009, "train/policy_randomness_max": 0.8827191043426009, "train/policy_randomness_mean": 0.2365532473606222, "train/policy_randomness_min": 0.02801597923697794, "train/policy_randomness_std": 0.23123025444938855, "train/post_ent_mag": 57.58016914479873, "train/post_ent_max": 57.58016914479873, "train/post_ent_mean": 40.13098192214966, "train/post_ent_min": 21.596622565213373, "train/post_ent_std": 6.853977936155656, "train/prior_ent_mag": 67.1711233363432, "train/prior_ent_max": 67.1711233363432, "train/prior_ent_mean": 53.65358243269079, "train/prior_ent_min": 34.33956738079296, "train/prior_ent_std": 5.660887728719151, "train/rep_loss_mean": 13.442164084490608, "train/rep_loss_std": 9.790013018776389, "train/reward_avg": 0.01725068934576805, "train/reward_loss_mean": 0.04605568481116172, "train/reward_loss_std": 0.22970072508734815, "train/reward_max_data": 1.0117647086872774, "train/reward_max_pred": 1.0036105022710913, "train/reward_neg_acc": 0.9942940412198796, "train/reward_neg_loss": 0.026622492525562206, "train/reward_pos_acc": 0.9568669270066654, "train/reward_pos_loss": 0.8996233436114648, "train/reward_pred": 0.016512307256241057, "train/reward_rate": 0.022353228400735295, "train_stats/max_log_achievement_collect_coal": 0.011904761904761904, "eval_stats/sum_log_reward": 4.662499912083149, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.3125, "eval_stats/max_log_achievement_collect_sapling": 2.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.4375, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_stone": 0.08, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.0001670791389187798, "report/cont_loss_std": 0.004528466146439314, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.025184396654367447, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.9629349480965175e-05, "report/cont_pred": 0.9942590594291687, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 15.647160530090332, "report/dyn_loss_std": 9.936312675476074, "report/image_loss_mean": 8.756420135498047, "report/image_loss_std": 12.136253356933594, "report/model_loss_mean": 18.191267013549805, "report/model_loss_std": 16.28589630126953, "report/post_ent_mag": 59.4122200012207, "report/post_ent_max": 59.4122200012207, "report/post_ent_mean": 39.920448303222656, "report/post_ent_min": 21.039173126220703, "report/post_ent_std": 6.626465797424316, "report/prior_ent_mag": 67.69556427001953, "report/prior_ent_max": 67.69556427001953, "report/prior_ent_mean": 55.42164611816406, "report/prior_ent_min": 36.63665771484375, "report/prior_ent_std": 5.578544616699219, "report/rep_loss_mean": 15.647160530090332, "report/rep_loss_std": 9.936312675476074, "report/reward_avg": 0.0224609375, "report/reward_loss_mean": 0.04638393223285675, "report/reward_loss_std": 0.19602937996387482, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.057175874710083, "report/reward_neg_acc": 0.9929719567298889, "report/reward_neg_loss": 0.027806522324681282, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7072092294692993, "report/reward_pred": 0.02330506034195423, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0005107725155539811, "eval/cont_loss_std": 0.01316028367727995, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.09351950883865356, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.439989399746992e-05, "eval/cont_pred": 0.9954450726509094, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.981855392456055, "eval/dyn_loss_std": 11.242951393127441, "eval/image_loss_mean": 13.141674041748047, "eval/image_loss_std": 21.45853614807129, "eval/model_loss_mean": 23.41690444946289, "eval/model_loss_std": 26.043275833129883, "eval/post_ent_mag": 52.84269332885742, "eval/post_ent_max": 52.84269332885742, "eval/post_ent_mean": 38.38519287109375, "eval/post_ent_min": 21.40859603881836, "eval/post_ent_std": 5.859528064727783, "eval/prior_ent_mag": 67.69556427001953, "eval/prior_ent_max": 67.69556427001953, "eval/prior_ent_mean": 52.724365234375, "eval/prior_ent_min": 33.71704864501953, "eval/prior_ent_std": 5.634295463562012, "eval/rep_loss_mean": 16.981855392456055, "eval/rep_loss_std": 11.242951393127441, "eval/reward_avg": 0.01992187462747097, "eval/reward_loss_mean": 0.0856056660413742, "eval/reward_loss_std": 0.4346145689487457, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0051767826080322, "eval/reward_neg_acc": 0.9909909963607788, "eval/reward_neg_loss": 0.04918507859110832, "eval/reward_pos_acc": 0.8399999737739563, "eval/reward_pos_loss": 1.5409722328186035, "eval/reward_pred": 0.013537779450416565, "eval/reward_rate": 0.0244140625, "replay/size": 383953.0, "replay/inserts": 21728.0, "replay/samples": 21728.0, "replay/insert_wait_avg": 1.4260235696548215e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.91106995988489e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 72896.0, "eval_replay/inserts": 3376.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2508500808788138e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4819774627686, "timer/env.step_count": 2716.0, "timer/env.step_total": 265.45122241973877, "timer/env.step_frac": 0.2653233425482841, "timer/env.step_avg": 0.09773609072891708, "timer/env.step_min": 0.0244443416595459, "timer/env.step_max": 2.1895956993103027, "timer/replay._sample_count": 21728.0, "timer/replay._sample_total": 12.148138523101807, "timer/replay._sample_frac": 0.012142286214799788, "timer/replay._sample_avg": 0.0005591006315860551, "timer/replay._sample_min": 0.0003819465637207031, "timer/replay._sample_max": 0.029671430587768555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3138.0, "timer/agent.policy_total": 54.9389705657959, "timer/agent.policy_frac": 0.05491250397645506, "timer/agent.policy_avg": 0.01750763880363158, "timer/agent.policy_min": 0.009839773178100586, "timer/agent.policy_max": 0.09390401840209961, "timer/dataset_train_count": 1358.0, "timer/dataset_train_total": 0.1727428436279297, "timer/dataset_train_frac": 0.00017265962557967023, "timer/dataset_train_avg": 0.00012720386128713528, "timer/dataset_train_min": 0.00011014938354492188, "timer/dataset_train_max": 0.0009603500366210938, "timer/agent.train_count": 1358.0, "timer/agent.train_total": 614.1307809352875, "timer/agent.train_frac": 0.6138349263349339, "timer/agent.train_avg": 0.4522317974486653, "timer/agent.train_min": 0.43888425827026367, "timer/agent.train_max": 1.562910556793213, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4762461185455322, "timer/agent.report_frac": 0.00047601668922942197, "timer/agent.report_avg": 0.2381230592727661, "timer/agent.report_min": 0.2304227352142334, "timer/agent.report_max": 0.24582338333129883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.3124217368873543e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 21.717210378459516}
{"step": 384608, "time": 18374.632116556168, "episode/length": 28.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 384984, "time": 18389.023196935654, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 385080, "time": 18395.384896039963, "episode/length": 298.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9866220735785953, "episode/intrinsic_return": 0.0}
{"step": 385176, "time": 18400.214259386063, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 385224, "time": 18403.296588897705, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 385288, "time": 18407.134070158005, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 385400, "time": 18412.96982526779, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 385800, "time": 18428.0568215847, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 386040, "time": 18437.800691127777, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 386368, "time": 18450.832001686096, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 386440, "time": 18454.672331094742, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 386696, "time": 18464.900318145752, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 386728, "time": 18467.636937856674, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 386856, "time": 18473.61251449585, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 387208, "time": 18487.244589805603, "episode/length": 239.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 387392, "time": 18495.265204429626, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 387488, "time": 18500.050092935562, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 387560, "time": 18503.766672372818, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 387736, "time": 18511.422818660736, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 388120, "time": 18526.091140031815, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 388200, "time": 18530.359687566757, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 388296, "time": 18535.164309740067, "episode/length": 179.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 388440, "time": 18541.721922397614, "episode/length": 39.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 388480, "time": 18544.849396944046, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 388680, "time": 18552.874834775925, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 388888, "time": 18561.50439095497, "episode/length": 143.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 388960, "time": 18565.729224205017, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 389552, "time": 18587.503632068634, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 389672, "time": 18593.005378723145, "episode/length": 263.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 389832, "time": 18600.059509038925, "episode/length": 168.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 18622.462933778763, "eval_episode/length": 34.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 390000, "time": 18631.973093032837, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 390000, "time": 18634.102620363235, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 390000, "time": 18636.465341567993, "eval_episode/length": 189.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.968421052631579}
{"step": 390000, "time": 18638.56747198105, "eval_episode/length": 198.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 390000, "time": 18640.12646961212, "eval_episode/length": 164.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 390000, "time": 18642.107986688614, "eval_episode/length": 209.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 390000, "time": 18644.95088982582, "eval_episode/length": 237.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 390024, "time": 18645.548228263855, "episode/length": 132.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 390040, "time": 18647.74232673645, "episode/length": 199.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 390096, "time": 18651.51221036911, "episode/length": 224.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 390360, "time": 18662.04883790016, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 390440, "time": 18666.294646263123, "episode/length": 42.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 390544, "time": 18671.789530277252, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 390672, "time": 18677.73845601082, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 390840, "time": 18684.69361615181, "episode/length": 145.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 391208, "time": 18698.684185743332, "episode/length": 171.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 391624, "time": 18714.42433166504, "episode/length": 197.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 391672, "time": 18717.726006031036, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 391728, "time": 18721.943585157394, "episode/length": 147.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 391888, "time": 18728.952906847, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 392592, "time": 18754.44438767433, "episode/length": 239.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 392736, "time": 18760.768602609634, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 392912, "time": 18768.369089841843, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 393320, "time": 18785.294909477234, "episode/length": 263.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 393368, "time": 18788.622905254364, "episode/length": 417.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9784688995215312, "episode/intrinsic_return": 0.0}
{"step": 393592, "time": 18797.94800925255, "episode/length": 232.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 393624, "time": 18800.67351603508, "episode/length": 243.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 393856, "time": 18810.51202058792, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 394288, "time": 18826.779527902603, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 394648, "time": 18840.534876585007, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 394920, "time": 18851.433959007263, "episode/length": 250.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9880478087649402, "episode/intrinsic_return": 0.0}
{"step": 394952, "time": 18854.090164661407, "episode/length": 37.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 394952, "time": 18854.097600460052, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 395112, "time": 18862.875571489334, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 395192, "time": 18867.23429965973, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700854700854701, "episode/intrinsic_return": 0.0}
{"step": 395248, "time": 18871.062943458557, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 395720, "time": 18888.35520172119, "episode/length": 178.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 395856, "time": 18894.67243385315, "episode/length": 310.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9839228295819936, "episode/intrinsic_return": 0.0}
{"step": 396016, "time": 18901.931221961975, "episode/length": 132.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 396448, "time": 18918.131546020508, "episode/length": 186.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 396552, "time": 18923.066741228104, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 396736, "time": 18931.250108242035, "episode/length": 35.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 396776, "time": 18933.986451387405, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 396872, "time": 18938.759865283966, "episode/length": 39.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 397040, "time": 18946.548060894012, "episode/length": 264.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 397064, "time": 18949.262130737305, "episode/length": 150.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 397096, "time": 18952.446699619293, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 397840, "time": 18979.668035030365, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 398040, "time": 18987.87814116478, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 398208, "time": 18995.36166858673, "episode/length": 183.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 398384, "time": 19002.984224557877, "episode/length": 408.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9975550122249389, "episode/intrinsic_return": 0.0}
{"step": 398552, "time": 19010.023918151855, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 398568, "time": 19012.180695533752, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 398616, "time": 19015.5112285614, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 398728, "time": 19021.136528253555, "episode/length": 42.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 398872, "time": 19027.54927921295, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 399104, "time": 19037.16920733452, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 399264, "time": 19044.309309005737, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 399560, "time": 19055.94820833206, "episode/length": 168.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 400024, "time": 19073.283108472824, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 400056, "time": 19076.04310464859, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 19093.761402845383, "eval_episode/length": 36.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.972972972972973}
{"step": 400088, "time": 19095.505092144012, "eval_episode/length": 39.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 400088, "time": 19102.46343064308, "eval_episode/length": 161.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9567901234567902}
{"step": 400088, "time": 19105.093718528748, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 400088, "time": 19107.014364004135, "eval_episode/length": 191.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 400088, "time": 19110.10973739624, "eval_episode/length": 219.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9681818181818181}
{"step": 400088, "time": 19111.997667074203, "eval_episode/length": 225.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 400088, "time": 19114.980371952057, "eval_episode/length": 220.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9864253393665159}
{"step": 400128, "time": 19116.570083618164, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 400424, "time": 19127.94726705551, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 400592, "time": 19135.533187150955, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 400664, "time": 19139.380962610245, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 400664, "time": 19139.390364408493, "episode/length": 223.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 400696, "time": 19143.778128385544, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 401336, "time": 19167.06465125084, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 401400, "time": 19170.927822828293, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 401440, "time": 19175.60441493988, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 402048, "time": 19199.157732486725, "episode/length": 252.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 402080, "time": 19201.90202641487, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 402080, "time": 19201.911042690277, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 402160, "time": 19207.938567638397, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 402376, "time": 19216.551506519318, "episode/length": 36.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 402464, "time": 19221.386746883392, "episode/length": 37.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 402664, "time": 19229.782983779907, "episode/length": 165.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 402872, "time": 19238.414683818817, "episode/length": 271.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 402912, "time": 19241.603537797928, "episode/length": 188.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 402920, "time": 19243.225994110107, "episode/length": 184.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 402936, "time": 19245.324421405792, "episode/length": 33.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 403512, "time": 19266.5576941967, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 403752, "time": 19276.260040044785, "episode/length": 160.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 404128, "time": 19291.07834339142, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9680365296803652, "episode/intrinsic_return": 0.0}
{"step": 404160, "time": 19293.740039110184, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 404200, "time": 19296.46343779564, "episode/length": 268.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 404264, "time": 19300.37164759636, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 404560, "time": 19312.34218764305, "episode/length": 36.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 404696, "time": 19318.44380259514, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 404896, "time": 19327.20268058777, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 404944, "time": 19330.453353405, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 405432, "time": 19348.523408412933, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 405456, "time": 19351.183069229126, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 405464, "time": 19352.72880077362, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 405520, "time": 19356.358321905136, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 405800, "time": 19367.39831161499, "episode/length": 137.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 405800, "time": 19367.40372276306, "episode/length": 34.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 405801, "time": 19371.97669005394, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.69629502834234, "train/action_min": 0.0, "train/action_std": 3.5555232557139003, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049323357809755136, "train/actor_opt_grad_steps": 24600.0, "train/actor_opt_loss": 2.8832245782801977, "train/adv_mag": 0.7995548024213404, "train/adv_max": 0.7874931339034461, "train/adv_mean": 0.005533513939423885, "train/adv_min": -0.5035380772630075, "train/adv_std": 0.07945060116568006, "train/cont_avg": 0.9943315319548872, "train/cont_loss_mean": 0.00024651395778603805, "train/cont_loss_std": 0.007378813036217352, "train/cont_neg_acc": 0.9927855362569479, "train/cont_neg_loss": 0.018793107018018076, "train/cont_pos_acc": 0.9999777871863287, "train/cont_pos_loss": 0.0001367134770424499, "train/cont_pred": 0.9943232110568455, "train/cont_rate": 0.9943315319548872, "train/dyn_loss_mean": 13.695123686826319, "train/dyn_loss_std": 9.748666125132626, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9085984662511295, "train/extr_critic_critic_opt_grad_steps": 24600.0, "train/extr_critic_critic_opt_loss": 15979.970247885338, "train/extr_critic_mag": 4.535929905740838, "train/extr_critic_max": 4.535929905740838, "train/extr_critic_mean": 0.9348106648688926, "train/extr_critic_min": -0.3559275740071347, "train/extr_critic_std": 0.9974794455040666, "train/extr_return_normed_mag": 1.8425289804774119, "train/extr_return_normed_max": 1.8425289804774119, "train/extr_return_normed_mean": 0.3406506952710618, "train/extr_return_normed_min": -0.16730055294202684, "train/extr_return_normed_std": 0.33051349973320066, "train/extr_return_rate": 0.5293032665898029, "train/extr_return_raw_mag": 5.658754721620029, "train/extr_return_raw_max": 5.658754721620029, "train/extr_return_raw_mean": 0.9521223687587824, "train/extr_return_raw_min": -0.6399454147295844, "train/extr_return_raw_std": 1.0358701079411614, "train/extr_reward_mag": 1.013801736042912, "train/extr_reward_max": 1.013801736042912, "train/extr_reward_mean": 0.024079192527814916, "train/extr_reward_min": -0.4316774624630921, "train/extr_reward_std": 0.1443885977667077, "train/image_loss_mean": 7.573109132006652, "train/image_loss_std": 11.93780309634101, "train/model_loss_mean": 15.837504279344602, "train/model_loss_std": 16.088669160254916, "train/model_opt_grad_norm": 60.67804432632332, "train/model_opt_grad_steps": 24576.225563909775, "train/model_opt_loss": 12305.494441670582, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 780.0751879699249, "train/policy_entropy_mag": 2.4620827893565473, "train/policy_entropy_max": 2.4620827893565473, "train/policy_entropy_mean": 0.6195892041787169, "train/policy_entropy_min": 0.07937520764824144, "train/policy_entropy_std": 0.6054812537548238, "train/policy_logprob_mag": 7.438382686528945, "train/policy_logprob_max": -0.009455728708745394, "train/policy_logprob_mean": -0.619662078251516, "train/policy_logprob_min": -7.438382686528945, "train/policy_logprob_std": 1.1379197342951495, "train/policy_randomness_mag": 0.8690071769226763, "train/policy_randomness_max": 0.8690071769226763, "train/policy_randomness_mean": 0.21868780255317688, "train/policy_randomness_min": 0.028015965035647378, "train/policy_randomness_std": 0.2137083129999333, "train/post_ent_mag": 57.902684520061754, "train/post_ent_max": 57.902684520061754, "train/post_ent_mean": 40.311834120212644, "train/post_ent_min": 21.45012389448352, "train/post_ent_std": 6.927507655064862, "train/prior_ent_mag": 67.52437321942551, "train/prior_ent_max": 67.52437321942551, "train/prior_ent_mean": 54.04920523507254, "train/prior_ent_min": 34.947092142320216, "train/prior_ent_std": 5.48752899098217, "train/rep_loss_mean": 13.695123686826319, "train/rep_loss_std": 9.748666125132626, "train/reward_avg": 0.016973096688271017, "train/reward_loss_mean": 0.04707439588312816, "train/reward_loss_std": 0.23476083884785945, "train/reward_max_data": 1.006766918906592, "train/reward_max_pred": 1.0037166821329218, "train/reward_neg_acc": 0.994086374017529, "train/reward_neg_loss": 0.02778843239201863, "train/reward_pos_acc": 0.9608550712578279, "train/reward_pos_loss": 0.8987037095808446, "train/reward_pred": 0.016441627752203914, "train/reward_rate": 0.022159891917293232, "train_stats/sum_log_reward": 5.1916666117186345, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.333333333333333, "train_stats/max_log_achievement_collect_sapling": 2.816666666666667, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 6.216666666666667, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.43333333333333335, "train_stats/max_log_achievement_eat_cow": 0.09166666666666666, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.016666666666666666, "train_stats/max_log_achievement_make_wood_sword": 0.5666666666666667, "train_stats/max_log_achievement_place_plant": 2.691666666666667, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.1, "train_stats/max_log_achievement_wake_up": 1.1083333333333334, "train_stats/mean_log_entropy": 0.5438547283411026, "eval_stats/sum_log_reward": 4.474999977275729, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.125, "eval_stats/max_log_achievement_collect_sapling": 2.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.5, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00030462839640676975, "report/cont_loss_std": 0.0061246491968631744, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.8773929696180858e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0003065959317609668, "report/cont_pred": 0.9928774833679199, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.414752960205078, "report/dyn_loss_std": 9.51575756072998, "report/image_loss_mean": 6.172940254211426, "report/image_loss_std": 10.602107048034668, "report/model_loss_mean": 14.269153594970703, "report/model_loss_std": 14.641385078430176, "report/post_ent_mag": 56.33599090576172, "report/post_ent_max": 56.33599090576172, "report/post_ent_mean": 40.740089416503906, "report/post_ent_min": 22.297649383544922, "report/post_ent_std": 6.742170333862305, "report/prior_ent_mag": 68.23294067382812, "report/prior_ent_max": 68.23294067382812, "report/prior_ent_mean": 54.344974517822266, "report/prior_ent_min": 37.09546661376953, "report/prior_ent_std": 5.857563495635986, "report/rep_loss_mean": 13.414752960205078, "report/rep_loss_std": 9.51575756072998, "report/reward_avg": 0.02373046800494194, "report/reward_loss_mean": 0.047057125717401505, "report/reward_loss_std": 0.22228465974330902, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.999752402305603, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.021808356046676636, "report/reward_pos_acc": 0.9655172228813171, "report/reward_pos_loss": 0.9133509993553162, "report/reward_pred": 0.020474525168538094, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 4.2714167648227885e-05, "eval/cont_loss_std": 0.0009385510347783566, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.000505432253703475, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.2261854105163366e-05, "eval/cont_pred": 0.9989821314811707, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 14.340801239013672, "eval/dyn_loss_std": 10.714903831481934, "eval/image_loss_mean": 11.863190650939941, "eval/image_loss_std": 17.59967613220215, "eval/model_loss_mean": 20.508441925048828, "eval/model_loss_std": 22.16463279724121, "eval/post_ent_mag": 56.87371826171875, "eval/post_ent_max": 56.87371826171875, "eval/post_ent_mean": 40.61283874511719, "eval/post_ent_min": 23.558334350585938, "eval/post_ent_std": 6.220967769622803, "eval/prior_ent_mag": 68.23294067382812, "eval/prior_ent_max": 68.23294067382812, "eval/prior_ent_mean": 53.712432861328125, "eval/prior_ent_min": 37.80180358886719, "eval/prior_ent_std": 5.491262435913086, "eval/rep_loss_mean": 14.340801239013672, "eval/rep_loss_std": 10.714903831481934, "eval/reward_avg": 0.02031249925494194, "eval/reward_loss_mean": 0.04072713106870651, "eval/reward_loss_std": 0.3380486071109772, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000343322753906, "eval/reward_neg_acc": 0.9950049519538879, "eval/reward_neg_loss": 0.010438508354127407, "eval/reward_pos_acc": 0.8695652484893799, "eval/reward_pos_loss": 1.358940601348877, "eval/reward_pred": 0.017703350633382797, "eval/reward_rate": 0.0224609375, "replay/size": 405297.0, "replay/inserts": 21344.0, "replay/samples": 21344.0, "replay/insert_wait_avg": 1.433035959189442e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.984149127885856e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 76864.0, "eval_replay/inserts": 3968.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.254761891980325e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2367963790893555e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.5691006183624, "timer/env.step_count": 2668.0, "timer/env.step_total": 270.7294182777405, "timer/env.step_frac": 0.2700356694723192, "timer/env.step_avg": 0.10147279545642447, "timer/env.step_min": 0.02477431297302246, "timer/env.step_max": 3.574583053588867, "timer/replay._sample_count": 21344.0, "timer/replay._sample_total": 11.871830701828003, "timer/replay._sample_frac": 0.011841408930821548, "timer/replay._sample_avg": 0.0005562139571696029, "timer/replay._sample_min": 0.00038623809814453125, "timer/replay._sample_max": 0.009978055953979492, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3164.0, "timer/agent.policy_total": 56.90252447128296, "timer/agent.policy_frac": 0.05675671077054613, "timer/agent.policy_avg": 0.017984362980810038, "timer/agent.policy_min": 0.009780645370483398, "timer/agent.policy_max": 0.13661694526672363, "timer/dataset_train_count": 1334.0, "timer/dataset_train_total": 0.16796112060546875, "timer/dataset_train_frac": 0.00016753071733596622, "timer/dataset_train_avg": 0.00012590788651084615, "timer/dataset_train_min": 0.00010848045349121094, "timer/dataset_train_max": 0.0010881423950195312, "timer/agent.train_count": 1334.0, "timer/agent.train_total": 605.7467455863953, "timer/agent.train_frac": 0.6041945090994567, "timer/agent.train_avg": 0.454083017680956, "timer/agent.train_min": 0.43990492820739746, "timer/agent.train_max": 1.7373933792114258, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4787471294403076, "timer/agent.report_frac": 0.00047752033166095683, "timer/agent.report_avg": 0.2393735647201538, "timer/agent.report_min": 0.2321913242340088, "timer/agent.report_max": 0.24655580520629883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2817452578303626e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 21.288996802839357}
{"step": 406112, "time": 19382.914014816284, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 406320, "time": 19391.690933704376, "episode/length": 219.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9863636363636363, "episode/intrinsic_return": 0.0}
{"step": 406520, "time": 19399.81906604767, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 406816, "time": 19411.85965371132, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 406840, "time": 19414.13698029518, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 407208, "time": 19428.341648817062, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 407432, "time": 19437.86965584755, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 407520, "time": 19442.956399440765, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 407720, "time": 19451.210155963898, "episode/length": 285.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 407752, "time": 19453.7611246109, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 407936, "time": 19462.21841430664, "episode/length": 136.0, "episode/score": 7.1000000461936, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 407936, "time": 19462.22979950905, "episode/length": 176.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 408040, "time": 19468.978783607483, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 408040, "time": 19468.985681772232, "episode/length": 39.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 408528, "time": 19488.97736644745, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 408832, "time": 19501.104091882706, "episode/length": 37.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 409072, "time": 19510.778022766113, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 409144, "time": 19514.608258247375, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 409280, "time": 19521.032803297043, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 409312, "time": 19523.779757976532, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 409440, "time": 19529.86186313629, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 409472, "time": 19532.517131567, "episode/length": 178.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 409496, "time": 19534.699936389923, "episode/length": 194.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 410016, "time": 19555.555307388306, "episode/length": 147.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 19579.52124285698, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 410072, "time": 19581.606526374817, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 410072, "time": 19584.73743700981, "eval_episode/length": 197.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 410072, "time": 19586.6288626194, "eval_episode/length": 204.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9804878048780488}
{"step": 410072, "time": 19588.51689338684, "eval_episode/length": 206.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 410072, "time": 19590.452770233154, "eval_episode/length": 213.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 410072, "time": 19592.464619398117, "eval_episode/length": 223.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9776785714285714}
{"step": 410072, "time": 19594.27853322029, "eval_episode/length": 225.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 410464, "time": 19607.74863386154, "episode/length": 123.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.0}
{"step": 410544, "time": 19612.063388347626, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 410600, "time": 19615.35092663765, "episode/length": 137.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 410656, "time": 19619.21747112274, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 410816, "time": 19626.1527030468, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 411200, "time": 19640.755462408066, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 411240, "time": 19643.514307498932, "episode/length": 270.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 411312, "time": 19647.82253432274, "episode/length": 253.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 411568, "time": 19658.163712978363, "episode/length": 137.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 412184, "time": 19680.625111341476, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 412456, "time": 19691.463086605072, "episode/length": 142.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 412456, "time": 19691.472875356674, "episode/length": 204.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 412624, "time": 19700.657068014145, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 412632, "time": 19702.253256082535, "episode/length": 253.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 412680, "time": 19705.483406066895, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 412880, "time": 19714.290043592453, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 412928, "time": 19717.633791446686, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 413528, "time": 19739.409265995026, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 413800, "time": 19750.49003124237, "episode/length": 167.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 414136, "time": 19763.576187372208, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 414136, "time": 19763.626566410065, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 414288, "time": 19772.468915462494, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 414512, "time": 19781.82590031624, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 414632, "time": 19787.236456632614, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 415208, "time": 19808.55224609375, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 415272, "time": 19812.36905694008, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 415368, "time": 19817.20808672905, "episode/length": 342.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9912536443148688, "episode/intrinsic_return": 0.0}
{"step": 415440, "time": 19821.457750558853, "episode/length": 143.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 415624, "time": 19829.18089056015, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 415832, "time": 19837.73752641678, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9669811320754716, "episode/intrinsic_return": 0.0}
{"step": 416088, "time": 19847.999036073685, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 416312, "time": 19857.2455701828, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 416432, "time": 19863.252588510513, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 416856, "time": 19878.998811006546, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 417256, "time": 19894.374242544174, "episode/length": 203.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 417288, "time": 19897.03142476082, "episode/length": 251.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 417344, "time": 19900.790687322617, "episode/length": 188.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 417368, "time": 19903.043737649918, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 417704, "time": 19916.18751168251, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 417808, "time": 19923.26345348358, "episode/length": 295.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 417864, "time": 19926.399065732956, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 418184, "time": 19938.88209104538, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 418656, "time": 19956.827667951584, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 418712, "time": 19960.261168003082, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 418944, "time": 19970.050314188004, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 418984, "time": 19972.760184288025, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 419024, "time": 19976.028751134872, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 419160, "time": 19982.380543470383, "episode/length": 26.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8518518518518519, "episode/intrinsic_return": 0.0}
{"step": 419240, "time": 19986.75693488121, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 419288, "time": 19990.03961801529, "episode/length": 37.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 419864, "time": 20011.49903678894, "episode/length": 249.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 419992, "time": 20017.483766555786, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 20042.451679706573, "eval_episode/length": 166.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 420056, "time": 20044.15639257431, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 420056, "time": 20047.0310690403, "eval_episode/length": 194.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 420056, "time": 20050.026484012604, "eval_episode/length": 224.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 420056, "time": 20053.165392160416, "eval_episode/length": 258.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9884169884169884}
{"step": 420056, "time": 20055.538573503494, "eval_episode/length": 272.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9853479853479854}
{"step": 420056, "time": 20057.536033391953, "eval_episode/length": 281.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9822695035460993}
{"step": 420056, "time": 20061.204602956772, "eval_episode/length": 162.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 420360, "time": 20071.655655145645, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 420392, "time": 20074.307707071304, "episode/length": 275.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 420560, "time": 20081.80458879471, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 421128, "time": 20102.5070207119, "episode/length": 262.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 421136, "time": 20104.589864730835, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 421456, "time": 20117.084539175034, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 421504, "time": 20120.294650554657, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 421728, "time": 20129.762961387634, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 421768, "time": 20132.421110391617, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 422040, "time": 20143.21579670906, "episode/length": 72.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9315068493150684, "episode/intrinsic_return": 0.0}
{"step": 422272, "time": 20152.767355918884, "episode/length": 444.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 422480, "time": 20161.587953567505, "episode/length": 264.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 422576, "time": 20166.38799571991, "episode/length": 37.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 422592, "time": 20169.001368761063, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 422632, "time": 20171.73700928688, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 422752, "time": 20177.61248397827, "episode/length": 127.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 423112, "time": 20191.30840086937, "episode/length": 246.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 423496, "time": 20206.22107744217, "episode/length": 215.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675925925925926, "episode/intrinsic_return": 0.0}
{"step": 423808, "time": 20218.870829343796, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9518072289156626, "episode/intrinsic_return": 0.0}
{"step": 423808, "time": 20218.881006479263, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 423840, "time": 20223.429089784622, "episode/length": 157.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 424056, "time": 20232.038066864014, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 424200, "time": 20238.544582128525, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 424488, "time": 20249.816128730774, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 425024, "time": 20269.79095673561, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 425072, "time": 20272.960096359253, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 425232, "time": 20280.135316848755, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 425240, "time": 20281.755095243454, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 425320, "time": 20286.078015565872, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 425432, "time": 20291.46582198143, "episode/length": 241.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 426024, "time": 20314.587789058685, "episode/length": 227.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 426064, "time": 20317.83514738083, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 426216, "time": 20324.715230941772, "episode/length": 148.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 426520, "time": 20336.74559187889, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 426544, "time": 20339.465037584305, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 426616, "time": 20343.282583475113, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 426848, "time": 20352.89490890503, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 427208, "time": 20366.44411301613, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 427305, "time": 20372.41380047798, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4796147099247685, "train/action_min": 0.0, "train/action_std": 3.320278208344071, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04829340257026531, "train/actor_opt_grad_steps": 25940.0, "train/actor_opt_loss": -2.153817714585198, "train/adv_mag": 0.7170497289410344, "train/adv_max": 0.6978577922891688, "train/adv_mean": 0.0040400049696102175, "train/adv_min": -0.5188055444646764, "train/adv_std": 0.0764045931674816, "train/cont_avg": 0.993894675925926, "train/cont_loss_mean": 0.00015438625398816073, "train/cont_loss_std": 0.0044816743621019575, "train/cont_neg_acc": 0.9965843624538846, "train/cont_neg_loss": 0.011892301991102376, "train/cont_pos_acc": 0.9999854357154281, "train/cont_pos_loss": 6.936370576469202e-05, "train/cont_pred": 0.9939112928178575, "train/cont_rate": 0.993894675925926, "train/dyn_loss_mean": 13.431889088948568, "train/dyn_loss_std": 9.644497037816931, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8537975015463652, "train/extr_critic_critic_opt_grad_steps": 25940.0, "train/extr_critic_critic_opt_loss": 15922.704701967592, "train/extr_critic_mag": 4.660376728905572, "train/extr_critic_max": 4.660376728905572, "train/extr_critic_mean": 1.0217987846445153, "train/extr_critic_min": -0.3648573946069788, "train/extr_critic_std": 1.0901378984804506, "train/extr_return_normed_mag": 1.8072991123905888, "train/extr_return_normed_max": 1.8072991123905888, "train/extr_return_normed_mean": 0.34672363279042423, "train/extr_return_normed_min": -0.1778844344947073, "train/extr_return_normed_std": 0.3397513401729089, "train/extr_return_rate": 0.5339448586658195, "train/extr_return_raw_mag": 5.877156020976879, "train/extr_return_raw_max": 5.877156020976879, "train/extr_return_raw_mean": 1.0351650449964735, "train/extr_return_raw_min": -0.704186369975408, "train/extr_return_raw_std": 1.12631537605215, "train/extr_reward_mag": 1.0120694337067782, "train/extr_reward_max": 1.0120694337067782, "train/extr_reward_mean": 0.025372934010293748, "train/extr_reward_min": -0.47994293371836344, "train/extr_reward_std": 0.1500714432310175, "train/image_loss_mean": 7.275337789676808, "train/image_loss_std": 11.462748456884313, "train/model_loss_mean": 15.38371814445213, "train/model_loss_std": 15.551061962268971, "train/model_opt_grad_norm": 60.06291961669922, "train/model_opt_grad_steps": 25914.94074074074, "train/model_opt_loss": 11374.45185546875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 740.7407407407408, "train/policy_entropy_mag": 2.4757275175165248, "train/policy_entropy_max": 2.4757275175165248, "train/policy_entropy_mean": 0.6019476122326322, "train/policy_entropy_min": 0.07937516189283794, "train/policy_entropy_std": 0.60328464684663, "train/policy_logprob_mag": 7.438382780993426, "train/policy_logprob_max": -0.009455703999157305, "train/policy_logprob_mean": -0.6039042399989234, "train/policy_logprob_min": -7.438382780993426, "train/policy_logprob_std": 1.1288858537320738, "train/policy_randomness_mag": 0.87382316854265, "train/policy_randomness_max": 0.87382316854265, "train/policy_randomness_mean": 0.21246109185395418, "train/policy_randomness_min": 0.02801594869406135, "train/policy_randomness_std": 0.21293300677228857, "train/post_ent_mag": 58.26058109424732, "train/post_ent_max": 58.26058109424732, "train/post_ent_mean": 40.865822007921004, "train/post_ent_min": 21.705656376591435, "train/post_ent_std": 6.999769118980125, "train/prior_ent_mag": 67.69188791910807, "train/prior_ent_max": 67.69188791910807, "train/prior_ent_mean": 54.37332633689598, "train/prior_ent_min": 36.058543014526364, "train/prior_ent_std": 5.280814036616572, "train/rep_loss_mean": 13.431889088948568, "train/rep_loss_std": 9.644497037816931, "train/reward_avg": 0.017599826234530797, "train/reward_loss_mean": 0.04909257793592082, "train/reward_loss_std": 0.24333685757937254, "train/reward_max_data": 1.007407409173471, "train/reward_max_pred": 1.003866559487802, "train/reward_neg_acc": 0.99410256323991, "train/reward_neg_loss": 0.029085172216097514, "train/reward_pos_acc": 0.9574446448573359, "train/reward_pos_loss": 0.896847481639297, "train/reward_pred": 0.016879500120153858, "train/reward_rate": 0.022981770833333335, "train_stats/sum_log_reward": 5.407017482804102, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.807017543859649, "train_stats/max_log_achievement_collect_sapling": 2.5964912280701755, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 7.43859649122807, "train_stats/max_log_achievement_defeat_skeleton": 0.008771929824561403, "train_stats/max_log_achievement_defeat_zombie": 0.40350877192982454, "train_stats/max_log_achievement_eat_cow": 0.07894736842105263, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008771929824561403, "train_stats/max_log_achievement_make_wood_sword": 0.8070175438596491, "train_stats/max_log_achievement_place_plant": 2.508771929824561, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.56140350877193, "train_stats/max_log_achievement_wake_up": 1.236842105263158, "train_stats/mean_log_entropy": 0.5363905414154655, "eval_stats/sum_log_reward": 6.224999964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 10.1875, "eval_stats/max_log_achievement_collect_sapling": 3.0625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 9.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_plant": 3.0, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 4.0061972867988516e-06, "report/cont_loss_std": 0.00010990604641847312, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0011873572366312146, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.29162264228944e-07, "report/cont_pred": 0.9970732927322388, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 14.221221923828125, "report/dyn_loss_std": 9.382076263427734, "report/image_loss_mean": 7.2009382247924805, "report/image_loss_std": 10.498220443725586, "report/model_loss_mean": 15.772346496582031, "report/model_loss_std": 14.440428733825684, "report/post_ent_mag": 60.152713775634766, "report/post_ent_max": 60.152713775634766, "report/post_ent_mean": 40.75957489013672, "report/post_ent_min": 22.479995727539062, "report/post_ent_std": 6.823343753814697, "report/prior_ent_mag": 67.5037612915039, "report/prior_ent_max": 67.5037612915039, "report/prior_ent_mean": 55.00680923461914, "report/prior_ent_min": 36.10968017578125, "report/prior_ent_std": 5.3114800453186035, "report/rep_loss_mean": 14.221221923828125, "report/rep_loss_std": 9.382076263427734, "report/reward_avg": 0.0068359375, "report/reward_loss_mean": 0.03867170959711075, "report/reward_loss_std": 0.2306712567806244, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0000495910644531, "report/reward_neg_acc": 0.9980237483978271, "report/reward_neg_loss": 0.03056803159415722, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7220820188522339, "report/reward_pred": 0.007698377128690481, "report/reward_rate": 0.01171875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 8.809418432065286e-06, "eval/cont_loss_std": 0.00023448448337148875, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001619314425624907, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.070370197150623e-07, "eval/cont_pred": 0.9951242208480835, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.931317329406738, "eval/dyn_loss_std": 10.610930442810059, "eval/image_loss_mean": 10.456217765808105, "eval/image_loss_std": 14.651084899902344, "eval/model_loss_mean": 20.08859634399414, "eval/model_loss_std": 19.203550338745117, "eval/post_ent_mag": 55.87956619262695, "eval/post_ent_max": 55.87956619262695, "eval/post_ent_mean": 41.05484390258789, "eval/post_ent_min": 22.183609008789062, "eval/post_ent_std": 6.346700191497803, "eval/prior_ent_mag": 67.5037612915039, "eval/prior_ent_max": 67.5037612915039, "eval/prior_ent_mean": 54.582061767578125, "eval/prior_ent_min": 36.52412414550781, "eval/prior_ent_std": 5.557678699493408, "eval/rep_loss_mean": 15.931317329406738, "eval/rep_loss_std": 10.610930442810059, "eval/reward_avg": 0.02285156212747097, "eval/reward_loss_mean": 0.07357936352491379, "eval/reward_loss_std": 0.3954918086528778, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001457691192627, "eval/reward_neg_acc": 0.9979899525642395, "eval/reward_neg_loss": 0.039971280843019485, "eval/reward_pos_acc": 0.8965517282485962, "eval/reward_pos_loss": 1.2266844511032104, "eval/reward_pred": 0.018803639337420464, "eval/reward_rate": 0.0283203125, "replay/size": 426801.0, "replay/inserts": 21504.0, "replay/samples": 21504.0, "replay/insert_wait_avg": 1.4448582771278563e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.702544229371207e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 81312.0, "eval_replay/inserts": 4448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.26938596903849e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3262033462524414e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4263432025909, "timer/env.step_count": 2688.0, "timer/env.step_total": 262.3988242149353, "timer/env.step_frac": 0.2622869999353849, "timer/env.step_avg": 0.09761861019900867, "timer/env.step_min": 0.024494647979736328, "timer/env.step_max": 3.496206760406494, "timer/replay._sample_count": 21504.0, "timer/replay._sample_total": 11.658961772918701, "timer/replay._sample_frac": 0.011653993172146715, "timer/replay._sample_avg": 0.0005421764217317104, "timer/replay._sample_min": 0.00041794776916503906, "timer/replay._sample_max": 0.03374624252319336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3244.0, "timer/agent.policy_total": 57.42458534240723, "timer/agent.policy_frac": 0.057400113194318876, "timer/agent.policy_avg": 0.017701783397782746, "timer/agent.policy_min": 0.00997161865234375, "timer/agent.policy_max": 0.11507654190063477, "timer/dataset_train_count": 1344.0, "timer/dataset_train_total": 0.17248749732971191, "timer/dataset_train_frac": 0.00017241398979713033, "timer/dataset_train_avg": 0.00012833891170365469, "timer/dataset_train_min": 0.00010776519775390625, "timer/dataset_train_max": 0.0022656917572021484, "timer/agent.train_count": 1344.0, "timer/agent.train_total": 609.5484952926636, "timer/agent.train_frac": 0.6092887291845605, "timer/agent.train_avg": 0.45353310661656515, "timer/agent.train_min": 0.4399592876434326, "timer/agent.train_max": 1.5511765480041504, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4717140197753906, "timer/agent.report_frac": 0.00047151299341571454, "timer/agent.report_avg": 0.2358570098876953, "timer/agent.report_min": 0.22303223609924316, "timer/agent.report_max": 0.24868178367614746, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.5762786865234375e-05, "timer/dataset_eval_frac": 3.5747546141927455e-08, "timer/dataset_eval_avg": 3.5762786865234375e-05, "timer/dataset_eval_min": 3.5762786865234375e-05, "timer/dataset_eval_max": 3.5762786865234375e-05, "fps": 21.494550001824173}
{"step": 427480, "time": 20378.192101716995, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 427688, "time": 20386.86916899681, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 428112, "time": 20403.097239017487, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 428192, "time": 20407.55849981308, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 428264, "time": 20411.391106128693, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 428568, "time": 20423.2965092659, "episode/length": 37.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 428600, "time": 20426.025738716125, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 428800, "time": 20434.673052310944, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 428920, "time": 20440.044507741928, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 428920, "time": 20440.05170607567, "episode/length": 43.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 429264, "time": 20455.32681965828, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 429416, "time": 20462.007898807526, "episode/length": 418.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9928400954653938, "episode/intrinsic_return": 0.0}
{"step": 429656, "time": 20471.80332684517, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 429928, "time": 20482.678776979446, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 20509.365529298782, "eval_episode/length": 139.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 430040, "time": 20512.188313245773, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 430040, "time": 20514.219753980637, "eval_episode/length": 166.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 430040, "time": 20516.69819688797, "eval_episode/length": 184.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 430040, "time": 20519.15625500679, "eval_episode/length": 198.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 430040, "time": 20521.23293375969, "eval_episode/length": 207.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 430040, "time": 20522.87163901329, "eval_episode/length": 208.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 430040, "time": 20526.12490940094, "eval_episode/length": 35.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 430120, "time": 20528.8390314579, "episode/length": 149.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 430200, "time": 20533.22264933586, "episode/length": 250.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 430264, "time": 20536.96281313896, "episode/length": 167.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 430608, "time": 20550.525854587555, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 430760, "time": 20556.98561000824, "episode/length": 186.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 430824, "time": 20560.789060354233, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 431568, "time": 20587.899169921875, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 431696, "time": 20593.793124198914, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 431720, "time": 20595.848980903625, "episode/length": 257.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 431952, "time": 20605.72814631462, "episode/length": 252.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 432008, "time": 20608.97505044937, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 432112, "time": 20614.269887685776, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 432168, "time": 20617.456476688385, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 432912, "time": 20644.528553009033, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 433176, "time": 20654.877331018448, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 433272, "time": 20660.199985027313, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 433376, "time": 20665.448312282562, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 433408, "time": 20668.22598171234, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 433688, "time": 20679.051819086075, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 433704, "time": 20681.310329675674, "episode/length": 40.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 433856, "time": 20688.17926812172, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 434224, "time": 20703.941617250443, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 434296, "time": 20707.806613206863, "episode/length": 441.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 434688, "time": 20722.902446508408, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 434792, "time": 20727.878573417664, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 434816, "time": 20730.387343645096, "episode/length": 140.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 434824, "time": 20732.063516139984, "episode/length": 65.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9393939393939394, "episode/intrinsic_return": 0.0}
{"step": 435128, "time": 20744.057639598846, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 435336, "time": 20752.747759580612, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 435456, "time": 20758.926461458206, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 436032, "time": 20780.076677560806, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 436264, "time": 20789.409348726273, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 436264, "time": 20789.457538843155, "episode/length": 254.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 436264, "time": 20789.477757692337, "episode/length": 300.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 436328, "time": 20797.148257017136, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 436480, "time": 20804.049834251404, "episode/length": 223.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 436984, "time": 20822.908178806305, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 437368, "time": 20837.290812969208, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 437440, "time": 20841.56123495102, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 437576, "time": 20847.588514328003, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 437704, "time": 20853.801908016205, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 437704, "time": 20853.820227861404, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 437768, "time": 20859.504451990128, "episode/length": 303.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 437936, "time": 20866.938596010208, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 438312, "time": 20880.961539268494, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 438696, "time": 20895.422008275986, "episode/length": 123.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9516129032258065, "episode/intrinsic_return": 0.0}
{"step": 438728, "time": 20898.134008169174, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 438856, "time": 20904.072821855545, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 439048, "time": 20912.321422815323, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 439280, "time": 20921.99440550804, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 439328, "time": 20925.218814134598, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 439328, "time": 20925.22824525833, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 439768, "time": 20943.143595695496, "episode/length": 133.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 439808, "time": 20946.272307872772, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 20974.868970632553, "eval_episode/length": 153.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 440024, "time": 20977.74250292778, "eval_episode/length": 180.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9613259668508287}
{"step": 440024, "time": 20979.7912402153, "eval_episode/length": 190.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 440024, "time": 20981.71420288086, "eval_episode/length": 194.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 440024, "time": 20984.047869682312, "eval_episode/length": 207.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 440024, "time": 20985.733976840973, "eval_episode/length": 208.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 440024, "time": 20987.451836824417, "eval_episode/length": 211.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 440024, "time": 20991.384438991547, "eval_episode/length": 263.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9734848484848485}
{"step": 440432, "time": 21005.468978405, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 440672, "time": 21015.200082302094, "episode/length": 226.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 440776, "time": 21020.03394460678, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 440896, "time": 21025.84925341606, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 441008, "time": 21031.40438222885, "episode/length": 149.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 441160, "time": 21037.91261792183, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 441168, "time": 21040.13157439232, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 441504, "time": 21052.805181980133, "episode/length": 346.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942363112391931, "episode/intrinsic_return": 0.0}
{"step": 441584, "time": 21057.092493772507, "episode/length": 52.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 441984, "time": 21072.343173265457, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 442112, "time": 21078.212884664536, "episode/length": 166.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 442288, "time": 21085.68985438347, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 442288, "time": 21085.69938826561, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 442400, "time": 21094.165825128555, "episode/length": 35.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 442520, "time": 21099.675109148026, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 442560, "time": 21102.891525268555, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 442792, "time": 21112.14468884468, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 443344, "time": 21132.73498225212, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 443496, "time": 21139.25432753563, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 443544, "time": 21142.478815078735, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 443744, "time": 21151.18142747879, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 444112, "time": 21165.235030651093, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 444552, "time": 21181.618710041046, "episode/length": 268.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 444560, "time": 21183.689100027084, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 444704, "time": 21190.178148508072, "episode/length": 267.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 444776, "time": 21193.91357588768, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 444936, "time": 21200.80538392067, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 445584, "time": 21224.575239419937, "episode/length": 183.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 445736, "time": 21231.0044734478, "episode/length": 401.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9975124378109452, "episode/intrinsic_return": 0.0}
{"step": 445928, "time": 21239.185088157654, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 445936, "time": 21241.233403921127, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 446032, "time": 21246.127646684647, "episode/length": 36.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 446456, "time": 21261.880934238434, "episode/length": 237.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 446720, "time": 21272.74313020706, "episode/length": 371.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9973118279569892, "episode/intrinsic_return": 0.0}
{"step": 446840, "time": 21278.21499156952, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 446848, "time": 21280.19093823433, "episode/length": 258.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 447088, "time": 21289.85077738762, "episode/length": 268.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 447144, "time": 21293.118069410324, "episode/length": 37.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 447272, "time": 21299.06012582779, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 447512, "time": 21308.707848072052, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 447544, "time": 21311.37531399727, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 448280, "time": 21337.934367895126, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 448488, "time": 21346.518548488617, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 448528, "time": 21349.592073202133, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 448696, "time": 21356.567999839783, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 448816, "time": 21362.628767728806, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 448952, "time": 21368.630088806152, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 449001, "time": 21372.876304626465, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.512136501736111, "train/action_min": 0.0, "train/action_std": 3.3224371751149495, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04908352737073545, "train/actor_opt_grad_steps": 27290.0, "train/actor_opt_loss": -4.242427206591324, "train/adv_mag": 0.7321005554110915, "train/adv_max": 0.7172201578263884, "train/adv_mean": 0.004022364709211009, "train/adv_min": -0.4923394779364268, "train/adv_std": 0.07713190314394457, "train/cont_avg": 0.9941840277777778, "train/cont_loss_mean": 0.00030976686037960193, "train/cont_loss_std": 0.009394901308217884, "train/cont_neg_acc": 0.9937416504930567, "train/cont_neg_loss": 0.03128996969665052, "train/cont_pos_acc": 0.9999417521335461, "train/cont_pos_loss": 0.00016672797237407411, "train/cont_pred": 0.9941612583619577, "train/cont_rate": 0.9941840277777778, "train/dyn_loss_mean": 13.404497196056225, "train/dyn_loss_std": 9.604662096941913, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.903555953502655, "train/extr_critic_critic_opt_grad_steps": 27290.0, "train/extr_critic_critic_opt_loss": 16087.809866898147, "train/extr_critic_mag": 4.692821545071072, "train/extr_critic_max": 4.692821545071072, "train/extr_critic_mean": 1.0137421382798089, "train/extr_critic_min": -0.356866392382869, "train/extr_critic_std": 1.0754287132510432, "train/extr_return_normed_mag": 1.7972000069088405, "train/extr_return_normed_max": 1.7972000069088405, "train/extr_return_normed_mean": 0.34093976252608826, "train/extr_return_normed_min": -0.1580992767104396, "train/extr_return_normed_std": 0.3325240716890053, "train/extr_return_rate": 0.5453901716956386, "train/extr_return_raw_mag": 5.901593324873183, "train/extr_return_raw_max": 5.901593324873183, "train/extr_return_raw_mean": 1.0272157536612616, "train/extr_return_raw_min": -0.643314778804779, "train/extr_return_raw_std": 1.1131656191967152, "train/extr_reward_mag": 1.01368632139983, "train/extr_reward_max": 1.01368632139983, "train/extr_reward_mean": 0.026040245144179575, "train/extr_reward_min": -0.4746136356283117, "train/extr_reward_std": 0.15128610774322793, "train/image_loss_mean": 7.140844917297363, "train/image_loss_std": 11.626107851664225, "train/model_loss_mean": 15.231961497554073, "train/model_loss_std": 15.653253753096969, "train/model_opt_grad_norm": 56.344906376026294, "train/model_opt_grad_steps": 27263.814814814814, "train/model_opt_loss": 10944.867241753473, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 717.5925925925926, "train/policy_entropy_mag": 2.4574020209135834, "train/policy_entropy_max": 2.4574020209135834, "train/policy_entropy_mean": 0.6277667317125533, "train/policy_entropy_min": 0.07937518650734866, "train/policy_entropy_std": 0.6252889661877243, "train/policy_logprob_mag": 7.438382872828731, "train/policy_logprob_max": -0.009455735539948499, "train/policy_logprob_mean": -0.6275254156854417, "train/policy_logprob_min": -7.438382872828731, "train/policy_logprob_std": 1.1332572513156467, "train/policy_randomness_mag": 0.8673550777965122, "train/policy_randomness_max": 0.8673550777965122, "train/policy_randomness_mean": 0.22157410725399299, "train/policy_randomness_min": 0.02801595738640538, "train/policy_randomness_std": 0.22069956649232794, "train/post_ent_mag": 57.807853868272566, "train/post_ent_max": 57.807853868272566, "train/post_ent_mean": 41.01955187762225, "train/post_ent_min": 21.801735037344475, "train/post_ent_std": 6.998389833944815, "train/prior_ent_mag": 67.97991423430267, "train/prior_ent_max": 67.97991423430267, "train/prior_ent_mean": 54.53253091882776, "train/prior_ent_min": 36.024743426287614, "train/prior_ent_std": 5.16357028749254, "train/rep_loss_mean": 13.404497196056225, "train/rep_loss_std": 9.604662096941913, "train/reward_avg": 0.01908420126678215, "train/reward_loss_mean": 0.04810857207134918, "train/reward_loss_std": 0.23350562707141595, "train/reward_max_data": 1.0096296319255122, "train/reward_max_pred": 1.0040175844121861, "train/reward_neg_acc": 0.9939277141182511, "train/reward_neg_loss": 0.026996954268327465, "train/reward_pos_acc": 0.9546492435314037, "train/reward_pos_loss": 0.9033861570888095, "train/reward_pred": 0.01832146258610818, "train/reward_rate": 0.02426215277777778, "train_stats/sum_log_reward": 5.682608660407689, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 9.269565217391305, "train_stats/max_log_achievement_collect_sapling": 2.965217391304348, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 8.252173913043478, "train_stats/max_log_achievement_defeat_skeleton": 0.008695652173913044, "train_stats/max_log_achievement_defeat_zombie": 0.4608695652173913, "train_stats/max_log_achievement_eat_cow": 0.08695652173913043, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008695652173913044, "train_stats/max_log_achievement_make_wood_sword": 1.2, "train_stats/max_log_achievement_place_plant": 2.8, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.7304347826086954, "train_stats/max_log_achievement_wake_up": 1.3565217391304347, "train_stats/mean_log_entropy": 0.5382133253242658, "eval_stats/sum_log_reward": 6.099999964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 13.1875, "eval_stats/max_log_achievement_collect_sapling": 3.25, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.8125, "eval_stats/max_log_achievement_place_plant": 3.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.5384759283042513e-05, "report/cont_loss_std": 0.0005681370967067778, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001962057431228459, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.4377954105148092e-05, "report/cont_pred": 0.9941177368164062, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 15.846536636352539, "report/dyn_loss_std": 9.417346954345703, "report/image_loss_mean": 8.31999397277832, "report/image_loss_std": 11.666244506835938, "report/model_loss_mean": 17.870569229125977, "report/model_loss_std": 15.568628311157227, "report/post_ent_mag": 56.53703308105469, "report/post_ent_max": 56.53703308105469, "report/post_ent_mean": 39.9571533203125, "report/post_ent_min": 19.07949447631836, "report/post_ent_std": 6.990544319152832, "report/prior_ent_mag": 68.21632385253906, "report/prior_ent_max": 68.21632385253906, "report/prior_ent_mean": 55.907997131347656, "report/prior_ent_min": 34.75486373901367, "report/prior_ent_std": 4.7432684898376465, "report/rep_loss_mean": 15.846536636352539, "report/rep_loss_std": 9.417346954345703, "report/reward_avg": 0.01728515699505806, "report/reward_loss_mean": 0.04262782633304596, "report/reward_loss_std": 0.19146263599395752, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0045340061187744, "report/reward_neg_acc": 0.9940000176429749, "report/reward_neg_loss": 0.02656247839331627, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7120174765586853, "report/reward_pred": 0.019055282697081566, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.0019942130893468857, "eval/cont_loss_std": 0.05833594128489494, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.015508782118558884, "eval/cont_pos_acc": 0.999015748500824, "eval/cont_pos_loss": 0.0018877990078181028, "eval/cont_pred": 0.9914280772209167, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 16.861204147338867, "eval/dyn_loss_std": 12.256791114807129, "eval/image_loss_mean": 14.99261474609375, "eval/image_loss_std": 29.917024612426758, "eval/model_loss_mean": 25.201576232910156, "eval/model_loss_std": 34.94346618652344, "eval/post_ent_mag": 54.468936920166016, "eval/post_ent_max": 54.468936920166016, "eval/post_ent_mean": 40.104835510253906, "eval/post_ent_min": 24.081584930419922, "eval/post_ent_std": 6.684756278991699, "eval/prior_ent_mag": 68.21632385253906, "eval/prior_ent_max": 68.21632385253906, "eval/prior_ent_mean": 54.36125946044922, "eval/prior_ent_min": 36.15936279296875, "eval/prior_ent_std": 5.428525447845459, "eval/rep_loss_mean": 16.861204147338867, "eval/rep_loss_std": 12.256791114807129, "eval/reward_avg": 0.02353515475988388, "eval/reward_loss_mean": 0.09024333953857422, "eval/reward_loss_std": 0.5770655274391174, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023736953735352, "eval/reward_neg_acc": 0.9949647784233093, "eval/reward_neg_loss": 0.0578388050198555, "eval/reward_pos_acc": 0.9354838132858276, "eval/reward_pos_loss": 1.128233790397644, "eval/reward_pred": 0.021464606747031212, "eval/reward_rate": 0.0302734375, "replay/size": 448497.0, "replay/inserts": 21696.0, "replay/samples": 21696.0, "replay/insert_wait_avg": 1.4434455946131793e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.540255481866257e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 85384.0, "eval_replay/inserts": 4072.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.4480766940913173e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1622905731201172e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4493117332458, "timer/env.step_count": 2712.0, "timer/env.step_total": 262.0925643444061, "timer/env.step_frac": 0.2619748559678044, "timer/env.step_avg": 0.09664180101194916, "timer/env.step_min": 0.024645328521728516, "timer/env.step_max": 5.525007963180542, "timer/replay._sample_count": 21696.0, "timer/replay._sample_total": 11.43325424194336, "timer/replay._sample_frac": 0.011428119453783839, "timer/replay._sample_avg": 0.000526975213953879, "timer/replay._sample_min": 0.0004088878631591797, "timer/replay._sample_max": 0.010202884674072266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3221.0, "timer/agent.policy_total": 57.12630295753479, "timer/agent.policy_frac": 0.057100646966876646, "timer/agent.policy_avg": 0.017735579930932874, "timer/agent.policy_min": 0.009761810302734375, "timer/agent.policy_max": 0.12829875946044922, "timer/dataset_train_count": 1356.0, "timer/dataset_train_total": 0.16698169708251953, "timer/dataset_train_frac": 0.00016690670394208095, "timer/dataset_train_avg": 0.00012314284445613536, "timer/dataset_train_min": 0.00010848045349121094, "timer/dataset_train_max": 0.0010950565338134766, "timer/agent.train_count": 1356.0, "timer/agent.train_total": 611.5425746440887, "timer/agent.train_frac": 0.6112679247933223, "timer/agent.train_avg": 0.4509900992950507, "timer/agent.train_min": 0.43612074851989746, "timer/agent.train_max": 1.5792620182037354, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47695088386535645, "timer/agent.report_frac": 0.00047673668048114757, "timer/agent.report_avg": 0.23847544193267822, "timer/agent.report_min": 0.23176789283752441, "timer/agent.report_max": 0.24518299102783203, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2886987406702685e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 21.68598902220477}
{"step": 449024, "time": 21373.60456418991, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 449288, "time": 21384.102699041367, "episode/length": 217.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 449376, "time": 21388.98157286644, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 449608, "time": 21398.1582365036, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 449792, "time": 21406.116273880005, "episode/length": 157.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 21429.9581823349, "eval_episode/length": 36.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.972972972972973}
{"step": 450008, "time": 21431.756584644318, "eval_episode/length": 41.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 450008, "time": 21437.982327461243, "eval_episode/length": 148.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 450008, "time": 21440.266987800598, "eval_episode/length": 163.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 450008, "time": 21442.978240966797, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 450008, "time": 21444.946239948273, "eval_episode/length": 149.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 450008, "time": 21447.256141901016, "eval_episode/length": 208.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9712918660287081}
{"step": 450008, "time": 21449.0870821476, "eval_episode/length": 209.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 450112, "time": 21452.826436281204, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 450272, "time": 21459.833639383316, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 450424, "time": 21466.411407470703, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 450632, "time": 21476.487339258194, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 450760, "time": 21482.52511882782, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 450968, "time": 21491.35025882721, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 451232, "time": 21502.814799308777, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 451440, "time": 21511.62501502037, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 451456, "time": 21514.32092642784, "episode/length": 167.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 451592, "time": 21520.88496041298, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 452024, "time": 21537.24687051773, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 452280, "time": 21547.90856552124, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 452400, "time": 21553.658684015274, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9832402234636871, "episode/intrinsic_return": 0.0}
{"step": 452536, "time": 21559.598815202713, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 452808, "time": 21570.6619412899, "episode/length": 170.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 452864, "time": 21574.573311567307, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 453160, "time": 21586.02501487732, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 453472, "time": 21598.480588912964, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 453600, "time": 21604.470912218094, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 453776, "time": 21611.963777303696, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 453856, "time": 21616.292664527893, "episode/length": 428.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953379953379954, "episode/intrinsic_return": 0.0}
{"step": 454144, "time": 21627.715567588806, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 454192, "time": 21631.1391582489, "episode/length": 128.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9689922480620154, "episode/intrinsic_return": 0.0}
{"step": 454744, "time": 21651.546236276627, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.987603305785124, "episode/intrinsic_return": 0.0}
{"step": 454768, "time": 21654.133741140366, "episode/length": 278.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 454896, "time": 21660.303555250168, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 455056, "time": 21667.287211418152, "episode/length": 149.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9533333333333334, "episode/intrinsic_return": 0.0}
{"step": 455144, "time": 21671.78974223137, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 455400, "time": 21681.990553617477, "episode/length": 78.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 455448, "time": 21685.21074962616, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 456064, "time": 21707.896809101105, "episode/length": 285.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9895104895104895, "episode/intrinsic_return": 0.0}
{"step": 456120, "time": 21711.25049638748, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 456360, "time": 21721.057049036026, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 456568, "time": 21730.070199251175, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 456616, "time": 21733.205798864365, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 456688, "time": 21737.41176366806, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 456776, "time": 21741.82381272316, "episode/length": 171.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 457320, "time": 21761.98694086075, "episode/length": 233.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 457432, "time": 21767.41409802437, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 457488, "time": 21771.098507642746, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 457768, "time": 21781.94705605507, "episode/length": 143.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 457936, "time": 21789.34015107155, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 458016, "time": 21793.650369405746, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 458512, "time": 21812.024361133575, "episode/length": 431.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 458624, "time": 21817.406242847443, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 458632, "time": 21818.985934257507, "episode/length": 257.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 458928, "time": 21832.2988781929, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 459032, "time": 21837.309190034866, "episode/length": 192.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 459168, "time": 21843.818965911865, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 459888, "time": 21869.830676317215, "episode/length": 106.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9439252336448598, "episode/intrinsic_return": 0.0}
{"step": 459888, "time": 21869.84135699272, "episode/length": 243.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9713114754098361, "episode/intrinsic_return": 0.0}
{"step": 459968, "time": 21875.828726291656, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 460000, "time": 21878.49632692337, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 21898.38472056389, "eval_episode/length": 33.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 460096, "time": 21906.1347386837, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 460096, "time": 21908.691389799118, "eval_episode/length": 193.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 460096, "time": 21910.69341635704, "eval_episode/length": 169.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 460096, "time": 21912.550099134445, "eval_episode/length": 209.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 460096, "time": 21914.329942941666, "eval_episode/length": 213.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.985981308411215}
{"step": 460096, "time": 21916.82039833069, "eval_episode/length": 228.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 460096, "time": 21919.217591524124, "eval_episode/length": 41.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 460144, "time": 21920.868270158768, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 460192, "time": 21924.082554101944, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 460616, "time": 21939.913719177246, "episode/length": 210.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 460872, "time": 21950.13967037201, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 461384, "time": 21969.22572827339, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 461600, "time": 21978.401317834854, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 461640, "time": 21981.141137361526, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 461720, "time": 21985.470097780228, "episode/length": 196.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 462016, "time": 21997.34864115715, "episode/length": 36.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 462040, "time": 21999.52921795845, "episode/length": 54.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 462072, "time": 22002.10925102234, "episode/length": 258.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 462128, "time": 22005.800012111664, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 462264, "time": 22011.814581155777, "episode/length": 296.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 462344, "time": 22016.080299139023, "episode/length": 37.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 462520, "time": 22023.674000024796, "episode/length": 109.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9454545454545454, "episode/intrinsic_return": 0.0}
{"step": 462560, "time": 22026.875390052795, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 462664, "time": 22031.731394052505, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 462696, "time": 22034.493619918823, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 463264, "time": 22055.470050811768, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 463576, "time": 22067.226227760315, "episode/length": 187.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 463904, "time": 22080.346395730972, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 463960, "time": 22083.57874250412, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 464008, "time": 22086.81723856926, "episode/length": 185.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 464048, "time": 22090.693372011185, "episode/length": 239.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9708333333333333, "episode/intrinsic_return": 0.0}
{"step": 464312, "time": 22101.577216625214, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 464312, "time": 22101.5875415802, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 464360, "time": 22106.531851291656, "episode/length": 38.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 464904, "time": 22126.643795490265, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9518072289156626, "episode/intrinsic_return": 0.0}
{"step": 465000, "time": 22131.48967885971, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 465216, "time": 22140.74144077301, "episode/length": 150.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 465296, "time": 22145.062012672424, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 465696, "time": 22160.16093492508, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 465728, "time": 22162.866721868515, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 465776, "time": 22165.97737956047, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 466272, "time": 22184.50447654724, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 466376, "time": 22189.33348250389, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 466416, "time": 22192.503563642502, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 466664, "time": 22202.342516183853, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 466896, "time": 22212.086714744568, "episode/length": 59.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 466984, "time": 22217.87125635147, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 467104, "time": 22223.837299108505, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 467128, "time": 22225.89690566063, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 467280, "time": 22232.988626003265, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 467376, "time": 22237.85115790367, "episode/length": 137.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 467560, "time": 22245.562191724777, "episode/length": 34.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 468176, "time": 22268.48365712166, "episode/length": 309.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 468200, "time": 22270.76395225525, "episode/length": 162.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 468352, "time": 22277.717216014862, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 468472, "time": 22283.131001234055, "episode/length": 261.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 468568, "time": 22288.24066734314, "episode/length": 179.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 468576, "time": 22290.293127298355, "episode/length": 126.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 468648, "time": 22294.130311727524, "episode/length": 36.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 468792, "time": 22300.504441976547, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 469328, "time": 22320.566130161285, "episode/length": 277.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 469832, "time": 22338.99297761917, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 469888, "time": 22342.68684363365, "episode/length": 176.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 469976, "time": 22347.017959594727, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 469992, "time": 22349.294093608856, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 470016, "time": 22351.875430107117, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 22378.029008626938, "eval_episode/length": 143.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 470080, "time": 22379.944026231766, "eval_episode/length": 147.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9864864864864865}
{"step": 470080, "time": 22382.416276931763, "eval_episode/length": 167.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 470080, "time": 22384.146035671234, "eval_episode/length": 169.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 470080, "time": 22386.379325151443, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 470080, "time": 22389.196629285812, "eval_episode/length": 207.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 470080, "time": 22392.41544532776, "eval_episode/length": 241.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9752066115702479}
{"step": 470080, "time": 22395.3309237957, "eval_episode/length": 271.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9816176470588235}
{"step": 470081, "time": 22395.909746408463, "train_stats/sum_log_reward": 5.535897392493028, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.213675213675214, "train_stats/max_log_achievement_collect_sapling": 2.3675213675213675, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 7.162393162393163, "train_stats/max_log_achievement_defeat_skeleton": 0.017094017094017096, "train_stats/max_log_achievement_defeat_zombie": 0.48717948717948717, "train_stats/max_log_achievement_eat_cow": 0.09401709401709402, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008547008547008548, "train_stats/max_log_achievement_make_wood_sword": 1.0256410256410255, "train_stats/max_log_achievement_place_plant": 2.2393162393162394, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.341880341880342, "train_stats/max_log_achievement_wake_up": 1.7777777777777777, "train_stats/mean_log_entropy": 0.5511922068320788, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.8178729433001894, "train/action_min": 0.0, "train/action_std": 3.7057366316968743, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049367964352396404, "train/actor_opt_grad_steps": 28625.0, "train/actor_opt_loss": -4.935942959266178, "train/adv_mag": 0.7583048009511196, "train/adv_max": 0.7406299913471396, "train/adv_mean": 0.0037691877775724797, "train/adv_min": -0.5157549541556474, "train/adv_std": 0.07687651453483285, "train/cont_avg": 0.9943921638257576, "train/cont_loss_mean": 0.0001345353232542748, "train/cont_loss_std": 0.0038356456697585133, "train/cont_neg_acc": 0.9942279959266836, "train/cont_neg_loss": 0.013833872269327512, "train/cont_pos_acc": 0.9999851223194238, "train/cont_pos_loss": 6.089999437568763e-05, "train/cont_pred": 0.9943999679702701, "train/cont_rate": 0.9943921638257576, "train/dyn_loss_mean": 13.625066135868881, "train/dyn_loss_std": 9.618422240921944, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8750271444970911, "train/extr_critic_critic_opt_grad_steps": 28625.0, "train/extr_critic_critic_opt_loss": 16077.319239760891, "train/extr_critic_mag": 4.741360220042142, "train/extr_critic_max": 4.741360220042142, "train/extr_critic_mean": 0.9273789055419691, "train/extr_critic_min": -0.37738803390300635, "train/extr_critic_std": 1.062508708599842, "train/extr_return_normed_mag": 1.8671265199328915, "train/extr_return_normed_max": 1.8671265199328915, "train/extr_return_normed_mean": 0.3258552813168728, "train/extr_return_normed_min": -0.16858606017900235, "train/extr_return_normed_std": 0.33272956481034105, "train/extr_return_rate": 0.49860176782716403, "train/extr_return_raw_mag": 6.0307662450906, "train/extr_return_raw_max": 6.0307662450906, "train/extr_return_raw_mean": 0.9398183452360558, "train/extr_return_raw_min": -0.6934707221208196, "train/extr_return_raw_std": 1.0990331561276407, "train/extr_reward_mag": 1.0135630351124387, "train/extr_reward_max": 1.0135630351124387, "train/extr_reward_mean": 0.02505311911050795, "train/extr_reward_min": -0.4807839167840553, "train/extr_reward_std": 0.1494170722523422, "train/image_loss_mean": 7.056009816400932, "train/image_loss_std": 11.4553984078494, "train/model_loss_mean": 15.27969206463207, "train/model_loss_std": 15.474372899893558, "train/model_opt_grad_norm": 59.37342840252501, "train/model_opt_grad_steps": 28597.636363636364, "train/model_opt_loss": 10187.884495590672, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 667.6136363636364, "train/policy_entropy_mag": 2.452191883867437, "train/policy_entropy_max": 2.452191883867437, "train/policy_entropy_mean": 0.6394971575249325, "train/policy_entropy_min": 0.07937515967271545, "train/policy_entropy_std": 0.6304905954183955, "train/policy_logprob_mag": 7.438382975982897, "train/policy_logprob_max": -0.009455700574273413, "train/policy_logprob_mean": -0.6397348396254309, "train/policy_logprob_min": -7.438382975982897, "train/policy_logprob_std": 1.1420326458685326, "train/policy_randomness_mag": 0.8655161238981016, "train/policy_randomness_max": 0.8655161238981016, "train/policy_randomness_mean": 0.22571443292227658, "train/policy_randomness_min": 0.028015948041821972, "train/policy_randomness_std": 0.22253551187388826, "train/post_ent_mag": 57.80857831781561, "train/post_ent_max": 57.80857831781561, "train/post_ent_mean": 41.01130280350194, "train/post_ent_min": 21.660922628460508, "train/post_ent_std": 7.036587783784578, "train/prior_ent_mag": 68.2075120752508, "train/prior_ent_max": 68.2075120752508, "train/prior_ent_mean": 54.69830963828347, "train/prior_ent_min": 36.541959805922076, "train/prior_ent_std": 5.055801756454237, "train/rep_loss_mean": 13.625066135868881, "train/rep_loss_std": 9.618422240921944, "train/reward_avg": 0.019668856374637195, "train/reward_loss_mean": 0.04850797324130932, "train/reward_loss_std": 0.2340298123431928, "train/reward_max_data": 1.0113636390729384, "train/reward_max_pred": 1.0041532796440702, "train/reward_neg_acc": 0.9934464268612139, "train/reward_neg_loss": 0.027171729696970997, "train/reward_pos_acc": 0.9585236595435576, "train/reward_pos_loss": 0.8949321056857253, "train/reward_pred": 0.01896328768326026, "train/reward_rate": 0.02472478693181818, "eval_stats/sum_log_reward": 5.4749999443689985, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.541666666666667, "eval_stats/max_log_achievement_collect_sapling": 2.0416666666666665, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.208333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4166666666666667, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_sword": 0.9583333333333334, "eval_stats/max_log_achievement_place_plant": 2.0416666666666665, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.0416666666666665, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.3217802461440442e-06, "report/cont_loss_std": 3.065924465772696e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.3720462195342407e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.255966367352812e-06, "report/cont_pred": 0.997069239616394, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.647655487060547, "report/dyn_loss_std": 9.811870574951172, "report/image_loss_mean": 6.730163097381592, "report/image_loss_std": 11.201111793518066, "report/model_loss_mean": 14.977987289428711, "report/model_loss_std": 15.489806175231934, "report/post_ent_mag": 57.537899017333984, "report/post_ent_max": 57.537899017333984, "report/post_ent_mean": 41.43238067626953, "report/post_ent_min": 20.90321922302246, "report/post_ent_std": 7.302258014678955, "report/prior_ent_mag": 68.154296875, "report/prior_ent_max": 68.154296875, "report/prior_ent_mean": 55.19520950317383, "report/prior_ent_min": 37.991119384765625, "report/prior_ent_std": 4.523338317871094, "report/rep_loss_mean": 13.647655487060547, "report/rep_loss_std": 9.811870574951172, "report/reward_avg": 0.02304687350988388, "report/reward_loss_mean": 0.059229616075754166, "report/reward_loss_std": 0.35779571533203125, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0011112689971924, "report/reward_neg_acc": 0.9939759969711304, "report/reward_neg_loss": 0.02339215762913227, "report/reward_pos_acc": 0.8928571939468384, "report/reward_pos_loss": 1.3340193033218384, "report/reward_pred": 0.01693730428814888, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.00020223567844368517, "eval/cont_loss_std": 0.006352908443659544, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.10250291973352432, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.038618731603492e-06, "eval/cont_pred": 0.9982262849807739, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.999410629272461, "eval/dyn_loss_std": 11.032950401306152, "eval/image_loss_mean": 11.745450973510742, "eval/image_loss_std": 18.571386337280273, "eval/model_loss_mean": 21.397382736206055, "eval/model_loss_std": 23.111223220825195, "eval/post_ent_mag": 56.51457977294922, "eval/post_ent_max": 56.51457977294922, "eval/post_ent_mean": 40.67964172363281, "eval/post_ent_min": 23.18564224243164, "eval/post_ent_std": 6.897955417633057, "eval/prior_ent_mag": 68.154296875, "eval/prior_ent_max": 68.154296875, "eval/prior_ent_mean": 55.06479263305664, "eval/prior_ent_min": 39.707881927490234, "eval/prior_ent_std": 4.488415718078613, "eval/rep_loss_mean": 15.999410629272461, "eval/rep_loss_std": 11.032950401306152, "eval/reward_avg": 0.01679687574505806, "eval/reward_loss_mean": 0.052083246409893036, "eval/reward_loss_std": 0.39683112502098083, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000950574874878, "eval/reward_neg_acc": 0.9940239191055298, "eval/reward_neg_loss": 0.03016737662255764, "eval/reward_pos_acc": 0.949999988079071, "eval/reward_pos_loss": 1.1522598266601562, "eval/reward_pred": 0.018637077882885933, "eval/reward_rate": 0.01953125, "replay/size": 469577.0, "replay/inserts": 21080.0, "replay/samples": 21072.0, "replay/insert_wait_avg": 1.4075970513997088e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.610314099102556e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 91208.0, "eval_replay/inserts": 5824.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.249405053945688e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1023.0202903747559, "timer/env.step_count": 2635.0, "timer/env.step_total": 264.4572865962982, "timer/env.step_frac": 0.2585063943349759, "timer/env.step_avg": 0.10036329662098604, "timer/env.step_min": 0.024320125579833984, "timer/env.step_max": 3.357652187347412, "timer/replay._sample_count": 21072.0, "timer/replay._sample_total": 11.203237056732178, "timer/replay._sample_frac": 0.010951138664735745, "timer/replay._sample_avg": 0.000531664628736341, "timer/replay._sample_min": 0.00040078163146972656, "timer/replay._sample_max": 0.025361299514770508, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3363.0, "timer/agent.policy_total": 59.87825894355774, "timer/agent.policy_frac": 0.05853086151558436, "timer/agent.policy_avg": 0.017805013066773043, "timer/agent.policy_min": 0.009700298309326172, "timer/agent.policy_max": 0.15408658981323242, "timer/dataset_train_count": 1317.0, "timer/dataset_train_total": 0.1627657413482666, "timer/dataset_train_frac": 0.00015910314084644574, "timer/dataset_train_avg": 0.00012358826222343705, "timer/dataset_train_min": 0.000102996826171875, "timer/dataset_train_max": 0.0005404949188232422, "timer/agent.train_count": 1317.0, "timer/agent.train_total": 597.0866372585297, "timer/agent.train_frac": 0.5836508257717968, "timer/agent.train_avg": 0.4533687450710172, "timer/agent.train_min": 0.43665194511413574, "timer/agent.train_max": 1.532625675201416, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4711878299713135, "timer/agent.report_frac": 0.00046058502886458543, "timer/agent.report_avg": 0.23559391498565674, "timer/agent.report_min": 0.22417950630187988, "timer/agent.report_max": 0.2470083236694336, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 3.5191096191403855e-08, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05, "fps": 20.605382772677576}
{"step": 470240, "time": 22401.655096292496, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 470328, "time": 22406.024911403656, "episode/length": 41.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 470376, "time": 22409.41464662552, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 470832, "time": 22426.622722148895, "episode/length": 187.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 471312, "time": 22444.625604629517, "episode/length": 133.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9552238805970149, "episode/intrinsic_return": 0.0}
{"step": 471368, "time": 22447.90776491165, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 471376, "time": 22450.059208631516, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 471456, "time": 22454.290607452393, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 471616, "time": 22461.318484783173, "episode/length": 37.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 471768, "time": 22468.031586408615, "episode/length": 223.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 472032, "time": 22479.239293813705, "episode/length": 51.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 472040, "time": 22481.00887274742, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 472232, "time": 22489.34046459198, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 472352, "time": 22495.689502477646, "episode/length": 252.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 472632, "time": 22506.589199781418, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 472672, "time": 22509.713141202927, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 473232, "time": 22530.417393922806, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 473384, "time": 22536.97043967247, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 473432, "time": 22540.19660282135, "episode/length": 246.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 473712, "time": 22551.46592116356, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 473808, "time": 22556.33133506775, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 473928, "time": 22561.998207330704, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 474216, "time": 22573.432988643646, "episode/length": 247.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 474288, "time": 22577.62400650978, "episode/length": 201.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 474312, "time": 22579.783053398132, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 474544, "time": 22589.926689386368, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 474784, "time": 22599.57536673546, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 475176, "time": 22615.761875867844, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 475712, "time": 22635.967042922974, "episode/length": 237.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 475720, "time": 22637.677172899246, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 475824, "time": 22643.146426439285, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 476072, "time": 22653.07687830925, "episode/length": 267.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 476208, "time": 22659.50155353546, "episode/length": 177.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9831460674157303, "episode/intrinsic_return": 0.0}
{"step": 476288, "time": 22663.76005268097, "episode/length": 246.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 476296, "time": 22665.381395339966, "episode/length": 218.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 476528, "time": 22675.11909198761, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 477088, "time": 22695.71693086624, "episode/length": 171.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 477096, "time": 22697.333768844604, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 477512, "time": 22713.085391521454, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 477632, "time": 22718.922053813934, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 477776, "time": 22725.325469255447, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 478152, "time": 22739.552518844604, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 478264, "time": 22744.98796272278, "episode/length": 216.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 478568, "time": 22756.845472812653, "episode/length": 37.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 479104, "time": 22777.122371196747, "episode/length": 251.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 479120, "time": 22779.25378060341, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 479248, "time": 22785.22699546814, "episode/length": 268.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 479680, "time": 22801.750522375107, "episode/length": 433.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 479744, "time": 22805.43220424652, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 479800, "time": 22808.698701143265, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 479824, "time": 22811.408450126648, "episode/length": 273.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 480024, "time": 22819.561804771423, "episode/length": 42.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 22843.389047145844, "eval_episode/length": 157.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 480064, "time": 22845.04868555069, "eval_episode/length": 159.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9625}
{"step": 480064, "time": 22848.2621986866, "eval_episode/length": 194.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 480064, "time": 22851.06522321701, "eval_episode/length": 220.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9683257918552036}
{"step": 480064, "time": 22852.72507596016, "eval_episode/length": 223.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9776785714285714}
{"step": 480064, "time": 22855.00017809868, "eval_episode/length": 236.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9873417721518988}
{"step": 480064, "time": 22858.527369499207, "eval_episode/length": 275.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9746376811594203}
{"step": 480064, "time": 22860.25525712967, "eval_episode/length": 279.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9785714285714285}
{"step": 480336, "time": 22869.47073483467, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 480560, "time": 22878.606001377106, "episode/length": 163.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 480856, "time": 22890.07003712654, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 480928, "time": 22894.417946100235, "episode/length": 137.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 481008, "time": 22898.698355197906, "episode/length": 150.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 481240, "time": 22907.90105509758, "episode/length": 432.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 481440, "time": 22916.47334766388, "episode/length": 289.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 481560, "time": 22922.166140794754, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 481624, "time": 22925.873223543167, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 482280, "time": 22949.781612873077, "episode/length": 242.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.0}
{"step": 482408, "time": 22955.728937625885, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 482464, "time": 22959.463304519653, "episode/length": 181.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 482608, "time": 22965.990203142166, "episode/length": 437.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.997716894977169, "episode/intrinsic_return": 0.0}
{"step": 482888, "time": 22976.84556722641, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 482960, "time": 22981.413329839706, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 483016, "time": 22984.708011865616, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 483384, "time": 23000.21213388443, "episode/length": 242.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 483688, "time": 23012.225068330765, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 484024, "time": 23025.25233912468, "episode/length": 194.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 484192, "time": 23032.73442029953, "episode/length": 146.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 484240, "time": 23035.97857785225, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 484376, "time": 23042.13477420807, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 484768, "time": 23057.254989385605, "episode/length": 294.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 485128, "time": 23070.932085752487, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 485216, "time": 23075.72727894783, "episode/length": 325.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9969325153374233, "episode/intrinsic_return": 0.0}
{"step": 485352, "time": 23081.811685800552, "episode/length": 245.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 485520, "time": 23089.3211042881, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 485640, "time": 23094.711720466614, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 486168, "time": 23114.270790100098, "episode/length": 174.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 486248, "time": 23119.503535747528, "episode/length": 250.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 486312, "time": 23123.220615148544, "episode/length": 241.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 486336, "time": 23125.8328666687, "episode/length": 150.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 486536, "time": 23134.23328113556, "episode/length": 164.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 486656, "time": 23140.05940103531, "episode/length": 162.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 487008, "time": 23153.563354492188, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 487328, "time": 23166.04684829712, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 487464, "time": 23172.01085305214, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 487496, "time": 23174.623584508896, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 487568, "time": 23178.93862080574, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 487816, "time": 23188.902879953384, "episode/length": 60.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9344262295081968, "episode/intrinsic_return": 0.0}
{"step": 487992, "time": 23196.428034305573, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 488000, "time": 23198.537912368774, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 488080, "time": 23202.86004114151, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 488128, "time": 23206.06695508957, "episode/length": 139.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 488136, "time": 23207.67800807953, "episode/length": 79.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 488768, "time": 23231.137078523636, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 489032, "time": 23241.41445016861, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 489368, "time": 23254.56678891182, "episode/length": 153.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 489664, "time": 23266.417619228363, "episode/length": 191.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 489944, "time": 23277.276304006577, "episode/length": 232.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 490024, "time": 23281.743163347244, "episode/length": 253.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 23299.050791502, "eval_episode/length": 37.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 490048, "time": 23300.700872182846, "eval_episode/length": 39.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 490048, "time": 23302.37593126297, "eval_episode/length": 40.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.975609756097561}
{"step": 490048, "time": 23309.994824886322, "eval_episode/length": 171.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 490048, "time": 23311.715015649796, "eval_episode/length": 173.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 490048, "time": 23313.35847377777, "eval_episode/length": 177.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 490048, "time": 23315.825185775757, "eval_episode/length": 195.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 490048, "time": 23319.122425079346, "eval_episode/length": 195.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9693877551020408}
{"step": 490344, "time": 23328.975153446198, "episode/length": 315.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 490408, "time": 23332.800069332123, "episode/length": 171.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 490696, "time": 23344.237867116928, "episode/length": 35.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 490720, "time": 23346.86485695839, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 490896, "time": 23354.617090940475, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 491000, "time": 23359.510367155075, "episode/length": 278.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 491192, "time": 23367.593249320984, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 491848, "time": 23393.20292377472, "episode/length": 480.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9812889812889813, "episode/intrinsic_return": 0.0}
{"step": 491865, "time": 23396.38923549652, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.182387856876149, "train/action_min": 0.0, "train/action_std": 3.1650082188494064, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04905054929173168, "train/actor_opt_grad_steps": 29965.0, "train/actor_opt_loss": -9.098463890526224, "train/adv_mag": 0.7125533909043845, "train/adv_max": 0.6974476994398762, "train/adv_mean": 0.0030798413337620066, "train/adv_min": -0.5190883684245979, "train/adv_std": 0.07612987533759545, "train/cont_avg": 0.9941047219669118, "train/cont_loss_mean": 0.00019468688429401983, "train/cont_loss_std": 0.005558736949401468, "train/cont_neg_acc": 0.9969070970135576, "train/cont_neg_loss": 0.010635453315507996, "train/cont_pos_acc": 0.9999783065389184, "train/cont_pos_loss": 0.00012891756997150428, "train/cont_pred": 0.9941026441314641, "train/cont_rate": 0.9941047219669118, "train/dyn_loss_mean": 13.506360558902516, "train/dyn_loss_std": 9.61200749874115, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8604995301541161, "train/extr_critic_critic_opt_grad_steps": 29965.0, "train/extr_critic_critic_opt_loss": 16144.635735006894, "train/extr_critic_mag": 4.8002554178237915, "train/extr_critic_max": 4.8002554178237915, "train/extr_critic_mean": 0.9313043583841885, "train/extr_critic_min": -0.3617779156740974, "train/extr_critic_std": 1.1026082599864286, "train/extr_return_normed_mag": 1.8393236179562176, "train/extr_return_normed_max": 1.8393236179562176, "train/extr_return_normed_mean": 0.3183832529055722, "train/extr_return_normed_min": -0.16530005546177134, "train/extr_return_normed_std": 0.3371347007067764, "train/extr_return_rate": 0.4768267701215604, "train/extr_return_raw_mag": 6.0765736348488755, "train/extr_return_raw_max": 6.0765736348488755, "train/extr_return_raw_mean": 0.9417221208705622, "train/extr_return_raw_min": -0.6909410543739796, "train/extr_return_raw_std": 1.1380701612900286, "train/extr_reward_mag": 1.0125144071438734, "train/extr_reward_max": 1.0125144071438734, "train/extr_reward_mean": 0.026198195957797852, "train/extr_reward_min": -0.4747377081828959, "train/extr_reward_std": 0.15271470629993608, "train/image_loss_mean": 6.847815352327683, "train/image_loss_std": 11.175282387172475, "train/model_loss_mean": 15.000702900045058, "train/model_loss_std": 15.223256889511557, "train/model_opt_grad_norm": 58.26620469373815, "train/model_opt_grad_steps": 29937.0, "train/model_opt_loss": 15181.160303452436, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1011.0294117647059, "train/policy_entropy_mag": 2.4835239193018745, "train/policy_entropy_max": 2.4835239193018745, "train/policy_entropy_mean": 0.5516515032333487, "train/policy_entropy_min": 0.07937513209660263, "train/policy_entropy_std": 0.5547069946632666, "train/policy_logprob_mag": 7.4383831269600815, "train/policy_logprob_max": -0.00945568278514068, "train/policy_logprob_mean": -0.551243240123286, "train/policy_logprob_min": -7.4383831269600815, "train/policy_logprob_std": 1.092973393114174, "train/policy_randomness_mag": 0.8765749585102586, "train/policy_randomness_max": 0.8765749585102586, "train/policy_randomness_mean": 0.19470877079840967, "train/policy_randomness_min": 0.02801593823139282, "train/policy_randomness_std": 0.19578722798649004, "train/post_ent_mag": 57.727940054500806, "train/post_ent_max": 57.727940054500806, "train/post_ent_mean": 41.232714148128736, "train/post_ent_min": 21.552517273846796, "train/post_ent_std": 7.038158010034, "train/prior_ent_mag": 68.29006901909324, "train/prior_ent_max": 68.29006901909324, "train/prior_ent_mean": 54.79405551798203, "train/prior_ent_min": 37.362877032336065, "train/prior_ent_std": 4.935224312193253, "train/rep_loss_mean": 13.506360558902516, "train/rep_loss_std": 9.61200749874115, "train/reward_avg": 0.019944852789836553, "train/reward_loss_mean": 0.048876673709053325, "train/reward_loss_std": 0.23400784590665033, "train/reward_max_data": 1.0036764714647741, "train/reward_max_pred": 1.0028762615778868, "train/reward_neg_acc": 0.9939341536339592, "train/reward_neg_loss": 0.02749436439754551, "train/reward_pos_acc": 0.9607838707811692, "train/reward_pos_loss": 0.883222936269115, "train/reward_pred": 0.019166685414829236, "train/reward_rate": 0.025146484375, "train_stats/sum_log_reward": 5.7666666185533675, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.306306306306307, "train_stats/max_log_achievement_collect_sapling": 2.936936936936937, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 7.63063063063063, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.6306306306306306, "train_stats/max_log_achievement_eat_cow": 0.0990990990990991, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.018018018018018018, "train_stats/max_log_achievement_make_wood_sword": 0.990990990990991, "train_stats/max_log_achievement_place_plant": 2.72972972972973, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.6576576576576576, "train_stats/max_log_achievement_wake_up": 1.6936936936936937, "train_stats/mean_log_entropy": 0.4726887954784943, "eval_stats/sum_log_reward": 5.224999934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 7.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.5, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.8125, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 8.234430879383581e-07, "report/cont_loss_std": 1.65285928233061e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.1335308701964095e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.430043069689418e-07, "report/cont_pred": 0.9960931539535522, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.195403099060059, "report/dyn_loss_std": 9.417671203613281, "report/image_loss_mean": 7.635745525360107, "report/image_loss_std": 11.11048412322998, "report/model_loss_mean": 16.201784133911133, "report/model_loss_std": 15.334295272827148, "report/post_ent_mag": 60.21764373779297, "report/post_ent_max": 60.21764373779297, "report/post_ent_mean": 41.3603515625, "report/post_ent_min": 20.679155349731445, "report/post_ent_std": 7.104687690734863, "report/prior_ent_mag": 69.00189208984375, "report/prior_ent_max": 69.00189208984375, "report/prior_ent_mean": 55.74580383300781, "report/prior_ent_min": 38.82427978515625, "report/prior_ent_std": 4.330127239227295, "report/rep_loss_mean": 14.195403099060059, "report/rep_loss_std": 9.417671203613281, "report/reward_avg": 0.01748046837747097, "report/reward_loss_mean": 0.04879724234342575, "report/reward_loss_std": 0.24909402430057526, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0015814304351807, "report/reward_neg_acc": 0.9900299310684204, "report/reward_neg_loss": 0.02603837661445141, "report/reward_pos_acc": 0.8571428656578064, "report/reward_pos_loss": 1.1358040571212769, "report/reward_pred": 0.015053294599056244, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.240377287103911e-06, "eval/cont_loss_std": 2.42360656557139e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.828274930128828e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0586187499939115e-06, "eval/cont_pred": 0.9951163530349731, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.67778778076172, "eval/dyn_loss_std": 10.335527420043945, "eval/image_loss_mean": 11.866440773010254, "eval/image_loss_std": 17.24043846130371, "eval/model_loss_mean": 22.5363826751709, "eval/model_loss_std": 21.620635986328125, "eval/post_ent_mag": 54.90522384643555, "eval/post_ent_max": 54.90522384643555, "eval/post_ent_mean": 40.01158905029297, "eval/post_ent_min": 23.722023010253906, "eval/post_ent_std": 6.681201934814453, "eval/prior_ent_mag": 69.00189208984375, "eval/prior_ent_max": 69.00189208984375, "eval/prior_ent_mean": 55.64868927001953, "eval/prior_ent_min": 39.16339874267578, "eval/prior_ent_std": 4.947558879852295, "eval/rep_loss_mean": 17.67778778076172, "eval/rep_loss_std": 10.335527420043945, "eval/reward_avg": 0.01777343824505806, "eval/reward_loss_mean": 0.06326945126056671, "eval/reward_loss_std": 0.3144892156124115, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999253749847412, "eval/reward_neg_acc": 0.9890109896659851, "eval/reward_neg_loss": 0.03878239542245865, "eval/reward_pos_acc": 0.9130434989929199, "eval/reward_pos_loss": 1.1289887428283691, "eval/reward_pred": 0.016998231410980225, "eval/reward_rate": 0.0224609375, "replay/size": 491361.0, "replay/inserts": 21784.0, "replay/samples": 21792.0, "replay/insert_wait_avg": 1.4366842655850121e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.654051765296253e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 95320.0, "eval_replay/inserts": 4112.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2487984816851782e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4621500968933, "timer/env.step_count": 2723.0, "timer/env.step_total": 256.07206177711487, "timer/env.step_frac": 0.25595377271625386, "timer/env.step_avg": 0.09404041930852547, "timer/env.step_min": 0.024488210678100586, "timer/env.step_max": 2.033374547958374, "timer/replay._sample_count": 21792.0, "timer/replay._sample_total": 11.594483375549316, "timer/replay._sample_frac": 0.011589127459171152, "timer/replay._sample_avg": 0.000532052284120288, "timer/replay._sample_min": 0.0004169940948486328, "timer/replay._sample_max": 0.025732040405273438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3237.0, "timer/agent.policy_total": 56.43878102302551, "timer/agent.policy_frac": 0.056412709883686754, "timer/agent.policy_avg": 0.017435520859754562, "timer/agent.policy_min": 0.00982975959777832, "timer/agent.policy_max": 0.13414835929870605, "timer/dataset_train_count": 1362.0, "timer/dataset_train_total": 0.16764020919799805, "timer/dataset_train_frac": 0.00016756277004758484, "timer/dataset_train_avg": 0.00012308385403670929, "timer/dataset_train_min": 0.00010776519775390625, "timer/dataset_train_max": 0.00030875205993652344, "timer/agent.train_count": 1362.0, "timer/agent.train_total": 619.300347328186, "timer/agent.train_frac": 0.6190142698234088, "timer/agent.train_avg": 0.4546992271132056, "timer/agent.train_min": 0.4412555694580078, "timer/agent.train_max": 1.5693066120147705, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4791548252105713, "timer/agent.report_frac": 0.0004789334860535862, "timer/agent.report_avg": 0.23957741260528564, "timer/agent.report_min": 0.23154187202453613, "timer/agent.report_max": 0.24761295318603516, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8358704934852527e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 21.773634928021877}
{"step": 492056, "time": 23402.928175210953, "episode/length": 213.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 492216, "time": 23409.97291779518, "episode/length": 273.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744525547445255, "episode/intrinsic_return": 0.0}
{"step": 492256, "time": 23413.288306951523, "episode/length": 169.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 492408, "time": 23419.78873538971, "episode/length": 151.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 492584, "time": 23427.378043413162, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 492848, "time": 23439.674840450287, "episode/length": 78.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 493152, "time": 23451.96412563324, "episode/length": 306.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9869706840390879, "episode/intrinsic_return": 0.0}
{"step": 493224, "time": 23455.850578308105, "episode/length": 277.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 493480, "time": 23466.246156454086, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 493536, "time": 23469.91042780876, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 493768, "time": 23479.54541015625, "episode/length": 147.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 494088, "time": 23492.036742925644, "episode/length": 209.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 494360, "time": 23502.810383319855, "episode/length": 102.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9514563106796117, "episode/intrinsic_return": 0.0}
{"step": 494392, "time": 23505.423167467117, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 494536, "time": 23511.826045036316, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 494688, "time": 23518.92692375183, "episode/length": 36.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 494936, "time": 23528.5817759037, "episode/length": 181.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 494952, "time": 23530.707050085068, "episode/length": 262.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 495624, "time": 23555.22754073143, "episode/length": 231.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 495704, "time": 23559.597956180573, "episode/length": 430.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 495752, "time": 23562.93609023094, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 495792, "time": 23566.132076263428, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 496224, "time": 23582.48682641983, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 496272, "time": 23585.617114305496, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 496320, "time": 23588.773275136948, "episode/length": 76.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.935064935064935, "episode/intrinsic_return": 0.0}
{"step": 496720, "time": 23604.10930776596, "episode/length": 220.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 497080, "time": 23617.71210694313, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 497544, "time": 23635.045253753662, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 497544, "time": 23635.054960012436, "episode/length": 158.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 497664, "time": 23642.82626914978, "episode/length": 233.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 497736, "time": 23646.74298262596, "episode/length": 263.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 498048, "time": 23659.07800745964, "episode/length": 215.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 498080, "time": 23661.76163649559, "episode/length": 42.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 498176, "time": 23666.590201854706, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 498376, "time": 23674.751106500626, "episode/length": 429.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 498680, "time": 23686.539536714554, "episode/length": 199.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 499192, "time": 23705.61222720146, "episode/length": 205.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9854368932038835, "episode/intrinsic_return": 0.0}
{"step": 499248, "time": 23709.27825665474, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 499488, "time": 23718.960942983627, "episode/length": 242.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 499648, "time": 23725.99267745018, "episode/length": 199.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 499720, "time": 23730.22557783127, "episode/length": 204.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 23765.02960896492, "eval_episode/length": 156.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 500032, "time": 23767.080444574356, "eval_episode/length": 165.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 500032, "time": 23769.341949939728, "eval_episode/length": 179.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 500032, "time": 23769.34906053543, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 500032, "time": 23772.696940422058, "eval_episode/length": 181.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 500032, "time": 23774.398297071457, "eval_episode/length": 183.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 500032, "time": 23776.319501638412, "eval_episode/length": 191.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 500032, "time": 23784.761999368668, "eval_episode/length": 319.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.990625}
{"step": 500128, "time": 23788.490953683853, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 500424, "time": 23799.719032526016, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 500504, "time": 23804.01482152939, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 500544, "time": 23807.142555236816, "episode/length": 295.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 500696, "time": 23813.5701379776, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 500848, "time": 23820.681481838226, "episode/length": 270.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 501280, "time": 23836.94550037384, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 501416, "time": 23842.949414730072, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 501464, "time": 23846.075273752213, "episode/length": 217.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 501784, "time": 23858.568492650986, "episode/length": 39.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 501936, "time": 23865.614089488983, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 501976, "time": 23868.221523046494, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 502264, "time": 23879.626207351685, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 502424, "time": 23886.71431183815, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 502616, "time": 23894.832663059235, "episode/length": 79.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 502760, "time": 23901.321576356888, "episode/length": 281.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9822695035460993, "episode/intrinsic_return": 0.0}
{"step": 503152, "time": 23916.501982927322, "episode/length": 216.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9585253456221198, "episode/intrinsic_return": 0.0}
{"step": 503280, "time": 23922.450762033463, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 503464, "time": 23930.055591344833, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 503640, "time": 23937.606641292572, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 503688, "time": 23940.956419944763, "episode/length": 300.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9900332225913622, "episode/intrinsic_return": 0.0}
{"step": 503912, "time": 23950.07549905777, "episode/length": 94.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 504008, "time": 23954.822745084763, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 504024, "time": 23956.80722475052, "episode/length": 69.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 504312, "time": 23968.191854715347, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 504776, "time": 23985.565461158752, "episode/length": 186.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 504960, "time": 23993.584218978882, "episode/length": 292.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795221843003413, "episode/intrinsic_return": 0.0}
{"step": 505200, "time": 24003.370375156403, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 505240, "time": 24006.164088964462, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 505512, "time": 24016.907740831375, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 505528, "time": 24019.06783223152, "episode/length": 187.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9840425531914894, "episode/intrinsic_return": 0.0}
{"step": 505592, "time": 24022.895179748535, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 505928, "time": 24036.13824892044, "episode/length": 51.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 506312, "time": 24050.754353523254, "episode/length": 299.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 506392, "time": 24054.99424290657, "episode/length": 178.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 506448, "time": 24058.76851296425, "episode/length": 208.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 506616, "time": 24065.893483400345, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 506704, "time": 24070.765583992004, "episode/length": 48.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 506760, "time": 24074.06024312973, "episode/length": 45.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 506912, "time": 24081.0244948864, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 507040, "time": 24086.923438072205, "episode/length": 224.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 507112, "time": 24090.74511885643, "episode/length": 189.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 507272, "time": 24097.668003320694, "episode/length": 167.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 508080, "time": 24128.526218891144, "episode/length": 100.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9405940594059405, "episode/intrinsic_return": 0.0}
{"step": 508120, "time": 24131.738423347473, "episode/length": 208.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 508232, "time": 24137.07842350006, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 508392, "time": 24144.214162111282, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 508456, "time": 24148.170609235764, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 508592, "time": 24154.614247083664, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 508880, "time": 24165.901522874832, "episode/length": 282.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 509040, "time": 24172.94032907486, "episode/length": 240.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.966804979253112, "episode/intrinsic_return": 0.0}
{"step": 509592, "time": 24193.10115122795, "episode/length": 141.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 509600, "time": 24195.27199625969, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 509712, "time": 24200.681468486786, "episode/length": 203.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 510000, "time": 24212.181120872498, "episode/length": 200.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 24229.310537815094, "eval_episode/length": 40.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9024390243902439}
{"step": 510016, "time": 24235.955230236053, "eval_episode/length": 152.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9607843137254902}
{"step": 510016, "time": 24237.749364852905, "eval_episode/length": 155.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 510016, "time": 24239.438970565796, "eval_episode/length": 156.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 510016, "time": 24241.224239349365, "eval_episode/length": 161.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 510016, "time": 24243.04246044159, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 510016, "time": 24245.48480820656, "eval_episode/length": 183.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9619565217391305}
{"step": 510016, "time": 24247.450797080994, "eval_episode/length": 152.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 510168, "time": 24252.35927605629, "episode/length": 196.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 510240, "time": 24256.67477464676, "episode/length": 250.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9721115537848606, "episode/intrinsic_return": 0.0}
{"step": 510432, "time": 24265.27532696724, "episode/length": 32.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 510576, "time": 24271.671275138855, "episode/length": 122.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967479674796748, "episode/intrinsic_return": 0.0}
{"step": 510872, "time": 24282.96745300293, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9718875502008032, "episode/intrinsic_return": 0.0}
{"step": 510888, "time": 24285.179048538208, "episode/length": 230.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 511384, "time": 24303.55330467224, "episode/length": 222.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 511544, "time": 24310.482026576996, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 511576, "time": 24313.206095457077, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 511744, "time": 24320.70600104332, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 512032, "time": 24332.172433137894, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 512152, "time": 24337.547336101532, "episode/length": 214.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 512176, "time": 24340.16965675354, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 512320, "time": 24346.652634620667, "episode/length": 35.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 512384, "time": 24350.30016040802, "episode/length": 186.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 512744, "time": 24364.045345544815, "episode/length": 169.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 513192, "time": 24380.806314706802, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 513224, "time": 24383.477782011032, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 513320, "time": 24388.421130657196, "episode/length": 217.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 513481, "time": 24396.48320055008, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.402351888020833, "train/action_min": 0.0, "train/action_std": 3.2778569133193405, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05146135994129711, "train/actor_opt_grad_steps": 31320.0, "train/actor_opt_loss": -0.10127837653789255, "train/adv_mag": 0.7430386953883701, "train/adv_max": 0.7295334732090986, "train/adv_mean": 0.004936511159933246, "train/adv_min": -0.5093418295736666, "train/adv_std": 0.07993209215777891, "train/cont_avg": 0.9942780671296296, "train/cont_loss_mean": 0.00030462131720296554, "train/cont_loss_std": 0.009395368470477984, "train/cont_neg_acc": 0.9948148153446339, "train/cont_neg_loss": 0.01666351870681629, "train/cont_pos_acc": 0.9999562872780694, "train/cont_pos_loss": 0.00022681189175388967, "train/cont_pred": 0.994246553933179, "train/cont_rate": 0.9942780671296296, "train/dyn_loss_mean": 13.13069497567636, "train/dyn_loss_std": 9.467065521522805, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8596462889953896, "train/extr_critic_critic_opt_grad_steps": 31320.0, "train/extr_critic_critic_opt_loss": 16478.32374855324, "train/extr_critic_mag": 4.8244120244626645, "train/extr_critic_max": 4.8244120244626645, "train/extr_critic_mean": 0.9555720079828192, "train/extr_critic_min": -0.35850952907844824, "train/extr_critic_std": 1.0929082504025212, "train/extr_return_normed_mag": 1.8381202777226766, "train/extr_return_normed_max": 1.8381202777226766, "train/extr_return_normed_mean": 0.3211197704076767, "train/extr_return_normed_min": -0.16692825610990877, "train/extr_return_normed_std": 0.3361162695619795, "train/extr_return_rate": 0.4954567184050878, "train/extr_return_raw_mag": 6.0844122604087545, "train/extr_return_raw_max": 6.0844122604087545, "train/extr_return_raw_mean": 0.9722277842186116, "train/extr_return_raw_min": -0.6726894398530324, "train/extr_return_raw_std": 1.1327162376156559, "train/extr_reward_mag": 1.0121219935240569, "train/extr_reward_max": 1.0121219935240569, "train/extr_reward_mean": 0.027112839343371213, "train/extr_reward_min": -0.4879161145952013, "train/extr_reward_std": 0.15592158376066773, "train/image_loss_mean": 6.520065282892298, "train/image_loss_std": 10.486949316660564, "train/model_loss_mean": 14.448371639958134, "train/model_loss_std": 14.459615686204698, "train/model_opt_grad_norm": 57.6352557570846, "train/model_opt_grad_steps": 31291.022222222222, "train/model_opt_loss": 18587.835930266203, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1287.037037037037, "train/policy_entropy_mag": 2.513041362056026, "train/policy_entropy_max": 2.513041362056026, "train/policy_entropy_mean": 0.5792554252677493, "train/policy_entropy_min": 0.07937512121818684, "train/policy_entropy_std": 0.6018626736270056, "train/policy_logprob_mag": 7.438383208380805, "train/policy_logprob_max": -0.009455682095830087, "train/policy_logprob_mean": -0.5782970194463377, "train/policy_logprob_min": -7.438383208380805, "train/policy_logprob_std": 1.1090222305721706, "train/policy_randomness_mag": 0.8869933198999476, "train/policy_randomness_max": 0.8869933198999476, "train/policy_randomness_mean": 0.20445174696268859, "train/policy_randomness_min": 0.0280159344965661, "train/policy_randomness_std": 0.21243111259407468, "train/post_ent_mag": 58.44625314783167, "train/post_ent_max": 58.44625314783167, "train/post_ent_mean": 41.719810457582824, "train/post_ent_min": 21.57739267702456, "train/post_ent_std": 7.12973733831335, "train/prior_ent_mag": 68.40714755588108, "train/prior_ent_max": 68.40714755588108, "train/prior_ent_mean": 54.91875356038411, "train/prior_ent_min": 37.53765866314923, "train/prior_ent_std": 4.926525220164546, "train/rep_loss_mean": 13.13069497567636, "train/rep_loss_std": 9.467065521522805, "train/reward_avg": 0.02061848946398607, "train/reward_loss_mean": 0.049584805482515586, "train/reward_loss_std": 0.23422260483105978, "train/reward_max_data": 1.008148150090818, "train/reward_max_pred": 1.0053551091088189, "train/reward_neg_acc": 0.9934765096063967, "train/reward_neg_loss": 0.027808861165410943, "train/reward_pos_acc": 0.9626318825615777, "train/reward_pos_loss": 0.8756115953127543, "train/reward_pred": 0.01985698368538309, "train/reward_rate": 0.02581741898148148, "train_stats/sum_log_reward": 5.769565180073614, "train_stats/max_log_achievement_collect_coal": 0.017391304347826087, "train_stats/max_log_achievement_collect_drink": 6.104347826086957, "train_stats/max_log_achievement_collect_sapling": 2.8521739130434782, "train_stats/max_log_achievement_collect_stone": 0.11304347826086956, "train_stats/max_log_achievement_collect_wood": 8.182608695652174, "train_stats/max_log_achievement_defeat_skeleton": 0.008695652173913044, "train_stats/max_log_achievement_defeat_zombie": 0.6347826086956522, "train_stats/max_log_achievement_eat_cow": 0.06086956521739131, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02608695652173913, "train_stats/max_log_achievement_make_wood_sword": 1.1565217391304348, "train_stats/max_log_achievement_place_plant": 2.7217391304347824, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.5739130434782607, "train_stats/max_log_achievement_wake_up": 1.6347826086956523, "train_stats/mean_log_entropy": 0.5303859950407691, "eval_stats/sum_log_reward": 5.850000008940697, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.8125, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.9375, "eval_stats/max_log_achievement_place_plant": 2.75, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.25, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.1395513865863904e-06, "report/cont_loss_std": 1.4190515685186256e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00019668746972456574, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.726967179318308e-07, "report/cont_pred": 0.9960942268371582, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.951908111572266, "report/dyn_loss_std": 9.797720909118652, "report/image_loss_mean": 5.854978561401367, "report/image_loss_std": 11.433320999145508, "report/model_loss_mean": 13.665306091308594, "report/model_loss_std": 15.653295516967773, "report/post_ent_mag": 56.96867370605469, "report/post_ent_max": 56.96867370605469, "report/post_ent_mean": 41.296165466308594, "report/post_ent_min": 20.100008010864258, "report/post_ent_std": 6.860016345977783, "report/prior_ent_mag": 68.48551177978516, "report/prior_ent_max": 68.48551177978516, "report/prior_ent_mean": 54.57762145996094, "report/prior_ent_min": 36.214759826660156, "report/prior_ent_std": 4.681342601776123, "report/rep_loss_mean": 12.951908111572266, "report/rep_loss_std": 9.797720909118652, "report/reward_avg": 0.01962890475988388, "report/reward_loss_mean": 0.039181455969810486, "report/reward_loss_std": 0.23526516556739807, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0019917488098145, "report/reward_neg_acc": 0.9960000514984131, "report/reward_neg_loss": 0.021010491997003555, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7963051199913025, "report/reward_pred": 0.01958942785859108, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.826708052656613e-06, "eval/cont_loss_std": 6.263613613555208e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00097912538331002, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.9181002244295087e-06, "eval/cont_pred": 0.998046875, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.477066040039062, "eval/dyn_loss_std": 9.863238334655762, "eval/image_loss_mean": 11.890451431274414, "eval/image_loss_std": 15.192760467529297, "eval/model_loss_mean": 21.306320190429688, "eval/model_loss_std": 19.05949592590332, "eval/post_ent_mag": 59.047515869140625, "eval/post_ent_max": 59.047515869140625, "eval/post_ent_mean": 41.99271774291992, "eval/post_ent_min": 21.593273162841797, "eval/post_ent_std": 7.103084087371826, "eval/prior_ent_mag": 68.48551177978516, "eval/prior_ent_max": 68.48551177978516, "eval/prior_ent_mean": 55.5433235168457, "eval/prior_ent_min": 39.13334274291992, "eval/prior_ent_std": 4.66248083114624, "eval/rep_loss_mean": 15.477066040039062, "eval/rep_loss_std": 9.863238334655762, "eval/reward_avg": 0.03291015699505806, "eval/reward_loss_mean": 0.12962648272514343, "eval/reward_loss_std": 0.7918058037757874, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.004894733428955, "eval/reward_neg_acc": 0.9858441948890686, "eval/reward_neg_loss": 0.04113489016890526, "eval/reward_pos_acc": 0.6857143044471741, "eval/reward_pos_loss": 2.630146026611328, "eval/reward_pred": 0.02566773071885109, "eval/reward_rate": 0.0341796875, "replay/size": 512977.0, "replay/inserts": 21616.0, "replay/samples": 21616.0, "replay/insert_wait_avg": 1.4382984618801791e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.620503741136575e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 99432.0, "eval_replay/inserts": 4112.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.246189328946956e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0828955173492, "timer/env.step_count": 2702.0, "timer/env.step_total": 264.5648036003113, "timer/env.step_frac": 0.2645428741818949, "timer/env.step_avg": 0.09791443508523734, "timer/env.step_min": 0.024889469146728516, "timer/env.step_max": 3.524144411087036, "timer/replay._sample_count": 21616.0, "timer/replay._sample_total": 11.561458587646484, "timer/replay._sample_frac": 0.011560500273995456, "timer/replay._sample_avg": 0.0005348565223744673, "timer/replay._sample_min": 0.00039649009704589844, "timer/replay._sample_max": 0.0318760871887207, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3216.0, "timer/agent.policy_total": 56.74988627433777, "timer/agent.policy_frac": 0.056745182353089535, "timer/agent.policy_avg": 0.017646108916149802, "timer/agent.policy_min": 0.009765625, "timer/agent.policy_max": 0.13304567337036133, "timer/dataset_train_count": 1351.0, "timer/dataset_train_total": 0.1659390926361084, "timer/dataset_train_frac": 0.0001659253381693595, "timer/dataset_train_avg": 0.0001228268635352394, "timer/dataset_train_min": 0.00010633468627929688, "timer/dataset_train_max": 0.0004749298095703125, "timer/agent.train_count": 1351.0, "timer/agent.train_total": 609.6737034320831, "timer/agent.train_frac": 0.6096231684041502, "timer/agent.train_avg": 0.4512758722665308, "timer/agent.train_min": 0.4350547790527344, "timer/agent.train_max": 1.90958833694458, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4750189781188965, "timer/agent.report_frac": 0.00047497960443885617, "timer/agent.report_avg": 0.23750948905944824, "timer/agent.report_min": 0.2308213710784912, "timer/agent.report_max": 0.24419760704040527, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.743171691894531e-05, "timer/dataset_eval_frac": 3.742861425460301e-08, "timer/dataset_eval_avg": 3.743171691894531e-05, "timer/dataset_eval_min": 3.743171691894531e-05, "timer/dataset_eval_max": 3.743171691894531e-05, "fps": 21.613923662616788}
{"step": 513560, "time": 24399.021257400513, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 513696, "time": 24405.286328554153, "episode/length": 189.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 514200, "time": 24423.801455259323, "episode/length": 226.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 514328, "time": 24429.756709337234, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 514352, "time": 24432.29484629631, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 514384, "time": 24434.8494412899, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 514688, "time": 24446.651829719543, "episode/length": 186.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 514864, "time": 24454.17641568184, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 514984, "time": 24459.556400299072, "episode/length": 74.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 515256, "time": 24470.396879434586, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 515424, "time": 24478.080551862717, "episode/length": 232.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 515728, "time": 24489.924092531204, "episode/length": 190.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 515864, "time": 24495.804649353027, "episode/length": 188.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 515992, "time": 24501.726146936417, "episode/length": 207.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 516336, "time": 24516.752078533173, "episode/length": 205.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 516480, "time": 24523.14505457878, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 516568, "time": 24527.469508886337, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 516736, "time": 24535.012783527374, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 517096, "time": 24548.72400021553, "episode/length": 208.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9904306220095693, "episode/intrinsic_return": 0.0}
{"step": 517552, "time": 24565.88340139389, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 517736, "time": 24573.521760702133, "episode/length": 217.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 517776, "time": 24576.53761267662, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 517824, "time": 24579.828629732132, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 518136, "time": 24591.75358390808, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 518168, "time": 24594.4017932415, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 518656, "time": 24612.723827123642, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 518800, "time": 24619.15760064125, "episode/length": 257.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 519168, "time": 24633.22476053238, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 519176, "time": 24634.949786663055, "episode/length": 179.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 519432, "time": 24645.101814985275, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 519448, "time": 24647.23332309723, "episode/length": 202.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9605911330049262, "episode/intrinsic_return": 0.0}
{"step": 519472, "time": 24649.810747385025, "episode/length": 36.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 519600, "time": 24655.63530397415, "episode/length": 255.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 519776, "time": 24663.236105442047, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 519976, "time": 24671.253747940063, "episode/length": 146.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 24690.63442826271, "eval_episode/length": 79.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9375}
{"step": 520000, "time": 24696.96387720108, "eval_episode/length": 185.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 520000, "time": 24698.70590376854, "eval_episode/length": 188.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 520000, "time": 24700.50232744217, "eval_episode/length": 191.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 520000, "time": 24703.35161757469, "eval_episode/length": 217.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.981651376146789}
{"step": 520000, "time": 24705.927461862564, "eval_episode/length": 239.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9958333333333333}
{"step": 520000, "time": 24707.834576129913, "eval_episode/length": 249.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.968}
{"step": 520000, "time": 24709.83006286621, "eval_episode/length": 178.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.994413407821229}
{"step": 520080, "time": 24712.515643119812, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 520296, "time": 24721.199072122574, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 520432, "time": 24727.657682180405, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 520752, "time": 24739.93620324135, "episode/length": 39.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 520808, "time": 24743.1790060997, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 520872, "time": 24746.95915079117, "episode/length": 174.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 521104, "time": 24756.6545855999, "episode/length": 206.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 521112, "time": 24758.232152462006, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 521296, "time": 24766.295984745026, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 521560, "time": 24776.36765575409, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 521864, "time": 24788.299403190613, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 522064, "time": 24796.71806526184, "episode/length": 148.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 522224, "time": 24803.659687280655, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 522400, "time": 24811.33934020996, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 522632, "time": 24820.44376397133, "episode/length": 190.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 522688, "time": 24824.255518436432, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 522912, "time": 24833.260068655014, "episode/length": 201.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 523032, "time": 24838.766705513, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 523296, "time": 24849.365832567215, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 523344, "time": 24852.563470840454, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 523552, "time": 24861.114849567413, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 523864, "time": 24873.020370960236, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 524280, "time": 24888.755709409714, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 524328, "time": 24893.41121506691, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 524344, "time": 24895.514802455902, "episode/length": 206.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 524664, "time": 24908.112812280655, "episode/length": 203.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 524784, "time": 24913.811429023743, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 525032, "time": 24923.499436616898, "episode/length": 216.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 525104, "time": 24927.814220666885, "episode/length": 39.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 525112, "time": 24929.459939956665, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 525200, "time": 24934.13671064377, "episode/length": 114.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 525504, "time": 24945.920849084854, "episode/length": 243.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 525616, "time": 24951.189866781235, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 526104, "time": 24968.993386030197, "episode/length": 221.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 526728, "time": 24991.78548836708, "episode/length": 211.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 526736, "time": 24993.93656229973, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 526752, "time": 24996.06943631172, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 526752, "time": 24996.079654693604, "episode/length": 141.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 526848, "time": 25002.60181760788, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 526856, "time": 25004.258225679398, "episode/length": 218.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 526984, "time": 25010.104789495468, "episode/length": 289.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 527672, "time": 25034.945494413376, "episode/length": 195.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 528040, "time": 25049.173942565918, "episode/length": 148.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 528104, "time": 25052.968503713608, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 528144, "time": 25056.03785300255, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 528168, "time": 25058.302233457565, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 528272, "time": 25063.70920085907, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 528640, "time": 25078.162378311157, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 528968, "time": 25090.539140462875, "episode/length": 115.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9568965517241379, "episode/intrinsic_return": 0.0}
{"step": 529344, "time": 25104.933145284653, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 529832, "time": 25122.924808979034, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 529920, "time": 25127.72958946228, "episode/length": 226.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9647577092511013, "episode/intrinsic_return": 0.0}
{"step": 530008, "time": 25132.589221715927, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 25153.084787368774, "eval_episode/length": 52.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 530088, "time": 25159.338720560074, "eval_episode/length": 154.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 530088, "time": 25162.99446439743, "eval_episode/length": 184.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9675675675675676}
{"step": 530088, "time": 25166.560173034668, "eval_episode/length": 211.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 530088, "time": 25168.869522809982, "eval_episode/length": 213.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 530088, "time": 25171.575965881348, "eval_episode/length": 237.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9789915966386554}
{"step": 530088, "time": 25175.047394275665, "eval_episode/length": 277.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9712230215827338}
{"step": 530088, "time": 25178.475110769272, "eval_episode/length": 318.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9968652037617555}
{"step": 530192, "time": 25182.21601676941, "episode/length": 429.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9930232558139535, "episode/intrinsic_return": 0.0}
{"step": 530368, "time": 25189.6708920002, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 530448, "time": 25193.92457294464, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 530888, "time": 25210.317687034607, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 530912, "time": 25212.899047613144, "episode/length": 134.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 531736, "time": 25242.147243976593, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 531976, "time": 25251.937046289444, "episode/length": 222.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 531992, "time": 25254.02797818184, "episode/length": 247.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 532192, "time": 25262.815172195435, "episode/length": 443.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 532440, "time": 25272.545855760574, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 532504, "time": 25277.798572540283, "episode/length": 256.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9727626459143969, "episode/intrinsic_return": 0.0}
{"step": 532520, "time": 25280.003917217255, "episode/length": 324.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9876923076923076, "episode/intrinsic_return": 0.0}
{"step": 532960, "time": 25296.824575424194, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 533320, "time": 25310.465696811676, "episode/length": 300.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 533512, "time": 25318.702486753464, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 533536, "time": 25321.30782723427, "episode/length": 126.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 533728, "time": 25329.358261346817, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 533760, "time": 25332.020498514175, "episode/length": 220.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 534176, "time": 25347.470110416412, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 534440, "time": 25357.938318014145, "episode/length": 241.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 534528, "time": 25362.74054169655, "episode/length": 260.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731800766283525, "episode/intrinsic_return": 0.0}
{"step": 534776, "time": 25372.502986431122, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 534936, "time": 25379.58158636093, "episode/length": 146.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 534976, "time": 25382.848460435867, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 535224, "time": 25392.52107524872, "episode/length": 210.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 535273, "time": 25396.790193080902, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.343136058134191, "train/action_min": 0.0, "train/action_std": 3.2200648434021892, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05081170906915384, "train/actor_opt_grad_steps": 32675.0, "train/actor_opt_loss": 0.6637377558714327, "train/adv_mag": 0.7300383041010183, "train/adv_max": 0.7087039355846012, "train/adv_mean": 0.005110204482608584, "train/adv_min": -0.49797232032698746, "train/adv_std": 0.07842012344147353, "train/cont_avg": 0.9943704044117647, "train/cont_loss_mean": 0.00020302939035964166, "train/cont_loss_std": 0.006088344125033399, "train/cont_neg_acc": 0.9953431381898767, "train/cont_neg_loss": 0.01159011610117405, "train/cont_pos_acc": 0.9999638458385187, "train/cont_pos_loss": 0.0001366774358108646, "train/cont_pred": 0.9943470928598853, "train/cont_rate": 0.9943704044117647, "train/dyn_loss_mean": 13.04441133667441, "train/dyn_loss_std": 9.54415640410255, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8862990824615254, "train/extr_critic_critic_opt_grad_steps": 32675.0, "train/extr_critic_critic_opt_loss": 16535.370318244484, "train/extr_critic_mag": 4.934426914243137, "train/extr_critic_max": 4.934426914243137, "train/extr_critic_mean": 1.0148009210824966, "train/extr_critic_min": -0.3614834774942959, "train/extr_critic_std": 1.1243556514382362, "train/extr_return_normed_mag": 1.8533737159827177, "train/extr_return_normed_max": 1.8533737159827177, "train/extr_return_normed_mean": 0.3318404099520515, "train/extr_return_normed_min": -0.16834509159054825, "train/extr_return_normed_std": 0.3386007477255428, "train/extr_return_rate": 0.5228501523242277, "train/extr_return_raw_mag": 6.26009412723429, "train/extr_return_raw_max": 6.26009412723429, "train/extr_return_raw_mean": 1.0323486187878776, "train/extr_return_raw_min": -0.6862817969830597, "train/extr_return_raw_std": 1.1634838510962093, "train/extr_reward_mag": 1.0154765528791092, "train/extr_reward_max": 1.0154765528791092, "train/extr_reward_mean": 0.028373119092601186, "train/extr_reward_min": -0.48603907402823954, "train/extr_reward_std": 0.15879761602948694, "train/image_loss_mean": 6.48304210690891, "train/image_loss_std": 10.772911162937389, "train/model_loss_mean": 14.360949221779318, "train/model_loss_std": 14.771355867385864, "train/model_opt_grad_norm": 55.27455076049356, "train/model_opt_grad_steps": 32644.66176470588, "train/model_opt_loss": 18553.45448213465, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1295.9558823529412, "train/policy_entropy_mag": 2.4839902607833637, "train/policy_entropy_max": 2.4839902607833637, "train/policy_entropy_mean": 0.5920768963063464, "train/policy_entropy_min": 0.07937512837131233, "train/policy_entropy_std": 0.599403032046907, "train/policy_logprob_mag": 7.438383256687837, "train/policy_logprob_max": -0.009455686263904414, "train/policy_logprob_mean": -0.5927023309118608, "train/policy_logprob_min": -7.438383256687837, "train/policy_logprob_std": 1.1190796862630283, "train/policy_randomness_mag": 0.8767395562985364, "train/policy_randomness_max": 0.8767395562985364, "train/policy_randomness_mean": 0.20897716283798218, "train/policy_randomness_min": 0.028015936971368158, "train/policy_randomness_std": 0.21156296758529017, "train/post_ent_mag": 58.42239205977496, "train/post_ent_max": 58.42239205977496, "train/post_ent_mean": 41.86658836813534, "train/post_ent_min": 21.40883159637451, "train/post_ent_std": 7.203279631979325, "train/prior_ent_mag": 68.60599893682144, "train/prior_ent_max": 68.60599893682144, "train/prior_ent_mean": 54.99970694149242, "train/prior_ent_min": 37.387336141922894, "train/prior_ent_std": 4.896318013177199, "train/rep_loss_mean": 13.04441133667441, "train/rep_loss_std": 9.54415640410255, "train/reward_avg": 0.02115119467078544, "train/reward_loss_mean": 0.051057360874598515, "train/reward_loss_std": 0.24188377817764, "train/reward_max_data": 1.0066176486365936, "train/reward_max_pred": 1.0030382003854303, "train/reward_neg_acc": 0.9929846227169037, "train/reward_neg_loss": 0.02849221638376441, "train/reward_pos_acc": 0.9589655394939816, "train/reward_pos_loss": 0.8902811403660214, "train/reward_pred": 0.020386148442733374, "train/reward_rate": 0.026223575367647058, "train_stats/sum_log_reward": 6.215044238926035, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.716814159292035, "train_stats/max_log_achievement_collect_sapling": 3.0353982300884956, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 8.628318584070797, "train_stats/max_log_achievement_defeat_skeleton": 0.02654867256637168, "train_stats/max_log_achievement_defeat_zombie": 0.7256637168141593, "train_stats/max_log_achievement_eat_cow": 0.09734513274336283, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02654867256637168, "train_stats/max_log_achievement_make_wood_sword": 1.3805309734513274, "train_stats/max_log_achievement_place_plant": 2.8672566371681416, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.6371681415929205, "train_stats/max_log_achievement_wake_up": 1.5044247787610618, "train_stats/mean_log_entropy": 0.5369503126207706, "eval_stats/sum_log_reward": 6.78750005364418, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.5625, "eval_stats/max_log_achievement_collect_sapling": 2.8125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.4375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.5625, "eval_stats/max_log_achievement_place_plant": 2.5625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.8125, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 5.1520873967092484e-05, "report/cont_loss_std": 0.0015366004081442952, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003152853169012815, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.918207923765294e-05, "report/cont_pred": 0.9911661148071289, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 13.222335815429688, "report/dyn_loss_std": 9.127492904663086, "report/image_loss_mean": 7.060762405395508, "report/image_loss_std": 8.723053932189941, "report/model_loss_mean": 15.063020706176758, "report/model_loss_std": 12.599987983703613, "report/post_ent_mag": 58.375587463378906, "report/post_ent_max": 58.375587463378906, "report/post_ent_mean": 41.52268981933594, "report/post_ent_min": 19.788108825683594, "report/post_ent_std": 7.140262126922607, "report/prior_ent_mag": 68.67088317871094, "report/prior_ent_max": 68.67088317871094, "report/prior_ent_mean": 54.90770721435547, "report/prior_ent_min": 39.22685241699219, "report/prior_ent_std": 4.4073381423950195, "report/rep_loss_mean": 13.222335815429688, "report/rep_loss_std": 9.127492904663086, "report/reward_avg": 0.02871093899011612, "report/reward_loss_mean": 0.06880535185337067, "report/reward_loss_std": 0.3380073010921478, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023961067199707, "report/reward_neg_acc": 0.9989867806434631, "report/reward_neg_loss": 0.03906808793544769, "report/reward_pos_acc": 0.9459459185600281, "report/reward_pos_loss": 0.8620668649673462, "report/reward_pred": 0.02742031216621399, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.7189571483177133e-05, "eval/cont_loss_std": 0.0008028277079574764, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006801082636229694, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.5271103368140757e-05, "eval/cont_pred": 0.997047483921051, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.383419036865234, "eval/dyn_loss_std": 10.666132926940918, "eval/image_loss_mean": 10.932754516601562, "eval/image_loss_std": 14.548311233520508, "eval/model_loss_mean": 21.444053649902344, "eval/model_loss_std": 18.48169708251953, "eval/post_ent_mag": 54.29545211791992, "eval/post_ent_max": 54.29545211791992, "eval/post_ent_mean": 39.96833801269531, "eval/post_ent_min": 18.24295425415039, "eval/post_ent_std": 6.670273303985596, "eval/prior_ent_mag": 68.67088317871094, "eval/prior_ent_max": 68.67088317871094, "eval/prior_ent_mean": 55.054420471191406, "eval/prior_ent_min": 39.54274368286133, "eval/prior_ent_std": 4.484940528869629, "eval/rep_loss_mean": 17.383419036865234, "eval/rep_loss_std": 10.666132926940918, "eval/reward_avg": 0.02392578125, "eval/reward_loss_mean": 0.08122030645608902, "eval/reward_loss_std": 0.5756223797798157, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0022211074829102, "eval/reward_neg_acc": 0.9909639358520508, "eval/reward_neg_loss": 0.02552996762096882, "eval/reward_pos_acc": 0.8214285969734192, "eval/reward_pos_loss": 2.0622053146362305, "eval/reward_pred": 0.01838255114853382, "eval/reward_rate": 0.02734375, "replay/size": 534769.0, "replay/inserts": 21792.0, "replay/samples": 21792.0, "replay/insert_wait_avg": 1.4243737716506756e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.517950116800317e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2316918290610132e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.5348196029663086e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2936692237854, "timer/env.step_count": 2724.0, "timer/env.step_total": 257.15430784225464, "timer/env.step_frac": 0.2570788117071689, "timer/env.step_avg": 0.09440319671154722, "timer/env.step_min": 0.02397775650024414, "timer/env.step_max": 3.3012337684631348, "timer/replay._sample_count": 21792.0, "timer/replay._sample_total": 11.58628511428833, "timer/replay._sample_frac": 0.011582883577858824, "timer/replay._sample_avg": 0.0005316760790330548, "timer/replay._sample_min": 0.0004069805145263672, "timer/replay._sample_max": 0.01200723648071289, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3302.0, "timer/agent.policy_total": 56.99824285507202, "timer/agent.policy_frac": 0.0569815091395129, "timer/agent.policy_avg": 0.017261733148113877, "timer/agent.policy_min": 0.009620904922485352, "timer/agent.policy_max": 0.12168717384338379, "timer/dataset_train_count": 1362.0, "timer/dataset_train_total": 0.16538429260253906, "timer/dataset_train_frac": 0.00016533573858452496, "timer/dataset_train_avg": 0.0001214275276083253, "timer/dataset_train_min": 0.00010609626770019531, "timer/dataset_train_max": 0.00039505958557128906, "timer/agent.train_count": 1362.0, "timer/agent.train_total": 613.6304216384888, "timer/agent.train_frac": 0.6134502701738159, "timer/agent.train_avg": 0.4505362860781856, "timer/agent.train_min": 0.4372992515563965, "timer/agent.train_max": 1.7513198852539062, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47835254669189453, "timer/agent.report_frac": 0.00047821211051259554, "timer/agent.report_avg": 0.23917627334594727, "timer/agent.report_min": 0.23138880729675293, "timer/agent.report_max": 0.2469637393951416, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.122366443300691e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 21.785299163541154}
{"step": 535472, "time": 25403.621611595154, "episode/length": 217.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 535664, "time": 25411.653010845184, "episode/length": 185.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 535720, "time": 25414.914212703705, "episode/length": 159.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 536144, "time": 25430.886302232742, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9603960396039604, "episode/intrinsic_return": 0.0}
{"step": 536408, "time": 25441.214901447296, "episode/length": 203.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 536672, "time": 25451.946053028107, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 536752, "time": 25456.31914973259, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 536800, "time": 25459.472584486008, "episode/length": 48.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 536880, "time": 25463.817681074142, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 537256, "time": 25477.88881421089, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 537296, "time": 25481.03908777237, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 537320, "time": 25483.184730529785, "episode/length": 292.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9863481228668942, "episode/intrinsic_return": 0.0}
{"step": 537552, "time": 25492.756026029587, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 538032, "time": 25510.526566505432, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 538288, "time": 25520.613918542862, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 538392, "time": 25525.55859899521, "episode/length": 280.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715302491103203, "episode/intrinsic_return": 0.0}
{"step": 538432, "time": 25528.89932179451, "episode/length": 193.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 538576, "time": 25535.838228225708, "episode/length": 221.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 538584, "time": 25537.517552614212, "episode/length": 36.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 538704, "time": 25543.387413740158, "episode/length": 175.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 539064, "time": 25556.809156179428, "episode/length": 217.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 539064, "time": 25556.81810259819, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 539352, "time": 25569.935258865356, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 539936, "time": 25591.435595989227, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 25617.6324133873, "eval_episode/length": 159.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9625}
{"step": 540072, "time": 25620.113486766815, "eval_episode/length": 173.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 540072, "time": 25622.323946237564, "eval_episode/length": 186.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 540072, "time": 25624.673728227615, "eval_episode/length": 202.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 540072, "time": 25626.408641815186, "eval_episode/length": 206.0, "eval_episode/score": 4.0999999567866325, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 540072, "time": 25628.29793381691, "eval_episode/length": 212.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.971830985915493}
{"step": 540072, "time": 25630.796534061432, "eval_episode/length": 229.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 540072, "time": 25639.23440003395, "eval_episode/length": 155.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 540072, "time": 25639.24352478981, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 540200, "time": 25643.57853770256, "episode/length": 225.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 540256, "time": 25647.22133040428, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 540560, "time": 25659.211221456528, "episode/length": 247.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 540592, "time": 25661.84069633484, "episode/length": 154.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 540592, "time": 25661.85063266754, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 540728, "time": 25671.936186552048, "episode/length": 267.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 541440, "time": 25697.83668923378, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 541600, "time": 25704.726199388504, "episode/length": 167.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 541752, "time": 25711.31702232361, "episode/length": 144.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 541952, "time": 25719.945588350296, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 542176, "time": 25729.096316576004, "episode/length": 180.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 542256, "time": 25733.40414261818, "episode/length": 211.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 542424, "time": 25740.637818574905, "episode/length": 228.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 542600, "time": 25748.186631441116, "episode/length": 441.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 542872, "time": 25758.931185245514, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 543168, "time": 25770.837110996246, "episode/length": 215.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 543232, "time": 25774.538254976273, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 543288, "time": 25777.69618654251, "episode/length": 138.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9496402877697842, "episode/intrinsic_return": 0.0}
{"step": 543360, "time": 25781.932513237, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 543752, "time": 25796.456483840942, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 543936, "time": 25804.583742141724, "episode/length": 188.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 544128, "time": 25812.499222040176, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 544336, "time": 25821.003459215164, "episode/length": 216.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 544744, "time": 25836.199412822723, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 544784, "time": 25839.35861825943, "episode/length": 201.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 544976, "time": 25847.307906866074, "episode/length": 201.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 545192, "time": 25855.877470970154, "episode/length": 55.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 545192, "time": 25855.900540351868, "episode/length": 156.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 545232, "time": 25861.015768527985, "episode/length": 249.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 545368, "time": 25866.945511102676, "episode/length": 201.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 545840, "time": 25884.577944278717, "episode/length": 187.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 546216, "time": 25898.731667757034, "episode/length": 260.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 546408, "time": 25906.75496315956, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 546592, "time": 25914.69014286995, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 546600, "time": 25916.31864619255, "episode/length": 202.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 546608, "time": 25918.584082841873, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 546672, "time": 25922.30491042137, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 547048, "time": 25936.676254034042, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 547408, "time": 25950.774605989456, "episode/length": 195.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 547768, "time": 25964.060714244843, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 548120, "time": 25977.43883562088, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 548240, "time": 25983.315071821213, "episode/length": 58.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 548376, "time": 25989.163198947906, "episode/length": 165.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 548384, "time": 25991.17706179619, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 548416, "time": 25993.80159139633, "episode/length": 274.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9745454545454545, "episode/intrinsic_return": 0.0}
{"step": 548688, "time": 26004.413548231125, "episode/length": 260.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 549584, "time": 26038.357805252075, "episode/length": 371.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 549744, "time": 26045.364169359207, "episode/length": 169.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 549864, "time": 26050.823108434677, "episode/length": 217.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 549904, "time": 26054.018167972565, "episode/length": 151.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 549992, "time": 26058.396047592163, "episode/length": 322.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 26081.253929376602, "eval_episode/length": 128.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9922480620155039}
{"step": 550056, "time": 26084.277122735977, "eval_episode/length": 156.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 550056, "time": 26087.14802980423, "eval_episode/length": 172.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9826589595375722}
{"step": 550056, "time": 26088.893333911896, "eval_episode/length": 173.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 550056, "time": 26091.54688167572, "eval_episode/length": 197.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 550056, "time": 26093.382230997086, "eval_episode/length": 201.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 550056, "time": 26095.417506694794, "eval_episode/length": 39.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9}
{"step": 550056, "time": 26097.27031159401, "eval_episode/length": 218.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 550112, "time": 26099.510539531708, "episode/length": 216.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 550288, "time": 26107.006558656693, "episode/length": 233.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 550456, "time": 26114.020262479782, "episode/length": 42.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 550544, "time": 26118.821981191635, "episode/length": 287.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 550704, "time": 26125.761330604553, "episode/length": 104.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 550824, "time": 26131.345068454742, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 551192, "time": 26145.155390024185, "episode/length": 149.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 551784, "time": 26166.765187740326, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 551832, "time": 26169.944830417633, "episode/length": 171.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 552032, "time": 26178.49478816986, "episode/length": 150.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 552064, "time": 26181.203771591187, "episode/length": 221.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 552072, "time": 26182.790133953094, "episode/length": 290.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 552168, "time": 26187.638105392456, "episode/length": 182.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 552576, "time": 26203.212856292725, "episode/length": 253.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 552688, "time": 26208.52227449417, "episode/length": 186.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 553104, "time": 26224.271089315414, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 553328, "time": 26233.373772382736, "episode/length": 186.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 553744, "time": 26249.20982670784, "episode/length": 208.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 553792, "time": 26252.34472513199, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 554000, "time": 26260.849712371826, "episode/length": 163.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 554424, "time": 26276.511747837067, "episode/length": 298.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.979933110367893, "episode/intrinsic_return": 0.0}
{"step": 554488, "time": 26280.41903781891, "episode/length": 302.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 554496, "time": 26282.507819890976, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 554888, "time": 26297.130123853683, "episode/length": 222.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 555080, "time": 26305.208189725876, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9503105590062112, "episode/intrinsic_return": 0.0}
{"step": 555272, "time": 26313.331937789917, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 555384, "time": 26318.67411661148, "episode/length": 256.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 555552, "time": 26326.225838422775, "episode/length": 193.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 555568, "time": 26328.453419446945, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 555824, "time": 26338.781878471375, "episode/length": 174.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 556544, "time": 26364.608119487762, "episode/length": 182.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 556624, "time": 26368.964713335037, "episode/length": 265.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 556640, "time": 26371.13013601303, "episode/length": 268.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 556808, "time": 26378.183851242065, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 557000, "time": 26386.18019247055, "episode/length": 178.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 557201, "time": 26396.85402917862, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.211947475906706, "train/action_min": 0.0, "train/action_std": 3.1998639646237783, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05005151196552889, "train/actor_opt_grad_steps": 34040.0, "train/actor_opt_loss": -1.7985150921736321, "train/adv_mag": 0.7026166317671755, "train/adv_max": 0.6797051440625295, "train/adv_mean": 0.004761569600796198, "train/adv_min": -0.4983325217762133, "train/adv_std": 0.07643533636727472, "train/cont_avg": 0.9946823677007299, "train/cont_loss_mean": 0.0003076394252756029, "train/cont_loss_std": 0.009334370855940305, "train/cont_neg_acc": 0.98896183599444, "train/cont_neg_loss": 0.02576950594333111, "train/cont_pos_acc": 0.9999426094284893, "train/cont_pos_loss": 0.0001415498318777341, "train/cont_pred": 0.9946796141401695, "train/cont_rate": 0.9946823677007299, "train/dyn_loss_mean": 13.039735891523152, "train/dyn_loss_std": 9.4879636138025, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.847995875960719, "train/extr_critic_critic_opt_grad_steps": 34040.0, "train/extr_critic_critic_opt_loss": 16295.054352474908, "train/extr_critic_mag": 5.08599662084649, "train/extr_critic_max": 5.08599662084649, "train/extr_critic_mean": 1.0676450768526453, "train/extr_critic_min": -0.3616149112255904, "train/extr_critic_std": 1.1494418774208013, "train/extr_return_normed_mag": 1.821693886805625, "train/extr_return_normed_max": 1.821693886805625, "train/extr_return_normed_mean": 0.33566683041353296, "train/extr_return_normed_min": -0.15791425051806618, "train/extr_return_normed_std": 0.3348545151470351, "train/extr_return_rate": 0.5533835439786424, "train/extr_return_raw_mag": 6.370531249220353, "train/extr_return_raw_max": 6.370531249220353, "train/extr_return_raw_mean": 1.0845789539552952, "train/extr_return_raw_min": -0.6702648926607884, "train/extr_return_raw_std": 1.1908421272779033, "train/extr_reward_mag": 1.0144948402460474, "train/extr_reward_max": 1.0144948402460474, "train/extr_reward_mean": 0.027221569444739472, "train/extr_reward_min": -0.5090100495484624, "train/extr_reward_std": 0.15643789782358783, "train/image_loss_mean": 6.322480118187674, "train/image_loss_std": 10.77761070919733, "train/model_loss_mean": 14.196476024432775, "train/model_loss_std": 14.744659270683345, "train/model_opt_grad_norm": 52.47354318113888, "train/model_opt_grad_steps": 34008.42335766424, "train/model_opt_loss": 18400.405344719435, "train/model_opt_model_opt_grad_overflow": 0.0072992700729927005, "train/model_opt_model_opt_grad_scale": 1286.4963503649635, "train/policy_entropy_mag": 2.5156438246260593, "train/policy_entropy_max": 2.5156438246260593, "train/policy_entropy_mean": 0.603441524244573, "train/policy_entropy_min": 0.07937510665098246, "train/policy_entropy_std": 0.6359390646871859, "train/policy_logprob_mag": 7.438383408706554, "train/policy_logprob_max": -0.009455672240931622, "train/policy_logprob_mean": -0.6036266825930046, "train/policy_logprob_min": -7.438383408706554, "train/policy_logprob_std": 1.1254431209424987, "train/policy_randomness_mag": 0.8879118722720738, "train/policy_randomness_max": 0.8879118722720738, "train/policy_randomness_mean": 0.21298837955415684, "train/policy_randomness_min": 0.028015929267463022, "train/policy_randomness_std": 0.22445858286245027, "train/post_ent_mag": 58.48726876808779, "train/post_ent_max": 58.48726876808779, "train/post_ent_mean": 42.04350124832487, "train/post_ent_min": 21.25261937440747, "train/post_ent_std": 7.191028128575234, "train/prior_ent_mag": 68.73757550316135, "train/prior_ent_max": 68.73757550316135, "train/prior_ent_mean": 55.153808900039564, "train/prior_ent_min": 38.12766243593536, "train/prior_ent_std": 4.809934288915927, "train/rep_loss_mean": 13.039735891523152, "train/rep_loss_std": 9.4879636138025, "train/reward_avg": 0.021948420082348107, "train/reward_loss_mean": 0.04984692727507901, "train/reward_loss_std": 0.2397046674342051, "train/reward_max_data": 1.010218980538584, "train/reward_max_pred": 1.006687223476215, "train/reward_neg_acc": 0.9933909638954775, "train/reward_neg_loss": 0.02704669727542757, "train/reward_pos_acc": 0.9613962290930922, "train/reward_pos_loss": 0.887258924707009, "train/reward_pred": 0.02117152040294052, "train/reward_rate": 0.02673785355839416, "train_stats/sum_log_reward": 6.21818183335391, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.863636363636363, "train_stats/max_log_achievement_collect_sapling": 3.036363636363636, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 8.481818181818182, "train_stats/max_log_achievement_defeat_skeleton": 0.01818181818181818, "train_stats/max_log_achievement_defeat_zombie": 0.8909090909090909, "train_stats/max_log_achievement_eat_cow": 0.14545454545454545, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02727272727272727, "train_stats/max_log_achievement_make_wood_sword": 1.3363636363636364, "train_stats/max_log_achievement_place_plant": 2.9727272727272727, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.172727272727273, "train_stats/max_log_achievement_wake_up": 1.4363636363636363, "train_stats/mean_log_entropy": 0.5535283822904934, "eval_stats/sum_log_reward": 5.982353028129129, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.235294117647059, "eval_stats/max_log_achievement_collect_sapling": 2.4705882352941178, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 10.294117647058824, "eval_stats/max_log_achievement_defeat_skeleton": 0.11764705882352941, "eval_stats/max_log_achievement_defeat_zombie": 0.8823529411764706, "eval_stats/max_log_achievement_eat_cow": 0.058823529411764705, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 2.588235294117647, "eval_stats/max_log_achievement_place_plant": 2.2941176470588234, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.176470588235294, "eval_stats/max_log_achievement_wake_up": 1.2941176470588236, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 7.003371138125658e-05, "report/cont_loss_std": 0.002075379015877843, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.02220701426267624, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.988722594134742e-06, "report/cont_pred": 0.9971283674240112, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.029335021972656, "report/dyn_loss_std": 9.576783180236816, "report/image_loss_mean": 5.8471221923828125, "report/image_loss_std": 9.314888954162598, "report/model_loss_mean": 13.698238372802734, "report/model_loss_std": 13.50487232208252, "report/post_ent_mag": 60.658416748046875, "report/post_ent_max": 60.658416748046875, "report/post_ent_mean": 41.77250671386719, "report/post_ent_min": 19.468273162841797, "report/post_ent_std": 7.208972454071045, "report/prior_ent_mag": 68.8359375, "report/prior_ent_max": 68.8359375, "report/prior_ent_mean": 55.1651611328125, "report/prior_ent_min": 41.784278869628906, "report/prior_ent_std": 5.026925563812256, "report/rep_loss_mean": 13.029335021972656, "report/rep_loss_std": 9.576783180236816, "report/reward_avg": 0.013671875, "report/reward_loss_mean": 0.033444881439208984, "report/reward_loss_std": 0.150050088763237, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0015089511871338, "report/reward_neg_acc": 0.9970208406448364, "report/reward_neg_loss": 0.020924311131238937, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7751045227050781, "report/reward_pred": 0.013186724856495857, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.388641587458551e-05, "eval/cont_loss_std": 0.0006165643571875989, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004007111769169569, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.341642579674954e-06, "eval/cont_pred": 0.995132327079773, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 14.577805519104004, "eval/dyn_loss_std": 10.728910446166992, "eval/image_loss_mean": 10.201130867004395, "eval/image_loss_std": 15.90478229522705, "eval/model_loss_mean": 19.018348693847656, "eval/model_loss_std": 20.329551696777344, "eval/post_ent_mag": 57.555301666259766, "eval/post_ent_max": 57.555301666259766, "eval/post_ent_mean": 42.602664947509766, "eval/post_ent_min": 22.547327041625977, "eval/post_ent_std": 6.730625152587891, "eval/prior_ent_mag": 68.8359375, "eval/prior_ent_max": 68.8359375, "eval/prior_ent_mean": 55.040611267089844, "eval/prior_ent_min": 36.585853576660156, "eval/prior_ent_std": 5.169710636138916, "eval/rep_loss_mean": 14.577805519104004, "eval/rep_loss_std": 10.728910446166992, "eval/reward_avg": 0.01728515699505806, "eval/reward_loss_mean": 0.07050982862710953, "eval/reward_loss_std": 0.41389814019203186, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002732515335083, "eval/reward_neg_acc": 0.9910179376602173, "eval/reward_neg_loss": 0.03740344196557999, "eval/reward_pos_acc": 0.8181818723678589, "eval/reward_pos_loss": 1.5783551931381226, "eval/reward_pred": 0.015579333528876305, "eval/reward_rate": 0.021484375, "replay/size": 556697.0, "replay/inserts": 21928.0, "replay/samples": 21920.0, "replay/insert_wait_avg": 1.4283477890365361e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.663883174422884e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4496.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.319574715828132e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0495102405548, "timer/env.step_count": 2741.0, "timer/env.step_total": 253.46083283424377, "timer/env.step_frac": 0.25344828454870755, "timer/env.step_avg": 0.09247020533901633, "timer/env.step_min": 0.02431464195251465, "timer/env.step_max": 4.2377097606658936, "timer/replay._sample_count": 21920.0, "timer/replay._sample_total": 11.664098739624023, "timer/replay._sample_frac": 0.011663521275879938, "timer/replay._sample_avg": 0.0005321212928660595, "timer/replay._sample_min": 0.0003800392150878906, "timer/replay._sample_max": 0.011628150939941406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3303.0, "timer/agent.policy_total": 58.648332595825195, "timer/agent.policy_frac": 0.058645429046525664, "timer/agent.policy_avg": 0.017756080107727883, "timer/agent.policy_min": 0.009563207626342773, "timer/agent.policy_max": 0.14759588241577148, "timer/dataset_train_count": 1370.0, "timer/dataset_train_total": 0.16683483123779297, "timer/dataset_train_frac": 0.00016682657161410142, "timer/dataset_train_avg": 0.000121777249078681, "timer/dataset_train_min": 0.0001068115234375, "timer/dataset_train_max": 0.0010941028594970703, "timer/agent.train_count": 1370.0, "timer/agent.train_total": 616.649064540863, "timer/agent.train_frac": 0.6166185356088345, "timer/agent.train_avg": 0.45010880623420657, "timer/agent.train_min": 0.43779873847961426, "timer/agent.train_max": 1.6132521629333496, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48427367210388184, "timer/agent.report_frac": 0.0004842496967849054, "timer/agent.report_avg": 0.24213683605194092, "timer/agent.report_min": 0.2371690273284912, "timer/agent.report_max": 0.24710464477539062, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.744529724121094e-05, "timer/dataset_eval_frac": 4.744294832942652e-08, "timer/dataset_eval_avg": 4.744529724121094e-05, "timer/dataset_eval_min": 4.744529724121094e-05, "timer/dataset_eval_max": 4.744529724121094e-05, "fps": 21.92659216283578}
{"step": 557296, "time": 26400.63666009903, "episode/length": 238.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 557416, "time": 26406.000153064728, "episode/length": 198.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 557456, "time": 26409.106994628906, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 558096, "time": 26432.276710271835, "episode/length": 181.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 558384, "time": 26443.4734916687, "episode/length": 229.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 558552, "time": 26450.522521972656, "episode/length": 240.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 558600, "time": 26453.673021554947, "episode/length": 223.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 558600, "time": 26453.683164834976, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 558728, "time": 26461.371227502823, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 558776, "time": 26464.589679002762, "episode/length": 221.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 558976, "time": 26473.115370750427, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 559704, "time": 26499.20707821846, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 26532.191272735596, "eval_episode/length": 151.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 560040, "time": 26534.710077285767, "eval_episode/length": 172.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9595375722543352}
{"step": 560040, "time": 26536.729560613632, "eval_episode/length": 178.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.994413407821229}
{"step": 560040, "time": 26538.6289768219, "eval_episode/length": 184.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 560040, "time": 26540.28120446205, "eval_episode/length": 185.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 560040, "time": 26543.661635875702, "eval_episode/length": 227.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 560040, "time": 26545.86595582962, "eval_episode/length": 241.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9958677685950413}
{"step": 560040, "time": 26550.074233055115, "eval_episode/length": 296.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9865319865319865}
{"step": 560072, "time": 26551.164319992065, "episode/length": 167.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 560144, "time": 26555.436277389526, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 560192, "time": 26558.60280060768, "episode/length": 225.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 560272, "time": 26562.812350034714, "episode/length": 214.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 560288, "time": 26565.013469457626, "episode/length": 210.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 560408, "time": 26570.534328460693, "episode/length": 203.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 560576, "time": 26578.07882332802, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 560920, "time": 26591.239631652832, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 561272, "time": 26604.542237997055, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 561608, "time": 26618.163662433624, "episode/length": 191.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 561744, "time": 26624.615922927856, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 561768, "time": 26627.012100696564, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 561944, "time": 26634.528817653656, "episode/length": 218.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9908675799086758, "episode/intrinsic_return": 0.0}
{"step": 562416, "time": 26652.537088155746, "episode/length": 267.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 562728, "time": 26664.515456676483, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 562816, "time": 26669.544914722443, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 562880, "time": 26673.221423864365, "episode/length": 287.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9756944444444444, "episode/intrinsic_return": 0.0}
{"step": 562968, "time": 26677.516008377075, "episode/length": 149.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 563032, "time": 26681.284626960754, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 563712, "time": 26706.223494291306, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683257918552036, "episode/intrinsic_return": 0.0}
{"step": 563728, "time": 26708.809200286865, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 563792, "time": 26713.117842435837, "episode/length": 255.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 563960, "time": 26720.814970970154, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 564016, "time": 26724.553629636765, "episode/length": 130.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 564240, "time": 26733.674187898636, "episode/length": 177.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 564560, "time": 26745.920216321945, "episode/length": 209.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 564632, "time": 26749.667583703995, "episode/length": 199.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 565256, "time": 26772.651208877563, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 565288, "time": 26776.701004981995, "episode/length": 158.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 565416, "time": 26782.52646136284, "episode/length": 210.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 565704, "time": 26793.86591887474, "episode/length": 238.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 565712, "time": 26795.97543001175, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 565808, "time": 26800.67317390442, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 566440, "time": 26823.580938100815, "episode/length": 225.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 566528, "time": 26828.347094535828, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 566760, "time": 26837.561264514923, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9840425531914894, "episode/intrinsic_return": 0.0}
{"step": 566928, "time": 26845.085270404816, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 567160, "time": 26854.51297020912, "episode/length": 233.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 567184, "time": 26857.14855837822, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 567464, "time": 26867.95582675934, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 567712, "time": 26878.371686697006, "episode/length": 250.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 567752, "time": 26881.039022922516, "episode/length": 35.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 568120, "time": 26894.964254140854, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 568152, "time": 26897.624189138412, "episode/length": 213.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 568216, "time": 26901.376818180084, "episode/length": 210.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 568392, "time": 26909.061108112335, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 568528, "time": 26915.452781915665, "episode/length": 170.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 568760, "time": 26924.58349466324, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 568936, "time": 26932.02952694893, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 569240, "time": 26944.106202602386, "episode/length": 37.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 569480, "time": 26953.76941895485, "episode/length": 215.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 569752, "time": 26964.596930503845, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 569864, "time": 26970.034088134766, "episode/length": 217.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 569920, "time": 26973.756568193436, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 569992, "time": 26977.43562412262, "episode/length": 199.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 26999.155254125595, "eval_episode/length": 127.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9609375}
{"step": 570024, "time": 27002.565474271774, "eval_episode/length": 166.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9820359281437125}
{"step": 570024, "time": 27004.481995105743, "eval_episode/length": 174.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 570024, "time": 27006.586082696915, "eval_episode/length": 185.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 570024, "time": 27008.481874465942, "eval_episode/length": 192.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 570024, "time": 27010.59361767769, "eval_episode/length": 201.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.995049504950495}
{"step": 570024, "time": 27014.98267865181, "eval_episode/length": 260.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9616858237547893}
{"step": 570024, "time": 27018.577335834503, "eval_episode/length": 176.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.96045197740113}
{"step": 570288, "time": 27027.70866417885, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 570568, "time": 27038.548414707184, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 570720, "time": 27045.519342184067, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 571128, "time": 27060.880769968033, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 571432, "time": 27072.80130672455, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 571480, "time": 27076.60399413109, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 571672, "time": 27085.184636831284, "episode/length": 273.0, "episode/score": 7.100000038743019, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 572184, "time": 27104.12152338028, "episode/length": 236.0, "episode/score": 7.1000000461936, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 572216, "time": 27106.719789505005, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 572488, "time": 27117.34241938591, "episode/length": 239.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 572528, "time": 27120.700853586197, "episode/length": 316.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779179810725552, "episode/intrinsic_return": 0.0}
{"step": 572848, "time": 27133.14705681801, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 572872, "time": 27135.366681098938, "episode/length": 47.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 573032, "time": 27142.45407795906, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 573152, "time": 27148.374577760696, "episode/length": 184.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 573264, "time": 27153.691985845566, "episode/length": 228.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 573792, "time": 27175.076050519943, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 573920, "time": 27181.34020757675, "episode/length": 216.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 573992, "time": 27184.961772441864, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 574192, "time": 27193.467166662216, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 574464, "time": 27204.147762537003, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 574912, "time": 27221.036603927612, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 575264, "time": 27234.49081468582, "episode/length": 301.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 575424, "time": 27241.662336349487, "episode/length": 203.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 575576, "time": 27248.195006370544, "episode/length": 206.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 575632, "time": 27251.804177761078, "episode/length": 295.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 575816, "time": 27259.3172454834, "episode/length": 202.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 576240, "time": 27275.424508810043, "episode/length": 221.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 576384, "time": 27281.776211500168, "episode/length": 298.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.0}
{"step": 576480, "time": 27286.568400621414, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 576712, "time": 27295.69170999527, "episode/length": 40.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 576904, "time": 27303.877222776413, "episode/length": 248.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 576968, "time": 27307.608453273773, "episode/length": 166.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 577048, "time": 27311.85237956047, "episode/length": 41.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 577080, "time": 27314.666975021362, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 577280, "time": 27323.192667722702, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 577384, "time": 27328.244059324265, "episode/length": 37.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 577472, "time": 27333.484748125076, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 577512, "time": 27336.175139427185, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 577800, "time": 27347.4375064373, "episode/length": 40.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 578256, "time": 27364.726816177368, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 578272, "time": 27366.874021053314, "episode/length": 223.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 578576, "time": 27378.674580812454, "episode/length": 200.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 578784, "time": 27387.282187461853, "episode/length": 216.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 578784, "time": 27387.290549755096, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 578880, "time": 27393.995143651962, "episode/length": 37.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 578905, "time": 27397.272530794144, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.102897644042969, "train/action_min": 0.0, "train/action_std": 3.101256242569755, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04983547280597336, "train/actor_opt_grad_steps": 35405.0, "train/actor_opt_loss": -2.4809507784598015, "train/adv_mag": 0.6905414190362481, "train/adv_max": 0.678180357112604, "train/adv_mean": 0.004859924549129894, "train/adv_min": -0.4770812475505997, "train/adv_std": 0.07591612894526299, "train/cont_avg": 0.9945786420036765, "train/cont_loss_mean": 0.00022286736988059587, "train/cont_loss_std": 0.006624762094408171, "train/cont_neg_acc": 0.9933648473199677, "train/cont_neg_loss": 0.012034512704858839, "train/cont_pos_acc": 0.9999566665467094, "train/cont_pos_loss": 0.0001582575807368033, "train/cont_pred": 0.9945541414267877, "train/cont_rate": 0.9945786420036765, "train/dyn_loss_mean": 12.935545633820926, "train/dyn_loss_std": 9.472460368100334, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8595700281507829, "train/extr_critic_critic_opt_grad_steps": 35405.0, "train/extr_critic_critic_opt_loss": 16519.193194221047, "train/extr_critic_mag": 5.368701349286472, "train/extr_critic_max": 5.368701349286472, "train/extr_critic_mean": 1.1094217142638039, "train/extr_critic_min": -0.3539159219054615, "train/extr_critic_std": 1.1991541657377691, "train/extr_return_normed_mag": 1.8483698148937786, "train/extr_return_normed_max": 1.8483698148937786, "train/extr_return_normed_mean": 0.33334792646415096, "train/extr_return_normed_min": -0.15969074495575009, "train/extr_return_normed_std": 0.334992152364815, "train/extr_return_rate": 0.5678864410694908, "train/extr_return_raw_mag": 6.721121290150811, "train/extr_return_raw_max": 6.721121290150811, "train/extr_return_raw_mean": 1.1273838180829496, "train/extr_return_raw_min": -0.6931777931749821, "train/extr_return_raw_std": 1.237100515733747, "train/extr_reward_mag": 1.0182331134291256, "train/extr_reward_max": 1.0182331134291256, "train/extr_reward_mean": 0.028142910443848985, "train/extr_reward_min": -0.499063137699576, "train/extr_reward_std": 0.1586567210033536, "train/image_loss_mean": 6.22984739261515, "train/image_loss_std": 10.638062915381264, "train/model_loss_mean": 14.039143176639781, "train/model_loss_std": 14.562430451898013, "train/model_opt_grad_norm": 52.61555085358796, "train/model_opt_grad_steps": 35372.21323529412, "train/model_opt_loss": 19367.262601964612, "train/model_opt_model_opt_grad_overflow": 0.007352941176470588, "train/model_opt_model_opt_grad_scale": 1369.485294117647, "train/policy_entropy_mag": 2.5083266146042766, "train/policy_entropy_max": 2.5083266146042766, "train/policy_entropy_mean": 0.5430451274356421, "train/policy_entropy_min": 0.07937507605289712, "train/policy_entropy_std": 0.5877913620103808, "train/policy_logprob_mag": 7.438383512637195, "train/policy_logprob_max": -0.00945566626101294, "train/policy_logprob_mean": -0.5429520278292543, "train/policy_logprob_min": -7.438383512637195, "train/policy_logprob_std": 1.0922826462808777, "train/policy_randomness_mag": 0.8853292215396377, "train/policy_randomness_max": 0.8853292215396377, "train/policy_randomness_mean": 0.1916710987467976, "train/policy_randomness_min": 0.02801591855035547, "train/policy_randomness_std": 0.2074645596611149, "train/post_ent_mag": 58.64347802891451, "train/post_ent_max": 58.64347802891451, "train/post_ent_mean": 42.180389039656696, "train/post_ent_min": 21.12446604055517, "train/post_ent_std": 7.217777778120602, "train/prior_ent_mag": 68.9119920169606, "train/prior_ent_max": 68.9119920169606, "train/prior_ent_mean": 55.18933290593765, "train/prior_ent_min": 38.1952072872835, "train/prior_ent_std": 4.750715502921273, "train/rep_loss_mean": 12.935545633820926, "train/rep_loss_std": 9.472460368100334, "train/reward_avg": 0.02063634530093302, "train/reward_loss_mean": 0.04774565560578862, "train/reward_loss_std": 0.2233455668148749, "train/reward_max_data": 1.0110294143943226, "train/reward_max_pred": 1.0077289114980137, "train/reward_neg_acc": 0.9935943769181476, "train/reward_neg_loss": 0.0271703875349725, "train/reward_pos_acc": 0.9716485129559741, "train/reward_pos_loss": 0.8369692130123868, "train/reward_pred": 0.020160785413977197, "train/reward_rate": 0.02558450137867647, "train_stats/sum_log_reward": 6.445132711292368, "train_stats/max_log_achievement_collect_coal": 0.008849557522123894, "train_stats/max_log_achievement_collect_drink": 6.548672566371682, "train_stats/max_log_achievement_collect_sapling": 2.2920353982300883, "train_stats/max_log_achievement_collect_stone": 0.04424778761061947, "train_stats/max_log_achievement_collect_wood": 11.230088495575222, "train_stats/max_log_achievement_defeat_skeleton": 0.017699115044247787, "train_stats/max_log_achievement_defeat_zombie": 0.9734513274336283, "train_stats/max_log_achievement_eat_cow": 0.13274336283185842, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02654867256637168, "train_stats/max_log_achievement_make_wood_sword": 2.3451327433628317, "train_stats/max_log_achievement_place_plant": 2.230088495575221, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.6548672566371683, "train_stats/max_log_achievement_wake_up": 1.3097345132743363, "train_stats/mean_log_entropy": 0.5041950105038364, "eval_stats/sum_log_reward": 6.412499845027924, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.25, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.8125, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 5.905348189116921e-06, "report/cont_loss_std": 7.396222645184025e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003629192360676825, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.0942155717639253e-06, "report/cont_pred": 0.9921872615814209, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 13.699014663696289, "report/dyn_loss_std": 8.949579238891602, "report/image_loss_mean": 5.55853271484375, "report/image_loss_std": 9.685651779174805, "report/model_loss_mean": 13.831884384155273, "report/model_loss_std": 13.338004112243652, "report/post_ent_mag": 58.47562789916992, "report/post_ent_max": 58.47562789916992, "report/post_ent_mean": 41.76741027832031, "report/post_ent_min": 20.12413787841797, "report/post_ent_std": 7.3041887283325195, "report/prior_ent_mag": 69.69395446777344, "report/prior_ent_max": 69.69395446777344, "report/prior_ent_mean": 55.301021575927734, "report/prior_ent_min": 37.703819274902344, "report/prior_ent_std": 4.894192695617676, "report/rep_loss_mean": 13.699014663696289, "report/rep_loss_std": 8.949579238891602, "report/reward_avg": 0.02255859412252903, "report/reward_loss_mean": 0.05393700301647186, "report/reward_loss_std": 0.2019793540239334, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0007145404815674, "report/reward_neg_acc": 0.9929577112197876, "report/reward_neg_loss": 0.033846527338027954, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7196014523506165, "report/reward_pred": 0.022734351456165314, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0006010407814756036, "eval/cont_loss_std": 0.017498468980193138, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.10198044776916504, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.519787924233242e-06, "eval/cont_pred": 0.9946061372756958, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 13.231868743896484, "eval/dyn_loss_std": 10.792581558227539, "eval/image_loss_mean": 7.165079593658447, "eval/image_loss_std": 14.704212188720703, "eval/model_loss_mean": 15.162069320678711, "eval/model_loss_std": 18.794721603393555, "eval/post_ent_mag": 57.61045837402344, "eval/post_ent_max": 57.61045837402344, "eval/post_ent_mean": 43.55372619628906, "eval/post_ent_min": 21.76238250732422, "eval/post_ent_std": 7.397641181945801, "eval/prior_ent_mag": 69.69395446777344, "eval/prior_ent_max": 69.69395446777344, "eval/prior_ent_mean": 54.456546783447266, "eval/prior_ent_min": 39.6806526184082, "eval/prior_ent_std": 5.047729015350342, "eval/rep_loss_mean": 13.231868743896484, "eval/rep_loss_std": 10.792581558227539, "eval/reward_avg": 0.01630859449505806, "eval/reward_loss_mean": 0.057267025113105774, "eval/reward_loss_std": 0.382975697517395, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0002110004425049, "eval/reward_neg_acc": 0.9910179376602173, "eval/reward_neg_loss": 0.02539016492664814, "eval/reward_pos_acc": 0.8636363744735718, "eval/reward_pos_loss": 1.5091133117675781, "eval/reward_pred": 0.013621075078845024, "eval/reward_rate": 0.021484375, "replay/size": 578401.0, "replay/inserts": 21704.0, "replay/samples": 21712.0, "replay/insert_wait_avg": 1.4301709394106952e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.765111183891774e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2519945733967017e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4035387039185, "timer/env.step_count": 2713.0, "timer/env.step_total": 261.63460302352905, "timer/env.step_frac": 0.2615290659232294, "timer/env.step_avg": 0.09643737671342759, "timer/env.step_min": 0.024655580520629883, "timer/env.step_max": 3.4885919094085693, "timer/replay._sample_count": 21712.0, "timer/replay._sample_total": 11.780079364776611, "timer/replay._sample_frac": 0.011775327564353077, "timer/replay._sample_avg": 0.0005425607666164615, "timer/replay._sample_min": 0.0004105567932128906, "timer/replay._sample_max": 0.018767118453979492, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3315.0, "timer/agent.policy_total": 57.60984230041504, "timer/agent.policy_frac": 0.05758660387692348, "timer/agent.policy_avg": 0.017378534630592773, "timer/agent.policy_min": 0.009669303894042969, "timer/agent.policy_max": 0.09817814826965332, "timer/dataset_train_count": 1357.0, "timer/dataset_train_total": 0.1659543514251709, "timer/dataset_train_frac": 0.00016588740943497112, "timer/dataset_train_avg": 0.00012229502684242514, "timer/dataset_train_min": 0.00010657310485839844, "timer/dataset_train_max": 0.00046753883361816406, "timer/agent.train_count": 1357.0, "timer/agent.train_total": 609.9094829559326, "timer/agent.train_frac": 0.6096634601533959, "timer/agent.train_avg": 0.44945429841999457, "timer/agent.train_min": 0.43726682662963867, "timer/agent.train_max": 1.6300766468048096, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4782710075378418, "timer/agent.report_frac": 0.00047807808452723986, "timer/agent.report_avg": 0.2391355037689209, "timer/agent.report_min": 0.23252344131469727, "timer/agent.report_max": 0.24574756622314453, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.217352491616578e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 21.694943695092736}
{"step": 579488, "time": 27417.11652159691, "episode/length": 262.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 579712, "time": 27426.49494957924, "episode/length": 181.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 579752, "time": 27429.22462296486, "episode/length": 184.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 579792, "time": 27432.439003944397, "episode/length": 248.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 27464.007383823395, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 580008, "time": 27465.809627771378, "eval_episode/length": 176.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 580008, "time": 27468.447228193283, "eval_episode/length": 197.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 580008, "time": 27470.12400317192, "eval_episode/length": 198.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9698492462311558}
{"step": 580008, "time": 27471.894644737244, "eval_episode/length": 202.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 580008, "time": 27473.845690250397, "eval_episode/length": 209.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 580008, "time": 27475.927894115448, "eval_episode/length": 220.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9728506787330317}
{"step": 580008, "time": 27484.419609069824, "eval_episode/length": 195.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9693877551020408}
{"step": 580104, "time": 27487.677453517914, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 580136, "time": 27490.388073682785, "episode/length": 327.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9969512195121951, "episode/intrinsic_return": 0.0}
{"step": 580448, "time": 27502.632672071457, "episode/length": 195.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 580744, "time": 27514.003359794617, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 581016, "time": 27524.828461170197, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 581208, "time": 27532.929118156433, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 581232, "time": 27535.635672092438, "episode/length": 217.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 581432, "time": 27543.824545145035, "episode/length": 204.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 581680, "time": 27555.582602500916, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 581776, "time": 27560.507612466812, "episode/length": 204.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 582160, "time": 27575.6816470623, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 582600, "time": 27591.926425218582, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 582608, "time": 27594.118945121765, "episode/length": 232.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 582696, "time": 27598.72166991234, "episode/length": 209.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 582752, "time": 27602.359263420105, "episode/length": 164.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 582752, "time": 27602.367413282394, "episode/length": 189.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 583224, "time": 27621.348160743713, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 583376, "time": 27628.368459939957, "episode/length": 77.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 583688, "time": 27640.285697460175, "episode/length": 190.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 584072, "time": 27654.93821835518, "episode/length": 298.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.0}
{"step": 584112, "time": 27658.16380262375, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 584184, "time": 27662.106615543365, "episode/length": 196.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 584352, "time": 27669.59007000923, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 584816, "time": 27686.856835603714, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 585088, "time": 27697.667304039, "episode/length": 213.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 585264, "time": 27705.136225938797, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 585328, "time": 27708.928143262863, "episode/length": 340.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9970674486803519, "episode/intrinsic_return": 0.0}
{"step": 585744, "time": 27724.731524944305, "episode/length": 208.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 585840, "time": 27729.45821738243, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 586144, "time": 27741.234615564346, "episode/length": 253.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 586184, "time": 27743.839617967606, "episode/length": 228.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 586336, "time": 27750.816705465317, "episode/length": 133.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9552238805970149, "episode/intrinsic_return": 0.0}
{"step": 586480, "time": 27757.194184541702, "episode/length": 143.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 586528, "time": 27760.438852071762, "episode/length": 213.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 586952, "time": 27775.98035287857, "episode/length": 232.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 587280, "time": 27788.924696683884, "episode/length": 179.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 587512, "time": 27798.10016131401, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 587736, "time": 27807.684995412827, "episode/length": 174.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 587840, "time": 27813.174861431122, "episode/length": 211.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 587864, "time": 27815.334745645523, "episode/length": 166.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 588080, "time": 27824.40718269348, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 588096, "time": 27826.50681757927, "episode/length": 44.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 588536, "time": 27842.759318113327, "episode/length": 197.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 588904, "time": 27856.80704307556, "episode/length": 394.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9898734177215189, "episode/intrinsic_return": 0.0}
{"step": 588928, "time": 27859.901529073715, "episode/length": 205.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 589240, "time": 27872.385631084442, "episode/length": 38.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 589256, "time": 27874.68899345398, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 589320, "time": 27878.5094499588, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 589528, "time": 27886.99985766411, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 589736, "time": 27895.64464688301, "episode/length": 236.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 589784, "time": 27898.977468967438, "episode/length": 210.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 589904, "time": 27906.398342370987, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 27936.25964975357, "eval_episode/length": 185.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 590096, "time": 27936.27833890915, "eval_episode/length": 185.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 590096, "time": 27939.913017988205, "eval_episode/length": 191.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 590096, "time": 27941.679634809494, "eval_episode/length": 193.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9639175257731959}
{"step": 590096, "time": 27943.519504070282, "eval_episode/length": 199.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.99}
{"step": 590096, "time": 27943.526537418365, "eval_episode/length": 199.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.995}
{"step": 590096, "time": 27947.430047512054, "eval_episode/length": 214.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 590096, "time": 27949.54025578499, "eval_episode/length": 222.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 590384, "time": 27959.36208152771, "episode/length": 142.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 590728, "time": 27972.286924123764, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 591096, "time": 27986.256922006607, "episode/length": 195.0, "episode/score": 7.100000038743019, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 591136, "time": 27989.59200501442, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 591224, "time": 27993.958782434464, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715447154471545, "episode/intrinsic_return": 0.0}
{"step": 591640, "time": 28009.513252973557, "episode/length": 156.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 591680, "time": 28012.742448568344, "episode/length": 221.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 591888, "time": 28021.462366104126, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 591968, "time": 28025.786066055298, "episode/length": 330.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9969788519637462, "episode/intrinsic_return": 0.0}
{"step": 592064, "time": 28030.55184650421, "episode/length": 284.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 592280, "time": 28039.018838644028, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9527027027027027, "episode/intrinsic_return": 0.0}
{"step": 592512, "time": 28048.88821029663, "episode/length": 160.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 593016, "time": 28067.154116630554, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 593040, "time": 28069.73895263672, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 593072, "time": 28072.381325483322, "episode/length": 241.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 593264, "time": 28080.614020586014, "episode/length": 149.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 593624, "time": 28094.080961704254, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 593672, "time": 28097.334991693497, "episode/length": 222.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 593840, "time": 28104.70677804947, "episode/length": 194.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 594304, "time": 28122.127423524857, "episode/length": 84.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 594360, "time": 28125.42588019371, "episode/length": 230.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 594464, "time": 28130.667412996292, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 594584, "time": 28136.044440746307, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 594680, "time": 28141.753264427185, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 594696, "time": 28144.33864426613, "episode/length": 48.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 594800, "time": 28149.68773984909, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 595552, "time": 28176.67813897133, "episode/length": 213.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 595624, "time": 28180.416343212128, "episode/length": 243.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 595728, "time": 28185.71521139145, "episode/length": 157.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 596048, "time": 28198.25447154045, "episode/length": 168.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 596096, "time": 28201.9772400856, "episode/length": 45.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 596160, "time": 28206.150527238846, "episode/length": 169.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 596168, "time": 28207.764781713486, "episode/length": 197.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 596264, "time": 28212.524926900864, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 596280, "time": 28214.594103336334, "episode/length": 239.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 596744, "time": 28231.85786509514, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 597640, "time": 28265.561903715134, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 597648, "time": 28267.617723226547, "episode/length": 184.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 597800, "time": 28274.063766002655, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 597816, "time": 28276.216906785965, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 597856, "time": 28279.503986358643, "episode/length": 278.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 597992, "time": 28285.389353990555, "episode/length": 242.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 598184, "time": 28295.168959617615, "episode/length": 252.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 598192, "time": 28297.34591794014, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 598296, "time": 28302.202424764633, "episode/length": 37.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 598952, "time": 28326.20376777649, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 599232, "time": 28337.486121177673, "episode/length": 176.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9887005649717514, "episode/intrinsic_return": 0.0}
{"step": 599280, "time": 28340.727655172348, "episode/length": 204.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 599496, "time": 28349.552468061447, "episode/length": 211.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 599632, "time": 28355.961906194687, "episode/length": 49.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 599672, "time": 28358.7490131855, "episode/length": 48.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 599672, "time": 28358.757594347, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 599840, "time": 28367.883770227432, "episode/length": 247.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 28398.54215860367, "eval_episode/length": 161.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 600080, "time": 28400.623386621475, "eval_episode/length": 169.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 600080, "time": 28402.366219758987, "eval_episode/length": 172.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9653179190751445}
{"step": 600080, "time": 28405.003314971924, "eval_episode/length": 194.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 600080, "time": 28406.69665503502, "eval_episode/length": 197.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 600080, "time": 28409.220589399338, "eval_episode/length": 214.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 600080, "time": 28410.882305383682, "eval_episode/length": 216.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 600080, "time": 28415.272609949112, "eval_episode/length": 278.0, "eval_episode/score": 7.1000000312924385, "eval_episode/reward_rate": 0.996415770609319}
{"step": 600081, "time": 28415.86827659607, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.078302094430635, "train/action_min": 0.0, "train/action_std": 3.078244391715888, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04596174127337607, "train/actor_opt_grad_steps": 36745.0, "train/actor_opt_loss": -1.0759990445592187, "train/adv_mag": 0.645303465200193, "train/adv_max": 0.631419796157967, "train/adv_mean": 0.0048135495732519, "train/adv_min": -0.46625089848583395, "train/adv_std": 0.07199009355496276, "train/cont_avg": 0.9945475260416666, "train/cont_loss_mean": 0.00012493361703079563, "train/cont_loss_std": 0.0037664630310502794, "train/cont_neg_acc": 0.9961233216982621, "train/cont_neg_loss": 0.009441426953141601, "train/cont_pos_acc": 0.9999701904528069, "train/cont_pos_loss": 7.51396619368708e-05, "train/cont_pred": 0.9945435212417082, "train/cont_rate": 0.9945475260416666, "train/dyn_loss_mean": 13.065704251780655, "train/dyn_loss_std": 9.549011772329157, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8678094979488489, "train/extr_critic_critic_opt_grad_steps": 36745.0, "train/extr_critic_critic_opt_loss": 16480.75167939157, "train/extr_critic_mag": 5.519621498656996, "train/extr_critic_max": 5.519621498656996, "train/extr_critic_mean": 1.2448898874449008, "train/extr_critic_min": -0.34768134445855114, "train/extr_critic_std": 1.2560941680814282, "train/extr_return_normed_mag": 1.7649596053542513, "train/extr_return_normed_max": 1.7649596053542513, "train/extr_return_normed_mean": 0.3461411675494729, "train/extr_return_normed_min": -0.1519095270584027, "train/extr_return_normed_std": 0.32986700918638345, "train/extr_return_rate": 0.6170282223910997, "train/extr_return_raw_mag": 6.830234632347569, "train/extr_return_raw_max": 6.830234632347569, "train/extr_return_raw_mean": 1.2637728542992563, "train/extr_return_raw_min": -0.6911723078651861, "train/extr_return_raw_std": 1.2944257349678965, "train/extr_reward_mag": 1.0213446906118682, "train/extr_reward_max": 1.0213446906118682, "train/extr_reward_mean": 0.028915198851433215, "train/extr_reward_min": -0.5166079654838099, "train/extr_reward_std": 0.1608411195038846, "train/image_loss_mean": 6.291205482049421, "train/image_loss_std": 10.96073900569569, "train/model_loss_mean": 14.180028835932413, "train/model_loss_std": 14.955506909977306, "train/model_opt_grad_norm": 55.863516547463156, "train/model_opt_grad_steps": 36710.878787878784, "train/model_opt_loss": 19043.61513080019, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1344.6969696969697, "train/policy_entropy_mag": 2.5143667603984023, "train/policy_entropy_max": 2.5143667603984023, "train/policy_entropy_mean": 0.5018966782725218, "train/policy_entropy_min": 0.07937504977665165, "train/policy_entropy_std": 0.5669152287371231, "train/policy_logprob_mag": 7.438383582866553, "train/policy_logprob_max": -0.009455658460148808, "train/policy_logprob_mean": -0.5005393683007269, "train/policy_logprob_min": -7.438383582866553, "train/policy_logprob_std": 1.0654188344875972, "train/policy_randomness_mag": 0.8874611249475768, "train/policy_randomness_max": 0.8874611249475768, "train/policy_randomness_mean": 0.17714750360358844, "train/policy_randomness_min": 0.028015909250825644, "train/policy_randomness_std": 0.2000961982165322, "train/post_ent_mag": 58.540470296686344, "train/post_ent_max": 58.540470296686344, "train/post_ent_mean": 42.192695848869555, "train/post_ent_min": 20.77045839483088, "train/post_ent_std": 7.22830990227786, "train/prior_ent_mag": 69.0194865140048, "train/prior_ent_max": 69.0194865140048, "train/prior_ent_mean": 55.31470162940748, "train/prior_ent_min": 38.37851324948397, "train/prior_ent_std": 4.723178379463427, "train/rep_loss_mean": 13.065704251780655, "train/rep_loss_std": 9.549011772329157, "train/reward_avg": 0.02116921150732334, "train/reward_loss_mean": 0.04927590689762975, "train/reward_loss_std": 0.2393774049300136, "train/reward_max_data": 1.0106060631347424, "train/reward_max_pred": 1.0064810993093434, "train/reward_neg_acc": 0.9935161232045202, "train/reward_neg_loss": 0.027723259257265563, "train/reward_pos_acc": 0.9681718164321148, "train/reward_pos_loss": 0.8569146579865253, "train/reward_pred": 0.020608455542418542, "train/reward_rate": 0.026004675662878788, "train_stats/sum_log_reward": 6.494495390957102, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.513761467889908, "train_stats/max_log_achievement_collect_sapling": 2.18348623853211, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 11.761467889908257, "train_stats/max_log_achievement_defeat_skeleton": 0.01834862385321101, "train_stats/max_log_achievement_defeat_zombie": 0.981651376146789, "train_stats/max_log_achievement_eat_cow": 0.1559633027522936, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009174311926605505, "train_stats/max_log_achievement_make_wood_sword": 2.36697247706422, "train_stats/max_log_achievement_place_plant": 2.091743119266055, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.6422018348623855, "train_stats/max_log_achievement_wake_up": 1.3761467889908257, "train_stats/mean_log_entropy": 0.4727332300822669, "eval_stats/sum_log_reward": 7.01666659116745, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.958333333333333, "eval_stats/max_log_achievement_collect_sapling": 2.7083333333333335, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 11.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.1666666666666667, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_sword": 2.2083333333333335, "eval_stats/max_log_achievement_place_plant": 2.6666666666666665, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.7916666666666665, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 5.343142765923403e-05, "report/cont_loss_std": 0.0016108456766232848, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.007643560878932476, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.1886452284670668e-06, "report/cont_pred": 0.9932138919830322, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 11.391472816467285, "report/dyn_loss_std": 9.403989791870117, "report/image_loss_mean": 4.905183792114258, "report/image_loss_std": 12.537599563598633, "report/model_loss_mean": 11.786401748657227, "report/model_loss_std": 16.14029312133789, "report/post_ent_mag": 56.36452102661133, "report/post_ent_max": 56.36452102661133, "report/post_ent_mean": 43.237876892089844, "report/post_ent_min": 22.52332878112793, "report/post_ent_std": 7.208486080169678, "report/prior_ent_mag": 69.06610107421875, "report/prior_ent_max": 69.06610107421875, "report/prior_ent_mean": 54.45185852050781, "report/prior_ent_min": 38.95321273803711, "report/prior_ent_std": 4.621665954589844, "report/rep_loss_mean": 11.391472816467285, "report/rep_loss_std": 9.403989791870117, "report/reward_avg": 0.01914062350988388, "report/reward_loss_mean": 0.046281248331069946, "report/reward_loss_std": 0.19003485143184662, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0018086433410645, "report/reward_neg_acc": 0.9909819960594177, "report/reward_neg_loss": 0.02757957950234413, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7641376852989197, "report/reward_pred": 0.01886988990008831, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.430025460853358e-06, "eval/cont_loss_std": 3.872071465593763e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00034231130848638713, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.0971576784868375e-06, "eval/cont_pred": 0.9960939884185791, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 14.436803817749023, "eval/dyn_loss_std": 10.427326202392578, "eval/image_loss_mean": 7.592313289642334, "eval/image_loss_std": 13.289483070373535, "eval/model_loss_mean": 16.345115661621094, "eval/model_loss_std": 17.400724411010742, "eval/post_ent_mag": 57.84163284301758, "eval/post_ent_max": 57.84163284301758, "eval/post_ent_mean": 42.161216735839844, "eval/post_ent_min": 21.764816284179688, "eval/post_ent_std": 6.841984272003174, "eval/prior_ent_mag": 69.06610107421875, "eval/prior_ent_max": 69.06610107421875, "eval/prior_ent_mean": 54.61346435546875, "eval/prior_ent_min": 40.73515701293945, "eval/prior_ent_std": 4.542919635772705, "eval/rep_loss_mean": 14.436803817749023, "eval/rep_loss_std": 10.427326202392578, "eval/reward_avg": 0.01914062537252903, "eval/reward_loss_mean": 0.0907178670167923, "eval/reward_loss_std": 0.6078271269798279, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018041133880615, "eval/reward_neg_acc": 0.9880000352859497, "eval/reward_neg_loss": 0.05716710165143013, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 1.4886667728424072, "eval/reward_pred": 0.020645171403884888, "eval/reward_rate": 0.0234375, "replay/size": 599577.0, "replay/inserts": 21176.0, "replay/samples": 21168.0, "replay/insert_wait_avg": 1.4412524702866932e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.552230314512822e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.255298511342706e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1018.5789420604706, "timer/env.step_count": 2647.0, "timer/env.step_total": 252.89430475234985, "timer/env.step_frac": 0.24828149720116258, "timer/env.step_avg": 0.09553997157247822, "timer/env.step_min": 0.024492740631103516, "timer/env.step_max": 3.38196063041687, "timer/replay._sample_count": 21168.0, "timer/replay._sample_total": 11.363029718399048, "timer/replay._sample_frac": 0.01115576736292321, "timer/replay._sample_avg": 0.0005368022353741047, "timer/replay._sample_min": 0.0003848075866699219, "timer/replay._sample_max": 0.025857925415039062, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3516.0, "timer/agent.policy_total": 62.182164907455444, "timer/agent.policy_frac": 0.06104795842496795, "timer/agent.policy_avg": 0.017685484899731357, "timer/agent.policy_min": 0.009656906127929688, "timer/agent.policy_max": 0.13880276679992676, "timer/dataset_train_count": 1323.0, "timer/dataset_train_total": 0.16261816024780273, "timer/dataset_train_frac": 0.00015965199508134783, "timer/dataset_train_avg": 0.00012291622089781007, "timer/dataset_train_min": 0.00010514259338378906, "timer/dataset_train_max": 0.0008683204650878906, "timer/agent.train_count": 1323.0, "timer/agent.train_total": 598.5385444164276, "timer/agent.train_frac": 0.5876211648413342, "timer/agent.train_avg": 0.45241008648256054, "timer/agent.train_min": 0.4349238872528076, "timer/agent.train_max": 2.148824453353882, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48172569274902344, "timer/agent.report_frac": 0.00047293898671667663, "timer/agent.report_avg": 0.24086284637451172, "timer/agent.report_min": 0.2333993911743164, "timer/agent.report_max": 0.24832630157470703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.647804260253906e-05, "timer/dataset_eval_frac": 3.581268087944965e-08, "timer/dataset_eval_avg": 3.647804260253906e-05, "timer/dataset_eval_min": 3.647804260253906e-05, "timer/dataset_eval_max": 3.647804260253906e-05, "fps": 20.789465445508885}
{"step": 600192, "time": 28419.91686797142, "episode/length": 154.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 600272, "time": 28424.152013540268, "episode/length": 259.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 600384, "time": 28429.528606891632, "episode/length": 274.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9709090909090909, "episode/intrinsic_return": 0.0}
{"step": 600944, "time": 28450.04988193512, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 600960, "time": 28452.130641698837, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 601088, "time": 28458.029618263245, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 601528, "time": 28474.52793073654, "episode/length": 231.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 601576, "time": 28477.71283364296, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 601808, "time": 28487.31744647026, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 601904, "time": 28492.23220181465, "episode/length": 203.0, "episode/score": 7.099999949336052, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 602496, "time": 28513.840097904205, "episode/length": 263.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 602664, "time": 28520.78093481064, "episode/length": 214.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 602712, "time": 28524.136407136917, "episode/length": 218.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 602880, "time": 28531.724781274796, "episode/length": 223.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 602968, "time": 28535.993272781372, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 603072, "time": 28541.34783267975, "episode/length": 192.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 603288, "time": 28549.97215461731, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 603648, "time": 28564.143094062805, "episode/length": 44.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 603816, "time": 28571.894624471664, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 603888, "time": 28576.18196630478, "episode/length": 247.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 604112, "time": 28585.39011144638, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 604336, "time": 28594.583713293076, "episode/length": 202.0, "episode/score": 7.099999949336052, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 604392, "time": 28597.83327317238, "episode/length": 34.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 604400, "time": 28599.891902685165, "episode/length": 189.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 604616, "time": 28608.592788219452, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 604640, "time": 28611.296585798264, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 605032, "time": 28626.14612722397, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.951048951048951, "episode/intrinsic_return": 0.0}
{"step": 605272, "time": 28635.781766414642, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 605528, "time": 28646.056233882904, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9672897196261683, "episode/intrinsic_return": 0.0}
{"step": 605784, "time": 28656.358667612076, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 606096, "time": 28668.594160318375, "episode/length": 181.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 606560, "time": 28687.525931596756, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 606592, "time": 28690.333969593048, "episode/length": 274.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9745454545454545, "episode/intrinsic_return": 0.0}
{"step": 606712, "time": 28695.785170793533, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 606792, "time": 28700.05402779579, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 606904, "time": 28705.376310825348, "episode/length": 320.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9844236760124611, "episode/intrinsic_return": 0.0}
{"step": 607064, "time": 28712.410800933838, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 607432, "time": 28726.38557457924, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 607768, "time": 28739.353049993515, "episode/length": 208.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 607920, "time": 28746.307148694992, "episode/length": 140.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 607944, "time": 28748.47446012497, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 608320, "time": 28762.937242031097, "episode/length": 215.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 608472, "time": 28769.569460392, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 608904, "time": 28785.737960100174, "episode/length": 249.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 609056, "time": 28792.6574511528, "episode/length": 202.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 609272, "time": 28801.40388607979, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 609360, "time": 28806.095214366913, "episode/length": 37.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 609616, "time": 28816.263788700104, "episode/length": 230.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 609656, "time": 28818.93472456932, "episode/length": 216.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 28854.763420820236, "eval_episode/length": 154.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 610064, "time": 28856.681703329086, "eval_episode/length": 157.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 610064, "time": 28858.919980287552, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9529411764705882}
{"step": 610064, "time": 28861.64294075966, "eval_episode/length": 194.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 610064, "time": 28863.49893593788, "eval_episode/length": 199.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.965}
{"step": 610064, "time": 28866.15538740158, "eval_episode/length": 220.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9773755656108597}
{"step": 610064, "time": 28868.197148561478, "eval_episode/length": 230.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 610064, "time": 28870.58626794815, "eval_episode/length": 48.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 610144, "time": 28873.280324935913, "episode/length": 227.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 610512, "time": 28887.238520622253, "episode/length": 430.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9976798143851509, "episode/intrinsic_return": 0.0}
{"step": 610528, "time": 28889.474652290344, "episode/length": 256.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.0}
{"step": 610720, "time": 28897.489733219147, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 610872, "time": 28903.966645240784, "episode/length": 156.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 611392, "time": 28923.554002046585, "episode/length": 155.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 611848, "time": 28940.40780854225, "episode/length": 310.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 612016, "time": 28947.97664141655, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 612040, "time": 28950.226024866104, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 612120, "time": 28954.510415792465, "episode/length": 200.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 612344, "time": 28963.625952243805, "episode/length": 429.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9906976744186047, "episode/intrinsic_return": 0.0}
{"step": 612928, "time": 28985.218581676483, "episode/length": 191.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 612976, "time": 28988.571727991104, "episode/length": 262.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 613112, "time": 28994.478670835495, "episode/length": 431.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 613304, "time": 29002.56854867935, "episode/length": 40.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 613432, "time": 29008.45604777336, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 613680, "time": 29018.512361764908, "episode/length": 228.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 613736, "time": 29021.83940052986, "episode/length": 214.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 614168, "time": 29038.22100162506, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 614408, "time": 29048.73846077919, "episode/length": 295.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9763513513513513, "episode/intrinsic_return": 0.0}
{"step": 614784, "time": 29065.109407901764, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 614808, "time": 29067.37638926506, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 614856, "time": 29070.73910832405, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 614944, "time": 29075.43408370018, "episode/length": 324.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 615160, "time": 29084.10524892807, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 615360, "time": 29092.65696787834, "episode/length": 202.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9852216748768473, "episode/intrinsic_return": 0.0}
{"step": 615968, "time": 29114.85789513588, "episode/length": 224.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 616096, "time": 29120.789457559586, "episode/length": 210.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 616448, "time": 29134.419376850128, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 616464, "time": 29136.54511475563, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 616624, "time": 29143.444249629974, "episode/length": 226.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 616720, "time": 29148.22432899475, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 616744, "time": 29150.488195180893, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 616952, "time": 29159.21889400482, "episode/length": 223.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 617272, "time": 29171.481543302536, "episode/length": 146.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 617368, "time": 29176.351442813873, "episode/length": 174.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 618008, "time": 29200.02396082878, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 618256, "time": 29210.25322318077, "episode/length": 188.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 618264, "time": 29211.853086471558, "episode/length": 204.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9853658536585366, "episode/intrinsic_return": 0.0}
{"step": 618296, "time": 29214.48713541031, "episode/length": 228.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 618320, "time": 29217.015498161316, "episode/length": 38.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 618416, "time": 29221.981887102127, "episode/length": 182.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 618496, "time": 29226.325417518616, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 619296, "time": 29254.852782726288, "episode/length": 240.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 619568, "time": 29265.658892154694, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 619640, "time": 29269.43901538849, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 619720, "time": 29273.69103360176, "episode/length": 374.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946666666666667, "episode/intrinsic_return": 0.0}
{"step": 619784, "time": 29277.531370401382, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 619792, "time": 29279.733783960342, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 29311.370698690414, "eval_episode/length": 146.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 620048, "time": 29315.044316768646, "eval_episode/length": 191.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 620048, "time": 29316.891518354416, "eval_episode/length": 199.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.995}
{"step": 620048, "time": 29319.081970453262, "eval_episode/length": 208.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 620048, "time": 29320.793634414673, "eval_episode/length": 209.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 620048, "time": 29322.77421617508, "eval_episode/length": 216.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 620048, "time": 29325.51242375374, "eval_episode/length": 239.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9708333333333333}
{"step": 620048, "time": 29332.44659423828, "eval_episode/length": 359.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 620256, "time": 29339.56336760521, "episode/length": 219.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 620672, "time": 29355.12069296837, "episode/length": 301.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 621088, "time": 29370.805495023727, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 621360, "time": 29381.543003559113, "episode/length": 196.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 621408, "time": 29384.75169992447, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 621504, "time": 29389.544852495193, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 621504, "time": 29389.554552078247, "episode/length": 222.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 621704, "time": 29399.442420959473, "episode/length": 300.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 622016, "time": 29411.66690468788, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 622073, "time": 29416.032606124878, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.191234643908515, "train/action_min": 0.0, "train/action_std": 3.2456225847852402, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0463206444637499, "train/actor_opt_grad_steps": 38095.0, "train/actor_opt_loss": -2.157802804008774, "train/adv_mag": 0.6197070619766263, "train/adv_max": 0.5952725956837336, "train/adv_mean": 0.004337818572610664, "train/adv_min": -0.4651116782772368, "train/adv_std": 0.06934249749326188, "train/cont_avg": 0.994735054347826, "train/cont_loss_mean": 0.0002152614895955505, "train/cont_loss_std": 0.006595152136440305, "train/cont_neg_acc": 0.9910091540239153, "train/cont_neg_loss": 0.023774661368127847, "train/cont_pos_acc": 0.999978637781696, "train/cont_pos_loss": 7.365649326919848e-05, "train/cont_pred": 0.9947393536567688, "train/cont_rate": 0.994735054347826, "train/dyn_loss_mean": 12.862813956495645, "train/dyn_loss_std": 9.475119224493055, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8616987129916316, "train/extr_critic_critic_opt_grad_steps": 38095.0, "train/extr_critic_critic_opt_loss": 16501.937195708786, "train/extr_critic_mag": 5.7451415891232696, "train/extr_critic_max": 5.7451415891232696, "train/extr_critic_mean": 1.364433598259221, "train/extr_critic_min": -0.349885112133579, "train/extr_critic_std": 1.3440347106560417, "train/extr_return_normed_mag": 1.7407363152158433, "train/extr_return_normed_max": 1.7407363152158433, "train/extr_return_normed_mean": 0.35342876019253244, "train/extr_return_normed_min": -0.13692769370433214, "train/extr_return_normed_std": 0.3311199171171672, "train/extr_return_rate": 0.6390493242205053, "train/extr_return_raw_mag": 7.177770801212477, "train/extr_return_raw_max": 7.177770801212477, "train/extr_return_raw_mean": 1.382544541704482, "train/extr_return_raw_min": -0.6650472713121469, "train/extr_return_raw_std": 1.3827518876911937, "train/extr_reward_mag": 1.0243849460629448, "train/extr_reward_max": 1.0243849460629448, "train/extr_reward_mean": 0.031202923553739336, "train/extr_reward_min": -0.4731190360110739, "train/extr_reward_std": 0.16677402289233345, "train/image_loss_mean": 6.061903678852579, "train/image_loss_std": 10.884881199270055, "train/model_loss_mean": 13.829921273217685, "train/model_loss_std": 14.83075679557911, "train/model_opt_grad_norm": 55.48249181111654, "train/model_opt_grad_steps": 38059.19565217391, "train/model_opt_loss": 14100.165230129076, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1019.0217391304348, "train/policy_entropy_mag": 2.494430395140164, "train/policy_entropy_max": 2.494430395140164, "train/policy_entropy_mean": 0.5219704232354095, "train/policy_entropy_min": 0.07937504772258841, "train/policy_entropy_std": 0.5901066421166711, "train/policy_logprob_mag": 7.438383596530859, "train/policy_logprob_max": -0.009455658421190321, "train/policy_logprob_mean": -0.522013281998427, "train/policy_logprob_min": -7.438383596530859, "train/policy_logprob_std": 1.0794122974941696, "train/policy_randomness_mag": 0.880424465822137, "train/policy_randomness_max": 0.880424465822137, "train/policy_randomness_mean": 0.1842326540229977, "train/policy_randomness_min": 0.028015908569205498, "train/policy_randomness_std": 0.20828174886064252, "train/post_ent_mag": 59.06483713785807, "train/post_ent_max": 59.06483713785807, "train/post_ent_mean": 42.44056444582732, "train/post_ent_min": 21.003896188044894, "train/post_ent_std": 7.273104595101398, "train/prior_ent_mag": 69.1025718467823, "train/prior_ent_max": 69.1025718467823, "train/prior_ent_mean": 55.36601478466089, "train/prior_ent_min": 38.019672808439836, "train/prior_ent_std": 4.804094546083091, "train/rep_loss_mean": 12.862813956495645, "train/rep_loss_std": 9.475119224493055, "train/reward_avg": 0.022773012822574896, "train/reward_loss_mean": 0.05011400855753733, "train/reward_loss_std": 0.236148732241945, "train/reward_max_data": 1.0166666706403096, "train/reward_max_pred": 1.0093635052874468, "train/reward_neg_acc": 0.99338382612104, "train/reward_neg_loss": 0.027201585451383955, "train/reward_pos_acc": 0.9656910326169885, "train/reward_pos_loss": 0.8651347069636636, "train/reward_pred": 0.02202144632473642, "train/reward_rate": 0.027584352355072464, "train_stats/sum_log_reward": 6.585981281004219, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.308411214953271, "train_stats/max_log_achievement_collect_sapling": 2.457943925233645, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 12.663551401869158, "train_stats/max_log_achievement_defeat_skeleton": 0.009345794392523364, "train_stats/max_log_achievement_defeat_zombie": 1.0654205607476634, "train_stats/max_log_achievement_eat_cow": 0.1308411214953271, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 2.046728971962617, "train_stats/max_log_achievement_place_plant": 2.364485981308411, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.635514018691589, "train_stats/max_log_achievement_wake_up": 1.485981308411215, "train_stats/mean_log_entropy": 0.506453467585216, "eval_stats/sum_log_reward": 6.474999934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.625, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 11.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.1875, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.75, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.008625637652585e-06, "report/cont_loss_std": 6.543502968270332e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.877469761297107e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.567961357475724e-06, "report/cont_pred": 0.9941375255584717, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.486678123474121, "report/dyn_loss_std": 9.010629653930664, "report/image_loss_mean": 4.743966579437256, "report/image_loss_std": 6.3659138679504395, "report/model_loss_mean": 12.295997619628906, "report/model_loss_std": 10.33612060546875, "report/post_ent_mag": 57.93708038330078, "report/post_ent_max": 57.93708038330078, "report/post_ent_mean": 42.26563262939453, "report/post_ent_min": 22.847389221191406, "report/post_ent_std": 7.420530796051025, "report/prior_ent_mag": 69.21101379394531, "report/prior_ent_max": 69.21101379394531, "report/prior_ent_mean": 55.23672103881836, "report/prior_ent_min": 40.33317184448242, "report/prior_ent_std": 4.535439968109131, "report/rep_loss_mean": 12.486678123474121, "report/rep_loss_std": 9.010629653930664, "report/reward_avg": 0.02089843526482582, "report/reward_loss_mean": 0.060021061450242996, "report/reward_loss_std": 0.27312222123146057, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.003408432006836, "report/reward_neg_acc": 0.9849548935890198, "report/reward_neg_loss": 0.04217967763543129, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7188307046890259, "report/reward_pred": 0.021609243005514145, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.1123986951133702e-05, "eval/cont_loss_std": 0.00028380099684000015, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.003043327247723937, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.21447839976463e-06, "eval/cont_pred": 0.9970769286155701, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.069934844970703, "eval/dyn_loss_std": 10.785226821899414, "eval/image_loss_mean": 11.189338684082031, "eval/image_loss_std": 16.004337310791016, "eval/model_loss_mean": 21.51931381225586, "eval/model_loss_std": 20.396055221557617, "eval/post_ent_mag": 56.078216552734375, "eval/post_ent_max": 56.078216552734375, "eval/post_ent_mean": 40.61756896972656, "eval/post_ent_min": 20.467620849609375, "eval/post_ent_std": 6.999417304992676, "eval/prior_ent_mag": 69.21101379394531, "eval/prior_ent_max": 69.21101379394531, "eval/prior_ent_mean": 55.413387298583984, "eval/prior_ent_min": 36.83636474609375, "eval/prior_ent_std": 4.221345901489258, "eval/rep_loss_mean": 17.069934844970703, "eval/rep_loss_std": 10.785226821899414, "eval/reward_avg": 0.04111327975988388, "eval/reward_loss_mean": 0.08800403773784637, "eval/reward_loss_std": 0.4637916684150696, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.004807472229004, "eval/reward_neg_acc": 0.9826353788375854, "eval/reward_neg_loss": 0.034463416785001755, "eval/reward_pos_acc": 0.9333333373069763, "eval/reward_pos_loss": 1.2528101205825806, "eval/reward_pred": 0.035615138709545135, "eval/reward_rate": 0.0439453125, "replay/size": 621569.0, "replay/inserts": 21992.0, "replay/samples": 22000.0, "replay/insert_wait_avg": 1.4320834414141097e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.553158153187145e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4872.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.24817411300584e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.147531747818, "timer/env.step_count": 2749.0, "timer/env.step_total": 250.2647807598114, "timer/env.step_frac": 0.25022786420565235, "timer/env.step_avg": 0.09103847972346722, "timer/env.step_min": 0.024221181869506836, "timer/env.step_max": 3.4580113887786865, "timer/replay._sample_count": 22000.0, "timer/replay._sample_total": 11.620188474655151, "timer/replay._sample_frac": 0.01161847438082277, "timer/replay._sample_avg": 0.0005281903852115978, "timer/replay._sample_min": 0.0004200935363769531, "timer/replay._sample_max": 0.011303424835205078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3358.0, "timer/agent.policy_total": 58.90467858314514, "timer/agent.policy_frac": 0.05889598955486664, "timer/agent.policy_avg": 0.01754159576627312, "timer/agent.policy_min": 0.009473800659179688, "timer/agent.policy_max": 0.13884687423706055, "timer/dataset_train_count": 1375.0, "timer/dataset_train_total": 0.16532278060913086, "timer/dataset_train_frac": 0.00016529839384817494, "timer/dataset_train_avg": 0.00012023474953391336, "timer/dataset_train_min": 0.000102996826171875, "timer/dataset_train_max": 0.0003802776336669922, "timer/agent.train_count": 1375.0, "timer/agent.train_total": 618.9063701629639, "timer/agent.train_frac": 0.6188150752933297, "timer/agent.train_avg": 0.4501137237548828, "timer/agent.train_min": 0.43609070777893066, "timer/agent.train_max": 1.5618412494659424, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47741007804870605, "timer/agent.report_frac": 0.00047733965529505755, "timer/agent.report_avg": 0.23870503902435303, "timer/agent.report_min": 0.23237347602844238, "timer/agent.report_max": 0.24503660202026367, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.748603820800781e-05, "timer/dataset_eval_frac": 7.747460824364211e-08, "timer/dataset_eval_avg": 7.748603820800781e-05, "timer/dataset_eval_min": 7.748603820800781e-05, "timer/dataset_eval_max": 7.748603820800781e-05, "fps": 21.98837462936489}
{"step": 622440, "time": 29428.422775506973, "episode/length": 358.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9860724233983287, "episode/intrinsic_return": 0.0}
{"step": 622824, "time": 29444.393336057663, "episode/length": 176.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 622944, "time": 29450.250337839127, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 623016, "time": 29454.035890817642, "episode/length": 206.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 623040, "time": 29456.645213603973, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 623120, "time": 29461.062397956848, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 623136, "time": 29463.19051671028, "episode/length": 178.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 623312, "time": 29470.665093898773, "episode/length": 36.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 624184, "time": 29501.43089580536, "episode/length": 270.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 624200, "time": 29503.549424409866, "episode/length": 171.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 624336, "time": 29509.87829875946, "episode/length": 236.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 624456, "time": 29515.340965032578, "episode/length": 166.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 624680, "time": 29524.708654642105, "episode/length": 216.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 624768, "time": 29529.47345662117, "episode/length": 203.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 625304, "time": 29549.035850524902, "episode/length": 282.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 625688, "time": 29563.5155479908, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 625736, "time": 29566.79152917862, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 626040, "time": 29578.722639083862, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 626096, "time": 29582.594769716263, "episode/length": 238.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 626216, "time": 29587.915123462677, "episode/length": 191.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 626400, "time": 29595.841300964355, "episode/length": 257.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 626576, "time": 29603.237649202347, "episode/length": 44.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 626864, "time": 29614.595920801163, "episode/length": 443.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 626928, "time": 29618.427555799484, "episode/length": 202.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 627168, "time": 29628.096469163895, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 627216, "time": 29631.356756210327, "episode/length": 190.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 627784, "time": 29651.944388866425, "episode/length": 217.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 627824, "time": 29655.11523294449, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 627832, "time": 29656.73416161537, "episode/length": 216.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 628888, "time": 29694.12587594986, "episode/length": 288.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 628952, "time": 29697.997000694275, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 629032, "time": 29702.206891059875, "episode/length": 262.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 629112, "time": 29706.4267206192, "episode/length": 165.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 629152, "time": 29709.635130643845, "episode/length": 247.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 629208, "time": 29712.750591754913, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 629304, "time": 29717.468088150024, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 629488, "time": 29725.402139425278, "episode/length": 327.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9847560975609756, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 29765.0950152874, "eval_episode/length": 138.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 630032, "time": 29768.8164768219, "eval_episode/length": 181.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 630032, "time": 29770.986456871033, "eval_episode/length": 187.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 630032, "time": 29773.455935239792, "eval_episode/length": 196.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 630032, "time": 29776.352375745773, "eval_episode/length": 210.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.995260663507109}
{"step": 630032, "time": 29778.591554403305, "eval_episode/length": 213.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 630032, "time": 29782.69507408142, "eval_episode/length": 251.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.996031746031746}
{"step": 630032, "time": 29787.3481965065, "eval_episode/length": 123.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9516129032258065}
{"step": 630360, "time": 29798.373475074768, "episode/length": 175.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 630656, "time": 29810.189311027527, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 630840, "time": 29819.743541002274, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 630928, "time": 29824.527595996857, "episode/length": 236.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 631160, "time": 29833.759514808655, "episode/length": 208.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 631200, "time": 29836.956903219223, "episode/length": 255.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 631288, "time": 29841.15596818924, "episode/length": 299.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766666666666667, "episode/intrinsic_return": 0.0}
{"step": 631624, "time": 29854.1716029644, "episode/length": 41.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 631784, "time": 29861.34808254242, "episode/length": 309.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 631968, "time": 29869.24165201187, "episode/length": 200.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 632152, "time": 29876.78248810768, "episode/length": 45.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9130434782608695, "episode/intrinsic_return": 0.0}
{"step": 632400, "time": 29887.071837186813, "episode/length": 217.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 632592, "time": 29895.104522705078, "episode/length": 178.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 632840, "time": 29904.83995771408, "episode/length": 204.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 633064, "time": 29914.21223950386, "episode/length": 277.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 633152, "time": 29919.058257102966, "episode/length": 277.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 633432, "time": 29929.934602499008, "episode/length": 225.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 633840, "time": 29945.76867699623, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 633920, "time": 29950.054836273193, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 633952, "time": 29952.709830760956, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 634424, "time": 29970.12197780609, "episode/length": 228.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 634512, "time": 29974.87944316864, "episode/length": 169.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 634696, "time": 29982.779353618622, "episode/length": 231.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 634920, "time": 29991.969628810883, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 635272, "time": 30005.49574804306, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 635408, "time": 30012.093123197556, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 635552, "time": 30018.550595521927, "episode/length": 310.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.977491961414791, "episode/intrinsic_return": 0.0}
{"step": 635560, "time": 30020.169973134995, "episode/length": 214.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 635600, "time": 30023.315641880035, "episode/length": 40.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 635912, "time": 30035.358879327774, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 635960, "time": 30038.58994078636, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 636336, "time": 30053.055508852005, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 636440, "time": 30058.203547477722, "episode/length": 217.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 636888, "time": 30074.87585377693, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 636952, "time": 30078.61673474312, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 637296, "time": 30092.279805898666, "episode/length": 216.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 637400, "time": 30097.761457681656, "episode/length": 230.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 637504, "time": 30103.083980321884, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 637536, "time": 30105.862636566162, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 637808, "time": 30116.747302532196, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 637840, "time": 30119.688569307327, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 638040, "time": 30127.779401779175, "episode/length": 199.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 638448, "time": 30143.273377656937, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 638600, "time": 30149.871925115585, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 638920, "time": 30162.239670991898, "episode/length": 172.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 639032, "time": 30169.669922590256, "episode/length": 203.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 639256, "time": 30179.405648469925, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 639504, "time": 30189.544595479965, "episode/length": 207.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 639792, "time": 30200.83106446266, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 639824, "time": 30203.516683340073, "episode/length": 112.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9646017699115044, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 30226.73347568512, "eval_episode/length": 36.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.972972972972973}
{"step": 640016, "time": 30228.3890106678, "eval_episode/length": 40.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8780487804878049}
{"step": 640016, "time": 30235.204828500748, "eval_episode/length": 156.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 640016, "time": 30238.070768356323, "eval_episode/length": 179.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 640016, "time": 30240.827516555786, "eval_episode/length": 206.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 640016, "time": 30242.55055117607, "eval_episode/length": 207.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 640016, "time": 30244.74921822548, "eval_episode/length": 183.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 640016, "time": 30246.467112779617, "eval_episode/length": 222.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 640016, "time": 30246.475709199905, "eval_episode/length": 222.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 640152, "time": 30250.865988492966, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 640208, "time": 30254.54180765152, "episode/length": 270.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.977859778597786, "episode/intrinsic_return": 0.0}
{"step": 640784, "time": 30275.68781733513, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9581151832460733, "episode/intrinsic_return": 0.0}
{"step": 640984, "time": 30283.72034263611, "episode/length": 460.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9978308026030369, "episode/intrinsic_return": 0.0}
{"step": 641064, "time": 30288.00597834587, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 641400, "time": 30301.057708978653, "episode/length": 295.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 641520, "time": 30306.932926654816, "episode/length": 215.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 641584, "time": 30310.756346464157, "episode/length": 219.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 641944, "time": 30324.164561510086, "episode/length": 223.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 642000, "time": 30327.82594037056, "episode/length": 151.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 642616, "time": 30349.93041920662, "episode/length": 300.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 642832, "time": 30359.218453645706, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 642912, "time": 30363.538172721863, "episode/length": 240.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 643136, "time": 30372.822912693024, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 643136, "time": 30372.8307056427, "episode/length": 216.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 643160, "time": 30376.707701206207, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 643376, "time": 30385.958475112915, "episode/length": 178.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 643928, "time": 30406.02749991417, "episode/length": 240.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.991701244813278, "episode/intrinsic_return": 0.0}
{"step": 643984, "time": 30409.803750753403, "episode/length": 299.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 644105, "time": 30416.272305965424, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.384791719740716, "train/action_min": 0.0, "train/action_std": 3.42982626479605, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04557165463009606, "train/actor_opt_grad_steps": 39475.0, "train/actor_opt_loss": -0.27335631261255755, "train/adv_mag": 0.6080791969662127, "train/adv_max": 0.5758977225725201, "train/adv_mean": 0.004273818500908986, "train/adv_min": -0.4432426762321721, "train/adv_std": 0.06830625227935937, "train/cont_avg": 0.9946501358695652, "train/cont_loss_mean": 0.00023714843988791858, "train/cont_loss_std": 0.007280190168043079, "train/cont_neg_acc": 0.987592019032741, "train/cont_neg_loss": 0.0355879841865475, "train/cont_pos_acc": 0.999985740236614, "train/cont_pos_loss": 4.478580711089551e-05, "train/cont_pred": 0.9946837204953899, "train/cont_rate": 0.9946501358695652, "train/dyn_loss_mean": 12.759655344313469, "train/dyn_loss_std": 9.510937379754107, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8603071488332057, "train/extr_critic_critic_opt_grad_steps": 39475.0, "train/extr_critic_critic_opt_loss": 16459.037944406704, "train/extr_critic_mag": 5.86472171285878, "train/extr_critic_max": 5.86472171285878, "train/extr_critic_mean": 1.402785581091176, "train/extr_critic_min": -0.3516606533009073, "train/extr_critic_std": 1.3683497076449187, "train/extr_return_normed_mag": 1.702582945858223, "train/extr_return_normed_max": 1.702582945858223, "train/extr_return_normed_mean": 0.3521881927398668, "train/extr_return_normed_min": -0.1269722592247569, "train/extr_return_normed_std": 0.3261681851269542, "train/extr_return_rate": 0.650142506196879, "train/extr_return_raw_mag": 7.238524975983993, "train/extr_return_raw_max": 7.238524975983993, "train/extr_return_raw_mean": 1.4211896066216454, "train/extr_return_raw_min": -0.6430788541185684, "train/extr_return_raw_std": 1.4052681672400322, "train/extr_reward_mag": 1.0219814259073008, "train/extr_reward_max": 1.0219814259073008, "train/extr_reward_mean": 0.03242913219213918, "train/extr_reward_min": -0.4568737961243892, "train/extr_reward_std": 0.16975045533499855, "train/image_loss_mean": 5.925169241601142, "train/image_loss_std": 10.505102845205776, "train/model_loss_mean": 13.630748140639152, "train/model_loss_std": 14.47731027741363, "train/model_opt_grad_norm": 52.74793595853059, "train/model_opt_grad_steps": 39438.0, "train/model_opt_loss": 14019.480525362318, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1028.0797101449275, "train/policy_entropy_mag": 2.482641230458799, "train/policy_entropy_max": 2.482641230458799, "train/policy_entropy_mean": 0.5524111590955568, "train/policy_entropy_min": 0.07937506175991418, "train/policy_entropy_std": 0.6411366682985554, "train/policy_logprob_mag": 7.438383582709492, "train/policy_logprob_max": -0.00945566184953719, "train/policy_logprob_mean": -0.5515783385954042, "train/policy_logprob_min": -7.438383582709492, "train/policy_logprob_std": 1.0927671012671099, "train/policy_randomness_mag": 0.8762634063976399, "train/policy_randomness_max": 0.8762634063976399, "train/policy_randomness_mean": 0.19497689982687216, "train/policy_randomness_min": 0.028015913468772087, "train/policy_randomness_std": 0.22629310968129532, "train/post_ent_mag": 58.713206940802976, "train/post_ent_max": 58.713206940802976, "train/post_ent_mean": 42.489609980928726, "train/post_ent_min": 21.0039080467777, "train/post_ent_std": 7.2322799813920176, "train/prior_ent_mag": 69.11655724566916, "train/prior_ent_max": 69.11655724566916, "train/prior_ent_mean": 55.33784075750821, "train/prior_ent_min": 38.316329195879504, "train/prior_ent_std": 4.762726873591326, "train/rep_loss_mean": 12.759655344313469, "train/rep_loss_std": 9.510937379754107, "train/reward_avg": 0.023064566148525995, "train/reward_loss_mean": 0.04954855210161296, "train/reward_loss_std": 0.23231001608613608, "train/reward_max_data": 1.0123188435167507, "train/reward_max_pred": 1.0070740589197131, "train/reward_neg_acc": 0.9937625220720319, "train/reward_neg_loss": 0.02682838653065804, "train/reward_pos_acc": 0.96845251624135, "train/reward_pos_loss": 0.8472131158130757, "train/reward_pred": 0.022336842701432928, "train/reward_rate": 0.027846184329710144, "train_stats/sum_log_reward": 6.675471681468892, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.481132075471698, "train_stats/max_log_achievement_collect_sapling": 2.5377358490566038, "train_stats/max_log_achievement_collect_stone": 0.009433962264150943, "train_stats/max_log_achievement_collect_wood": 12.19811320754717, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 1.2452830188679245, "train_stats/max_log_achievement_eat_cow": 0.18867924528301888, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.018867924528301886, "train_stats/max_log_achievement_make_wood_sword": 1.9245283018867925, "train_stats/max_log_achievement_place_plant": 2.443396226415094, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.811320754716981, "train_stats/max_log_achievement_wake_up": 1.349056603773585, "train_stats/mean_log_entropy": 0.5253223020513103, "eval_stats/sum_log_reward": 6.335294050328872, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.823529411764706, "eval_stats/max_log_achievement_collect_sapling": 1.8823529411764706, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 10.764705882352942, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.058823529411764705, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.588235294117647, "eval_stats/max_log_achievement_place_plant": 1.8823529411764706, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.6470588235294117, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 3.196075795131037e-06, "report/cont_loss_std": 6.807073077652603e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.951722313417122e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.91305559585453e-06, "report/cont_pred": 0.9970678091049194, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 14.782691955566406, "report/dyn_loss_std": 9.558831214904785, "report/image_loss_mean": 5.518834590911865, "report/image_loss_std": 9.99200439453125, "report/model_loss_mean": 14.441868782043457, "report/model_loss_std": 14.249367713928223, "report/post_ent_mag": 55.961036682128906, "report/post_ent_max": 55.961036682128906, "report/post_ent_mean": 41.244293212890625, "report/post_ent_min": 17.285221099853516, "report/post_ent_std": 7.1636271476745605, "report/prior_ent_mag": 69.81896209716797, "report/prior_ent_max": 69.81896209716797, "report/prior_ent_mean": 55.97511291503906, "report/prior_ent_min": 41.50547790527344, "report/prior_ent_std": 4.477528095245361, "report/rep_loss_mean": 14.782691955566406, "report/rep_loss_std": 9.558831214904785, "report/reward_avg": 0.01328124850988388, "report/reward_loss_mean": 0.05341650918126106, "report/reward_loss_std": 0.27169445157051086, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0034666061401367, "report/reward_neg_acc": 0.9940239191055298, "report/reward_neg_loss": 0.03208474442362785, "report/reward_pos_acc": 0.949999988079071, "report/reward_pos_loss": 1.1242711544036865, "report/reward_pred": 0.010293275117874146, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.328097955090925e-05, "eval/cont_loss_std": 0.0007615942740812898, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.003058907575905323, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.439079798932653e-05, "eval/cont_pred": 0.9970552325248718, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.356441497802734, "eval/dyn_loss_std": 10.696117401123047, "eval/image_loss_mean": 7.5295610427856445, "eval/image_loss_std": 10.504776954650879, "eval/model_loss_mean": 17.424209594726562, "eval/model_loss_std": 15.205455780029297, "eval/post_ent_mag": 56.95697021484375, "eval/post_ent_max": 56.95697021484375, "eval/post_ent_mean": 41.430320739746094, "eval/post_ent_min": 21.247970581054688, "eval/post_ent_std": 7.4361982345581055, "eval/prior_ent_mag": 69.81896209716797, "eval/prior_ent_max": 69.81896209716797, "eval/prior_ent_mean": 56.019351959228516, "eval/prior_ent_min": 40.5082893371582, "eval/prior_ent_std": 4.416247367858887, "eval/rep_loss_mean": 16.356441497802734, "eval/rep_loss_std": 10.696117401123047, "eval/reward_avg": 0.03173828125, "eval/reward_loss_mean": 0.08075004816055298, "eval/reward_loss_std": 0.42383718490600586, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001755714416504, "eval/reward_neg_acc": 0.9858441948890686, "eval/reward_neg_loss": 0.04717521741986275, "eval/reward_pos_acc": 0.9428571462631226, "eval/reward_pos_loss": 1.029478907585144, "eval/reward_pred": 0.03269268944859505, "eval/reward_rate": 0.0341796875, "replay/size": 643601.0, "replay/inserts": 22032.0, "replay/samples": 22032.0, "replay/insert_wait_avg": 1.4153073123164514e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.488034717224609e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2294443884058125e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2249200344086, "timer/env.step_count": 2754.0, "timer/env.step_total": 247.63396453857422, "timer/env.step_frac": 0.24757827922349246, "timer/env.step_avg": 0.08991792466905382, "timer/env.step_min": 0.024225473403930664, "timer/env.step_max": 3.2940592765808105, "timer/replay._sample_count": 22032.0, "timer/replay._sample_total": 11.447269201278687, "timer/replay._sample_frac": 0.01144469506007198, "timer/replay._sample_avg": 0.0005195746732606521, "timer/replay._sample_min": 0.00038242340087890625, "timer/replay._sample_max": 0.011286020278930664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3283.0, "timer/agent.policy_total": 56.80090618133545, "timer/agent.policy_frac": 0.05678813339241883, "timer/agent.policy_avg": 0.017301524880089993, "timer/agent.policy_min": 0.009810447692871094, "timer/agent.policy_max": 0.0980076789855957, "timer/dataset_train_count": 1377.0, "timer/dataset_train_total": 0.16682171821594238, "timer/dataset_train_frac": 0.00016678420510679096, "timer/dataset_train_avg": 0.00012114866972835322, "timer/dataset_train_min": 0.00010037422180175781, "timer/dataset_train_max": 0.0008661746978759766, "timer/agent.train_count": 1377.0, "timer/agent.train_total": 622.8014552593231, "timer/agent.train_frac": 0.622661406234408, "timer/agent.train_avg": 0.4522886385325513, "timer/agent.train_min": 0.43974804878234863, "timer/agent.train_max": 1.7866754531860352, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4774281978607178, "timer/agent.report_frac": 0.0004773208388412217, "timer/agent.report_avg": 0.2387140989303589, "timer/agent.report_min": 0.23006319999694824, "timer/agent.report_max": 0.24736499786376953, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.1225810551920915e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 22.02671562040182}
{"step": 644536, "time": 30430.844593524933, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 644600, "time": 30434.560109853745, "episode/length": 210.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 644824, "time": 30443.75242447853, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 644896, "time": 30448.124392032623, "episode/length": 216.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 644928, "time": 30450.736542224884, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 645168, "time": 30460.406042814255, "episode/length": 318.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9968652037617555, "episode/intrinsic_return": 0.0}
{"step": 645408, "time": 30469.941867351532, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 645584, "time": 30477.336955308914, "episode/length": 206.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 645960, "time": 30491.562277793884, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9831460674157303, "episode/intrinsic_return": 0.0}
{"step": 646040, "time": 30495.83687567711, "episode/length": 332.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 646424, "time": 30510.304009199142, "episode/length": 186.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 646480, "time": 30513.96697640419, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 646736, "time": 30524.12864112854, "episode/length": 195.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 647112, "time": 30538.242933750153, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 647200, "time": 30544.71827316284, "episode/length": 223.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 647344, "time": 30551.137316703796, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 647800, "time": 30567.88114619255, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 648080, "time": 30579.13262438774, "episode/length": 254.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9686274509803922, "episode/intrinsic_return": 0.0}
{"step": 648120, "time": 30581.88992547989, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 648176, "time": 30585.537747383118, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 648384, "time": 30594.022114515305, "episode/length": 435.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9885321100917431, "episode/intrinsic_return": 0.0}
{"step": 648480, "time": 30598.87495827675, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 649176, "time": 30623.634657144547, "episode/length": 257.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 649232, "time": 30627.350140094757, "episode/length": 178.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 649696, "time": 30644.683766126633, "episode/length": 201.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 649720, "time": 30646.905920028687, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 649728, "time": 30649.015677928925, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 649776, "time": 30652.292067050934, "episode/length": 303.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 649848, "time": 30656.092101335526, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 649952, "time": 30662.20522904396, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 30685.506558656693, "eval_episode/length": 144.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 650000, "time": 30691.076642513275, "eval_episode/length": 198.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 650000, "time": 30693.7125916481, "eval_episode/length": 220.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9773755656108597}
{"step": 650000, "time": 30695.613822460175, "eval_episode/length": 228.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 650000, "time": 30697.37623643875, "eval_episode/length": 231.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 650000, "time": 30699.715074300766, "eval_episode/length": 246.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 650000, "time": 30703.981463193893, "eval_episode/length": 161.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 650000, "time": 30710.025158166885, "eval_episode/length": 202.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 650016, "time": 30710.560726881027, "episode/length": 35.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 650504, "time": 30728.395398378372, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 650784, "time": 30739.567522525787, "episode/length": 132.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 651040, "time": 30749.759895324707, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 651088, "time": 30753.031425714493, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 651104, "time": 30755.199231147766, "episode/length": 233.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 651216, "time": 30760.55306482315, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 651784, "time": 30781.10338282585, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 651800, "time": 30783.19149541855, "episode/length": 222.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 652128, "time": 30795.890553474426, "episode/length": 271.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 652480, "time": 30809.481272935867, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 652752, "time": 30820.313418388367, "episode/length": 213.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 652824, "time": 30824.104016065598, "episode/length": 214.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 652920, "time": 30828.957401514053, "episode/length": 139.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 653192, "time": 30839.835543632507, "episode/length": 246.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 653336, "time": 30846.240431547165, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 653456, "time": 30852.034093141556, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 654112, "time": 30875.653906583786, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 654264, "time": 30882.172479867935, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 654392, "time": 30888.022265434265, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 654624, "time": 30897.711594581604, "episode/length": 224.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 654848, "time": 30907.086255073547, "episode/length": 469.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.997872340425532, "episode/intrinsic_return": 0.0}
{"step": 654896, "time": 30910.720977544785, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 655112, "time": 30919.456796884537, "episode/length": 105.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.0}
{"step": 655296, "time": 30927.50780439377, "episode/length": 244.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 655320, "time": 30929.752232789993, "episode/length": 232.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 655584, "time": 30941.99240756035, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 656016, "time": 30958.191878795624, "episode/length": 202.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 656064, "time": 30961.496544122696, "episode/length": 92.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 656176, "time": 30966.953877687454, "episode/length": 159.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 656376, "time": 30975.125930547714, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 656496, "time": 30981.03547334671, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 656576, "time": 30985.32845044136, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 656952, "time": 30999.41339659691, "episode/length": 290.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759450171821306, "episode/intrinsic_return": 0.0}
{"step": 657048, "time": 31004.17936563492, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 657296, "time": 31014.54483127594, "episode/length": 42.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 657600, "time": 31026.44113445282, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 657648, "time": 31029.65119433403, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 657960, "time": 31041.69934296608, "episode/length": 236.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 658000, "time": 31044.851816892624, "episode/length": 227.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 658312, "time": 31056.719589710236, "episode/length": 226.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 658320, "time": 31058.800768136978, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 658664, "time": 31071.707921028137, "episode/length": 260.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 658704, "time": 31074.933633327484, "episode/length": 47.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 659352, "time": 31098.379322767258, "episode/length": 256.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 659504, "time": 31105.28755903244, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 659664, "time": 31112.42188310623, "episode/length": 257.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9728682170542635, "episode/intrinsic_return": 0.0}
{"step": 659752, "time": 31116.74991297722, "episode/length": 218.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 659896, "time": 31123.086463689804, "episode/length": 280.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9822064056939501, "episode/intrinsic_return": 0.0}
{"step": 659896, "time": 31123.095463752747, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 31153.893168210983, "eval_episode/length": 172.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9595375722543352}
{"step": 660088, "time": 31155.909439086914, "eval_episode/length": 181.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.967032967032967}
{"step": 660088, "time": 31158.060717344284, "eval_episode/length": 195.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9846938775510204}
{"step": 660088, "time": 31159.852509737015, "eval_episode/length": 199.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.965}
{"step": 660088, "time": 31164.124271154404, "eval_episode/length": 253.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9960629921259843}
{"step": 660088, "time": 31167.372244358063, "eval_episode/length": 36.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.972972972972973}
{"step": 660088, "time": 31169.42621254921, "eval_episode/length": 296.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9831649831649831}
{"step": 660088, "time": 31169.434916496277, "eval_episode/length": 296.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9831649831649831}
{"step": 660096, "time": 31169.943064451218, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 660528, "time": 31186.027205228806, "episode/length": 227.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 660680, "time": 31192.390038490295, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 660976, "time": 31204.218843221664, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 661432, "time": 31220.992969036102, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 661568, "time": 31228.13900923729, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 661624, "time": 31231.51355624199, "episode/length": 136.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 661640, "time": 31233.644553661346, "episode/length": 217.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 661656, "time": 31235.71749138832, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 661688, "time": 31238.36516904831, "episode/length": 252.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 663072, "time": 31286.738650798798, "episode/length": 261.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 663192, "time": 31292.313878536224, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 663664, "time": 31311.876893997192, "episode/length": 261.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 663968, "time": 31324.324040174484, "episode/length": 288.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 664312, "time": 31337.189662456512, "episode/length": 453.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9845814977973568, "episode/intrinsic_return": 0.0}
{"step": 664424, "time": 31342.56628346443, "episode/length": 349.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9971428571428571, "episode/intrinsic_return": 0.0}
{"step": 664480, "time": 31346.23111462593, "episode/length": 160.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 665296, "time": 31375.38881134987, "episode/length": 482.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9834368530020704, "episode/intrinsic_return": 0.0}
{"step": 665328, "time": 31378.119552135468, "episode/length": 281.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 665472, "time": 31384.5106446743, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 665648, "time": 31391.988406658173, "episode/length": 494.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9838383838383838, "episode/intrinsic_return": 0.0}
{"step": 665784, "time": 31397.854421138763, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 665848, "time": 31401.580672740936, "episode/length": 234.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 666160, "time": 31413.825424671173, "episode/length": 38.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 666169, "time": 31416.493362903595, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.424862604071624, "train/action_min": 0.0, "train/action_std": 3.4399021959652867, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04455184607501447, "train/actor_opt_grad_steps": 40850.0, "train/actor_opt_loss": -3.5266689466462084, "train/adv_mag": 0.6021975178788178, "train/adv_max": 0.5703220626298529, "train/adv_mean": 0.003953274560177077, "train/adv_min": -0.45161081709130835, "train/adv_std": 0.06717843701043268, "train/cont_avg": 0.9943473426094891, "train/cont_loss_mean": 0.00013564153481510847, "train/cont_loss_std": 0.004122124685288134, "train/cont_neg_acc": 0.9958637474227126, "train/cont_neg_loss": 0.006874475239816544, "train/cont_pos_acc": 0.9999712971005127, "train/cont_pos_loss": 9.71278487614583e-05, "train/cont_pred": 0.9943312615373708, "train/cont_rate": 0.9943473426094891, "train/dyn_loss_mean": 12.832240000258397, "train/dyn_loss_std": 9.443076300795061, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8250917296339996, "train/extr_critic_critic_opt_grad_steps": 40850.0, "train/extr_critic_critic_opt_loss": 16258.118406421077, "train/extr_critic_mag": 6.0233472594379505, "train/extr_critic_max": 6.0233472594379505, "train/extr_critic_mean": 1.4724942824266252, "train/extr_critic_min": -0.37524476190553097, "train/extr_critic_std": 1.4328059836895797, "train/extr_return_normed_mag": 1.7095008427209228, "train/extr_return_normed_max": 1.7095008427209228, "train/extr_return_normed_mean": 0.3594826922146943, "train/extr_return_normed_min": -0.13974297098325986, "train/extr_return_normed_std": 0.33508702938574075, "train/extr_return_rate": 0.6527662453425191, "train/extr_return_raw_mag": 7.413169913048292, "train/extr_return_raw_max": 7.413169913048292, "train/extr_return_raw_mean": 1.4898489282949128, "train/extr_return_raw_min": -0.7006190560594963, "train/extr_return_raw_std": 1.4705193268991734, "train/extr_reward_mag": 1.0274676162831105, "train/extr_reward_max": 1.0274676162831105, "train/extr_reward_mean": 0.034455249670648225, "train/extr_reward_min": -0.5144712994568539, "train/extr_reward_std": 0.17611737320893003, "train/image_loss_mean": 5.798467615225019, "train/image_loss_std": 10.377873479884906, "train/model_loss_mean": 13.548322531428651, "train/model_loss_std": 14.281470159544561, "train/model_opt_grad_norm": 54.32217785911838, "train/model_opt_grad_steps": 40811.99270072993, "train/model_opt_loss": 18342.435226106296, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1350.3649635036497, "train/policy_entropy_mag": 2.520200952126162, "train/policy_entropy_max": 2.520200952126162, "train/policy_entropy_mean": 0.5583330862713556, "train/policy_entropy_min": 0.07937505232156629, "train/policy_entropy_std": 0.6476645051997943, "train/policy_logprob_mag": 7.438383534006829, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5586182301061867, "train/policy_logprob_min": -7.438383534006829, "train/policy_logprob_std": 1.103111738706157, "train/policy_randomness_mag": 0.8895203423326032, "train/policy_randomness_max": 0.8895203423326032, "train/policy_randomness_mean": 0.19706707844768998, "train/policy_randomness_min": 0.02801591015155733, "train/policy_randomness_std": 0.22859715001426473, "train/post_ent_mag": 58.9783875681188, "train/post_ent_max": 58.9783875681188, "train/post_ent_mean": 42.550302046058825, "train/post_ent_min": 20.852427030131764, "train/post_ent_std": 7.309852530486392, "train/prior_ent_mag": 69.42143449992159, "train/prior_ent_max": 69.42143449992159, "train/prior_ent_mean": 55.49729398741339, "train/prior_ent_min": 38.51003787465339, "train/prior_ent_std": 4.745992751017104, "train/rep_loss_mean": 12.832240000258397, "train/rep_loss_std": 9.443076300795061, "train/reward_avg": 0.02401916043030737, "train/reward_loss_mean": 0.050375339568313894, "train/reward_loss_std": 0.22937948534088412, "train/reward_max_data": 1.0094890533572567, "train/reward_max_pred": 1.006420803766181, "train/reward_neg_acc": 0.9936598822148177, "train/reward_neg_loss": 0.027054148634392632, "train/reward_pos_acc": 0.9697766399731601, "train/reward_pos_loss": 0.8323430967156904, "train/reward_pred": 0.02337281189750146, "train/reward_rate": 0.029026003649635035, "train_stats/sum_log_reward": 6.686538448700538, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.105769230769231, "train_stats/max_log_achievement_collect_sapling": 2.5384615384615383, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 11.865384615384615, "train_stats/max_log_achievement_defeat_skeleton": 0.028846153846153848, "train_stats/max_log_achievement_defeat_zombie": 1.2307692307692308, "train_stats/max_log_achievement_eat_cow": 0.18269230769230768, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009615384615384616, "train_stats/max_log_achievement_make_wood_sword": 1.8269230769230769, "train_stats/max_log_achievement_place_plant": 2.5096153846153846, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.9423076923076925, "train_stats/max_log_achievement_wake_up": 1.6730769230769231, "train_stats/mean_log_entropy": 0.5383979223955137, "eval_stats/sum_log_reward": 6.8499999940395355, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.6875, "eval_stats/max_log_achievement_collect_sapling": 3.0, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 11.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.1875, "eval_stats/max_log_achievement_eat_cow": 0.4375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.75, "eval_stats/max_log_achievement_place_plant": 2.9375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00010566507990006357, "report/cont_loss_std": 0.002247821306809783, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003325316065456718, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00010477539763087407, "report/cont_pred": 0.9959932565689087, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.253602981567383, "report/dyn_loss_std": 9.52254581451416, "report/image_loss_mean": 6.028780937194824, "report/image_loss_std": 9.635453224182129, "report/model_loss_mean": 14.636333465576172, "report/model_loss_std": 13.453694343566895, "report/post_ent_mag": 58.374168395996094, "report/post_ent_max": 58.374168395996094, "report/post_ent_mean": 41.603797912597656, "report/post_ent_min": 21.208763122558594, "report/post_ent_std": 7.476894855499268, "report/prior_ent_mag": 69.43592834472656, "report/prior_ent_max": 69.43592834472656, "report/prior_ent_mean": 55.89653015136719, "report/prior_ent_min": 38.942691802978516, "report/prior_ent_std": 4.768845081329346, "report/rep_loss_mean": 14.253602981567383, "report/rep_loss_std": 9.52254581451416, "report/reward_avg": 0.02695312350988388, "report/reward_loss_mean": 0.05528496950864792, "report/reward_loss_std": 0.2433883547782898, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.003002405166626, "report/reward_neg_acc": 0.9969757795333862, "report/reward_neg_loss": 0.02948414906859398, "report/reward_pos_acc": 0.9375, "report/reward_pos_loss": 0.8551103472709656, "report/reward_pred": 0.024828143417835236, "report/reward_rate": 0.03125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 5.364551270758966e-06, "eval/cont_loss_std": 0.0001098181091947481, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0001794105482986197, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.166593953414122e-06, "eval/cont_pred": 0.9931612014770508, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 16.470909118652344, "eval/dyn_loss_std": 10.921833038330078, "eval/image_loss_mean": 7.905803680419922, "eval/image_loss_std": 11.055085182189941, "eval/model_loss_mean": 17.89078140258789, "eval/model_loss_std": 15.570995330810547, "eval/post_ent_mag": 56.99919509887695, "eval/post_ent_max": 56.99919509887695, "eval/post_ent_mean": 42.045143127441406, "eval/post_ent_min": 18.10804557800293, "eval/post_ent_std": 7.169853210449219, "eval/prior_ent_mag": 69.43592834472656, "eval/prior_ent_max": 69.43592834472656, "eval/prior_ent_mean": 56.07123565673828, "eval/prior_ent_min": 39.14588165283203, "eval/prior_ent_std": 4.549678802490234, "eval/rep_loss_mean": 16.470909118652344, "eval/rep_loss_std": 10.921833038330078, "eval/reward_avg": 0.03310546651482582, "eval/reward_loss_mean": 0.10242529213428497, "eval/reward_loss_std": 0.6037025451660156, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0002086162567139, "eval/reward_neg_acc": 0.992893397808075, "eval/reward_neg_loss": 0.03439220413565636, "eval/reward_pos_acc": 0.7948718070983887, "eval/reward_pos_loss": 1.8206967115402222, "eval/reward_pred": 0.025764252990484238, "eval/reward_rate": 0.0380859375, "replay/size": 665665.0, "replay/inserts": 22064.0, "replay/samples": 22064.0, "replay/insert_wait_avg": 1.4328995504787298e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.329306070661095e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5592.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2079959945787859e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2218952178955078e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2104892730713, "timer/env.step_count": 2758.0, "timer/env.step_total": 245.57755327224731, "timer/env.step_frac": 0.24552587270978043, "timer/env.step_avg": 0.08904189748812448, "timer/env.step_min": 0.0247952938079834, "timer/env.step_max": 3.3383634090423584, "timer/replay._sample_count": 22064.0, "timer/replay._sample_total": 11.25598931312561, "timer/replay._sample_frac": 0.011253620546717311, "timer/replay._sample_avg": 0.0005101517999059831, "timer/replay._sample_min": 0.0003581047058105469, "timer/replay._sample_max": 0.016752958297729492, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3457.0, "timer/agent.policy_total": 60.00371527671814, "timer/agent.policy_frac": 0.05999108779625715, "timer/agent.policy_avg": 0.017357163805819538, "timer/agent.policy_min": 0.009431600570678711, "timer/agent.policy_max": 0.11988162994384766, "timer/dataset_train_count": 1379.0, "timer/dataset_train_total": 0.16108155250549316, "timer/dataset_train_frac": 0.00016104765370193562, "timer/dataset_train_avg": 0.0001168104079082619, "timer/dataset_train_min": 0.00010347366333007812, "timer/dataset_train_max": 0.00048279762268066406, "timer/agent.train_count": 1379.0, "timer/agent.train_total": 620.0539753437042, "timer/agent.train_frac": 0.6199234880993344, "timer/agent.train_avg": 0.44964030119195375, "timer/agent.train_min": 0.4336986541748047, "timer/agent.train_max": 1.6769704818725586, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48232579231262207, "timer/agent.report_frac": 0.0004822242892725158, "timer/agent.report_avg": 0.24116289615631104, "timer/agent.report_min": 0.2341454029083252, "timer/agent.report_max": 0.24818038940429688, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.8623809814453125e-05, "timer/dataset_eval_frac": 3.861568162769816e-08, "timer/dataset_eval_avg": 3.8623809814453125e-05, "timer/dataset_eval_min": 3.8623809814453125e-05, "timer/dataset_eval_max": 3.8623809814453125e-05, "fps": 22.059053276614826}
{"step": 666184, "time": 31416.580331087112, "episode/length": 212.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 666376, "time": 31425.28757739067, "episode/length": 257.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 666800, "time": 31442.04938173294, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 666944, "time": 31448.742474794388, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 667008, "time": 31453.01500058174, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 667032, "time": 31455.35157084465, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 667424, "time": 31470.49412703514, "episode/length": 157.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 667464, "time": 31473.208299398422, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 667488, "time": 31475.803933382034, "episode/length": 67.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 667632, "time": 31482.18433856964, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 667696, "time": 31485.94415283203, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 668456, "time": 31513.230590105057, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 668536, "time": 31517.549468040466, "episode/length": 138.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 668672, "time": 31524.583745241165, "episode/length": 233.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 669040, "time": 31539.097935199738, "episode/length": 167.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 669120, "time": 31543.38036632538, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 669264, "time": 31549.830220222473, "episode/length": 224.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 31599.05729651451, "eval_episode/length": 160.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9813664596273292}
{"step": 670072, "time": 31600.646301984787, "eval_episode/length": 161.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 670072, "time": 31602.403472661972, "eval_episode/length": 166.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9820359281437125}
{"step": 670072, "time": 31605.61398434639, "eval_episode/length": 199.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 670072, "time": 31607.54516506195, "eval_episode/length": 206.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 670072, "time": 31609.63386464119, "eval_episode/length": 217.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.981651376146789}
{"step": 670072, "time": 31611.678039073944, "eval_episode/length": 228.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9694323144104804}
{"step": 670072, "time": 31615.17130970955, "eval_episode/length": 104.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9428571428571428}
{"step": 670152, "time": 31617.98694086075, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 670264, "time": 31623.339399576187, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 670360, "time": 31628.18702530861, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 670416, "time": 31631.94281077385, "episode/length": 365.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9972677595628415, "episode/intrinsic_return": 0.0}
{"step": 670480, "time": 31635.7062792778, "episode/length": 169.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 670632, "time": 31642.250992059708, "episode/length": 170.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 670768, "time": 31648.801445245743, "episode/length": 261.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 670808, "time": 31651.487686872482, "episode/length": 474.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747368421052631, "episode/intrinsic_return": 0.0}
{"step": 670896, "time": 31656.665788173676, "episode/length": 51.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 671712, "time": 31685.69392633438, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 671864, "time": 31693.526141881943, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 671920, "time": 31697.15742135048, "episode/length": 206.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 672112, "time": 31705.202656269073, "episode/length": 211.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 672368, "time": 31715.462629795074, "episode/length": 216.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 672456, "time": 31719.840378284454, "episode/length": 205.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 672456, "time": 31719.84919142723, "episode/length": 210.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 672584, "time": 31727.556988716125, "episode/length": 210.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 673400, "time": 31756.406514406204, "episode/length": 160.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 673424, "time": 31758.97939634323, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 673688, "time": 31769.260479688644, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 673704, "time": 31771.415600061417, "episode/length": 34.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 673720, "time": 31773.448315620422, "episode/length": 231.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 673872, "time": 31780.351746320724, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 674248, "time": 31794.22891998291, "episode/length": 223.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 674288, "time": 31797.346926689148, "episode/length": 295.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 674816, "time": 31816.80113863945, "episode/length": 278.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 675048, "time": 31826.04846549034, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 675080, "time": 31828.959637403488, "episode/length": 209.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 675168, "time": 31833.68386244774, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 675200, "time": 31836.28301882744, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 675312, "time": 31841.594739675522, "episode/length": 32.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 675368, "time": 31844.85338997841, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 675880, "time": 31863.688279390335, "episode/length": 198.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 676016, "time": 31869.880249500275, "episode/length": 220.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 676456, "time": 31886.181515216827, "episode/length": 160.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 676776, "time": 31898.762733221054, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 676856, "time": 31903.04723906517, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 677032, "time": 31910.543927669525, "episode/length": 214.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 677040, "time": 31912.566571235657, "episode/length": 277.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9892086330935251, "episode/intrinsic_return": 0.0}
{"step": 677072, "time": 31915.308447360992, "episode/length": 36.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 677176, "time": 31920.15063047409, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 677280, "time": 31925.363639593124, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 677536, "time": 31935.52907896042, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 677840, "time": 31947.26589179039, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 678456, "time": 31969.225490808487, "episode/length": 176.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 678568, "time": 31974.595788002014, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 678664, "time": 31979.504926919937, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 678808, "time": 31985.848502874374, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 678864, "time": 31989.597800016403, "episode/length": 210.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 678944, "time": 31993.82622027397, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 679280, "time": 32006.649114370346, "episode/length": 41.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 679288, "time": 32008.44150686264, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 679488, "time": 32017.029307603836, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 679664, "time": 32024.47369813919, "episode/length": 46.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 679928, "time": 32034.80998134613, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 679936, "time": 32037.053168296814, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 32065.241903543472, "eval_episode/length": 164.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 680056, "time": 32067.307950735092, "eval_episode/length": 165.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9578313253012049}
{"step": 680056, "time": 32070.167850017548, "eval_episode/length": 186.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9679144385026738}
{"step": 680056, "time": 32074.96292948723, "eval_episode/length": 216.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 680056, "time": 32076.791692733765, "eval_episode/length": 219.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 680056, "time": 32080.161779880524, "eval_episode/length": 259.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9961538461538462}
{"step": 680056, "time": 32083.72044157982, "eval_episode/length": 137.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9565217391304348}
{"step": 680056, "time": 32083.728628396988, "eval_episode/length": 303.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9967105263157895}
{"step": 680368, "time": 32094.390496492386, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 680592, "time": 32103.735932588577, "episode/length": 215.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 680744, "time": 32110.271800756454, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 680808, "time": 32113.994572639465, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 680984, "time": 32121.575941324234, "episode/length": 271.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 681344, "time": 32135.580573797226, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 681480, "time": 32141.554784297943, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 681664, "time": 32149.50642681122, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 682112, "time": 32166.608489513397, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 682304, "time": 32174.607729673386, "episode/length": 194.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 682440, "time": 32180.47321653366, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 682568, "time": 32186.341772556305, "episode/length": 197.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 682568, "time": 32186.351442337036, "episode/length": 274.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 682952, "time": 32202.61630487442, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 683008, "time": 32206.40560555458, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 683288, "time": 32217.145101308823, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 683416, "time": 32223.148416757584, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 683440, "time": 32225.747675657272, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 683896, "time": 32242.390873670578, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 683912, "time": 32244.606199026108, "episode/length": 112.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 684152, "time": 32254.35030412674, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 684160, "time": 32256.4068069458, "episode/length": 231.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 684248, "time": 32260.764668941498, "episode/length": 209.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 684416, "time": 32268.242589473724, "episode/length": 140.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 685032, "time": 32290.335634708405, "episode/length": 141.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 685336, "time": 32302.1225566864, "episode/length": 236.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 685408, "time": 32306.309937238693, "episode/length": 248.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 685664, "time": 32316.72756433487, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 685672, "time": 32318.40654540062, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 685888, "time": 32327.60401248932, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 686344, "time": 32344.599241256714, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 686712, "time": 32358.50303220749, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 687096, "time": 32373.08740711212, "episode/length": 210.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 687240, "time": 32379.6525452137, "episode/length": 196.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 687408, "time": 32387.146522521973, "episode/length": 216.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 687536, "time": 32393.07977104187, "episode/length": 452.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9977924944812362, "episode/intrinsic_return": 0.0}
{"step": 688137, "time": 32417.783125400543, "train_stats/sum_log_reward": 6.6045871798051605, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.412844036697248, "train_stats/max_log_achievement_collect_sapling": 1.9724770642201834, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 11.220183486238533, "train_stats/max_log_achievement_defeat_skeleton": 0.009174311926605505, "train_stats/max_log_achievement_defeat_zombie": 1.1192660550458715, "train_stats/max_log_achievement_eat_cow": 0.1834862385321101, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 1.8623853211009174, "train_stats/max_log_achievement_place_plant": 1.8990825688073394, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.889908256880734, "train_stats/max_log_achievement_wake_up": 1.4862385321100917, "train_stats/mean_log_entropy": 0.49255493939469713, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.379160563151042, "train/action_min": 0.0, "train/action_std": 3.3773698012034097, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044573733367133835, "train/actor_opt_grad_steps": 42225.0, "train/actor_opt_loss": -2.2070864199296287, "train/adv_mag": 0.5758871827004612, "train/adv_max": 0.5545816104049268, "train/adv_mean": 0.003966213986415454, "train/adv_min": -0.428593504903973, "train/adv_std": 0.066717565599559, "train/cont_avg": 0.994430763134058, "train/cont_loss_mean": 0.00029900415618640085, "train/cont_loss_std": 0.00879966129853288, "train/cont_neg_acc": 0.9886818515217822, "train/cont_neg_loss": 0.030366723106888694, "train/cont_pos_acc": 0.9999501363954683, "train/cont_pos_loss": 0.00013623111766126433, "train/cont_pred": 0.9944457074870234, "train/cont_rate": 0.994430763134058, "train/dyn_loss_mean": 12.759202141692674, "train/dyn_loss_std": 9.508001486460367, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8606115605520166, "train/extr_critic_critic_opt_grad_steps": 42225.0, "train/extr_critic_critic_opt_loss": 16262.494084012682, "train/extr_critic_mag": 6.130110975624858, "train/extr_critic_max": 6.130110975624858, "train/extr_critic_mean": 1.468172606350719, "train/extr_critic_min": -0.34218867360681726, "train/extr_critic_std": 1.4160166585790939, "train/extr_return_normed_mag": 1.7090188947276792, "train/extr_return_normed_max": 1.7090188947276792, "train/extr_return_normed_mean": 0.3529516679869182, "train/extr_return_normed_min": -0.12946582566676795, "train/extr_return_normed_std": 0.33110633265712985, "train/extr_return_rate": 0.6542266123536704, "train/extr_return_raw_mag": 7.435397783915202, "train/extr_return_raw_max": 7.435397783915202, "train/extr_return_raw_mean": 1.4855266982230588, "train/extr_return_raw_min": -0.6307702254557955, "train/extr_return_raw_std": 1.452643055414808, "train/extr_reward_mag": 1.0266550373339998, "train/extr_reward_max": 1.0266550373339998, "train/extr_reward_mean": 0.03372486420245706, "train/extr_reward_min": -0.446628054846888, "train/extr_reward_std": 0.1740584810250911, "train/image_loss_mean": 5.841039204943007, "train/image_loss_std": 10.664465990619384, "train/model_loss_mean": 13.547470535057178, "train/model_loss_std": 14.609849522079246, "train/model_opt_grad_norm": 50.510117489358656, "train/model_opt_grad_steps": 42185.31884057971, "train/model_opt_loss": 11141.83060178895, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 824.2753623188406, "train/policy_entropy_mag": 2.526793851368669, "train/policy_entropy_max": 2.526793851368669, "train/policy_entropy_mean": 0.536974914048029, "train/policy_entropy_min": 0.07937505042207414, "train/policy_entropy_std": 0.616520793541618, "train/policy_logprob_mag": 7.438383613807567, "train/policy_logprob_max": -0.009455660992450472, "train/policy_logprob_mean": -0.5364069666551508, "train/policy_logprob_min": -7.438383613807567, "train/policy_logprob_std": 1.0892350919868634, "train/policy_randomness_mag": 0.8918473461399907, "train/policy_randomness_max": 0.8918473461399907, "train/policy_randomness_mean": 0.18952858005312906, "train/policy_randomness_min": 0.02801590952752293, "train/policy_randomness_std": 0.21760478410599887, "train/post_ent_mag": 59.11421446869339, "train/post_ent_max": 59.11421446869339, "train/post_ent_mean": 42.75558764692666, "train/post_ent_min": 20.861140569051106, "train/post_ent_std": 7.341366512188013, "train/prior_ent_mag": 69.40742542432702, "train/prior_ent_max": 69.40742542432702, "train/prior_ent_mean": 55.57970281960308, "train/prior_ent_min": 38.47543007394542, "train/prior_ent_std": 4.767743459646253, "train/rep_loss_mean": 12.759202141692674, "train/rep_loss_std": 9.508001486460367, "train/reward_avg": 0.022999462000080857, "train/reward_loss_mean": 0.0506111776618206, "train/reward_loss_std": 0.23511116422604825, "train/reward_max_data": 1.0115942056628242, "train/reward_max_pred": 1.0072112852248594, "train/reward_neg_acc": 0.9938136511954708, "train/reward_neg_loss": 0.02757106056652855, "train/reward_pos_acc": 0.9657133610352225, "train/reward_pos_loss": 0.8563738987929579, "train/reward_pred": 0.022155575349630006, "train/reward_rate": 0.02798063858695652, "eval_stats/sum_log_reward": 6.662500023841858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.375, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 11.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.9375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 2.1875, "eval_stats/max_log_achievement_place_plant": 2.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.8125, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0006863418384455144, "report/cont_loss_std": 0.01883702725172043, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.08639369904994965, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 9.641914948588237e-05, "report/cont_pred": 0.9935157299041748, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.910127639770508, "report/dyn_loss_std": 9.302245140075684, "report/image_loss_mean": 5.5533366203308105, "report/image_loss_std": 8.79375171661377, "report/model_loss_mean": 13.347352981567383, "report/model_loss_std": 13.034393310546875, "report/post_ent_mag": 58.4962158203125, "report/post_ent_max": 58.4962158203125, "report/post_ent_mean": 42.69298553466797, "report/post_ent_min": 21.69390106201172, "report/post_ent_std": 6.795522212982178, "report/prior_ent_mag": 69.67924499511719, "report/prior_ent_max": 69.67924499511719, "report/prior_ent_mean": 55.76111602783203, "report/prior_ent_min": 42.278709411621094, "report/prior_ent_std": 4.831151485443115, "report/rep_loss_mean": 12.910127639770508, "report/rep_loss_std": 9.302245140075684, "report/reward_avg": 0.01689453050494194, "report/reward_loss_mean": 0.04725384712219238, "report/reward_loss_std": 0.17912012338638306, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0638103485107422, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03134717419743538, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7100319862365723, "report/reward_pred": 0.0165414996445179, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.0002601824817247689, "eval/cont_loss_std": 0.008131550624966621, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00013300831778906286, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00026118382811546326, "eval/cont_pred": 0.991959810256958, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 16.653133392333984, "eval/dyn_loss_std": 10.9697904586792, "eval/image_loss_mean": 9.46760368347168, "eval/image_loss_std": 13.067133903503418, "eval/model_loss_mean": 19.530427932739258, "eval/model_loss_std": 17.238462448120117, "eval/post_ent_mag": 59.29338073730469, "eval/post_ent_max": 59.29338073730469, "eval/post_ent_mean": 41.57904815673828, "eval/post_ent_min": 20.91851043701172, "eval/post_ent_std": 7.39640998840332, "eval/prior_ent_mag": 69.67924499511719, "eval/prior_ent_max": 69.67924499511719, "eval/prior_ent_mean": 56.0635986328125, "eval/prior_ent_min": 33.54355239868164, "eval/prior_ent_std": 4.3612213134765625, "eval/rep_loss_mean": 16.653133392333984, "eval/rep_loss_std": 10.9697904586792, "eval/reward_avg": 0.02333984524011612, "eval/reward_loss_mean": 0.07068422436714172, "eval/reward_loss_std": 0.32316508889198303, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0035715103149414, "eval/reward_neg_acc": 0.9959757924079895, "eval/reward_neg_loss": 0.04327823221683502, "eval/reward_pos_acc": 0.9333333969116211, "eval/reward_pos_loss": 0.978736162185669, "eval/reward_pred": 0.023225080221891403, "eval/reward_rate": 0.029296875, "replay/size": 687633.0, "replay/inserts": 21968.0, "replay/samples": 21968.0, "replay/insert_wait_avg": 1.4422327084690659e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.544670953771448e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4568.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2653721610635466e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.2686116695404, "timer/env.step_count": 2746.0, "timer/env.step_total": 256.74522829055786, "timer/env.step_frac": 0.2564199309738217, "timer/env.step_avg": 0.09349789813931458, "timer/env.step_min": 0.02386188507080078, "timer/env.step_max": 3.4687283039093018, "timer/replay._sample_count": 21968.0, "timer/replay._sample_total": 11.34990930557251, "timer/replay._sample_frac": 0.011335528921302532, "timer/replay._sample_avg": 0.0005166564687533007, "timer/replay._sample_min": 0.0003960132598876953, "timer/replay._sample_max": 0.012002944946289062, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3317.0, "timer/agent.policy_total": 58.98137164115906, "timer/agent.policy_frac": 0.05890664198772, "timer/agent.policy_avg": 0.017781541043460674, "timer/agent.policy_min": 0.009608268737792969, "timer/agent.policy_max": 0.13580679893493652, "timer/dataset_train_count": 1373.0, "timer/dataset_train_total": 0.16249561309814453, "timer/dataset_train_frac": 0.00016228973045224625, "timer/dataset_train_avg": 0.00011835077428852478, "timer/dataset_train_min": 0.00010395050048828125, "timer/dataset_train_max": 0.0004792213439941406, "timer/agent.train_count": 1373.0, "timer/agent.train_total": 615.0336215496063, "timer/agent.train_frac": 0.6142543712861266, "timer/agent.train_avg": 0.4479487411140614, "timer/agent.train_min": 0.4333033561706543, "timer/agent.train_max": 1.5619258880615234, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48055434226989746, "timer/agent.report_frac": 0.0004799454778359716, "timer/agent.report_avg": 0.24027717113494873, "timer/agent.report_min": 0.2328808307647705, "timer/agent.report_max": 0.24767351150512695, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.524124225585637e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 21.93978414005163}
{"step": 688400, "time": 32426.737881183624, "episode/length": 497.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9979919678714859, "episode/intrinsic_return": 0.0}
{"step": 688408, "time": 32428.64527821541, "episode/length": 314.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 688520, "time": 32433.979922056198, "episode/length": 225.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 688544, "time": 32436.611209869385, "episode/length": 180.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 688672, "time": 32442.55950331688, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 688760, "time": 32446.9189388752, "episode/length": 301.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 689112, "time": 32460.99340415001, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 689152, "time": 32464.126185178757, "episode/length": 201.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 32515.103649377823, "eval_episode/length": 139.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 690040, "time": 32517.786348819733, "eval_episode/length": 162.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 690040, "time": 32519.75212430954, "eval_episode/length": 169.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 690040, "time": 32521.838337421417, "eval_episode/length": 37.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 690040, "time": 32523.7847571373, "eval_episode/length": 185.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 690040, "time": 32525.82160782814, "eval_episode/length": 194.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9692307692307692}
{"step": 690040, "time": 32527.718603134155, "eval_episode/length": 200.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 690040, "time": 32529.44577717781, "eval_episode/length": 202.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 690200, "time": 32534.85969400406, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 690200, "time": 32534.86869931221, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 690336, "time": 32542.97827386856, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 690456, "time": 32548.530182361603, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 690664, "time": 32557.06893801689, "episode/length": 267.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 690784, "time": 32562.85314655304, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 691304, "time": 32581.708126068115, "episode/length": 361.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9972375690607734, "episode/intrinsic_return": 0.0}
{"step": 691728, "time": 32597.811518907547, "episode/length": 190.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 691872, "time": 32604.2512011528, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 691880, "time": 32605.988706827164, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 691888, "time": 32608.174052476883, "episode/length": 435.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 692192, "time": 32620.015638828278, "episode/length": 39.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 692280, "time": 32624.43140053749, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 692512, "time": 32634.035699129105, "episode/length": 150.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 692624, "time": 32640.03350162506, "episode/length": 229.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 692704, "time": 32644.304865837097, "episode/length": 254.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 693016, "time": 32656.076891183853, "episode/length": 38.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 693064, "time": 32659.172935962677, "episode/length": 146.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 693592, "time": 32678.7056453228, "episode/length": 232.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 693672, "time": 32682.936463356018, "episode/length": 223.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 693816, "time": 32689.479727745056, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 693960, "time": 32695.967928171158, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 694312, "time": 32709.557059049606, "episode/length": 264.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9735849056603774, "episode/intrinsic_return": 0.0}
{"step": 694568, "time": 32719.734002113342, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 694816, "time": 32730.024354219437, "episode/length": 224.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 695128, "time": 32741.885334014893, "episode/length": 312.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.0}
{"step": 695200, "time": 32746.064824581146, "episode/length": 172.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 695512, "time": 32758.174525737762, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 695680, "time": 32765.629106521606, "episode/length": 250.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 695712, "time": 32768.38126659393, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 695752, "time": 32771.093448638916, "episode/length": 269.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 696456, "time": 32798.14026141167, "episode/length": 235.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 696488, "time": 32801.28713679314, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 696736, "time": 32812.051891326904, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 697016, "time": 32823.15303874016, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 697248, "time": 32832.925258398056, "episode/length": 216.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 697424, "time": 32840.4757707119, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 697736, "time": 32852.465640068054, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 698008, "time": 32863.37519073486, "episode/length": 290.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 698032, "time": 32866.02949118614, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 698280, "time": 32875.66470718384, "episode/length": 393.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 698480, "time": 32884.27651309967, "episode/length": 58.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 698536, "time": 32887.51067614555, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 698624, "time": 32892.370097875595, "episode/length": 200.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 698912, "time": 32904.11636328697, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 699216, "time": 32915.971833229065, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 699432, "time": 32924.59950757027, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 699656, "time": 32933.76065373421, "episode/length": 300.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9800664451827242, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 32965.30008649826, "eval_episode/length": 39.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.975}
{"step": 700024, "time": 32973.1713347435, "eval_episode/length": 164.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 700024, "time": 32975.60139656067, "eval_episode/length": 183.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 700024, "time": 32977.31513237953, "eval_episode/length": 185.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9623655913978495}
{"step": 700024, "time": 32980.827634096146, "eval_episode/length": 215.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 700024, "time": 32983.508121967316, "eval_episode/length": 227.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 700024, "time": 32986.647268772125, "eval_episode/length": 207.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 700024, "time": 32988.848096847534, "eval_episode/length": 251.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.996031746031746}
{"step": 700160, "time": 32993.66990160942, "episode/length": 234.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 700216, "time": 32996.888043642044, "episode/length": 216.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 700552, "time": 33009.90245985985, "episode/length": 240.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 700672, "time": 33015.73950004578, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 700848, "time": 33023.21333670616, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 700928, "time": 33027.52727437019, "episode/length": 298.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9866220735785953, "episode/intrinsic_return": 0.0}
{"step": 701240, "time": 33039.59997868538, "episode/length": 38.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 701312, "time": 33043.71988630295, "episode/length": 206.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 701640, "time": 33056.120129585266, "episode/length": 177.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 701736, "time": 33061.102806568146, "episode/length": 196.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 702104, "time": 33074.93027019501, "episode/length": 178.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 702224, "time": 33080.75227189064, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 702376, "time": 33087.12133932114, "episode/length": 227.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 702520, "time": 33093.663793325424, "episode/length": 36.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 702664, "time": 33100.05002999306, "episode/length": 430.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9976798143851509, "episode/intrinsic_return": 0.0}
{"step": 702728, "time": 33103.816423654556, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 703096, "time": 33117.61477947235, "episode/length": 231.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 703304, "time": 33126.32083153725, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 703752, "time": 33142.953085422516, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 703880, "time": 33148.92174625397, "episode/length": 279.0, "episode/score": 8.100000038743019, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 703968, "time": 33153.69543290138, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 704064, "time": 33158.55359530449, "episode/length": 174.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 704440, "time": 33172.54726886749, "episode/length": 213.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 704656, "time": 33183.381722450256, "episode/length": 266.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 704776, "time": 33188.7897670269, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 705000, "time": 33197.99658584595, "episode/length": 211.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 705536, "time": 33217.845338106155, "episode/length": 206.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 705712, "time": 33225.41966485977, "episode/length": 244.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 705832, "time": 33230.7231862545, "episode/length": 232.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 705944, "time": 33236.10069012642, "episode/length": 187.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9840425531914894, "episode/intrinsic_return": 0.0}
{"step": 706040, "time": 33241.0443508625, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 706048, "time": 33243.10166287422, "episode/length": 247.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 706512, "time": 33260.22825932503, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 706600, "time": 33264.5171148777, "episode/length": 242.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9670781893004116, "episode/intrinsic_return": 0.0}
{"step": 706976, "time": 33279.10914301872, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 707408, "time": 33295.13308906555, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 707520, "time": 33300.63525223732, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 707528, "time": 33302.32404732704, "episode/length": 197.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 707560, "time": 33305.06895804405, "episode/length": 252.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 707816, "time": 33315.17061972618, "episode/length": 36.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 707928, "time": 33320.5247528553, "episode/length": 49.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 708048, "time": 33326.56571435928, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 708232, "time": 33334.28653359413, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9627906976744186, "episode/intrinsic_return": 0.0}
{"step": 708688, "time": 33351.347230196, "episode/length": 329.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 708728, "time": 33353.93289613724, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9680365296803652, "episode/intrinsic_return": 0.0}
{"step": 708776, "time": 33357.15855097771, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 708880, "time": 33362.739278793335, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 709392, "time": 33381.82363009453, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 709656, "time": 33392.088029146194, "episode/length": 229.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 709760, "time": 33397.393314123154, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 709928, "time": 33404.86706376076, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 33430.77705979347, "eval_episode/length": 155.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 710008, "time": 33432.92133498192, "eval_episode/length": 168.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 710008, "time": 33434.70254611969, "eval_episode/length": 172.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 710008, "time": 33437.827176332474, "eval_episode/length": 204.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9658536585365853}
{"step": 710008, "time": 33439.59081339836, "eval_episode/length": 207.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 710008, "time": 33441.59252524376, "eval_episode/length": 218.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 710008, "time": 33443.599390506744, "eval_episode/length": 225.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 710008, "time": 33448.63040471077, "eval_episode/length": 291.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9965753424657534}
{"step": 710009, "time": 33449.66963505745, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.338727614458869, "train/action_min": 0.0, "train/action_std": 3.281813779297997, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045183836811167354, "train/actor_opt_grad_steps": 43595.0, "train/actor_opt_loss": -5.267816441133618, "train/adv_mag": 0.6080761946299497, "train/adv_max": 0.5844357228454422, "train/adv_mean": 0.003371751969499361, "train/adv_min": -0.4343809325467138, "train/adv_std": 0.06661762223195504, "train/cont_avg": 0.9944924747242647, "train/cont_loss_mean": 0.00017483671060059645, "train/cont_loss_std": 0.004932608416625579, "train/cont_neg_acc": 0.9933156980408563, "train/cont_neg_loss": 0.017557203045470048, "train/cont_pos_acc": 0.9999710856115117, "train/cont_pos_loss": 6.104389453201953e-05, "train/cont_pred": 0.9945054019198698, "train/cont_rate": 0.9944924747242647, "train/dyn_loss_mean": 12.758208976072424, "train/dyn_loss_std": 9.405702170203714, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8246897248660817, "train/extr_critic_critic_opt_grad_steps": 43595.0, "train/extr_critic_critic_opt_loss": 16207.883530560663, "train/extr_critic_mag": 6.2580419287962075, "train/extr_critic_max": 6.2580419287962075, "train/extr_critic_mean": 1.43934824887444, "train/extr_critic_min": -0.362091146847781, "train/extr_critic_std": 1.4218252003192902, "train/extr_return_normed_mag": 1.7298749290844972, "train/extr_return_normed_max": 1.7298749290844972, "train/extr_return_normed_mean": 0.34406914781121645, "train/extr_return_normed_min": -0.14054550178458586, "train/extr_return_normed_std": 0.32891525591121, "train/extr_return_rate": 0.6444915493621546, "train/extr_return_raw_mag": 7.605446647195255, "train/extr_return_raw_max": 7.605446647195255, "train/extr_return_raw_mean": 1.454325432286543, "train/extr_return_raw_min": -0.6966247008565594, "train/extr_return_raw_std": 1.4598440633100622, "train/extr_reward_mag": 1.0297510886893553, "train/extr_reward_max": 1.0297510886893553, "train/extr_reward_mean": 0.03401746555669781, "train/extr_reward_min": -0.5167267585501951, "train/extr_reward_std": 0.1752356694025152, "train/image_loss_mean": 5.725789348868763, "train/image_loss_std": 10.286614330375896, "train/model_loss_mean": 13.430688339121202, "train/model_loss_std": 14.193646711461684, "train/model_opt_grad_norm": 51.50634614159079, "train/model_opt_grad_steps": 43554.875, "train/model_opt_loss": 17847.782075769763, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1341.9117647058824, "train/policy_entropy_mag": 2.494105843936696, "train/policy_entropy_max": 2.494105843936696, "train/policy_entropy_mean": 0.5356543079456862, "train/policy_entropy_min": 0.07937507479287245, "train/policy_entropy_std": 0.6059288185308961, "train/policy_logprob_mag": 7.43838357224184, "train/policy_logprob_max": -0.009455661042867339, "train/policy_logprob_mean": -0.5367237517938894, "train/policy_logprob_min": -7.43838357224184, "train/policy_logprob_std": 1.0892919152975082, "train/policy_randomness_mag": 0.8803099091438686, "train/policy_randomness_max": 0.8803099091438686, "train/policy_randomness_mean": 0.18906246476313648, "train/policy_randomness_min": 0.028015918029910502, "train/policy_randomness_std": 0.21386628258315957, "train/post_ent_mag": 59.3209989491631, "train/post_ent_max": 59.3209989491631, "train/post_ent_mean": 42.909167261684644, "train/post_ent_min": 20.76586193898145, "train/post_ent_std": 7.367454662042506, "train/prior_ent_mag": 69.47169483409209, "train/prior_ent_max": 69.47169483409209, "train/prior_ent_mean": 55.721026448642505, "train/prior_ent_min": 38.66840763653026, "train/prior_ent_std": 4.623891199336333, "train/rep_loss_mean": 12.758208976072424, "train/rep_loss_std": 9.405702170203714, "train/reward_avg": 0.022774729860590443, "train/reward_loss_mean": 0.04979880512965953, "train/reward_loss_std": 0.23439442777239225, "train/reward_max_data": 1.0147058858590967, "train/reward_max_pred": 1.009806092171108, "train/reward_neg_acc": 0.9934941582819995, "train/reward_neg_loss": 0.027215922737548894, "train/reward_pos_acc": 0.9686127164784599, "train/reward_pos_loss": 0.8427780384526533, "train/reward_pred": 0.02214249921962619, "train/reward_rate": 0.0277099609375, "train_stats/sum_log_reward": 6.651401876289154, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.728971962616822, "train_stats/max_log_achievement_collect_sapling": 2.2523364485981308, "train_stats/max_log_achievement_collect_stone": 0.009345794392523364, "train_stats/max_log_achievement_collect_wood": 11.570093457943925, "train_stats/max_log_achievement_defeat_skeleton": 0.028037383177570093, "train_stats/max_log_achievement_defeat_zombie": 1.3177570093457944, "train_stats/max_log_achievement_eat_cow": 0.18691588785046728, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.018691588785046728, "train_stats/max_log_achievement_make_wood_sword": 1.7757009345794392, "train_stats/max_log_achievement_place_plant": 2.196261682242991, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 3.0186915887850465, "train_stats/max_log_achievement_wake_up": 1.588785046728972, "train_stats/mean_log_entropy": 0.5245042262233306, "eval_stats/sum_log_reward": 6.516666670640309, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.291666666666667, "eval_stats/max_log_achievement_collect_sapling": 2.4166666666666665, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 9.458333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.9166666666666666, "eval_stats/max_log_achievement_eat_cow": 0.20833333333333334, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_plant": 2.4166666666666665, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.9166666666666665, "eval_stats/max_log_achievement_wake_up": 1.2916666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.123880014754832e-05, "report/cont_loss_std": 0.0004460063937585801, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.005033986642956734, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.1620179066085257e-05, "report/cont_pred": 0.9961017370223999, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.800521850585938, "report/dyn_loss_std": 9.500402450561523, "report/image_loss_mean": 5.628029823303223, "report/image_loss_std": 10.451125144958496, "report/model_loss_mean": 13.35862922668457, "report/model_loss_std": 14.223844528198242, "report/post_ent_mag": 60.48748016357422, "report/post_ent_max": 60.48748016357422, "report/post_ent_mean": 42.70341110229492, "report/post_ent_min": 19.730981826782227, "report/post_ent_std": 8.016142845153809, "report/prior_ent_mag": 69.16291046142578, "report/prior_ent_max": 69.16291046142578, "report/prior_ent_mean": 56.080928802490234, "report/prior_ent_min": 39.737022399902344, "report/prior_ent_std": 4.931802749633789, "report/rep_loss_mean": 12.800521850585938, "report/rep_loss_std": 9.500402450561523, "report/reward_avg": 0.02255859225988388, "report/reward_loss_mean": 0.0502561554312706, "report/reward_loss_std": 0.34207701683044434, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0023186206817627, "report/reward_neg_acc": 0.9899799823760986, "report/reward_neg_loss": 0.019480479881167412, "report/reward_pos_acc": 0.9230769872665405, "report/reward_pos_loss": 1.2315685749053955, "report/reward_pred": 0.019407527521252632, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0027453957591205835, "eval/cont_loss_std": 0.08742953836917877, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.46729132533073425, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.403923973470228e-06, "eval/cont_pred": 0.9950549006462097, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.634048461914062, "eval/dyn_loss_std": 10.599918365478516, "eval/image_loss_mean": 10.562271118164062, "eval/image_loss_std": 18.702058792114258, "eval/model_loss_mean": 20.632221221923828, "eval/model_loss_std": 22.847665786743164, "eval/post_ent_mag": 60.7347526550293, "eval/post_ent_max": 60.7347526550293, "eval/post_ent_mean": 42.05469512939453, "eval/post_ent_min": 23.100223541259766, "eval/post_ent_std": 7.318085670471191, "eval/prior_ent_mag": 69.16291046142578, "eval/prior_ent_max": 69.16291046142578, "eval/prior_ent_mean": 56.928443908691406, "eval/prior_ent_min": 38.492549896240234, "eval/prior_ent_std": 4.394505977630615, "eval/rep_loss_mean": 16.634048461914062, "eval/rep_loss_std": 10.599918365478516, "eval/reward_avg": 0.03183593600988388, "eval/reward_loss_mean": 0.08677578717470169, "eval/reward_loss_std": 0.48300737142562866, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011675357818604, "eval/reward_neg_acc": 0.9898682236671448, "eval/reward_neg_loss": 0.042775724083185196, "eval/reward_pos_acc": 0.8918918371200562, "eval/reward_pos_loss": 1.2605071067810059, "eval/reward_pred": 0.02638339251279831, "eval/reward_rate": 0.0361328125, "replay/size": 709505.0, "replay/inserts": 21872.0, "replay/samples": 21872.0, "replay/insert_wait_avg": 1.4793462969564397e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.55557745882605e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5976.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2786273496696748e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1031.8710100650787, "timer/env.step_count": 2734.0, "timer/env.step_total": 251.2352271080017, "timer/env.step_frac": 0.24347541956058696, "timer/env.step_avg": 0.09189291408485797, "timer/env.step_min": 0.024331092834472656, "timer/env.step_max": 3.313138008117676, "timer/replay._sample_count": 21872.0, "timer/replay._sample_total": 11.34005331993103, "timer/replay._sample_frac": 0.01098979737711192, "timer/replay._sample_avg": 0.0005184735424255226, "timer/replay._sample_min": 0.00042247772216796875, "timer/replay._sample_max": 0.008992910385131836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3481.0, "timer/agent.policy_total": 61.33608150482178, "timer/agent.policy_frac": 0.05944161712708005, "timer/agent.policy_avg": 0.017620247487739667, "timer/agent.policy_min": 0.009806394577026367, "timer/agent.policy_max": 0.12074804306030273, "timer/dataset_train_count": 1367.0, "timer/dataset_train_total": 0.16588997840881348, "timer/dataset_train_frac": 0.00016076619731602985, "timer/dataset_train_avg": 0.0001213533126618972, "timer/dataset_train_min": 0.00010609626770019531, "timer/dataset_train_max": 0.0003256797790527344, "timer/agent.train_count": 1367.0, "timer/agent.train_total": 612.8739490509033, "timer/agent.train_frac": 0.5939443429196156, "timer/agent.train_avg": 0.4483350029633528, "timer/agent.train_min": 0.4367055892944336, "timer/agent.train_max": 1.7829184532165527, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48089122772216797, "timer/agent.report_frac": 0.00046603812204379965, "timer/agent.report_avg": 0.24044561386108398, "timer/agent.report_min": 0.2318270206451416, "timer/agent.report_max": 0.24906420707702637, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 3.488924981240183e-08, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05, "fps": 21.19615752088885}
{"step": 710144, "time": 33454.33439087868, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 710408, "time": 33464.60957980156, "episode/length": 209.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 710936, "time": 33484.16303873062, "episode/length": 256.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 710992, "time": 33487.893795251846, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 711192, "time": 33496.10072541237, "episode/length": 224.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 711352, "time": 33503.126225948334, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 711400, "time": 33506.247901678085, "episode/length": 204.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 711600, "time": 33514.89726924896, "episode/length": 148.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 711640, "time": 33517.5375392437, "episode/length": 87.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 711840, "time": 33526.120950460434, "episode/length": 211.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 711968, "time": 33532.02781414986, "episode/length": 40.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 712288, "time": 33546.29564213753, "episode/length": 438.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9954441913439636, "episode/intrinsic_return": 0.0}
{"step": 712664, "time": 33560.519709825516, "episode/length": 183.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 712768, "time": 33567.33317375183, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 712920, "time": 33574.00190114975, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 713048, "time": 33579.868646383286, "episode/length": 205.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 713088, "time": 33583.59471702576, "episode/length": 155.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 713400, "time": 33596.11026978493, "episode/length": 300.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 714144, "time": 33623.23639464378, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 714160, "time": 33625.270171403885, "episode/length": 273.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 714312, "time": 33632.05144929886, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 714504, "time": 33640.11855053902, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 714552, "time": 33643.879239320755, "episode/length": 222.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 714664, "time": 33649.83024907112, "episode/length": 157.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 715056, "time": 33665.07597517967, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 715464, "time": 33680.31227016449, "episode/length": 396.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9974811083123426, "episode/intrinsic_return": 0.0}
{"step": 715576, "time": 33685.69627737999, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 715728, "time": 33692.72430849075, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 715792, "time": 33696.52377009392, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 715824, "time": 33699.1933221817, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 716152, "time": 33711.52389001846, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 716232, "time": 33715.79414653778, "episode/length": 239.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 716776, "time": 33735.891882419586, "episode/length": 163.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.0}
{"step": 717128, "time": 33750.12994623184, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 717280, "time": 33757.079320669174, "episode/length": 140.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 717296, "time": 33759.159600019455, "episode/length": 279.0, "episode/score": 7.10000005364418, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 717440, "time": 33765.55569601059, "episode/length": 232.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 717664, "time": 33774.66703438759, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 717896, "time": 33784.087772130966, "episode/length": 258.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 718184, "time": 33795.43796443939, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 718504, "time": 33807.81256175041, "episode/length": 283.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 718640, "time": 33814.31499004364, "episode/length": 188.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 718864, "time": 33823.544016599655, "episode/length": 177.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 719032, "time": 33830.48104548454, "episode/length": 218.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 719064, "time": 33833.13694834709, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 719160, "time": 33838.17175030708, "episode/length": 232.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 719264, "time": 33843.50000882149, "episode/length": 170.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 719496, "time": 33852.64953327179, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 719912, "time": 33868.245136260986, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 33897.225957393646, "eval_episode/length": 167.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 720096, "time": 33899.76946544647, "eval_episode/length": 175.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 720096, "time": 33903.55222582817, "eval_episode/length": 192.0, "eval_episode/score": 7.1000000312924385, "eval_episode/reward_rate": 0.9689119170984456}
{"step": 720096, "time": 33905.168867111206, "eval_episode/length": 195.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 720096, "time": 33907.70220899582, "eval_episode/length": 213.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 720096, "time": 33909.51252579689, "eval_episode/length": 219.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 720096, "time": 33911.225942611694, "eval_episode/length": 222.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 720096, "time": 33913.140052080154, "eval_episode/length": 35.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 720328, "time": 33920.75988149643, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 720424, "time": 33925.59782719612, "episode/length": 222.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 720440, "time": 33927.83197212219, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 720456, "time": 33930.00134396553, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 720520, "time": 33933.69538640976, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 721136, "time": 33957.74375247955, "episode/length": 258.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 721512, "time": 33971.8340485096, "episode/length": 251.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 721992, "time": 33989.79164671898, "episode/length": 259.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 722064, "time": 33994.57120394707, "episode/length": 200.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 722184, "time": 34000.43221449852, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 722184, "time": 34000.440860271454, "episode/length": 219.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 722848, "time": 34026.449437618256, "episode/length": 290.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.993127147766323, "episode/intrinsic_return": 0.0}
{"step": 723440, "time": 34047.806609630585, "episode/length": 374.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 723632, "time": 34056.088883161545, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 723656, "time": 34058.26331973076, "episode/length": 314.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 723760, "time": 34063.438460826874, "episode/length": 220.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 723856, "time": 34068.36925196648, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 724168, "time": 34080.36150574684, "episode/length": 38.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 724424, "time": 34090.45345067978, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 724520, "time": 34095.26660776138, "episode/length": 375.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 724720, "time": 34103.77830982208, "episode/length": 36.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 725040, "time": 34116.25586462021, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 725128, "time": 34120.55796337128, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 725184, "time": 34124.266411304474, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 725464, "time": 34135.134967803955, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 725760, "time": 34147.03408765793, "episode/length": 446.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 726056, "time": 34158.47532939911, "episode/length": 235.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 726408, "time": 34171.98068833351, "episode/length": 210.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 726416, "time": 34174.110328912735, "episode/length": 160.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 726816, "time": 34189.14547395706, "episode/length": 286.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 727240, "time": 34204.97935342789, "episode/length": 256.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9727626459143969, "episode/intrinsic_return": 0.0}
{"step": 727312, "time": 34209.12310695648, "episode/length": 283.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 727512, "time": 34217.44798731804, "episode/length": 33.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 727824, "time": 34230.02391695976, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 727848, "time": 34232.314131736755, "episode/length": 297.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9865771812080537, "episode/intrinsic_return": 0.0}
{"step": 727880, "time": 34234.98619413376, "episode/length": 264.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9773584905660377, "episode/intrinsic_return": 0.0}
{"step": 728008, "time": 34240.855732917786, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 728032, "time": 34243.4905128479, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 728056, "time": 34245.66769194603, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 728624, "time": 34266.84808635712, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 728912, "time": 34278.09302806854, "episode/length": 174.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9828571428571429, "episode/intrinsic_return": 0.0}
{"step": 729152, "time": 34289.60937833786, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 729312, "time": 34296.77847981453, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 729608, "time": 34308.00712823868, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 729736, "time": 34314.07083058357, "episode/length": 212.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 729792, "time": 34318.48967385292, "episode/length": 222.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 729848, "time": 34321.65403223038, "episode/length": 223.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 729992, "time": 34328.18847370148, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 34355.18170905113, "eval_episode/length": 188.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 730080, "time": 34357.28883433342, "eval_episode/length": 199.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.995}
{"step": 730080, "time": 34359.592923402786, "eval_episode/length": 214.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 730080, "time": 34361.26620745659, "eval_episode/length": 216.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9815668202764977}
{"step": 730080, "time": 34361.27348446846, "eval_episode/length": 216.0, "eval_episode/score": 8.100000016391277, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 730080, "time": 34366.86719107628, "eval_episode/length": 267.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.996268656716418}
{"step": 730080, "time": 34370.15346312523, "eval_episode/length": 305.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9967320261437909}
{"step": 730080, "time": 34371.9310798645, "eval_episode/length": 43.0, "eval_episode/score": 4.100000023841858, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 730704, "time": 34393.4573674202, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 730888, "time": 34401.10276556015, "episode/length": 143.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 731160, "time": 34412.00663995743, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 731240, "time": 34416.19403195381, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 731376, "time": 34422.653869867325, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 731640, "time": 34432.96495652199, "episode/length": 49.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.94, "episode/intrinsic_return": 0.0}
{"step": 732065, "time": 34449.685899972916, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.47293356190557, "train/action_min": 0.0, "train/action_std": 3.4641935151556265, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04534634040749591, "train/actor_opt_grad_steps": 44965.0, "train/actor_opt_loss": 0.0680472464233205, "train/adv_mag": 0.5949981817300769, "train/adv_max": 0.5706828519485999, "train/adv_mean": 0.003963707198346273, "train/adv_min": -0.45302965330040973, "train/adv_std": 0.06635077103324559, "train/cont_avg": 0.9949261209239131, "train/cont_loss_mean": 0.00011946007590017541, "train/cont_loss_std": 0.003607054897985484, "train/cont_neg_acc": 0.9975845416386923, "train/cont_neg_loss": 0.011050399382206113, "train/cont_pos_acc": 0.9999786762223728, "train/cont_pos_loss": 5.8243332980378064e-05, "train/cont_pred": 0.9949160740859266, "train/cont_rate": 0.9949261209239131, "train/dyn_loss_mean": 12.539984544118246, "train/dyn_loss_std": 9.393009310183318, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8232740876467332, "train/extr_critic_critic_opt_grad_steps": 44965.0, "train/extr_critic_critic_opt_loss": 16149.341428894928, "train/extr_critic_mag": 6.286255490952644, "train/extr_critic_max": 6.286255490952644, "train/extr_critic_mean": 1.4481754030870355, "train/extr_critic_min": -0.3287821844004203, "train/extr_critic_std": 1.4039018646530483, "train/extr_return_normed_mag": 1.6971222455950752, "train/extr_return_normed_max": 1.6971222455950752, "train/extr_return_normed_mean": 0.3447146273177603, "train/extr_return_normed_min": -0.12461276317312234, "train/extr_return_normed_std": 0.3241648639457813, "train/extr_return_rate": 0.6507911915364473, "train/extr_return_raw_mag": 7.467551874077839, "train/extr_return_raw_max": 7.467551874077839, "train/extr_return_raw_mean": 1.465774719265924, "train/extr_return_raw_min": -0.6170388662080833, "train/extr_return_raw_std": 1.438672766737316, "train/extr_reward_mag": 1.0326636286749356, "train/extr_reward_max": 1.0326636286749356, "train/extr_reward_mean": 0.034016981606196234, "train/extr_reward_min": -0.44790818639423535, "train/extr_reward_std": 0.17521104886048083, "train/image_loss_mean": 5.637838743735051, "train/image_loss_std": 10.721819459528163, "train/model_loss_mean": 13.212840087171914, "train/model_loss_std": 14.590771384861158, "train/model_opt_grad_norm": 49.056176157965176, "train/model_opt_grad_steps": 44923.65217391304, "train/model_opt_loss": 17380.168209352356, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1313.4057971014493, "train/policy_entropy_mag": 2.5213325973870098, "train/policy_entropy_max": 2.5213325973870098, "train/policy_entropy_mean": 0.5794992142397425, "train/policy_entropy_min": 0.07937508929466856, "train/policy_entropy_std": 0.649878329988839, "train/policy_logprob_mag": 7.438383620718251, "train/policy_logprob_max": -0.009455668706230927, "train/policy_logprob_mean": -0.5791527041490527, "train/policy_logprob_min": -7.438383620718251, "train/policy_logprob_std": 1.1167549084925996, "train/policy_randomness_mag": 0.8899197608664415, "train/policy_randomness_max": 0.8899197608664415, "train/policy_randomness_mean": 0.20453779302213504, "train/policy_randomness_min": 0.02801592321391555, "train/policy_randomness_std": 0.22937853170045908, "train/post_ent_mag": 59.598093530406125, "train/post_ent_max": 59.598093530406125, "train/post_ent_mean": 43.03783366991126, "train/post_ent_min": 20.89230393672335, "train/post_ent_std": 7.410756684731746, "train/prior_ent_mag": 69.57620476985323, "train/prior_ent_max": 69.57620476985323, "train/prior_ent_mean": 55.694387435913086, "train/prior_ent_min": 38.908587289893106, "train/prior_ent_std": 4.675841792770054, "train/rep_loss_mean": 12.539984544118246, "train/rep_loss_std": 9.393009310183318, "train/reward_avg": 0.023898182527931487, "train/reward_loss_mean": 0.050891265408068466, "train/reward_loss_std": 0.2404075290845788, "train/reward_max_data": 1.01449275707853, "train/reward_max_pred": 1.0088096226471057, "train/reward_neg_acc": 0.9932910860448644, "train/reward_neg_loss": 0.02758257865797782, "train/reward_pos_acc": 0.9689504746077717, "train/reward_pos_loss": 0.8379828705303911, "train/reward_pred": 0.023309666137008564, "train/reward_rate": 0.028645833333333332, "train_stats/sum_log_reward": 6.711650473400227, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.349514563106796, "train_stats/max_log_achievement_collect_sapling": 2.058252427184466, "train_stats/max_log_achievement_collect_stone": 0.019417475728155338, "train_stats/max_log_achievement_collect_wood": 10.79611650485437, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 1.1067961165048543, "train_stats/max_log_achievement_eat_cow": 0.14563106796116504, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05825242718446602, "train_stats/max_log_achievement_make_wood_sword": 1.5631067961165048, "train_stats/max_log_achievement_place_plant": 2.0194174757281553, "train_stats/max_log_achievement_place_stone": 0.009708737864077669, "train_stats/max_log_achievement_place_table": 2.9611650485436893, "train_stats/max_log_achievement_wake_up": 1.5825242718446602, "train_stats/mean_log_entropy": 0.5730567198355221, "eval_stats/sum_log_reward": 6.850000116974115, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 8.4375, "eval_stats/max_log_achievement_collect_sapling": 2.5625, "eval_stats/max_log_achievement_collect_stone": 0.3125, "eval_stats/max_log_achievement_collect_wood": 10.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.375, "eval_stats/max_log_achievement_eat_cow": 0.4375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.375, "eval_stats/max_log_achievement_place_plant": 2.5625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.75, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.3572169993713032e-06, "report/cont_loss_std": 4.3039090087404475e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.3058177248458378e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.2556421299668727e-06, "report/cont_pred": 0.9951151013374329, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.802573204040527, "report/dyn_loss_std": 9.092864990234375, "report/image_loss_mean": 5.63092041015625, "report/image_loss_std": 8.315949440002441, "report/model_loss_mean": 12.775052070617676, "report/model_loss_std": 12.400774002075195, "report/post_ent_mag": 60.01750183105469, "report/post_ent_max": 60.01750183105469, "report/post_ent_mean": 43.68463134765625, "report/post_ent_min": 21.474214553833008, "report/post_ent_std": 7.10042142868042, "report/prior_ent_mag": 69.51542663574219, "report/prior_ent_max": 69.51542663574219, "report/prior_ent_mean": 55.636207580566406, "report/prior_ent_min": 40.07883071899414, "report/prior_ent_std": 4.92838191986084, "report/rep_loss_mean": 11.802573204040527, "report/rep_loss_std": 9.092864990234375, "report/reward_avg": 0.02734375, "report/reward_loss_mean": 0.06258563697338104, "report/reward_loss_std": 0.2472531646490097, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 0.9999210834503174, "report/reward_neg_acc": 0.9868819117546082, "report/reward_neg_loss": 0.03510099649429321, "report/reward_pos_acc": 0.9696969389915466, "report/reward_pos_loss": 0.887957751750946, "report/reward_pred": 0.025660138577222824, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.644395292212721e-06, "eval/cont_loss_std": 5.232810144661926e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006446763291023672, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.989980766367808e-07, "eval/cont_pred": 0.9951199293136597, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.81905746459961, "eval/dyn_loss_std": 10.64083480834961, "eval/image_loss_mean": 9.986250877380371, "eval/image_loss_std": 14.98383903503418, "eval/model_loss_mean": 20.750911712646484, "eval/model_loss_std": 18.978796005249023, "eval/post_ent_mag": 60.19961166381836, "eval/post_ent_max": 60.19961166381836, "eval/post_ent_mean": 40.95189666748047, "eval/post_ent_min": 22.31139373779297, "eval/post_ent_std": 7.673419952392578, "eval/prior_ent_mag": 69.51542663574219, "eval/prior_ent_max": 69.51542663574219, "eval/prior_ent_mean": 56.509857177734375, "eval/prior_ent_min": 42.87721633911133, "eval/prior_ent_std": 4.6113996505737305, "eval/rep_loss_mean": 17.81905746459961, "eval/rep_loss_std": 10.64083480834961, "eval/reward_avg": 0.03750000149011612, "eval/reward_loss_mean": 0.07322518527507782, "eval/reward_loss_std": 0.35131943225860596, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0028154850006104, "eval/reward_neg_acc": 0.9847251176834106, "eval/reward_neg_loss": 0.030011147260665894, "eval/reward_pos_acc": 0.9285714626312256, "eval/reward_pos_loss": 1.0836105346679688, "eval/reward_pred": 0.03562184423208237, "eval/reward_rate": 0.041015625, "replay/size": 731561.0, "replay/inserts": 22056.0, "replay/samples": 22048.0, "replay/insert_wait_avg": 1.418318141401787e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.520371509048174e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4352.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2251274550662321e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0080058574677, "timer/env.step_count": 2757.0, "timer/env.step_total": 246.4204807281494, "timer/env.step_frac": 0.24641850793669748, "timer/env.step_avg": 0.08937993497575242, "timer/env.step_min": 0.0246121883392334, "timer/env.step_max": 3.2865734100341797, "timer/replay._sample_count": 22048.0, "timer/replay._sample_total": 11.466572523117065, "timer/replay._sample_frac": 0.011466480724106732, "timer/replay._sample_avg": 0.0005200731369338292, "timer/replay._sample_min": 0.00039958953857421875, "timer/replay._sample_max": 0.009559869766235352, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3301.0, "timer/agent.policy_total": 57.58383131027222, "timer/agent.policy_frac": 0.05758337030601704, "timer/agent.policy_avg": 0.017444359681997035, "timer/agent.policy_min": 0.00953817367553711, "timer/agent.policy_max": 0.12104582786560059, "timer/dataset_train_count": 1378.0, "timer/dataset_train_total": 0.16743040084838867, "timer/dataset_train_frac": 0.00016742906043519488, "timer/dataset_train_avg": 0.00012150246795964345, "timer/dataset_train_min": 0.00010418891906738281, "timer/dataset_train_max": 0.0006325244903564453, "timer/agent.train_count": 1378.0, "timer/agent.train_total": 624.2644965648651, "timer/agent.train_frac": 0.6242594988322946, "timer/agent.train_avg": 0.4530221310340095, "timer/agent.train_min": 0.4364166259765625, "timer/agent.train_max": 2.2859373092651367, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47667813301086426, "timer/agent.report_frac": 0.0004766743168242253, "timer/agent.report_avg": 0.23833906650543213, "timer/agent.report_min": 0.23032522201538086, "timer/agent.report_max": 0.2463529109954834, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.528566721500888e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 22.055515034692384}
{"step": 732224, "time": 34455.33312225342, "episode/length": 278.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 732296, "time": 34459.22849369049, "episode/length": 312.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9968051118210862, "episode/intrinsic_return": 0.0}
{"step": 732440, "time": 34465.83200478554, "episode/length": 159.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 732528, "time": 34471.294439315796, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 732912, "time": 34485.81190228462, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 733296, "time": 34500.61718797684, "episode/length": 517.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 733472, "time": 34508.23480510712, "episode/length": 322.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9845201238390093, "episode/intrinsic_return": 0.0}
{"step": 733616, "time": 34514.621547460556, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 733864, "time": 34524.36074090004, "episode/length": 177.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 734152, "time": 34535.709476947784, "episode/length": 313.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9904458598726115, "episode/intrinsic_return": 0.0}
{"step": 734176, "time": 34538.39746046066, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9617021276595744, "episode/intrinsic_return": 0.0}
{"step": 734176, "time": 34538.40673661232, "episode/length": 38.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 734224, "time": 34543.32438802719, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9669811320754716, "episode/intrinsic_return": 0.0}
{"step": 734296, "time": 34547.1712603569, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 734536, "time": 34556.88127660751, "episode/length": 44.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 735048, "time": 34575.86202597618, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 735536, "time": 34594.139340400696, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 735664, "time": 34599.97538518906, "episode/length": 255.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 735744, "time": 34604.22154855728, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 735784, "time": 34606.97367954254, "episode/length": 200.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 735832, "time": 34610.23412871361, "episode/length": 294.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796610169491525, "episode/intrinsic_return": 0.0}
{"step": 736120, "time": 34621.72264409065, "episode/length": 41.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 736280, "time": 34628.598199129105, "episode/length": 153.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 736584, "time": 34640.37013792992, "episode/length": 294.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 736608, "time": 34642.96785211563, "episode/length": 306.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771986970684039, "episode/intrinsic_return": 0.0}
{"step": 737040, "time": 34659.522800683975, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 737120, "time": 34663.79804730415, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 737120, "time": 34663.80721402168, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 737656, "time": 34686.77579498291, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 737752, "time": 34691.6254799366, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 737936, "time": 34699.63924598694, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 738376, "time": 34715.966946840286, "episode/length": 223.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 738440, "time": 34719.63056540489, "episode/length": 174.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 738456, "time": 34721.75880885124, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 738624, "time": 34729.230637311935, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 738808, "time": 34737.00434303284, "episode/length": 143.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 738960, "time": 34744.099419116974, "episode/length": 401.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 739392, "time": 34760.2628133297, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 739832, "time": 34776.64190673828, "episode/length": 181.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 739880, "time": 34779.853659152985, "episode/length": 179.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 739912, "time": 34782.54798960686, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 34804.64118170738, "eval_episode/length": 40.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.975609756097561}
{"step": 740064, "time": 34811.84058594704, "eval_episode/length": 162.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 740064, "time": 34814.36574912071, "eval_episode/length": 181.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 740064, "time": 34816.14642071724, "eval_episode/length": 184.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 740064, "time": 34818.43087172508, "eval_episode/length": 197.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 740064, "time": 34819.99154639244, "eval_episode/length": 198.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 740064, "time": 34825.8051199913, "eval_episode/length": 247.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9959677419354839}
{"step": 740064, "time": 34827.3619992733, "eval_episode/length": 289.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9758620689655172}
{"step": 740184, "time": 34831.348308086395, "episode/length": 303.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769736842105263, "episode/intrinsic_return": 0.0}
{"step": 740240, "time": 34835.064877033234, "episode/length": 201.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 740256, "time": 34837.31377387047, "episode/length": 42.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 740512, "time": 34847.52124333382, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 740648, "time": 34853.32234096527, "episode/length": 156.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 741208, "time": 34874.12850403786, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 741312, "time": 34879.498455524445, "episode/length": 312.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9744408945686901, "episode/intrinsic_return": 0.0}
{"step": 741344, "time": 34882.143513441086, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 741576, "time": 34891.486154317856, "episode/length": 173.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 741696, "time": 34897.28505015373, "episode/length": 147.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 742032, "time": 34910.066244363785, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 742080, "time": 34913.346774578094, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 742264, "time": 34921.194873809814, "episode/length": 250.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 742512, "time": 34931.35580301285, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 742936, "time": 34946.802080869675, "episode/length": 83.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 743216, "time": 34958.10800290108, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 743216, "time": 34958.11657857895, "episode/length": 233.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 743496, "time": 34970.65715456009, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 743528, "time": 34973.31045174599, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 743592, "time": 34977.031459093094, "episode/length": 194.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 744120, "time": 34996.399909973145, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 744976, "time": 35027.051565647125, "episode/length": 254.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 745000, "time": 35029.21747851372, "episode/length": 460.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9891540130151844, "episode/intrinsic_return": 0.0}
{"step": 745056, "time": 35032.864493608475, "episode/length": 190.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 745064, "time": 35034.48123073578, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 745080, "time": 35036.59342908859, "episode/length": 232.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 745096, "time": 35038.894347667694, "episode/length": 234.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9659574468085106, "episode/intrinsic_return": 0.0}
{"step": 745200, "time": 35044.21440625191, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 746272, "time": 35083.41276049614, "episode/length": 268.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9739776951672863, "episode/intrinsic_return": 0.0}
{"step": 746432, "time": 35090.34934306145, "episode/length": 170.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 746512, "time": 35094.6339764595, "episode/length": 181.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 746656, "time": 35101.18339705467, "episode/length": 196.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 746832, "time": 35108.73279595375, "episode/length": 228.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 747120, "time": 35119.964852809906, "episode/length": 239.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 747152, "time": 35122.737325668335, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 747344, "time": 35130.84040427208, "episode/length": 280.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786476868327402, "episode/intrinsic_return": 0.0}
{"step": 747512, "time": 35137.7839987278, "episode/length": 316.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9842271293375394, "episode/intrinsic_return": 0.0}
{"step": 747768, "time": 35147.973279476166, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 747872, "time": 35153.31594085693, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 748240, "time": 35167.41250562668, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 748392, "time": 35173.82376217842, "episode/length": 216.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 748544, "time": 35180.81387925148, "episode/length": 173.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 748600, "time": 35184.09673953056, "episode/length": 156.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9872611464968153, "episode/intrinsic_return": 0.0}
{"step": 748776, "time": 35191.66568994522, "episode/length": 206.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 748840, "time": 35195.460626363754, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 749624, "time": 35223.47922992706, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 749952, "time": 35236.257986068726, "episode/length": 40.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 749976, "time": 35238.38897871971, "episode/length": 262.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9885931558935361, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 35257.79333925247, "eval_episode/length": 41.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 750048, "time": 35265.553188085556, "eval_episode/length": 160.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.968944099378882}
{"step": 750048, "time": 35267.431347608566, "eval_episode/length": 165.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 750048, "time": 35270.08497428894, "eval_episode/length": 184.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 750048, "time": 35271.89253401756, "eval_episode/length": 189.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 750048, "time": 35271.900153160095, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.968421052631579}
{"step": 750048, "time": 35276.390721559525, "eval_episode/length": 211.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9716981132075472}
{"step": 750048, "time": 35279.644768476486, "eval_episode/length": 244.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 750120, "time": 35281.869616270065, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 750248, "time": 35287.88095998764, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 750304, "time": 35291.40418744087, "episode/length": 238.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 750432, "time": 35297.35725045204, "episode/length": 235.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 750560, "time": 35303.269367694855, "episode/length": 222.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 750896, "time": 35316.22403049469, "episode/length": 331.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 751328, "time": 35332.27807354927, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 751568, "time": 35342.027462005615, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 751632, "time": 35345.809868335724, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 751864, "time": 35355.17816948891, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 751912, "time": 35358.820721149445, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 752272, "time": 35373.35317850113, "episode/length": 268.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 752408, "time": 35379.243621110916, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 753352, "time": 35412.87231183052, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 753368, "time": 35415.061521053314, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 753416, "time": 35418.35739636421, "episode/length": 187.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 753656, "time": 35428.22631764412, "episode/length": 260.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 753720, "time": 35433.4728782177, "episode/length": 163.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 753816, "time": 35438.56657862663, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 753968, "time": 35445.70613217354, "episode/length": 441.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 754025, "time": 35450.13042831421, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.581589408542799, "train/action_min": 0.0, "train/action_std": 3.518692374229431, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044687614573732666, "train/actor_opt_grad_steps": 46345.0, "train/actor_opt_loss": 1.8652041403279789, "train/adv_mag": 0.5638644876687423, "train/adv_max": 0.5391755849123001, "train/adv_mean": 0.0049798553504776955, "train/adv_min": -0.4156647102124449, "train/adv_std": 0.06522184132557848, "train/cont_avg": 0.9946713654891305, "train/cont_loss_mean": 0.00017900855921461567, "train/cont_loss_std": 0.005505661054855551, "train/cont_neg_acc": 0.992957788101141, "train/cont_neg_loss": 0.018694729274448433, "train/cont_pos_acc": 0.999971500341443, "train/cont_pos_loss": 8.469706532308182e-05, "train/cont_pred": 0.9946727998878645, "train/cont_rate": 0.9946713654891305, "train/dyn_loss_mean": 12.614974125571873, "train/dyn_loss_std": 9.389408007912014, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8225818475087484, "train/extr_critic_critic_opt_grad_steps": 46345.0, "train/extr_critic_critic_opt_loss": 16294.496291893116, "train/extr_critic_mag": 6.518068925194118, "train/extr_critic_max": 6.518068925194118, "train/extr_critic_mean": 1.5861613275348276, "train/extr_critic_min": -0.3276806732882624, "train/extr_critic_std": 1.4872036697208018, "train/extr_return_normed_mag": 1.688668308050736, "train/extr_return_normed_max": 1.688668308050736, "train/extr_return_normed_mean": 0.35837150149155356, "train/extr_return_normed_min": -0.13038180833277496, "train/extr_return_normed_std": 0.33013487434473593, "train/extr_return_rate": 0.6800607058449067, "train/extr_return_raw_mag": 7.7592857575071035, "train/extr_return_raw_max": 7.7592857575071035, "train/extr_return_raw_mean": 1.609227795963702, "train/extr_return_raw_min": -0.651499359935954, "train/extr_return_raw_std": 1.5267047320587048, "train/extr_reward_mag": 1.0298079615053923, "train/extr_reward_max": 1.0298079615053923, "train/extr_reward_mean": 0.03584536856067353, "train/extr_reward_min": -0.5034756677738135, "train/extr_reward_std": 0.17913369413303293, "train/image_loss_mean": 5.527038339255513, "train/image_loss_std": 10.310755328855652, "train/model_loss_mean": 13.146542811739272, "train/model_loss_std": 14.219175456226736, "train/model_opt_grad_norm": 50.309963253961094, "train/model_opt_grad_steps": 46302.39855072464, "train/model_opt_loss": 16665.820517719654, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1277.1739130434783, "train/policy_entropy_mag": 2.5303617059320644, "train/policy_entropy_max": 2.5303617059320644, "train/policy_entropy_mean": 0.5454684498085491, "train/policy_entropy_min": 0.07937505906042845, "train/policy_entropy_std": 0.6205100626617238, "train/policy_logprob_mag": 7.438383596530859, "train/policy_logprob_max": -0.00945566442079734, "train/policy_logprob_mean": -0.5457982140174811, "train/policy_logprob_min": -7.438383596530859, "train/policy_logprob_std": 1.1057462450386821, "train/policy_randomness_mag": 0.8931066385213879, "train/policy_randomness_max": 0.8931066385213879, "train/policy_randomness_mean": 0.19252642600432687, "train/policy_randomness_min": 0.028015912604936653, "train/policy_randomness_std": 0.21901282365771307, "train/post_ent_mag": 59.44111428744551, "train/post_ent_max": 59.44111428744551, "train/post_ent_mean": 42.99025295091712, "train/post_ent_min": 20.682438421940457, "train/post_ent_std": 7.378857149594072, "train/prior_ent_mag": 69.69122126482534, "train/prior_ent_max": 69.69122126482534, "train/prior_ent_mean": 55.6938591003418, "train/prior_ent_min": 39.07443680970565, "train/prior_ent_std": 4.6697816468667295, "train/rep_loss_mean": 12.614974125571873, "train/rep_loss_std": 9.389408007912014, "train/reward_avg": 0.02424917901204764, "train/reward_loss_mean": 0.05034101728781842, "train/reward_loss_std": 0.2328774825386379, "train/reward_max_data": 1.01449275707853, "train/reward_max_pred": 1.0071376613948657, "train/reward_neg_acc": 0.9936363057813783, "train/reward_neg_loss": 0.027097944851856733, "train/reward_pos_acc": 0.9715786701527195, "train/reward_pos_loss": 0.825654571471007, "train/reward_pred": 0.02373433748152161, "train/reward_rate": 0.029049196105072464, "train_stats/sum_log_reward": 6.457798151521508, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.614678899082569, "train_stats/max_log_achievement_collect_sapling": 2.0, "train_stats/max_log_achievement_collect_stone": 0.027522935779816515, "train_stats/max_log_achievement_collect_wood": 10.357798165137615, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 1.3302752293577982, "train_stats/max_log_achievement_eat_cow": 0.1834862385321101, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.03669724770642202, "train_stats/max_log_achievement_make_wood_sword": 1.4220183486238531, "train_stats/max_log_achievement_place_plant": 1.9541284403669725, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 3.165137614678899, "train_stats/max_log_achievement_wake_up": 1.5045871559633028, "train_stats/mean_log_entropy": 0.5223644077777863, "eval_stats/sum_log_reward": 6.537500023841858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.5, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 7.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.125, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00035476317862048745, "report/cont_loss_std": 0.010867449454963207, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.069667749106884, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.4660192391602322e-05, "report/cont_pred": 0.9953900575637817, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.746150016784668, "report/dyn_loss_std": 9.5750093460083, "report/image_loss_mean": 5.170322895050049, "report/image_loss_std": 10.500178337097168, "report/model_loss_mean": 13.454156875610352, "report/model_loss_std": 14.480786323547363, "report/post_ent_mag": 58.39494705200195, "report/post_ent_max": 58.39494705200195, "report/post_ent_mean": 41.94487762451172, "report/post_ent_min": 21.03612518310547, "report/post_ent_std": 6.948817729949951, "report/prior_ent_mag": 70.19566345214844, "report/prior_ent_max": 70.19566345214844, "report/prior_ent_mean": 55.78477478027344, "report/prior_ent_min": 43.45903015136719, "report/prior_ent_std": 4.485136032104492, "report/rep_loss_mean": 13.746150016784668, "report/rep_loss_std": 9.5750093460083, "report/reward_avg": 0.02128906175494194, "report/reward_loss_mean": 0.035788506269454956, "report/reward_loss_std": 0.1513933539390564, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012171268463135, "report/reward_neg_acc": 0.9919840097427368, "report/reward_neg_loss": 0.018455103039741516, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7011246681213379, "report/reward_pred": 0.02261386066675186, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.271652076364262e-06, "eval/cont_loss_std": 1.4361950888996944e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 9.00380764505826e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.0167066142894328e-06, "eval/cont_pred": 0.9970675706863403, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.253925323486328, "eval/dyn_loss_std": 10.594382286071777, "eval/image_loss_mean": 8.62436294555664, "eval/image_loss_std": 13.04273509979248, "eval/model_loss_mean": 18.471946716308594, "eval/model_loss_std": 17.367931365966797, "eval/post_ent_mag": 59.266693115234375, "eval/post_ent_max": 59.266693115234375, "eval/post_ent_mean": 41.7855339050293, "eval/post_ent_min": 21.764041900634766, "eval/post_ent_std": 7.180893898010254, "eval/prior_ent_mag": 70.19566345214844, "eval/prior_ent_max": 70.19566345214844, "eval/prior_ent_mean": 56.18382263183594, "eval/prior_ent_min": 43.30539321899414, "eval/prior_ent_std": 4.463112831115723, "eval/rep_loss_mean": 16.253925323486328, "eval/rep_loss_std": 10.594382286071777, "eval/reward_avg": 0.04414062574505806, "eval/reward_loss_mean": 0.09522604942321777, "eval/reward_loss_std": 0.5395514965057373, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0004096031188965, "eval/reward_neg_acc": 0.9867075681686401, "eval/reward_neg_loss": 0.029862377792596817, "eval/reward_pos_acc": 0.8260869979858398, "eval/reward_pos_loss": 1.484914779663086, "eval/reward_pred": 0.036704741418361664, "eval/reward_rate": 0.044921875, "replay/size": 753521.0, "replay/inserts": 21960.0, "replay/samples": 21968.0, "replay/insert_wait_avg": 1.4387844690208226e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.586563511825528e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4280.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.234150378503532e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1622905731201172e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.426741361618, "timer/env.step_count": 2745.0, "timer/env.step_total": 255.00734424591064, "timer/env.step_frac": 0.2548985684837214, "timer/env.step_avg": 0.09289885036280898, "timer/env.step_min": 0.02387690544128418, "timer/env.step_max": 3.4917397499084473, "timer/replay._sample_count": 21968.0, "timer/replay._sample_total": 11.557055950164795, "timer/replay._sample_frac": 0.011552126180109111, "timer/replay._sample_avg": 0.0005260859409215584, "timer/replay._sample_min": 0.000408172607421875, "timer/replay._sample_max": 0.02996349334716797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3280.0, "timer/agent.policy_total": 57.19900918006897, "timer/agent.policy_frac": 0.057174610408973064, "timer/agent.policy_avg": 0.01743872231099664, "timer/agent.policy_min": 0.009534358978271484, "timer/agent.policy_max": 0.12804961204528809, "timer/dataset_train_count": 1373.0, "timer/dataset_train_total": 0.16869688034057617, "timer/dataset_train_frac": 0.00016862492111213804, "timer/dataset_train_avg": 0.00012286735640245898, "timer/dataset_train_min": 0.0001049041748046875, "timer/dataset_train_max": 0.0010800361633300781, "timer/agent.train_count": 1373.0, "timer/agent.train_total": 617.1685347557068, "timer/agent.train_frac": 0.6169052757583403, "timer/agent.train_avg": 0.44950366697429484, "timer/agent.train_min": 0.4357569217681885, "timer/agent.train_max": 1.6139867305755615, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4903721809387207, "timer/agent.report_frac": 0.0004901630081092254, "timer/agent.report_avg": 0.24518609046936035, "timer/agent.report_min": 0.23606181144714355, "timer/agent.report_max": 0.25431036949157715, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.431763063819895e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 21.950274127137938}
{"step": 754456, "time": 35465.30022239685, "episode/length": 390.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9923273657289002, "episode/intrinsic_return": 0.0}
{"step": 754608, "time": 35472.28942942619, "episode/length": 156.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 754840, "time": 35481.58079791069, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 755128, "time": 35493.16155195236, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 755272, "time": 35499.649196624756, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 755448, "time": 35507.610827207565, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 755568, "time": 35513.4316778183, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 755584, "time": 35515.70060157776, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 755808, "time": 35524.97355437279, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 756152, "time": 35537.897023677826, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 756280, "time": 35543.659933805466, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 756480, "time": 35552.21733427048, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 756528, "time": 35555.43749833107, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 756560, "time": 35558.10083627701, "episode/length": 34.0, "episode/score": 2.100000038743019, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 757056, "time": 35576.434816122055, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 757336, "time": 35587.48086762428, "episode/length": 190.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 757384, "time": 35590.64882802963, "episode/length": 226.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 757456, "time": 35594.934973955154, "episode/length": 49.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 757488, "time": 35597.552013874054, "episode/length": 125.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 757512, "time": 35599.70415401459, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 757800, "time": 35611.18475937843, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 758048, "time": 35621.31786990166, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 758224, "time": 35628.75313258171, "episode/length": 329.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 758720, "time": 35647.09080219269, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 758992, "time": 35657.780089616776, "episode/length": 206.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 759032, "time": 35660.48003554344, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9844559585492227, "episode/intrinsic_return": 0.0}
{"step": 759208, "time": 35667.93360424042, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 759384, "time": 35675.45885562897, "episode/length": 43.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 759472, "time": 35680.49519395828, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 759528, "time": 35683.77407455444, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 759552, "time": 35686.440373659134, "episode/length": 42.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 759760, "time": 35694.93413758278, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 759960, "time": 35703.132922410965, "episode/length": 50.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 759968, "time": 35705.236244916916, "episode/length": 54.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 35724.21364092827, "eval_episode/length": 37.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 760032, "time": 35730.099034547806, "eval_episode/length": 112.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9557522123893806}
{"step": 760032, "time": 35735.72912859917, "eval_episode/length": 161.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 760032, "time": 35739.543531656265, "eval_episode/length": 207.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9711538461538461}
{"step": 760032, "time": 35741.200719594955, "eval_episode/length": 208.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 760032, "time": 35741.208612680435, "eval_episode/length": 170.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 760032, "time": 35744.8085463047, "eval_episode/length": 213.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 760032, "time": 35746.95261263847, "eval_episode/length": 224.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 760360, "time": 35757.76817154884, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 760576, "time": 35766.76816225052, "episode/length": 197.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 760752, "time": 35774.21181821823, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 761040, "time": 35785.426416397095, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 761424, "time": 35800.081397295, "episode/length": 495.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 761568, "time": 35806.43903517723, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 761600, "time": 35809.1078209877, "episode/length": 204.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 761600, "time": 35809.11632347107, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 761632, "time": 35813.63186144829, "episode/length": 109.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 761688, "time": 35816.85824966431, "episode/length": 214.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 762416, "time": 35844.727045059204, "episode/length": 229.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 762448, "time": 35847.45747613907, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 762944, "time": 35865.86490678787, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 762984, "time": 35868.600919008255, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 763032, "time": 35871.87791180611, "episode/length": 182.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9890710382513661, "episode/intrinsic_return": 0.0}
{"step": 763120, "time": 35876.63797354698, "episode/length": 211.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 763392, "time": 35887.57582807541, "episode/length": 219.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 764056, "time": 35911.499873399734, "episode/length": 306.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 764072, "time": 35913.54126238823, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 764392, "time": 35925.949122428894, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 764600, "time": 35934.589790821075, "episode/length": 206.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 764720, "time": 35940.60369181633, "episode/length": 80.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 764728, "time": 35942.18439221382, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 764944, "time": 35951.27448105812, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 765112, "time": 35958.35579395294, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 765520, "time": 35974.01790356636, "episode/length": 316.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 765920, "time": 35989.05632328987, "episode/length": 190.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 765952, "time": 35991.69208550453, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 766000, "time": 35994.86065220833, "episode/length": 174.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 766144, "time": 36001.38353610039, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 766392, "time": 36011.139808654785, "episode/length": 180.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 766576, "time": 36019.18177127838, "episode/length": 182.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 766600, "time": 36021.39587569237, "episode/length": 234.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 766968, "time": 36035.40082979202, "episode/length": 180.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 767200, "time": 36044.99272060394, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 767624, "time": 36060.901621341705, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 767680, "time": 36064.57253241539, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 767736, "time": 36067.85466122627, "episode/length": 144.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 767856, "time": 36073.714653491974, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 768216, "time": 36087.25089621544, "episode/length": 227.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 768488, "time": 36098.25019001961, "episode/length": 235.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 768640, "time": 36105.10574221611, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 768680, "time": 36107.76869249344, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 768736, "time": 36111.46838378906, "episode/length": 124.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 769000, "time": 36121.94899535179, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 769104, "time": 36127.30060839653, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 769488, "time": 36141.80359888077, "episode/length": 225.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 769832, "time": 36155.193242788315, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 36179.485335588455, "eval_episode/length": 45.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 770016, "time": 36185.16361951828, "eval_episode/length": 135.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 770016, "time": 36188.51878476143, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9651162790697675}
{"step": 770016, "time": 36190.599828481674, "eval_episode/length": 173.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 770016, "time": 36194.47943472862, "eval_episode/length": 208.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 770016, "time": 36196.90301370621, "eval_episode/length": 217.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 770016, "time": 36199.118420124054, "eval_episode/length": 222.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 770016, "time": 36201.90669131279, "eval_episode/length": 202.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 770040, "time": 36202.51572918892, "episode/length": 227.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 770248, "time": 36212.930864572525, "episode/length": 200.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 770312, "time": 36216.73360681534, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 770528, "time": 36226.2406976223, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 770784, "time": 36236.834600925446, "episode/length": 222.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 771048, "time": 36247.51001238823, "episode/length": 288.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9792387543252595, "episode/intrinsic_return": 0.0}
{"step": 771688, "time": 36270.91345500946, "episode/length": 274.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 771736, "time": 36274.14836740494, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9669811320754716, "episode/intrinsic_return": 0.0}
{"step": 771952, "time": 36283.24433898926, "episode/length": 145.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 771976, "time": 36285.40361261368, "episode/length": 215.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 772096, "time": 36291.23640060425, "episode/length": 222.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9865470852017937, "episode/intrinsic_return": 0.0}
{"step": 772176, "time": 36295.679935216904, "episode/length": 292.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9726962457337884, "episode/intrinsic_return": 0.0}
{"step": 772224, "time": 36299.088807582855, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 773184, "time": 36333.04248261452, "episode/length": 153.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 773280, "time": 36337.79516363144, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 773304, "time": 36340.013209581375, "episode/length": 281.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 773536, "time": 36349.58168387413, "episode/length": 230.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 773576, "time": 36352.21915388107, "episode/length": 184.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 773736, "time": 36359.3108215332, "episode/length": 219.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 773760, "time": 36361.88598155975, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 773984, "time": 36370.97987151146, "episode/length": 225.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 774424, "time": 36387.4842004776, "episode/length": 85.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 774736, "time": 36399.99795007706, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 774808, "time": 36403.788752794266, "episode/length": 187.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 775040, "time": 36413.332132816315, "episode/length": 219.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 775072, "time": 36415.994421482086, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 775160, "time": 36420.48037672043, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 775248, "time": 36425.25413250923, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 775440, "time": 36433.3336391449, "episode/length": 49.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 775576, "time": 36439.30245256424, "episode/length": 95.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 775704, "time": 36445.1937789917, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 775720, "time": 36447.23904299736, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 775737, "time": 36450.55293536186, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.671351453993055, "train/action_min": 0.0, "train/action_std": 3.5128011880097567, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0442481623755561, "train/actor_opt_grad_steps": 47710.0, "train/actor_opt_loss": -5.304610162035183, "train/adv_mag": 0.5897946421746855, "train/adv_max": 0.5602326823605431, "train/adv_mean": 0.0028575714035132143, "train/adv_min": -0.4427784937399405, "train/adv_std": 0.06444515812176245, "train/cont_avg": 0.9944155092592593, "train/cont_loss_mean": 0.00022397929446019252, "train/cont_loss_std": 0.006701421599475705, "train/cont_neg_acc": 0.9913261087972727, "train/cont_neg_loss": 0.024060624003958996, "train/cont_pos_acc": 0.9999635714071768, "train/cont_pos_loss": 7.866284839729411e-05, "train/cont_pred": 0.9944242389113814, "train/cont_rate": 0.9944155092592593, "train/dyn_loss_mean": 12.434452325326426, "train/dyn_loss_std": 9.362864056339971, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8120596554544237, "train/extr_critic_critic_opt_grad_steps": 47710.0, "train/extr_critic_critic_opt_loss": 16124.768655960648, "train/extr_critic_mag": 6.634452593768084, "train/extr_critic_max": 6.634452593768084, "train/extr_critic_mean": 1.6862604962454901, "train/extr_critic_min": -0.3170491351021661, "train/extr_critic_std": 1.530747937714612, "train/extr_return_normed_mag": 1.6777652978897095, "train/extr_return_normed_max": 1.6777652978897095, "train/extr_return_normed_mean": 0.3638990560063609, "train/extr_return_normed_min": -0.13065581357589476, "train/extr_return_normed_std": 0.3311489715620323, "train/extr_return_rate": 0.6974870160773948, "train/extr_return_raw_mag": 7.89572316982128, "train/extr_return_raw_max": 7.89572316982128, "train/extr_return_raw_mean": 1.699663191371494, "train/extr_return_raw_min": -0.6344274489967912, "train/extr_return_raw_std": 1.5626819407498396, "train/extr_reward_mag": 1.030182917912801, "train/extr_reward_max": 1.030182917912801, "train/extr_reward_mean": 0.03662678428270199, "train/extr_reward_min": -0.516032193325184, "train/extr_reward_std": 0.1813768807384703, "train/image_loss_mean": 5.4900817005722615, "train/image_loss_std": 9.790294763776991, "train/model_loss_mean": 13.003504795498317, "train/model_loss_std": 13.722473391780147, "train/model_opt_grad_norm": 52.63342415138527, "train/model_opt_grad_steps": 47666.02222222222, "train/model_opt_loss": 10190.664424189816, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 787.0370370370371, "train/policy_entropy_mag": 2.5532038264804418, "train/policy_entropy_max": 2.5532038264804418, "train/policy_entropy_mean": 0.5490815999331298, "train/policy_entropy_min": 0.07937506900893318, "train/policy_entropy_std": 0.6229317885858041, "train/policy_logprob_mag": 7.438383611043294, "train/policy_logprob_max": -0.009455661068635959, "train/policy_logprob_mean": -0.5495811802369577, "train/policy_logprob_min": -7.438383611043294, "train/policy_logprob_std": 1.1071389644234269, "train/policy_randomness_mag": 0.901168907130206, "train/policy_randomness_max": 0.901168907130206, "train/policy_randomness_mean": 0.1938017071397216, "train/policy_randomness_min": 0.028015916104669924, "train/policy_randomness_std": 0.21986758488195915, "train/post_ent_mag": 59.92824797453704, "train/post_ent_max": 59.92824797453704, "train/post_ent_mean": 43.28460252549913, "train/post_ent_min": 20.917163764105904, "train/post_ent_std": 7.475094074673123, "train/prior_ent_mag": 69.72992553710938, "train/prior_ent_max": 69.72992553710938, "train/prior_ent_mean": 55.800631826895255, "train/prior_ent_min": 39.07654054429796, "train/prior_ent_std": 4.650214744497228, "train/rep_loss_mean": 12.434452325326426, "train/rep_loss_std": 9.362864056339971, "train/reward_avg": 0.024889322818705328, "train/reward_loss_mean": 0.05252780660435005, "train/reward_loss_std": 0.2417177359263102, "train/reward_max_data": 1.0177777820163303, "train/reward_max_pred": 1.0130720880296495, "train/reward_neg_acc": 0.993396457919368, "train/reward_neg_loss": 0.02904220935371187, "train/reward_pos_acc": 0.9728690677218967, "train/reward_pos_loss": 0.8189716961648729, "train/reward_pred": 0.024423748441040515, "train/reward_rate": 0.02984664351851852, "train_stats/sum_log_reward": 6.494736869084208, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.5701754385964914, "train_stats/max_log_achievement_collect_sapling": 2.008771929824561, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 8.289473684210526, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 1.2280701754385965, "train_stats/max_log_achievement_eat_cow": 0.18421052631578946, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008771929824561403, "train_stats/max_log_achievement_make_wood_sword": 1.0614035087719298, "train_stats/max_log_achievement_place_plant": 1.912280701754386, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.982456140350877, "train_stats/max_log_achievement_wake_up": 1.3771929824561404, "train_stats/mean_log_entropy": 0.5239543629842892, "eval_stats/sum_log_reward": 6.225000023841858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.0, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0625, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.00021114210539963096, "report/cont_loss_std": 0.0051888576708734035, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00047687505139037967, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00020904972916468978, "report/cont_pred": 0.9919966459274292, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 12.927062034606934, "report/dyn_loss_std": 10.301750183105469, "report/image_loss_mean": 5.957353591918945, "report/image_loss_std": 10.56985855102539, "report/model_loss_mean": 13.772218704223633, "report/model_loss_std": 15.145248413085938, "report/post_ent_mag": 61.37031555175781, "report/post_ent_max": 61.37031555175781, "report/post_ent_mean": 43.21009826660156, "report/post_ent_min": 18.647647857666016, "report/post_ent_std": 7.865599632263184, "report/prior_ent_mag": 69.60479736328125, "report/prior_ent_max": 69.60479736328125, "report/prior_ent_mean": 55.90841293334961, "report/prior_ent_min": 38.36025619506836, "report/prior_ent_std": 4.645374774932861, "report/rep_loss_mean": 12.927062034606934, "report/rep_loss_std": 10.301750183105469, "report/reward_avg": 0.02480468712747097, "report/reward_loss_mean": 0.05841778218746185, "report/reward_loss_std": 0.2708793878555298, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0289273262023926, "report/reward_neg_acc": 0.9959717988967896, "report/reward_neg_loss": 0.039028093218803406, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6795132160186768, "report/reward_pred": 0.02652103826403618, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.151063356199302e-05, "eval/cont_loss_std": 0.0008643176988698542, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0013490899000316858, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.7639196559903212e-05, "eval/cont_pred": 0.9970471262931824, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.081409454345703, "eval/dyn_loss_std": 10.683348655700684, "eval/image_loss_mean": 12.18276309967041, "eval/image_loss_std": 15.520915031433105, "eval/model_loss_mean": 23.705224990844727, "eval/model_loss_std": 19.762353897094727, "eval/post_ent_mag": 58.208946228027344, "eval/post_ent_max": 58.208946228027344, "eval/post_ent_mean": 39.864768981933594, "eval/post_ent_min": 21.07891273498535, "eval/post_ent_std": 7.076493263244629, "eval/prior_ent_mag": 69.60479736328125, "eval/prior_ent_max": 69.60479736328125, "eval/prior_ent_mean": 56.63775634765625, "eval/prior_ent_min": 43.15367126464844, "eval/prior_ent_std": 4.160301685333252, "eval/rep_loss_mean": 19.081409454345703, "eval/rep_loss_std": 10.683348655700684, "eval/reward_avg": 0.03408203274011612, "eval/reward_loss_mean": 0.07358517497777939, "eval/reward_loss_std": 0.4181513786315918, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0041749477386475, "eval/reward_neg_acc": 0.9898682236671448, "eval/reward_neg_loss": 0.03890044987201691, "eval/reward_pos_acc": 0.9459459185600281, "eval/reward_pos_loss": 0.9988234639167786, "eval/reward_pred": 0.03397064656019211, "eval/reward_rate": 0.0361328125, "replay/size": 775233.0, "replay/inserts": 21712.0, "replay/samples": 21712.0, "replay/insert_wait_avg": 1.435145439254772e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.447981091571715e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.261002906767125e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4059054851532, "timer/env.step_count": 2714.0, "timer/env.step_total": 260.3255889415741, "timer/env.step_frac": 0.26021996423074645, "timer/env.step_avg": 0.0959195242968217, "timer/env.step_min": 0.02452254295349121, "timer/env.step_max": 3.4706923961639404, "timer/replay._sample_count": 21712.0, "timer/replay._sample_total": 11.792748212814331, "timer/replay._sample_frac": 0.011787963413805882, "timer/replay._sample_avg": 0.0005431442618282209, "timer/replay._sample_min": 0.00042748451232910156, "timer/replay._sample_max": 0.027765274047851562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3188.0, "timer/agent.policy_total": 57.12763738632202, "timer/agent.policy_frac": 0.05710445837344154, "timer/agent.policy_avg": 0.017919585127453584, "timer/agent.policy_min": 0.009768962860107422, "timer/agent.policy_max": 0.13468551635742188, "timer/dataset_train_count": 1357.0, "timer/dataset_train_total": 0.16710233688354492, "timer/dataset_train_frac": 0.0001670345366489091, "timer/dataset_train_avg": 0.00012314099991418196, "timer/dataset_train_min": 0.00010609626770019531, "timer/dataset_train_max": 0.0005259513854980469, "timer/agent.train_count": 1357.0, "timer/agent.train_total": 610.6923930644989, "timer/agent.train_frac": 0.6104446102488167, "timer/agent.train_avg": 0.4500312402833448, "timer/agent.train_min": 0.43635129928588867, "timer/agent.train_max": 1.5259270668029785, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4790818691253662, "timer/agent.report_frac": 0.000478887486068, "timer/agent.report_avg": 0.2395409345626831, "timer/agent.report_min": 0.23491430282592773, "timer/agent.report_max": 0.24416756629943848, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.440017700195312e-05, "timer/dataset_eval_frac": 8.436593240722896e-08, "timer/dataset_eval_avg": 8.440017700195312e-05, "timer/dataset_eval_min": 8.440017700195312e-05, "timer/dataset_eval_max": 8.440017700195312e-05, "fps": 21.70285455010271}
{"step": 775864, "time": 36454.67521929741, "episode/length": 140.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 776376, "time": 36473.50421142578, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 776864, "time": 36491.87244772911, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 776984, "time": 36497.28611803055, "episode/length": 238.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 777168, "time": 36505.29917025566, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 777264, "time": 36510.22801041603, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 777312, "time": 36513.42908000946, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 777808, "time": 36531.6827352047, "episode/length": 278.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 777840, "time": 36534.28018593788, "episode/length": 264.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 778072, "time": 36543.67683720589, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 778296, "time": 36554.165940999985, "episode/length": 27.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 778304, "time": 36556.21158909798, "episode/length": 123.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9596774193548387, "episode/intrinsic_return": 0.0}
{"step": 778544, "time": 36565.94154429436, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 778720, "time": 36573.531668424606, "episode/length": 193.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 778728, "time": 36575.19811964035, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 778928, "time": 36583.73866534233, "episode/length": 207.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 779536, "time": 36605.92058992386, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9675925925925926, "episode/intrinsic_return": 0.0}
{"step": 779648, "time": 36611.245990514755, "episode/length": 225.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 779832, "time": 36618.77466106415, "episode/length": 36.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 779840, "time": 36620.832340955734, "episode/length": 191.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 36648.70160841942, "eval_episode/length": 161.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 780000, "time": 36651.827097177505, "eval_episode/length": 191.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 780000, "time": 36653.89757204056, "eval_episode/length": 201.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 780000, "time": 36655.64557981491, "eval_episode/length": 204.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9707317073170731}
{"step": 780000, "time": 36657.445345163345, "eval_episode/length": 207.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 780000, "time": 36659.348127126694, "eval_episode/length": 209.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 780000, "time": 36661.10844230652, "eval_episode/length": 210.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 780000, "time": 36662.98684501648, "eval_episode/length": 216.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 780064, "time": 36665.201369047165, "episode/length": 220.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 780144, "time": 36669.52404356003, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 780216, "time": 36673.20830345154, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 780456, "time": 36682.94079065323, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 781192, "time": 36709.327560424805, "episode/length": 307.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 781320, "time": 36715.27211070061, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 781552, "time": 36724.992215156555, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 781592, "time": 36727.80025959015, "episode/length": 219.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 781648, "time": 36731.5429122448, "episode/length": 197.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 781736, "time": 36735.822257995605, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 781800, "time": 36739.58142542839, "episode/length": 268.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 781984, "time": 36747.57191705704, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 782768, "time": 36775.61360001564, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 782880, "time": 36781.15481495857, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 782952, "time": 36784.88887643814, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 783048, "time": 36789.69472408295, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 783064, "time": 36792.02163982391, "episode/length": 36.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 783240, "time": 36799.56479859352, "episode/length": 198.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 783472, "time": 36809.34148359299, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 783480, "time": 36811.04202580452, "episode/length": 235.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 783656, "time": 36818.524456977844, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 784736, "time": 36856.707012176514, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 784800, "time": 36860.92927026749, "episode/length": 239.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 784864, "time": 36864.64685058594, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 784872, "time": 36866.40572476387, "episode/length": 239.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 785000, "time": 36872.47136068344, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 785048, "time": 36875.76172399521, "episode/length": 225.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 785104, "time": 36879.481487989426, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 785960, "time": 36909.558822155, "episode/length": 106.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 786008, "time": 36912.72241353989, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 786192, "time": 36920.70818114281, "episode/length": 392.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 786280, "time": 36925.07392835617, "episode/length": 192.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 786472, "time": 36935.07292056084, "episode/length": 183.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 786672, "time": 36944.27500247955, "episode/length": 224.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 786760, "time": 36948.48680281639, "episode/length": 236.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 786848, "time": 36953.30726265907, "episode/length": 224.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 787040, "time": 36961.49947953224, "episode/length": 34.0, "episode/score": 2.099999949336052, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 787248, "time": 36970.02985334396, "episode/length": 160.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 787624, "time": 36983.96900343895, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 787728, "time": 36989.29764294624, "episode/length": 131.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 788048, "time": 37001.61734342575, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 788240, "time": 37009.579981803894, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 788648, "time": 37024.91108441353, "episode/length": 271.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 788824, "time": 37032.44269514084, "episode/length": 246.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 789136, "time": 37044.6772441864, "episode/length": 261.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 789416, "time": 37055.60902404785, "episode/length": 270.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.977859778597786, "episode/intrinsic_return": 0.0}
{"step": 789552, "time": 37061.980526685715, "episode/length": 240.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 789808, "time": 37072.09412407875, "episode/length": 195.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 790040, "time": 37081.42726135254, "episode/length": 248.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 37099.956434726715, "eval_episode/length": 48.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.8979591836734694}
{"step": 790088, "time": 37106.91737270355, "eval_episode/length": 165.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 790088, "time": 37106.93359255791, "eval_episode/length": 165.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 790088, "time": 37110.974653959274, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 790088, "time": 37114.19338226318, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 790088, "time": 37116.024062633514, "eval_episode/length": 221.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 790088, "time": 37119.428886413574, "eval_episode/length": 97.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9489795918367347}
{"step": 790088, "time": 37122.17511630058, "eval_episode/length": 292.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9761092150170648}
{"step": 790248, "time": 37127.56198000908, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 790472, "time": 37136.67702245712, "episode/length": 342.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9912536443148688, "episode/intrinsic_return": 0.0}
{"step": 790928, "time": 37154.00205898285, "episode/length": 84.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 790928, "time": 37154.01136183739, "episode/length": 284.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 790984, "time": 37158.98209810257, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 791392, "time": 37174.44057202339, "episode/length": 229.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 791616, "time": 37183.497569561005, "episode/length": 309.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 791640, "time": 37185.76354074478, "episode/length": 228.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 791888, "time": 37195.72556567192, "episode/length": 33.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 792056, "time": 37202.99997258186, "episode/length": 251.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 792400, "time": 37216.36380529404, "episode/length": 240.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 792416, "time": 37218.393711566925, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 792672, "time": 37228.66904234886, "episode/length": 210.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 792880, "time": 37237.159366607666, "episode/length": 243.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 793352, "time": 37254.39615702629, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 793816, "time": 37271.703891038895, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 793848, "time": 37274.34304046631, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 793896, "time": 37277.610352516174, "episode/length": 312.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9968051118210862, "episode/intrinsic_return": 0.0}
{"step": 793896, "time": 37277.618688583374, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 793944, "time": 37282.55260181427, "episode/length": 132.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 794112, "time": 37290.15574789047, "episode/length": 213.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 794136, "time": 37292.40801811218, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 794448, "time": 37304.74694490433, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 794720, "time": 37317.2964515686, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 795112, "time": 37332.48105978966, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 795304, "time": 37340.471445798874, "episode/length": 175.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 795456, "time": 37347.36956691742, "episode/length": 200.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 795600, "time": 37354.62620782852, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 795864, "time": 37365.01602315903, "episode/length": 245.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 796064, "time": 37373.506865262985, "episode/length": 240.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.991701244813278, "episode/intrinsic_return": 0.0}
{"step": 796104, "time": 37376.22793316841, "episode/length": 206.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 796448, "time": 37389.63097691536, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 796840, "time": 37404.18262910843, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 797304, "time": 37421.469014406204, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 797368, "time": 37425.21686387062, "episode/length": 281.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 797536, "time": 37432.81716609001, "episode/length": 259.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 797672, "time": 37439.00867795944, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 797752, "time": 37443.25166583061, "episode/length": 47.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 797897, "time": 37450.79254770279, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.584711966754721, "train/action_min": 0.0, "train/action_std": 3.443129982022073, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045110575533170494, "train/actor_opt_grad_steps": 49080.0, "train/actor_opt_loss": -3.552708308044955, "train/adv_mag": 0.5729692966389142, "train/adv_max": 0.5519846369036667, "train/adv_mean": 0.0034083059002526384, "train/adv_min": -0.4103192376147071, "train/adv_std": 0.06485957373603643, "train/cont_avg": 0.9948431879496403, "train/cont_loss_mean": 0.00025316751838759603, "train/cont_loss_std": 0.0077763896817025675, "train/cont_neg_acc": 0.9915296349594062, "train/cont_neg_loss": 0.015716783216009764, "train/cont_pos_acc": 0.9999575704979382, "train/cont_pos_loss": 0.00016191310139538923, "train/cont_pred": 0.9948367660851787, "train/cont_rate": 0.9948431879496403, "train/dyn_loss_mean": 12.330301648421253, "train/dyn_loss_std": 9.349305351861089, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.815527947686559, "train/extr_critic_critic_opt_grad_steps": 49080.0, "train/extr_critic_critic_opt_loss": 16069.789947729316, "train/extr_critic_mag": 6.577367717413593, "train/extr_critic_max": 6.577367717413593, "train/extr_critic_mean": 1.611648849446139, "train/extr_critic_min": -0.30994116831168855, "train/extr_critic_std": 1.4448016830485502, "train/extr_return_normed_mag": 1.6881627650569668, "train/extr_return_normed_max": 1.6881627650569668, "train/extr_return_normed_mean": 0.35523908504908036, "train/extr_return_normed_min": -0.13311751460214313, "train/extr_return_normed_std": 0.32319554107652293, "train/extr_return_rate": 0.6847014948189687, "train/extr_return_raw_mag": 7.733438831439122, "train/extr_return_raw_max": 7.733438831439122, "train/extr_return_raw_mean": 1.627266716614044, "train/extr_return_raw_min": -0.6103075860644416, "train/extr_return_raw_std": 1.4806246714626285, "train/extr_reward_mag": 1.0292913639288155, "train/extr_reward_max": 1.0292913639288155, "train/extr_reward_mean": 0.03555537161263202, "train/extr_reward_min": -0.48886614737750816, "train/extr_reward_std": 0.17858218010380972, "train/image_loss_mean": 5.389582597952095, "train/image_loss_std": 9.95504404314988, "train/model_loss_mean": 12.83821559466904, "train/model_loss_std": 13.862930743814372, "train/model_opt_grad_norm": 49.13706185320299, "train/model_opt_grad_steps": 49035.56834532374, "train/model_opt_loss": 17268.869850213578, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1348.9208633093526, "train/policy_entropy_mag": 2.532697826838322, "train/policy_entropy_max": 2.532697826838322, "train/policy_entropy_mean": 0.5828687917414329, "train/policy_entropy_min": 0.07937503965209713, "train/policy_entropy_std": 0.6428813955766691, "train/policy_logprob_mag": 7.438383592976083, "train/policy_logprob_max": -0.009455659265944855, "train/policy_logprob_mean": -0.5839239354613873, "train/policy_logprob_min": -7.438383592976083, "train/policy_logprob_std": 1.1311767478640988, "train/policy_randomness_mag": 0.8939311886005264, "train/policy_randomness_max": 0.8939311886005264, "train/policy_randomness_mean": 0.20572710369559502, "train/policy_randomness_min": 0.028015905682989162, "train/policy_randomness_std": 0.22690892080180078, "train/post_ent_mag": 59.90660174802053, "train/post_ent_max": 59.90660174802053, "train/post_ent_mean": 43.40899408463952, "train/post_ent_min": 20.924374868543886, "train/post_ent_std": 7.468426429968086, "train/prior_ent_mag": 69.82746299908315, "train/prior_ent_max": 69.82746299908315, "train/prior_ent_mean": 55.83089315290931, "train/prior_ent_min": 38.91330058969182, "train/prior_ent_std": 4.62892440068636, "train/rep_loss_mean": 12.330301648421253, "train/rep_loss_std": 9.349305351861089, "train/reward_avg": 0.024678928586620866, "train/reward_loss_mean": 0.050198942543469745, "train/reward_loss_std": 0.2309530838895187, "train/reward_max_data": 1.019424465062807, "train/reward_max_pred": 1.0108119232191457, "train/reward_neg_acc": 0.9934835674093782, "train/reward_neg_loss": 0.027091889601978038, "train/reward_pos_acc": 0.9731726354832272, "train/reward_pos_loss": 0.819613795915096, "train/reward_pred": 0.024143384736058093, "train/reward_rate": 0.029212567446043166, "train_stats/sum_log_reward": 6.557943950189609, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.4672897196261685, "train_stats/max_log_achievement_collect_sapling": 1.8130841121495327, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 8.327102803738319, "train_stats/max_log_achievement_defeat_skeleton": 0.018691588785046728, "train_stats/max_log_achievement_defeat_zombie": 1.2242990654205608, "train_stats/max_log_achievement_eat_cow": 0.17757009345794392, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.018691588785046728, "train_stats/max_log_achievement_make_wood_sword": 1.0560747663551402, "train_stats/max_log_achievement_place_plant": 1.7009345794392523, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.8130841121495327, "train_stats/max_log_achievement_wake_up": 1.4205607476635513, "train_stats/mean_log_entropy": 0.6199377326764793, "eval_stats/sum_log_reward": 6.412500023841858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.8125, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 9.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.9375, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.0625, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 2.068484536721371e-05, "report/cont_loss_std": 0.00048046198207885027, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006019488791935146, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.4952458514017053e-05, "report/cont_pred": 0.9902255535125732, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 13.216567039489746, "report/dyn_loss_std": 9.687057495117188, "report/image_loss_mean": 6.793402671813965, "report/image_loss_std": 11.119611740112305, "report/model_loss_mean": 14.790218353271484, "report/model_loss_std": 14.816540718078613, "report/post_ent_mag": 61.600685119628906, "report/post_ent_max": 61.600685119628906, "report/post_ent_mean": 43.735435485839844, "report/post_ent_min": 17.101909637451172, "report/post_ent_std": 8.057365417480469, "report/prior_ent_mag": 70.07597351074219, "report/prior_ent_max": 70.07597351074219, "report/prior_ent_mean": 56.95294952392578, "report/prior_ent_min": 42.40574645996094, "report/prior_ent_std": 4.321549892425537, "report/rep_loss_mean": 13.216567039489746, "report/rep_loss_std": 9.687057495117188, "report/reward_avg": 0.03476562350988388, "report/reward_loss_mean": 0.06685414910316467, "report/reward_loss_std": 0.27245834469795227, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0017855167388916, "report/reward_neg_acc": 0.9949030876159668, "report/reward_neg_loss": 0.03595781698822975, "report/reward_pos_acc": 0.9767441749572754, "report/reward_pos_loss": 0.771721601486206, "report/reward_pred": 0.036043573170900345, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 3.968933469877811e-06, "eval/cont_loss_std": 5.7684235798660666e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005559801356866956, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.154296213229827e-07, "eval/cont_pred": 0.9941431879997253, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.986989974975586, "eval/dyn_loss_std": 10.630963325500488, "eval/image_loss_mean": 9.700052261352539, "eval/image_loss_std": 15.731827735900879, "eval/model_loss_mean": 20.006359100341797, "eval/model_loss_std": 19.229202270507812, "eval/post_ent_mag": 57.73174285888672, "eval/post_ent_max": 57.73174285888672, "eval/post_ent_mean": 41.22777557373047, "eval/post_ent_min": 20.014984130859375, "eval/post_ent_std": 7.0279741287231445, "eval/prior_ent_mag": 70.07597351074219, "eval/prior_ent_max": 70.07597351074219, "eval/prior_ent_mean": 56.087703704833984, "eval/prior_ent_min": 43.15410614013672, "eval/prior_ent_std": 4.198843002319336, "eval/rep_loss_mean": 16.986989974975586, "eval/rep_loss_std": 10.630963325500488, "eval/reward_avg": 0.04248046875, "eval/reward_loss_mean": 0.11410866677761078, "eval/reward_loss_std": 0.5749967694282532, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017938613891602, "eval/reward_neg_acc": 0.9887179136276245, "eval/reward_neg_loss": 0.05435246601700783, "eval/reward_pos_acc": 0.8979591727256775, "eval/reward_pos_loss": 1.3031349182128906, "eval/reward_pred": 0.03836464136838913, "eval/reward_rate": 0.0478515625, "replay/size": 797393.0, "replay/inserts": 22160.0, "replay/samples": 22160.0, "replay/insert_wait_avg": 1.4195803700801698e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.248249976643586e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4080.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1922097673603134e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2233526706696, "timer/env.step_count": 2770.0, "timer/env.step_total": 250.4894299507141, "timer/env.step_frac": 0.2504334949607895, "timer/env.step_avg": 0.09042939709412062, "timer/env.step_min": 0.02418208122253418, "timer/env.step_max": 3.353987455368042, "timer/replay._sample_count": 22160.0, "timer/replay._sample_total": 11.65056324005127, "timer/replay._sample_frac": 0.011647961636711853, "timer/replay._sample_avg": 0.0005257474386304725, "timer/replay._sample_min": 0.00039076805114746094, "timer/replay._sample_max": 0.011869668960571289, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3280.0, "timer/agent.policy_total": 56.920570611953735, "timer/agent.policy_frac": 0.05690786008942068, "timer/agent.policy_avg": 0.01735383250364443, "timer/agent.policy_min": 0.009728193283081055, "timer/agent.policy_max": 0.11716985702514648, "timer/dataset_train_count": 1385.0, "timer/dataset_train_total": 0.16684365272521973, "timer/dataset_train_frac": 0.00016680639607117247, "timer/dataset_train_avg": 0.00012046473120954493, "timer/dataset_train_min": 0.00010585784912109375, "timer/dataset_train_max": 0.00038170814514160156, "timer/agent.train_count": 1385.0, "timer/agent.train_total": 623.3013827800751, "timer/agent.train_frac": 0.6231621978389275, "timer/agent.train_avg": 0.4500370994801986, "timer/agent.train_min": 0.435133695602417, "timer/agent.train_max": 1.7012083530426025, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4819517135620117, "timer/agent.report_frac": 0.00048184409239712846, "timer/agent.report_avg": 0.24097585678100586, "timer/agent.report_min": 0.233170747756958, "timer/agent.report_max": 0.2487809658050537, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8603840747965034e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 22.154738393304743}
{"step": 797944, "time": 37452.353123664856, "episode/length": 234.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 798000, "time": 37456.58056807518, "episode/length": 40.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 798528, "time": 37476.53957056999, "episode/length": 302.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 798600, "time": 37480.33604001999, "episode/length": 219.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 798624, "time": 37482.88123583794, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 799024, "time": 37498.148777484894, "episode/length": 214.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 799272, "time": 37507.78100728989, "episode/length": 158.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 799336, "time": 37511.46198177338, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 799360, "time": 37514.44950771332, "episode/length": 227.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 800000, "time": 37538.41842961311, "episode/length": 280.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9893238434163701, "episode/intrinsic_return": 0.0}
{"step": 800064, "time": 37542.23861861229, "episode/length": 179.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 37565.47907328606, "eval_episode/length": 162.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 800072, "time": 37570.69208216667, "eval_episode/length": 211.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 800072, "time": 37572.44108963013, "eval_episode/length": 216.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 800072, "time": 37574.37585067749, "eval_episode/length": 223.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 800072, "time": 37576.53313565254, "eval_episode/length": 234.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9957446808510638}
{"step": 800072, "time": 37578.4373087883, "eval_episode/length": 240.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.970954356846473}
{"step": 800072, "time": 37580.10019850731, "eval_episode/length": 241.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9958677685950413}
{"step": 800072, "time": 37580.10871052742, "eval_episode/length": 241.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9958677685950413}
{"step": 800272, "time": 37587.16671180725, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 800336, "time": 37591.0990486145, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 800568, "time": 37600.3057243824, "episode/length": 36.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 800672, "time": 37605.57494544983, "episode/length": 205.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 800688, "time": 37607.75478577614, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 800728, "time": 37610.468039512634, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 800960, "time": 37620.28363800049, "episode/length": 202.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 801040, "time": 37624.584064006805, "episode/length": 38.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 801712, "time": 37648.95526242256, "episode/length": 142.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 801752, "time": 37651.70845031738, "episode/length": 218.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9680365296803652, "episode/intrinsic_return": 0.0}
{"step": 801768, "time": 37653.85210490227, "episode/length": 136.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 801904, "time": 37660.267800331116, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 802360, "time": 37677.067418813705, "episode/length": 208.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 802456, "time": 37682.0845720768, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 802688, "time": 37691.74827480316, "episode/length": 293.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 802768, "time": 37695.98644089699, "episode/length": 215.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 803000, "time": 37706.927688360214, "episode/length": 153.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 803056, "time": 37710.80797410011, "episode/length": 167.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 803080, "time": 37712.89316225052, "episode/length": 165.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 803496, "time": 37728.52218222618, "episode/length": 129.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 803736, "time": 37738.38140940666, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 804152, "time": 37753.9598941803, "episode/length": 223.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 804432, "time": 37765.132467508316, "episode/length": 171.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 804544, "time": 37770.55448913574, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 804664, "time": 37775.97003078461, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 804704, "time": 37779.201572179794, "episode/length": 251.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 804816, "time": 37784.50342965126, "episode/length": 226.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 805304, "time": 37802.452919483185, "episode/length": 225.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 805640, "time": 37815.287023067474, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 805736, "time": 37820.22052574158, "episode/length": 249.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 805984, "time": 37830.58922743797, "episode/length": 228.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 806088, "time": 37835.47079205513, "episode/length": 177.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 806264, "time": 37842.985501766205, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 806392, "time": 37848.944787979126, "episode/length": 244.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 806472, "time": 37853.161518096924, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 806824, "time": 37866.73648071289, "episode/length": 135.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 806992, "time": 37874.39919376373, "episode/length": 112.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.0}
{"step": 807320, "time": 37886.79176878929, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 807832, "time": 37906.047071933746, "episode/length": 273.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 807976, "time": 37912.51457309723, "episode/length": 187.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 808048, "time": 37916.74823999405, "episode/length": 206.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 808136, "time": 37921.22253489494, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 808184, "time": 37924.375544548035, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 808320, "time": 37930.79101014137, "episode/length": 471.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9978813559322034, "episode/intrinsic_return": 0.0}
{"step": 808360, "time": 37933.59673523903, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 808400, "time": 37936.85545039177, "episode/length": 134.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 808680, "time": 37947.75744986534, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 809648, "time": 37982.47699260712, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 809664, "time": 37984.58562254906, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 809800, "time": 37990.51755166054, "episode/length": 207.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 809856, "time": 37994.23521018028, "episode/length": 181.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 38018.35419631004, "eval_episode/length": 58.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 810056, "time": 38024.31390166283, "eval_episode/length": 153.0, "eval_episode/score": 5.099999964237213, "eval_episode/reward_rate": 0.974025974025974}
{"step": 810056, "time": 38027.13582491875, "eval_episode/length": 179.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 810056, "time": 38029.34430074692, "eval_episode/length": 193.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 810056, "time": 38031.52056312561, "eval_episode/length": 205.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.970873786407767}
{"step": 810056, "time": 38033.3703918457, "eval_episode/length": 210.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.995260663507109}
{"step": 810056, "time": 38035.63830113411, "eval_episode/length": 224.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 810056, "time": 38038.057725429535, "eval_episode/length": 178.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 810128, "time": 38040.719871759415, "episode/length": 40.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 810176, "time": 38043.903035879135, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 811296, "time": 38084.868171691895, "episode/length": 371.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9973118279569892, "episode/intrinsic_return": 0.0}
{"step": 811312, "time": 38087.03708696365, "episode/length": 205.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 811416, "time": 38091.93852543831, "episode/length": 447.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9977678571428571, "episode/intrinsic_return": 0.0}
{"step": 811424, "time": 38094.07552361488, "episode/length": 221.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 811584, "time": 38101.11645388603, "episode/length": 215.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 811664, "time": 38105.49956250191, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 812000, "time": 38118.351643800735, "episode/length": 454.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9802197802197802, "episode/intrinsic_return": 0.0}
{"step": 812592, "time": 38140.09656953812, "episode/length": 307.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 812856, "time": 38150.3488638401, "episode/length": 194.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 813192, "time": 38163.34911322594, "episode/length": 200.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 813272, "time": 38167.69626832008, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 813448, "time": 38175.12963938713, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 814016, "time": 38196.14621567726, "episode/length": 337.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 814032, "time": 38198.25714588165, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 814600, "time": 38218.83216691017, "episode/length": 217.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 814728, "time": 38224.7550368309, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 814832, "time": 38230.12775564194, "episode/length": 353.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 815176, "time": 38243.14003419876, "episode/length": 215.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 815504, "time": 38256.25572633743, "episode/length": 288.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792387543252595, "episode/intrinsic_return": 0.0}
{"step": 815664, "time": 38263.32157301903, "episode/length": 529.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 815856, "time": 38271.297736644745, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 816176, "time": 38283.94006109238, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 816176, "time": 38283.952642679214, "episode/length": 267.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 816344, "time": 38292.794821977615, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 816688, "time": 38306.22795891762, "episode/length": 244.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 816960, "time": 38317.072836875916, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 817296, "time": 38329.986874341965, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 817544, "time": 38339.82450914383, "episode/length": 210.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 817760, "time": 38348.936394929886, "episode/length": 197.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 818040, "time": 38359.68574261665, "episode/length": 211.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 818040, "time": 38359.7022049427, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 818304, "time": 38372.41208076477, "episode/length": 265.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 818720, "time": 38387.92467093468, "episode/length": 219.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 818728, "time": 38389.65735244751, "episode/length": 443.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 818896, "time": 38397.16916561127, "episode/length": 199.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 819176, "time": 38408.79332923889, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 819496, "time": 38422.85897779465, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 819680, "time": 38431.132806777954, "episode/length": 266.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 819712, "time": 38433.748883247375, "episode/length": 243.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 38466.43853807449, "eval_episode/length": 101.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9901960784313726}
{"step": 820040, "time": 38470.862944602966, "eval_episode/length": 163.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9634146341463414}
{"step": 820040, "time": 38473.79646730423, "eval_episode/length": 191.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 820040, "time": 38476.28745532036, "eval_episode/length": 207.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9903846153846154}
{"step": 820040, "time": 38478.32724618912, "eval_episode/length": 218.0, "eval_episode/score": 7.099999964237213, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 820040, "time": 38479.92394709587, "eval_episode/length": 220.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9773755656108597}
{"step": 820040, "time": 38482.843502283096, "eval_episode/length": 245.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9959349593495935}
{"step": 820040, "time": 38485.41439414024, "eval_episode/length": 268.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9962825278810409}
{"step": 820041, "time": 38486.45669054985, "train_stats/sum_log_reward": 6.604854340692168, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 8.16504854368932, "train_stats/max_log_achievement_collect_sapling": 2.4271844660194173, "train_stats/max_log_achievement_collect_stone": 0.02912621359223301, "train_stats/max_log_achievement_collect_wood": 9.233009708737864, "train_stats/max_log_achievement_defeat_skeleton": 0.009708737864077669, "train_stats/max_log_achievement_defeat_zombie": 1.2233009708737863, "train_stats/max_log_achievement_eat_cow": 0.1553398058252427, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05825242718446602, "train_stats/max_log_achievement_make_wood_sword": 1.0097087378640777, "train_stats/max_log_achievement_place_plant": 2.3106796116504853, "train_stats/max_log_achievement_place_stone": 0.02912621359223301, "train_stats/max_log_achievement_place_table": 2.883495145631068, "train_stats/max_log_achievement_wake_up": 1.4077669902912622, "train_stats/mean_log_entropy": 0.644423273581903, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.330042742300725, "train/action_min": 0.0, "train/action_std": 3.2614929209584775, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.043334512040019035, "train/actor_opt_grad_steps": 50465.0, "train/actor_opt_loss": -5.593629289040531, "train/adv_mag": 0.5564874088850574, "train/adv_max": 0.5315229145513065, "train/adv_mean": 0.0029387470126559915, "train/adv_min": -0.41609689787678095, "train/adv_std": 0.06282096671993317, "train/cont_avg": 0.994827049365942, "train/cont_loss_mean": 0.0001964022512195457, "train/cont_loss_std": 0.006016823615950209, "train/cont_neg_acc": 0.9941338862197987, "train/cont_neg_loss": 0.03108883963466434, "train/cont_pos_acc": 0.9999715055244557, "train/cont_pos_loss": 6.991154617522803e-05, "train/cont_pred": 0.9948148839715598, "train/cont_rate": 0.994827049365942, "train/dyn_loss_mean": 12.285930364028268, "train/dyn_loss_std": 9.338437716166178, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7959510256414828, "train/extr_critic_critic_opt_grad_steps": 50465.0, "train/extr_critic_critic_opt_loss": 15898.914366791214, "train/extr_critic_mag": 6.660002362900886, "train/extr_critic_max": 6.660002362900886, "train/extr_critic_mean": 1.6080965382465418, "train/extr_critic_min": -0.3298352067021356, "train/extr_critic_std": 1.4762685152067654, "train/extr_return_normed_mag": 1.6902537414993064, "train/extr_return_normed_max": 1.6902537414993064, "train/extr_return_normed_mean": 0.35076172217942664, "train/extr_return_normed_min": -0.13703072003588296, "train/extr_return_normed_std": 0.323316543214563, "train/extr_return_rate": 0.6856775899296221, "train/extr_return_raw_mag": 7.878887010657269, "train/extr_return_raw_max": 7.878887010657269, "train/extr_return_raw_mean": 1.6218286964340487, "train/extr_return_raw_min": -0.6571676556182944, "train/extr_return_raw_std": 1.510391248309094, "train/extr_reward_mag": 1.0279127031132795, "train/extr_reward_max": 1.0279127031132795, "train/extr_reward_mean": 0.033995255544457745, "train/extr_reward_min": -0.5041374434595522, "train/extr_reward_std": 0.17462403424408124, "train/image_loss_mean": 5.388270599254663, "train/image_loss_std": 10.034447099851524, "train/model_loss_mean": 12.810138578000275, "train/model_loss_std": 13.935145702914916, "train/model_opt_grad_norm": 49.84018439968137, "train/model_opt_grad_steps": 50419.311594202896, "train/model_opt_loss": 16320.412887794384, "train/model_opt_model_opt_grad_overflow": 0.007246376811594203, "train/model_opt_model_opt_grad_scale": 1277.1739130434783, "train/policy_entropy_mag": 2.5666267180788345, "train/policy_entropy_max": 2.5666267180788345, "train/policy_entropy_mean": 0.5925208274005116, "train/policy_entropy_min": 0.07937504453719527, "train/policy_entropy_std": 0.6389669981123745, "train/policy_logprob_mag": 7.4383836449056435, "train/policy_logprob_max": -0.00945566184953719, "train/policy_logprob_mean": -0.5919216806473939, "train/policy_logprob_min": -7.4383836449056435, "train/policy_logprob_std": 1.1266216065572656, "train/policy_randomness_mag": 0.9059065956136455, "train/policy_randomness_max": 0.9059065956136455, "train/policy_randomness_mean": 0.20913385135540064, "train/policy_randomness_min": 0.028015907421924065, "train/policy_randomness_std": 0.22552731082491254, "train/post_ent_mag": 59.92105083189149, "train/post_ent_max": 59.92105083189149, "train/post_ent_mean": 43.511674936266914, "train/post_ent_min": 20.554245948791504, "train/post_ent_std": 7.504920779794887, "train/prior_ent_mag": 69.83906820546026, "train/prior_ent_max": 69.83906820546026, "train/prior_ent_mean": 55.89361013882402, "train/prior_ent_min": 39.70066916424295, "train/prior_ent_std": 4.620794574419658, "train/rep_loss_mean": 12.285930364028268, "train/rep_loss_std": 9.338437716166178, "train/reward_avg": 0.024785580653427303, "train/reward_loss_mean": 0.050113464287225754, "train/reward_loss_std": 0.2262689524154732, "train/reward_max_data": 1.015942032786383, "train/reward_max_pred": 1.0093247182127358, "train/reward_neg_acc": 0.9936574010745339, "train/reward_neg_loss": 0.027095198152127905, "train/reward_pos_acc": 0.9736523308615753, "train/reward_pos_loss": 0.8085417371729146, "train/reward_pred": 0.024253446176864098, "train/reward_rate": 0.029417176177536232, "eval_stats/sum_log_reward": 6.51666663090388, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 8.083333333333334, "eval_stats/max_log_achievement_collect_sapling": 2.7083333333333335, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.958333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.25, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_sword": 0.9166666666666666, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.1666666666666665, "eval_stats/max_log_achievement_wake_up": 1.1666666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.0002655770513229072, "report/cont_loss_std": 0.007472747936844826, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.890090637374669e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00026704694028012455, "report/cont_pred": 0.9919490218162537, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 13.796996116638184, "report/dyn_loss_std": 9.959126472473145, "report/image_loss_mean": 6.383449554443359, "report/image_loss_std": 9.775373458862305, "report/model_loss_mean": 14.710746765136719, "report/model_loss_std": 13.66916561126709, "report/post_ent_mag": 58.73352813720703, "report/post_ent_max": 58.73352813720703, "report/post_ent_mean": 43.01134490966797, "report/post_ent_min": 23.19580841064453, "report/post_ent_std": 7.72605037689209, "report/prior_ent_mag": 69.81883239746094, "report/prior_ent_max": 69.81883239746094, "report/prior_ent_mean": 56.401695251464844, "report/prior_ent_min": 40.34581756591797, "report/prior_ent_std": 4.716746807098389, "report/rep_loss_mean": 13.796996116638184, "report/rep_loss_std": 9.959126472473145, "report/reward_avg": 0.01728515699505806, "report/reward_loss_mean": 0.04883408918976784, "report/reward_loss_std": 0.18208901584148407, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.026590347290039, "report/reward_neg_acc": 0.9939939975738525, "report/reward_neg_loss": 0.03154963627457619, "report/reward_pos_acc": 0.9599999785423279, "report/reward_pos_loss": 0.7395208477973938, "report/reward_pred": 0.016377730295062065, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.3561813577543944e-05, "eval/cont_loss_std": 0.0004966462729498744, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006996458396315575, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.0244426195858978e-05, "eval/cont_pred": 0.9951006174087524, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.123271942138672, "eval/dyn_loss_std": 11.017205238342285, "eval/image_loss_mean": 10.671245574951172, "eval/image_loss_std": 13.192853927612305, "eval/model_loss_mean": 21.642919540405273, "eval/model_loss_std": 17.43988800048828, "eval/post_ent_mag": 57.64097595214844, "eval/post_ent_max": 57.64097595214844, "eval/post_ent_mean": 40.77432632446289, "eval/post_ent_min": 16.857656478881836, "eval/post_ent_std": 7.577944755554199, "eval/prior_ent_mag": 69.81883239746094, "eval/prior_ent_max": 69.81883239746094, "eval/prior_ent_mean": 56.65168762207031, "eval/prior_ent_min": 41.16680908203125, "eval/prior_ent_std": 4.397338390350342, "eval/rep_loss_mean": 18.123271942138672, "eval/rep_loss_std": 11.017205238342285, "eval/reward_avg": 0.04072265699505806, "eval/reward_loss_mean": 0.09768694639205933, "eval/reward_loss_std": 0.5591796636581421, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0015676021575928, "eval/reward_neg_acc": 0.9856703877449036, "eval/reward_neg_loss": 0.034394748508930206, "eval/reward_pos_acc": 0.8723403811454773, "eval/reward_pos_loss": 1.4133566617965698, "eval/reward_pred": 0.040236495435237885, "eval/reward_rate": 0.0458984375, "replay/size": 819537.0, "replay/inserts": 22144.0, "replay/samples": 22144.0, "replay/insert_wait_avg": 1.4131770313130637e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.340774243966693e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5992.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2257945871798792e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1035.6497359275818, "timer/env.step_count": 2768.0, "timer/env.step_total": 246.77843189239502, "timer/env.step_frac": 0.23828368156862167, "timer/env.step_avg": 0.08915405776459358, "timer/env.step_min": 0.024585723876953125, "timer/env.step_max": 3.5138161182403564, "timer/replay._sample_count": 22144.0, "timer/replay._sample_total": 11.5722177028656, "timer/replay._sample_frac": 0.011173872112757235, "timer/replay._sample_avg": 0.000522589311003685, "timer/replay._sample_min": 0.00038123130798339844, "timer/replay._sample_max": 0.00843358039855957, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3517.0, "timer/agent.policy_total": 61.512866258621216, "timer/agent.policy_frac": 0.05939543469639095, "timer/agent.policy_avg": 0.017490152476150475, "timer/agent.policy_min": 0.009832382202148438, "timer/agent.policy_max": 0.18268346786499023, "timer/dataset_train_count": 1384.0, "timer/dataset_train_total": 0.16631412506103516, "timer/dataset_train_frac": 0.000160589163779466, "timer/dataset_train_avg": 0.00012016916550652829, "timer/dataset_train_min": 0.00010561943054199219, "timer/dataset_train_max": 0.0005981922149658203, "timer/agent.train_count": 1384.0, "timer/agent.train_total": 623.9566977024078, "timer/agent.train_frac": 0.6024784983347288, "timer/agent.train_avg": 0.4508357642358438, "timer/agent.train_min": 0.43605828285217285, "timer/agent.train_max": 1.7086734771728516, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48074984550476074, "timer/agent.report_frac": 0.00046420119546902234, "timer/agent.report_avg": 0.24037492275238037, "timer/agent.report_min": 0.2322704792022705, "timer/agent.report_max": 0.24847936630249023, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 2.9006661156429324e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 21.381444800952767}
{"step": 820112, "time": 38489.04925084114, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 820200, "time": 38493.353633880615, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 820304, "time": 38498.71773099899, "episode/length": 249.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 820624, "time": 38510.94043016434, "episode/length": 52.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 820992, "time": 38525.09962081909, "episode/length": 226.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 820992, "time": 38525.107410907745, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 821328, "time": 38539.79361605644, "episode/length": 410.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9902676399026764, "episode/intrinsic_return": 0.0}
{"step": 821600, "time": 38550.6238694191, "episode/length": 235.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 821616, "time": 38552.699900865555, "episode/length": 264.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 821752, "time": 38558.5694360733, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 821896, "time": 38564.93497776985, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 822312, "time": 38580.686488866806, "episode/length": 210.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 822560, "time": 38590.82915139198, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 822824, "time": 38600.959580898285, "episode/length": 228.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 822960, "time": 38607.21317768097, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 823048, "time": 38611.64106464386, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 823176, "time": 38617.55928182602, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 823464, "time": 38628.83034777641, "episode/length": 143.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 823888, "time": 38645.79058885574, "episode/length": 165.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 824160, "time": 38656.51369166374, "episode/length": 138.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 824864, "time": 38681.85866570473, "episode/length": 405.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 824944, "time": 38686.08705687523, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9891891891891892, "episode/intrinsic_return": 0.0}
{"step": 824992, "time": 38689.325060606, "episode/length": 226.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 825168, "time": 38696.820452451706, "episode/length": 445.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798206278026906, "episode/intrinsic_return": 0.0}
{"step": 825536, "time": 38710.97628259659, "episode/length": 321.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 825576, "time": 38713.779749155045, "episode/length": 210.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 825784, "time": 38722.356790304184, "episode/length": 369.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 825816, "time": 38725.09598708153, "episode/length": 206.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 826432, "time": 38747.783358335495, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 826792, "time": 38761.491868019104, "episode/length": 240.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 826912, "time": 38767.306069374084, "episode/length": 217.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 827040, "time": 38773.029445171356, "episode/length": 261.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 827368, "time": 38785.4676759243, "episode/length": 40.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 827568, "time": 38795.76775550842, "episode/length": 248.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 827592, "time": 38797.85265445709, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 828160, "time": 38818.90470170975, "episode/length": 292.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761092150170648, "episode/intrinsic_return": 0.0}
{"step": 828184, "time": 38821.10668635368, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 828472, "time": 38832.56440591812, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 829112, "time": 38856.30105948448, "episode/length": 446.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9977628635346756, "episode/intrinsic_return": 0.0}
{"step": 829176, "time": 38860.04025435448, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 829488, "time": 38872.28918862343, "episode/length": 236.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 829632, "time": 38878.791922330856, "episode/length": 257.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 829752, "time": 38884.22202730179, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 38914.72816681862, "eval_episode/length": 156.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 830024, "time": 38916.39624905586, "eval_episode/length": 157.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 830024, "time": 38918.308344602585, "eval_episode/length": 165.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 830024, "time": 38923.13328194618, "eval_episode/length": 235.0, "eval_episode/score": 7.099999964237213, "eval_episode/reward_rate": 0.9915254237288136}
{"step": 830024, "time": 38924.91538763046, "eval_episode/length": 240.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.995850622406639}
{"step": 830024, "time": 38928.2011590004, "eval_episode/length": 278.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.982078853046595}
{"step": 830024, "time": 38930.31752514839, "eval_episode/length": 291.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9965753424657534}
{"step": 830024, "time": 38932.21865820885, "eval_episode/length": 299.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.98}
{"step": 830376, "time": 38944.187680244446, "episode/length": 432.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9976905311778291, "episode/intrinsic_return": 0.0}
{"step": 830568, "time": 38952.17422962189, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 830648, "time": 38956.50970864296, "episode/length": 271.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 830968, "time": 38968.98045158386, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 831048, "time": 38973.28400707245, "episode/length": 241.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 831152, "time": 38979.07156777382, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 831552, "time": 38994.00660586357, "episode/length": 224.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 831696, "time": 39000.49497127533, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 831816, "time": 39005.91560602188, "episode/length": 456.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9803063457330415, "episode/intrinsic_return": 0.0}
{"step": 832488, "time": 39030.38408923149, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 832512, "time": 39033.0394821167, "episode/length": 232.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 832712, "time": 39041.151010513306, "episode/length": 267.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 832776, "time": 39044.8389582634, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 832784, "time": 39046.89032793045, "episode/length": 216.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 833312, "time": 39066.365794181824, "episode/length": 219.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 833344, "time": 39069.03284692764, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 833544, "time": 39077.12659239769, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 833808, "time": 39087.8293428421, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 833808, "time": 39087.86003661156, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 834208, "time": 39104.56057858467, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 835048, "time": 39134.84464883804, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 835104, "time": 39138.50490999222, "episode/length": 223.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 835320, "time": 39147.113146305084, "episode/length": 316.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9810725552050473, "episode/intrinsic_return": 0.0}
{"step": 835584, "time": 39158.268832445145, "episode/length": 350.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 835640, "time": 39163.24793505669, "episode/length": 261.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 835704, "time": 39167.0091946125, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 835896, "time": 39175.03793025017, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 836176, "time": 39186.39012694359, "episode/length": 58.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 836704, "time": 39205.67661476135, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 837000, "time": 39217.21138501167, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 837048, "time": 39220.30757212639, "episode/length": 215.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 837112, "time": 39224.03582382202, "episode/length": 190.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 837336, "time": 39233.02720093727, "episode/length": 41.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 837768, "time": 39249.36153841019, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 837952, "time": 39257.44512987137, "episode/length": 517.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9980694980694981, "episode/intrinsic_return": 0.0}
{"step": 838104, "time": 39263.91752696037, "episode/length": 240.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 838424, "time": 39276.33249640465, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 838520, "time": 39281.168354034424, "episode/length": 147.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 838552, "time": 39283.84755373001, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 838632, "time": 39288.1173119545, "episode/length": 440.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9977324263038548, "episode/intrinsic_return": 0.0}
{"step": 838896, "time": 39299.108650922775, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 839176, "time": 39309.942091703415, "episode/length": 175.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 839640, "time": 39327.23043394089, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 839808, "time": 39334.85357451439, "episode/length": 212.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 839952, "time": 39341.72417426109, "episode/length": 190.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 39367.79858136177, "eval_episode/length": 169.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 840008, "time": 39369.4125828743, "eval_episode/length": 170.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 840008, "time": 39371.2627055645, "eval_episode/length": 176.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 840008, "time": 39374.23992753029, "eval_episode/length": 206.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 840008, "time": 39376.0895113945, "eval_episode/length": 211.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 840008, "time": 39379.405029296875, "eval_episode/length": 248.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 840008, "time": 39384.46957159042, "eval_episode/length": 323.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9876543209876543}
{"step": 840008, "time": 39386.318927288055, "eval_episode/length": 157.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 840088, "time": 39389.14274930954, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 840152, "time": 39392.95108437538, "episode/length": 199.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 840440, "time": 39406.44847846031, "episode/length": 239.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 840528, "time": 39411.246586084366, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 841088, "time": 39431.733013391495, "episode/length": 238.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 841120, "time": 39434.46453881264, "episode/length": 184.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 841272, "time": 39441.03440737724, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 841296, "time": 39443.61953210831, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 841568, "time": 39454.41033697128, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 841936, "time": 39468.28928208351, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 841944, "time": 39469.86326479912, "episode/length": 231.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 842136, "time": 39478.12531208992, "episode/length": 200.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 842313, "time": 39486.69774723053, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.243990013067671, "train/action_min": 0.0, "train/action_std": 3.250960168221014, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044995053530597004, "train/actor_opt_grad_steps": 51850.0, "train/actor_opt_loss": -7.33182939318873, "train/adv_mag": 0.5598735845775056, "train/adv_max": 0.5374181525741549, "train/adv_mean": 0.0031515948198928448, "train/adv_min": -0.41589009504524066, "train/adv_std": 0.06429674910555641, "train/cont_avg": 0.9944216501798561, "train/cont_loss_mean": 0.00019286627756854706, "train/cont_loss_std": 0.005801214643541754, "train/cont_neg_acc": 0.9955035975511125, "train/cont_neg_loss": 0.014509275775165295, "train/cont_pos_acc": 0.9999574971713608, "train/cont_pos_loss": 0.0001162204581644115, "train/cont_pred": 0.9944192364061479, "train/cont_rate": 0.9944216501798561, "train/dyn_loss_mean": 12.2843637191992, "train/dyn_loss_std": 9.32197979714373, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7992468860080774, "train/extr_critic_critic_opt_grad_steps": 51850.0, "train/extr_critic_critic_opt_loss": 16004.808474314299, "train/extr_critic_mag": 6.694404787296872, "train/extr_critic_max": 6.694404787296872, "train/extr_critic_mean": 1.6497974412904368, "train/extr_critic_min": -0.3328195072764115, "train/extr_critic_std": 1.5404080023868478, "train/extr_return_normed_mag": 1.6861445509272515, "train/extr_return_normed_max": 1.6861445509272515, "train/extr_return_normed_mean": 0.3605989422515142, "train/extr_return_normed_min": -0.1279939941311483, "train/extr_return_normed_std": 0.33261727439842637, "train/extr_return_rate": 0.67719858992014, "train/extr_return_raw_mag": 7.947278441285058, "train/extr_return_raw_max": 7.947278441285058, "train/extr_return_raw_mean": 1.664743683321013, "train/extr_return_raw_min": -0.6512301555640406, "train/extr_return_raw_std": 1.5766173541117057, "train/extr_reward_mag": 1.0285430177510213, "train/extr_reward_max": 1.0285430177510213, "train/extr_reward_mean": 0.036529587514752104, "train/extr_reward_min": -0.4870720252716284, "train/extr_reward_std": 0.18199019155485166, "train/image_loss_mean": 5.339979758365549, "train/image_loss_std": 10.167091551444514, "train/model_loss_mean": 12.762783482777987, "train/model_loss_std": 14.015291611925303, "train/model_opt_grad_norm": 49.486843814020574, "train/model_opt_grad_steps": 51802.89208633093, "train/model_opt_loss": 16173.689871149954, "train/model_opt_model_opt_grad_overflow": 0.007194244604316547, "train/model_opt_model_opt_grad_scale": 1258.9928057553957, "train/policy_entropy_mag": 2.5563688792770716, "train/policy_entropy_max": 2.5563688792770716, "train/policy_entropy_mean": 0.5928177353289488, "train/policy_entropy_min": 0.07937505117637648, "train/policy_entropy_std": 0.6280964387835358, "train/policy_logprob_mag": 7.438383613558982, "train/policy_logprob_max": -0.00945566011686548, "train/policy_logprob_mean": -0.5921194493341789, "train/policy_logprob_min": -7.438383613558982, "train/policy_logprob_std": 1.1263811451068027, "train/policy_randomness_mag": 0.9022860329785793, "train/policy_randomness_max": 0.9022860329785793, "train/policy_randomness_mean": 0.20923864552014165, "train/policy_randomness_min": 0.02801590985049018, "train/policy_randomness_std": 0.22169048172964467, "train/post_ent_mag": 59.9306666696672, "train/post_ent_max": 59.9306666696672, "train/post_ent_mean": 43.56006284754911, "train/post_ent_min": 20.501666638490963, "train/post_ent_std": 7.553748185686071, "train/prior_ent_mag": 69.94026881156208, "train/prior_ent_max": 69.94026881156208, "train/prior_ent_mean": 55.896252446895026, "train/prior_ent_min": 39.23692944753084, "train/prior_ent_std": 4.619741287162836, "train/rep_loss_mean": 12.2843637191992, "train/rep_loss_std": 9.32197979714373, "train/reward_avg": 0.026282879698137158, "train/reward_loss_mean": 0.05199271033136107, "train/reward_loss_std": 0.23500542707151648, "train/reward_max_data": 1.0129496433752045, "train/reward_max_pred": 1.0087778105152596, "train/reward_neg_acc": 0.9937174144408686, "train/reward_neg_loss": 0.027416144464191772, "train/reward_pos_acc": 0.9715378910517521, "train/reward_pos_loss": 0.8190097928904801, "train/reward_pred": 0.02565804196240233, "train/reward_rate": 0.031165692446043166, "train_stats/sum_log_reward": 6.850000011920929, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.23, "train_stats/max_log_achievement_collect_sapling": 2.9, "train_stats/max_log_achievement_collect_stone": 0.14, "train_stats/max_log_achievement_collect_wood": 9.46, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 1.37, "train_stats/max_log_achievement_eat_cow": 0.2, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07, "train_stats/max_log_achievement_make_wood_sword": 0.99, "train_stats/max_log_achievement_place_plant": 2.69, "train_stats/max_log_achievement_place_stone": 0.07, "train_stats/max_log_achievement_place_table": 2.89, "train_stats/max_log_achievement_wake_up": 1.54, "train_stats/mean_log_entropy": 0.6562307538092136, "train_stats/max_log_achievement_place_furnace": 0.010638297872340425, "eval_stats/sum_log_reward": 7.162500083446503, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 7.5625, "eval_stats/max_log_achievement_collect_sapling": 3.0625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 9.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.5, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.9375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.875, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0002501269627828151, "report/cont_loss_std": 0.00711526395753026, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.008186628110706806, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00023459564545191824, "report/cont_pred": 0.9978521466255188, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 11.79617691040039, "report/dyn_loss_std": 8.991954803466797, "report/image_loss_mean": 5.411110877990723, "report/image_loss_std": 11.558300018310547, "report/model_loss_mean": 12.529520034790039, "report/model_loss_std": 15.104726791381836, "report/post_ent_mag": 59.78396224975586, "report/post_ent_max": 59.78396224975586, "report/post_ent_mean": 44.0230827331543, "report/post_ent_min": 17.853796005249023, "report/post_ent_std": 7.843074798583984, "report/prior_ent_mag": 69.47120666503906, "report/prior_ent_max": 69.47120666503906, "report/prior_ent_mean": 56.331939697265625, "report/prior_ent_min": 44.28895950317383, "report/prior_ent_std": 4.028971195220947, "report/rep_loss_mean": 11.79617691040039, "report/rep_loss_std": 8.991954803466797, "report/reward_avg": 0.02519531175494194, "report/reward_loss_mean": 0.0404529832303524, "report/reward_loss_std": 0.2350338250398636, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0122389793395996, "report/reward_neg_acc": 0.9979920387268066, "report/reward_neg_loss": 0.013286706060171127, "report/reward_pos_acc": 0.9285714626312256, "report/reward_pos_loss": 1.0067963600158691, "report/reward_pred": 0.022042054682970047, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0003798315301537514, "eval/cont_loss_std": 0.008709356188774109, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00036550950608216226, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0003799018159043044, "eval/cont_pred": 0.9947762489318848, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.566844940185547, "eval/dyn_loss_std": 10.86616325378418, "eval/image_loss_mean": 8.165712356567383, "eval/image_loss_std": 11.066706657409668, "eval/model_loss_mean": 18.244586944580078, "eval/model_loss_std": 15.31550121307373, "eval/post_ent_mag": 58.97335433959961, "eval/post_ent_max": 58.97335433959961, "eval/post_ent_mean": 42.32731246948242, "eval/post_ent_min": 18.038808822631836, "eval/post_ent_std": 7.832270622253418, "eval/prior_ent_mag": 69.47120666503906, "eval/prior_ent_max": 69.47120666503906, "eval/prior_ent_mean": 56.70182800292969, "eval/prior_ent_min": 41.02981948852539, "eval/prior_ent_std": 4.564974784851074, "eval/rep_loss_mean": 16.566844940185547, "eval/rep_loss_std": 10.86616325378418, "eval/reward_avg": 0.04521484300494194, "eval/reward_loss_mean": 0.13838809728622437, "eval/reward_loss_std": 0.8116140961647034, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.041846513748169, "eval/reward_neg_acc": 0.9907597899436951, "eval/reward_neg_loss": 0.034499552100896835, "eval/reward_pos_acc": 0.7999999523162842, "eval/reward_pos_loss": 2.162137031555176, "eval/reward_pred": 0.03703097999095917, "eval/reward_rate": 0.048828125, "replay/size": 841809.0, "replay/inserts": 22272.0, "replay/samples": 22272.0, "replay/insert_wait_avg": 1.4132231302645014e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.37430272294187e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5024.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2322406100619371e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.229611158371, "timer/env.step_count": 2784.0, "timer/env.step_total": 239.89230871200562, "timer/env.step_frac": 0.2398372394056452, "timer/env.step_avg": 0.08616821433620891, "timer/env.step_min": 0.024483442306518555, "timer/env.step_max": 3.364119291305542, "timer/replay._sample_count": 22272.0, "timer/replay._sample_total": 11.64557695388794, "timer/replay._sample_frac": 0.011642903613302488, "timer/replay._sample_avg": 0.0005228797123692501, "timer/replay._sample_min": 0.0003731250762939453, "timer/replay._sample_max": 0.025069236755371094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3412.0, "timer/agent.policy_total": 60.56603121757507, "timer/agent.policy_frac": 0.0605521277733752, "timer/agent.policy_avg": 0.017750888399054827, "timer/agent.policy_min": 0.009625911712646484, "timer/agent.policy_max": 0.1312868595123291, "timer/dataset_train_count": 1392.0, "timer/dataset_train_total": 0.16736960411071777, "timer/dataset_train_frac": 0.00016733118300395666, "timer/dataset_train_avg": 0.00012023678456229726, "timer/dataset_train_min": 0.00010538101196289062, "timer/dataset_train_max": 0.00054168701171875, "timer/agent.train_count": 1392.0, "timer/agent.train_total": 628.1579973697662, "timer/agent.train_frac": 0.628013798394044, "timer/agent.train_avg": 0.45126292914494703, "timer/agent.train_min": 0.43845295906066895, "timer/agent.train_max": 2.60668683052063, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4733154773712158, "timer/agent.report_frac": 0.00047320682380425305, "timer/agent.report_avg": 0.2366577386856079, "timer/agent.report_min": 0.229231595993042, "timer/agent.report_max": 0.24408388137817383, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.267692565917969e-05, "timer/dataset_eval_frac": 4.266712881030919e-08, "timer/dataset_eval_avg": 4.267692565917969e-05, "timer/dataset_eval_min": 4.267692565917969e-05, "timer/dataset_eval_max": 4.267692565917969e-05, "fps": 22.26658095970645}
{"step": 842672, "time": 39498.90211844444, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 842976, "time": 39510.88941550255, "episode/length": 37.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 842976, "time": 39510.89780664444, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 843320, "time": 39525.43311691284, "episode/length": 218.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 843576, "time": 39535.750626802444, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 843600, "time": 39538.43882250786, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 843760, "time": 39545.41754198074, "episode/length": 310.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.977491961414791, "episode/intrinsic_return": 0.0}
{"step": 844008, "time": 39556.7070980072, "episode/length": 50.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 844264, "time": 39566.808925151825, "episode/length": 31.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.0}
{"step": 844392, "time": 39572.791857242584, "episode/length": 412.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9903147699757869, "episode/intrinsic_return": 0.0}
{"step": 844704, "time": 39585.11678171158, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 845096, "time": 39599.79445576668, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 845200, "time": 39605.1108379364, "episode/length": 234.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 845400, "time": 39613.20501327515, "episode/length": 302.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9933993399339934, "episode/intrinsic_return": 0.0}
{"step": 845504, "time": 39618.36244368553, "episode/length": 37.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 845976, "time": 39635.695697784424, "episode/length": 276.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 846216, "time": 39645.614535331726, "episode/length": 509.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9921568627450981, "episode/intrinsic_return": 0.0}
{"step": 846272, "time": 39649.36203622818, "episode/length": 250.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 846440, "time": 39656.45543265343, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9631336405529954, "episode/intrinsic_return": 0.0}
{"step": 846624, "time": 39664.73913311958, "episode/length": 190.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 847072, "time": 39681.32595515251, "episode/length": 334.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.0}
{"step": 847152, "time": 39685.65643286705, "episode/length": 218.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 847624, "time": 39702.99576663971, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 847800, "time": 39710.4089281559, "episode/length": 90.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9560439560439561, "episode/intrinsic_return": 0.0}
{"step": 847808, "time": 39712.606357097626, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 847912, "time": 39717.5294148922, "episode/length": 35.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 847920, "time": 39719.68747520447, "episode/length": 301.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 848096, "time": 39727.34246754646, "episode/length": 264.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 848168, "time": 39731.142015218735, "episode/length": 45.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 848256, "time": 39735.93314695358, "episode/length": 41.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 848808, "time": 39755.94910573959, "episode/length": 206.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 848872, "time": 39759.67436861992, "episode/length": 280.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9750889679715302, "episode/intrinsic_return": 0.0}
{"step": 848896, "time": 39762.309926986694, "episode/length": 135.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 849704, "time": 39790.93789744377, "episode/length": 428.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9906759906759907, "episode/intrinsic_return": 0.0}
{"step": 849960, "time": 39801.13932847977, "episode/length": 232.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 850048, "time": 39805.9624581337, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 39829.654938697815, "eval_episode/length": 143.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 850096, "time": 39831.6947760582, "eval_episode/length": 153.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 850096, "time": 39834.20226073265, "eval_episode/length": 172.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 850096, "time": 39838.92015385628, "eval_episode/length": 237.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 850096, "time": 39840.89694285393, "eval_episode/length": 245.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.983739837398374}
{"step": 850096, "time": 39843.463165044785, "eval_episode/length": 264.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9962264150943396}
{"step": 850096, "time": 39847.33387541771, "eval_episode/length": 172.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 850096, "time": 39853.46903538704, "eval_episode/length": 179.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9611111111111111}
{"step": 850152, "time": 39855.13644695282, "episode/length": 236.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 850224, "time": 39859.356553316116, "episode/length": 288.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 850504, "time": 39870.15323162079, "episode/length": 200.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 850976, "time": 39887.93595314026, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 851232, "time": 39898.23077630997, "episode/length": 294.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 851352, "time": 39903.65941762924, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 851456, "time": 39908.93778038025, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 851536, "time": 39913.21123170853, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 851968, "time": 39929.60588145256, "episode/length": 217.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 852432, "time": 39948.57951426506, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 852552, "time": 39953.99926280975, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 852864, "time": 39966.44152998924, "episode/length": 38.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 853144, "time": 39977.38773417473, "episode/length": 223.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 853216, "time": 39981.54157161713, "episode/length": 155.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 853656, "time": 39997.953137636185, "episode/length": 334.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 853848, "time": 40006.08204960823, "episode/length": 288.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757785467128027, "episode/intrinsic_return": 0.0}
{"step": 853984, "time": 40012.447696208954, "episode/length": 646.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9860896445131375, "episode/intrinsic_return": 0.0}
{"step": 854000, "time": 40014.580327034, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 854600, "time": 40036.41000199318, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 854632, "time": 40039.1069188118, "episode/length": 220.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 855040, "time": 40054.76262497902, "episode/length": 447.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 855088, "time": 40057.98487687111, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9658119658119658, "episode/intrinsic_return": 0.0}
{"step": 855448, "time": 40071.48000359535, "episode/length": 223.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 855480, "time": 40074.111105918884, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 855768, "time": 40085.51068639755, "episode/length": 222.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 855936, "time": 40092.89690876007, "episode/length": 241.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 855952, "time": 40095.02306461334, "episode/length": 168.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 856032, "time": 40099.101996421814, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 856256, "time": 40108.30136537552, "episode/length": 145.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 856752, "time": 40126.53094291687, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 856816, "time": 40130.405583143234, "episode/length": 170.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 857024, "time": 40139.046311855316, "episode/length": 192.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 857320, "time": 40150.37406373024, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 857488, "time": 40157.934113025665, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 857520, "time": 40160.58869552612, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 857896, "time": 40174.77504634857, "episode/length": 244.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 858008, "time": 40180.14567923546, "episode/length": 156.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 858136, "time": 40186.09826993942, "episode/length": 234.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 858136, "time": 40186.10712647438, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 858280, "time": 40194.21618247032, "episode/length": 33.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 858680, "time": 40209.43197059631, "episode/length": 148.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 859080, "time": 40224.56191968918, "episode/length": 256.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 859464, "time": 40239.393638134, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 859568, "time": 40244.817240953445, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 859600, "time": 40247.39499545097, "episode/length": 284.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 859736, "time": 40253.54489469528, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 40287.484461307526, "eval_episode/length": 144.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9793103448275862}
{"step": 860080, "time": 40290.119126319885, "eval_episode/length": 163.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 860080, "time": 40292.57784199715, "eval_episode/length": 181.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 860080, "time": 40294.496171712875, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 860080, "time": 40296.63325023651, "eval_episode/length": 201.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.995049504950495}
{"step": 860080, "time": 40298.59367775917, "eval_episode/length": 208.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 860080, "time": 40300.247650146484, "eval_episode/length": 210.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 860080, "time": 40302.600895404816, "eval_episode/length": 39.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 860232, "time": 40309.071430683136, "episode/length": 243.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 860360, "time": 40314.98418354988, "episode/length": 209.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 860920, "time": 40335.6060693264, "episode/length": 424.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9929411764705882, "episode/intrinsic_return": 0.0}
{"step": 860976, "time": 40339.309797525406, "episode/length": 236.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 861008, "time": 40341.940977334976, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 861016, "time": 40343.54442024231, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 861104, "time": 40348.41511178017, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 861584, "time": 40366.491755485535, "episode/length": 152.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 862280, "time": 40391.82426857948, "episode/length": 255.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 862456, "time": 40399.346982479095, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 862776, "time": 40411.96534991264, "episode/length": 396.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9874055415617129, "episode/intrinsic_return": 0.0}
{"step": 862872, "time": 40417.386906147, "episode/length": 236.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 862888, "time": 40419.94900941849, "episode/length": 245.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 862936, "time": 40423.56074857712, "episode/length": 240.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 863024, "time": 40428.865032196045, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 863248, "time": 40438.67202210426, "episode/length": 267.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 863840, "time": 40460.166778326035, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 864040, "time": 40468.28701257706, "episode/length": 219.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 864440, "time": 40483.71767282486, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 864457, "time": 40486.87983250618, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.361307487213354, "train/action_min": 0.0, "train/action_std": 3.3035540975255073, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04380775271184582, "train/actor_opt_grad_steps": 53240.0, "train/actor_opt_loss": -8.941072953560075, "train/adv_mag": 0.5704923300005549, "train/adv_max": 0.5293456719076033, "train/adv_mean": 0.002473267388843936, "train/adv_min": -0.45298169864167415, "train/adv_std": 0.06332053552321393, "train/cont_avg": 0.9944989321043165, "train/cont_loss_mean": 0.00016063865955005758, "train/cont_loss_std": 0.004782842147607436, "train/cont_neg_acc": 0.9955464215587368, "train/cont_neg_loss": 0.014751211587647847, "train/cont_pos_acc": 0.9999716980851812, "train/cont_pos_loss": 6.727802893334128e-05, "train/cont_pred": 0.9944958077917854, "train/cont_rate": 0.9944989321043165, "train/dyn_loss_mean": 12.064959773056799, "train/dyn_loss_std": 9.318079571072147, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8088438219303707, "train/extr_critic_critic_opt_grad_steps": 53240.0, "train/extr_critic_critic_opt_loss": 15814.555980215828, "train/extr_critic_mag": 6.620036821571185, "train/extr_critic_max": 6.620036821571185, "train/extr_critic_mean": 1.5394174971168848, "train/extr_critic_min": -0.34015349261194683, "train/extr_critic_std": 1.5091756247788024, "train/extr_return_normed_mag": 1.686864563029447, "train/extr_return_normed_max": 1.686864563029447, "train/extr_return_normed_mean": 0.3479794801996766, "train/extr_return_normed_min": -0.13195059794208985, "train/extr_return_normed_std": 0.33191917375694935, "train/extr_return_rate": 0.6501105725765228, "train/extr_return_raw_mag": 7.762265064733492, "train/extr_return_raw_max": 7.762265064733492, "train/extr_return_raw_mean": 1.5508984653212183, "train/extr_return_raw_min": -0.6758704873726522, "train/extr_return_raw_std": 1.5399552240646144, "train/extr_reward_mag": 1.0304973983078551, "train/extr_reward_max": 1.0304973983078551, "train/extr_reward_mean": 0.03556578239198211, "train/extr_reward_min": -0.5245473633567206, "train/extr_reward_std": 0.1795794089063466, "train/image_loss_mean": 5.277221753442888, "train/image_loss_std": 10.099632132825233, "train/model_loss_mean": 12.568407010689056, "train/model_loss_std": 13.963477958020546, "train/model_opt_grad_norm": 49.44980029922595, "train/model_opt_grad_steps": 53192.0, "train/model_opt_loss": 12502.150113112635, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 998.2014388489208, "train/policy_entropy_mag": 2.563949056666532, "train/policy_entropy_max": 2.563949056666532, "train/policy_entropy_mean": 0.632521653132473, "train/policy_entropy_min": 0.07937506516631558, "train/policy_entropy_std": 0.6750106991623803, "train/policy_logprob_mag": 7.438383634141881, "train/policy_logprob_max": -0.009455667775151113, "train/policy_logprob_mean": -0.6323301635628982, "train/policy_logprob_min": -7.438383634141881, "train/policy_logprob_std": 1.1582437119037985, "train/policy_randomness_mag": 0.9049615010940771, "train/policy_randomness_max": 0.9049615010940771, "train/policy_randomness_mean": 0.22325238703394965, "train/policy_randomness_min": 0.028015914674607113, "train/policy_randomness_std": 0.23824915515004302, "train/post_ent_mag": 60.013703188450215, "train/post_ent_max": 60.013703188450215, "train/post_ent_mean": 43.784360515127936, "train/post_ent_min": 20.519072477766077, "train/post_ent_std": 7.573095530914745, "train/prior_ent_mag": 69.88179910783288, "train/prior_ent_max": 69.88179910783288, "train/prior_ent_mean": 55.928605086511844, "train/prior_ent_min": 38.99475883922989, "train/prior_ent_std": 4.63645294415865, "train/rep_loss_mean": 12.064959773056799, "train/rep_loss_std": 9.318079571072147, "train/reward_avg": 0.024640990200070597, "train/reward_loss_mean": 0.05204881698214751, "train/reward_loss_std": 0.24065680158652847, "train/reward_max_data": 1.0136690680071605, "train/reward_max_pred": 1.0088107697397686, "train/reward_neg_acc": 0.9935036824761535, "train/reward_neg_loss": 0.028422621889508885, "train/reward_pos_acc": 0.9727286533486071, "train/reward_pos_loss": 0.8306338263930176, "train/reward_pred": 0.02405814498850553, "train/reward_rate": 0.02968328462230216, "train_stats/sum_log_reward": 6.773267358836561, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.7227722772277225, "train_stats/max_log_achievement_collect_sapling": 3.0792079207920793, "train_stats/max_log_achievement_collect_stone": 0.07920792079207921, "train_stats/max_log_achievement_collect_wood": 9.029702970297029, "train_stats/max_log_achievement_defeat_skeleton": 0.009900990099009901, "train_stats/max_log_achievement_defeat_zombie": 1.316831683168317, "train_stats/max_log_achievement_eat_cow": 0.1485148514851485, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.19801980198019803, "train_stats/max_log_achievement_make_wood_sword": 1.0693069306930694, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.881188118811881, "train_stats/max_log_achievement_place_stone": 0.04950495049504951, "train_stats/max_log_achievement_place_table": 2.98019801980198, "train_stats/max_log_achievement_wake_up": 1.4752475247524752, "train_stats/mean_log_entropy": 0.6685387170550847, "eval_stats/sum_log_reward": 6.975000113248825, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.625, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 7.939419447211549e-06, "report/cont_loss_std": 0.0001682172587607056, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0008379716309718788, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.2263163828029064e-06, "report/cont_pred": 0.9931676387786865, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.751457214355469, "report/dyn_loss_std": 9.768784523010254, "report/image_loss_mean": 7.055930137634277, "report/image_loss_std": 12.779413223266602, "report/model_loss_mean": 14.771261215209961, "report/model_loss_std": 16.608600616455078, "report/post_ent_mag": 59.58025360107422, "report/post_ent_max": 59.58025360107422, "report/post_ent_mean": 43.24757385253906, "report/post_ent_min": 19.678081512451172, "report/post_ent_std": 7.734588146209717, "report/prior_ent_mag": 69.5600357055664, "report/prior_ent_max": 69.5600357055664, "report/prior_ent_mean": 56.32910919189453, "report/prior_ent_min": 41.83174133300781, "report/prior_ent_std": 4.3618245124816895, "report/rep_loss_mean": 12.751457214355469, "report/rep_loss_std": 9.768784523010254, "report/reward_avg": 0.02675781212747097, "report/reward_loss_mean": 0.06444897502660751, "report/reward_loss_std": 0.4389447569847107, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0016436576843262, "report/reward_neg_acc": 0.9909182786941528, "report/reward_neg_loss": 0.02562244050204754, "report/reward_pos_acc": 0.939393937587738, "report/reward_pos_loss": 1.230421543121338, "report/reward_pred": 0.024703724309802055, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 7.880258635850623e-06, "eval/cont_loss_std": 0.00020516283984761685, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0033429984468966722, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.3536088090404519e-06, "eval/cont_pred": 0.9980521202087402, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.14236068725586, "eval/dyn_loss_std": 10.516526222229004, "eval/image_loss_mean": 9.775269508361816, "eval/image_loss_std": 13.750125885009766, "eval/model_loss_mean": 20.170272827148438, "eval/model_loss_std": 17.94047737121582, "eval/post_ent_mag": 60.083919525146484, "eval/post_ent_max": 60.083919525146484, "eval/post_ent_mean": 41.452545166015625, "eval/post_ent_min": 18.759273529052734, "eval/post_ent_std": 7.684168815612793, "eval/prior_ent_mag": 69.5600357055664, "eval/prior_ent_max": 69.5600357055664, "eval/prior_ent_mean": 57.15486145019531, "eval/prior_ent_min": 43.316158294677734, "eval/prior_ent_std": 4.713179111480713, "eval/rep_loss_mean": 17.14236068725586, "eval/rep_loss_std": 10.516526222229004, "eval/reward_avg": 0.03564453125, "eval/reward_loss_mean": 0.10957936197519302, "eval/reward_loss_std": 0.6481088399887085, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9994120597839355, "eval/reward_neg_acc": 0.9827236533164978, "eval/reward_neg_loss": 0.03322138264775276, "eval/reward_pos_acc": 0.7750000357627869, "eval/reward_pos_loss": 1.987985610961914, "eval/reward_pred": 0.028663933277130127, "eval/reward_rate": 0.0390625, "replay/size": 863953.0, "replay/inserts": 22144.0, "replay/samples": 22144.0, "replay/insert_wait_avg": 1.4119711569967987e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.278434848509772e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5184.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2129269264362477e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1695544719696, "timer/env.step_count": 2768.0, "timer/env.step_total": 243.90506267547607, "timer/env.step_frac": 0.24386371449213282, "timer/env.step_avg": 0.08811599085096679, "timer/env.step_min": 0.024420499801635742, "timer/env.step_max": 3.4123904705047607, "timer/replay._sample_count": 22144.0, "timer/replay._sample_total": 11.537988424301147, "timer/replay._sample_frac": 0.011536032438412428, "timer/replay._sample_avg": 0.0005210435523979926, "timer/replay._sample_min": 0.0004258155822753906, "timer/replay._sample_max": 0.011377334594726562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3416.0, "timer/agent.policy_total": 59.35511803627014, "timer/agent.policy_frac": 0.05934505581666714, "timer/agent.policy_avg": 0.017375620034036927, "timer/agent.policy_min": 0.009761333465576172, "timer/agent.policy_max": 0.12887144088745117, "timer/dataset_train_count": 1384.0, "timer/dataset_train_total": 0.17012929916381836, "timer/dataset_train_frac": 0.00017010045787050235, "timer/dataset_train_avg": 0.00012292579419351037, "timer/dataset_train_min": 0.00010347366333007812, "timer/dataset_train_max": 0.0010862350463867188, "timer/agent.train_count": 1384.0, "timer/agent.train_total": 623.5820393562317, "timer/agent.train_frac": 0.6234763261569646, "timer/agent.train_avg": 0.4505650573383177, "timer/agent.train_min": 0.4384458065032959, "timer/agent.train_max": 1.650188684463501, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47643518447875977, "timer/agent.report_frac": 0.00047635441645720695, "timer/agent.report_avg": 0.23821759223937988, "timer/agent.report_min": 0.2317349910736084, "timer/agent.report_max": 0.24470019340515137, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.170429541543948e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 22.1399691865801}
{"step": 864720, "time": 40495.88243627548, "episode/length": 230.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 864720, "time": 40495.89120054245, "episode/length": 222.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 864744, "time": 40500.000915288925, "episode/length": 214.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 864888, "time": 40506.580223321915, "episode/length": 204.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 865080, "time": 40514.5303940773, "episode/length": 44.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 865688, "time": 40536.77782654762, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 865696, "time": 40538.75985431671, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 865720, "time": 40540.81099939346, "episode/length": 79.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 865784, "time": 40544.587893247604, "episode/length": 217.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 866232, "time": 40561.433297395706, "episode/length": 431.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 866400, "time": 40568.88844418526, "episode/length": 209.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 866528, "time": 40574.85955476761, "episode/length": 204.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 866984, "time": 40591.700511693954, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 867160, "time": 40599.25273489952, "episode/length": 301.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 867376, "time": 40608.307809114456, "episode/length": 206.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 867392, "time": 40610.51477742195, "episode/length": 211.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 868256, "time": 40641.47098445892, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 868504, "time": 40652.89197015762, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 868624, "time": 40658.83573317528, "episode/length": 261.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 868888, "time": 40669.12580251694, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 869016, "time": 40675.09840583801, "episode/length": 231.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 869176, "time": 40682.12844347954, "episode/length": 224.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 869336, "time": 40689.17530298233, "episode/length": 443.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 869760, "time": 40705.28674507141, "episode/length": 187.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9840425531914894, "episode/intrinsic_return": 0.0}
{"step": 869816, "time": 40708.71079492569, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 869936, "time": 40714.599326610565, "episode/length": 462.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9978401727861771, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 40736.02457690239, "eval_episode/length": 46.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 870064, "time": 40739.623091220856, "eval_episode/length": 40.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9024390243902439}
{"step": 870064, "time": 40741.660442113876, "eval_episode/length": 98.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9494949494949495}
{"step": 870064, "time": 40748.069907426834, "eval_episode/length": 182.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 870064, "time": 40752.1096599102, "eval_episode/length": 198.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 870064, "time": 40754.16404390335, "eval_episode/length": 208.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 870064, "time": 40755.95060014725, "eval_episode/length": 210.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.981042654028436}
{"step": 870064, "time": 40757.96781849861, "eval_episode/length": 220.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.995475113122172}
{"step": 870272, "time": 40765.03426337242, "episode/length": 172.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 870744, "time": 40782.41237306595, "episode/length": 215.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 870776, "time": 40785.16408085823, "episode/length": 268.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 870912, "time": 40791.567776441574, "episode/length": 216.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 871584, "time": 40815.81279182434, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 871824, "time": 40825.548483371735, "episode/length": 250.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 872064, "time": 40835.39200782776, "episode/length": 223.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 872224, "time": 40842.2899286747, "episode/length": 307.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 872280, "time": 40845.50163245201, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 872424, "time": 40851.883326768875, "episode/length": 205.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 872552, "time": 40857.84645676613, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 872696, "time": 40864.41086745262, "episode/length": 419.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 873416, "time": 40891.50578188896, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 873488, "time": 40895.695800065994, "episode/length": 237.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 873520, "time": 40898.28789114952, "episode/length": 211.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 873704, "time": 40905.97363805771, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 873920, "time": 40915.071803569794, "episode/length": 211.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 874160, "time": 40924.89196181297, "episode/length": 234.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 874384, "time": 40934.030609846115, "episode/length": 210.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 874416, "time": 40936.72529745102, "episode/length": 232.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 875024, "time": 40958.91287589073, "episode/length": 200.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 875040, "time": 40961.11926174164, "episode/length": 139.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 875224, "time": 40968.76237988472, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 875472, "time": 40979.22726678848, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 875928, "time": 40996.0791554451, "episode/length": 304.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9934426229508196, "episode/intrinsic_return": 0.0}
{"step": 876088, "time": 41002.85279965401, "episode/length": 212.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 876568, "time": 41022.491309165955, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 876792, "time": 41031.722485780716, "episode/length": 220.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 876928, "time": 41038.195940971375, "episode/length": 425.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 877000, "time": 41042.04623770714, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 877112, "time": 41047.26997900009, "episode/length": 336.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9881305637982196, "episode/intrinsic_return": 0.0}
{"step": 877200, "time": 41052.02790427208, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 877760, "time": 41072.73820853233, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 878112, "time": 41086.295481443405, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 878272, "time": 41093.36429667473, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 878552, "time": 41104.356665849686, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 878632, "time": 41108.50769805908, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 878792, "time": 41115.658781051636, "episode/length": 223.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 879008, "time": 41124.852397203445, "episode/length": 441.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.997737556561086, "episode/intrinsic_return": 0.0}
{"step": 879168, "time": 41131.98458623886, "episode/length": 256.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 879328, "time": 41138.9845495224, "episode/length": 195.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 879760, "time": 41155.129539489746, "episode/length": 185.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 41166.66254544258, "episode/length": 241.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 41181.882503032684, "eval_episode/length": 43.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 880048, "time": 41189.10701608658, "eval_episode/length": 160.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 880048, "time": 41190.80102586746, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9570552147239264}
{"step": 880048, "time": 41193.70587515831, "eval_episode/length": 192.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 880048, "time": 41195.44908976555, "eval_episode/length": 194.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 880048, "time": 41197.31121015549, "eval_episode/length": 201.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 880048, "time": 41199.26545000076, "eval_episode/length": 168.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 880048, "time": 41200.91752433777, "eval_episode/length": 215.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 880192, "time": 41207.32035422325, "episode/length": 194.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9897435897435898, "episode/intrinsic_return": 0.0}
{"step": 880480, "time": 41218.70956277847, "episode/length": 210.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 880680, "time": 41226.80015921593, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 880816, "time": 41233.25769352913, "episode/length": 205.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 880864, "time": 41236.514207839966, "episode/length": 288.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 881120, "time": 41246.66964840889, "episode/length": 263.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 881296, "time": 41254.59408378601, "episode/length": 191.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 881448, "time": 41261.17788720131, "episode/length": 156.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 881760, "time": 41273.55248117447, "episode/length": 38.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 882008, "time": 41283.60943078995, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 882008, "time": 41283.626049518585, "episode/length": 244.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 882400, "time": 41300.68033742905, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 882448, "time": 41303.93577957153, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 882704, "time": 41314.24309134483, "episode/length": 229.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 882736, "time": 41317.302114486694, "episode/length": 256.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 882952, "time": 41326.554374694824, "episode/length": 206.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 883704, "time": 41353.71609377861, "episode/length": 211.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 883832, "time": 41359.74129652977, "episode/length": 227.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 883912, "time": 41363.962713479996, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 884064, "time": 41371.198112010956, "episode/length": 165.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 884104, "time": 41373.87980771065, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 884256, "time": 41380.74600434303, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 884440, "time": 41388.43254947662, "episode/length": 334.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 884800, "time": 41404.58368396759, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 885112, "time": 41416.45301795006, "episode/length": 175.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 885328, "time": 41425.52903962135, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 885352, "time": 41427.58745098114, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 885704, "time": 41441.29856681824, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 885904, "time": 41449.81900072098, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 885968, "time": 41453.60981750488, "episode/length": 145.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 886200, "time": 41462.96083521843, "episode/length": 219.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 886416, "time": 41472.06812000275, "episode/length": 135.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 886768, "time": 41485.556895017624, "episode/length": 206.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 886769, "time": 41487.92787241936, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.375451396695144, "train/action_min": 0.0, "train/action_std": 3.3279785955552574, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044007726496072125, "train/actor_opt_grad_steps": 54630.0, "train/actor_opt_loss": -3.867046953011438, "train/adv_mag": 0.5764506903054903, "train/adv_max": 0.5417386083294162, "train/adv_mean": 0.0034210965654074897, "train/adv_min": -0.42114962004929135, "train/adv_std": 0.06324066814008376, "train/cont_avg": 0.9945621627697842, "train/cont_loss_mean": 0.00019301790734398768, "train/cont_loss_std": 0.005973747663365233, "train/cont_neg_acc": 0.9960914399984072, "train/cont_neg_loss": 0.02304437842418246, "train/cont_pos_acc": 0.9999858561179621, "train/cont_pos_loss": 4.034723593226666e-05, "train/cont_pred": 0.9945688110461338, "train/cont_rate": 0.9945621627697842, "train/dyn_loss_mean": 12.106701699949854, "train/dyn_loss_std": 9.251201403226784, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7848054775231176, "train/extr_critic_critic_opt_grad_steps": 54630.0, "train/extr_critic_critic_opt_loss": 15827.516053563399, "train/extr_critic_mag": 6.6325176396815895, "train/extr_critic_max": 6.6325176396815895, "train/extr_critic_mean": 1.5532724814449284, "train/extr_critic_min": -0.30770464595273245, "train/extr_critic_std": 1.4990558135423728, "train/extr_return_normed_mag": 1.6742872102655095, "train/extr_return_normed_max": 1.6742872102655095, "train/extr_return_normed_mean": 0.34955366974254304, "train/extr_return_normed_min": -0.12379532655794843, "train/extr_return_normed_std": 0.32885928934426617, "train/extr_return_rate": 0.6523330093716546, "train/extr_return_raw_mag": 7.742879987620621, "train/extr_return_raw_max": 7.742879987620621, "train/extr_return_raw_mean": 1.5692017258500024, "train/extr_return_raw_min": -0.6369212664288583, "train/extr_return_raw_std": 1.5330295622777597, "train/extr_reward_mag": 1.032530839494664, "train/extr_reward_max": 1.032530839494664, "train/extr_reward_mean": 0.035547389588553274, "train/extr_reward_min": -0.5073236690150748, "train/extr_reward_std": 0.17952495695446893, "train/image_loss_mean": 5.175265260737577, "train/image_loss_std": 9.481562271392603, "train/model_loss_mean": 12.49095147633724, "train/model_loss_std": 13.32062153850528, "train/model_opt_grad_norm": 48.696431647101754, "train/model_opt_grad_steps": 54581.13669064748, "train/model_opt_loss": 17991.155744154676, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1447.841726618705, "train/policy_entropy_mag": 2.576004779596123, "train/policy_entropy_max": 2.576004779596123, "train/policy_entropy_mean": 0.6461774458130487, "train/policy_entropy_min": 0.07937504742428553, "train/policy_entropy_std": 0.6931150945828115, "train/policy_logprob_mag": 7.438383675307679, "train/policy_logprob_max": -0.009455661818706732, "train/policy_logprob_mean": -0.6461691213168687, "train/policy_logprob_min": -7.438383675307679, "train/policy_logprob_std": 1.1689411684763518, "train/policy_randomness_mag": 0.9092166406645191, "train/policy_randomness_max": 0.9092166406645191, "train/policy_randomness_mean": 0.22807228200727228, "train/policy_randomness_min": 0.028015908497057374, "train/policy_randomness_std": 0.24463921034936426, "train/post_ent_mag": 60.06045968584019, "train/post_ent_max": 60.06045968584019, "train/post_ent_mean": 43.82170368441575, "train/post_ent_min": 20.452983046607148, "train/post_ent_std": 7.606806240493445, "train/prior_ent_mag": 69.98885263127389, "train/prior_ent_max": 69.98885263127389, "train/prior_ent_mean": 56.01086538301097, "train/prior_ent_min": 39.586088084488466, "train/prior_ent_std": 4.594473075523651, "train/rep_loss_mean": 12.106701699949854, "train/rep_loss_std": 9.251201403226784, "train/reward_avg": 0.02511662531563704, "train/reward_loss_mean": 0.05147223681104269, "train/reward_loss_std": 0.23278251097356673, "train/reward_max_data": 1.0201438896947628, "train/reward_max_pred": 1.0115220135064433, "train/reward_neg_acc": 0.9932149987426593, "train/reward_neg_loss": 0.028163904933888706, "train/reward_pos_acc": 0.9752109252291618, "train/reward_pos_loss": 0.8071847069177697, "train/reward_pred": 0.02467758609852988, "train/reward_rate": 0.030041591726618706, "train_stats/sum_log_reward": 7.119607888016046, "train_stats/max_log_achievement_collect_coal": 0.0196078431372549, "train_stats/max_log_achievement_collect_drink": 6.549019607843137, "train_stats/max_log_achievement_collect_sapling": 3.196078431372549, "train_stats/max_log_achievement_collect_stone": 0.00980392156862745, "train_stats/max_log_achievement_collect_wood": 9.352941176470589, "train_stats/max_log_achievement_defeat_skeleton": 0.0196078431372549, "train_stats/max_log_achievement_defeat_zombie": 1.5098039215686274, "train_stats/max_log_achievement_eat_cow": 0.18627450980392157, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.21568627450980393, "train_stats/max_log_achievement_make_wood_sword": 1.107843137254902, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 3.0392156862745097, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 3.049019607843137, "train_stats/max_log_achievement_wake_up": 1.3725490196078431, "train_stats/mean_log_entropy": 0.6609282286143771, "eval_stats/sum_log_reward": 6.225000038743019, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.75, "eval_stats/max_log_achievement_collect_sapling": 2.6875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 7.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.6875, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.0113346888829255e-06, "report/cont_loss_std": 8.587838237872347e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.6568391806213185e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.01764599600574e-07, "report/cont_pred": 0.9941400289535522, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.805895805358887, "report/dyn_loss_std": 9.438318252563477, "report/image_loss_mean": 5.321154594421387, "report/image_loss_std": 12.068146705627441, "report/model_loss_mean": 12.462508201599121, "report/model_loss_std": 16.326759338378906, "report/post_ent_mag": 58.145450592041016, "report/post_ent_max": 58.145450592041016, "report/post_ent_mean": 44.544151306152344, "report/post_ent_min": 20.494375228881836, "report/post_ent_std": 7.566208839416504, "report/prior_ent_mag": 70.05487060546875, "report/prior_ent_max": 70.05487060546875, "report/prior_ent_mean": 56.627540588378906, "report/prior_ent_min": 34.69454574584961, "report/prior_ent_std": 4.739275932312012, "report/rep_loss_mean": 11.805895805358887, "report/rep_loss_std": 9.438318252563477, "report/reward_avg": 0.02089843899011612, "report/reward_loss_mean": 0.057815976440906525, "report/reward_loss_std": 0.2943916618824005, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0022644996643066, "report/reward_neg_acc": 0.9899699091911316, "report/reward_neg_loss": 0.03068685345351696, "report/reward_pos_acc": 0.9259259104728699, "report/reward_pos_loss": 1.0595840215682983, "report/reward_pred": 0.01847979985177517, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.522792439980549e-07, "eval/cont_loss_std": 4.20072728957166e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.597475294256583e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.5946099551911175e-07, "eval/cont_pred": 0.9970704317092896, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.76984405517578, "eval/dyn_loss_std": 10.606142044067383, "eval/image_loss_mean": 11.920319557189941, "eval/image_loss_std": 16.902542114257812, "eval/model_loss_mean": 22.666275024414062, "eval/model_loss_std": 20.80164337158203, "eval/post_ent_mag": 60.3426628112793, "eval/post_ent_max": 60.3426628112793, "eval/post_ent_mean": 41.09861755371094, "eval/post_ent_min": 15.036966323852539, "eval/post_ent_std": 7.380576133728027, "eval/prior_ent_mag": 70.05487060546875, "eval/prior_ent_max": 70.05487060546875, "eval/prior_ent_mean": 56.53376007080078, "eval/prior_ent_min": 42.180519104003906, "eval/prior_ent_std": 4.213479518890381, "eval/rep_loss_mean": 17.76984405517578, "eval/rep_loss_std": 10.606142044067383, "eval/reward_avg": 0.02226562611758709, "eval/reward_loss_mean": 0.08405102789402008, "eval/reward_loss_std": 0.5707045793533325, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002901554107666, "eval/reward_neg_acc": 0.9789579510688782, "eval/reward_neg_loss": 0.056152474135160446, "eval/reward_pos_acc": 0.9230769872665405, "eval/reward_pos_loss": 1.154926061630249, "eval/reward_pred": 0.026110492646694183, "eval/reward_rate": 0.025390625, "replay/size": 886265.0, "replay/inserts": 22312.0, "replay/samples": 22304.0, "replay/insert_wait_avg": 1.410230080600108e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.488317131140994e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3496.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2277602058253517e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.8904070854187, "timer/env.step_count": 2789.0, "timer/env.step_total": 242.97864961624146, "timer/env.step_frac": 0.24276249217313658, "timer/env.step_avg": 0.08712034765731139, "timer/env.step_min": 0.024489641189575195, "timer/env.step_max": 3.552600860595703, "timer/replay._sample_count": 22304.0, "timer/replay._sample_total": 11.520313024520874, "timer/replay._sample_frac": 0.011510064381641835, "timer/replay._sample_avg": 0.0005165133170965241, "timer/replay._sample_min": 0.0003921985626220703, "timer/replay._sample_max": 0.025278329849243164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3226.0, "timer/agent.policy_total": 56.351895809173584, "timer/agent.policy_frac": 0.0563017643193021, "timer/agent.policy_avg": 0.017468039618466703, "timer/agent.policy_min": 0.009697437286376953, "timer/agent.policy_max": 0.12074565887451172, "timer/dataset_train_count": 1394.0, "timer/dataset_train_total": 0.16743111610412598, "timer/dataset_train_frac": 0.00016728216687747407, "timer/dataset_train_avg": 0.00012010840466580055, "timer/dataset_train_min": 0.00010395050048828125, "timer/dataset_train_max": 0.0008876323699951172, "timer/agent.train_count": 1394.0, "timer/agent.train_total": 632.0873057842255, "timer/agent.train_frac": 0.631524991457213, "timer/agent.train_avg": 0.45343422222684754, "timer/agent.train_min": 0.43962979316711426, "timer/agent.train_max": 1.7431230545043945, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4977753162384033, "timer/agent.report_frac": 0.0004973324878673973, "timer/agent.report_avg": 0.24888765811920166, "timer/agent.report_min": 0.22976946830749512, "timer/agent.report_max": 0.2680058479309082, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.1681461622602623e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 22.29052877213634}
{"step": 887672, "time": 41518.800177812576, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 887672, "time": 41518.81213402748, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 887824, "time": 41527.52724647522, "episode/length": 239.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 887848, "time": 41529.600274562836, "episode/length": 448.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9910913140311804, "episode/intrinsic_return": 0.0}
{"step": 888000, "time": 41536.5827190876, "episode/length": 40.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 888192, "time": 41544.70696187019, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 888392, "time": 41553.00586748123, "episode/length": 335.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 888536, "time": 41559.44819355011, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683257918552036, "episode/intrinsic_return": 0.0}
{"step": 889408, "time": 41590.7901494503, "episode/length": 506.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9881656804733728, "episode/intrinsic_return": 0.0}
{"step": 889528, "time": 41596.12640810013, "episode/length": 212.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 889592, "time": 41599.941754341125, "episode/length": 217.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 889664, "time": 41604.15811395645, "episode/length": 248.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 889728, "time": 41607.824479818344, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 889896, "time": 41614.801231861115, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 41621.23585009575, "episode/length": 229.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 41641.851360082626, "eval_episode/length": 165.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 890032, "time": 41643.97498750687, "eval_episode/length": 178.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 890032, "time": 41645.77215242386, "eval_episode/length": 183.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 890032, "time": 41647.49594449997, "eval_episode/length": 184.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 890032, "time": 41650.27498245239, "eval_episode/length": 211.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 890032, "time": 41652.039707660675, "eval_episode/length": 214.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 890032, "time": 41653.92762541771, "eval_episode/length": 218.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 890032, "time": 41655.86805820465, "eval_episode/length": 222.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 890096, "time": 41659.65459680557, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 890112, "time": 41661.86476778984, "episode/length": 214.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 890776, "time": 41685.47603201866, "episode/length": 84.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 891200, "time": 41701.888600587845, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 891208, "time": 41703.591040849686, "episode/length": 184.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 891240, "time": 41706.222881793976, "episode/length": 213.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 891264, "time": 41708.790996313095, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 891512, "time": 41718.54672408104, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 891600, "time": 41723.368919849396, "episode/length": 212.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 892032, "time": 41739.53094506264, "episode/length": 239.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 892280, "time": 41749.12039875984, "episode/length": 129.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 892432, "time": 41756.06799411774, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 892496, "time": 41760.05181288719, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 892680, "time": 41767.72404766083, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 892808, "time": 41773.62787723541, "episode/length": 199.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 893160, "time": 41788.649928569794, "episode/length": 205.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 893280, "time": 41794.550057172775, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 893408, "time": 41800.423426151276, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 893728, "time": 41812.67763924599, "episode/length": 130.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 893840, "time": 41818.161120176315, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 893856, "time": 41820.328077077866, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 894496, "time": 41843.6101064682, "episode/length": 210.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 894776, "time": 41854.47081542015, "episode/length": 170.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 895064, "time": 41865.779156684875, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 895144, "time": 41870.078164339066, "episode/length": 247.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 895472, "time": 41883.244267225266, "episode/length": 217.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 895872, "time": 41898.4646487236, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 895928, "time": 41901.76766681671, "episode/length": 330.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9848942598187311, "episode/intrinsic_return": 0.0}
{"step": 896136, "time": 41910.537937641144, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 896512, "time": 41924.98636889458, "episode/length": 501.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9880478087649402, "episode/intrinsic_return": 0.0}
{"step": 896520, "time": 41926.691054582596, "episode/length": 217.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 896640, "time": 41932.45960378647, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 897112, "time": 41949.82784843445, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 897224, "time": 41955.22822642326, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 897304, "time": 41959.585074186325, "episode/length": 269.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.0}
{"step": 897720, "time": 41975.20091199875, "episode/length": 223.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 897864, "time": 41981.67597770691, "episode/length": 215.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 898144, "time": 41993.07477617264, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 898304, "time": 42000.697157382965, "episode/length": 222.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 898568, "time": 42011.02395486832, "episode/length": 256.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 898656, "time": 42015.90766811371, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 898704, "time": 42019.0480530262, "episode/length": 184.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 898960, "time": 42029.43390083313, "episode/length": 154.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 898992, "time": 42032.103982687, "episode/length": 234.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 899296, "time": 42044.22511839867, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 899816, "time": 42063.3379547596, "episode/length": 155.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 42086.696637392044, "eval_episode/length": 33.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 900016, "time": 42088.73152542114, "eval_episode/length": 38.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 900016, "time": 42097.1142039299, "eval_episode/length": 188.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 900016, "time": 42098.879956007004, "eval_episode/length": 193.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 900016, "time": 42100.61173272133, "eval_episode/length": 194.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 900016, "time": 42102.70804309845, "eval_episode/length": 205.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 900016, "time": 42104.78422164917, "eval_episode/length": 215.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 900016, "time": 42107.256336688995, "eval_episode/length": 194.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 900080, "time": 42109.42866039276, "episode/length": 241.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.0}
{"step": 900184, "time": 42114.32395648956, "episode/length": 190.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 900304, "time": 42120.26330971718, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 900304, "time": 42120.271585702896, "episode/length": 249.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 900328, "time": 42124.25530910492, "episode/length": 166.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 900616, "time": 42135.48468995094, "episode/length": 238.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 901440, "time": 42166.7044839859, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 901696, "time": 42177.016599178314, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 902024, "time": 42189.645367622375, "episode/length": 214.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 902152, "time": 42195.59274768829, "episode/length": 258.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 902176, "time": 42198.162516355515, "episode/length": 359.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 902200, "time": 42200.31100034714, "episode/length": 236.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 902264, "time": 42203.93894076347, "episode/length": 241.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 902448, "time": 42212.080228090286, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 902920, "time": 42229.4641661644, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 902960, "time": 42232.698935985565, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 903448, "time": 42250.578530073166, "episode/length": 177.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 903448, "time": 42250.590874910355, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 903544, "time": 42257.34692835808, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 903880, "time": 42270.49490571022, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 904720, "time": 42300.72869157791, "episode/length": 224.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 905240, "time": 42319.77676343918, "episode/length": 348.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9828080229226361, "episode/intrinsic_return": 0.0}
{"step": 905240, "time": 42319.785231113434, "episode/length": 223.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 905256, "time": 42323.690076351166, "episode/length": 213.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 905384, "time": 42329.75438141823, "episode/length": 241.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 905400, "time": 42332.09950685501, "episode/length": 402.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9975186104218362, "episode/intrinsic_return": 0.0}
{"step": 905424, "time": 42334.6302447319, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 906536, "time": 42373.634716033936, "episode/length": 446.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9977628635346756, "episode/intrinsic_return": 0.0}
{"step": 906712, "time": 42381.19549012184, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 906728, "time": 42383.35416984558, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 906760, "time": 42385.887506723404, "episode/length": 166.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 906808, "time": 42389.17090320587, "episode/length": 193.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 906880, "time": 42393.40454387665, "episode/length": 269.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 906968, "time": 42397.79609012604, "episode/length": 195.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 907224, "time": 42407.98929691315, "episode/length": 247.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 907312, "time": 42412.76282262802, "episode/length": 42.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9069767441860465, "episode/intrinsic_return": 0.0}
{"step": 907640, "time": 42425.32028222084, "episode/length": 103.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9519230769230769, "episode/intrinsic_return": 0.0}
{"step": 907784, "time": 42431.66592335701, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9487179487179487, "episode/intrinsic_return": 0.0}
{"step": 907944, "time": 42438.64816951752, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 908376, "time": 42455.507041692734, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 908528, "time": 42462.41152024269, "episode/length": 205.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 908560, "time": 42465.15724372864, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 908712, "time": 42471.604887247086, "episode/length": 249.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 909096, "time": 42486.30879449844, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 909096, "time": 42486.31935882568, "episode/length": 47.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 909097, "time": 42490.572675943375, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.291978236607143, "train/action_min": 0.0, "train/action_std": 3.2610383646828787, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044568211039794345, "train/actor_opt_grad_steps": 56025.0, "train/actor_opt_loss": -6.133476187820945, "train/adv_mag": 0.5540786679301943, "train/adv_max": 0.5373840185148375, "train/adv_mean": 0.003031058452324942, "train/adv_min": -0.41847515127488544, "train/adv_std": 0.06313260040645088, "train/cont_avg": 0.9945661272321429, "train/cont_loss_mean": 0.00015849427907593645, "train/cont_loss_std": 0.004808233800162855, "train/cont_neg_acc": 0.9941047164176008, "train/cont_neg_loss": 0.01890599817150412, "train/cont_pos_acc": 0.9999719138656343, "train/cont_pos_loss": 6.960123738827103e-05, "train/cont_pred": 0.9945614401783262, "train/cont_rate": 0.9945661272321429, "train/dyn_loss_mean": 12.115547009876796, "train/dyn_loss_std": 9.259274884632655, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7737131727593286, "train/extr_critic_critic_opt_grad_steps": 56025.0, "train/extr_critic_critic_opt_loss": 15629.969419642857, "train/extr_critic_mag": 6.53076445715768, "train/extr_critic_max": 6.53076445715768, "train/extr_critic_mean": 1.5047586300543376, "train/extr_critic_min": -0.29995632767677305, "train/extr_critic_std": 1.4507458827325277, "train/extr_return_normed_mag": 1.6933337586266655, "train/extr_return_normed_max": 1.6933337586266655, "train/extr_return_normed_mean": 0.3459185524710587, "train/extr_return_normed_min": -0.12229574261499303, "train/extr_return_normed_std": 0.32491045647433825, "train/extr_return_rate": 0.64806039418493, "train/extr_return_raw_mag": 7.657724060331073, "train/extr_return_raw_max": 7.657724060331073, "train/extr_return_raw_mean": 1.5185566948992866, "train/extr_return_raw_min": -0.6148906886577606, "train/extr_return_raw_std": 1.4807950245482582, "train/extr_reward_mag": 1.0351104923657009, "train/extr_reward_max": 1.0351104923657009, "train/extr_reward_mean": 0.03540561455967171, "train/extr_reward_min": -0.47337409939084735, "train/extr_reward_std": 0.1790656919990267, "train/image_loss_mean": 5.3309882930346895, "train/image_loss_std": 10.01264623914446, "train/model_loss_mean": 12.652881969724383, "train/model_loss_std": 13.814158882413592, "train/model_opt_grad_norm": 48.73166689191546, "train/model_opt_grad_steps": 55974.82142857143, "train/model_opt_loss": 16988.25043247768, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1339.2857142857142, "train/policy_entropy_mag": 2.6388608608927044, "train/policy_entropy_max": 2.6388608608927044, "train/policy_entropy_mean": 0.6052916143621717, "train/policy_entropy_min": 0.07937505490013531, "train/policy_entropy_std": 0.6669189636196409, "train/policy_logprob_mag": 7.438383674621582, "train/policy_logprob_max": -0.009455664322844573, "train/policy_logprob_mean": -0.6053136329565729, "train/policy_logprob_min": -7.438383674621582, "train/policy_logprob_std": 1.1460082939692906, "train/policy_randomness_mag": 0.931402080825397, "train/policy_randomness_max": 0.931402080825397, "train/policy_randomness_mean": 0.21364137807062694, "train/policy_randomness_min": 0.028015911086861578, "train/policy_randomness_std": 0.23539312886340277, "train/post_ent_mag": 60.26497949872698, "train/post_ent_max": 60.26497949872698, "train/post_ent_mean": 43.83821645464216, "train/post_ent_min": 20.663133008139475, "train/post_ent_std": 7.61754629952567, "train/prior_ent_mag": 69.96462146214077, "train/prior_ent_max": 69.96462146214077, "train/prior_ent_mean": 56.039354869297576, "train/prior_ent_min": 39.71362043108259, "train/prior_ent_std": 4.614507075718471, "train/rep_loss_mean": 12.115547009876796, "train/rep_loss_std": 9.259274884632655, "train/reward_avg": 0.02570940286054143, "train/reward_loss_mean": 0.05240698203976665, "train/reward_loss_std": 0.23622166269591877, "train/reward_max_data": 1.0135714318071092, "train/reward_max_pred": 1.0084902431283678, "train/reward_neg_acc": 0.9931781326021467, "train/reward_neg_loss": 0.028145751350426247, "train/reward_pos_acc": 0.9735190855605261, "train/reward_pos_loss": 0.8259084028857094, "train/reward_pred": 0.024979249042059695, "train/reward_rate": 0.030538504464285715, "train_stats/sum_log_reward": 6.91132079767731, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.2075471698113205, "train_stats/max_log_achievement_collect_sapling": 2.5660377358490565, "train_stats/max_log_achievement_collect_stone": 0.03773584905660377, "train_stats/max_log_achievement_collect_wood": 9.49056603773585, "train_stats/max_log_achievement_defeat_skeleton": 0.018867924528301886, "train_stats/max_log_achievement_defeat_zombie": 1.349056603773585, "train_stats/max_log_achievement_eat_cow": 0.16981132075471697, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.1509433962264151, "train_stats/max_log_achievement_make_wood_sword": 1.150943396226415, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.3679245283018866, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 3.1132075471698113, "train_stats/max_log_achievement_wake_up": 1.4056603773584906, "train_stats/mean_log_entropy": 0.6140131232029987, "eval_stats/sum_log_reward": 6.475000061094761, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.125, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.25, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.9375, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.75, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 5.501366103999317e-05, "report/cont_loss_std": 0.001314895460382104, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.351229189429432e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.478925959323533e-05, "report/cont_pred": 0.992134690284729, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 9.818406105041504, "report/dyn_loss_std": 8.727497100830078, "report/image_loss_mean": 3.1548733711242676, "report/image_loss_std": 6.704809188842773, "report/model_loss_mean": 9.106961250305176, "report/model_loss_std": 10.517887115478516, "report/post_ent_mag": 61.880882263183594, "report/post_ent_max": 61.880882263183594, "report/post_ent_mean": 46.232757568359375, "report/post_ent_min": 21.855573654174805, "report/post_ent_std": 7.879561424255371, "report/prior_ent_mag": 69.84675598144531, "report/prior_ent_max": 69.84675598144531, "report/prior_ent_mean": 56.02688217163086, "report/prior_ent_min": 39.97937774658203, "report/prior_ent_std": 4.4707560539245605, "report/rep_loss_mean": 9.818406105041504, "report/rep_loss_std": 8.727497100830078, "report/reward_avg": 0.02138671837747097, "report/reward_loss_mean": 0.060989223420619965, "report/reward_loss_std": 0.3056422173976898, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000619649887085, "report/reward_neg_acc": 0.9979878664016724, "report/reward_neg_loss": 0.03673563152551651, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.864591658115387, "report/reward_pred": 0.02033320814371109, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 7.57641828386113e-07, "eval/cont_loss_std": 2.1228566765785217e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0001906289835460484, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.3048179425823037e-08, "eval/cont_pred": 0.9960944652557373, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.43511962890625, "eval/dyn_loss_std": 11.491124153137207, "eval/image_loss_mean": 11.21074104309082, "eval/image_loss_std": 15.906475067138672, "eval/model_loss_mean": 21.213151931762695, "eval/model_loss_std": 20.56962776184082, "eval/post_ent_mag": 61.0568733215332, "eval/post_ent_max": 61.0568733215332, "eval/post_ent_mean": 42.30071258544922, "eval/post_ent_min": 19.223703384399414, "eval/post_ent_std": 7.981730937957764, "eval/prior_ent_mag": 69.84675598144531, "eval/prior_ent_max": 69.84675598144531, "eval/prior_ent_mean": 56.48400115966797, "eval/prior_ent_min": 37.57786178588867, "eval/prior_ent_std": 4.910745620727539, "eval/rep_loss_mean": 16.43511962890625, "eval/rep_loss_std": 11.491124153137207, "eval/reward_avg": 0.03183593973517418, "eval/reward_loss_mean": 0.14133772253990173, "eval/reward_loss_std": 0.8074164390563965, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0010149478912354, "eval/reward_neg_acc": 0.9787233471870422, "eval/reward_neg_loss": 0.05289078131318092, "eval/reward_pos_acc": 0.7297297120094299, "eval/reward_pos_loss": 2.5007197856903076, "eval/reward_pred": 0.02703884057700634, "eval/reward_rate": 0.0361328125, "replay/size": 908593.0, "replay/inserts": 22328.0, "replay/samples": 22336.0, "replay/insert_wait_avg": 1.428589433036539e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.525043982147828e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3656.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1889626734627154e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.7170445919037, "timer/env.step_count": 2791.0, "timer/env.step_total": 249.0227119922638, "timer/env.step_frac": 0.24834793956615514, "timer/env.step_avg": 0.08922347258769753, "timer/env.step_min": 0.02448129653930664, "timer/env.step_max": 3.502195119857788, "timer/replay._sample_count": 22336.0, "timer/replay._sample_total": 11.567009687423706, "timer/replay._sample_frac": 0.011535666766421995, "timer/replay._sample_avg": 0.0005178639723954023, "timer/replay._sample_min": 0.0003693103790283203, "timer/replay._sample_max": 0.02797389030456543, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3248.0, "timer/agent.policy_total": 56.306578636169434, "timer/agent.policy_frac": 0.05615400569867213, "timer/agent.policy_avg": 0.017335769284534924, "timer/agent.policy_min": 0.0096282958984375, "timer/agent.policy_max": 0.11157608032226562, "timer/dataset_train_count": 1396.0, "timer/dataset_train_total": 0.16849088668823242, "timer/dataset_train_frac": 0.00016803432992086676, "timer/dataset_train_avg": 0.00012069547757036706, "timer/dataset_train_min": 0.00010585784912109375, "timer/dataset_train_max": 0.0005927085876464844, "timer/agent.train_count": 1396.0, "timer/agent.train_total": 629.7647929191589, "timer/agent.train_frac": 0.6280583304290666, "timer/agent.train_avg": 0.4511209118332084, "timer/agent.train_min": 0.4383687973022461, "timer/agent.train_max": 1.5932245254516602, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4753718376159668, "timer/agent.report_frac": 0.00047408373097860185, "timer/agent.report_avg": 0.2376859188079834, "timer/agent.report_min": 0.2309551239013672, "timer/agent.report_max": 0.2444167137145996, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.186152042784108e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 22.267200831301427}
{"step": 909416, "time": 42502.84159255028, "episode/length": 203.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 909464, "time": 42506.0851225853, "episode/length": 45.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 909680, "time": 42515.36874985695, "episode/length": 216.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 909912, "time": 42524.603773355484, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 42550.87295484543, "eval_episode/length": 182.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 910000, "time": 42552.951954603195, "eval_episode/length": 193.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 910000, "time": 42555.60108232498, "eval_episode/length": 214.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 910000, "time": 42559.15484189987, "eval_episode/length": 255.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.99609375}
{"step": 910000, "time": 42561.1423368454, "eval_episode/length": 264.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9962264150943396}
{"step": 910000, "time": 42563.788080215454, "eval_episode/length": 290.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9965635738831615}
{"step": 910000, "time": 42566.13723349571, "eval_episode/length": 307.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9967532467532467}
{"step": 910000, "time": 42572.301587581635, "eval_episode/length": 181.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 910136, "time": 42576.656572818756, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 910600, "time": 42594.264464616776, "episode/length": 277.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748201438848921, "episode/intrinsic_return": 0.0}
{"step": 910728, "time": 42600.428109407425, "episode/length": 203.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 911096, "time": 42614.298739910126, "episode/length": 431.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9884259259259259, "episode/intrinsic_return": 0.0}
{"step": 911192, "time": 42619.17820763588, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 911280, "time": 42623.90496516228, "episode/length": 226.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 911456, "time": 42631.67968297005, "episode/length": 221.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 911808, "time": 42645.14073967934, "episode/length": 236.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 911912, "time": 42650.055857658386, "episode/length": 221.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 912064, "time": 42656.90452861786, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 912392, "time": 42669.58120107651, "episode/length": 207.0, "episode/score": 7.1000000685453415, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 912544, "time": 42676.514471292496, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 912768, "time": 42685.734679460526, "episode/length": 208.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 912800, "time": 42688.49486589432, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 913304, "time": 42706.93212080002, "episode/length": 252.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 913368, "time": 42710.61606502533, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 913448, "time": 42714.78855800629, "episode/length": 204.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 913528, "time": 42719.21632647514, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 913944, "time": 42734.642369270325, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 914224, "time": 42745.94057583809, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 914464, "time": 42755.68467092514, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 914544, "time": 42759.968990564346, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 914664, "time": 42765.36390542984, "episode/length": 151.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 914752, "time": 42770.28144955635, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 914760, "time": 42771.981627225876, "episode/length": 153.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9805194805194806, "episode/intrinsic_return": 0.0}
{"step": 914976, "time": 42781.32250928879, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 915496, "time": 42800.2585747242, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 915936, "time": 42816.971219301224, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 915960, "time": 42819.142703294754, "episode/length": 176.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 916008, "time": 42822.41290950775, "episode/length": 192.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 916024, "time": 42824.59817361832, "episode/length": 157.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 916400, "time": 42839.26376080513, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 916432, "time": 42842.01953434944, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 916856, "time": 42857.5617249012, "episode/length": 234.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 917000, "time": 42864.04595327377, "episode/length": 187.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9840425531914894, "episode/intrinsic_return": 0.0}
{"step": 917344, "time": 42877.5237865448, "episode/length": 172.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9884393063583815, "episode/intrinsic_return": 0.0}
{"step": 917512, "time": 42884.93439126015, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 917672, "time": 42893.399883031845, "episode/length": 205.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9854368932038835, "episode/intrinsic_return": 0.0}
{"step": 917824, "time": 42900.56374883652, "episode/length": 226.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 918080, "time": 42910.72734332085, "episode/length": 205.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 918400, "time": 42922.97086071968, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 918472, "time": 42926.71048069, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 918488, "time": 42929.01203632355, "episode/length": 260.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 918856, "time": 42943.05294775963, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 919480, "time": 42965.78858566284, "episode/length": 125.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 919488, "time": 42967.868258953094, "episode/length": 207.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 919520, "time": 42970.523533821106, "episode/length": 230.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 919648, "time": 42976.433513879776, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 919952, "time": 42988.37542104721, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 43014.80109858513, "eval_episode/length": 165.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 920088, "time": 43018.1956744194, "eval_episode/length": 201.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.995049504950495}
{"step": 920088, "time": 43020.04668521881, "eval_episode/length": 206.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 920088, "time": 43022.016951560974, "eval_episode/length": 213.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9719626168224299}
{"step": 920088, "time": 43023.903379917145, "eval_episode/length": 218.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 920088, "time": 43026.372967004776, "eval_episode/length": 237.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9831932773109243}
{"step": 920088, "time": 43029.74946594238, "eval_episode/length": 276.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9783393501805054}
{"step": 920088, "time": 43037.448573589325, "eval_episode/length": 228.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9781659388646288}
{"step": 920168, "time": 43040.27192211151, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 920720, "time": 43061.572556734085, "episode/length": 154.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 920808, "time": 43065.93799138069, "episode/length": 411.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975728155339806, "episode/intrinsic_return": 0.0}
{"step": 920816, "time": 43067.9772233963, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 920856, "time": 43070.70943760872, "episode/length": 346.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9855907780979827, "episode/intrinsic_return": 0.0}
{"step": 920928, "time": 43074.92200756073, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 921112, "time": 43082.5574157238, "episode/length": 37.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 921472, "time": 43096.668689489365, "episode/length": 67.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 921552, "time": 43100.92981052399, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 921744, "time": 43109.04001069069, "episode/length": 196.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 922224, "time": 43126.80015587807, "episode/length": 170.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 922400, "time": 43134.28176379204, "episode/length": 209.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 922400, "time": 43134.29172348976, "episode/length": 343.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9912790697674418, "episode/intrinsic_return": 0.0}
{"step": 922896, "time": 43154.431079149246, "episode/length": 259.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 922904, "time": 43156.119754076004, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 923224, "time": 43168.74367046356, "episode/length": 218.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 923592, "time": 43182.84717798233, "episode/length": 309.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 923624, "time": 43185.4322385788, "episode/length": 234.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 923896, "time": 43196.239364385605, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 923952, "time": 43200.0384247303, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 924064, "time": 43205.40635895729, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 924352, "time": 43216.748881816864, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 924704, "time": 43230.34965252876, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 924936, "time": 43239.66490483284, "episode/length": 316.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779179810725552, "episode/intrinsic_return": 0.0}
{"step": 925088, "time": 43246.71757888794, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 925104, "time": 43248.827659368515, "episode/length": 143.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 925576, "time": 43266.36649823189, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 925728, "time": 43274.93285083771, "episode/length": 266.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 925800, "time": 43278.663180828094, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 925928, "time": 43284.58462023735, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 926208, "time": 43295.975417375565, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 926456, "time": 43305.644735336304, "episode/length": 170.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 926752, "time": 43317.44820380211, "episode/length": 205.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 927032, "time": 43328.44531440735, "episode/length": 153.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 927072, "time": 43331.496129989624, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 927248, "time": 43338.973783016205, "episode/length": 317.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 927672, "time": 43354.80156040192, "episode/length": 217.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 927840, "time": 43362.323726177216, "episode/length": 282.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 928200, "time": 43375.903802633286, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 928200, "time": 43375.91209292412, "episode/length": 248.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 928448, "time": 43387.793598890305, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 928648, "time": 43395.977573394775, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 928728, "time": 43400.256804943085, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 928752, "time": 43402.91607713699, "episode/length": 37.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 928920, "time": 43409.9829761982, "episode/length": 270.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.977859778597786, "episode/intrinsic_return": 0.0}
{"step": 929576, "time": 43433.526915073395, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 929608, "time": 43436.116171360016, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9829545454545454, "episode/intrinsic_return": 0.0}
{"step": 929896, "time": 43447.74238562584, "episode/length": 211.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 43475.904584646225, "eval_episode/length": 160.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 930072, "time": 43478.43921136856, "eval_episode/length": 183.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 930072, "time": 43480.05124092102, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 930072, "time": 43481.73781967163, "eval_episode/length": 187.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 930072, "time": 43484.881494283676, "eval_episode/length": 220.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.995475113122172}
{"step": 930072, "time": 43486.61041903496, "eval_episode/length": 221.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9819819819819819}
{"step": 930072, "time": 43488.6869032383, "eval_episode/length": 231.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 930072, "time": 43491.03219771385, "eval_episode/length": 250.0, "eval_episode/score": 8.100000031292439, "eval_episode/reward_rate": 0.9960159362549801}
{"step": 930073, "time": 43492.06288051605, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.424132834864027, "train/action_min": 0.0, "train/action_std": 3.403881442455845, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04551585920098174, "train/actor_opt_grad_steps": 57380.0, "train/actor_opt_loss": -2.503844913863044, "train/adv_mag": 0.5778203788604445, "train/adv_max": 0.544942386505258, "train/adv_mean": 0.0038197677688475854, "train/adv_min": -0.45125559131607756, "train/adv_std": 0.06427407068491892, "train/cont_avg": 0.9946400882633588, "train/cont_loss_mean": 0.00017602672240935374, "train/cont_loss_std": 0.00500529135688825, "train/cont_neg_acc": 0.9968498179545769, "train/cont_neg_loss": 0.008526681732340736, "train/cont_pos_acc": 0.9999400554722502, "train/cont_pos_loss": 0.000124947651183543, "train/cont_pred": 0.9946117091724891, "train/cont_rate": 0.9946400882633588, "train/dyn_loss_mean": 12.037395768493186, "train/dyn_loss_std": 9.282114028930664, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8146030541139705, "train/extr_critic_critic_opt_grad_steps": 57380.0, "train/extr_critic_critic_opt_loss": 15714.770805999522, "train/extr_critic_mag": 6.612891106205132, "train/extr_critic_max": 6.612891106205132, "train/extr_critic_mean": 1.5823994752104955, "train/extr_critic_min": -0.3005924206653624, "train/extr_critic_std": 1.4736661155715243, "train/extr_return_normed_mag": 1.6877728045441722, "train/extr_return_normed_max": 1.6877728045441722, "train/extr_return_normed_mean": 0.3604794849876229, "train/extr_return_normed_min": -0.1236544155892525, "train/extr_return_normed_std": 0.32930478146513, "train/extr_return_rate": 0.6628046804712019, "train/extr_return_raw_mag": 7.671971117267172, "train/extr_return_raw_max": 7.671971117267172, "train/extr_return_raw_mean": 1.5998668343056248, "train/extr_return_raw_min": -0.6151000538855108, "train/extr_return_raw_std": 1.5065717387745399, "train/extr_reward_mag": 1.0287628665225197, "train/extr_reward_max": 1.0287628665225197, "train/extr_reward_mean": 0.03666024649416218, "train/extr_reward_min": -0.5019730375013278, "train/extr_reward_std": 0.18202175017986588, "train/image_loss_mean": 5.132245395019765, "train/image_loss_std": 9.922371048963706, "train/model_loss_mean": 12.406965707094615, "train/model_loss_std": 13.726763805360285, "train/model_opt_grad_norm": 47.34018567500224, "train/model_opt_grad_steps": 57328.53435114504, "train/model_opt_loss": 15508.707113251432, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.6064643350266317, "train/policy_entropy_max": 2.6064643350266317, "train/policy_entropy_mean": 0.6174808017170156, "train/policy_entropy_min": 0.07937504186202551, "train/policy_entropy_std": 0.6670279025121499, "train/policy_logprob_mag": 7.438383630213846, "train/policy_logprob_max": -0.009455660272759335, "train/policy_logprob_mean": -0.617879675089858, "train/policy_logprob_min": -7.438383630213846, "train/policy_logprob_std": 1.1565373972172046, "train/policy_randomness_mag": 0.9199675303379088, "train/policy_randomness_max": 0.9199675303379088, "train/policy_randomness_mean": 0.21794362582323204, "train/policy_randomness_min": 0.02801590647463125, "train/policy_randomness_std": 0.2354315767306408, "train/post_ent_mag": 60.16323890394837, "train/post_ent_max": 60.16323890394837, "train/post_ent_mean": 43.861309342711934, "train/post_ent_min": 20.468436961865606, "train/post_ent_std": 7.6696843372956485, "train/prior_ent_mag": 70.16504523590321, "train/prior_ent_max": 70.16504523590321, "train/prior_ent_mean": 55.98562805525219, "train/prior_ent_min": 39.53100714064736, "train/prior_ent_std": 4.6391685755198235, "train/rep_loss_mean": 12.037395768493186, "train/rep_loss_std": 9.282114028930664, "train/reward_avg": 0.0266310827849248, "train/reward_loss_mean": 0.052106925179712646, "train/reward_loss_std": 0.22798298208313134, "train/reward_max_data": 1.0099236664881233, "train/reward_max_pred": 1.0053006619897507, "train/reward_neg_acc": 0.9932636968962109, "train/reward_neg_loss": 0.027836740898494503, "train/reward_pos_acc": 0.9765315128646734, "train/reward_pos_loss": 0.8020446600804803, "train/reward_pred": 0.026134589857613768, "train/reward_rate": 0.03130218272900764, "train_stats/sum_log_reward": 7.040594070264609, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.821782178217822, "train_stats/max_log_achievement_collect_sapling": 2.5544554455445545, "train_stats/max_log_achievement_collect_stone": 0.15841584158415842, "train_stats/max_log_achievement_collect_wood": 9.554455445544555, "train_stats/max_log_achievement_defeat_skeleton": 0.009900990099009901, "train_stats/max_log_achievement_defeat_zombie": 1.5247524752475248, "train_stats/max_log_achievement_eat_cow": 0.13861386138613863, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.25742574257425743, "train_stats/max_log_achievement_make_wood_sword": 1.5346534653465347, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.3465346534653464, "train_stats/max_log_achievement_place_stone": 0.0297029702970297, "train_stats/max_log_achievement_place_table": 3.1584158415841586, "train_stats/max_log_achievement_wake_up": 1.2772277227722773, "train_stats/mean_log_entropy": 0.5898717317250696, "eval_stats/sum_log_reward": 7.058333317438762, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.541666666666667, "eval_stats/max_log_achievement_collect_sapling": 3.1666666666666665, "eval_stats/max_log_achievement_collect_stone": 0.16666666666666666, "eval_stats/max_log_achievement_collect_wood": 8.458333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.2916666666666667, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.4166666666666667, "eval_stats/max_log_achievement_make_wood_sword": 1.5416666666666667, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 3.0416666666666665, "eval_stats/max_log_achievement_place_stone": 0.08333333333333333, "eval_stats/max_log_achievement_place_table": 2.8333333333333335, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.07692307692307693, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 6.431053043343127e-05, "report/cont_loss_std": 0.001940266927704215, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006717276410199702, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.192849104991183e-05, "report/cont_pred": 0.9960365891456604, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.244464874267578, "report/dyn_loss_std": 9.933869361877441, "report/image_loss_mean": 6.2303972244262695, "report/image_loss_std": 12.19732666015625, "report/model_loss_mean": 14.229122161865234, "report/model_loss_std": 16.438983917236328, "report/post_ent_mag": 60.990299224853516, "report/post_ent_max": 60.990299224853516, "report/post_ent_mean": 43.02123260498047, "report/post_ent_min": 21.18621063232422, "report/post_ent_std": 7.6369452476501465, "report/prior_ent_mag": 70.58074951171875, "report/prior_ent_max": 70.58074951171875, "report/prior_ent_mean": 56.418785095214844, "report/prior_ent_min": 41.0894775390625, "report/prior_ent_std": 5.102325916290283, "report/rep_loss_mean": 13.244464874267578, "report/rep_loss_std": 9.933869361877441, "report/reward_avg": 0.01835937425494194, "report/reward_loss_mean": 0.051981233060359955, "report/reward_loss_std": 0.21902967989444733, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0626890659332275, "report/reward_neg_acc": 0.9900000691413879, "report/reward_neg_loss": 0.029679682105779648, "report/reward_pos_acc": 0.9166666865348816, "report/reward_pos_loss": 0.9812126159667969, "report/reward_pred": 0.016358494758605957, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.001142662949860096, "eval/cont_loss_std": 0.03602270781993866, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.3900167644023895, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.587852148712045e-08, "eval/cont_pred": 0.9977549910545349, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.429157257080078, "eval/dyn_loss_std": 10.264044761657715, "eval/image_loss_mean": 7.571041107177734, "eval/image_loss_std": 12.369860649108887, "eval/model_loss_mean": 18.084362030029297, "eval/model_loss_std": 16.48973846435547, "eval/post_ent_mag": 60.213314056396484, "eval/post_ent_max": 60.213314056396484, "eval/post_ent_mean": 41.89057159423828, "eval/post_ent_min": 19.807567596435547, "eval/post_ent_std": 7.458250522613525, "eval/prior_ent_mag": 70.58074951171875, "eval/prior_ent_max": 70.58074951171875, "eval/prior_ent_mean": 57.60450744628906, "eval/prior_ent_min": 44.64979934692383, "eval/prior_ent_std": 3.961634397506714, "eval/rep_loss_mean": 17.429157257080078, "eval/rep_loss_std": 10.264044761657715, "eval/reward_avg": 0.02255859412252903, "eval/reward_loss_mean": 0.0546838641166687, "eval/reward_loss_std": 0.2975466549396515, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9987457990646362, "eval/reward_neg_acc": 0.9899799823760986, "eval/reward_neg_loss": 0.026708053424954414, "eval/reward_pos_acc": 0.9230769872665405, "eval/reward_pos_loss": 1.1285247802734375, "eval/reward_pred": 0.021468497812747955, "eval/reward_rate": 0.025390625, "replay/size": 929569.0, "replay/inserts": 20976.0, "replay/samples": 20976.0, "replay/insert_wait_avg": 1.4574608668218942e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.602209622217989e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8088.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2187115870172971e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1920928955078125e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.4749612808228, "timer/env.step_count": 2622.0, "timer/env.step_total": 237.2832841873169, "timer/env.step_frac": 0.23693381598262495, "timer/env.step_avg": 0.09049705727967845, "timer/env.step_min": 0.02478480339050293, "timer/env.step_max": 3.282973051071167, "timer/replay._sample_count": 20976.0, "timer/replay._sample_total": 10.846694469451904, "timer/replay._sample_frac": 0.010830719577431744, "timer/replay._sample_avg": 0.0005171002321439695, "timer/replay._sample_min": 0.0003895759582519531, "timer/replay._sample_max": 0.0198824405670166, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3633.0, "timer/agent.policy_total": 64.59763932228088, "timer/agent.policy_frac": 0.06450250063133342, "timer/agent.policy_avg": 0.01778079805182518, "timer/agent.policy_min": 0.009671688079833984, "timer/agent.policy_max": 0.13917827606201172, "timer/dataset_train_count": 1311.0, "timer/dataset_train_total": 0.17807531356811523, "timer/dataset_train_frac": 0.00017781304620973073, "timer/dataset_train_avg": 0.0001358316655744586, "timer/dataset_train_min": 0.00010323524475097656, "timer/dataset_train_max": 0.021218061447143555, "timer/agent.train_count": 1311.0, "timer/agent.train_total": 591.6421010494232, "timer/agent.train_frac": 0.5907707370863777, "timer/agent.train_avg": 0.4512906949270963, "timer/agent.train_min": 0.43874073028564453, "timer/agent.train_max": 1.6559937000274658, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47723913192749023, "timer/agent.report_frac": 0.0004765362593959731, "timer/agent.report_avg": 0.23861956596374512, "timer/agent.report_min": 0.2300128936767578, "timer/agent.report_max": 0.24722623825073242, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.213910424435019e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 20.944848060026285}
{"step": 930112, "time": 43493.466618299484, "episode/length": 182.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 930288, "time": 43501.13516187668, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 930304, "time": 43503.195231199265, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 930544, "time": 43512.82043337822, "episode/length": 358.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9944289693593314, "episode/intrinsic_return": 0.0}
{"step": 930784, "time": 43522.470442056656, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 931008, "time": 43531.666796922684, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 931528, "time": 43550.469762563705, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 931664, "time": 43556.83944153786, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 932312, "time": 43580.21652507782, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 932416, "time": 43585.33551335335, "episode/length": 263.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 932792, "time": 43599.456778526306, "episode/length": 507.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9980314960629921, "episode/intrinsic_return": 0.0}
{"step": 932928, "time": 43605.86114478111, "episode/length": 297.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 932936, "time": 43607.45091295242, "episode/length": 240.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 933032, "time": 43612.30572962761, "episode/length": 170.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 933248, "time": 43621.49567127228, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9627906976744186, "episode/intrinsic_return": 0.0}
{"step": 933584, "time": 43634.21436262131, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 933800, "time": 43642.91115665436, "episode/length": 172.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 933888, "time": 43647.99903535843, "episode/length": 498.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9799599198396793, "episode/intrinsic_return": 0.0}
{"step": 934184, "time": 43660.89733862877, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9540229885057471, "episode/intrinsic_return": 0.0}
{"step": 934376, "time": 43668.980563640594, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 934576, "time": 43677.71265411377, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 935000, "time": 43693.515645980835, "episode/length": 218.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 935008, "time": 43695.51344847679, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 935336, "time": 43707.90751838684, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 935456, "time": 43713.87468647957, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 935800, "time": 43726.80856180191, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 935920, "time": 43732.56944155693, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 936088, "time": 43739.78059864044, "episode/length": 135.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 936272, "time": 43747.737182855606, "episode/length": 157.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 936456, "time": 43755.19060373306, "episode/length": 439.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795454545454545, "episode/intrinsic_return": 0.0}
{"step": 936656, "time": 43764.30026650429, "episode/length": 164.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 936912, "time": 43774.66835093498, "episode/length": 181.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 937632, "time": 43800.68286895752, "episode/length": 213.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 937672, "time": 43803.42442345619, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 938000, "time": 43816.23965668678, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 938080, "time": 43820.52702784538, "episode/length": 248.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 938088, "time": 43822.27408194542, "episode/length": 56.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9122807017543859, "episode/intrinsic_return": 0.0}
{"step": 938136, "time": 43825.4310195446, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 938312, "time": 43833.092470645905, "episode/length": 174.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 938464, "time": 43840.03609704971, "episode/length": 485.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9979423868312757, "episode/intrinsic_return": 0.0}
{"step": 939368, "time": 43871.750963926315, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 939616, "time": 43881.908712387085, "episode/length": 201.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 939624, "time": 43883.47392344475, "episode/length": 370.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9973045822102425, "episode/intrinsic_return": 0.0}
{"step": 939624, "time": 43883.481638908386, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 939800, "time": 43893.04491376877, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 939848, "time": 43896.26433944702, "episode/length": 191.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 939856, "time": 43898.283046245575, "episode/length": 173.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 939896, "time": 43900.938708782196, "episode/length": 277.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 43923.687670230865, "eval_episode/length": 46.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 940056, "time": 43928.96289038658, "eval_episode/length": 132.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9699248120300752}
{"step": 940056, "time": 43931.35986447334, "eval_episode/length": 149.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 940056, "time": 43933.463357687, "eval_episode/length": 160.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 940056, "time": 43935.76969695091, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 940056, "time": 43938.6075155735, "eval_episode/length": 201.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 940056, "time": 43940.13897204399, "eval_episode/length": 202.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 940056, "time": 43942.122987270355, "eval_episode/length": 166.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 940144, "time": 43945.30916929245, "episode/length": 96.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9484536082474226, "episode/intrinsic_return": 0.0}
{"step": 940248, "time": 43950.23785161972, "episode/length": 48.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 941232, "time": 43985.192353487015, "episode/length": 178.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 941248, "time": 43987.32889294624, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 941536, "time": 43998.56152296066, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 941560, "time": 44000.7869951725, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 941704, "time": 44007.26875305176, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 941760, "time": 44011.285840034485, "episode/length": 266.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 942080, "time": 44023.99799656868, "episode/length": 278.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 942312, "time": 44034.79145073891, "episode/length": 257.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728682170542635, "episode/intrinsic_return": 0.0}
{"step": 942760, "time": 44051.71808505058, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 942888, "time": 44057.55924272537, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 942936, "time": 44060.70286369324, "episode/length": 174.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 943392, "time": 44078.30159974098, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 943544, "time": 44085.36502170563, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 943624, "time": 44089.68879675865, "episode/length": 298.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765886287625418, "episode/intrinsic_return": 0.0}
{"step": 943624, "time": 44089.69594359398, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 943888, "time": 44102.46191072464, "episode/length": 265.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 944032, "time": 44108.85521221161, "episode/length": 158.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 944488, "time": 44125.65187835693, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 944624, "time": 44132.1036067009, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 945080, "time": 44148.7200012207, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 945272, "time": 44156.74792575836, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 945352, "time": 44161.2334985733, "episode/length": 33.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 945648, "time": 44173.083013534546, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 945792, "time": 44179.56904554367, "episode/length": 299.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 946056, "time": 44190.37150502205, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 946072, "time": 44192.57019948959, "episode/length": 254.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 946144, "time": 44196.71357488632, "episode/length": 206.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 946176, "time": 44199.34882712364, "episode/length": 318.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 946952, "time": 44226.69672226906, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 946952, "time": 44226.705074071884, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 947160, "time": 44236.8424847126, "episode/length": 188.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 947304, "time": 44243.2897131443, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 947576, "time": 44254.67844939232, "episode/length": 222.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 947640, "time": 44258.373725414276, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 947712, "time": 44262.48385620117, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 947744, "time": 44265.108709812164, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 948264, "time": 44283.894223213196, "episode/length": 77.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9358974358974359, "episode/intrinsic_return": 0.0}
{"step": 948576, "time": 44296.15802645683, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 948592, "time": 44298.453533649445, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 948600, "time": 44300.079062223434, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 949152, "time": 44320.4608604908, "episode/length": 248.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 949472, "time": 44332.81420636177, "episode/length": 219.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 949600, "time": 44338.88173913956, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 949656, "time": 44342.563446998596, "episode/length": 259.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 950032, "time": 44357.82963132858, "episode/length": 220.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 44381.582939863205, "eval_episode/length": 163.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 950040, "time": 44383.87115621567, "eval_episode/length": 177.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 950040, "time": 44385.58208990097, "eval_episode/length": 180.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 950040, "time": 44387.30014491081, "eval_episode/length": 184.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 950040, "time": 44389.08596611023, "eval_episode/length": 185.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.978494623655914}
{"step": 950040, "time": 44392.02686262131, "eval_episode/length": 215.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 950040, "time": 44393.67323637009, "eval_episode/length": 38.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 950040, "time": 44396.27044177055, "eval_episode/length": 237.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 950144, "time": 44400.093556404114, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 950176, "time": 44402.64421057701, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 950360, "time": 44411.86568570137, "episode/length": 219.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 950448, "time": 44417.07643890381, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 950872, "time": 44433.27341008186, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 950920, "time": 44436.47321462631, "episode/length": 164.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 950960, "time": 44439.582280159, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 951712, "time": 44466.48017787933, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 951712, "time": 44466.503407239914, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 951944, "time": 44477.42710804939, "episode/length": 197.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 951984, "time": 44480.59837770462, "episode/length": 243.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 952080, "time": 44485.42691683769, "episode/length": 203.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 952217, "time": 44492.50144100189, "train_stats/sum_log_reward": 7.156074840331746, "train_stats/max_log_achievement_collect_coal": 0.018691588785046728, "train_stats/max_log_achievement_collect_drink": 4.411214953271028, "train_stats/max_log_achievement_collect_sapling": 2.196261682242991, "train_stats/max_log_achievement_collect_stone": 0.24299065420560748, "train_stats/max_log_achievement_collect_wood": 12.719626168224298, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 1.2616822429906542, "train_stats/max_log_achievement_eat_cow": 0.11214953271028037, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 4.046728971962617, "train_stats/max_log_achievement_make_wood_sword": 0.5420560747663551, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.074766355140187, "train_stats/max_log_achievement_place_stone": 0.056074766355140186, "train_stats/max_log_achievement_place_table": 3.308411214953271, "train_stats/max_log_achievement_wake_up": 1.1121495327102804, "train_stats/mean_log_entropy": 0.523657557563247, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.42380468396173, "train/action_min": 0.0, "train/action_std": 3.335145658341007, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04596524734212005, "train/actor_opt_grad_steps": 58725.0, "train/actor_opt_loss": 3.5824637147935405, "train/adv_mag": 0.6231809418270553, "train/adv_max": 0.5907511080520741, "train/adv_mean": 0.005184782791611328, "train/adv_min": -0.4294982815998188, "train/adv_std": 0.0666879358013039, "train/cont_avg": 0.9948624320652174, "train/cont_loss_mean": 0.0003669377502100104, "train/cont_loss_std": 0.010131774270123713, "train/cont_neg_acc": 0.9852283208266549, "train/cont_neg_loss": 0.05584152913254325, "train/cont_pos_acc": 0.9999643680842026, "train/cont_pos_loss": 0.0001013334885288725, "train/cont_pred": 0.9948812222135239, "train/cont_rate": 0.9948624320652174, "train/dyn_loss_mean": 12.156750243643057, "train/dyn_loss_std": 9.321648701377537, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8376409826071366, "train/extr_critic_critic_opt_grad_steps": 58725.0, "train/extr_critic_critic_opt_loss": 16129.978692538496, "train/extr_critic_mag": 6.648021114045295, "train/extr_critic_max": 6.648021114045295, "train/extr_critic_mean": 1.6609629003897957, "train/extr_critic_min": -0.3097020603608394, "train/extr_critic_std": 1.461048152135766, "train/extr_return_normed_mag": 1.6797231573989426, "train/extr_return_normed_max": 1.6797231573989426, "train/extr_return_normed_mean": 0.3688851132772971, "train/extr_return_normed_min": -0.131829545347263, "train/extr_return_normed_std": 0.3239332881310712, "train/extr_return_rate": 0.6847911349673202, "train/extr_return_raw_mag": 7.768229940663213, "train/extr_return_raw_max": 7.768229940663213, "train/extr_return_raw_mean": 1.68502106960269, "train/extr_return_raw_min": -0.6394558343226495, "train/extr_return_raw_std": 1.5033685262652412, "train/extr_reward_mag": 1.0346302640610847, "train/extr_reward_max": 1.0346302640610847, "train/extr_reward_mean": 0.0332509810509889, "train/extr_reward_min": -0.4903130090754965, "train/extr_reward_std": 0.17226508610706398, "train/image_loss_mean": 5.293852890747181, "train/image_loss_std": 9.96181441389996, "train/model_loss_mean": 12.639346592668174, "train/model_loss_std": 13.833078826683154, "train/model_opt_grad_norm": 50.01514401643173, "train/model_opt_grad_steps": 58672.289855072464, "train/model_opt_loss": 15799.183254076086, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1259.0579710144928, "train/policy_entropy_mag": 2.5622840238654097, "train/policy_entropy_max": 2.5622840238654097, "train/policy_entropy_mean": 0.5992370474597682, "train/policy_entropy_min": 0.07937503719459409, "train/policy_entropy_std": 0.6345509880262873, "train/policy_logprob_mag": 7.4383837312891865, "train/policy_logprob_max": -0.009455660992450472, "train/policy_logprob_mean": -0.59901014359101, "train/policy_logprob_min": -7.4383837312891865, "train/policy_logprob_std": 1.1324533258659253, "train/policy_randomness_mag": 0.904373815526133, "train/policy_randomness_max": 0.904373815526133, "train/policy_randomness_mean": 0.21150438228379126, "train/policy_randomness_min": 0.02801590481692034, "train/policy_randomness_std": 0.22396865314331607, "train/post_ent_mag": 60.12290528891743, "train/post_ent_max": 60.12290528891743, "train/post_ent_mean": 43.84128037051878, "train/post_ent_min": 20.48540715203769, "train/post_ent_std": 7.642975886662801, "train/prior_ent_mag": 70.1503655253977, "train/prior_ent_max": 70.1503655253977, "train/prior_ent_mean": 56.04767077902089, "train/prior_ent_min": 39.49825096130371, "train/prior_ent_std": 4.605053656343101, "train/rep_loss_mean": 12.156750243643057, "train/rep_loss_std": 9.321648701377537, "train/reward_avg": 0.025060858159069565, "train/reward_loss_mean": 0.051076751607267754, "train/reward_loss_std": 0.22977959256673205, "train/reward_max_data": 1.0137681192246035, "train/reward_max_pred": 1.0097890496253967, "train/reward_neg_acc": 0.9933425853217858, "train/reward_neg_loss": 0.027246780065900606, "train/reward_pos_acc": 0.9752102757709614, "train/reward_pos_loss": 0.8264197162959886, "train/reward_pred": 0.02440252610941188, "train/reward_rate": 0.02989838088768116, "eval_stats/sum_log_reward": 6.0999999940395355, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.8125, "eval_stats/max_log_achievement_collect_sapling": 1.1875, "eval_stats/max_log_achievement_collect_stone": 0.3125, "eval_stats/max_log_achievement_collect_wood": 10.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 3.625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 2.5907049803208793e-06, "report/cont_loss_std": 5.331569627742283e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004632009658962488, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.689315013209125e-06, "report/cont_pred": 0.9980461597442627, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 12.41220474243164, "report/dyn_loss_std": 8.91966724395752, "report/image_loss_mean": 7.988271713256836, "report/image_loss_std": 13.316587448120117, "report/model_loss_mean": 15.486352920532227, "report/model_loss_std": 16.63343620300293, "report/post_ent_mag": 61.61524200439453, "report/post_ent_max": 61.61524200439453, "report/post_ent_mean": 44.87034225463867, "report/post_ent_min": 22.575939178466797, "report/post_ent_std": 8.556497573852539, "report/prior_ent_mag": 70.5170669555664, "report/prior_ent_max": 70.5170669555664, "report/prior_ent_mean": 57.299537658691406, "report/prior_ent_min": 42.968772888183594, "report/prior_ent_std": 4.424960613250732, "report/rep_loss_mean": 12.41220474243164, "report/rep_loss_std": 8.91966724395752, "report/reward_avg": 0.01689453050494194, "report/reward_loss_mean": 0.050755757838487625, "report/reward_loss_std": 0.3083043098449707, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0047636032104492, "report/reward_neg_acc": 0.9960119724273682, "report/reward_neg_loss": 0.020378265529870987, "report/reward_pos_acc": 0.761904776096344, "report/reward_pos_loss": 1.5016429424285889, "report/reward_pred": 0.012092148885130882, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0043054609559476376, "eval/cont_loss_std": 0.13692346215248108, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.8817326426506042, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2722540532195126e-07, "eval/cont_pred": 0.9961056113243103, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 14.546460151672363, "eval/dyn_loss_std": 10.304240226745605, "eval/image_loss_mean": 7.90172815322876, "eval/image_loss_std": 11.249760627746582, "eval/model_loss_mean": 16.760250091552734, "eval/model_loss_std": 15.265363693237305, "eval/post_ent_mag": 59.28364562988281, "eval/post_ent_max": 59.28364562988281, "eval/post_ent_mean": 43.74622344970703, "eval/post_ent_min": 21.618791580200195, "eval/post_ent_std": 7.352116584777832, "eval/prior_ent_mag": 70.5170669555664, "eval/prior_ent_max": 70.5170669555664, "eval/prior_ent_mean": 57.191436767578125, "eval/prior_ent_min": 43.878684997558594, "eval/prior_ent_std": 4.230427265167236, "eval/rep_loss_mean": 14.546460151672363, "eval/rep_loss_std": 10.304240226745605, "eval/reward_avg": 0.04091797024011612, "eval/reward_loss_mean": 0.1263415515422821, "eval/reward_loss_std": 0.5658102631568909, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0008537769317627, "eval/reward_neg_acc": 0.9815762639045715, "eval/reward_neg_loss": 0.06430123746395111, "eval/reward_pos_acc": 0.8085106015205383, "eval/reward_pos_loss": 1.4159879684448242, "eval/reward_pred": 0.03777199238538742, "eval/reward_rate": 0.0458984375, "replay/size": 951713.0, "replay/inserts": 22144.0, "replay/samples": 22144.0, "replay/insert_wait_avg": 1.4225656242039852e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.524885411896457e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3616.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.237126050797184e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4282710552216, "timer/env.step_count": 2768.0, "timer/env.step_total": 255.26303386688232, "timer/env.step_frac": 0.2551537588973156, "timer/env.step_avg": 0.0922193041426598, "timer/env.step_min": 0.02405095100402832, "timer/env.step_max": 3.5218443870544434, "timer/replay._sample_count": 22144.0, "timer/replay._sample_total": 11.397416114807129, "timer/replay._sample_frac": 0.011392537020955513, "timer/replay._sample_avg": 0.0005146954531614491, "timer/replay._sample_min": 0.00041365623474121094, "timer/replay._sample_max": 0.010150671005249023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3220.0, "timer/agent.policy_total": 56.972795248031616, "timer/agent.policy_frac": 0.05694840589414615, "timer/agent.policy_avg": 0.017693414673301745, "timer/agent.policy_min": 0.009732484817504883, "timer/agent.policy_max": 0.1529221534729004, "timer/dataset_train_count": 1384.0, "timer/dataset_train_total": 0.1651601791381836, "timer/dataset_train_frac": 0.0001650894760940508, "timer/dataset_train_avg": 0.0001193353895507107, "timer/dataset_train_min": 0.00010347366333007812, "timer/dataset_train_max": 0.0002999305725097656, "timer/agent.train_count": 1384.0, "timer/agent.train_total": 620.6504316329956, "timer/agent.train_frac": 0.6203847388062637, "timer/agent.train_avg": 0.4484468436654592, "timer/agent.train_min": 0.43320178985595703, "timer/agent.train_max": 1.5994794368743896, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47601819038391113, "timer/agent.report_frac": 0.00047581441284323315, "timer/agent.report_avg": 0.23800909519195557, "timer/agent.report_min": 0.2308189868927002, "timer/agent.report_max": 0.24519920349121094, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2172729529885815e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 22.13422070817702}
{"step": 952304, "time": 44495.569774627686, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 952456, "time": 44502.03274965286, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 953064, "time": 44524.297949790955, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 953352, "time": 44535.60031056404, "episode/length": 303.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 953376, "time": 44538.254890203476, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 953656, "time": 44549.18294930458, "episode/length": 208.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 953656, "time": 44549.19466471672, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 953680, "time": 44553.711379528046, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 954040, "time": 44567.14631652832, "episode/length": 244.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 954136, "time": 44571.98530960083, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 954592, "time": 44589.28140425682, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 954792, "time": 44597.41121006012, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 954952, "time": 44604.39700579643, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 954960, "time": 44606.52353525162, "episode/length": 159.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 955088, "time": 44612.5385184288, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 955416, "time": 44625.068816661835, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 955552, "time": 44631.564309597015, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 955608, "time": 44634.88599038124, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 956144, "time": 44654.96354985237, "episode/length": 90.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9340659340659341, "episode/intrinsic_return": 0.0}
{"step": 956168, "time": 44657.15957593918, "episode/length": 171.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 956456, "time": 44668.56003284454, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 956480, "time": 44671.22432804108, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 956520, "time": 44673.87723302841, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 956896, "time": 44688.285788059235, "episode/length": 241.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 956984, "time": 44692.67151927948, "episode/length": 178.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9553072625698324, "episode/intrinsic_return": 0.0}
{"step": 957000, "time": 44695.01200199127, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9540229885057471, "episode/intrinsic_return": 0.0}
{"step": 957352, "time": 44708.398164987564, "episode/length": 45.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 957560, "time": 44716.99610996246, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 957680, "time": 44722.86371397972, "episode/length": 191.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 957776, "time": 44727.60611152649, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 957984, "time": 44736.443583488464, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 958208, "time": 44745.54226708412, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 958440, "time": 44754.69405293465, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 958744, "time": 44768.2669672966, "episode/length": 66.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 958768, "time": 44770.8838288784, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 959088, "time": 44783.231001615524, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 959184, "time": 44788.08146691322, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 959600, "time": 44803.673402786255, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 959752, "time": 44810.14075565338, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 959960, "time": 44818.79781961441, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 959968, "time": 44820.82221198082, "episode/length": 273.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 44844.97886276245, "eval_episode/length": 165.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 960024, "time": 44846.74750041962, "eval_episode/length": 168.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 960024, "time": 44849.2301967144, "eval_episode/length": 181.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 960024, "time": 44852.500361680984, "eval_episode/length": 217.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.963302752293578}
{"step": 960024, "time": 44854.68794250488, "eval_episode/length": 231.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 960024, "time": 44856.32862281799, "eval_episode/length": 233.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 960024, "time": 44858.37318110466, "eval_episode/length": 244.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 960024, "time": 44860.777581214905, "eval_episode/length": 42.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 960072, "time": 44862.38670897484, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 960368, "time": 44874.172684669495, "episode/length": 159.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 960856, "time": 44892.188234090805, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 960880, "time": 44894.82384347916, "episode/length": 266.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9737827715355806, "episode/intrinsic_return": 0.0}
{"step": 960952, "time": 44898.620935201645, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 961208, "time": 44909.026198625565, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 961408, "time": 44917.58387255669, "episode/length": 180.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 961504, "time": 44922.311917066574, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 961736, "time": 44931.60404443741, "episode/length": 207.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 961856, "time": 44937.408131599426, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 962288, "time": 44953.8882830143, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 962616, "time": 44966.91245007515, "episode/length": 216.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 962744, "time": 44972.96310853958, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 962880, "time": 44979.394753456116, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 963072, "time": 44987.44912362099, "episode/length": 207.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 963232, "time": 44994.63397169113, "episode/length": 186.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 963520, "time": 45006.25312614441, "episode/length": 251.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 963744, "time": 45015.31919002533, "episode/length": 235.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 964016, "time": 45026.081448316574, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 964448, "time": 45042.42104291916, "episode/length": 228.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 964472, "time": 45044.5725004673, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 964480, "time": 45046.687056064606, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 964536, "time": 45049.88044667244, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 964832, "time": 45062.064467430115, "episode/length": 43.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 964888, "time": 45065.25045681, "episode/length": 267.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 965080, "time": 45073.31388807297, "episode/length": 166.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9880239520958084, "episode/intrinsic_return": 0.0}
{"step": 965264, "time": 45081.29370760918, "episode/length": 217.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 965784, "time": 45100.33731222153, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 966008, "time": 45109.6196846962, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 966024, "time": 45111.6724653244, "episode/length": 148.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 966096, "time": 45115.95272350311, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 966160, "time": 45119.883914232254, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 966344, "time": 45127.33916974068, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 967144, "time": 45157.85075569153, "episode/length": 281.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 967256, "time": 45163.34868264198, "episode/length": 248.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 967352, "time": 45168.23315238953, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 967440, "time": 45172.95733046532, "episode/length": 178.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 967608, "time": 45180.08290410042, "episode/length": 180.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 967680, "time": 45184.26504731178, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 967688, "time": 45185.900720357895, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 967816, "time": 45191.83590531349, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 968624, "time": 45220.83891868591, "episode/length": 184.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 968824, "time": 45229.045619249344, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 969016, "time": 45237.19342517853, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 969016, "time": 45237.20191884041, "episode/length": 149.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 969120, "time": 45244.59387612343, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9656652360515021, "episode/intrinsic_return": 0.0}
{"step": 969312, "time": 45252.70188641548, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 969680, "time": 45266.652586221695, "episode/length": 248.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 45299.81317281723, "eval_episode/length": 155.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 970008, "time": 45301.54715633392, "eval_episode/length": 158.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 970008, "time": 45303.48564743996, "eval_episode/length": 165.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 970008, "time": 45305.41877961159, "eval_episode/length": 170.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 970008, "time": 45309.88656592369, "eval_episode/length": 217.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 970008, "time": 45311.717224121094, "eval_episode/length": 223.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 970008, "time": 45315.018860816956, "eval_episode/length": 262.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9961977186311787}
{"step": 970008, "time": 45316.69313502312, "eval_episode/length": 264.0, "eval_episode/score": 11.099999964237213, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 970200, "time": 45323.1803252697, "episode/length": 171.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 970392, "time": 45331.40902757645, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 970440, "time": 45334.608045578, "episode/length": 164.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 970536, "time": 45339.85543203354, "episode/length": 189.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 971144, "time": 45362.083515405655, "episode/length": 441.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.997737556561086, "episode/intrinsic_return": 0.0}
{"step": 971312, "time": 45369.518746614456, "episode/length": 203.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 971504, "time": 45377.4936568737, "episode/length": 44.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 971640, "time": 45383.40798354149, "episode/length": 290.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9828178694158075, "episode/intrinsic_return": 0.0}
{"step": 971696, "time": 45387.08561420441, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 971832, "time": 45393.17573881149, "episode/length": 179.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 971896, "time": 45396.919827222824, "episode/length": 169.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 972008, "time": 45402.23426389694, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 972464, "time": 45419.45886993408, "episode/length": 430.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976798143851509, "episode/intrinsic_return": 0.0}
{"step": 973040, "time": 45440.639380931854, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 973120, "time": 45445.00493597984, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 973368, "time": 45454.87254238129, "episode/length": 215.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 973400, "time": 45457.51305103302, "episode/length": 212.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 973440, "time": 45460.68940448761, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 973496, "time": 45463.88893342018, "episode/length": 185.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 973704, "time": 45472.38128256798, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 974088, "time": 45487.05665540695, "episode/length": 273.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 974185, "time": 45492.855788469315, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.152962504953578, "train/action_min": 0.0, "train/action_std": 3.144701095594876, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.042102224368979965, "train/actor_opt_grad_steps": 60105.0, "train/actor_opt_loss": -9.965019079762092, "train/adv_mag": 0.5358087811349095, "train/adv_max": 0.5058575760627139, "train/adv_mean": 0.0020191731434971334, "train/adv_min": -0.41895787201929785, "train/adv_std": 0.06120421100353849, "train/cont_avg": 0.9948553555253623, "train/cont_loss_mean": 0.0001556681367674791, "train/cont_loss_std": 0.004707156181141116, "train/cont_neg_acc": 0.9946859910868217, "train/cont_neg_loss": 0.01716879044647942, "train/cont_pos_acc": 0.9999857423962026, "train/cont_pos_loss": 6.4746411486956e-05, "train/cont_pred": 0.9948447217112002, "train/cont_rate": 0.9948553555253623, "train/dyn_loss_mean": 12.051650918048361, "train/dyn_loss_std": 9.274573574895443, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7956234497436578, "train/extr_critic_critic_opt_grad_steps": 60105.0, "train/extr_critic_critic_opt_loss": 15871.044546818388, "train/extr_critic_mag": 6.846102427745211, "train/extr_critic_max": 6.846102427745211, "train/extr_critic_mean": 1.7597214769626008, "train/extr_critic_min": -0.3115353428799173, "train/extr_critic_std": 1.5854791411455127, "train/extr_return_normed_mag": 1.6548047627227893, "train/extr_return_normed_max": 1.6548047627227893, "train/extr_return_normed_mean": 0.36376755047535553, "train/extr_return_normed_min": -0.12418939240708732, "train/extr_return_normed_std": 0.32723674188921414, "train/extr_return_rate": 0.6935264168010242, "train/extr_return_raw_mag": 8.142373306163844, "train/extr_return_raw_max": 8.142373306163844, "train/extr_return_raw_mean": 1.7696318807809248, "train/extr_return_raw_min": -0.6388383265854656, "train/extr_return_raw_std": 1.6156938378361687, "train/extr_reward_mag": 1.0344113768010899, "train/extr_reward_max": 1.0344113768010899, "train/extr_reward_mean": 0.03482814914668384, "train/extr_reward_min": -0.4917135955630869, "train/extr_reward_std": 0.17723665861547858, "train/image_loss_mean": 5.306816828423652, "train/image_loss_std": 10.02882138542507, "train/model_loss_mean": 12.590319142825361, "train/model_loss_std": 13.845662414163783, "train/model_opt_grad_norm": 48.08509977313056, "train/model_opt_grad_steps": 60050.862318840576, "train/model_opt_loss": 17390.91061622509, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1376.8115942028985, "train/policy_entropy_mag": 2.596932331720988, "train/policy_entropy_max": 2.596932331720988, "train/policy_entropy_mean": 0.5547585938719736, "train/policy_entropy_min": 0.07937503665469695, "train/policy_entropy_std": 0.6298897072024967, "train/policy_logprob_mag": 7.438383717467819, "train/policy_logprob_max": -0.009455658421190321, "train/policy_logprob_mean": -0.5536445221607236, "train/policy_logprob_min": -7.438383717467819, "train/policy_logprob_std": 1.103646458491035, "train/policy_randomness_mag": 0.9166031501431396, "train/policy_randomness_max": 0.9166031501431396, "train/policy_randomness_mean": 0.19580543883468793, "train/policy_randomness_min": 0.028015904614458912, "train/policy_randomness_std": 0.22232342479021652, "train/post_ent_mag": 60.38789110598357, "train/post_ent_max": 60.38789110598357, "train/post_ent_mean": 43.82294342483299, "train/post_ent_min": 20.325306201326676, "train/post_ent_std": 7.645439033922941, "train/prior_ent_mag": 70.07363969001217, "train/prior_ent_max": 70.07363969001217, "train/prior_ent_mean": 55.95746460513792, "train/prior_ent_min": 39.591504774231844, "train/prior_ent_std": 4.571926421013432, "train/rep_loss_mean": 12.051650918048361, "train/rep_loss_std": 9.274573574895443, "train/reward_avg": 0.026639634014471718, "train/reward_loss_mean": 0.05235610570272674, "train/reward_loss_std": 0.2338495558478694, "train/reward_max_data": 1.015942032786383, "train/reward_max_pred": 1.0126705325168113, "train/reward_neg_acc": 0.9930891468041185, "train/reward_neg_loss": 0.02793357919469692, "train/reward_pos_acc": 0.9760633223298667, "train/reward_pos_loss": 0.8072341265885726, "train/reward_pred": 0.02606154957354285, "train/reward_rate": 0.031349071557971016, "train_stats/sum_log_reward": 7.509091054309498, "train_stats/max_log_achievement_collect_coal": 0.06363636363636363, "train_stats/max_log_achievement_collect_drink": 6.036363636363636, "train_stats/max_log_achievement_collect_sapling": 2.109090909090909, "train_stats/max_log_achievement_collect_stone": 0.6181818181818182, "train_stats/max_log_achievement_collect_wood": 13.445454545454545, "train_stats/max_log_achievement_defeat_skeleton": 0.01818181818181818, "train_stats/max_log_achievement_defeat_zombie": 1.3272727272727274, "train_stats/max_log_achievement_eat_cow": 0.21818181818181817, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 3.9727272727272727, "train_stats/max_log_achievement_make_wood_sword": 0.44545454545454544, "train_stats/max_log_achievement_place_furnace": 0.00909090909090909, "train_stats/max_log_achievement_place_plant": 1.8727272727272728, "train_stats/max_log_achievement_place_stone": 0.1, "train_stats/max_log_achievement_place_table": 3.5090909090909093, "train_stats/max_log_achievement_wake_up": 1.1818181818181819, "train_stats/mean_log_entropy": 0.4680581873113459, "eval_stats/sum_log_reward": 7.7250001430511475, "eval_stats/max_log_achievement_collect_coal": 0.1875, "eval_stats/max_log_achievement_collect_drink": 6.5, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 0.625, "eval_stats/max_log_achievement_collect_wood": 11.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.5, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.9375, "eval_stats/max_log_achievement_make_wood_sword": 0.4375, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 3.25, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.7459726627275813e-06, "report/cont_loss_std": 7.670008926652372e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.548315817170078e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.7471377254405525e-06, "report/cont_pred": 0.9941369891166687, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.653907775878906, "report/dyn_loss_std": 9.334715843200684, "report/image_loss_mean": 5.273765563964844, "report/image_loss_std": 8.063688278198242, "report/model_loss_mean": 12.316268920898438, "report/model_loss_std": 11.73117446899414, "report/post_ent_mag": 58.93699645996094, "report/post_ent_max": 58.93699645996094, "report/post_ent_mean": 44.24607467651367, "report/post_ent_min": 21.515247344970703, "report/post_ent_std": 7.815059661865234, "report/prior_ent_mag": 70.05772399902344, "report/prior_ent_max": 70.05772399902344, "report/prior_ent_mean": 56.263336181640625, "report/prior_ent_min": 36.83000946044922, "report/prior_ent_std": 4.578716278076172, "report/rep_loss_mean": 11.653907775878906, "report/rep_loss_std": 9.334715843200684, "report/reward_avg": 0.02363281324505806, "report/reward_loss_mean": 0.05015489086508751, "report/reward_loss_std": 0.25209739804267883, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.00119948387146, "report/reward_neg_acc": 0.9929577112197876, "report/reward_neg_loss": 0.027617886662483215, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7968810200691223, "report/reward_pred": 0.022755466401576996, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 6.5798067225841805e-06, "eval/cont_loss_std": 0.00016434132703579962, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0003037182614207268, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.706725914933486e-06, "eval/cont_pred": 0.9970656037330627, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.665237426757812, "eval/dyn_loss_std": 10.478602409362793, "eval/image_loss_mean": 8.258726119995117, "eval/image_loss_std": 11.589699745178223, "eval/model_loss_mean": 18.35834503173828, "eval/model_loss_std": 15.510892868041992, "eval/post_ent_mag": 61.199954986572266, "eval/post_ent_max": 61.199954986572266, "eval/post_ent_mean": 41.75315475463867, "eval/post_ent_min": 20.10712242126465, "eval/post_ent_std": 7.612123012542725, "eval/prior_ent_mag": 70.05772399902344, "eval/prior_ent_max": 70.05772399902344, "eval/prior_ent_mean": 56.69978713989258, "eval/prior_ent_min": 44.61255645751953, "eval/prior_ent_std": 4.3058061599731445, "eval/rep_loss_mean": 16.665237426757812, "eval/rep_loss_std": 10.478602409362793, "eval/reward_avg": 0.04794921725988388, "eval/reward_loss_mean": 0.10046999156475067, "eval/reward_loss_std": 0.5873071551322937, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017638206481934, "eval/reward_neg_acc": 0.9907408356666565, "eval/reward_neg_loss": 0.01659284718334675, "eval/reward_pos_acc": 0.7884615659713745, "eval/reward_pos_loss": 1.6683275699615479, "eval/reward_pred": 0.03834030032157898, "eval/reward_rate": 0.05078125, "replay/size": 973681.0, "replay/inserts": 21968.0, "replay/samples": 21968.0, "replay/insert_wait_avg": 1.429339351223406e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.512437560657299e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4208.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2182124214027319e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3346319198608, "timer/env.step_count": 2746.0, "timer/env.step_total": 255.46213603019714, "timer/env.step_frac": 0.2553766788418686, "timer/env.step_avg": 0.09303063948659765, "timer/env.step_min": 0.02447986602783203, "timer/env.step_max": 3.6604490280151367, "timer/replay._sample_count": 21968.0, "timer/replay._sample_total": 11.358628034591675, "timer/replay._sample_frac": 0.011354828346582368, "timer/replay._sample_avg": 0.0005170533519023887, "timer/replay._sample_min": 0.000423431396484375, "timer/replay._sample_max": 0.011262655258178711, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3272.0, "timer/agent.policy_total": 56.65394139289856, "timer/agent.policy_frac": 0.05663498951762498, "timer/agent.policy_avg": 0.0173147742643333, "timer/agent.policy_min": 0.009780406951904297, "timer/agent.policy_max": 0.1775498390197754, "timer/dataset_train_count": 1373.0, "timer/dataset_train_total": 0.16341710090637207, "timer/dataset_train_frac": 0.00016336243462124162, "timer/dataset_train_avg": 0.00011902192345693523, "timer/dataset_train_min": 0.00010323524475097656, "timer/dataset_train_max": 0.00041794776916503906, "timer/agent.train_count": 1373.0, "timer/agent.train_total": 617.7473304271698, "timer/agent.train_frac": 0.6175406816032927, "timer/agent.train_avg": 0.4499252224524179, "timer/agent.train_min": 0.4367501735687256, "timer/agent.train_max": 1.6272308826446533, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47479844093322754, "timer/agent.report_frac": 0.00047463961136883317, "timer/agent.report_avg": 0.23739922046661377, "timer/agent.report_min": 0.23071026802062988, "timer/agent.report_max": 0.24408817291259766, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8123981152177292e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 21.96031574503807}
{"step": 974688, "time": 45510.084680080414, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 974848, "time": 45517.528611421585, "episode/length": 215.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 974880, "time": 45521.6875770092, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 975088, "time": 45530.26651263237, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 975232, "time": 45536.8832449913, "episode/length": 228.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 975464, "time": 45546.16057705879, "episode/length": 252.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 975488, "time": 45548.73412322998, "episode/length": 248.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 975832, "time": 45561.59279203415, "episode/length": 122.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 975840, "time": 45563.56891536713, "episode/length": 218.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 976120, "time": 45574.50236749649, "episode/length": 35.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 976512, "time": 45589.722548007965, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 976744, "time": 45599.015774965286, "episode/length": 232.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 976872, "time": 45604.90996217728, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 976936, "time": 45608.5909204483, "episode/length": 180.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 977160, "time": 45617.65735030174, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 977200, "time": 45620.805557727814, "episode/length": 263.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 977496, "time": 45632.28015756607, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 977880, "time": 45646.699685812, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 978520, "time": 45670.277158260345, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 978736, "time": 45679.46908402443, "episode/length": 224.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 978768, "time": 45682.21919465065, "episode/length": 236.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 979008, "time": 45692.06100487709, "episode/length": 188.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 979144, "time": 45698.09084534645, "episode/length": 299.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766666666666667, "episode/intrinsic_return": 0.0}
{"step": 979672, "time": 45717.448818445206, "episode/length": 394.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9898734177215189, "episode/intrinsic_return": 0.0}
{"step": 979816, "time": 45724.05288887024, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 45751.21853041649, "eval_episode/length": 60.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9180327868852459}
{"step": 980096, "time": 45757.3043589592, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 980096, "time": 45759.60767841339, "eval_episode/length": 173.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 980096, "time": 45761.32731819153, "eval_episode/length": 175.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 980096, "time": 45763.565265893936, "eval_episode/length": 185.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.967741935483871}
{"step": 980096, "time": 45766.16821193695, "eval_episode/length": 206.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9710144927536232}
{"step": 980096, "time": 45768.12889814377, "eval_episode/length": 212.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 980096, "time": 45769.8866519928, "eval_episode/length": 38.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 980368, "time": 45779.303753614426, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 980560, "time": 45787.358698129654, "episode/length": 424.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952941176470588, "episode/intrinsic_return": 0.0}
{"step": 980632, "time": 45791.21820521355, "episode/length": 202.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 981088, "time": 45808.670784950256, "episode/length": 289.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 981136, "time": 45811.878532886505, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 981448, "time": 45823.848912239075, "episode/length": 445.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9977578475336323, "episode/intrinsic_return": 0.0}
{"step": 981640, "time": 45831.8884100914, "episode/length": 134.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.0}
{"step": 981784, "time": 45838.50880908966, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 982232, "time": 45855.24676346779, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 982280, "time": 45858.43405222893, "episode/length": 391.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 982304, "time": 45861.00784063339, "episode/length": 82.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.927710843373494, "episode/intrinsic_return": 0.0}
{"step": 982368, "time": 45864.82329916954, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 982600, "time": 45874.04655742645, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 983080, "time": 45896.22598028183, "episode/length": 242.0, "episode/score": 10.100000038743019, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 983120, "time": 45899.57076048851, "episode/length": 430.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 983432, "time": 45911.7566075325, "episode/length": 247.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 983832, "time": 45926.928505420685, "episode/length": 255.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 983864, "time": 45929.77822303772, "episode/length": 203.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 984000, "time": 45936.1254234314, "episode/length": 203.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 984296, "time": 45947.56333351135, "episode/length": 211.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 984312, "time": 45949.751468896866, "episode/length": 253.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 984424, "time": 45955.18831396103, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 984672, "time": 45965.6138715744, "episode/length": 154.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 985320, "time": 45989.00578069687, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 985496, "time": 45996.44418621063, "episode/length": 301.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 985632, "time": 46002.93090629578, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 985784, "time": 46009.48824286461, "episode/length": 243.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 985912, "time": 46015.31661272049, "episode/length": 199.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 986176, "time": 46026.31288790703, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 986224, "time": 46029.50438165665, "episode/length": 277.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 986312, "time": 46033.78360271454, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9609756097560975, "episode/intrinsic_return": 0.0}
{"step": 986736, "time": 46050.01956772804, "episode/length": 52.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 987000, "time": 46060.38149571419, "episode/length": 170.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9883040935672515, "episode/intrinsic_return": 0.0}
{"step": 987008, "time": 46062.52346730232, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 987416, "time": 46077.70690155029, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 987736, "time": 46090.23391056061, "episode/length": 227.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 987832, "time": 46095.09589910507, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 987968, "time": 46101.72675895691, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 988120, "time": 46108.47798752785, "episode/length": 327.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.0}
{"step": 988200, "time": 46113.32057595253, "episode/length": 45.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 988424, "time": 46122.47875070572, "episode/length": 176.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 988456, "time": 46125.09974837303, "episode/length": 60.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 988800, "time": 46138.653297662735, "episode/length": 257.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 989000, "time": 46146.694501161575, "episode/length": 197.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 989280, "time": 46157.99061155319, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 989664, "time": 46173.01494550705, "episode/length": 332.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 989896, "time": 46182.20269680023, "episode/length": 221.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 989960, "time": 46186.011645555496, "episode/length": 191.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 989992, "time": 46188.725230932236, "episode/length": 223.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 46212.69415473938, "eval_episode/length": 133.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9925373134328358}
{"step": 990080, "time": 46218.24978685379, "eval_episode/length": 181.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 990080, "time": 46221.02818059921, "eval_episode/length": 205.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.970873786407767}
{"step": 990080, "time": 46222.6971681118, "eval_episode/length": 208.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 990080, "time": 46224.94590425491, "eval_episode/length": 218.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 990080, "time": 46227.050791502, "eval_episode/length": 225.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 990080, "time": 46229.20336294174, "eval_episode/length": 231.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 990080, "time": 46234.18209671974, "eval_episode/length": 307.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9967532467532467}
{"step": 990096, "time": 46234.73115897179, "episode/length": 204.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 990288, "time": 46242.73994421959, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 990496, "time": 46251.302203416824, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 990568, "time": 46255.13496303558, "episode/length": 220.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 990976, "time": 46271.475192546844, "episode/length": 246.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 991104, "time": 46277.36303281784, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 991288, "time": 46286.460632801056, "episode/length": 202.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 991488, "time": 46295.54553461075, "episode/length": 186.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 991528, "time": 46298.19273352623, "episode/length": 154.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 991584, "time": 46301.74091386795, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 992088, "time": 46320.16812205315, "episode/length": 198.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9597989949748744, "episode/intrinsic_return": 0.0}
{"step": 992336, "time": 46330.214661598206, "episode/length": 220.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 992552, "time": 46338.78246879578, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 992616, "time": 46342.5873003006, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 992768, "time": 46349.74943089485, "episode/length": 223.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 993296, "time": 46369.20148682594, "episode/length": 213.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 993328, "time": 46371.84738588333, "episode/length": 229.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 993328, "time": 46371.85669851303, "episode/length": 224.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 993672, "time": 46386.647315740585, "episode/length": 166.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 993936, "time": 46397.330282211304, "episode/length": 230.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 994088, "time": 46403.794647693634, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 994128, "time": 46406.982320547104, "episode/length": 169.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 994584, "time": 46423.92166161537, "episode/length": 160.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 994656, "time": 46428.081278800964, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 994960, "time": 46440.09590601921, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 995080, "time": 46445.533957481384, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 995376, "time": 46457.28641152382, "episode/length": 179.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 995608, "time": 46466.480675935745, "episode/length": 373.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 995704, "time": 46471.60590553284, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 995776, "time": 46475.85304379463, "episode/length": 139.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 996217, "time": 46493.14967608452, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.152574970774407, "train/action_min": 0.0, "train/action_std": 3.117835300682235, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0438642952808716, "train/actor_opt_grad_steps": 61480.0, "train/actor_opt_loss": -2.5457588337416195, "train/adv_mag": 0.5627528925011628, "train/adv_max": 0.5232268056295214, "train/adv_mean": 0.003750742772944827, "train/adv_min": -0.4397244427325952, "train/adv_std": 0.06302205614582465, "train/cont_avg": 0.9947037522810219, "train/cont_loss_mean": 0.0001262597196942677, "train/cont_loss_std": 0.0038227283863575957, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0024040177725337545, "train/cont_pos_acc": 0.9999570224406945, "train/cont_pos_loss": 0.00011271390270221458, "train/cont_pred": 0.9946658224084951, "train/cont_rate": 0.9947037522810219, "train/dyn_loss_mean": 12.179555412626614, "train/dyn_loss_std": 9.342571356000692, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7706714024508956, "train/extr_critic_critic_opt_grad_steps": 61480.0, "train/extr_critic_critic_opt_loss": 15810.80775975137, "train/extr_critic_mag": 6.7475108334617895, "train/extr_critic_max": 6.7475108334617895, "train/extr_critic_mean": 1.7218919857575075, "train/extr_critic_min": -0.30325482709564433, "train/extr_critic_std": 1.5173574403254655, "train/extr_return_normed_mag": 1.6727121293979839, "train/extr_return_normed_max": 1.6727121293979839, "train/extr_return_normed_mean": 0.3689359663611781, "train/extr_return_normed_min": -0.12147277120473611, "train/extr_return_normed_std": 0.32364025255189327, "train/extr_return_rate": 0.7040303179817479, "train/extr_return_raw_mag": 7.978284310250387, "train/extr_return_raw_max": 7.978284310250387, "train/extr_return_raw_mean": 1.7398182580070773, "train/extr_return_raw_min": -0.6067595094659902, "train/extr_return_raw_std": 1.5485748183118166, "train/extr_reward_mag": 1.033129425814552, "train/extr_reward_max": 1.033129425814552, "train/extr_reward_mean": 0.034943628893063884, "train/extr_reward_min": -0.4960290985385867, "train/extr_reward_std": 0.1778779730309535, "train/image_loss_mean": 5.43697383978071, "train/image_loss_std": 10.283520601091594, "train/model_loss_mean": 12.796550855149318, "train/model_loss_std": 14.143473465077198, "train/model_opt_grad_norm": 47.64459028035185, "train/model_opt_grad_steps": 61424.722627737225, "train/model_opt_loss": 18410.630039632757, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1441.6058394160584, "train/policy_entropy_mag": 2.609937779224702, "train/policy_entropy_max": 2.609937779224702, "train/policy_entropy_mean": 0.5467509416333081, "train/policy_entropy_min": 0.0793750317101061, "train/policy_entropy_std": 0.6355729779622851, "train/policy_logprob_mag": 7.438383704554425, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5470448934683835, "train/policy_logprob_min": -7.438383704554425, "train/policy_logprob_std": 1.1026702205630114, "train/policy_randomness_mag": 0.921193500939947, "train/policy_randomness_max": 0.921193500939947, "train/policy_randomness_mean": 0.19297909203672062, "train/policy_randomness_min": 0.028015902877724083, "train/policy_randomness_std": 0.224329370651802, "train/post_ent_mag": 60.21622609047994, "train/post_ent_max": 60.21622609047994, "train/post_ent_mean": 43.84410131412701, "train/post_ent_min": 20.375668483929044, "train/post_ent_std": 7.6408334926967205, "train/prior_ent_mag": 70.12358316017763, "train/prior_ent_max": 70.12358316017763, "train/prior_ent_mean": 56.04792014351727, "train/prior_ent_min": 39.80458272112547, "train/prior_ent_std": 4.531706905713047, "train/rep_loss_mean": 12.179555412626614, "train/rep_loss_std": 9.342571356000692, "train/reward_avg": 0.026240305614786862, "train/reward_loss_mean": 0.05171757702627321, "train/reward_loss_std": 0.22542602552549681, "train/reward_max_data": 1.0145985436265486, "train/reward_max_pred": 1.0116735313930652, "train/reward_neg_acc": 0.9931478987645058, "train/reward_neg_loss": 0.02766420752027609, "train/reward_pos_acc": 0.9759549302776365, "train/reward_pos_loss": 0.8005702269338343, "train/reward_pred": 0.025637312275595472, "train/reward_rate": 0.031057538777372263, "train_stats/sum_log_reward": 8.119230952400427, "train_stats/max_log_achievement_collect_coal": 0.11538461538461539, "train_stats/max_log_achievement_collect_drink": 7.028846153846154, "train_stats/max_log_achievement_collect_sapling": 2.0288461538461537, "train_stats/max_log_achievement_collect_stone": 1.3076923076923077, "train_stats/max_log_achievement_collect_wood": 13.64423076923077, "train_stats/max_log_achievement_defeat_skeleton": 0.04807692307692308, "train_stats/max_log_achievement_defeat_zombie": 1.2596153846153846, "train_stats/max_log_achievement_eat_cow": 0.18269230769230768, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 3.2788461538461537, "train_stats/max_log_achievement_make_wood_sword": 0.8269230769230769, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.9134615384615385, "train_stats/max_log_achievement_place_stone": 0.18269230769230768, "train_stats/max_log_achievement_place_table": 3.576923076923077, "train_stats/max_log_achievement_wake_up": 1.1826923076923077, "train_stats/mean_log_entropy": 0.5106692901597574, "train_stats/max_log_achievement_make_stone_pickaxe": 0.023809523809523808, "eval_stats/sum_log_reward": 7.100000120699406, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 6.25, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 0.875, "eval_stats/max_log_achievement_collect_wood": 11.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.6875, "eval_stats/max_log_achievement_make_wood_sword": 0.75, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.0625, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.950139048607525e-07, "report/cont_loss_std": 2.803451707222848e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.7956948542851023e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.5928311825064156e-07, "report/cont_pred": 0.9951172471046448, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.026323318481445, "report/dyn_loss_std": 9.20818042755127, "report/image_loss_mean": 5.726790428161621, "report/image_loss_std": 9.944293022155762, "report/model_loss_mean": 12.382091522216797, "report/model_loss_std": 13.401599884033203, "report/post_ent_mag": 59.75294876098633, "report/post_ent_max": 59.75294876098633, "report/post_ent_mean": 44.105865478515625, "report/post_ent_min": 19.428936004638672, "report/post_ent_std": 7.772027015686035, "report/prior_ent_mag": 69.44713592529297, "report/prior_ent_max": 69.44713592529297, "report/prior_ent_mean": 55.56830978393555, "report/prior_ent_min": 36.247867584228516, "report/prior_ent_std": 4.355500221252441, "report/rep_loss_mean": 11.026323318481445, "report/rep_loss_std": 9.20818042755127, "report/reward_avg": 0.02324218675494194, "report/reward_loss_mean": 0.0395067036151886, "report/reward_loss_std": 0.16202063858509064, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0017671585083008, "report/reward_neg_acc": 0.9979940056800842, "report/reward_neg_loss": 0.020543763414025307, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.739730715751648, "report/reward_pred": 0.022898202762007713, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.222016312065534e-05, "eval/cont_loss_std": 0.0005881150718778372, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.531689774012193e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.218168058083393e-05, "eval/cont_pred": 0.9970386028289795, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.37108039855957, "eval/dyn_loss_std": 10.749581336975098, "eval/image_loss_mean": 8.679512023925781, "eval/image_loss_std": 12.858345031738281, "eval/model_loss_mean": 18.608558654785156, "eval/model_loss_std": 16.698299407958984, "eval/post_ent_mag": 62.06655502319336, "eval/post_ent_max": 62.06655502319336, "eval/post_ent_mean": 42.16021728515625, "eval/post_ent_min": 20.395336151123047, "eval/post_ent_std": 7.704718589782715, "eval/prior_ent_mag": 69.44713592529297, "eval/prior_ent_max": 69.44713592529297, "eval/prior_ent_mean": 56.375465393066406, "eval/prior_ent_min": 34.01630783081055, "eval/prior_ent_std": 4.489005088806152, "eval/rep_loss_mean": 16.37108039855957, "eval/rep_loss_std": 10.749581336975098, "eval/reward_avg": 0.05654296651482582, "eval/reward_loss_mean": 0.10636773705482483, "eval/reward_loss_std": 0.5239036679267883, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002537488937378, "eval/reward_neg_acc": 0.9937824010848999, "eval/reward_neg_loss": 0.03317062556743622, "eval/reward_pos_acc": 0.8644067645072937, "eval/reward_pos_loss": 1.3035746812820435, "eval/reward_pred": 0.04962550103664398, "eval/reward_rate": 0.0576171875, "replay/size": 995713.0, "replay/inserts": 22032.0, "replay/samples": 22032.0, "replay/insert_wait_avg": 1.443356556916635e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.732383460693803e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4184.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2250293053358964e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2766056060791, "timer/env.step_count": 2754.0, "timer/env.step_total": 248.08394408226013, "timer/env.step_frac": 0.24801534164836658, "timer/env.step_avg": 0.09008131593400877, "timer/env.step_min": 0.02491927146911621, "timer/env.step_max": 3.289707660675049, "timer/replay._sample_count": 22032.0, "timer/replay._sample_total": 11.509777069091797, "timer/replay._sample_frac": 0.011506594280606902, "timer/replay._sample_avg": 0.000522411813230383, "timer/replay._sample_min": 0.0004215240478515625, "timer/replay._sample_max": 0.008587837219238281, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3277.0, "timer/agent.policy_total": 58.34259366989136, "timer/agent.policy_frac": 0.05832646024400512, "timer/agent.policy_avg": 0.017803659954193272, "timer/agent.policy_min": 0.009801864624023438, "timer/agent.policy_max": 0.12700557708740234, "timer/dataset_train_count": 1377.0, "timer/dataset_train_total": 0.1672523021697998, "timer/dataset_train_frac": 0.0001672060520384356, "timer/dataset_train_avg": 0.00012146136686259971, "timer/dataset_train_min": 0.00010371208190917969, "timer/dataset_train_max": 0.0008039474487304688, "timer/agent.train_count": 1377.0, "timer/agent.train_total": 623.3149652481079, "timer/agent.train_frac": 0.6231426005114198, "timer/agent.train_avg": 0.45266155791438484, "timer/agent.train_min": 0.43570399284362793, "timer/agent.train_max": 2.853059768676758, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.480327844619751, "timer/agent.report_frac": 0.0004801950199852118, "timer/agent.report_avg": 0.2401639223098755, "timer/agent.report_min": 0.23188328742980957, "timer/agent.report_max": 0.2484445571899414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.2415960321461144e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 22.025581042983482}
{"step": 996224, "time": 46493.17043924332, "episode/length": 157.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 996760, "time": 46513.4711458683, "episode/length": 172.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 997200, "time": 46530.37466287613, "episode/length": 198.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 997472, "time": 46541.12731695175, "episode/length": 211.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 997552, "time": 46545.50729513168, "episode/length": 427.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 997664, "time": 46550.81707954407, "episode/length": 244.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 998032, "time": 46564.945342063904, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 998072, "time": 46567.64343905449, "episode/length": 435.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 998512, "time": 46584.34283733368, "episode/length": 218.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 998576, "time": 46588.19114565849, "episode/length": 436.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9977116704805492, "episode/intrinsic_return": 0.0}
{"step": 998880, "time": 46599.96934366226, "episode/length": 151.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 999104, "time": 46609.07884430885, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 999296, "time": 46617.08533477783, "episode/length": 261.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 999448, "time": 46625.27618122101, "episode/length": 176.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 999616, "time": 46632.726696014404, "episode/length": 39.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 999736, "time": 46638.135731220245, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 999864, "time": 46644.38547825813, "episode/length": 298.0, "episode/score": 10.10000005364418, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 999984, "time": 46650.40749311447, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 999992, "time": 46652.17611336708, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 46676.80650162697, "eval_episode/length": 156.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9617834394904459}
{"step": 1000064, "time": 46680.68134498596, "eval_episode/length": 199.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 1000064, "time": 46682.51776266098, "eval_episode/length": 203.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 1000064, "time": 46684.345793008804, "eval_episode/length": 207.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 1000064, "time": 46686.09716749191, "eval_episode/length": 212.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 1000064, "time": 46694.54309511185, "eval_episode/length": 359.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9888888888888889}
{"step": 1000064, "time": 46696.55134153366, "eval_episode/length": 368.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.991869918699187}
{"step": 1000064, "time": 46699.01977586746, "eval_episode/length": 179.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 1000480, "time": 46713.06761050224, "episode/length": 171.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 1000768, "time": 46724.38096284866, "episode/length": 235.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1001000, "time": 46734.171196460724, "episode/length": 193.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 1001048, "time": 46737.44733762741, "episode/length": 178.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 1001312, "time": 46748.471755981445, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 1001400, "time": 46752.9479970932, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 1001656, "time": 46763.31836795807, "episode/length": 146.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 1001784, "time": 46769.32257914543, "episode/length": 239.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9708333333333333, "episode/intrinsic_return": 0.0}
{"step": 1002112, "time": 46782.12038683891, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 1002152, "time": 46784.83218383789, "episode/length": 269.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 1002704, "time": 46805.433213472366, "episode/length": 206.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 1003008, "time": 46817.39002919197, "episode/length": 250.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 1003072, "time": 46821.107486248016, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 1003304, "time": 46830.35950922966, "episode/length": 237.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 1003376, "time": 46834.59949207306, "episode/length": 157.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 1003552, "time": 46842.18382000923, "episode/length": 220.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1003888, "time": 46855.32575035095, "episode/length": 278.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.974910394265233, "episode/intrinsic_return": 0.0}
{"step": 1004040, "time": 46861.98905491829, "episode/length": 235.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 1004504, "time": 46879.14697217941, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 1004760, "time": 46889.46229863167, "episode/length": 218.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1004896, "time": 46895.83591032028, "episode/length": 273.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9708029197080292, "episode/intrinsic_return": 0.0}
{"step": 1005240, "time": 46908.755455732346, "episode/length": 210.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1005384, "time": 46915.19670653343, "episode/length": 259.0, "episode/score": 10.100000038743019, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 1005392, "time": 46917.26881861687, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 1005480, "time": 46921.82017326355, "episode/length": 262.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 1005896, "time": 46937.406220674515, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 1006016, "time": 46943.25358748436, "episode/length": 156.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 1006512, "time": 46961.59989738464, "episode/length": 308.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9741100323624595, "episode/intrinsic_return": 0.0}
{"step": 1006560, "time": 46964.81592845917, "episode/length": 207.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 1006672, "time": 46970.04993867874, "episode/length": 160.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 1006752, "time": 46974.254849910736, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1007112, "time": 46987.72972488403, "episode/length": 203.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1007128, "time": 46989.81813669205, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1007464, "time": 47002.73827576637, "episode/length": 195.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1007640, "time": 47012.01490902901, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 1007984, "time": 47025.45033240318, "episode/length": 163.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1008008, "time": 47027.606122493744, "episode/length": 186.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 1008320, "time": 47040.07864165306, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 1008544, "time": 47049.30509233475, "episode/length": 247.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 1008736, "time": 47057.46246147156, "episode/length": 158.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 1008872, "time": 47063.93254518509, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 1009280, "time": 47079.75280404091, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 1009408, "time": 47085.6963224411, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1009488, "time": 47089.942744493484, "episode/length": 296.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764309764309764, "episode/intrinsic_return": 0.0}
{"step": 1009744, "time": 47100.18299484253, "episode/length": 216.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1009928, "time": 47107.77562189102, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 47134.562447309494, "eval_episode/length": 157.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 1010048, "time": 47136.406229496, "eval_episode/length": 163.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 1010048, "time": 47137.999714136124, "eval_episode/length": 164.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 1010048, "time": 47140.84572792053, "eval_episode/length": 189.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 1010048, "time": 47142.63200187683, "eval_episode/length": 192.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 1010048, "time": 47144.866342544556, "eval_episode/length": 207.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 1010048, "time": 47147.29384088516, "eval_episode/length": 60.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 1010048, "time": 47148.832820892334, "eval_episode/length": 225.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 1010120, "time": 47151.061200618744, "episode/length": 224.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1010816, "time": 47176.51929354668, "episode/length": 175.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 1010944, "time": 47182.46907901764, "episode/length": 258.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 1011320, "time": 47196.63738536835, "episode/length": 254.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1011416, "time": 47201.45547294617, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 1011896, "time": 47219.758865594864, "episode/length": 394.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9974683544303797, "episode/intrinsic_return": 0.0}
{"step": 1012040, "time": 47226.14704275131, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 1012184, "time": 47232.47309231758, "episode/length": 170.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 1012520, "time": 47245.31530189514, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 1012680, "time": 47252.43851137161, "episode/length": 366.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9945504087193461, "episode/intrinsic_return": 0.0}
{"step": 1013032, "time": 47265.83384537697, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 1013040, "time": 47267.86797642708, "episode/length": 443.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 1013048, "time": 47269.46401023865, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 1013296, "time": 47279.828525066376, "episode/length": 31.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.0}
{"step": 1013528, "time": 47288.95889043808, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 1013840, "time": 47301.256563186646, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1014000, "time": 47308.39494395256, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 1014016, "time": 47310.50746464729, "episode/length": 228.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 1014152, "time": 47316.476954460144, "episode/length": 38.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 1014184, "time": 47319.29256916046, "episode/length": 187.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 1014224, "time": 47322.407500743866, "episode/length": 148.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 1014952, "time": 47348.55819249153, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 1015024, "time": 47352.96844124794, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 1015400, "time": 47367.09277200699, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 1015808, "time": 47383.10314798355, "episode/length": 223.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1015976, "time": 47391.90973353386, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1016336, "time": 47406.07469248772, "episode/length": 263.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 1016472, "time": 47412.11327266693, "episode/length": 427.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9976635514018691, "episode/intrinsic_return": 0.0}
{"step": 1016592, "time": 47418.08504486084, "episode/length": 204.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 1016640, "time": 47421.38225245476, "episode/length": 306.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9837133550488599, "episode/intrinsic_return": 0.0}
{"step": 1016648, "time": 47423.091257333755, "episode/length": 155.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 1017608, "time": 47457.42284202576, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 1017904, "time": 47470.013212919235, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 1017944, "time": 47472.728837013245, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 1018016, "time": 47476.89849495888, "episode/length": 209.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 1018328, "time": 47489.01070976257, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1018376, "time": 47492.243671417236, "episode/length": 216.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1018377, "time": 47494.883714199066, "train_stats/sum_log_reward": 8.580392433147804, "train_stats/max_log_achievement_collect_coal": 0.18627450980392157, "train_stats/max_log_achievement_collect_drink": 7.078431372549019, "train_stats/max_log_achievement_collect_sapling": 2.2745098039215685, "train_stats/max_log_achievement_collect_stone": 2.235294117647059, "train_stats/max_log_achievement_collect_wood": 12.607843137254902, "train_stats/max_log_achievement_defeat_skeleton": 0.00980392156862745, "train_stats/max_log_achievement_defeat_zombie": 1.4803921568627452, "train_stats/max_log_achievement_eat_cow": 0.3235294117647059, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.4705882352941178, "train_stats/max_log_achievement_make_wood_sword": 1.0294117647058822, "train_stats/max_log_achievement_place_furnace": 0.0392156862745098, "train_stats/max_log_achievement_place_plant": 2.0392156862745097, "train_stats/max_log_achievement_place_stone": 0.18627450980392157, "train_stats/max_log_achievement_place_table": 3.2254901960784315, "train_stats/max_log_achievement_wake_up": 1.2745098039215685, "train_stats/mean_log_entropy": 0.5619734042123252, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.198506087707958, "train/action_min": 0.0, "train/action_std": 3.184502581040636, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04194744561108754, "train/actor_opt_grad_steps": 62860.0, "train/actor_opt_loss": -3.311206423831608, "train/adv_mag": 0.5419500555923517, "train/adv_max": 0.5134220635719436, "train/adv_mean": 0.00371462690011429, "train/adv_min": -0.4042977551333338, "train/adv_std": 0.06123117955146934, "train/cont_avg": 0.9945902652877698, "train/cont_loss_mean": 0.00025685027023999416, "train/cont_loss_std": 0.008035265725628888, "train/cont_neg_acc": 0.990339158679084, "train/cont_neg_loss": 0.02874570448338084, "train/cont_pos_acc": 0.9999646351491804, "train/cont_pos_loss": 0.00010448327501856482, "train/cont_pred": 0.9946010258557986, "train/cont_rate": 0.9945902652877698, "train/dyn_loss_mean": 12.116899956902154, "train/dyn_loss_std": 9.333397858434443, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7972124274686087, "train/extr_critic_critic_opt_grad_steps": 62860.0, "train/extr_critic_critic_opt_loss": 15631.438595998201, "train/extr_critic_mag": 6.8959994041662425, "train/extr_critic_max": 6.8959994041662425, "train/extr_critic_mean": 1.8693721757518302, "train/extr_critic_min": -0.28498116242799826, "train/extr_critic_std": 1.594450402602875, "train/extr_return_normed_mag": 1.6442854584549829, "train/extr_return_normed_max": 1.6442854584549829, "train/extr_return_normed_mean": 0.3793369245400532, "train/extr_return_normed_min": -0.12262718577822335, "train/extr_return_normed_std": 0.3273700989193196, "train/extr_return_rate": 0.7439453541803703, "train/extr_return_raw_mag": 8.19071425293847, "train/extr_return_raw_max": 8.19071425293847, "train/extr_return_raw_mean": 1.8877981378020143, "train/extr_return_raw_min": -0.6127971515809889, "train/extr_return_raw_std": 1.6310740855100343, "train/extr_reward_mag": 1.0338239206684579, "train/extr_reward_max": 1.0338239206684579, "train/extr_reward_mean": 0.03612583815354666, "train/extr_reward_min": -0.5204218788970288, "train/extr_reward_std": 0.18063792393361922, "train/image_loss_mean": 5.306846906812929, "train/image_loss_std": 10.282405040246978, "train/model_loss_mean": 12.629150102464415, "train/model_loss_std": 14.180013944776796, "train/model_opt_grad_norm": 47.96238960979654, "train/model_opt_grad_steps": 62803.474820143885, "train/model_opt_loss": 16212.796109206385, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1285.9712230215828, "train/policy_entropy_mag": 2.5849389704011325, "train/policy_entropy_max": 2.5849389704011325, "train/policy_entropy_mean": 0.563473203413778, "train/policy_entropy_min": 0.07937503386315682, "train/policy_entropy_std": 0.6566301682870165, "train/policy_logprob_mag": 7.438383764500241, "train/policy_logprob_max": -0.009455658415024229, "train/policy_logprob_mean": -0.5638166265093165, "train/policy_logprob_min": -7.438383764500241, "train/policy_logprob_std": 1.1117033649691574, "train/policy_randomness_mag": 0.9123700183930157, "train/policy_randomness_max": 0.9123700183930157, "train/policy_randomness_mean": 0.19888131095351075, "train/policy_randomness_min": 0.028015903713141412, "train/policy_randomness_std": 0.231761634349823, "train/post_ent_mag": 60.36995370439488, "train/post_ent_max": 60.36995370439488, "train/post_ent_mean": 43.904330548622625, "train/post_ent_min": 20.37930584639954, "train/post_ent_std": 7.686477674854745, "train/prior_ent_mag": 70.28531202137899, "train/prior_ent_max": 70.28531202137899, "train/prior_ent_mean": 56.11304671472783, "train/prior_ent_min": 39.77555394344193, "train/prior_ent_std": 4.55269267576204, "train/rep_loss_mean": 12.116899956902154, "train/rep_loss_std": 9.333397858434443, "train/reward_avg": 0.02653088445420102, "train/reward_loss_mean": 0.05190646175375516, "train/reward_loss_std": 0.22948017180394784, "train/reward_max_data": 1.0179856157988953, "train/reward_max_pred": 1.01275659808152, "train/reward_neg_acc": 0.9930381590513875, "train/reward_neg_loss": 0.027603264020340478, "train/reward_pos_acc": 0.9744517275755354, "train/reward_pos_loss": 0.804475018446394, "train/reward_pred": 0.026000281313447643, "train/reward_rate": 0.03139051258992806, "eval_stats/sum_log_reward": 8.100000143051147, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 6.3125, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 0.625, "eval_stats/max_log_achievement_collect_wood": 13.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.6875, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 3.4375, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 4.0625, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.0009471779339946806, "report/cont_loss_std": 0.030155319720506668, "report/cont_neg_acc": 0.8333333730697632, "report/cont_neg_loss": 0.16163240373134613, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.1379036379821628e-07, "report/cont_pred": 0.9947494268417358, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.192025184631348, "report/dyn_loss_std": 9.475337982177734, "report/image_loss_mean": 5.577754020690918, "report/image_loss_std": 13.809517860412598, "report/model_loss_mean": 13.55549430847168, "report/model_loss_std": 17.65939712524414, "report/post_ent_mag": 58.844696044921875, "report/post_ent_max": 58.844696044921875, "report/post_ent_mean": 42.78980255126953, "report/post_ent_min": 20.69289779663086, "report/post_ent_std": 7.349038600921631, "report/prior_ent_mag": 69.7383804321289, "report/prior_ent_max": 69.7383804321289, "report/prior_ent_mean": 55.895545959472656, "report/prior_ent_min": 38.751365661621094, "report/prior_ent_std": 4.495777130126953, "report/rep_loss_mean": 13.192025184631348, "report/rep_loss_std": 9.475337982177734, "report/reward_avg": 0.03359375149011612, "report/reward_loss_mean": 0.061578236520290375, "report/reward_loss_std": 0.29465076327323914, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029780864715576, "report/reward_neg_acc": 0.992893397808075, "report/reward_neg_loss": 0.027068696916103363, "report/reward_pos_acc": 0.9487179517745972, "report/reward_pos_loss": 0.9331653714179993, "report/reward_pred": 0.030474532395601273, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 3.2353689221054083e-06, "eval/cont_loss_std": 7.888492837082595e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005436419742181897, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.0261551365338164e-08, "eval/cont_pred": 0.9941437840461731, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.690631866455078, "eval/dyn_loss_std": 11.107571601867676, "eval/image_loss_mean": 12.230706214904785, "eval/image_loss_std": 18.15742301940918, "eval/model_loss_mean": 22.958099365234375, "eval/model_loss_std": 22.24439811706543, "eval/post_ent_mag": 60.86537551879883, "eval/post_ent_max": 60.86537551879883, "eval/post_ent_mean": 41.445377349853516, "eval/post_ent_min": 20.077234268188477, "eval/post_ent_std": 7.563687324523926, "eval/prior_ent_mag": 69.7383804321289, "eval/prior_ent_max": 69.7383804321289, "eval/prior_ent_mean": 56.72323226928711, "eval/prior_ent_min": 44.18506622314453, "eval/prior_ent_std": 4.195964813232422, "eval/rep_loss_mean": 17.690631866455078, "eval/rep_loss_std": 11.107571601867676, "eval/reward_avg": 0.02773437462747097, "eval/reward_loss_mean": 0.11300963908433914, "eval/reward_loss_std": 0.6345630288124084, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0168259143829346, "eval/reward_neg_acc": 0.9838383197784424, "eval/reward_neg_loss": 0.050189897418022156, "eval/reward_pos_acc": 0.7941176295280457, "eval/reward_pos_loss": 1.9421722888946533, "eval/reward_pred": 0.02435498684644699, "eval/reward_rate": 0.033203125, "replay/size": 1000000.0, "replay/inserts": 22160.0, "replay/samples": 22160.0, "replay/insert_wait_avg": 1.3775451088640235e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.389299957330476e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4912.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2537361356256838e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.7120900154114, "timer/env.step_count": 2770.0, "timer/env.step_total": 246.02292895317078, "timer/env.step_frac": 0.24560243547563224, "timer/env.step_avg": 0.08881694186035045, "timer/env.step_min": 0.024484634399414062, "timer/env.step_max": 3.3337290287017822, "timer/replay._sample_count": 22160.0, "timer/replay._sample_total": 11.624854564666748, "timer/replay._sample_frac": 0.011604985784376326, "timer/replay._sample_avg": 0.0005245872998495825, "timer/replay._sample_min": 0.0004248619079589844, "timer/replay._sample_max": 0.02842259407043457, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3384.0, "timer/agent.policy_total": 58.82518649101257, "timer/agent.policy_frac": 0.05872464461331154, "timer/agent.policy_avg": 0.017383329341315774, "timer/agent.policy_min": 0.00988006591796875, "timer/agent.policy_max": 0.10597610473632812, "timer/dataset_train_count": 1385.0, "timer/dataset_train_total": 0.16858601570129395, "timer/dataset_train_frac": 0.00016829787459059244, "timer/dataset_train_avg": 0.0001217227550189848, "timer/dataset_train_min": 0.00010418891906738281, "timer/dataset_train_max": 0.0007712841033935547, "timer/agent.train_count": 1385.0, "timer/agent.train_total": 623.4365735054016, "timer/agent.train_frac": 0.6223710182990904, "timer/agent.train_avg": 0.45013471011220335, "timer/agent.train_min": 0.4332118034362793, "timer/agent.train_max": 1.6609015464782715, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4778001308441162, "timer/agent.report_frac": 0.0004769834921696565, "timer/agent.report_avg": 0.2389000654220581, "timer/agent.report_min": 0.23239827156066895, "timer/agent.report_max": 0.24540185928344727, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.552436828613281e-05, "timer/dataset_eval_frac": 3.546365132279303e-08, "timer/dataset_eval_avg": 3.552436828613281e-05, "timer/dataset_eval_min": 3.552436828613281e-05, "timer/dataset_eval_max": 3.552436828613281e-05, "fps": 22.12181564548248}
{"step": 1019224, "time": 47523.37559103966, "episode/length": 405.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975369458128078, "episode/intrinsic_return": 0.0}
{"step": 1019384, "time": 47530.635435819626, "episode/length": 170.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 1019512, "time": 47536.47114658356, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 1019576, "time": 47540.166395902634, "episode/length": 568.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.984182776801406, "episode/intrinsic_return": 0.0}
{"step": 1019800, "time": 47549.366169929504, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
