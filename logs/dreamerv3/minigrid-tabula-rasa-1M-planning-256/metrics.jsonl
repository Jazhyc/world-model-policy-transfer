{"step": 1560, "time": 112.36202454566956, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 112.37748050689697, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 112.67868041992188, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 112.68457293510437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 112.69011998176575, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 112.69604587554932, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 112.70178651809692, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 112.7076575756073, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 237.5552065372467, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.85418701171875, "train/action_min": 0.0, "train/action_std": 1.8550806045532227, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.000947894062846899, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.9038612842559814, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.5978432893753052, "train/cont_loss_std": 0.25174903869628906, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.685546875, "train/cont_pos_loss": 0.5978432893753052, "train/cont_pred": 0.5664523839950562, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.967159271240234, "train/dyn_loss_std": 0.3796193599700928, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 10.683175086975098, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 42468.12890625, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5006.69970703125, "train/image_loss_std": 41.27793884277344, "train/model_loss_mean": 5019.4189453125, "train/model_loss_std": 41.2638053894043, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50194188.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.920623779296875, "train/policy_entropy_max": 1.920623779296875, "train/policy_entropy_mean": 1.6453883647918701, "train/policy_entropy_min": 0.6338129043579102, "train/policy_entropy_std": 0.14156781136989594, "train/policy_logprob_mag": 4.469564914703369, "train/policy_logprob_max": -0.16856452822685242, "train/policy_logprob_mean": -1.65245521068573, "train/policy_logprob_min": -4.469564914703369, "train/policy_logprob_std": 0.7218153476715088, "train/policy_randomness_mag": 0.9870054125785828, "train/policy_randomness_max": 0.9870054125785828, "train/policy_randomness_mean": 0.8455623984336853, "train/policy_randomness_min": 0.32571542263031006, "train/policy_randomness_std": 0.0727514699101448, "train/post_ent_mag": 105.61109924316406, "train/post_ent_max": 105.61109924316406, "train/post_ent_mean": 105.30809020996094, "train/post_ent_min": 104.96218872070312, "train/post_ent_std": 0.10993893444538116, "train/prior_ent_mag": 106.40514373779297, "train/prior_ent_max": 106.40514373779297, "train/prior_ent_mean": 105.59352111816406, "train/prior_ent_min": 104.73147583007812, "train/prior_ent_std": 0.26681068539619446, "train/rep_loss_mean": 10.967159271240234, "train/rep_loss_std": 0.3796193599700928, "train/reward_avg": 0.0002672093687579036, "train/reward_loss_mean": 5.541263580322266, "train/reward_loss_std": 2.5636924760874535e-07, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263580322266, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.6224388480186462, "report/cont_loss_std": 0.266589879989624, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.6513671875, "report/cont_pos_loss": 0.6224388480186462, "report/cont_pred": 0.5547043085098267, "report/cont_rate": 1.0, "report/dyn_loss_mean": 10.994817733764648, "report/dyn_loss_std": 0.3680475950241089, "report/image_loss_mean": 5006.77099609375, "report/image_loss_std": 39.34111022949219, "report/model_loss_mean": 5019.53125, "report/model_loss_std": 39.36510467529297, "report/post_ent_mag": 105.64015197753906, "report/post_ent_max": 105.64015197753906, "report/post_ent_mean": 105.31307983398438, "report/post_ent_min": 104.92564392089844, "report/post_ent_std": 0.1064898818731308, "report/prior_ent_mag": 106.21817779541016, "report/prior_ent_max": 106.21817779541016, "report/prior_ent_mean": 105.53864288330078, "report/prior_ent_min": 104.35641479492188, "report/prior_ent_std": 0.28961971402168274, "report/rep_loss_mean": 10.994817733764648, "report/rep_loss_std": 0.3680475950241089, "report/reward_avg": 0.0002672093687579036, "report/reward_loss_mean": 5.541263580322266, "report/reward_loss_std": 2.5636924760874535e-07, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263580322266, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.662472128868103, "eval/cont_loss_std": 0.2862677276134491, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.609375, "eval/cont_pos_loss": 0.662472128868103, "eval/cont_pred": 0.535521388053894, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 11.017640113830566, "eval/dyn_loss_std": 0.36407792568206787, "eval/image_loss_mean": 4999.2529296875, "eval/image_loss_std": 39.585975646972656, "eval/model_loss_mean": 5012.0673828125, "eval/model_loss_std": 39.600677490234375, "eval/post_ent_mag": 105.58926391601562, "eval/post_ent_max": 105.58926391601562, "eval/post_ent_mean": 105.29164123535156, "eval/post_ent_min": 104.90855407714844, "eval/post_ent_std": 0.10971272736787796, "eval/prior_ent_mag": 106.43726348876953, "eval/prior_ent_max": 106.43726348876953, "eval/prior_ent_mean": 105.57097625732422, "eval/prior_ent_min": 104.78792572021484, "eval/prior_ent_std": 0.2759808897972107, "eval/rep_loss_mean": 11.017640113830566, "eval/rep_loss_std": 0.36407792568206787, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.1269281580409805e-05, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.258994238717216e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.174041607600776e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.08920179094587e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 152.68351125717163, "timer/env.step_count": 196.0, "timer/env.step_total": 1.328751564025879, "timer/env.step_frac": 0.008702652651128802, "timer/env.step_avg": 0.006779344714417749, "timer/env.step_min": 0.0060939788818359375, "timer/env.step_max": 0.017307758331298828, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.07988572120666504, "timer/replay._sample_frac": 0.0005232111873043708, "timer/replay._sample_avg": 0.0007132653679166521, "timer/replay._sample_min": 0.00034046173095703125, "timer/replay._sample_max": 0.0011532306671142578, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.2682392597198486, "timer/agent.save_frac": 0.014855823271573525, "timer/agent.save_avg": 2.2682392597198486, "timer/agent.save_min": 2.2682392597198486, "timer/agent.save_max": 2.2682392597198486, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 22.814684867858887, "timer/agent.policy_frac": 0.14942468037318776, "timer/agent.policy_avg": 0.07867132713054789, "timer/agent.policy_min": 0.008899927139282227, "timer/agent.policy_max": 17.799874305725098, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 2.7418136596679688e-05, "timer/dataset_train_frac": 1.7957496766299866e-07, "timer/dataset_train_avg": 2.7418136596679688e-05, "timer/dataset_train_min": 2.7418136596679688e-05, "timer/dataset_train_max": 2.7418136596679688e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 91.87740874290466, "timer/agent.train_frac": 0.6017506932241783, "timer/agent.train_avg": 91.87740874290466, "timer/agent.train_min": 91.87740874290466, "timer/agent.train_max": 91.87740874290466, "timer/agent.report_count": 2.0, "timer/agent.report_total": 30.6470947265625, "timer/agent.report_frac": 0.2007230150408464, "timer/agent.report_avg": 15.32354736328125, "timer/agent.report_min": 7.349609851837158, "timer/agent.report_max": 23.297484874725342, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.695487976074219e-05, "timer/dataset_eval_frac": 2.420358259805634e-07, "timer/dataset_eval_avg": 3.695487976074219e-05, "timer/dataset_eval_min": 3.695487976074219e-05, "timer/dataset_eval_max": 3.695487976074219e-05}
{"step": 2312, "time": 324.7061698436737, "episode/length": 288.0, "episode/score": 0.043305038171183696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043305038171183696}
{"step": 2312, "time": 324.7134282588959, "episode/length": 288.0, "episode/score": 0.06150907544019901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06150907544019901}
{"step": 2312, "time": 324.72048354148865, "episode/length": 288.0, "episode/score": 0.08810710194427429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08810710194427429}
{"step": 2312, "time": 324.7261793613434, "episode/length": 288.0, "episode/score": 0.06424202105199583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06424202105199583}
{"step": 2312, "time": 324.73260021209717, "episode/length": 288.0, "episode/score": 0.06670589652162562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06670589652162562}
{"step": 2312, "time": 324.73828864097595, "episode/length": 288.0, "episode/score": 0.06715927733898752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06715927733898752}
{"step": 2312, "time": 324.7447786331177, "episode/length": 288.0, "episode/score": 0.06859243441363105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06859243441363105}
{"step": 2312, "time": 324.75047540664673, "episode/length": 288.0, "episode/score": 0.09475822081458318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09475822081458318}
{"step": 2928, "time": 396.02851700782776, "episode/length": 76.0, "episode/score": 0.798670000757852, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.03616998404061178}
{"step": 4624, "time": 592.501425743103, "episode/length": 288.0, "episode/score": 0.082510435341419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.082510435341419}
{"step": 4624, "time": 592.5129547119141, "episode/length": 288.0, "episode/score": 0.08319792081169908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08319792081169908}
{"step": 4624, "time": 592.5208787918091, "episode/length": 288.0, "episode/score": 0.04919823933352063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04919823933352063}
{"step": 4624, "time": 592.5269291400909, "episode/length": 288.0, "episode/score": 0.0548151947211295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0548151947211295}
{"step": 4624, "time": 592.5329630374908, "episode/length": 288.0, "episode/score": 0.09209288748735389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09209288748735389}
{"step": 4624, "time": 592.5389924049377, "episode/length": 288.0, "episode/score": 0.08228473042231599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08228473042231599}
{"step": 4624, "time": 592.545572757721, "episode/length": 288.0, "episode/score": 0.0669873556474272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0669873556474272}
{"step": 5240, "time": 664.0317335128784, "episode/length": 288.0, "episode/score": 0.06827272449362454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06827272449362454}
{"step": 6936, "time": 860.4556648731232, "episode/length": 288.0, "episode/score": 0.07221082801669354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07221082801669354}
{"step": 6936, "time": 860.4770143032074, "episode/length": 288.0, "episode/score": 0.040106269736440936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040106269736440936}
{"step": 6936, "time": 860.483998298645, "episode/length": 288.0, "episode/score": 0.04993108544022107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04993108544022107}
{"step": 6936, "time": 860.4904825687408, "episode/length": 288.0, "episode/score": 0.03874750834762608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03874750834762608}
{"step": 6936, "time": 860.4967646598816, "episode/length": 288.0, "episode/score": 0.039496573805593016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039496573805593016}
{"step": 6936, "time": 860.5029742717743, "episode/length": 288.0, "episode/score": 0.04977620220392964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04977620220392964}
{"step": 6936, "time": 860.5090398788452, "episode/length": 288.0, "episode/score": 0.042927849865861845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042927849865861845}
{"step": 7552, "time": 932.3360233306885, "episode/length": 288.0, "episode/score": 0.053846902770430916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053846902770430916}
{"step": 9248, "time": 1129.2437555789948, "episode/length": 288.0, "episode/score": 0.05854034673859587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05854034673859587}
{"step": 9248, "time": 1129.2509407997131, "episode/length": 288.0, "episode/score": 0.07380977085335871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07380977085335871}
{"step": 9248, "time": 1129.2578144073486, "episode/length": 288.0, "episode/score": 0.07163065294963644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07163065294963644}
{"step": 9248, "time": 1129.263920545578, "episode/length": 288.0, "episode/score": 0.07924420912763708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07924420912763708}
{"step": 9248, "time": 1129.2698357105255, "episode/length": 288.0, "episode/score": 0.05799247281811404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05799247281811404}
{"step": 9248, "time": 1129.2753899097443, "episode/length": 288.0, "episode/score": 0.08127151785646447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08127151785646447}
{"step": 9248, "time": 1129.2824244499207, "episode/length": 288.0, "episode/score": 0.07115439565336601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07115439565336601}
{"step": 9864, "time": 1200.3271777629852, "episode/length": 288.0, "episode/score": 0.05409834725503515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05409834725503515}
{"step": 9921, "time": 1207.840990781784, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.002204858515251, "train/action_min": 0.0, "train/action_std": 1.9980618468882365, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007163392062801378, "train/actor_opt_grad_steps": 1050.0, "train/actor_opt_loss": 19.693140077248714, "train/adv_mag": 0.0022720989800204105, "train/adv_max": 0.0022720989800204105, "train/adv_mean": 0.0013296095925399674, "train/adv_min": 0.00015345895685388213, "train/adv_std": 0.0006180997198457312, "train/cont_avg": 0.9973927183014354, "train/cont_loss_mean": 0.020825772067056412, "train/cont_loss_std": 0.2747201944956453, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.946630506567616, "train/cont_pos_acc": 0.9985468242157018, "train/cont_pos_loss": 0.005457286710294789, "train/cont_pred": 0.9953032429708818, "train/cont_rate": 0.9973927183014354, "train/dyn_loss_mean": 1.0645781036769375, "train/dyn_loss_std": 0.004629342504878669, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.021516159568963, "train/extr_critic_critic_opt_grad_steps": 1050.0, "train/extr_critic_critic_opt_loss": 12224.007314873654, "train/extr_critic_mag": 0.025000974322049813, "train/extr_critic_max": 0.02500097318129106, "train/extr_critic_mean": 0.0249359711561111, "train/extr_critic_min": 0.024888603310835988, "train/extr_critic_std": 1.5612658013993945e-05, "train/extr_return_normed_mag": 0.0043144876577245845, "train/extr_return_normed_max": 0.004314486611313691, "train/extr_return_normed_mean": 0.003408114027136575, "train/extr_return_normed_min": 0.002255195783625958, "train/extr_return_normed_std": 0.0006178407776464165, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0271719427834817, "train/extr_return_raw_max": 0.02717194164614865, "train/extr_return_raw_mean": 0.026265570149903432, "train/extr_return_raw_min": 0.025112650820134693, "train/extr_return_raw_std": 0.000617840777985845, "train/extr_reward_mag": 0.00028542525460275165, "train/extr_reward_max": 0.00028542525460275165, "train/extr_reward_mean": 0.0002850749836030167, "train/extr_reward_min": 0.00028465809434224547, "train/extr_reward_std": 1.259941617544568e-07, "train/image_loss_mean": 25.094402244858195, "train/image_loss_std": 0.35553748386969974, "train/model_loss_mean": 25.865973864445845, "train/model_loss_std": 0.6133355671923126, "train/model_opt_grad_norm": 99.95096697257115, "train/model_opt_grad_steps": 1040.0, "train/model_opt_loss": 492.36944378848284, "train/model_opt_model_opt_grad_overflow": 0.004784688995215311, "train/model_opt_model_opt_grad_scale": 15.55958433014354, "train/policy_entropy_mag": 1.9457615516972884, "train/policy_entropy_max": 1.9457615516972884, "train/policy_entropy_mean": 1.9408739605588776, "train/policy_entropy_min": 1.8830837019892972, "train/policy_entropy_std": 0.0030204596852384615, "train/policy_logprob_mag": 2.3597723068803123, "train/policy_logprob_max": -1.4920489937780006, "train/policy_logprob_mean": -1.9407623555671656, "train/policy_logprob_min": -2.3597723068803123, "train/policy_logprob_std": 0.0892854528457069, "train/policy_randomness_mag": 0.9999236946471, "train/policy_randomness_max": 0.9999236946471, "train/policy_randomness_mean": 0.9974119706016978, "train/policy_randomness_min": 0.967713649763445, "train/policy_randomness_std": 0.0015522093409349313, "train/post_ent_mag": 77.17070407046086, "train/post_ent_max": 77.17070407046086, "train/post_ent_mean": 77.05501572823411, "train/post_ent_min": 76.99599416632401, "train/post_ent_std": 0.02480091879803812, "train/prior_ent_mag": 82.6624492298473, "train/prior_ent_max": 82.6624492298473, "train/prior_ent_mean": 82.49948247882168, "train/prior_ent_min": 82.33865995270213, "train/prior_ent_std": 0.05160552706195122, "train/rep_loss_mean": 1.0645781036769375, "train/rep_loss_std": 0.004629342504878669, "train/reward_avg": 0.00037898754406637963, "train/reward_loss_mean": 0.11199676733838314, "train/reward_loss_std": 0.06816422123979252, "train/reward_max_data": 0.1362380412090837, "train/reward_max_pred": 0.0002853185936594694, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.11021826504484604, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.548037477441737, "train/reward_pred": 0.0002848147771111801, "train/reward_rate": 0.00018690191387559809, "train_stats/mean_log_entropy": 1.92308027455301, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.03648165613412857, "report/cont_loss_std": 0.4266278147697449, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.593572616577148, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037286507431417704, "report/cont_pred": 0.9962780475616455, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.4436499774456024, "report/image_loss_std": 0.08917059749364853, "report/model_loss_mean": 1.0920807123184204, "report/model_loss_std": 0.4341373145580292, "report/post_ent_mag": 62.25825881958008, "report/post_ent_max": 62.25825881958008, "report/post_ent_mean": 62.06145477294922, "report/post_ent_min": 62.03888702392578, "report/post_ent_std": 0.03238895535469055, "report/prior_ent_mag": 70.27080535888672, "report/prior_ent_max": 70.27080535888672, "report/prior_ent_mean": 69.98255157470703, "report/prior_ent_min": 69.92444610595703, "report/prior_ent_std": 0.06300929188728333, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00024138958542607725, "report/reward_loss_mean": 0.011949073523283005, "report/reward_loss_std": 0.017033366486430168, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00032126903533935547, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01194907445460558, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00032021268270909786, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0037286507431417704, "eval/cont_loss_std": 6.984919309616089e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0037286507431417704, "eval/cont_pred": 0.9962780475616455, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.45066457986831665, "eval/image_loss_std": 0.09266222268342972, "eval/model_loss_mean": 1.0564130544662476, "eval/model_loss_std": 0.09266205132007599, "eval/post_ent_mag": 62.26044845581055, "eval/post_ent_max": 62.26044845581055, "eval/post_ent_mean": 62.05951690673828, "eval/post_ent_min": 62.04066467285156, "eval/post_ent_std": 0.028350654989480972, "eval/prior_ent_mag": 70.22250366210938, "eval/prior_ent_max": 70.22250366210938, "eval/prior_ent_mean": 69.97087097167969, "eval/prior_ent_min": 69.91588592529297, "eval/prior_ent_std": 0.05478355661034584, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.002019834239035845, "eval/reward_loss_std": 3.7375084502855316e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00032126903533935547, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002019834239035845, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0003202434163540602, "eval/reward_rate": 0.0, "replay/size": 9417.0, "replay/inserts": 8360.0, "replay/samples": 33440.0, "replay/insert_wait_avg": 1.6530164691249719e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.772345862320166e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 970.2757985591888, "timer/env.step_count": 1045.0, "timer/env.step_total": 10.2158203125, "timer/env.step_frac": 0.010528779886780628, "timer/env.step_avg": 0.009775904605263157, "timer/env.step_min": 0.008810758590698242, "timer/env.step_max": 0.035027503967285156, "timer/replay._sample_count": 33440.0, "timer/replay._sample_total": 16.389739274978638, "timer/replay._sample_frac": 0.016891835599029247, "timer/replay._sample_avg": 0.0004901237821464903, "timer/replay._sample_min": 0.00030803680419921875, "timer/replay._sample_max": 0.009855508804321289, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1045.0, "timer/agent.policy_total": 10.695224523544312, "timer/agent.policy_frac": 0.011022870548174227, "timer/agent.policy_avg": 0.010234664615831878, "timer/agent.policy_min": 0.009314298629760742, "timer/agent.policy_max": 0.04036855697631836, "timer/dataset_train_count": 2090.0, "timer/dataset_train_total": 0.3714418411254883, "timer/dataset_train_frac": 0.0003828208862645661, "timer/dataset_train_avg": 0.00017772336895956377, "timer/dataset_train_min": 8.106231689453125e-05, "timer/dataset_train_max": 0.0008027553558349609, "timer/agent.train_count": 2090.0, "timer/agent.train_total": 937.0618197917938, "timer/agent.train_frac": 0.9657685177588515, "timer/agent.train_avg": 0.44835493769942286, "timer/agent.train_min": 0.43633055686950684, "timer/agent.train_max": 0.6188809871673584, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4850594997406006, "timer/agent.report_frac": 0.0004999191987070993, "timer/agent.report_avg": 0.2425297498703003, "timer/agent.report_min": 0.2397608757019043, "timer/agent.report_max": 0.2452986240386963, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.5138315169925e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 8.61600825281555}
{"step": 10088, "time": 1232.1691858768463, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 1232.1756720542908, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 1232.1813957691193, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 1232.186686515808, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 1232.1922805309296, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 1232.197765827179, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 1232.203262090683, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 1232.2087681293488, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11560, "time": 1402.9266347885132, "episode/length": 288.0, "episode/score": 0.09321239347741539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09321239347741539}
{"step": 11560, "time": 1402.9382076263428, "episode/length": 288.0, "episode/score": 0.06293395957345638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06293395957345638}
{"step": 11560, "time": 1402.9461662769318, "episode/length": 288.0, "episode/score": 0.08713241028101493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08713241028101493}
{"step": 11560, "time": 1402.9530091285706, "episode/length": 288.0, "episode/score": 0.07724814492678433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07724814492678433}
{"step": 11560, "time": 1402.959060907364, "episode/length": 288.0, "episode/score": 0.06198176330769911, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06198176330769911}
{"step": 11560, "time": 1402.965448141098, "episode/length": 288.0, "episode/score": 0.050233936593713224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050233936593713224}
{"step": 11560, "time": 1402.971647977829, "episode/length": 288.0, "episode/score": 0.06070022353196691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06070022353196691}
{"step": 12176, "time": 1474.008493423462, "episode/length": 288.0, "episode/score": 0.08560656037025183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08560656037025183}
{"step": 13872, "time": 1670.1703538894653, "episode/length": 288.0, "episode/score": 0.04544422360157796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04544422360157796}
{"step": 13872, "time": 1670.1819097995758, "episode/length": 288.0, "episode/score": 0.052054541468123716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052054541468123716}
{"step": 13872, "time": 1670.1881861686707, "episode/length": 288.0, "episode/score": 0.06540785849540498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06540785849540498}
{"step": 13872, "time": 1670.1944561004639, "episode/length": 288.0, "episode/score": 0.06285174580636976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06285174580636976}
{"step": 13872, "time": 1670.202630996704, "episode/length": 288.0, "episode/score": 0.07761143780851398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07761143780851398}
{"step": 13872, "time": 1670.209473848343, "episode/length": 288.0, "episode/score": 0.053464795746492655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053464795746492655}
{"step": 13872, "time": 1670.2159550189972, "episode/length": 288.0, "episode/score": 0.060531217722939346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060531217722939346}
{"step": 14224, "time": 1711.0184857845306, "episode/length": 43.0, "episode/score": 0.8809782119911347, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.015353159511107606}
{"step": 14488, "time": 1741.575011730194, "episode/length": 288.0, "episode/score": 0.061819102350739286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061819102350739286}
{"step": 16184, "time": 1937.1123433113098, "episode/length": 288.0, "episode/score": 0.05515167901893392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05515167901893392}
{"step": 16184, "time": 1937.1329462528229, "episode/length": 288.0, "episode/score": 0.05021541566384258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05021541566384258}
{"step": 16184, "time": 1937.1400306224823, "episode/length": 288.0, "episode/score": 0.06050422373323272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06050422373323272}
{"step": 16184, "time": 1937.1467423439026, "episode/length": 288.0, "episode/score": 0.04488548422841632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04488548422841632}
{"step": 16184, "time": 1937.153178691864, "episode/length": 288.0, "episode/score": 0.06704856716237373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06704856716237373}
{"step": 16184, "time": 1937.1599209308624, "episode/length": 288.0, "episode/score": 0.027245851903842322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027245851903842322}
{"step": 16536, "time": 1978.1057562828064, "episode/length": 288.0, "episode/score": 0.04280819944005998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04280819944005998}
{"step": 16800, "time": 2008.5382988452911, "episode/length": 288.0, "episode/score": 0.04227724805434718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04227724805434718}
{"step": 18496, "time": 2205.1815938949585, "episode/length": 288.0, "episode/score": 0.047706377708578884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047706377708578884}
{"step": 18496, "time": 2205.18874669075, "episode/length": 288.0, "episode/score": 0.033352293709640435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033352293709640435}
{"step": 18496, "time": 2205.1960756778717, "episode/length": 288.0, "episode/score": 0.03306118835959637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03306118835959637}
{"step": 18496, "time": 2205.20267534256, "episode/length": 288.0, "episode/score": 0.07203070837368841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07203070837368841}
{"step": 18496, "time": 2205.209404230118, "episode/length": 288.0, "episode/score": 0.05748943925698313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05748943925698313}
{"step": 18496, "time": 2205.2160365581512, "episode/length": 288.0, "episode/score": 0.05772214091848582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05772214091848582}
{"step": 18513, "time": 2208.0465972423553, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.999885630384784, "train/action_min": 0.0, "train/action_std": 2.000052591350591, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0002531130372585509, "train/actor_opt_grad_steps": 3165.0, "train/actor_opt_loss": 5.035079504511206, "train/adv_mag": 0.0010337991483300646, "train/adv_max": 0.0010337991483300646, "train/adv_mean": 0.0005619145321080931, "train/adv_min": -3.2878158805526305e-05, "train/adv_std": 0.0002653503006598346, "train/cont_avg": 0.9966094115070093, "train/cont_loss_mean": 0.02274148175645202, "train/cont_loss_std": 0.3215936237171501, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.733499468220353, "train/cont_pos_acc": 0.9999999869092603, "train/cont_pos_loss": 0.003300964923697376, "train/cont_pred": 0.9967046708704155, "train/cont_rate": 0.9966094115070093, "train/dyn_loss_mean": 1.000000025067374, "train/dyn_loss_std": 3.458220919264507e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.06996583868967038, "train/extr_critic_critic_opt_grad_steps": 3165.0, "train/extr_critic_critic_opt_loss": 13031.14453125, "train/extr_critic_mag": 0.06394730772927543, "train/extr_critic_max": 0.06394730772927543, "train/extr_critic_mean": 0.06378724680186432, "train/extr_critic_min": 0.06371625951517408, "train/extr_critic_std": 2.9746050933470074e-05, "train/extr_return_normed_mag": 0.0020445496644650664, "train/extr_return_normed_max": 0.0020445496644650664, "train/extr_return_normed_mean": 0.0016260938546195992, "train/extr_return_normed_min": 0.0010959882219539624, "train/extr_return_normed_std": 0.00026336962700017433, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.064767643043371, "train/extr_return_raw_max": 0.064767643043371, "train/extr_return_raw_mean": 0.06434919035810734, "train/extr_return_raw_min": 0.0638190816008599, "train/extr_return_raw_std": 0.0002633696278841692, "train/extr_reward_mag": 0.00028073954805035457, "train/extr_reward_max": 0.00028073954805035457, "train/extr_reward_mean": 0.0002805547137031001, "train/extr_reward_min": 0.0002802337441488961, "train/extr_reward_std": 8.468042307602179e-08, "train/image_loss_mean": 0.2738944296246377, "train/image_loss_std": 0.08000284537812259, "train/model_loss_mean": 0.9082373408513649, "train/model_loss_std": 0.3476855924057069, "train/model_opt_grad_norm": 76.49553578813499, "train/model_opt_grad_steps": 3155.0, "train/model_opt_loss": 62.877780789526824, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 69.36331775700934, "train/policy_entropy_mag": 1.9458892757647506, "train/policy_entropy_max": 1.9458892757647506, "train/policy_entropy_mean": 1.9449057662598441, "train/policy_entropy_min": 1.9299861181562192, "train/policy_entropy_std": 0.0006658789185234824, "train/policy_logprob_mag": 2.1802446207153463, "train/policy_logprob_max": -1.718481460464335, "train/policy_logprob_mean": -1.9449070424677055, "train/policy_logprob_min": -2.1802446207153463, "train/policy_logprob_std": 0.04446375911411281, "train/policy_randomness_mag": 0.9999893316041644, "train/policy_randomness_max": 0.9999893316041644, "train/policy_randomness_mean": 0.9994839051059473, "train/policy_randomness_min": 0.9918167279145428, "train/policy_randomness_std": 0.0003421940940332155, "train/post_ent_mag": 52.93507722159413, "train/post_ent_max": 52.93507722159413, "train/post_ent_mean": 52.7997434206098, "train/post_ent_min": 52.771021709263884, "train/post_ent_std": 0.020724106506035428, "train/prior_ent_mag": 61.1476233473448, "train/prior_ent_max": 61.1476233473448, "train/prior_ent_mean": 60.96199356506918, "train/prior_ent_min": 60.88265572307266, "train/prior_ent_std": 0.045870447818572836, "train/rep_loss_mean": 1.000000025067374, "train/rep_loss_std": 3.458220919264507e-07, "train/reward_avg": 0.00027336273838768094, "train/reward_loss_mean": 0.011601390830615413, "train/reward_loss_std": 0.03601769284806519, "train/reward_max_data": 0.05257885670724595, "train/reward_max_pred": 0.0002810191885333195, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.010968497484295724, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.917226110185895, "train/reward_pred": 0.00028071889085869227, "train/reward_rate": 6.388726635514018e-05, "eval_stats/mean_log_entropy": 0.0, "train_stats/mean_log_entropy": 1.9369888305664062, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.030943719670176506, "report/cont_loss_std": 0.38420164585113525, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.515749931335449, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004031023941934109, "report/cont_pred": 0.9959771633148193, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2721121907234192, "report/image_loss_std": 0.07488036155700684, "report/model_loss_mean": 0.9147525429725647, "report/model_loss_std": 0.38952845335006714, "report/post_ent_mag": 45.30305099487305, "report/post_ent_max": 45.30305099487305, "report/post_ent_mean": 45.264041900634766, "report/post_ent_min": 45.21653747558594, "report/post_ent_std": 0.012267321348190308, "report/prior_ent_mag": 55.45435333251953, "report/prior_ent_max": 55.45435333251953, "report/prior_ent_mean": 55.39939498901367, "report/prior_ent_min": 55.291053771972656, "report/prior_ent_std": 0.02130221016705036, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002432025212328881, "report/reward_loss_mean": 0.01169662270694971, "report/reward_loss_std": 0.017963211983442307, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00026428699493408203, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01169662270694971, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00026427221018821, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004031023941934109, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004031023941934109, "eval/cont_pred": 0.9959771633148193, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2742854356765747, "eval/image_loss_std": 0.07872708886861801, "eval/model_loss_mean": 0.8798313736915588, "eval/model_loss_std": 0.0787271186709404, "eval/post_ent_mag": 45.3026123046875, "eval/post_ent_max": 45.3026123046875, "eval/post_ent_mean": 45.265281677246094, "eval/post_ent_min": 45.21400451660156, "eval/post_ent_std": 0.011127883568406105, "eval/prior_ent_mag": 55.456024169921875, "eval/prior_ent_max": 55.456024169921875, "eval/prior_ent_mean": 55.3977165222168, "eval/prior_ent_min": 55.29291915893555, "eval/prior_ent_std": 0.019163556396961212, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0015149093233048916, "eval/reward_loss_std": 2.8153951348031114e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00026428699493408203, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015149093233048916, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002642734907567501, "eval/reward_rate": 0.0, "replay/size": 18009.0, "replay/inserts": 8592.0, "replay/samples": 34368.0, "replay/insert_wait_avg": 1.6088536775755927e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.240730624847128e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 5680.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1365100174214189e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.194876909256, "timer/env.step_count": 1074.0, "timer/env.step_total": 10.306088924407959, "timer/env.step_frac": 0.010304080896970033, "timer/env.step_avg": 0.009595985963135902, "timer/env.step_min": 0.008508682250976562, "timer/env.step_max": 0.03545045852661133, "timer/replay._sample_count": 34368.0, "timer/replay._sample_total": 17.403393030166626, "timer/replay._sample_frac": 0.01740000217152239, "timer/replay._sample_avg": 0.0005063836426375299, "timer/replay._sample_min": 0.00035381317138671875, "timer/replay._sample_max": 0.026494741439819336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1363.0, "timer/agent.policy_total": 13.809036493301392, "timer/agent.policy_frac": 0.013806345955273509, "timer/agent.policy_avg": 0.010131354727293757, "timer/agent.policy_min": 0.008990287780761719, "timer/agent.policy_max": 0.03616023063659668, "timer/dataset_train_count": 2148.0, "timer/dataset_train_total": 0.37397050857543945, "timer/dataset_train_frac": 0.0003738976445580899, "timer/dataset_train_avg": 0.00017410172652487872, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0007016658782958984, "timer/agent.train_count": 2148.0, "timer/agent.train_total": 961.1095066070557, "timer/agent.train_frac": 0.960922245049905, "timer/agent.train_avg": 0.44744390437944864, "timer/agent.train_min": 0.43665194511413574, "timer/agent.train_max": 0.5736923217773438, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47484898567199707, "timer/agent.report_frac": 0.00047475646659913694, "timer/agent.report_avg": 0.23742449283599854, "timer/agent.report_min": 0.23091411590576172, "timer/agent.report_max": 0.24393486976623535, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8127910853653386e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 8.59022178707738}
{"step": 18848, "time": 2246.592379808426, "episode/length": 288.0, "episode/score": 0.06069013592224337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06069013592224337}
{"step": 19112, "time": 2277.1055071353912, "episode/length": 288.0, "episode/score": 0.046744482309208024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046744482309208024}
{"step": 20072, "time": 2394.1665885448456, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 2394.1733014583588, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 2394.17960357666, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 2394.185286998749, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 2394.1911301612854, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 2394.1969199180603, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 2394.2027657032013, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 2394.208570241928, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20808, "time": 2479.183682203293, "episode/length": 288.0, "episode/score": 0.05225595936440186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05225595936440186}
{"step": 20808, "time": 2479.2026600837708, "episode/length": 288.0, "episode/score": 0.04641525656811041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04641525656811041}
{"step": 20808, "time": 2479.2105429172516, "episode/length": 288.0, "episode/score": 0.0717987522996566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0717987522996566}
{"step": 20808, "time": 2479.2169890403748, "episode/length": 288.0, "episode/score": 0.05614876367411625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05614876367411625}
{"step": 20808, "time": 2479.2235090732574, "episode/length": 288.0, "episode/score": 0.05196971392658156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05196971392658156}
{"step": 20808, "time": 2479.2299427986145, "episode/length": 288.0, "episode/score": 0.03208657049719932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03208657049719932}
{"step": 21160, "time": 2520.2595245838165, "episode/length": 288.0, "episode/score": 0.05266942388684015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05266942388684015}
{"step": 21424, "time": 2550.881941318512, "episode/length": 288.0, "episode/score": 0.04993763685834551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04993763685834551}
{"step": 22608, "time": 2687.3093485832214, "episode/length": 224.0, "episode/score": 0.3407833995119063, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.040783388755130545}
{"step": 23120, "time": 2746.536718606949, "episode/length": 288.0, "episode/score": 0.06165585982233779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06165585982233779}
{"step": 23120, "time": 2746.5461156368256, "episode/length": 288.0, "episode/score": 0.03830095239132447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03830095239132447}
{"step": 23120, "time": 2746.553003311157, "episode/length": 288.0, "episode/score": 0.05445220374625137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05445220374625137}
{"step": 23120, "time": 2746.560265302658, "episode/length": 288.0, "episode/score": 0.05525249544976418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05525249544976418}
{"step": 23120, "time": 2746.5674827098846, "episode/length": 288.0, "episode/score": 0.042928151670963643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042928151670963643}
{"step": 23472, "time": 2787.269452571869, "episode/length": 288.0, "episode/score": 0.04500541034153116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04500541034153116}
{"step": 23736, "time": 2817.7845261096954, "episode/length": 288.0, "episode/score": 0.0415040935535842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0415040935535842}
{"step": 24920, "time": 2955.3141462802887, "episode/length": 288.0, "episode/score": 0.042936517435578025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042936517435578025}
{"step": 25432, "time": 3014.655755996704, "episode/length": 288.0, "episode/score": 0.043955694610104956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043955694610104956}
{"step": 25432, "time": 3014.674801826477, "episode/length": 288.0, "episode/score": 0.05692935604392346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05692935604392346}
{"step": 25432, "time": 3014.680362701416, "episode/length": 288.0, "episode/score": 0.040472841141053095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040472841141053095}
{"step": 25432, "time": 3014.6958179473877, "episode/length": 288.0, "episode/score": 0.04892230405178566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04892230405178566}
{"step": 25432, "time": 3014.724413394928, "episode/length": 288.0, "episode/score": 0.018876748796742504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018876748796742504}
{"step": 25784, "time": 3055.261782646179, "episode/length": 288.0, "episode/score": 0.029448442480500603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029448442480500603}
{"step": 26048, "time": 3086.016592502594, "episode/length": 288.0, "episode/score": 0.04195554088508402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04195554088508402}
{"step": 27101, "time": 3208.246948003769, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9986524005268897, "train/action_min": 0.0, "train/action_std": 1.999670227183852, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 7.48861139411104e-05, "train/actor_opt_grad_steps": 5310.0, "train/actor_opt_loss": -2.7537974101166394, "train/adv_mag": 0.0003947439928387487, "train/adv_max": 0.0003761430119359216, "train/adv_mean": 0.0001540134677746442, "train/adv_min": -0.00011620469564615295, "train/adv_std": 9.163285082998956e-05, "train/cont_avg": 0.9963026889534884, "train/cont_loss_mean": 0.02444667618635089, "train/cont_loss_std": 0.33385395845534044, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.684633163219327, "train/cont_pos_acc": 0.999999985583993, "train/cont_pos_loss": 0.0034556392342025457, "train/cont_pred": 0.9965504784916722, "train/cont_rate": 0.9963026889534884, "train/dyn_loss_mean": 1.000000029940938, "train/dyn_loss_std": 3.5683401091414134e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03275270249348047, "train/extr_critic_critic_opt_grad_steps": 5310.0, "train/extr_critic_critic_opt_loss": 13502.512640806686, "train/extr_critic_mag": 0.07783157991808515, "train/extr_critic_max": 0.07783157991808515, "train/extr_critic_mean": 0.07769310696180477, "train/extr_critic_min": 0.07761566694392714, "train/extr_critic_std": 2.908347755885709e-05, "train/extr_return_normed_mag": 0.000632597332776979, "train/extr_return_normed_max": 0.0006146023439806561, "train/extr_return_normed_mean": 0.0004609159054775033, "train/extr_return_normed_min": 0.00026157286971114404, "train/extr_return_normed_std": 8.38923218050822e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.07800082311380742, "train/extr_return_raw_max": 0.07800082311380742, "train/extr_return_raw_mean": 0.07784714081952739, "train/extr_return_raw_min": 0.0776477936395379, "train/extr_return_raw_std": 8.389232210701329e-05, "train/extr_reward_mag": 0.0002580542897069177, "train/extr_reward_max": 0.0002580542897069177, "train/extr_reward_mean": 0.00025786359951463205, "train/extr_reward_min": 0.0002576650575149891, "train/extr_reward_std": 7.678911150561311e-08, "train/image_loss_mean": 0.2624662399291992, "train/image_loss_std": 0.08121164766855019, "train/model_loss_mean": 0.8982931680457537, "train/model_loss_std": 0.37256468187930974, "train/model_opt_grad_norm": 62.80773670285247, "train/model_opt_grad_steps": 5300.0, "train/model_opt_loss": 277.72930347531343, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 309.59302325581393, "train/policy_entropy_mag": 1.9459003986314285, "train/policy_entropy_max": 1.9459003986314285, "train/policy_entropy_mean": 1.9453972395076309, "train/policy_entropy_min": 1.9374311264171156, "train/policy_entropy_std": 0.00035748160579566693, "train/policy_logprob_mag": 2.1180623109950574, "train/policy_logprob_max": -1.7846298672432124, "train/policy_logprob_mean": -1.9453889120456784, "train/policy_logprob_min": -2.1180623109950574, "train/policy_logprob_std": 0.03195333162019419, "train/policy_randomness_mag": 0.9999950469926346, "train/policy_randomness_max": 0.9999950469926346, "train/policy_randomness_mean": 0.9997364748355955, "train/policy_randomness_min": 0.9956427019695903, "train/policy_randomness_std": 0.00018370921634202605, "train/post_ent_mag": 42.9532296646473, "train/post_ent_max": 42.9532296646473, "train/post_ent_mean": 42.92299109170603, "train/post_ent_min": 42.75015629613122, "train/post_ent_std": 0.041624231744817525, "train/prior_ent_mag": 47.09516170412995, "train/prior_ent_max": 47.09516170412995, "train/prior_ent_mean": 46.87050429942996, "train/prior_ent_min": 46.821927660565045, "train/prior_ent_std": 0.04255801109207231, "train/rep_loss_mean": 1.000000029940938, "train/rep_loss_std": 3.5683401091414134e-07, "train/reward_avg": 0.00029371515299507614, "train/reward_loss_mean": 0.011380208569557168, "train/reward_loss_std": 0.051850125076639095, "train/reward_max_data": 0.08706395728946771, "train/reward_max_pred": 0.00025802712107813637, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.010162750066279673, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.939132194519043, "train/reward_pred": 0.00025775567845029884, "train/reward_rate": 0.00012263808139534885, "train_stats/mean_log_entropy": 1.9386041577045734, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.008578329347074032, "report/cont_loss_std": 0.18289406597614288, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.858328819274902, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002860098611563444, "report/cont_pred": 0.9971438050270081, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2702673673629761, "report/image_loss_std": 0.08613283932209015, "report/model_loss_mean": 0.890272319316864, "report/model_loss_std": 0.20211046934127808, "report/post_ent_mag": 40.646697998046875, "report/post_ent_max": 40.646697998046875, "report/post_ent_mean": 40.614166259765625, "report/post_ent_min": 40.3453254699707, "report/post_ent_std": 0.057594675570726395, "report/prior_ent_mag": 46.05900955200195, "report/prior_ent_max": 46.05900955200195, "report/prior_ent_mean": 45.81914520263672, "report/prior_ent_min": 45.784664154052734, "report/prior_ent_std": 0.037176426500082016, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002362532541155815, "report/reward_loss_mean": 0.01142666582018137, "report/reward_loss_std": 0.01746484637260437, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002752542495727539, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.011426666751503944, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002752542495727539, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.002860098844394088, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002860098844394088, "eval/cont_pred": 0.9971438050270081, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26398515701293945, "eval/image_loss_std": 0.08416176587343216, "eval/model_loss_mean": 0.86829674243927, "eval/model_loss_std": 0.08416176587343216, "eval/post_ent_mag": 40.64643096923828, "eval/post_ent_max": 40.64643096923828, "eval/post_ent_mean": 40.614768981933594, "eval/post_ent_min": 40.345619201660156, "eval/post_ent_std": 0.05616914480924606, "eval/prior_ent_mag": 46.05900955200195, "eval/prior_ent_max": 46.05900955200195, "eval/prior_ent_mean": 45.81778335571289, "eval/prior_ent_min": 45.78315353393555, "eval/prior_ent_std": 0.03670898452401161, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014514923095703125, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002752542495727539, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014514923095703125, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002752542495727539, "eval/reward_rate": 0.0, "replay/size": 26597.0, "replay/inserts": 8588.0, "replay/samples": 34352.0, "replay/insert_wait_avg": 1.5594096421418103e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.228258804548714e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 7992.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2195234067712277e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1872625350952, "timer/env.step_count": 1073.0, "timer/env.step_total": 10.278482437133789, "timer/env.step_frac": 0.010276558022826381, "timer/env.step_avg": 0.009579200780180605, "timer/env.step_min": 0.008673906326293945, "timer/env.step_max": 0.02911210060119629, "timer/replay._sample_count": 34352.0, "timer/replay._sample_total": 17.419955015182495, "timer/replay._sample_frac": 0.017416693521000778, "timer/replay._sample_avg": 0.0005071016248015398, "timer/replay._sample_min": 0.00037407875061035156, "timer/replay._sample_max": 0.0257415771484375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1362.0, "timer/agent.policy_total": 14.213927984237671, "timer/agent.policy_frac": 0.014211266746399826, "timer/agent.policy_avg": 0.010436070473008568, "timer/agent.policy_min": 0.009055852890014648, "timer/agent.policy_max": 0.08729267120361328, "timer/dataset_train_count": 2147.0, "timer/dataset_train_total": 0.37364912033081055, "timer/dataset_train_frac": 0.0003735791629496978, "timer/dataset_train_avg": 0.00017403312544518422, "timer/dataset_train_min": 8.678436279296875e-05, "timer/dataset_train_max": 0.0012040138244628906, "timer/agent.train_count": 2147.0, "timer/agent.train_total": 960.584686756134, "timer/agent.train_frac": 0.9604048389112818, "timer/agent.train_avg": 0.4474078652799879, "timer/agent.train_min": 0.43529701232910156, "timer/agent.train_max": 0.8099067211151123, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4722120761871338, "timer/agent.report_frac": 0.00047212366511272636, "timer/agent.report_avg": 0.2361060380935669, "timer/agent.report_min": 0.22834253311157227, "timer/agent.report_max": 0.24386954307556152, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.836649893058442e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 8.5862778186365}
{"step": 27232, "time": 3223.2114112377167, "episode/length": 288.0, "episode/score": 0.0404037128203214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0404037128203214}
{"step": 27744, "time": 3282.4375097751617, "episode/length": 288.0, "episode/score": 0.056036444178573674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056036444178573674}
{"step": 27744, "time": 3282.4446907043457, "episode/length": 288.0, "episode/score": 0.06271249035762594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06271249035762594}
{"step": 27744, "time": 3282.451896429062, "episode/length": 288.0, "episode/score": 0.06495475022940411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06495475022940411}
{"step": 27744, "time": 3282.4582664966583, "episode/length": 288.0, "episode/score": 0.0739029234230344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0739029234230344}
{"step": 27744, "time": 3282.4644889831543, "episode/length": 288.0, "episode/score": 0.06865727261038046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06865727261038046}
{"step": 28096, "time": 3322.960830926895, "episode/length": 288.0, "episode/score": 0.04949351570326144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04949351570326144}
{"step": 28360, "time": 3353.352861404419, "episode/length": 288.0, "episode/score": 0.055969921196293626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055969921196293626}
{"step": 29544, "time": 3490.726085662842, "episode/length": 288.0, "episode/score": 0.04006602562685657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04006602562685657}
{"step": 30056, "time": 3549.896460056305, "episode/length": 288.0, "episode/score": 0.041729282312374494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041729282312374494}
{"step": 30056, "time": 3549.903461933136, "episode/length": 288.0, "episode/score": 0.057450378432591265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057450378432591265}
{"step": 30056, "time": 3549.911509037018, "episode/length": 288.0, "episode/score": 0.05194166499579467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05194166499579467}
{"step": 30056, "time": 3549.9194531440735, "episode/length": 288.0, "episode/score": 0.053701060901303777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053701060901303777}
{"step": 30056, "time": 3549.9284036159515, "episode/length": 288.0, "episode/score": 0.06292819144739781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06292819144739781}
{"step": 30056, "time": 3552.6364619731903, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 30056, "time": 3555.2034080028534, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 3555.21133518219, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 3555.218409061432, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 3555.226714849472, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 3555.23468875885, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 3555.2457184791565, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 3555.255387544632, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30408, "time": 3595.9661478996277, "episode/length": 288.0, "episode/score": 0.03733265266268404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03733265266268404}
{"step": 30672, "time": 3626.322598218918, "episode/length": 288.0, "episode/score": 0.06776847940479058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06776847940479058}
{"step": 31856, "time": 3762.608976125717, "episode/length": 288.0, "episode/score": 0.05553517797774532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05553517797774532}
{"step": 32368, "time": 3821.434268951416, "episode/length": 288.0, "episode/score": 0.05443776142611512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05443776142611512}
{"step": 32368, "time": 3821.441714286804, "episode/length": 288.0, "episode/score": 0.04390918909595598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04390918909595598}
{"step": 32368, "time": 3821.4479348659515, "episode/length": 288.0, "episode/score": 0.06623769522187217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06623769522187217}
{"step": 32368, "time": 3821.454025745392, "episode/length": 288.0, "episode/score": 0.06295543464695186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06295543464695186}
{"step": 32368, "time": 3821.45960521698, "episode/length": 288.0, "episode/score": 0.039964588266329315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039964588266329315}
{"step": 32720, "time": 3861.943096637726, "episode/length": 288.0, "episode/score": 0.0644455324245854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0644455324245854}
{"step": 32984, "time": 3892.650421142578, "episode/length": 288.0, "episode/score": 0.048943386919063414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048943386919063414}
{"step": 34168, "time": 4029.489197731018, "episode/length": 288.0, "episode/score": 0.06465319791347213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06465319791347213}
{"step": 34384, "time": 4054.4976139068604, "episode/length": 251.0, "episode/score": 0.26469925171353736, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.049074249897458344}
{"step": 34680, "time": 4088.6132526397705, "episode/length": 288.0, "episode/score": 0.07214724404842343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07214724404842343}
{"step": 34680, "time": 4088.6208860874176, "episode/length": 288.0, "episode/score": 0.0700591605238543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0700591605238543}
{"step": 34680, "time": 4088.6272110939026, "episode/length": 288.0, "episode/score": 0.056886584898862225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056886584898862225}
{"step": 34680, "time": 4088.6333062648773, "episode/length": 288.0, "episode/score": 0.06251018662224794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06251018662224794}
{"step": 35032, "time": 4129.465416431427, "episode/length": 288.0, "episode/score": 0.05246105144426849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05246105144426849}
{"step": 35296, "time": 4160.066303491592, "episode/length": 288.0, "episode/score": 0.0740250528644566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0740250528644566}
{"step": 35709, "time": 4208.574180603027, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9996014262354653, "train/action_min": 0.0, "train/action_std": 1.99939075015312, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.126603771537152e-05, "train/actor_opt_grad_steps": 7460.0, "train/actor_opt_loss": -4.7890241590350175, "train/adv_mag": 0.0003162671313729397, "train/adv_max": 0.00025915188151736594, "train/adv_mean": 4.744999973782733e-05, "train/adv_min": -0.00018917294435722882, "train/adv_std": 7.105271903170898e-05, "train/cont_avg": 0.9965570494186047, "train/cont_loss_mean": 0.02299879241496498, "train/cont_loss_std": 0.3210911833312969, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.679622238537051, "train/cont_pos_acc": 0.9999999839206074, "train/cont_pos_loss": 0.0034547143507488937, "train/cont_pred": 0.9965513614721077, "train/cont_rate": 0.9965570494186047, "train/dyn_loss_mean": 1.0005687791247702, "train/dyn_loss_std": 4.040036068926024e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.025355262870272233, "train/extr_critic_critic_opt_grad_steps": 7460.0, "train/extr_critic_critic_opt_loss": 13528.727979651163, "train/extr_critic_mag": 0.08107769378395968, "train/extr_critic_max": 0.08107769378395968, "train/extr_critic_mean": 0.08094382511321889, "train/extr_critic_min": 0.08085503190062766, "train/extr_critic_std": 3.409900803880486e-05, "train/extr_return_normed_mag": 0.00039897703154142514, "train/extr_return_normed_max": 0.0003267648608185524, "train/extr_return_normed_mean": 0.00019191787631162106, "train/extr_return_normed_min": 5.5206237837325693e-05, "train/extr_return_normed_std": 5.801474028272043e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08112610003282858, "train/extr_return_raw_max": 0.08112610003282858, "train/extr_return_raw_mean": 0.08099125755387683, "train/extr_return_raw_min": 0.08085454140984735, "train/extr_return_raw_std": 5.801474039905114e-05, "train/extr_reward_mag": 0.0002508518307708031, "train/extr_reward_max": 0.0002508518307708031, "train/extr_reward_mean": 0.00025073670034924913, "train/extr_reward_min": 0.0002506078675735829, "train/extr_reward_std": 4.071082921627769e-08, "train/image_loss_mean": 0.2559447230987771, "train/image_loss_std": 0.0824180682038152, "train/model_loss_mean": 0.8904832515605661, "train/model_loss_std": 0.3656852923853453, "train/model_opt_grad_norm": 53.64215690257937, "train/model_opt_grad_steps": 7450.0, "train/model_opt_loss": 1218.5355255836664, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1369.1860465116279, "train/policy_entropy_mag": 1.9458786132723787, "train/policy_entropy_max": 1.9458786132723787, "train/policy_entropy_mean": 1.945219927610353, "train/policy_entropy_min": 1.9327624969704207, "train/policy_entropy_std": 0.0005031543445426884, "train/policy_logprob_mag": 2.1898180872895, "train/policy_logprob_max": -1.7554643564446029, "train/policy_logprob_mean": -1.945214667431144, "train/policy_logprob_min": -2.1898180872895, "train/policy_logprob_std": 0.03580725270128527, "train/policy_randomness_mag": 0.999983852685884, "train/policy_randomness_max": 0.999983852685884, "train/policy_randomness_mean": 0.9996453495912774, "train/policy_randomness_min": 0.9932435032933258, "train/policy_randomness_std": 0.00025857017736957775, "train/post_ent_mag": 41.296976045120594, "train/post_ent_max": 41.296976045120594, "train/post_ent_mean": 41.270379656414654, "train/post_ent_min": 41.053259046687636, "train/post_ent_std": 0.046306251019759236, "train/prior_ent_mag": 43.61164666109307, "train/prior_ent_max": 43.61164666109307, "train/prior_ent_mean": 43.47782642453216, "train/prior_ent_min": 43.430123759424966, "train/prior_ent_std": 0.026649911801309087, "train/rep_loss_mean": 1.0005687791247702, "train/rep_loss_std": 4.040036068926024e-05, "train/reward_avg": 0.00029498818811018367, "train/reward_loss_mean": 0.011198448106040095, "train/reward_loss_std": 0.05765607405540555, "train/reward_max_data": 0.0905813994470897, "train/reward_max_pred": 0.0002508141273675963, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009700789018859004, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.659343752367743, "train/reward_pred": 0.0002505987812223476, "train/reward_rate": 0.00015443313953488372, "train_stats/mean_log_entropy": 1.9385185651481152, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014229193329811096, "report/cont_loss_std": 0.2623189687728882, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.944031238555908, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002624883083626628, "report/cont_pred": 0.997378408908844, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25529295206069946, "report/image_loss_std": 0.09197434782981873, "report/model_loss_mean": 0.8873461484909058, "report/model_loss_std": 0.4791284501552582, "report/post_ent_mag": 40.456520080566406, "report/post_ent_max": 40.456520080566406, "report/post_ent_mean": 40.448482513427734, "report/post_ent_min": 40.40257263183594, "report/post_ent_std": 0.0075269038788974285, "report/prior_ent_mag": 40.7437744140625, "report/prior_ent_max": 40.7437744140625, "report/prior_ent_mean": 40.730560302734375, "report/prior_ent_min": 40.66148376464844, "report/prior_ent_std": 0.015249544754624367, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004232974024489522, "report/reward_loss_mean": 0.01782403513789177, "report/reward_loss_std": 0.23940850794315338, "report/reward_max_data": 0.21687500178813934, "report/reward_max_pred": 0.00025022029876708984, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010356227867305279, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 7.657390594482422, "report/reward_pred": 0.00025022029876708984, "report/reward_rate": 0.0009765625, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.002624883083626628, "eval/cont_loss_std": 0.0, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002624883083626628, "eval/cont_pred": 0.997378408908844, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2748987674713135, "eval/image_loss_std": 0.09722341597080231, "eval/model_loss_mean": 0.8788502216339111, "eval/model_loss_std": 0.09722341597080231, "eval/post_ent_mag": 40.45569610595703, "eval/post_ent_max": 40.45569610595703, "eval/post_ent_mean": 40.448570251464844, "eval/post_ent_min": 40.40302276611328, "eval/post_ent_std": 0.007103379815816879, "eval/prior_ent_mag": 40.743865966796875, "eval/prior_ent_max": 40.743865966796875, "eval/prior_ent_mean": 40.73113250732422, "eval/prior_ent_min": 40.66148376464844, "eval/prior_ent_std": 0.014391510747373104, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013265609741210938, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00025022029876708984, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013265609741210938, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00025022029876708984, "eval/reward_rate": 0.0, "replay/size": 35205.0, "replay/inserts": 8608.0, "replay/samples": 34432.0, "replay/insert_wait_avg": 1.5252640256208115e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.452323621976774e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1538345508509442e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.310010433197, "timer/env.step_count": 1076.0, "timer/env.step_total": 10.255005359649658, "timer/env.step_frac": 0.010251827186262583, "timer/env.step_avg": 0.009530674126068455, "timer/env.step_min": 0.008620738983154297, "timer/env.step_max": 0.03467583656311035, "timer/replay._sample_count": 34432.0, "timer/replay._sample_total": 17.482356071472168, "timer/replay._sample_frac": 0.017476938038339943, "timer/replay._sample_avg": 0.0005077357130422912, "timer/replay._sample_min": 0.0003628730773925781, "timer/replay._sample_max": 0.011153936386108398, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1365.0, "timer/agent.policy_total": 13.619223833084106, "timer/agent.policy_frac": 0.013615003040093668, "timer/agent.policy_avg": 0.009977453357570774, "timer/agent.policy_min": 0.009004831314086914, "timer/agent.policy_max": 0.03608441352844238, "timer/dataset_train_count": 2152.0, "timer/dataset_train_total": 0.37366628646850586, "timer/dataset_train_frac": 0.0003735504819217843, "timer/dataset_train_avg": 0.00017363675021770717, "timer/dataset_train_min": 8.630752563476562e-05, "timer/dataset_train_max": 0.006010532379150391, "timer/agent.train_count": 2152.0, "timer/agent.train_total": 961.5432693958282, "timer/agent.train_frac": 0.961245273332234, "timer/agent.train_avg": 0.4468137868939722, "timer/agent.train_min": 0.4357614517211914, "timer/agent.train_max": 0.5746979713439941, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4758288860321045, "timer/agent.report_frac": 0.00047568141982907953, "timer/agent.report_avg": 0.23791444301605225, "timer/agent.report_min": 0.23081684112548828, "timer/agent.report_max": 0.2450120449066162, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.050812028941305e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 8.605204299134854}
{"step": 36480, "time": 4297.223875284195, "episode/length": 288.0, "episode/score": 0.054718960016117535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054718960016117535}
{"step": 36696, "time": 4322.119652748108, "episode/length": 288.0, "episode/score": 0.07014222472092513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07014222472092513}
{"step": 36992, "time": 4356.118205785751, "episode/length": 288.0, "episode/score": 0.05662546302603744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05662546302603744}
{"step": 36992, "time": 4356.125109672546, "episode/length": 288.0, "episode/score": 0.05256467154484312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05256467154484312}
{"step": 36992, "time": 4356.131427526474, "episode/length": 288.0, "episode/score": 0.03555768970039708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03555768970039708}
{"step": 36992, "time": 4356.13752412796, "episode/length": 288.0, "episode/score": 0.04311163731910028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04311163731910028}
{"step": 37344, "time": 4396.598342657089, "episode/length": 288.0, "episode/score": 0.056518886873476504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056518886873476504}
{"step": 37608, "time": 4427.159913301468, "episode/length": 288.0, "episode/score": 0.04957118466266763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04957118466266763}
{"step": 38792, "time": 4564.00102186203, "episode/length": 288.0, "episode/score": 0.053164870622069316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053164870622069316}
{"step": 39008, "time": 4588.807460069656, "episode/length": 288.0, "episode/score": 0.03936728565061287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03936728565061287}
{"step": 39304, "time": 4623.050327062607, "episode/length": 288.0, "episode/score": 0.05932144219283941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05932144219283941}
{"step": 39304, "time": 4623.05730009079, "episode/length": 288.0, "episode/score": 0.041283311225512875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041283311225512875}
{"step": 39304, "time": 4623.063506126404, "episode/length": 288.0, "episode/score": 0.06040429003903114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06040429003903114}
{"step": 39304, "time": 4623.069169998169, "episode/length": 288.0, "episode/score": 0.05938838038134975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05938838038134975}
{"step": 39656, "time": 4663.89213013649, "episode/length": 288.0, "episode/score": 0.05416703037469972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05416703037469972}
{"step": 39920, "time": 4694.397097349167, "episode/length": 288.0, "episode/score": 0.043577903831632625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043577903831632625}
{"step": 40040, "time": 4713.349462985992, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 4713.3576238155365, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 4713.3633716106415, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 4713.36897444725, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 4713.374356746674, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 4713.379748106003, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 4713.385147094727, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 4713.390404701233, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 41104, "time": 4836.118913412094, "episode/length": 288.0, "episode/score": 0.04135040364070619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04135040364070619}
{"step": 41320, "time": 4861.17488360405, "episode/length": 288.0, "episode/score": 0.05713046346778583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05713046346778583}
{"step": 41616, "time": 4895.395754337311, "episode/length": 288.0, "episode/score": 0.05088848041842198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05088848041842198}
{"step": 41616, "time": 4895.403188705444, "episode/length": 288.0, "episode/score": 0.03662700591738144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03662700591738144}
{"step": 41616, "time": 4895.411259174347, "episode/length": 288.0, "episode/score": 0.059122369143096876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059122369143096876}
{"step": 41616, "time": 4895.41769194603, "episode/length": 288.0, "episode/score": 0.05230737700324539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05230737700324539}
{"step": 41968, "time": 4936.126209020615, "episode/length": 288.0, "episode/score": 0.05150743318115758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05150743318115758}
{"step": 42232, "time": 4966.676207780838, "episode/length": 288.0, "episode/score": 0.060096550769358714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060096550769358714}
{"step": 43416, "time": 5104.1803431510925, "episode/length": 288.0, "episode/score": 0.03318947159033314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03318947159033314}
{"step": 43632, "time": 5129.134710550308, "episode/length": 288.0, "episode/score": 0.047564747225841586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047564747225841586}
{"step": 43928, "time": 5163.527354955673, "episode/length": 288.0, "episode/score": 0.04846827376211138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04846827376211138}
{"step": 43928, "time": 5163.534384965897, "episode/length": 288.0, "episode/score": 0.047538513486557576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047538513486557576}
{"step": 43928, "time": 5163.541207313538, "episode/length": 288.0, "episode/score": 0.052963318706915175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052963318706915175}
{"step": 43928, "time": 5163.547341585159, "episode/length": 288.0, "episode/score": 0.040260147304827854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040260147304827854}
{"step": 44280, "time": 5204.352807760239, "episode/length": 288.0, "episode/score": 0.04930808343844717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04930808343844717}
{"step": 44313, "time": 5209.053186416626, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.00119259856468, "train/action_min": 0.0, "train/action_std": 1.9996833845626476, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.112790867709284e-05, "train/actor_opt_grad_steps": 9610.0, "train/actor_opt_loss": -6.349097070860308, "train/adv_mag": 0.0003452776129855666, "train/adv_max": 0.00022324999404508015, "train/adv_mean": -3.4267822355443144e-05, "train/adv_min": -0.00027978576199952945, "train/adv_std": 7.874621896388458e-05, "train/cont_avg": 0.9965888444767442, "train/cont_loss_mean": 0.022816759644639355, "train/cont_loss_std": 0.321417899462063, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.691652282154391, "train/cont_pos_acc": 0.9999999836433765, "train/cont_pos_loss": 0.0034049362269078574, "train/cont_pred": 0.9966009381205536, "train/cont_rate": 0.9965888444767442, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.01604122557828939, "train/extr_critic_critic_opt_grad_steps": 9610.0, "train/extr_critic_critic_opt_loss": 13528.778760901163, "train/extr_critic_mag": 0.08149848871452864, "train/extr_critic_max": 0.08149848871452864, "train/extr_critic_mean": 0.08137779752182406, "train/extr_critic_min": 0.0812502195668775, "train/extr_critic_std": 4.26445828436552e-05, "train/extr_return_normed_mag": 0.0003531995554303014, "train/extr_return_normed_max": 0.00016408368598583132, "train/extr_return_normed_mean": 1.4539628321916436e-05, "train/extr_return_normed_min": -0.00013697466184926587, "train/extr_return_normed_std": 6.270902173011648e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08149303142414537, "train/extr_return_raw_max": 0.08149303142414537, "train/extr_return_raw_mean": 0.08134349154871563, "train/extr_return_raw_min": 0.08119197307631026, "train/extr_return_raw_std": 6.270902200190735e-05, "train/extr_reward_mag": 0.00023910056713015535, "train/extr_reward_max": 0.00023910056713015535, "train/extr_reward_mean": 0.0002389813775364526, "train/extr_reward_min": 0.00023881113806436228, "train/extr_reward_std": 5.944970892829286e-08, "train/image_loss_mean": 0.2494799311077872, "train/image_loss_std": 0.08277433660141258, "train/model_loss_mean": 0.8829344430635142, "train/model_loss_std": 0.35644482994495436, "train/model_opt_grad_norm": 46.50048536256302, "train/model_opt_grad_steps": 9599.004651162792, "train/model_opt_loss": 2320.6741358557415, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2639.5348837209303, "train/policy_entropy_mag": 1.9458932954211567, "train/policy_entropy_max": 1.9458932954211567, "train/policy_entropy_mean": 1.9450796576433405, "train/policy_entropy_min": 1.931909295015557, "train/policy_entropy_std": 0.0005946371945292623, "train/policy_logprob_mag": 2.2073074052500172, "train/policy_logprob_max": -1.726739095532617, "train/policy_logprob_mean": -1.9450766574504763, "train/policy_logprob_min": -2.2073074052500172, "train/policy_logprob_std": 0.04043770286926003, "train/policy_randomness_mag": 0.9999913980794507, "train/policy_randomness_max": 0.9999913980794507, "train/policy_randomness_mean": 0.9995732678923496, "train/policy_randomness_min": 0.9928050426549689, "train/policy_randomness_std": 0.0003055830997804743, "train/post_ent_mag": 41.083686030188275, "train/post_ent_max": 41.083686030188275, "train/post_ent_mean": 41.07516577077467, "train/post_ent_min": 41.031921014120414, "train/post_ent_std": 0.0074401569942575555, "train/prior_ent_mag": 40.739774003139765, "train/prior_ent_max": 40.739774003139765, "train/prior_ent_mean": 40.71176544899164, "train/prior_ent_min": 40.64736457647279, "train/prior_ent_std": 0.01590625340075687, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00025670946864032206, "train/reward_loss_mean": 0.010637733255794575, "train/reward_loss_std": 0.0460649510195782, "train/reward_max_data": 0.06327035156793373, "train/reward_max_pred": 0.00023913716160973837, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00964890334451961, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.475091561027195, "train/reward_pred": 0.00023889186802904965, "train/reward_rate": 0.00010446947674418605, "train_stats/mean_log_entropy": 1.938371366070163, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02557527832686901, "report/cont_loss_std": 0.35136252641677856, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6363844871521, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0035721089225262403, "report/cont_pred": 0.996434211730957, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2721582055091858, "report/image_loss_std": 0.0821719616651535, "report/model_loss_mean": 0.9079054594039917, "report/model_loss_std": 0.3603910207748413, "report/post_ent_mag": 42.05275344848633, "report/post_ent_max": 42.05275344848633, "report/post_ent_mean": 42.039222717285156, "report/post_ent_min": 42.00641632080078, "report/post_ent_std": 0.006914660334587097, "report/prior_ent_mag": 40.68233871459961, "report/prior_ent_max": 40.68233871459961, "report/prior_ent_mean": 40.60105514526367, "report/prior_ent_min": 40.572784423828125, "report/prior_ent_std": 0.016359634697437286, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00020785839296877384, "report/reward_loss_mean": 0.010171948000788689, "report/reward_loss_std": 0.016547761857509613, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00024080276489257812, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010171948000788689, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00024080276489257812, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0035721093881875277, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0035721093881875277, "eval/cont_pred": 0.996434211730957, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.27397531270980835, "eval/image_loss_std": 0.07763484120368958, "eval/model_loss_mean": 0.8788358569145203, "eval/model_loss_std": 0.07763484120368958, "eval/post_ent_mag": 42.054134368896484, "eval/post_ent_max": 42.054134368896484, "eval/post_ent_mean": 42.03911590576172, "eval/post_ent_min": 42.00641632080078, "eval/post_ent_std": 0.006429383065551519, "eval/prior_ent_mag": 40.667335510253906, "eval/prior_ent_max": 40.667335510253906, "eval/prior_ent_mean": 40.60123825073242, "eval/prior_ent_min": 40.57025146484375, "eval/prior_ent_std": 0.01647079549729824, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012884140014648438, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00024080276489257812, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012884140014648438, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00024080276489257812, "eval/reward_rate": 0.0, "replay/size": 43809.0, "replay/inserts": 8604.0, "replay/samples": 34416.0, "replay/insert_wait_avg": 1.5419341973624412e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.538829509960336e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 12616.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.057002783646633e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4664885997772, "timer/env.step_count": 1076.0, "timer/env.step_total": 10.411072492599487, "timer/env.step_frac": 0.010406218110484151, "timer/env.step_avg": 0.009675717929925174, "timer/env.step_min": 0.008665084838867188, "timer/env.step_max": 0.05265307426452637, "timer/replay._sample_count": 34416.0, "timer/replay._sample_total": 17.70480489730835, "timer/replay._sample_frac": 0.017696549658637203, "timer/replay._sample_avg": 0.0005144352887409446, "timer/replay._sample_min": 0.0003719329833984375, "timer/replay._sample_max": 0.040305376052856445, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1365.0, "timer/agent.policy_total": 13.617119312286377, "timer/agent.policy_frac": 0.013610770043227022, "timer/agent.policy_avg": 0.009975911584092584, "timer/agent.policy_min": 0.008727550506591797, "timer/agent.policy_max": 0.03627300262451172, "timer/dataset_train_count": 2151.0, "timer/dataset_train_total": 0.3757796287536621, "timer/dataset_train_frac": 0.0003756044135767026, "timer/dataset_train_avg": 0.0001746999668775742, "timer/dataset_train_min": 8.630752563476562e-05, "timer/dataset_train_max": 0.0011899471282958984, "timer/agent.train_count": 2151.0, "timer/agent.train_total": 961.4888541698456, "timer/agent.train_frac": 0.9610405397141452, "timer/agent.train_avg": 0.4469962130031825, "timer/agent.train_min": 0.4358375072479248, "timer/agent.train_max": 0.5862183570861816, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47791504859924316, "timer/agent.report_frac": 0.0004776922106287825, "timer/agent.report_avg": 0.23895752429962158, "timer/agent.report_min": 0.2312633991241455, "timer/agent.report_max": 0.24665164947509766, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.835858195789673e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 8.599871671863331}
{"step": 44544, "time": 5235.73549413681, "episode/length": 288.0, "episode/score": 0.052510472993795076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052510472993795076}
{"step": 45728, "time": 5373.213005065918, "episode/length": 288.0, "episode/score": 0.05262080844210715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05262080844210715}
{"step": 45944, "time": 5398.1568830013275, "episode/length": 288.0, "episode/score": 0.05438616088123638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05438616088123638}
{"step": 46240, "time": 5432.606806516647, "episode/length": 288.0, "episode/score": 0.050211350054482295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050211350054482295}
{"step": 46240, "time": 5432.614620685577, "episode/length": 288.0, "episode/score": 0.02852109824918614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02852109824918614}
{"step": 46240, "time": 5432.621306657791, "episode/length": 288.0, "episode/score": 0.049106226200962055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049106226200962055}
{"step": 46240, "time": 5432.627804994583, "episode/length": 288.0, "episode/score": 0.05749685250044223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05749685250044223}
{"step": 46592, "time": 5473.310898303986, "episode/length": 288.0, "episode/score": 0.05101880591533359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05101880591533359}
{"step": 46856, "time": 5503.831729650497, "episode/length": 288.0, "episode/score": 0.037135941889125945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037135941889125945}
{"step": 48040, "time": 5641.266649723053, "episode/length": 288.0, "episode/score": 0.06761720147702732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06761720147702732}
{"step": 48256, "time": 5666.229009151459, "episode/length": 288.0, "episode/score": 0.08494312163041684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08494312163041684}
{"step": 48552, "time": 5700.667947769165, "episode/length": 288.0, "episode/score": 0.07011005915938995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07011005915938995}
{"step": 48552, "time": 5700.679646015167, "episode/length": 288.0, "episode/score": 0.07351876924107614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07351876924107614}
{"step": 48552, "time": 5700.687119483948, "episode/length": 288.0, "episode/score": 0.04235139105021801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04235139105021801}
{"step": 48552, "time": 5700.692811489105, "episode/length": 288.0, "episode/score": 0.06808819559573465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06808819559573465}
{"step": 48904, "time": 5741.513212919235, "episode/length": 288.0, "episode/score": 0.06173259773840556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06173259773840556}
{"step": 49168, "time": 5772.678283214569, "episode/length": 288.0, "episode/score": 0.09280620310974541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09280620310974541}
{"step": 50024, "time": 5876.519680976868, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 5876.529316186905, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 5876.535127878189, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 5876.540672779083, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 5876.546806573868, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 5876.552269935608, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 5876.557541847229, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 5876.562858104706, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50352, "time": 5914.579191207886, "episode/length": 288.0, "episode/score": 0.09064608240377936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09064608240377936}
{"step": 50568, "time": 5939.490444660187, "episode/length": 288.0, "episode/score": 0.07803672646388549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07803672646388549}
{"step": 50864, "time": 5973.806028366089, "episode/length": 288.0, "episode/score": 0.08191723361647263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08191723361647263}
{"step": 50864, "time": 5973.812900543213, "episode/length": 288.0, "episode/score": 0.09641628937043834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09641628937043834}
{"step": 50864, "time": 5973.8190705776215, "episode/length": 288.0, "episode/score": 0.09633607046802695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09633607046802695}
{"step": 50864, "time": 5973.82516169548, "episode/length": 288.0, "episode/score": 0.10967574267071711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10967574267071711}
{"step": 51216, "time": 6014.5680775642395, "episode/length": 288.0, "episode/score": 0.0835766172106247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0835766172106247}
{"step": 51480, "time": 6045.308564424515, "episode/length": 288.0, "episode/score": 0.11168723019704885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11168723019704885}
{"step": 52664, "time": 6182.383195638657, "episode/length": 288.0, "episode/score": 0.10633036745304736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10633036745304736}
{"step": 52880, "time": 6207.500331401825, "episode/length": 288.0, "episode/score": 0.05818815002339761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05818815002339761}
{"step": 52889, "time": 6209.414671182632, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.427845941587936, "train/action_min": 0.0, "train/action_std": 1.8866995384526808, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0004658955194700379, "train/actor_opt_grad_steps": 11760.0, "train/actor_opt_loss": 0.38588614148455996, "train/adv_mag": 0.0024959746834843657, "train/adv_max": 0.002441404551960701, "train/adv_mean": 0.0004091052551323861, "train/adv_min": -0.0011320300226987795, "train/adv_std": 0.00045618569697686577, "train/cont_avg": 0.9965116279069768, "train/cont_loss_mean": 0.02325048658693599, "train/cont_loss_std": 0.3242545827463951, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.682627174089539, "train/cont_pos_acc": 0.999999985029531, "train/cont_pos_loss": 0.0034366119804597178, "train/cont_pred": 0.9965693775997605, "train/cont_rate": 0.9965116279069768, "train/dyn_loss_mean": 1.000022442950759, "train/dyn_loss_std": 0.0005163558618013942, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.050072368148844255, "train/extr_critic_critic_opt_grad_steps": 11760.0, "train/extr_critic_critic_opt_loss": 13441.932844295057, "train/extr_critic_mag": 0.08678538300270258, "train/extr_critic_max": 0.08678538300270258, "train/extr_critic_mean": 0.08608630906010784, "train/extr_critic_min": 0.08468208867450093, "train/extr_critic_std": 0.00024295321303260037, "train/extr_return_normed_mag": 0.003248936977497367, "train/extr_return_normed_max": 0.0031386488745378895, "train/extr_return_normed_mean": 0.0014041216681541068, "train/extr_return_normed_min": -5.6862796461859415e-05, "train/extr_return_normed_std": 0.00045959326611367477, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08822997153498406, "train/extr_return_raw_max": 0.08822997153498406, "train/extr_return_raw_mean": 0.0864954489261605, "train/extr_return_raw_min": 0.08503445986398431, "train/extr_return_raw_std": 0.00045959326636748726, "train/extr_reward_mag": 0.0006758556809536246, "train/extr_reward_max": 0.0006758556809536246, "train/extr_reward_mean": 0.0003310647147415249, "train/extr_reward_min": 0.00011576996293178824, "train/extr_reward_std": 0.0001528835895942515, "train/image_loss_mean": 0.22001396743364113, "train/image_loss_std": 0.09083400760279145, "train/model_loss_mean": 0.8529272750366566, "train/model_loss_std": 0.35128502461106276, "train/model_opt_grad_norm": 42.93255771370821, "train/model_opt_grad_steps": 11747.097674418605, "train/model_opt_loss": 2522.735676894077, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2965.1162790697676, "train/policy_entropy_mag": 1.920299125826636, "train/policy_entropy_max": 1.920299125826636, "train/policy_entropy_mean": 1.7714592362559118, "train/policy_entropy_min": 1.4454428570215092, "train/policy_entropy_std": 0.058384290107168516, "train/policy_logprob_mag": 3.2520884380784145, "train/policy_logprob_max": -0.8159526113160821, "train/policy_logprob_mean": -1.771560069017632, "train/policy_logprob_min": -3.2520884380784145, "train/policy_logprob_std": 0.48173301762273146, "train/policy_randomness_mag": 0.9868385966434036, "train/policy_randomness_max": 0.9868385966434036, "train/policy_randomness_mean": 0.9103500174921613, "train/policy_randomness_min": 0.7428107330965441, "train/policy_randomness_std": 0.03000359158491889, "train/post_ent_mag": 45.00301641419876, "train/post_ent_max": 45.00301641419876, "train/post_ent_mean": 44.87421878548555, "train/post_ent_min": 44.73646240234375, "train/post_ent_std": 0.05358596263929855, "train/prior_ent_mag": 43.475262007602424, "train/prior_ent_max": 43.475262007602424, "train/prior_ent_mean": 41.32697466473247, "train/prior_ent_min": 40.54038369821948, "train/prior_ent_std": 0.41440967802218226, "train/rep_loss_mean": 1.000022442950759, "train/rep_loss_std": 0.0005163558618013942, "train/reward_avg": 0.0002224899705250336, "train/reward_loss_mean": 0.009649333953424249, "train/reward_loss_std": 0.030978984381397102, "train/reward_max_data": 0.026075582369772154, "train/reward_max_pred": 0.0006398744361345158, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00913757411763072, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.39875602722168, "train/reward_pred": 0.00023117837723517833, "train/reward_rate": 5.450581395348837e-05, "train_stats/mean_log_entropy": 1.7895645521305226, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.047243762761354446, "report/cont_loss_std": 0.48874717950820923, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.555144309997559, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0038744756020605564, "report/cont_pred": 0.996133029460907, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18505026400089264, "report/image_loss_std": 0.11220033466815948, "report/model_loss_mean": 0.8505933284759521, "report/model_loss_std": 0.6647543907165527, "report/post_ent_mag": 45.375244140625, "report/post_ent_max": 45.375244140625, "report/post_ent_mean": 45.16830062866211, "report/post_ent_min": 44.96601104736328, "report/post_ent_std": 0.08202137798070908, "report/prior_ent_mag": 45.991249084472656, "report/prior_ent_max": 45.991249084472656, "report/prior_ent_mean": 42.21198272705078, "report/prior_ent_min": 39.79662322998047, "report/prior_ent_std": 0.9554556608200073, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004252558574080467, "report/reward_loss_mean": 0.018299249932169914, "report/reward_loss_std": 0.2879756987094879, "report/reward_max_data": 0.21687500178813934, "report/reward_max_pred": 0.0009639263153076172, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009309722110629082, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 9.214584350585938, "report/reward_pred": 0.00022600323427468538, "report/reward_rate": 0.0009765625, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0038749363739043474, "eval/cont_loss_std": 5.071302894066321e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0038749363739043474, "eval/cont_pred": 0.9961326122283936, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1799626350402832, "eval/image_loss_std": 0.1248500868678093, "eval/model_loss_mean": 0.7848466634750366, "eval/model_loss_std": 0.12507228553295135, "eval/post_ent_mag": 45.357364654541016, "eval/post_ent_max": 45.357364654541016, "eval/post_ent_mean": 45.17200469970703, "eval/post_ent_min": 44.96539306640625, "eval/post_ent_std": 0.07517310231924057, "eval/prior_ent_mag": 45.94778823852539, "eval/prior_ent_max": 45.94778823852539, "eval/prior_ent_mean": 42.64629364013672, "eval/prior_ent_min": 39.648094177246094, "eval/prior_ent_std": 1.040839672088623, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0010090619325637817, "eval/reward_loss_std": 0.0013757136184722185, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0012379884719848633, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010090619325637817, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0001918624620884657, "eval/reward_rate": 0.0, "replay/size": 52385.0, "replay/inserts": 8576.0, "replay/samples": 34304.0, "replay/insert_wait_avg": 1.5380722818089955e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.597149888970958e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14928.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.054012239185584e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3501534461975, "timer/env.step_count": 1072.0, "timer/env.step_total": 10.303198099136353, "timer/env.step_frac": 0.010299591661621608, "timer/env.step_avg": 0.009611192256657046, "timer/env.step_min": 0.008704423904418945, "timer/env.step_max": 0.03473472595214844, "timer/replay._sample_count": 34304.0, "timer/replay._sample_total": 17.607557773590088, "timer/replay._sample_frac": 0.0176013945846184, "timer/replay._sample_avg": 0.0005132800190528827, "timer/replay._sample_min": 0.0003638267517089844, "timer/replay._sample_max": 0.011232614517211914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1361.0, "timer/agent.policy_total": 13.488033056259155, "timer/agent.policy_frac": 0.013483311828156371, "timer/agent.policy_avg": 0.009910384317604081, "timer/agent.policy_min": 0.008861780166625977, "timer/agent.policy_max": 0.038811445236206055, "timer/dataset_train_count": 2144.0, "timer/dataset_train_total": 0.3748142719268799, "timer/dataset_train_frac": 0.00037468307535681183, "timer/dataset_train_avg": 0.00017482008951813426, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0008060932159423828, "timer/agent.train_count": 2144.0, "timer/agent.train_total": 961.8970568180084, "timer/agent.train_frac": 0.9615603631431269, "timer/agent.train_avg": 0.4486460153069069, "timer/agent.train_min": 0.43721699714660645, "timer/agent.train_max": 0.6032838821411133, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47286319732666016, "timer/agent.report_frac": 0.00047269768060478683, "timer/agent.report_avg": 0.23643159866333008, "timer/agent.report_min": 0.2296617031097412, "timer/agent.report_max": 0.24320149421691895, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0030225779750004e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 8.572883036537451}
{"step": 53176, "time": 6242.416514635086, "episode/length": 288.0, "episode/score": 0.06443784146619436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06443784146619436}
{"step": 53176, "time": 6242.425801753998, "episode/length": 288.0, "episode/score": 0.08230134430676372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08230134430676372}
{"step": 53176, "time": 6242.431911706924, "episode/length": 288.0, "episode/score": 0.05864077707654758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05864077707654758}
{"step": 53176, "time": 6242.438040018082, "episode/length": 288.0, "episode/score": 0.06387477013789322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06387477013789322}
{"step": 53528, "time": 6283.024832010269, "episode/length": 288.0, "episode/score": 0.08717244188419926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08717244188419926}
{"step": 53792, "time": 6313.442495346069, "episode/length": 288.0, "episode/score": 0.06062453929271072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06062453929271072}
{"step": 54976, "time": 6450.15771150589, "episode/length": 288.0, "episode/score": 0.0678678788288849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0678678788288849}
{"step": 55192, "time": 6475.105163812637, "episode/length": 288.0, "episode/score": 0.07121547304168274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07121547304168274}
{"step": 55488, "time": 6509.378418207169, "episode/length": 288.0, "episode/score": 0.05931878539488622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05931878539488622}
{"step": 55488, "time": 6509.385576248169, "episode/length": 288.0, "episode/score": 0.06582418667733947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06582418667733947}
{"step": 55488, "time": 6509.392345666885, "episode/length": 288.0, "episode/score": 0.05936945364939561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05936945364939561}
{"step": 55488, "time": 6509.398297548294, "episode/length": 288.0, "episode/score": 0.04553797074341759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04553797074341759}
{"step": 55840, "time": 6550.258150815964, "episode/length": 288.0, "episode/score": 0.036791068822530804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036791068822530804}
{"step": 56104, "time": 6580.959779262543, "episode/length": 288.0, "episode/score": 0.049304596446759774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049304596446759774}
{"step": 57288, "time": 6717.66423034668, "episode/length": 288.0, "episode/score": 0.06965897465651949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06965897465651949}
{"step": 57504, "time": 6742.965678453445, "episode/length": 288.0, "episode/score": 0.10387866317325489, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10387866317325489}
{"step": 57800, "time": 6776.981970310211, "episode/length": 288.0, "episode/score": 0.09861854468308451, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09861854468308451}
{"step": 57800, "time": 6776.988309144974, "episode/length": 288.0, "episode/score": 0.1004616182124849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1004616182124849}
{"step": 57800, "time": 6777.00025677681, "episode/length": 288.0, "episode/score": 0.07253510738456725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07253510738456725}
{"step": 57800, "time": 6777.00585436821, "episode/length": 288.0, "episode/score": 0.08371310672766441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08371310672766441}
{"step": 58152, "time": 6817.807354688644, "episode/length": 288.0, "episode/score": 0.06555838321660445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06555838321660445}
{"step": 58416, "time": 6848.538761854172, "episode/length": 288.0, "episode/score": 0.060789745822681596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060789745822681596}
{"step": 59592, "time": 6984.124405384064, "episode/length": 146.0, "episode/score": 0.5607578067234726, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.017007790006232426}
{"step": 59600, "time": 6985.0615475177765, "episode/length": 288.0, "episode/score": 0.054372835315462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054372835315462}
{"step": 59816, "time": 7009.886291980743, "episode/length": 288.0, "episode/score": 0.02526468972996554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02526468972996554}
{"step": 60008, "time": 7037.589972019196, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 7037.5961084365845, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 7037.602032899857, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 7037.60887503624, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 7037.614634990692, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 7037.620514154434, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 7037.626615762711, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 7037.631953001022, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60112, "time": 7049.560654640198, "episode/length": 288.0, "episode/score": 0.027921701937486887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027921701937486887}
{"step": 60112, "time": 7049.57204914093, "episode/length": 288.0, "episode/score": 0.019663190607786873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019663190607786873}
{"step": 60112, "time": 7049.579993486404, "episode/length": 288.0, "episode/score": 0.042018609303568155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042018609303568155}
{"step": 60112, "time": 7049.586882352829, "episode/length": 288.0, "episode/score": 0.02668431234980062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02668431234980062}
{"step": 60464, "time": 7090.14274263382, "episode/length": 288.0, "episode/score": 0.02591061674775119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02591061674775119}
{"step": 61489, "time": 7209.726378917694, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8252055323401164, "train/action_min": 0.0, "train/action_std": 1.9425952226616616, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008042019805776193, "train/actor_opt_grad_steps": 13910.0, "train/actor_opt_loss": 21.2354109547924, "train/adv_mag": 0.19683439783578696, "train/adv_max": 0.16961401919292848, "train/adv_mean": 0.01135399141571936, "train/adv_min": -0.09515240649844325, "train/adv_std": 0.02251605979873539, "train/cont_avg": 0.996461664244186, "train/cont_loss_mean": 0.018773580051763633, "train/cont_loss_std": 0.27627707807520446, "train/cont_neg_acc": 0.14024595838953863, "train/cont_neg_loss": 4.490031410360111, "train/cont_pos_acc": 0.9998905495155689, "train/cont_pos_loss": 0.0028360870071188655, "train/cont_pred": 0.9967786594878796, "train/cont_rate": 0.996461664244186, "train/dyn_loss_mean": 1.000014417670494, "train/dyn_loss_std": 0.0003390037895896544, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0094998119853784, "train/extr_critic_critic_opt_grad_steps": 13910.0, "train/extr_critic_critic_opt_loss": 12030.99371366279, "train/extr_critic_mag": 0.20178307821584301, "train/extr_critic_max": 0.20178307821584301, "train/extr_critic_mean": 0.1791841635870379, "train/extr_critic_min": 0.15724969963694727, "train/extr_critic_std": 0.011197246389996888, "train/extr_return_normed_mag": 0.22187912183445554, "train/extr_return_normed_max": 0.2118295316086259, "train/extr_return_normed_mean": 0.036157110639777425, "train/extr_return_normed_min": -0.06573289345170176, "train/extr_return_normed_std": 0.02889606648796173, "train/extr_return_rate": 0.022542394476240166, "train/extr_return_raw_mag": 0.3662105627531229, "train/extr_return_raw_max": 0.3662105627531229, "train/extr_return_raw_mean": 0.19053815003744393, "train/extr_return_raw_min": 0.08864813731160275, "train/extr_return_raw_std": 0.028896066414322272, "train/extr_reward_mag": 0.12218331458956697, "train/extr_reward_max": 0.12218331458956697, "train/extr_reward_mean": 0.0017787749601222119, "train/extr_reward_min": 1.3934734255768533e-05, "train/extr_reward_std": 0.008533634481745838, "train/image_loss_mean": 0.1547674749826276, "train/image_loss_std": 0.10113254414741384, "train/model_loss_mean": 0.7829443349394687, "train/model_loss_std": 0.30951262431782345, "train/model_opt_grad_norm": 37.34447284964628, "train/model_opt_grad_steps": 13895.167441860465, "train/model_opt_loss": 2052.4475847111194, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2627.906976744186, "train/policy_entropy_mag": 1.7521226888479189, "train/policy_entropy_max": 1.7521226888479189, "train/policy_entropy_mean": 0.8050296111855396, "train/policy_entropy_min": 0.2838735959211061, "train/policy_entropy_std": 0.31722203420345174, "train/policy_logprob_mag": 6.032375319059505, "train/policy_logprob_max": -0.08475996747093145, "train/policy_logprob_mean": -0.8050645406856093, "train/policy_logprob_min": -6.032375319059505, "train/policy_logprob_std": 0.8479023850241373, "train/policy_randomness_mag": 0.9004129986430324, "train/policy_randomness_max": 0.9004129986430324, "train/policy_randomness_mean": 0.4137034084561259, "train/policy_randomness_min": 0.14588217865242514, "train/policy_randomness_std": 0.16301988690744998, "train/post_ent_mag": 37.50380820340889, "train/post_ent_max": 37.50380820340889, "train/post_ent_mean": 37.36689442479333, "train/post_ent_min": 37.235807747064634, "train/post_ent_std": 0.04924734156838683, "train/prior_ent_mag": 39.899629104969115, "train/prior_ent_max": 39.899629104969115, "train/prior_ent_mean": 37.2478740425997, "train/prior_ent_min": 35.61778274358705, "train/prior_ent_std": 0.6246009189029073, "train/rep_loss_mean": 1.000014417670494, "train/rep_loss_std": 0.0003390037895896544, "train/reward_avg": 0.00023891792231954114, "train/reward_loss_mean": 0.009394607792586782, "train/reward_loss_std": 0.026245232454912608, "train/reward_max_data": 0.03418604786031295, "train/reward_max_pred": 0.01573106466337692, "train/reward_neg_acc": 0.9999409431634947, "train/reward_neg_loss": 0.009026828377919141, "train/reward_pos_acc": 0.25, "train/reward_pos_loss": 6.5698456565539045, "train/reward_pred": 0.00024329806775461103, "train/reward_rate": 5.904796511627907e-05, "train_stats/mean_log_entropy": 1.0543359835942587, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.002003326080739498, "report/cont_loss_std": 0.019098643213510513, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.31297945976257324, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0013947620755061507, "report/cont_pred": 0.997259259223938, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12202917039394379, "report/image_loss_std": 0.10401276499032974, "report/model_loss_mean": 0.7309723496437073, "report/model_loss_std": 0.1084732785820961, "report/post_ent_mag": 33.20445251464844, "report/post_ent_max": 33.20445251464844, "report/post_ent_mean": 33.0479736328125, "report/post_ent_min": 32.933074951171875, "report/post_ent_std": 0.049990151077508926, "report/prior_ent_mag": 34.708980560302734, "report/prior_ent_max": 34.708980560302734, "report/prior_ent_mean": 32.93910217285156, "report/prior_ent_min": 31.862224578857422, "report/prior_ent_std": 0.47035378217697144, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.000157525937538594, "report/reward_loss_mean": 0.006939832586795092, "report/reward_loss_std": 0.013458235189318657, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012377500534057617, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.006939833052456379, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00017255742568522692, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003236468182876706, "eval/cont_loss_std": 0.07087799161672592, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.9990234375, "eval/cont_pos_loss": 0.003236468182876706, "eval/cont_pred": 0.9981174468994141, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19125501811504364, "eval/image_loss_std": 0.13634894788265228, "eval/model_loss_mean": 0.7951965928077698, "eval/model_loss_std": 0.15323255956172943, "eval/post_ent_mag": 33.204627990722656, "eval/post_ent_max": 33.204627990722656, "eval/post_ent_mean": 33.0506706237793, "eval/post_ent_min": 32.94565963745117, "eval/post_ent_std": 0.049335166811943054, "eval/prior_ent_mag": 34.410404205322266, "eval/prior_ent_max": 34.410404205322266, "eval/prior_ent_mean": 32.916831970214844, "eval/prior_ent_min": 31.683971405029297, "eval/prior_ent_std": 0.4576191008090973, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0007050931453704834, "eval/reward_loss_std": 0.001282281125895679, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0009720325469970703, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0007050931453704834, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00011394917964935303, "eval/reward_rate": 0.0, "replay/size": 60985.0, "replay/inserts": 8600.0, "replay/samples": 34400.0, "replay/insert_wait_avg": 1.5289838923964388e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.377086284548737e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0102884167205917e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2939779758453, "timer/env.step_count": 1075.0, "timer/env.step_total": 9.980010747909546, "timer/env.step_frac": 0.009977077706800449, "timer/env.step_avg": 0.00928373092828795, "timer/env.step_min": 0.008327722549438477, "timer/env.step_max": 0.015202999114990234, "timer/replay._sample_count": 34400.0, "timer/replay._sample_total": 17.07393169403076, "timer/replay._sample_frac": 0.017068913809299226, "timer/replay._sample_avg": 0.0004963352236636849, "timer/replay._sample_min": 0.00034880638122558594, "timer/replay._sample_max": 0.020428180694580078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1364.0, "timer/agent.policy_total": 13.83857250213623, "timer/agent.policy_frac": 0.013834505462223624, "timer/agent.policy_avg": 0.010145581013296356, "timer/agent.policy_min": 0.008742809295654297, "timer/agent.policy_max": 0.08060073852539062, "timer/dataset_train_count": 2150.0, "timer/dataset_train_total": 0.3640565872192383, "timer/dataset_train_frac": 0.00036394959405426847, "timer/dataset_train_avg": 0.00016932864521825036, "timer/dataset_train_min": 8.392333984375e-05, "timer/dataset_train_max": 0.0006074905395507812, "timer/agent.train_count": 2150.0, "timer/agent.train_total": 961.4795477390289, "timer/agent.train_frac": 0.9611969769973426, "timer/agent.train_avg": 0.44719978964605994, "timer/agent.train_min": 0.43408727645874023, "timer/agent.train_max": 0.5724425315856934, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46752333641052246, "timer/agent.report_frac": 0.0004673859352393422, "timer/agent.report_avg": 0.23376166820526123, "timer/agent.report_min": 0.22523784637451172, "timer/agent.report_max": 0.24228549003601074, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.693338161746599e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 8.597346420683884}
{"step": 61904, "time": 7257.551770448685, "episode/length": 288.0, "episode/score": 0.015723259072501605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015723259072501605}
{"step": 61912, "time": 7258.472661972046, "episode/length": 288.0, "episode/score": 0.01605034946339856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01605034946339856}
{"step": 62128, "time": 7283.332738876343, "episode/length": 288.0, "episode/score": 0.018524638604617394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018524638604617394}
{"step": 62424, "time": 7317.688503503799, "episode/length": 288.0, "episode/score": 0.013959229863246492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013959229863246492}
{"step": 62424, "time": 7317.696663379669, "episode/length": 288.0, "episode/score": 0.01906256645548865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01906256645548865}
{"step": 62424, "time": 7317.7050886154175, "episode/length": 288.0, "episode/score": 0.018113154605487125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018113154605487125}
{"step": 62424, "time": 7317.71488070488, "episode/length": 288.0, "episode/score": 0.01740661195822213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01740661195822213}
{"step": 62776, "time": 7358.324207782745, "episode/length": 288.0, "episode/score": 0.01925554278528807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01925554278528807}
{"step": 64216, "time": 7524.424512863159, "episode/length": 288.0, "episode/score": 0.019072867245427005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019072867245427005}
{"step": 64224, "time": 7525.351179361343, "episode/length": 288.0, "episode/score": 0.01209414523725627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01209414523725627}
{"step": 64440, "time": 7550.563563346863, "episode/length": 288.0, "episode/score": 0.03540401803570603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03540401803570603}
{"step": 64736, "time": 7584.614994764328, "episode/length": 288.0, "episode/score": 0.02311293859656871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02311293859656871}
{"step": 64736, "time": 7584.632142543793, "episode/length": 288.0, "episode/score": 0.010552000253710503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010552000253710503}
{"step": 64736, "time": 7584.640130281448, "episode/length": 288.0, "episode/score": 0.014059990096598085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014059990096598085}
{"step": 64736, "time": 7584.648762702942, "episode/length": 288.0, "episode/score": 0.012827295078182033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012827295078182033}
{"step": 65088, "time": 7625.1781187057495, "episode/length": 288.0, "episode/score": 0.009377090014481837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.009377090014481837}
{"step": 66528, "time": 7792.453461408615, "episode/length": 288.0, "episode/score": 0.0442453885834766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0442453885834766}
{"step": 66536, "time": 7793.390119791031, "episode/length": 288.0, "episode/score": 0.02064077847637691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02064077847637691}
{"step": 66752, "time": 7818.347285032272, "episode/length": 288.0, "episode/score": 0.04923574662802821, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04923574662802821}
{"step": 67048, "time": 7852.901721954346, "episode/length": 288.0, "episode/score": 0.06017495462754141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06017495462754141}
{"step": 67048, "time": 7852.915505409241, "episode/length": 288.0, "episode/score": 0.041942951862210975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041942951862210975}
{"step": 67048, "time": 7852.924235343933, "episode/length": 288.0, "episode/score": 0.05936445966210613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05936445966210613}
{"step": 67048, "time": 7852.932807683945, "episode/length": 288.0, "episode/score": 0.06581105777308949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06581105777308949}
{"step": 67400, "time": 7893.745015621185, "episode/length": 288.0, "episode/score": 0.06978469777902774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06978469777902774}
{"step": 68840, "time": 8060.7133457660675, "episode/length": 288.0, "episode/score": 0.06907547041839734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06907547041839734}
{"step": 68848, "time": 8061.637137413025, "episode/length": 288.0, "episode/score": 0.05378140317628777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05378140317628777}
{"step": 69064, "time": 8086.509801864624, "episode/length": 288.0, "episode/score": 0.06483218214896169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06483218214896169}
{"step": 69360, "time": 8120.57355761528, "episode/length": 288.0, "episode/score": 0.04109313475413501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04109313475413501}
{"step": 69360, "time": 8120.580405473709, "episode/length": 288.0, "episode/score": 0.05893641316367848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05893641316367848}
{"step": 69360, "time": 8120.5864017009735, "episode/length": 288.0, "episode/score": 0.047660764307408954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047660764307408954}
{"step": 69360, "time": 8120.592422246933, "episode/length": 288.0, "episode/score": 0.04496775963855271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04496775963855271}
{"step": 69712, "time": 8161.028594017029, "episode/length": 288.0, "episode/score": 0.03299235554868574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03299235554868574}
{"step": 70096, "time": 8210.542623281479, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 8210.549261569977, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 8210.55478644371, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 8210.56013250351, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 8210.565482616425, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 8210.570664644241, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 8210.575829029083, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 8210.581094264984, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70097, "time": 8211.572673559189, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.4641570335210754, "train/action_min": 0.0, "train/action_std": 1.868953974302425, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007846168722134344, "train/actor_opt_grad_steps": 16060.0, "train/actor_opt_loss": -10.605945434681205, "train/adv_mag": 0.415796162222707, "train/adv_max": 0.21212109881778096, "train/adv_mean": 0.0021449344742862637, "train/adv_min": -0.37123299906420154, "train/adv_std": 0.02350716064359213, "train/cont_avg": 0.9966388081395349, "train/cont_loss_mean": 0.004980508118413042, "train/cont_loss_std": 0.10981948000682128, "train/cont_neg_acc": 0.7432895391336027, "train/cont_neg_loss": 1.215331700763993, "train/cont_pos_acc": 0.9998540767403536, "train/cont_pos_loss": 0.00107906446521452, "train/cont_pred": 0.9966297839963159, "train/cont_rate": 0.9966388081395349, "train/dyn_loss_mean": 1.0000335538110068, "train/dyn_loss_std": 0.0006523276721689103, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.33974007936411127, "train/extr_critic_critic_opt_grad_steps": 16060.0, "train/extr_critic_critic_opt_loss": 8163.790906045603, "train/extr_critic_mag": 0.4583646763202756, "train/extr_critic_max": 0.4583646763202756, "train/extr_critic_mean": 0.4061017549315164, "train/extr_critic_min": 0.36773576459219287, "train/extr_critic_std": 0.019290758361011136, "train/extr_return_normed_mag": 0.4237224887969882, "train/extr_return_normed_max": 0.2661718552888826, "train/extr_return_normed_mean": 0.030030410676493396, "train/extr_return_normed_min": -0.33106588139090426, "train/extr_return_normed_std": 0.03227151772765399, "train/extr_return_rate": 0.037554810229495306, "train/extr_return_raw_mag": 0.6443881080594174, "train/extr_return_raw_max": 0.6443881080594174, "train/extr_return_raw_mean": 0.4082466821337855, "train/extr_return_raw_min": 0.047150370963784154, "train/extr_return_raw_std": 0.03227151763235587, "train/extr_reward_mag": 0.22631805885669798, "train/extr_reward_max": 0.22631805885669798, "train/extr_reward_mean": 0.0009722516664708586, "train/extr_reward_min": 4.200048224870548e-06, "train/extr_reward_std": 0.00838194189926198, "train/image_loss_mean": 0.10696048743503038, "train/image_loss_std": 0.0978687250683474, "train/model_loss_mean": 0.7206138763316842, "train/model_loss_std": 0.17213271326103877, "train/model_opt_grad_norm": 34.730141196140025, "train/model_opt_grad_steps": 16043.251162790697, "train/model_opt_loss": 2065.5329181050147, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2883.720930232558, "train/policy_entropy_mag": 1.6592275336731312, "train/policy_entropy_max": 1.6592275336731312, "train/policy_entropy_mean": 0.5022061887868615, "train/policy_entropy_min": 0.06471467822097068, "train/policy_entropy_std": 0.36241304188273676, "train/policy_logprob_mag": 6.55091734819634, "train/policy_logprob_max": -0.008612690541113532, "train/policy_logprob_mean": -0.5021612520134726, "train/policy_logprob_min": -6.55091734819634, "train/policy_logprob_std": 0.8848692342292431, "train/policy_randomness_mag": 0.8526743292808533, "train/policy_randomness_max": 0.8526743292808533, "train/policy_randomness_mean": 0.25808294276858484, "train/policy_randomness_min": 0.03325676777681639, "train/policy_randomness_std": 0.1862434722309889, "train/post_ent_mag": 31.70173786074616, "train/post_ent_max": 31.70173786074616, "train/post_ent_mean": 31.504388223692427, "train/post_ent_min": 31.373526923601016, "train/post_ent_std": 0.05930178901830385, "train/prior_ent_mag": 33.145953466725906, "train/prior_ent_max": 33.145953466725906, "train/prior_ent_mean": 31.06818625871525, "train/prior_ent_min": 29.51532506720964, "train/prior_ent_std": 0.5434208583000094, "train/rep_loss_mean": 1.0000335538110068, "train/rep_loss_std": 0.0006523276721689103, "train/reward_avg": 0.0002331995437744745, "train/reward_loss_mean": 0.00865272744017285, "train/reward_loss_std": 0.021416679483860036, "train/reward_max_data": 0.04170058309966915, "train/reward_max_pred": 0.027760491260262424, "train/reward_neg_acc": 0.9999909112619799, "train/reward_neg_loss": 0.00841825704934985, "train/reward_pos_acc": 0.7777777777777778, "train/reward_pos_loss": 2.8765522473388248, "train/reward_pred": 0.0002285908653162593, "train/reward_rate": 8.175872093023256e-05, "train_stats/mean_log_entropy": 0.3934725522994995, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.011294221505522728, "report/cont_loss_std": 0.23861347138881683, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 2.1719002723693848, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0006926223286427557, "report/cont_pred": 0.9964540600776672, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10068333148956299, "report/image_loss_std": 0.09083457291126251, "report/model_loss_mean": 0.7191138863563538, "report/model_loss_std": 0.2614116072654724, "report/post_ent_mag": 31.53061866760254, "report/post_ent_max": 31.53061866760254, "report/post_ent_mean": 31.351215362548828, "report/post_ent_min": 31.22064971923828, "report/post_ent_std": 0.06430192291736603, "report/prior_ent_mag": 33.105472564697266, "report/prior_ent_max": 33.105472564697266, "report/prior_ent_mean": 30.427473068237305, "report/prior_ent_min": 29.102771759033203, "report/prior_ent_std": 0.5524165630340576, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001653265062486753, "report/reward_loss_mean": 0.007136303465813398, "report/reward_loss_std": 0.013600701466202736, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0010733604431152344, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007136303465813398, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00017552671488374472, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.028581742197275162, "eval/cont_loss_std": 0.5311936736106873, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.485340118408203, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0007949864957481623, "eval/cont_pred": 0.9992155432701111, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25321832299232483, "eval/image_loss_std": 0.14776623249053955, "eval/model_loss_mean": 0.8828407526016235, "eval/model_loss_std": 0.5512362122535706, "eval/post_ent_mag": 31.530406951904297, "eval/post_ent_max": 31.530406951904297, "eval/post_ent_mean": 31.326824188232422, "eval/post_ent_min": 31.19980239868164, "eval/post_ent_std": 0.06371594965457916, "eval/prior_ent_mag": 32.843040466308594, "eval/prior_ent_max": 32.843040466308594, "eval/prior_ent_mean": 30.405879974365234, "eval/prior_ent_min": 28.95144271850586, "eval/prior_ent_std": 0.5626681447029114, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001040707342326641, "eval/reward_loss_std": 0.001534028211608529, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.001081705093383789, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001040707342326641, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0001642078859731555, "eval/reward_rate": 0.0, "replay/size": 69593.0, "replay/inserts": 8608.0, "replay/samples": 34432.0, "replay/insert_wait_avg": 1.540608344024885e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.260450398611757e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19552.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.850234721358672e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.8359389305115, "timer/env.step_count": 1076.0, "timer/env.step_total": 10.100316047668457, "timer/env.step_frac": 0.010081806466686384, "timer/env.step_avg": 0.009386910824970686, "timer/env.step_min": 0.008498907089233398, "timer/env.step_max": 0.034244537353515625, "timer/replay._sample_count": 34432.0, "timer/replay._sample_total": 16.96413564682007, "timer/replay._sample_frac": 0.01693304760550891, "timer/replay._sample_avg": 0.0004926851663226089, "timer/replay._sample_min": 0.0003654956817626953, "timer/replay._sample_max": 0.009517431259155273, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1365.0, "timer/agent.policy_total": 13.270018815994263, "timer/agent.policy_frac": 0.013245700518749993, "timer/agent.policy_avg": 0.009721625506222903, "timer/agent.policy_min": 0.008738040924072266, "timer/agent.policy_max": 0.019666194915771484, "timer/dataset_train_count": 2152.0, "timer/dataset_train_total": 0.4088404178619385, "timer/dataset_train_frac": 0.0004080911873638585, "timer/dataset_train_avg": 0.00018998160681316843, "timer/dataset_train_min": 8.416175842285156e-05, "timer/dataset_train_max": 0.04279756546020508, "timer/agent.train_count": 2152.0, "timer/agent.train_total": 963.8057460784912, "timer/agent.train_frac": 0.9620395003071874, "timer/agent.train_avg": 0.4478651236424216, "timer/agent.train_min": 0.43645501136779785, "timer/agent.train_max": 0.8746237754821777, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46826648712158203, "timer/agent.report_frac": 0.000467408353928159, "timer/agent.report_avg": 0.23413324356079102, "timer/agent.report_min": 0.224945068359375, "timer/agent.report_max": 0.24332141876220703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6653945842550916e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 8.592109412424938}
{"step": 71152, "time": 8333.337433338165, "episode/length": 288.0, "episode/score": 0.01861457842045411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01861457842045411}
{"step": 71160, "time": 8334.279143810272, "episode/length": 288.0, "episode/score": 0.014489554007866445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014489554007866445}
{"step": 71376, "time": 8359.104907035828, "episode/length": 288.0, "episode/score": 0.02110079741950699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02110079741950699}
{"step": 71672, "time": 8393.030135154724, "episode/length": 288.0, "episode/score": 0.018550677977941632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018550677977941632}
{"step": 71672, "time": 8393.036895036697, "episode/length": 288.0, "episode/score": 0.01661870206828553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01661870206828553}
{"step": 71672, "time": 8393.042800664902, "episode/length": 288.0, "episode/score": 0.018332688975505107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018332688975505107}
{"step": 71672, "time": 8393.048830032349, "episode/length": 288.0, "episode/score": 0.011343797929328048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.011343797929328048}
{"step": 72024, "time": 8433.487424612045, "episode/length": 288.0, "episode/score": 0.03323200997050435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03323200997050435}
{"step": 73464, "time": 8599.407501935959, "episode/length": 288.0, "episode/score": 0.084547279880411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.084547279880411}
{"step": 73472, "time": 8600.334519147873, "episode/length": 288.0, "episode/score": 0.09133993213580993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09133993213580993}
{"step": 73688, "time": 8625.176199674606, "episode/length": 288.0, "episode/score": 0.0769301702564178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0769301702564178}
{"step": 73984, "time": 8659.448197126389, "episode/length": 288.0, "episode/score": 0.06532221508177827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06532221508177827}
{"step": 73984, "time": 8659.455600976944, "episode/length": 288.0, "episode/score": 0.053423841325496824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053423841325496824}
{"step": 73984, "time": 8659.463061571121, "episode/length": 288.0, "episode/score": 0.12576484770551133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12576484770551133}
{"step": 73984, "time": 8659.469369888306, "episode/length": 288.0, "episode/score": 0.1319988263933567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1319988263933567}
{"step": 74336, "time": 8699.952674865723, "episode/length": 288.0, "episode/score": 0.07104969257670746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07104969257670746}
{"step": 75776, "time": 8865.27487874031, "episode/length": 288.0, "episode/score": 0.04057568137559997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04057568137559997}
{"step": 75784, "time": 8866.19699048996, "episode/length": 288.0, "episode/score": 0.08397174951485908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08397174951485908}
{"step": 76000, "time": 8890.909686088562, "episode/length": 288.0, "episode/score": 0.06320348732728576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06320348732728576}
{"step": 76296, "time": 8924.77765250206, "episode/length": 288.0, "episode/score": 0.03885772005531862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03885772005531862}
{"step": 76296, "time": 8924.794196605682, "episode/length": 288.0, "episode/score": 0.06804173769685917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06804173769685917}
{"step": 76296, "time": 8924.799841880798, "episode/length": 288.0, "episode/score": 0.07353634214408089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07353634214408089}
{"step": 76296, "time": 8924.806081295013, "episode/length": 288.0, "episode/score": 0.05720250389029502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05720250389029502}
{"step": 76648, "time": 8965.214225053787, "episode/length": 288.0, "episode/score": 0.05949116253447073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05949116253447073}
{"step": 78088, "time": 9131.47157216072, "episode/length": 288.0, "episode/score": 0.10606043475107185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10606043475107185}
{"step": 78096, "time": 9132.40984749794, "episode/length": 288.0, "episode/score": 0.12327268216134257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12327268216134257}
{"step": 78312, "time": 9157.351946115494, "episode/length": 288.0, "episode/score": 0.08572336156078109, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08572336156078109}
{"step": 78608, "time": 9191.274184942245, "episode/length": 288.0, "episode/score": 0.11951589884063196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11951589884063196}
{"step": 78608, "time": 9191.281468868256, "episode/length": 288.0, "episode/score": 0.12186340342810809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12186340342810809}
{"step": 78608, "time": 9191.287188768387, "episode/length": 288.0, "episode/score": 0.10700579349355621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10700579349355621}
{"step": 78608, "time": 9191.293108463287, "episode/length": 288.0, "episode/score": 0.07155540090681711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07155540090681711}
{"step": 78781, "time": 9211.96815085411, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.2547208021313363, "train/action_min": 0.0, "train/action_std": 1.0791583687479045, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005314218135194398, "train/actor_opt_grad_steps": 18220.0, "train/actor_opt_loss": -8.433206760388915, "train/adv_mag": 0.3508490598696168, "train/adv_max": 0.10677525881798036, "train/adv_mean": 0.0015348215928149794, "train/adv_min": -0.3173825801242881, "train/adv_std": 0.015638982157720777, "train/cont_avg": 0.9965572796658986, "train/cont_loss_mean": 0.0039059972060063192, "train/cont_loss_std": 0.08684233661761405, "train/cont_neg_acc": 0.7920803456514511, "train/cont_neg_loss": 0.8889143191356438, "train/cont_pos_acc": 0.9999141201445584, "train/cont_pos_loss": 0.0008321453972498582, "train/cont_pred": 0.996545992963325, "train/cont_rate": 0.9965572796658986, "train/dyn_loss_mean": 1.0000639577065744, "train/dyn_loss_std": 0.0006944061866801148, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.30399542009191854, "train/extr_critic_critic_opt_grad_steps": 18220.0, "train/extr_critic_critic_opt_loss": 7694.1254815308175, "train/extr_critic_mag": 0.41782775452609433, "train/extr_critic_max": 0.41782775452609433, "train/extr_critic_mean": 0.4000583378950022, "train/extr_critic_min": 0.3843805713038291, "train/extr_critic_std": 0.00551782389778176, "train/extr_return_normed_mag": 0.3567212158084465, "train/extr_return_normed_max": 0.12572815231463877, "train/extr_return_normed_mean": 0.012445257786369813, "train/extr_return_normed_min": -0.303412376598279, "train/extr_return_normed_std": 0.016810347873305532, "train/extr_return_rate": 0.032868005475015935, "train/extr_return_raw_mag": 0.5148760271237193, "train/extr_return_raw_max": 0.5148760271237193, "train/extr_return_raw_mean": 0.4015931537898455, "train/extr_return_raw_min": 0.08573549876015307, "train/extr_return_raw_std": 0.01681034784433582, "train/extr_reward_mag": 0.10502165583421558, "train/extr_reward_max": 0.10502165583421558, "train/extr_reward_mean": 0.0013560696198481074, "train/extr_reward_min": 2.765435776952225e-06, "train/extr_reward_std": 0.005272657410169239, "train/image_loss_mean": 0.0941806818071049, "train/image_loss_std": 0.09717493686258519, "train/model_loss_mean": 0.706569249179506, "train/model_loss_std": 0.1517559857824431, "train/model_opt_grad_norm": 32.68162074286817, "train/model_opt_grad_steps": 18201.460829493088, "train/model_opt_loss": 2036.3434906709028, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2880.1843317972352, "train/policy_entropy_mag": 1.4013868257197366, "train/policy_entropy_max": 1.4013868257197366, "train/policy_entropy_mean": 0.3317926225986349, "train/policy_entropy_min": 0.06469456872083075, "train/policy_entropy_std": 0.2518015345944787, "train/policy_logprob_mag": 6.551045975926835, "train/policy_logprob_max": -0.008609501039823903, "train/policy_logprob_mean": -0.3317565580804227, "train/policy_logprob_min": -6.551045975926835, "train/policy_logprob_std": 0.7498856258282464, "train/policy_randomness_mag": 0.720170408349982, "train/policy_randomness_max": 0.720170408349982, "train/policy_randomness_mean": 0.17050768920834164, "train/policy_randomness_min": 0.033246433662791404, "train/policy_randomness_std": 0.12940039835904601, "train/post_ent_mag": 31.357750958561347, "train/post_ent_max": 31.357750958561347, "train/post_ent_mean": 31.110084480953656, "train/post_ent_min": 30.932523621941492, "train/post_ent_std": 0.07978397971748756, "train/prior_ent_mag": 31.98842655129147, "train/prior_ent_max": 31.98842655129147, "train/prior_ent_mean": 30.058039968464232, "train/prior_ent_min": 28.72175485637331, "train/prior_ent_std": 0.5089609028282254, "train/rep_loss_mean": 1.0000639577065744, "train/rep_loss_std": 0.0006944061866801148, "train/reward_avg": 0.00021571940020872666, "train/reward_loss_mean": 0.008444171853809862, "train/reward_loss_std": 0.016780535111092204, "train/reward_max_data": 0.02378744313338866, "train/reward_max_pred": 0.022155038222739225, "train/reward_neg_acc": 0.9999909950291506, "train/reward_neg_loss": 0.00837108629974558, "train/reward_pos_acc": 0.9090909090909091, "train/reward_pos_loss": 1.4855274720625444, "train/reward_pred": 0.00021983242179546075, "train/reward_rate": 4.950316820276498e-05, "train_stats/mean_log_entropy": 0.29005315323029796, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.016214163973927498, "report/cont_loss_std": 0.35843098163604736, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 5.248467445373535, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0008402567473240197, "report/cont_pred": 0.9982190132141113, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0946943536400795, "report/image_loss_std": 0.10788795351982117, "report/model_loss_mean": 0.7168294787406921, "report/model_loss_std": 0.374748557806015, "report/post_ent_mag": 36.107200622558594, "report/post_ent_max": 36.107200622558594, "report/post_ent_mean": 35.832550048828125, "report/post_ent_min": 35.664337158203125, "report/post_ent_std": 0.09212686866521835, "report/prior_ent_mag": 37.23607635498047, "report/prior_ent_max": 37.23607635498047, "report/prior_ent_mean": 35.01597595214844, "report/prior_ent_min": 33.998069763183594, "report/prior_ent_std": 0.47861751914024353, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00013039156328886747, "report/reward_loss_mean": 0.005920951254665852, "report/reward_loss_std": 0.011744235642254353, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.015513777732849121, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.005920951254665852, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00015883834566920996, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03796633332967758, "eval/cont_loss_std": 0.6033709049224854, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.587082862854004, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0005188241484574974, "eval/cont_pred": 0.9994833469390869, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24688604474067688, "eval/image_loss_std": 0.15948933362960815, "eval/model_loss_mean": 0.8857581615447998, "eval/model_loss_std": 0.6187387704849243, "eval/post_ent_mag": 36.10753631591797, "eval/post_ent_max": 36.10753631591797, "eval/post_ent_mean": 35.79634094238281, "eval/post_ent_min": 35.651893615722656, "eval/post_ent_std": 0.08513058722019196, "eval/prior_ent_mag": 37.02787780761719, "eval/prior_ent_max": 37.02787780761719, "eval/prior_ent_mean": 34.96208953857422, "eval/prior_ent_min": 34.04021453857422, "eval/prior_ent_std": 0.4651672840118408, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0009057042188942432, "eval/reward_loss_std": 0.001374614192172885, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.001949906349182129, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009057042188942432, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0001505180262029171, "eval/reward_rate": 0.0, "replay/size": 78277.0, "replay/inserts": 8684.0, "replay/samples": 34736.0, "replay/insert_wait_avg": 1.5110367731474777e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.703577741836414e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19552.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 6.407499313354492e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3821804523468, "timer/env.step_count": 1085.0, "timer/env.step_total": 10.168142557144165, "timer/env.step_frac": 0.010164257976432962, "timer/env.step_avg": 0.009371559960501534, "timer/env.step_min": 0.008459329605102539, "timer/env.step_max": 0.03413081169128418, "timer/replay._sample_count": 34736.0, "timer/replay._sample_total": 16.306959629058838, "timer/replay._sample_frac": 0.01630072980876694, "timer/replay._sample_avg": 0.000469454157907037, "timer/replay._sample_min": 0.0003285408020019531, "timer/replay._sample_max": 0.030885934829711914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1085.0, "timer/agent.policy_total": 10.693710803985596, "timer/agent.policy_frac": 0.010689625438100245, "timer/agent.policy_avg": 0.00985595465805124, "timer/agent.policy_min": 0.00887608528137207, "timer/agent.policy_max": 0.03491663932800293, "timer/dataset_train_count": 2171.0, "timer/dataset_train_total": 0.362168550491333, "timer/dataset_train_frac": 0.00036203018962969715, "timer/dataset_train_avg": 0.00016682107346445554, "timer/dataset_train_min": 8.416175842285156e-05, "timer/dataset_train_max": 0.0008327960968017578, "timer/agent.train_count": 2171.0, "timer/agent.train_total": 967.2480473518372, "timer/agent.train_frac": 0.9668785252796813, "timer/agent.train_avg": 0.4455311134739001, "timer/agent.train_min": 0.4339923858642578, "timer/agent.train_max": 0.5726125240325928, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46596431732177734, "timer/agent.report_frac": 0.0004657863029018374, "timer/agent.report_avg": 0.23298215866088867, "timer/agent.report_min": 0.22319769859313965, "timer/agent.report_max": 0.2427666187286377, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.6216024449089188e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 8.680567510722053}
{"step": 78960, "time": 9232.276132822037, "episode/length": 288.0, "episode/score": 0.0960995833889342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0960995833889342}
{"step": 80080, "time": 9365.893324136734, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 9365.899722337723, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 9365.912810564041, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 9365.918501377106, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 9365.924023628235, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 9365.929416179657, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 9365.934746980667, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 9365.939870595932, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80400, "time": 9402.630972146988, "episode/length": 288.0, "episode/score": 0.09926776455648678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09926776455648678}
{"step": 80408, "time": 9403.545147418976, "episode/length": 288.0, "episode/score": 0.10125684506243715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10125684506243715}
{"step": 80624, "time": 9428.303082466125, "episode/length": 288.0, "episode/score": 0.11294900954877107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11294900954877107}
{"step": 80920, "time": 9462.494862318039, "episode/length": 288.0, "episode/score": 0.1024714291645239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1024714291645239}
{"step": 80920, "time": 9462.50202178955, "episode/length": 288.0, "episode/score": 0.09843522692736428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09843522692736428}
{"step": 80920, "time": 9462.50788450241, "episode/length": 288.0, "episode/score": 0.041356446535729674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041356446535729674}
{"step": 80920, "time": 9462.51468539238, "episode/length": 288.0, "episode/score": 0.0951696972757361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0951696972757361}
{"step": 81272, "time": 9503.228163957596, "episode/length": 288.0, "episode/score": 0.1349480747607572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1349480747607572}
{"step": 82712, "time": 9668.911657571793, "episode/length": 288.0, "episode/score": 0.06679881078551375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06679881078551375}
{"step": 82720, "time": 9669.853078126907, "episode/length": 288.0, "episode/score": 0.07824385797746913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07824385797746913}
{"step": 82936, "time": 9694.593454122543, "episode/length": 288.0, "episode/score": 0.053366613817871666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053366613817871666}
{"step": 83232, "time": 9728.675755262375, "episode/length": 288.0, "episode/score": 0.06941509912141441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06941509912141441}
{"step": 83232, "time": 9728.682935237885, "episode/length": 288.0, "episode/score": 0.05531851660308007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05531851660308007}
{"step": 83232, "time": 9728.690051078796, "episode/length": 288.0, "episode/score": 0.05802008640432632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05802008640432632}
{"step": 83232, "time": 9728.696495294571, "episode/length": 288.0, "episode/score": 0.06755418161151283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06755418161151283}
{"step": 83584, "time": 9769.528287649155, "episode/length": 288.0, "episode/score": 0.05263839650618252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05263839650618252}
{"step": 85024, "time": 9934.69001197815, "episode/length": 288.0, "episode/score": 0.04466647288191439, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04466647288191439}
{"step": 85032, "time": 9935.604744672775, "episode/length": 288.0, "episode/score": 0.05162847049939501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05162847049939501}
{"step": 85248, "time": 9960.350426197052, "episode/length": 288.0, "episode/score": 0.06030291696035306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06030291696035306}
{"step": 85544, "time": 9994.248549938202, "episode/length": 288.0, "episode/score": 0.060294556958751855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060294556958751855}
{"step": 85544, "time": 9994.255446434021, "episode/length": 288.0, "episode/score": 0.06681333827643243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06681333827643243}
{"step": 85544, "time": 9994.261354923248, "episode/length": 288.0, "episode/score": 0.07471859201714892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07471859201714892}
{"step": 85544, "time": 9994.26754617691, "episode/length": 288.0, "episode/score": 0.06294730693079487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06294730693079487}
{"step": 85896, "time": 10034.6206305027, "episode/length": 288.0, "episode/score": 0.04862775556955512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04862775556955512}
{"step": 87336, "time": 10200.988888263702, "episode/length": 288.0, "episode/score": 0.04833900892379006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04833900892379006}
{"step": 87344, "time": 10201.939460754395, "episode/length": 288.0, "episode/score": 0.04046167427273417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04046167427273417}
{"step": 87425, "time": 10212.134957790375, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.7605099148220487, "train/action_min": 0.0, "train/action_std": 0.9300179197280495, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002774697395108416, "train/actor_opt_grad_steps": 20385.0, "train/actor_opt_loss": -7.66148839339062, "train/adv_mag": 0.24338150438335207, "train/adv_max": 0.06182596294416322, "train/adv_mean": -0.0011944151232859844, "train/adv_min": -0.2227865719684848, "train/adv_std": 0.008555756355269329, "train/cont_avg": 0.9965910734953703, "train/cont_loss_mean": 0.005378993747702528, "train/cont_loss_std": 0.11834793802214942, "train/cont_neg_acc": 0.7475631638591838, "train/cont_neg_loss": 1.2287209207313534, "train/cont_pos_acc": 0.9999138103039177, "train/cont_pos_loss": 0.0009915565434413212, "train/cont_pred": 0.9966199246269686, "train/cont_rate": 0.9965910734953703, "train/dyn_loss_mean": 1.0000065995587244, "train/dyn_loss_std": 0.00018995512308956004, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.19181640554840365, "train/extr_critic_critic_opt_grad_steps": 20385.0, "train/extr_critic_critic_opt_loss": 10289.907190393518, "train/extr_critic_mag": 0.33106697267956203, "train/extr_critic_max": 0.33106697267956203, "train/extr_critic_mean": 0.32260442428566793, "train/extr_critic_min": 0.31410379376676345, "train/extr_critic_std": 0.002987802311609913, "train/extr_return_normed_mag": 0.24316292808011727, "train/extr_return_normed_max": 0.06862656178849715, "train/extr_return_normed_mean": 0.0033624337023091494, "train/extr_return_normed_min": -0.218549565722545, "train/extr_return_normed_std": 0.009324166464028638, "train/extr_return_rate": 0.007893880633774743, "train/extr_return_raw_mag": 0.3866741458574931, "train/extr_return_raw_max": 0.3866741458574931, "train/extr_return_raw_mean": 0.3214100335759145, "train/extr_return_raw_min": 0.09949801834645094, "train/extr_return_raw_std": 0.009324166455405281, "train/extr_reward_mag": 0.05794573547663512, "train/extr_reward_max": 0.05794573547663512, "train/extr_reward_mean": 0.0007170056224249829, "train/extr_reward_min": 2.1948858543678568e-06, "train/extr_reward_std": 0.002416004838003708, "train/image_loss_mean": 0.09487927698150829, "train/image_loss_std": 0.10096709495755257, "train/model_loss_mean": 0.7090422450392334, "train/model_loss_std": 0.17801623022252763, "train/model_opt_grad_norm": 31.01579228595451, "train/model_opt_grad_steps": 20364.564814814814, "train/model_opt_loss": 1905.4445947717738, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2685.185185185185, "train/policy_entropy_mag": 1.4140349510643218, "train/policy_entropy_max": 1.4140349510643218, "train/policy_entropy_mean": 0.30608701354099643, "train/policy_entropy_min": 0.06468812245185729, "train/policy_entropy_std": 0.26306346003656034, "train/policy_logprob_mag": 6.551068080796136, "train/policy_logprob_max": -0.008608457240000091, "train/policy_logprob_mean": -0.3065703557459293, "train/policy_logprob_min": -6.551068080796136, "train/policy_logprob_std": 0.7627535478936301, "train/policy_randomness_mag": 0.7266702602307001, "train/policy_randomness_max": 0.7266702602307001, "train/policy_randomness_mean": 0.15729761927354116, "train/policy_randomness_min": 0.03324312076869386, "train/policy_randomness_std": 0.13518788324048123, "train/post_ent_mag": 35.37666363186307, "train/post_ent_max": 35.37666363186307, "train/post_ent_mean": 35.12114639635439, "train/post_ent_min": 34.942286844606755, "train/post_ent_std": 0.0893515682330838, "train/prior_ent_mag": 37.19349145889282, "train/prior_ent_max": 37.19349145889282, "train/prior_ent_mean": 34.845116791901766, "train/prior_ent_min": 33.70178309193364, "train/prior_ent_std": 0.511421757577746, "train/rep_loss_mean": 1.0000065995587244, "train/rep_loss_std": 0.00018995512308956004, "train/reward_avg": 0.00022292800282162648, "train/reward_loss_mean": 0.00877999176736921, "train/reward_loss_std": 0.019066611162593797, "train/reward_max_data": 0.022633102344116196, "train/reward_max_pred": 0.01944776596846404, "train/reward_neg_acc": 0.9999864366319444, "train/reward_neg_loss": 0.00861650913807184, "train/reward_pos_acc": 0.7272727272727273, "train/reward_pos_loss": 3.2066109397194604, "train/reward_pred": 0.0002243063392126243, "train/reward_rate": 5.425347222222222e-05, "train_stats/mean_log_entropy": 0.30532905128267074, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.0015796960797160864, "report/cont_loss_std": 0.028564516454935074, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002674183633644134, "report/cont_pos_acc": 0.9990224838256836, "report/cont_pos_loss": 0.0015809788601472974, "report/cont_pred": 0.9977564811706543, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0801912471652031, "report/image_loss_std": 0.09254901111125946, "report/model_loss_mean": 0.6880522966384888, "report/model_loss_std": 0.09979712963104248, "report/post_ent_mag": 35.09496307373047, "report/post_ent_max": 35.09496307373047, "report/post_ent_mean": 34.80439758300781, "report/post_ent_min": 34.66897201538086, "report/post_ent_std": 0.07337088882923126, "report/prior_ent_mag": 36.285552978515625, "report/prior_ent_max": 36.285552978515625, "report/prior_ent_mean": 34.65343475341797, "report/prior_ent_min": 33.570945739746094, "report/prior_ent_std": 0.45385515689849854, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00014263007324188948, "report/reward_loss_mean": 0.0062812925316393375, "report/reward_loss_std": 0.012313290499150753, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0020035505294799805, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.006281292997300625, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00015779060777276754, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.01738421991467476, "eval/cont_loss_std": 0.4187299907207489, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.546878814697266, "eval/cont_pos_acc": 0.9990224838256836, "eval/cont_pos_loss": 0.005136426072567701, "eval/cont_pred": 0.9985270500183105, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2767163813114166, "eval/image_loss_std": 0.15547992289066315, "eval/model_loss_mean": 0.8950166702270508, "eval/model_loss_std": 0.45092833042144775, "eval/post_ent_mag": 35.09373474121094, "eval/post_ent_max": 35.09373474121094, "eval/post_ent_mean": 34.782264709472656, "eval/post_ent_min": 34.64844512939453, "eval/post_ent_std": 0.07984767109155655, "eval/prior_ent_mag": 36.397621154785156, "eval/prior_ent_max": 36.397621154785156, "eval/prior_ent_mean": 34.690521240234375, "eval/prior_ent_min": 33.3809814453125, "eval/prior_ent_std": 0.47168880701065063, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0009159673936665058, "eval/reward_loss_std": 0.0015655511524528265, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0014787912368774414, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009159673936665058, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00014627363998442888, "eval/reward_rate": 0.0, "replay/size": 86921.0, "replay/inserts": 8644.0, "replay/samples": 34576.0, "replay/insert_wait_avg": 1.59707901269294e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.57201023534292e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 21864.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0882488171534554e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3113021850585938e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1524322032928, "timer/env.step_count": 1081.0, "timer/env.step_total": 10.195163488388062, "timer/env.step_frac": 0.010193609654008994, "timer/env.step_avg": 0.009431233569276653, "timer/env.step_min": 0.008324146270751953, "timer/env.step_max": 0.036818504333496094, "timer/replay._sample_count": 34576.0, "timer/replay._sample_total": 16.089773178100586, "timer/replay._sample_frac": 0.016087320952322744, "timer/replay._sample_avg": 0.0004653451289362733, "timer/replay._sample_min": 0.0003352165222167969, "timer/replay._sample_max": 0.010791540145874023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1370.0, "timer/agent.policy_total": 13.330854177474976, "timer/agent.policy_frac": 0.013328822435703802, "timer/agent.policy_avg": 0.009730550494507282, "timer/agent.policy_min": 0.008769989013671875, "timer/agent.policy_max": 0.039444923400878906, "timer/dataset_train_count": 2161.0, "timer/dataset_train_total": 0.3590841293334961, "timer/dataset_train_frac": 0.0003590294016907495, "timer/dataset_train_avg": 0.00016616572389333462, "timer/dataset_train_min": 7.939338684082031e-05, "timer/dataset_train_max": 0.0011916160583496094, "timer/agent.train_count": 2161.0, "timer/agent.train_total": 962.0690319538116, "timer/agent.train_frac": 0.9619224040023728, "timer/agent.train_avg": 0.44519622024702066, "timer/agent.train_min": 0.43416619300842285, "timer/agent.train_max": 0.6022076606750488, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47798895835876465, "timer/agent.report_frac": 0.0004779161085533487, "timer/agent.report_avg": 0.23899447917938232, "timer/agent.report_min": 0.23166394233703613, "timer/agent.report_max": 0.24632501602172852, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.574920654296875e-05, "timer/dataset_eval_frac": 2.574528213288884e-08, "timer/dataset_eval_avg": 2.574920654296875e-05, "timer/dataset_eval_min": 2.574920654296875e-05, "timer/dataset_eval_max": 2.574920654296875e-05, "fps": 8.642572348057902}
{"step": 87560, "time": 10227.44237446785, "episode/length": 288.0, "episode/score": 0.06051941615277201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06051941615277201}
{"step": 87856, "time": 10261.656333446503, "episode/length": 288.0, "episode/score": 0.041818175295929905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041818175295929905}
{"step": 87856, "time": 10261.66323709488, "episode/length": 288.0, "episode/score": 0.053145571716271434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053145571716271434}
{"step": 87856, "time": 10261.68077325821, "episode/length": 288.0, "episode/score": 0.03207846897814193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03207846897814193}
{"step": 87856, "time": 10261.686701536179, "episode/length": 288.0, "episode/score": 0.07618025199386125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07618025199386125}
{"step": 88208, "time": 10302.22042131424, "episode/length": 288.0, "episode/score": 0.024805191125892634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024805191125892634}
{"step": 89648, "time": 10468.488050699234, "episode/length": 288.0, "episode/score": 0.07204422830028534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07204422830028534}
{"step": 89656, "time": 10469.408196926117, "episode/length": 288.0, "episode/score": 0.06978336439320287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06978336439320287}
{"step": 89872, "time": 10494.426374197006, "episode/length": 288.0, "episode/score": 0.05279372914824876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05279372914824876}
{"step": 90064, "time": 10522.182696580887, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 10522.189242601395, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 10522.19469332695, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 10522.200327634811, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 10522.205428123474, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 10522.210693836212, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 10522.215833425522, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 10522.220984458923, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90168, "time": 10534.735486745834, "episode/length": 288.0, "episode/score": 0.0848034764921124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0848034764921124}
{"step": 90168, "time": 10534.74274468422, "episode/length": 288.0, "episode/score": 0.025102884690426208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025102884690426208}
{"step": 90168, "time": 10534.750680208206, "episode/length": 288.0, "episode/score": 0.09297775152563759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09297775152563759}
{"step": 90168, "time": 10534.757451534271, "episode/length": 288.0, "episode/score": 0.06619571896868592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06619571896868592}
{"step": 90520, "time": 10575.66414642334, "episode/length": 288.0, "episode/score": 0.0752311829542407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0752311829542407}
{"step": 91960, "time": 10741.714272975922, "episode/length": 288.0, "episode/score": 0.08090762194012768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08090762194012768}
{"step": 91968, "time": 10742.63854432106, "episode/length": 288.0, "episode/score": 0.07445268076739353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07445268076739353}
{"step": 92184, "time": 10767.492391824722, "episode/length": 288.0, "episode/score": 0.1050534047068652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1050534047068652}
{"step": 92480, "time": 10801.643313407898, "episode/length": 288.0, "episode/score": 0.10652481473189823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10652481473189823}
{"step": 92480, "time": 10801.677604436874, "episode/length": 288.0, "episode/score": 0.12306773487858891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12306773487858891}
{"step": 92480, "time": 10801.68394613266, "episode/length": 288.0, "episode/score": 0.09794891549825024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09794891549825024}
{"step": 92480, "time": 10801.690028190613, "episode/length": 288.0, "episode/score": 0.09811977376190839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09811977376190839}
{"step": 92832, "time": 10842.265570640564, "episode/length": 288.0, "episode/score": 0.07230655041090017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07230655041090017}
{"step": 94272, "time": 11008.472523212433, "episode/length": 288.0, "episode/score": 0.08136459036313681, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08136459036313681}
{"step": 94280, "time": 11009.413935661316, "episode/length": 288.0, "episode/score": 0.08620389494922165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08620389494922165}
{"step": 94464, "time": 11030.599065542221, "episode/length": 247.0, "episode/score": 0.3192771418512166, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.09115213705490532}
{"step": 94496, "time": 11034.269921779633, "episode/length": 288.0, "episode/score": 0.09380350733977139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09380350733977139}
{"step": 94792, "time": 11068.297854185104, "episode/length": 288.0, "episode/score": 0.11581822070229464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11581822070229464}
{"step": 94792, "time": 11068.304979801178, "episode/length": 288.0, "episode/score": 0.09885496326796783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09885496326796783}
{"step": 94792, "time": 11068.310980558395, "episode/length": 288.0, "episode/score": 0.09033908076321495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09033908076321495}
{"step": 95144, "time": 11108.93452501297, "episode/length": 288.0, "episode/score": 0.1061315868339534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1061315868339534}
{"step": 96029, "time": 11212.218320846558, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.0890457508175873, "train/action_min": 0.0, "train/action_std": 1.5451412974401961, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0016457203988169949, "train/actor_opt_grad_steps": 22540.0, "train/actor_opt_loss": -22.168356034922045, "train/adv_mag": 0.18431450433509294, "train/adv_max": 0.022255254138347714, "train/adv_mean": -0.001774192717857659, "train/adv_min": -0.17500795812107797, "train/adv_std": 0.004252586409254649, "train/cont_avg": 0.9963072311046511, "train/cont_loss_mean": 0.00551935245112386, "train/cont_loss_std": 0.11320025088525443, "train/cont_neg_acc": 0.7392516780487248, "train/cont_neg_loss": 1.1490292959065749, "train/cont_pos_acc": 0.999922519783641, "train/cont_pos_loss": 0.0010610149254843722, "train/cont_pred": 0.9963800585547159, "train/cont_rate": 0.9963072311046511, "train/dyn_loss_mean": 1.0000049535618272, "train/dyn_loss_std": 0.00014350668386404596, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.06117465519887763, "train/extr_critic_critic_opt_grad_steps": 22540.0, "train/extr_critic_critic_opt_loss": 12034.065770348838, "train/extr_critic_mag": 0.2399169079093046, "train/extr_critic_max": 0.2399169079093046, "train/extr_critic_mean": 0.23654065028179524, "train/extr_critic_min": 0.2314522338467975, "train/extr_critic_std": 0.0009973641937100436, "train/extr_return_normed_mag": 0.18434112307637238, "train/extr_return_normed_max": 0.02275560927945514, "train/extr_return_normed_mean": -0.001334412441813816, "train/extr_return_normed_min": -0.1750058496414229, "train/extr_return_normed_std": 0.004420271676661837, "train/extr_return_rate": 9.387112994201828e-06, "train/extr_return_raw_mag": 0.25885644409545633, "train/extr_return_raw_max": 0.25885644409545633, "train/extr_return_raw_mean": 0.2347664336825526, "train/extr_return_raw_min": 0.06109498524388601, "train/extr_return_raw_std": 0.004420271631720108, "train/extr_reward_mag": 0.025130607915479084, "train/extr_reward_max": 0.025130607915479084, "train/extr_reward_mean": 0.0003642974629169763, "train/extr_reward_min": 2.2001044694767444e-06, "train/extr_reward_std": 0.0005800562765893288, "train/image_loss_mean": 0.09437050705039224, "train/image_loss_std": 0.10233947575785393, "train/model_loss_mean": 0.7090037778366444, "train/model_loss_std": 0.18019827451816825, "train/model_opt_grad_norm": 29.92540041457775, "train/model_opt_grad_steps": 22517.95348837209, "train/model_opt_loss": 2595.3513933048694, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3662.7906976744184, "train/policy_entropy_mag": 1.7300195372381875, "train/policy_entropy_max": 1.7300195372381875, "train/policy_entropy_mean": 1.0729056035363398, "train/policy_entropy_min": 0.0755767141663751, "train/policy_entropy_std": 0.3574263287145038, "train/policy_logprob_mag": 6.548074855360874, "train/policy_logprob_max": -0.010428345363673775, "train/policy_logprob_mean": -1.0728469054366268, "train/policy_logprob_min": -6.548074855360874, "train/policy_logprob_std": 0.8834421709526417, "train/policy_randomness_mag": 0.8890542232713033, "train/policy_randomness_max": 0.8890542232713033, "train/policy_randomness_mean": 0.5513644463101098, "train/policy_randomness_min": 0.03883875034922777, "train/policy_randomness_std": 0.183680809791698, "train/post_ent_mag": 34.6733855314033, "train/post_ent_max": 34.6733855314033, "train/post_ent_mean": 34.398936994685684, "train/post_ent_min": 34.2161740325218, "train/post_ent_std": 0.09225477940121363, "train/prior_ent_mag": 36.40444371423056, "train/prior_ent_max": 36.40444371423056, "train/prior_ent_mean": 34.64354210787041, "train/prior_ent_min": 33.55172839497411, "train/prior_ent_std": 0.4404293898926225, "train/rep_loss_mean": 1.0000049535618272, "train/rep_loss_std": 0.00014350668386404596, "train/reward_avg": 0.00025450618623560945, "train/reward_loss_mean": 0.009110924761828988, "train/reward_loss_std": 0.022905396808718528, "train/reward_max_data": 0.051177327252577905, "train/reward_max_pred": 0.024253728223401445, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008803976474459782, "train/reward_pos_acc": 0.5789473684210527, "train/reward_pos_loss": 3.383532051977358, "train/reward_pred": 0.00022963349339227344, "train/reward_rate": 9.084302325581395e-05, "train_stats/mean_log_entropy": 0.9403188566366831, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.0002857318031601608, "report/cont_loss_std": 0.0013417921727523208, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001155324513092637, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0002840300730895251, "report/cont_pred": 0.9977665543556213, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07374750077724457, "report/image_loss_std": 0.08736412972211838, "report/model_loss_mean": 0.6818090081214905, "report/model_loss_std": 0.09063971787691116, "report/post_ent_mag": 33.75885009765625, "report/post_ent_max": 33.75885009765625, "report/post_ent_mean": 33.47508239746094, "report/post_ent_min": 33.30487823486328, "report/post_ent_std": 0.08136773109436035, "report/prior_ent_mag": 35.62812805175781, "report/prior_ent_max": 35.62812805175781, "report/prior_ent_mean": 33.81697463989258, "report/prior_ent_min": 32.55149459838867, "report/prior_ent_std": 0.4838753938674927, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001767305948305875, "report/reward_loss_mean": 0.007775749079883099, "report/reward_loss_std": 0.013602479360997677, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012258291244506836, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007775748148560524, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0001865242375060916, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009596917778253555, "eval/cont_loss_std": 0.29965442419052124, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.593817710876465, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00022817593708168715, "eval/cont_pred": 0.999772310256958, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19059625267982483, "eval/image_loss_std": 0.14455050230026245, "eval/model_loss_mean": 0.8010333180427551, "eval/model_loss_std": 0.33779042959213257, "eval/post_ent_mag": 33.758697509765625, "eval/post_ent_max": 33.758697509765625, "eval/post_ent_mean": 33.45378112792969, "eval/post_ent_min": 33.303741455078125, "eval/post_ent_std": 0.08136755973100662, "eval/prior_ent_mag": 35.62812805175781, "eval/prior_ent_max": 35.62812805175781, "eval/prior_ent_mean": 33.867469787597656, "eval/prior_ent_min": 31.957935333251953, "eval/prior_ent_std": 0.508172333240509, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0008401200175285339, "eval/reward_loss_std": 0.0014695378486067057, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011947154998779297, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0008401200175285339, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00013294012751430273, "eval/reward_rate": 0.0, "replay/size": 95525.0, "replay/inserts": 8604.0, "replay/samples": 34416.0, "replay/insert_wait_avg": 1.4975701637569554e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.736757709391446e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0508154502789454e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.556510925292969e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0683867931366, "timer/env.step_count": 1075.0, "timer/env.step_total": 10.3132905960083, "timer/env.step_frac": 0.010312585351367174, "timer/env.step_avg": 0.00959375869396121, "timer/env.step_min": 0.008616209030151367, "timer/env.step_max": 0.035440921783447266, "timer/replay._sample_count": 34416.0, "timer/replay._sample_total": 16.647713899612427, "timer/replay._sample_frac": 0.016646575493697708, "timer/replay._sample_avg": 0.0004837201853676321, "timer/replay._sample_min": 0.0003342628479003906, "timer/replay._sample_max": 0.03766465187072754, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1364.0, "timer/agent.policy_total": 13.771559476852417, "timer/agent.policy_frac": 0.01377061774846509, "timer/agent.policy_avg": 0.010096451229363942, "timer/agent.policy_min": 0.008762836456298828, "timer/agent.policy_max": 0.07957196235656738, "timer/dataset_train_count": 2151.0, "timer/dataset_train_total": 0.4050142765045166, "timer/dataset_train_frac": 0.0004049865807709943, "timer/dataset_train_avg": 0.00018829115597606536, "timer/dataset_train_min": 8.440017700195312e-05, "timer/dataset_train_max": 0.04715991020202637, "timer/agent.train_count": 2151.0, "timer/agent.train_total": 961.1448223590851, "timer/agent.train_frac": 0.9610790972416741, "timer/agent.train_avg": 0.4468362725983659, "timer/agent.train_min": 0.4355614185333252, "timer/agent.train_max": 0.5752489566802979, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46840691566467285, "timer/agent.report_frac": 0.0004683748850083014, "timer/agent.report_avg": 0.23420345783233643, "timer/agent.report_min": 0.22489356994628906, "timer/agent.report_max": 0.2435133457183838, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.980028444180778e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 8.603293926701902}
{"step": 96216, "time": 11233.802060365677, "episode/length": 241.0, "episode/score": 0.2862182794292494, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.03934327761317036}
{"step": 96584, "time": 11276.687288999557, "episode/length": 288.0, "episode/score": 0.11365049245864611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11365049245864611}
{"step": 96776, "time": 11299.001435995102, "episode/length": 288.0, "episode/score": 0.09488122890059003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09488122890059003}
{"step": 96808, "time": 11302.695437431335, "episode/length": 288.0, "episode/score": 0.10010796217068219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10010796217068219}
{"step": 97104, "time": 11336.958558797836, "episode/length": 288.0, "episode/score": 0.08701617150552465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08701617150552465}
{"step": 97104, "time": 11336.965563774109, "episode/length": 288.0, "episode/score": 0.10468260876393742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10468260876393742}
{"step": 97104, "time": 11336.972550153732, "episode/length": 288.0, "episode/score": 0.07777157669443113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07777157669443113}
{"step": 97456, "time": 11377.813343286514, "episode/length": 288.0, "episode/score": 0.12582021831894963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12582021831894963}
{"step": 98528, "time": 11502.621669054031, "episode/length": 288.0, "episode/score": 0.11153807787275127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11153807787275127}
{"step": 98896, "time": 11545.24917626381, "episode/length": 288.0, "episode/score": 0.10658463789332018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10658463789332018}
{"step": 99088, "time": 11567.535166978836, "episode/length": 288.0, "episode/score": 0.12734641854717665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12734641854717665}
{"step": 99120, "time": 11571.296952962875, "episode/length": 288.0, "episode/score": 0.0927460418749888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0927460418749888}
{"step": 99208, "time": 11581.588289499283, "episode/length": 262.0, "episode/score": 0.2981926874715555, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.11694268232599825}
{"step": 99416, "time": 11605.62050485611, "episode/length": 288.0, "episode/score": 0.0909211976683082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0909211976683082}
{"step": 99416, "time": 11605.627405405045, "episode/length": 288.0, "episode/score": 0.10071939383090012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10071939383090012}
{"step": 99768, "time": 11646.480488538742, "episode/length": 288.0, "episode/score": 0.11759600427535588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11759600427535588}
{"step": 100048, "time": 11684.18961238861, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 11684.196815013885, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 11684.20269203186, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 11684.208488941193, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 11684.214144229889, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 11684.219824790955, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 11684.225608587265, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 11684.231192111969, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100840, "time": 11775.931334972382, "episode/length": 288.0, "episode/score": 0.0800001563551973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0800001563551973}
{"step": 101208, "time": 11818.42495751381, "episode/length": 288.0, "episode/score": 0.06992431884845018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06992431884845018}
{"step": 101400, "time": 11840.610620737076, "episode/length": 288.0, "episode/score": 0.09817314935196464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09817314935196464}
{"step": 101432, "time": 11844.30060172081, "episode/length": 288.0, "episode/score": 0.10845861450536631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10845861450536631}
{"step": 101520, "time": 11854.46420121193, "episode/length": 288.0, "episode/score": 0.08498125524312172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08498125524312172}
{"step": 101728, "time": 11878.385688304901, "episode/length": 288.0, "episode/score": 0.07783085627198716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07783085627198716}
{"step": 101728, "time": 11878.39252281189, "episode/length": 288.0, "episode/score": 0.06481154370419517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06481154370419517}
{"step": 102080, "time": 11918.982317209244, "episode/length": 288.0, "episode/score": 0.07846323747753559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07846323747753559}
{"step": 103152, "time": 12042.64538526535, "episode/length": 288.0, "episode/score": 0.04862975653122703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04862975653122703}
{"step": 103520, "time": 12085.134706735611, "episode/length": 288.0, "episode/score": 0.08638672117211854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08638672117211854}
{"step": 103712, "time": 12107.371993303299, "episode/length": 288.0, "episode/score": 0.07410099872237197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07410099872237197}
{"step": 103744, "time": 12111.073952198029, "episode/length": 288.0, "episode/score": 0.08741571601194664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08741571601194664}
{"step": 103832, "time": 12121.36832690239, "episode/length": 288.0, "episode/score": 0.09675347601040585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09675347601040585}
{"step": 104040, "time": 12145.319103479385, "episode/length": 288.0, "episode/score": 0.09748823347803182, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09748823347803182}
{"step": 104040, "time": 12145.325909376144, "episode/length": 288.0, "episode/score": 0.04132821012177601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04132821012177601}
{"step": 104392, "time": 12186.138443231583, "episode/length": 288.0, "episode/score": 0.07563127951880233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07563127951880233}
{"step": 104613, "time": 12212.645894050598, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.7747657953306686, "train/action_min": 0.0, "train/action_std": 1.6136468221974927, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.003297742429395141, "train/actor_opt_grad_steps": 24690.0, "train/actor_opt_loss": -4.798144868917244, "train/adv_mag": 0.2181569406459498, "train/adv_max": 0.08278278188649998, "train/adv_mean": 0.0033919716766916304, "train/adv_min": -0.19617375682952792, "train/adv_std": 0.01060420050296586, "train/cont_avg": 0.9966842296511628, "train/cont_loss_mean": 0.004368815276647247, "train/cont_loss_std": 0.09806654308191609, "train/cont_neg_acc": 0.7676360607147217, "train/cont_neg_loss": 1.1636153407099343, "train/cont_pos_acc": 0.9998950961024262, "train/cont_pos_loss": 0.0009117891618759957, "train/cont_pred": 0.9966321570928707, "train/cont_rate": 0.9966842296511628, "train/dyn_loss_mean": 1.0000021773715353, "train/dyn_loss_std": 6.425508200177424e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.35422452104949326, "train/extr_critic_critic_opt_grad_steps": 24690.0, "train/extr_critic_critic_opt_loss": 10941.504632994185, "train/extr_critic_mag": 0.25259394867475643, "train/extr_critic_max": 0.25259394867475643, "train/extr_critic_mean": 0.2472422938707263, "train/extr_critic_min": 0.23784273890561836, "train/extr_critic_std": 0.0025604401365853847, "train/extr_return_normed_mag": 0.21777037243510403, "train/extr_return_normed_max": 0.0934674660133761, "train/extr_return_normed_mean": 0.012446991940825767, "train/extr_return_normed_min": -0.18570317459660907, "train/extr_return_normed_std": 0.011113241253160806, "train/extr_return_rate": 0.009507934200891488, "train/extr_return_raw_mag": 0.33165469737940056, "train/extr_return_raw_max": 0.33165469737940056, "train/extr_return_raw_mean": 0.2506342367377392, "train/extr_return_raw_min": 0.0524840560070304, "train/extr_return_raw_std": 0.011113241242872942, "train/extr_reward_mag": 0.08448871346407158, "train/extr_reward_max": 0.08448871346407158, "train/extr_reward_mean": 0.0012877858205979993, "train/extr_reward_min": 1.8613283024277798e-06, "train/extr_reward_std": 0.004457841844833998, "train/image_loss_mean": 0.08750475721303806, "train/image_loss_std": 0.10107584637264873, "train/model_loss_mean": 0.7013368847758271, "train/model_loss_std": 0.16432098115599433, "train/model_opt_grad_norm": 27.049446287820505, "train/model_opt_grad_steps": 24666.474418604652, "train/model_opt_loss": 1998.0823753179507, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2848.8372093023254, "train/policy_entropy_mag": 1.381099269279214, "train/policy_entropy_max": 1.381099269279214, "train/policy_entropy_mean": 0.6949428227058677, "train/policy_entropy_min": 0.12670245544854986, "train/policy_entropy_std": 0.21238989469616912, "train/policy_logprob_mag": 6.545321757294411, "train/policy_logprob_max": -0.020605448005331116, "train/policy_logprob_mean": -0.6945355202916057, "train/policy_logprob_min": -6.545321757294411, "train/policy_logprob_std": 0.747585268353307, "train/policy_randomness_mag": 0.7097446675910506, "train/policy_randomness_max": 0.7097446675910506, "train/policy_randomness_mean": 0.3571299824950307, "train/policy_randomness_min": 0.06511218551286431, "train/policy_randomness_std": 0.10914682115233222, "train/post_ent_mag": 34.00639297130496, "train/post_ent_max": 34.00639297130496, "train/post_ent_mean": 33.69077279734057, "train/post_ent_min": 33.48686943941338, "train/post_ent_std": 0.10157140961220099, "train/prior_ent_mag": 35.35149131597475, "train/prior_ent_max": 35.35149131597475, "train/prior_ent_mean": 33.61548193998115, "train/prior_ent_min": 32.296394401372865, "train/prior_ent_std": 0.5107717889685963, "train/rep_loss_mean": 1.0000021773715353, "train/rep_loss_std": 6.425508200177424e-05, "train/reward_avg": 0.00024880284252630676, "train/reward_loss_mean": 0.009461984971841407, "train/reward_loss_std": 0.01771274417812048, "train/reward_max_data": 0.03329554362828995, "train/reward_max_pred": 0.02379758690678796, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009333704769351454, "train/reward_pos_acc": 0.8235294117647058, "train/reward_pos_loss": 1.6213662834728466, "train/reward_pred": 0.00024262052083517922, "train/reward_rate": 8.175872093023256e-05, "train_stats/mean_log_entropy": 0.836938492488116, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0014061547117307782, "report/cont_loss_std": 0.013405870646238327, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.004936521407216787, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0013888319954276085, "report/cont_pred": 0.9938412308692932, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08752425014972687, "report/image_loss_std": 0.09791494160890579, "report/model_loss_mean": 0.6958460211753845, "report/model_loss_std": 0.10349806398153305, "report/post_ent_mag": 33.65913391113281, "report/post_ent_max": 33.65913391113281, "report/post_ent_mean": 33.29932403564453, "report/post_ent_min": 33.07677459716797, "report/post_ent_std": 0.13763543963432312, "report/prior_ent_mag": 34.98686981201172, "report/prior_ent_max": 34.98686981201172, "report/prior_ent_mean": 33.311649322509766, "report/prior_ent_min": 31.785472869873047, "report/prior_ent_std": 0.7126078009605408, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00015675512258894742, "report/reward_loss_mean": 0.006915583275258541, "report/reward_loss_std": 0.012337679043412209, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0015016794204711914, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.006915582809597254, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00018047785852104425, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0368460938334465, "eval/cont_loss_std": 0.673091471195221, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.450525283813477, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0003710347809828818, "eval/cont_pred": 0.9996311664581299, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2511281967163086, "eval/image_loss_std": 0.16824543476104736, "eval/model_loss_mean": 0.8894605040550232, "eval/model_loss_std": 0.6888206601142883, "eval/post_ent_mag": 33.621551513671875, "eval/post_ent_max": 33.621551513671875, "eval/post_ent_mean": 33.245330810546875, "eval/post_ent_min": 33.07860565185547, "eval/post_ent_std": 0.09545604139566422, "eval/prior_ent_mag": 34.93661117553711, "eval/prior_ent_max": 34.93661117553711, "eval/prior_ent_mean": 33.076385498046875, "eval/prior_ent_min": 31.770639419555664, "eval/prior_ent_std": 0.5201980471611023, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014861710369586945, "eval/reward_loss_std": 0.002070555230602622, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0013189315795898438, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014861710369586945, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023714196868240833, "eval/reward_rate": 0.0, "replay/size": 104109.0, "replay/inserts": 8584.0, "replay/samples": 34336.0, "replay/insert_wait_avg": 1.5104750218173664e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.770476447902655e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26488.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1102138506087465e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.415759563446, "timer/env.step_count": 1073.0, "timer/env.step_total": 10.263330459594727, "timer/env.step_frac": 0.01025906515514446, "timer/env.step_avg": 0.009565079645475047, "timer/env.step_min": 0.008301734924316406, "timer/env.step_max": 0.03451371192932129, "timer/replay._sample_count": 34336.0, "timer/replay._sample_total": 16.71090078353882, "timer/replay._sample_frac": 0.016703955954103518, "timer/replay._sample_avg": 0.0004866874645718435, "timer/replay._sample_min": 0.0003330707550048828, "timer/replay._sample_max": 0.025814056396484375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1362.0, "timer/agent.policy_total": 13.445105075836182, "timer/agent.policy_frac": 0.013439517467920794, "timer/agent.policy_avg": 0.00987158962983567, "timer/agent.policy_min": 0.008672475814819336, "timer/agent.policy_max": 0.03436589241027832, "timer/dataset_train_count": 2146.0, "timer/dataset_train_total": 0.3597085475921631, "timer/dataset_train_frac": 0.00035955905747539404, "timer/dataset_train_avg": 0.0001676181489245867, "timer/dataset_train_min": 8.344650268554688e-05, "timer/dataset_train_max": 0.0011916160583496094, "timer/agent.train_count": 2146.0, "timer/agent.train_total": 962.1566169261932, "timer/agent.train_frac": 0.9617567573566134, "timer/agent.train_avg": 0.4483488429292606, "timer/agent.train_min": 0.4367942810058594, "timer/agent.train_max": 0.5790176391601562, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46795654296875, "timer/agent.report_frac": 0.00046776206641622016, "timer/agent.report_avg": 0.233978271484375, "timer/agent.report_min": 0.22375774383544922, "timer/agent.report_max": 0.24419879913330078, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7645061477090097e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 8.58031800725234}
{"step": 105464, "time": 12310.797182798386, "episode/length": 288.0, "episode/score": 0.08984559446105322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08984559446105322}
{"step": 105832, "time": 12353.39863872528, "episode/length": 288.0, "episode/score": 0.08482469415605465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08482469415605465}
{"step": 106024, "time": 12375.537155628204, "episode/length": 288.0, "episode/score": 0.07415329531175985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07415329531175985}
{"step": 106056, "time": 12379.225866317749, "episode/length": 288.0, "episode/score": 0.08169532145109315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08169532145109315}
{"step": 106144, "time": 12389.373726844788, "episode/length": 288.0, "episode/score": 0.08175833028241186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08175833028241186}
{"step": 106352, "time": 12413.293916225433, "episode/length": 288.0, "episode/score": 0.07065022804141563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07065022804141563}
{"step": 106352, "time": 12413.30912065506, "episode/length": 288.0, "episode/score": 0.06566996121341617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06566996121341617}
{"step": 106704, "time": 12454.237781047821, "episode/length": 288.0, "episode/score": 0.09365336668685131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09365336668685131}
{"step": 107776, "time": 12577.895478248596, "episode/length": 288.0, "episode/score": 0.08267643453393703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08267643453393703}
{"step": 108144, "time": 12620.25415635109, "episode/length": 288.0, "episode/score": 0.09704556281315035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09704556281315035}
{"step": 108336, "time": 12642.515716075897, "episode/length": 288.0, "episode/score": 0.1292049890160456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1292049890160456}
{"step": 108368, "time": 12646.202354431152, "episode/length": 288.0, "episode/score": 0.0977712953132368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0977712953132368}
{"step": 108456, "time": 12656.326712608337, "episode/length": 288.0, "episode/score": 0.09292315561981468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09292315561981468}
{"step": 108664, "time": 12680.372684001923, "episode/length": 288.0, "episode/score": 0.10759157619457937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10759157619457937}
{"step": 108664, "time": 12680.379828214645, "episode/length": 288.0, "episode/score": 0.10487254343360064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10487254343360064}
{"step": 109016, "time": 12720.938586711884, "episode/length": 288.0, "episode/score": 0.1301768363997553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1301768363997553}
{"step": 110032, "time": 12843.632593631744, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 12843.641034841537, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 12843.64730000496, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 12843.653824090958, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 12843.659949541092, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 12843.665448904037, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 12843.671050548553, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 12843.676819086075, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110088, "time": 12850.179936885834, "episode/length": 288.0, "episode/score": 0.08093686584408033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08093686584408033}
{"step": 110456, "time": 12892.43054485321, "episode/length": 288.0, "episode/score": 0.09368876398764314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09368876398764314}
{"step": 110648, "time": 12914.55030298233, "episode/length": 288.0, "episode/score": 0.10459913057712811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10459913057712811}
{"step": 110680, "time": 12918.23729634285, "episode/length": 288.0, "episode/score": 0.1091423925350341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1091423925350341}
{"step": 110768, "time": 12928.356297969818, "episode/length": 288.0, "episode/score": 0.0467480848571995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0467480848571995}
{"step": 110976, "time": 12952.555342435837, "episode/length": 288.0, "episode/score": 0.09536355215277581, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09536355215277581}
{"step": 110976, "time": 12952.56218457222, "episode/length": 288.0, "episode/score": 0.07514749227993889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07514749227993889}
{"step": 111328, "time": 12993.032226324081, "episode/length": 288.0, "episode/score": 0.09916025603888556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09916025603888556}
{"step": 112400, "time": 13116.473268032074, "episode/length": 288.0, "episode/score": 0.09211759367144623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09211759367144623}
{"step": 112768, "time": 13158.506118774414, "episode/length": 288.0, "episode/score": 0.16079348273615324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16079348273615324}
{"step": 112960, "time": 13180.586612224579, "episode/length": 288.0, "episode/score": 0.08698667566523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08698667566523}
{"step": 112992, "time": 13184.249988079071, "episode/length": 288.0, "episode/score": 0.10080086657671927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10080086657671927}
{"step": 113080, "time": 13194.374769926071, "episode/length": 288.0, "episode/score": 0.10255791815234261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10255791815234261}
{"step": 113136, "time": 13200.814913988113, "episode/length": 21.0, "episode/score": 0.9499255711248225, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.01555055440758224}
{"step": 113233, "time": 13213.016871213913, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.214441769622093, "train/action_min": 0.0, "train/action_std": 1.3222176241320234, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002853045847028667, "train/actor_opt_grad_steps": 26840.0, "train/actor_opt_loss": -16.079001499885738, "train/adv_mag": 0.23387790786665538, "train/adv_max": 0.03814056973124659, "train/adv_mean": -0.0010888047830396614, "train/adv_min": -0.22572620226893314, "train/adv_std": 0.008579987900461569, "train/cont_avg": 0.996593386627907, "train/cont_loss_mean": 0.004469517845698351, "train/cont_loss_std": 0.09817761686863377, "train/cont_neg_acc": 0.7767716145487193, "train/cont_neg_loss": 1.0731121967288708, "train/cont_pos_acc": 0.9999042613561764, "train/cont_pos_loss": 0.0009494158295172721, "train/cont_pred": 0.9965489534444587, "train/cont_rate": 0.996593386627907, "train/dyn_loss_mean": 1.00001003742218, "train/dyn_loss_std": 0.00027848366302096956, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1584811101797535, "train/extr_critic_critic_opt_grad_steps": 26840.0, "train/extr_critic_critic_opt_loss": 13121.958057776163, "train/extr_critic_mag": 0.27644289482471557, "train/extr_critic_max": 0.27644289482471557, "train/extr_critic_mean": 0.26723706763844157, "train/extr_critic_min": 0.2602001561674961, "train/extr_critic_std": 0.002414442358137823, "train/extr_return_normed_mag": 0.2303314396808314, "train/extr_return_normed_max": 0.04480276689972988, "train/extr_return_normed_mean": 0.0035779774664809146, "train/extr_return_normed_min": -0.22041503773179166, "train/extr_return_normed_std": 0.008954219893162507, "train/extr_return_rate": 2.967538870464967e-05, "train/extr_return_raw_mag": 0.3073730322510697, "train/extr_return_raw_max": 0.3073730322510697, "train/extr_return_raw_mean": 0.2661482564931692, "train/extr_return_raw_min": 0.042155227896779085, "train/extr_return_raw_std": 0.008954219854718377, "train/extr_reward_mag": 0.047580231067746184, "train/extr_reward_max": 0.047580231067746184, "train/extr_reward_mean": 0.0006658183777607371, "train/extr_reward_min": 1.4404917872229289e-06, "train/extr_reward_std": 0.0022588981029869944, "train/image_loss_mean": 0.08947203743249871, "train/image_loss_std": 0.10311903558498205, "train/model_loss_mean": 0.7036356044370075, "train/model_loss_std": 0.1657376378774643, "train/model_opt_grad_norm": 27.532645762243938, "train/model_opt_grad_steps": 26814.92558139535, "train/model_opt_loss": 2496.0338401617005, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3546.5116279069766, "train/policy_entropy_mag": 1.4661956997804864, "train/policy_entropy_max": 1.4661956997804864, "train/policy_entropy_mean": 0.7053435579981915, "train/policy_entropy_min": 0.07698254377342933, "train/policy_entropy_std": 0.2647949730934099, "train/policy_logprob_mag": 6.548926615160565, "train/policy_logprob_max": -0.0109149913758386, "train/policy_logprob_mean": -0.7054558040097703, "train/policy_logprob_min": -6.548926615160565, "train/policy_logprob_std": 0.8081835297651069, "train/policy_randomness_mag": 0.7534755845402562, "train/policy_randomness_max": 0.7534755845402562, "train/policy_randomness_mean": 0.3624749042613562, "train/policy_randomness_min": 0.03956120409244715, "train/policy_randomness_std": 0.13607770460982654, "train/post_ent_mag": 33.98035060084143, "train/post_ent_max": 33.98035060084143, "train/post_ent_mean": 33.53536740680074, "train/post_ent_min": 33.25852563547534, "train/post_ent_std": 0.14534791111946105, "train/prior_ent_mag": 34.893171638666196, "train/prior_ent_max": 34.893171638666196, "train/prior_ent_mean": 33.257726305584576, "train/prior_ent_min": 32.02760121545126, "train/prior_ent_std": 0.48322901711907496, "train/rep_loss_mean": 1.00001003742218, "train/rep_loss_std": 0.00027848366302096956, "train/reward_avg": 0.0002431953552606797, "train/reward_loss_mean": 0.009688005410134792, "train/reward_loss_std": 0.01574063816995815, "train/reward_max_data": 0.020928295408267267, "train/reward_max_pred": 0.017723660136378088, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00963755895188728, "train/reward_pos_acc": 0.8, "train/reward_pos_loss": 1.1199026107788086, "train/reward_pred": 0.00024506176962668815, "train/reward_rate": 4.5421511627906976e-05, "train_stats/mean_log_entropy": 0.6219100847840309, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.00047471997095271945, "report/cont_loss_std": 0.002916723256930709, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.004774266388267279, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00046208660933189094, "report/cont_pred": 0.9966277480125427, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07985251396894455, "report/image_loss_std": 0.11693653464317322, "report/model_loss_mean": 0.6904411911964417, "report/model_loss_std": 0.12324993312358856, "report/post_ent_mag": 34.4074821472168, "report/post_ent_max": 34.4074821472168, "report/post_ent_mean": 33.85590744018555, "report/post_ent_min": 33.51788330078125, "report/post_ent_std": 0.17492063343524933, "report/prior_ent_mag": 34.33197021484375, "report/prior_ent_max": 34.33197021484375, "report/prior_ent_mean": 32.863365173339844, "report/prior_ent_min": 31.688369750976562, "report/prior_ent_std": 0.4363345801830292, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007521401275880635, "report/reward_loss_mean": 0.01011393591761589, "report/reward_loss_std": 0.02238277718424797, "report/reward_max_data": 0.5450000166893005, "report/reward_max_pred": 0.5361455678939819, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00957213994115591, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.5643711686134338, "report/reward_pred": 0.0007669111946597695, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.024476710706949234, "eval/cont_loss_std": 0.5392844676971436, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.214848518371582, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0006207958213053644, "eval/cont_pred": 0.9993869066238403, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26913267374038696, "eval/image_loss_std": 0.15061482787132263, "eval/model_loss_mean": 0.8947499990463257, "eval/model_loss_std": 0.5538574457168579, "eval/post_ent_mag": 34.325225830078125, "eval/post_ent_max": 34.325225830078125, "eval/post_ent_mean": 33.77984619140625, "eval/post_ent_min": 33.49925231933594, "eval/post_ent_std": 0.14384543895721436, "eval/prior_ent_mag": 34.33197021484375, "eval/prior_ent_max": 34.33197021484375, "eval/prior_ent_mean": 32.86029052734375, "eval/prior_ent_min": 31.696556091308594, "eval/prior_ent_std": 0.4089582562446594, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001140656415373087, "eval/reward_loss_std": 0.0018395534716546535, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.005475401878356934, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001140656415373087, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00018994021229445934, "eval/reward_rate": 0.0, "replay/size": 112729.0, "replay/inserts": 8620.0, "replay/samples": 34480.0, "replay/insert_wait_avg": 1.5095878919703225e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.936337707767354e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 28800.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1320757618412426e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.357750415802, "timer/env.step_count": 1078.0, "timer/env.step_total": 10.038436651229858, "timer/env.step_frac": 0.010034846680657343, "timer/env.step_avg": 0.009312093368487808, "timer/env.step_min": 0.008155584335327148, "timer/env.step_max": 0.03463602066040039, "timer/replay._sample_count": 34480.0, "timer/replay._sample_total": 16.467710971832275, "timer/replay._sample_frac": 0.01646182174825698, "timer/replay._sample_avg": 0.0004776018263292423, "timer/replay._sample_min": 0.00035071372985839844, "timer/replay._sample_max": 0.010442972183227539, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1367.0, "timer/agent.policy_total": 13.437304735183716, "timer/agent.policy_frac": 0.013432499252990698, "timer/agent.policy_avg": 0.009829776689966142, "timer/agent.policy_min": 0.008798837661743164, "timer/agent.policy_max": 0.03680062294006348, "timer/dataset_train_count": 2155.0, "timer/dataset_train_total": 0.36293768882751465, "timer/dataset_train_frac": 0.00036280789415252533, "timer/dataset_train_avg": 0.00016841656094084207, "timer/dataset_train_min": 8.559226989746094e-05, "timer/dataset_train_max": 0.00048279762268066406, "timer/agent.train_count": 2155.0, "timer/agent.train_total": 962.3131604194641, "timer/agent.train_frac": 0.961969015604143, "timer/agent.train_avg": 0.4465490303570599, "timer/agent.train_min": 0.4337162971496582, "timer/agent.train_max": 0.5808100700378418, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47721147537231445, "timer/agent.report_frac": 0.00047704081382281483, "timer/agent.report_avg": 0.23860573768615723, "timer/agent.report_min": 0.2332744598388672, "timer/agent.report_max": 0.24393701553344727, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.145999761417865e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 8.616798117727663}
{"step": 113288, "time": 13219.147825479507, "episode/length": 288.0, "episode/score": 0.10275416878562282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10275416878562282}
{"step": 113288, "time": 13219.15480709076, "episode/length": 288.0, "episode/score": 0.11058794280370421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11058794280370421}
{"step": 113336, "time": 13224.655313253403, "episode/length": 5.0, "episode/score": 0.9884309726694482, "episode/reward_rate": 0.16666666666666666, "episode/intrinsic_return": 0.0040559440312790684}
{"step": 113640, "time": 13259.523530960083, "episode/length": 288.0, "episode/score": 0.1156241014157331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1156241014157331}
{"step": 114712, "time": 13383.260552167892, "episode/length": 288.0, "episode/score": 0.10269954386149038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10269954386149038}
{"step": 115080, "time": 13425.508083105087, "episode/length": 288.0, "episode/score": 0.1265281133710232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1265281133710232}
{"step": 115304, "time": 13451.157655000687, "episode/length": 288.0, "episode/score": 0.09014742130102604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09014742130102604}
{"step": 115392, "time": 13461.232967376709, "episode/length": 288.0, "episode/score": 0.06617190274550921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06617190274550921}
{"step": 115448, "time": 13467.64564871788, "episode/length": 288.0, "episode/score": 0.11394292606155432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11394292606155432}
{"step": 115600, "time": 13485.165986537933, "episode/length": 288.0, "episode/score": 0.08847433062362597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08847433062362597}
{"step": 115648, "time": 13490.672719478607, "episode/length": 288.0, "episode/score": 0.08900254889067583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08900254889067583}
{"step": 115952, "time": 13525.983859062195, "episode/length": 288.0, "episode/score": 0.0677630654386121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0677630654386121}
{"step": 116688, "time": 13610.735862016678, "episode/length": 154.0, "episode/score": 0.5733966367741914, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.05464659621509327}
{"step": 116888, "time": 13633.881156206131, "episode/length": 197.0, "episode/score": 0.45749211996849226, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.07311711482293504}
{"step": 117024, "time": 13649.522519826889, "episode/length": 288.0, "episode/score": 0.11494966895998004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11494966895998004}
{"step": 117392, "time": 13692.085040807724, "episode/length": 288.0, "episode/score": 0.04993300350145091, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04993300350145091}
{"step": 117624, "time": 13719.140436172485, "episode/length": 278.0, "episode/score": 0.20084244942415808, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.06959245596669916}
{"step": 117848, "time": 13745.241526603699, "episode/length": 280.0, "episode/score": 0.20787568292746528, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0828756840916185}
{"step": 117960, "time": 13758.125355005264, "episode/length": 288.0, "episode/score": 0.07168853229666183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07168853229666183}
{"step": 118120, "time": 13776.512192249298, "episode/length": 61.0, "episode/score": 0.8350915789064857, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.025716576508330036}
{"step": 118152, "time": 13780.165056467056, "episode/length": 274.0, "episode/score": 0.23217922627657117, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.08842922966425704}
{"step": 119000, "time": 13877.682595729828, "episode/length": 288.0, "episode/score": 0.049711368126850175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049711368126850175}
{"step": 119200, "time": 13900.65749502182, "episode/length": 288.0, "episode/score": 0.08007915326811599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08007915326811599}
{"step": 119336, "time": 13916.223492383957, "episode/length": 288.0, "episode/score": 0.0809616469471166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0809616469471166}
{"step": 119704, "time": 13958.520274400711, "episode/length": 288.0, "episode/score": 0.051258366301681235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051258366301681235}
{"step": 120016, "time": 13998.097468614578, "eval_episode/length": 225.0, "eval_episode/score": 0.296875, "eval_episode/reward_rate": 0.004424778761061947}
{"step": 120016, "time": 13999.168449878693, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 13999.175299406052, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 13999.180716753006, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 13999.186050653458, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 13999.201030254364, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 13999.213638305664, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 13999.218937158585, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120160, "time": 14015.805014133453, "episode/length": 288.0, "episode/score": 0.04759246047473198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04759246047473198}
{"step": 120200, "time": 14020.368932008743, "episode/length": 107.0, "episode/score": 0.694172199269417, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.02854722392618214}
{"step": 120272, "time": 14028.645408153534, "episode/length": 288.0, "episode/score": 0.03320838581561247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03320838581561247}
{"step": 120432, "time": 14047.209356546402, "episode/length": 288.0, "episode/score": 0.06667714997774965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06667714997774965}
{"step": 120456, "time": 14049.973893404007, "episode/length": 156.0, "episode/score": 0.5604553162914954, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.04795532902733157}
{"step": 120464, "time": 14050.893667459488, "episode/length": 288.0, "episode/score": 0.05807234072170786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05807234072170786}
{"step": 120656, "time": 14072.98636674881, "episode/length": 23.0, "episode/score": 0.9389314753847771, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.010806422148050387}
{"step": 121312, "time": 14148.573969125748, "episode/length": 288.0, "episode/score": 0.04666281336830025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04666281336830025}
{"step": 121552, "time": 14176.461495876312, "episode/length": 230.0, "episode/score": 0.33129900625493747, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.050048999095395175}
{"step": 121865, "time": 14213.34202671051, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.177189862286603, "train/action_min": 0.0, "train/action_std": 1.5527896660345573, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0060445699498275106, "train/actor_opt_grad_steps": 28995.0, "train/actor_opt_loss": -5.1441512168557555, "train/adv_mag": 0.3319021945612298, "train/adv_max": 0.12546902839784269, "train/adv_mean": 0.012222511316024422, "train/adv_min": -0.26363871101703906, "train/adv_std": 0.02120365518257367, "train/cont_avg": 0.9966362847222222, "train/cont_loss_mean": 0.005207753454602358, "train/cont_loss_std": 0.1151931514490301, "train/cont_neg_acc": 0.7249529895624278, "train/cont_neg_loss": 1.3106956153081, "train/cont_pos_acc": 0.9998774357416012, "train/cont_pos_loss": 0.0009651443866055666, "train/cont_pred": 0.9967206879346459, "train/cont_rate": 0.9966362847222222, "train/dyn_loss_mean": 1.0000460120262924, "train/dyn_loss_std": 0.00037396172985137564, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5482661064673232, "train/extr_critic_critic_opt_grad_steps": 28995.0, "train/extr_critic_critic_opt_loss": 10874.774052372684, "train/extr_critic_mag": 0.31601178535708674, "train/extr_critic_max": 0.31601178535708674, "train/extr_critic_mean": 0.308460289819373, "train/extr_critic_min": 0.29146641823980546, "train/extr_critic_std": 0.0019438089474095722, "train/extr_return_normed_mag": 0.3399629704654217, "train/extr_return_normed_max": 0.13978387822431546, "train/extr_return_normed_mean": 0.026759763453044257, "train/extr_return_normed_min": -0.24804178080349057, "train/extr_return_normed_std": 0.021297335446299123, "train/extr_return_rate": 0.03921772711425917, "train/extr_return_raw_mag": 0.433706897345406, "train/extr_return_raw_max": 0.433706897345406, "train/extr_return_raw_mean": 0.32068279799487853, "train/extr_return_raw_min": 0.045881237351784, "train/extr_return_raw_std": 0.021297335660805133, "train/extr_reward_mag": 0.09351076516840193, "train/extr_reward_max": 0.09351076516840193, "train/extr_reward_mean": 0.0024457314550629774, "train/extr_reward_min": 4.0282805760701495e-06, "train/extr_reward_std": 0.007522065789897978, "train/image_loss_mean": 0.08672187456654178, "train/image_loss_std": 0.10306942673331057, "train/model_loss_mean": 0.7022048670936514, "train/model_loss_std": 0.1844971668044174, "train/model_opt_grad_norm": 25.386726948950027, "train/model_opt_grad_steps": 28968.449074074073, "train/model_opt_loss": 2079.77153467249, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2974.537037037037, "train/policy_entropy_mag": 1.5359105396049995, "train/policy_entropy_max": 1.5359105396049995, "train/policy_entropy_mean": 0.8367161637999945, "train/policy_entropy_min": 0.1442254924180883, "train/policy_entropy_std": 0.21187793525556722, "train/policy_logprob_mag": 6.538355429967244, "train/policy_logprob_max": -0.0249456506162123, "train/policy_logprob_mean": -0.8367823727635874, "train/policy_logprob_min": -6.538355429967244, "train/policy_logprob_std": 0.7375628305254159, "train/policy_randomness_mag": 0.7893019263391141, "train/policy_randomness_max": 0.7893019263391141, "train/policy_randomness_mean": 0.4299870752039607, "train/policy_randomness_min": 0.07411724579072108, "train/policy_randomness_std": 0.10888372625534733, "train/post_ent_mag": 33.83588907453749, "train/post_ent_max": 33.83588907453749, "train/post_ent_mean": 33.400420330188894, "train/post_ent_min": 33.102301597595215, "train/post_ent_std": 0.14845023497387214, "train/prior_ent_mag": 34.58949802539967, "train/prior_ent_max": 34.58949802539967, "train/prior_ent_mean": 33.011285605253995, "train/prior_ent_min": 31.736978884096498, "train/prior_ent_std": 0.49624008092063443, "train/rep_loss_mean": 1.0000460120262924, "train/rep_loss_std": 0.00037396172985137564, "train/reward_avg": 0.0002682131651252146, "train/reward_loss_mean": 0.01024761047274633, "train/reward_loss_std": 0.02607448325337221, "train/reward_max_data": 0.04442804891085769, "train/reward_max_pred": 0.02415393348093386, "train/reward_neg_acc": 0.9999367042824074, "train/reward_neg_loss": 0.009890081188469022, "train/reward_pos_acc": 0.4666666666666667, "train/reward_pos_loss": 5.281712917486827, "train/reward_pred": 0.00028638769247293195, "train/reward_rate": 6.781684027777778e-05, "train_stats/mean_log_entropy": 0.9542830231435159, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.014137737452983856, "report/cont_loss_std": 0.2886809706687927, "report/cont_neg_acc": 0.5714285969734192, "report/cont_neg_loss": 1.9592362642288208, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0007496451144106686, "report/cont_pred": 0.9949498772621155, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10080376267433167, "report/image_loss_std": 0.105875663459301, "report/model_loss_mean": 0.7258350849151611, "report/model_loss_std": 0.31380853056907654, "report/post_ent_mag": 32.86042785644531, "report/post_ent_max": 32.86042785644531, "report/post_ent_mean": 32.48073196411133, "report/post_ent_min": 32.163692474365234, "report/post_ent_std": 0.17580102384090424, "report/prior_ent_mag": 33.97520446777344, "report/prior_ent_max": 33.97520446777344, "report/prior_ent_mean": 32.451908111572266, "report/prior_ent_min": 30.894174575805664, "report/prior_ent_std": 0.6826575398445129, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002525392919778824, "report/reward_loss_mean": 0.01089359913021326, "report/reward_loss_std": 0.015597791410982609, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.009826302528381348, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010893598198890686, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002723574871197343, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.020965266972780228, "eval/cont_loss_std": 0.4648110866546631, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.402423858642578, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0006493034888990223, "eval/cont_pred": 0.9993557929992676, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25730130076408386, "eval/image_loss_std": 0.1503223478794098, "eval/model_loss_mean": 0.8792699575424194, "eval/model_loss_std": 0.49181193113327026, "eval/post_ent_mag": 32.82963562011719, "eval/post_ent_max": 32.82963562011719, "eval/post_ent_mean": 32.35118865966797, "eval/post_ent_min": 32.11902618408203, "eval/post_ent_std": 0.13599860668182373, "eval/prior_ent_mag": 33.97520446777344, "eval/prior_ent_max": 33.97520446777344, "eval/prior_ent_mean": 32.211421966552734, "eval/prior_ent_min": 30.93414878845215, "eval/prior_ent_std": 0.5375862717628479, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0010033119469881058, "eval/reward_loss_std": 0.0017951158806681633, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.010921716690063477, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010033119469881058, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00017891766037791967, "eval/reward_rate": 0.0, "replay/size": 121361.0, "replay/inserts": 8632.0, "replay/samples": 34528.0, "replay/insert_wait_avg": 1.525773949044186e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.774635969874371e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.803829721101016e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3101098537445, "timer/env.step_count": 1079.0, "timer/env.step_total": 10.072366952896118, "timer/env.step_frac": 0.010069244380993811, "timer/env.step_avg": 0.009334909131507061, "timer/env.step_min": 0.00819540023803711, "timer/env.step_max": 0.03403496742248535, "timer/replay._sample_count": 34528.0, "timer/replay._sample_total": 16.503135442733765, "timer/replay._sample_frac": 0.01649801924439881, "timer/replay._sample_avg": 0.000477963839282141, "timer/replay._sample_min": 0.00034356117248535156, "timer/replay._sample_max": 0.01074981689453125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1368.0, "timer/agent.policy_total": 13.168659925460815, "timer/agent.policy_frac": 0.013164577460270003, "timer/agent.policy_avg": 0.00962621339580469, "timer/agent.policy_min": 0.008632659912109375, "timer/agent.policy_max": 0.04036116600036621, "timer/dataset_train_count": 2158.0, "timer/dataset_train_total": 0.37468838691711426, "timer/dataset_train_frac": 0.00037457222837815514, "timer/dataset_train_avg": 0.00017362761210246258, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.0006721019744873047, "timer/agent.train_count": 2158.0, "timer/agent.train_total": 962.5236623287201, "timer/agent.train_frac": 0.962225266791966, "timer/agent.train_avg": 0.44602579347948107, "timer/agent.train_min": 0.43378162384033203, "timer/agent.train_max": 0.9754767417907715, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4745066165924072, "timer/agent.report_frac": 0.00047435951303319816, "timer/agent.report_avg": 0.2372533082962036, "timer/agent.report_min": 0.23186540603637695, "timer/agent.report_max": 0.24264121055603027, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6694602600066926e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 8.62921025549835}
{"step": 122472, "time": 14282.96482872963, "episode/length": 288.0, "episode/score": 0.04771096696225641, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04771096696225641}
{"step": 122512, "time": 14287.55663895607, "episode/length": 288.0, "episode/score": 0.05316972511673157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05316972511673157}
{"step": 122584, "time": 14295.82342338562, "episode/length": 288.0, "episode/score": 0.05137292354731926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05137292354731926}
{"step": 122744, "time": 14314.246848106384, "episode/length": 288.0, "episode/score": 0.030322583542499615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030322583542499615}
{"step": 122768, "time": 14317.032660484314, "episode/length": 288.0, "episode/score": 0.034582452638858285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034582452638858285}
{"step": 122968, "time": 14340.315766572952, "episode/length": 288.0, "episode/score": 0.030223948070897677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030223948070897677}
{"step": 123624, "time": 14415.571851015091, "episode/length": 288.0, "episode/score": 0.01661448332316695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01661448332316695}
{"step": 123864, "time": 14443.18737745285, "episode/length": 288.0, "episode/score": 0.035704884500773915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035704884500773915}
{"step": 124208, "time": 14482.711902618408, "episode/length": 179.0, "episode/score": 0.47107649495364967, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.030451475873178424}
{"step": 124784, "time": 14549.237209320068, "episode/length": 288.0, "episode/score": 0.03631712410199839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03631712410199839}
{"step": 124824, "time": 14553.994808197021, "episode/length": 288.0, "episode/score": 0.024959190464869607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024959190464869607}
{"step": 124896, "time": 14562.355995416641, "episode/length": 288.0, "episode/score": 0.027264318900421358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027264318900421358}
{"step": 125056, "time": 14580.755165100098, "episode/length": 288.0, "episode/score": 0.027574034443887285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027574034443887285}
{"step": 125176, "time": 14594.559888124466, "episode/length": 163.0, "episode/score": 0.5241585196343124, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.03353351127569226}
{"step": 125280, "time": 14606.501326084137, "episode/length": 288.0, "episode/score": 0.03609351565526708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03609351565526708}
{"step": 125672, "time": 14651.580877304077, "episode/length": 255.0, "episode/score": 0.2406342688943539, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.03750926947643052}
{"step": 126216, "time": 14714.48668885231, "episode/length": 67.0, "episode/score": 0.808793827961324, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.018168828461909925}
{"step": 126312, "time": 14725.496380329132, "episode/length": 176.0, "episode/score": 0.4828274199160205, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.03282742217447776}
{"step": 126424, "time": 14738.491289615631, "episode/length": 204.0, "episode/score": 0.4008127968895394, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.038312773297974445}
{"step": 126520, "time": 14749.551832914352, "episode/length": 288.0, "episode/score": 0.06050136917599502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06050136917599502}
{"step": 126992, "time": 14803.77327990532, "episode/length": 241.0, "episode/score": 0.2967174104071546, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.049842413887972725}
{"step": 127096, "time": 14815.704319477081, "episode/length": 97.0, "episode/score": 0.7184796644764901, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.02160468853662678}
{"step": 127136, "time": 14820.29478931427, "episode/length": 288.0, "episode/score": 0.034129122513661514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034129122513661514}
{"step": 127488, "time": 14861.209488868713, "episode/length": 288.0, "episode/score": 0.03933295074250509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03933295074250509}
{"step": 127592, "time": 14873.174075603485, "episode/length": 288.0, "episode/score": 0.04041149807207489, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04041149807207489}
{"step": 128528, "time": 14981.726874351501, "episode/length": 288.0, "episode/score": 0.045817719930397516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045817719930397516}
{"step": 128736, "time": 15005.802535057068, "episode/length": 288.0, "episode/score": 0.05802330148492274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05802330148492274}
{"step": 128832, "time": 15016.863320827484, "episode/length": 288.0, "episode/score": 0.04965881647655124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04965881647655124}
{"step": 129304, "time": 15071.794429063797, "episode/length": 288.0, "episode/score": 0.023376191420538817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023376191420538817}
{"step": 129408, "time": 15083.76973938942, "episode/length": 288.0, "episode/score": 0.021778313478563405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021778313478563405}
{"step": 129448, "time": 15088.389730453491, "episode/length": 288.0, "episode/score": 0.062298940060060204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062298940060060204}
{"step": 129520, "time": 15096.804292678833, "episode/length": 253.0, "episode/score": 0.2581936605289741, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.04881867295048892}
{"step": 129904, "time": 15141.29994893074, "episode/length": 288.0, "episode/score": 0.06384988985087148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06384988985087148}
{"step": 130000, "time": 15153.776967287064, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 130000, "time": 15156.496963262558, "eval_episode/length": 197.0, "eval_episode/score": 0.3843750059604645, "eval_episode/reward_rate": 0.005050505050505051}
{"step": 130000, "time": 15158.06842327118, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 15158.074513673782, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 15158.079752206802, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 15158.084938764572, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 15158.090059041977, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 15158.095121860504, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130256, "time": 15187.666568756104, "episode/length": 177.0, "episode/score": 0.47599024593176864, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.02911524037875779}
{"step": 130473, "time": 15213.55282998085, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7332863031431684, "train/action_min": 0.0, "train/action_std": 1.4543788178022519, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0076565494306038975, "train/actor_opt_grad_steps": 31150.0, "train/actor_opt_loss": -2.814975676988793, "train/adv_mag": 0.5154621997544931, "train/adv_max": 0.2501425124878107, "train/adv_mean": 0.007785892410699257, "train/adv_min": -0.4614195630993954, "train/adv_std": 0.03746047507819915, "train/cont_avg": 0.9964707485465116, "train/cont_loss_mean": 0.005007378729385172, "train/cont_loss_std": 0.10885618622875014, "train/cont_neg_acc": 0.7658071986165657, "train/cont_neg_loss": 1.1345787618179741, "train/cont_pos_acc": 0.9999133406683456, "train/cont_pos_loss": 0.0010284666344252697, "train/cont_pred": 0.9963910396708998, "train/cont_rate": 0.9964707485465116, "train/dyn_loss_mean": 1.000001373401908, "train/dyn_loss_std": 4.3933939724770744e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2273458264941393, "train/extr_critic_critic_opt_grad_steps": 31150.0, "train/extr_critic_critic_opt_loss": 7406.555841206396, "train/extr_critic_mag": 0.5323387212531511, "train/extr_critic_max": 0.5323387212531511, "train/extr_critic_mean": 0.5156620653562768, "train/extr_critic_min": 0.49248718550038895, "train/extr_critic_std": 0.00791864990592436, "train/extr_return_normed_mag": 0.5202864411265351, "train/extr_return_normed_max": 0.2871008592982625, "train/extr_return_normed_mean": 0.03655082892679317, "train/extr_return_normed_min": -0.4312686271445696, "train/extr_return_normed_std": 0.03877625779118822, "train/extr_return_rate": 0.5895161382261079, "train/extr_return_raw_mag": 0.7739979720392892, "train/extr_return_raw_max": 0.7739979720392892, "train/extr_return_raw_mean": 0.5234479657439298, "train/extr_return_raw_min": 0.05562848448753357, "train/extr_return_raw_std": 0.03877625772404636, "train/extr_reward_mag": 0.2574781201606573, "train/extr_reward_max": 0.2574781201606573, "train/extr_reward_mean": 0.0025448516454563887, "train/extr_reward_min": 2.834963244061137e-06, "train/extr_reward_std": 0.013209623082941614, "train/image_loss_mean": 0.08458500610187997, "train/image_loss_std": 0.1028512382576632, "train/model_loss_mean": 0.6997689904168595, "train/model_loss_std": 0.1819392632259879, "train/model_opt_grad_norm": 23.900239780337312, "train/model_opt_grad_steps": 31122.12093023256, "train/model_opt_loss": 2683.005496570676, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3837.2093023255816, "train/policy_entropy_mag": 1.2177732473195986, "train/policy_entropy_max": 1.2177732473195986, "train/policy_entropy_mean": 0.10565779687360276, "train/policy_entropy_min": 0.06468720678673234, "train/policy_entropy_std": 0.12987739786852237, "train/policy_logprob_mag": 6.5510798276856885, "train/policy_logprob_max": -0.00860832616426917, "train/policy_logprob_mean": -0.10566465490779212, "train/policy_logprob_min": -6.5510798276856885, "train/policy_logprob_std": 0.6448728134465772, "train/policy_randomness_mag": 0.6258116893990096, "train/policy_randomness_max": 0.6258116893990096, "train/policy_randomness_mean": 0.05429736982251322, "train/policy_randomness_min": 0.03324265000085498, "train/policy_randomness_std": 0.06674378337555154, "train/post_ent_mag": 33.081665251975835, "train/post_ent_max": 33.081665251975835, "train/post_ent_mean": 32.61808118598406, "train/post_ent_min": 32.290623926561935, "train/post_ent_std": 0.15811628373556358, "train/prior_ent_mag": 33.9997233900913, "train/prior_ent_max": 33.9997233900913, "train/prior_ent_mean": 32.369413854909496, "train/prior_ent_min": 30.7919992757398, "train/prior_ent_std": 0.5495035928349162, "train/rep_loss_mean": 1.000001373401908, "train/rep_loss_std": 4.3933939724770744e-05, "train/reward_avg": 0.00029457485916493676, "train/reward_loss_mean": 0.01017576241865754, "train/reward_loss_std": 0.026899314329547938, "train/reward_max_data": 0.07293594231027677, "train/reward_max_pred": 0.05165009387703829, "train/reward_neg_acc": 0.9999318411183912, "train/reward_neg_loss": 0.009749914030002993, "train/reward_pos_acc": 0.6470588235294118, "train/reward_pos_loss": 2.726456182406229, "train/reward_pred": 0.00030627050328739855, "train/reward_rate": 0.00015897529069767443, "train_stats/mean_log_entropy": 0.1109478482428719, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.011700074188411236, "report/cont_loss_std": 0.2505803108215332, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 3.7761192321777344, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0006390978232957423, "report/cont_pred": 0.9984021186828613, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07223065942525864, "report/image_loss_std": 0.10276501625776291, "report/model_loss_mean": 0.6946164965629578, "report/model_loss_std": 0.27422210574150085, "report/post_ent_mag": 32.87987518310547, "report/post_ent_max": 32.87987518310547, "report/post_ent_mean": 32.350852966308594, "report/post_ent_min": 32.01392364501953, "report/post_ent_std": 0.1865805834531784, "report/prior_ent_mag": 34.057334899902344, "report/prior_ent_max": 34.057334899902344, "report/prior_ent_mean": 32.63078308105469, "report/prior_ent_min": 31.39065170288086, "report/prior_ent_std": 0.45013126730918884, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002523444127291441, "report/reward_loss_mean": 0.010685727931559086, "report/reward_loss_std": 0.015776222571730614, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001249551773071289, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010685727000236511, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00022342510055750608, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03847719728946686, "eval/cont_loss_std": 0.6975641846656799, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.90625286102295, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0006678723148070276, "eval/cont_pred": 0.9993399977684021, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25347787141799927, "eval/image_loss_std": 0.14963650703430176, "eval/model_loss_mean": 0.8928736448287964, "eval/model_loss_std": 0.7114986777305603, "eval/post_ent_mag": 32.83073806762695, "eval/post_ent_max": 32.83073806762695, "eval/post_ent_mean": 32.27713394165039, "eval/post_ent_min": 32.0045166015625, "eval/post_ent_std": 0.15396760404109955, "eval/prior_ent_mag": 34.057334899902344, "eval/prior_ent_max": 34.057334899902344, "eval/prior_ent_mean": 32.533843994140625, "eval/prior_ent_min": 31.249759674072266, "eval/prior_ent_std": 0.4104939103126526, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0009185085073113441, "eval/reward_loss_std": 0.0015617675380781293, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0027756690979003906, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009185085073113441, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00014924060087651014, "eval/reward_rate": 0.0, "replay/size": 129969.0, "replay/inserts": 8608.0, "replay/samples": 34432.0, "replay/insert_wait_avg": 1.5318005944716444e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.871164486753897e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33424.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0773178615372073e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1973750591278, "timer/env.step_count": 1076.0, "timer/env.step_total": 10.135707139968872, "timer/env.step_frac": 0.01013370699895077, "timer/env.step_avg": 0.00941980217469226, "timer/env.step_min": 0.008267641067504883, "timer/env.step_max": 0.03472328186035156, "timer/replay._sample_count": 34432.0, "timer/replay._sample_total": 16.798563241958618, "timer/replay._sample_frac": 0.016795248278836515, "timer/replay._sample_avg": 0.00048787648820744126, "timer/replay._sample_min": 0.0003578662872314453, "timer/replay._sample_max": 0.011093854904174805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1365.0, "timer/agent.policy_total": 13.752383708953857, "timer/agent.policy_frac": 0.01374966986705086, "timer/agent.policy_avg": 0.010075006380185976, "timer/agent.policy_min": 0.008669137954711914, "timer/agent.policy_max": 0.08367109298706055, "timer/dataset_train_count": 2152.0, "timer/dataset_train_total": 0.3785693645477295, "timer/dataset_train_frac": 0.0003784946591420018, "timer/dataset_train_avg": 0.00017591513222478138, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.0008983612060546875, "timer/agent.train_count": 2152.0, "timer/agent.train_total": 961.4123690128326, "timer/agent.train_frac": 0.9612226476359205, "timer/agent.train_avg": 0.44675295957845385, "timer/agent.train_min": 0.43077707290649414, "timer/agent.train_max": 0.5888853073120117, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46953344345092773, "timer/agent.report_frac": 0.0004694407875477285, "timer/agent.report_avg": 0.23476672172546387, "timer/agent.report_min": 0.22268438339233398, "timer/agent.report_max": 0.24684906005859375, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.6459239886236414e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 8.606184083142681}
{"step": 130544, "time": 15221.592589855194, "episode/length": 251.0, "episode/score": 0.25311835020121976, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.03749335394397235}
{"step": 130696, "time": 15239.201357364655, "episode/length": 244.0, "episode/score": 0.28436112884480735, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.04686112773595141}
{"step": 131144, "time": 15291.549166679382, "episode/length": 216.0, "episode/score": 0.35114313792854546, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.02614315025692804}
{"step": 131288, "time": 15308.587000370026, "episode/length": 220.0, "episode/score": 0.3640712615770383, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.05157125488315728}
{"step": 131616, "time": 15346.719743013382, "episode/length": 288.0, "episode/score": 0.030819487586967398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030819487586967398}
{"step": 131640, "time": 15349.50033068657, "episode/length": 61.0, "episode/score": 0.8254298407042597, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.016054864703278326}
{"step": 131640, "time": 15349.50740480423, "episode/length": 273.0, "episode/score": 0.21708695029528258, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.07021196149443654}
{"step": 131720, "time": 15358.745621204376, "episode/length": 127.0, "episode/score": 0.6251068006466483, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.02198184462835684}
{"step": 131872, "time": 15376.336949110031, "episode/length": 72.0, "episode/score": 0.8015339567984938, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.026533980858630457}
{"step": 132216, "time": 15416.10182595253, "episode/length": 288.0, "episode/score": 0.0333348585640465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0333348585640465}
{"step": 132568, "time": 15456.782212734222, "episode/length": 288.0, "episode/score": 0.05063580692717551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05063580692717551}
{"step": 132856, "time": 15490.121738910675, "episode/length": 288.0, "episode/score": 0.04804512292210461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04804512292210461}
{"step": 133128, "time": 15521.80131983757, "episode/length": 188.0, "episode/score": 0.4407821769135296, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.028282168176559708}
{"step": 133656, "time": 15583.395200490952, "episode/length": 241.0, "episode/score": 0.27420415657510944, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.02732914950578902}
{"step": 133952, "time": 15618.007174491882, "episode/length": 288.0, "episode/score": 0.03764502106474765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03764502106474765}
{"step": 133952, "time": 15618.016613721848, "episode/length": 288.0, "episode/score": 0.02835757741110001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02835757741110001}
{"step": 134184, "time": 15645.10353255272, "episode/length": 288.0, "episode/score": 0.030418603409458456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030418603409458456}
{"step": 134528, "time": 15685.002690792084, "episode/length": 288.0, "episode/score": 0.03253433864598776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03253433864598776}
{"step": 134880, "time": 15725.744269609451, "episode/length": 288.0, "episode/score": 0.03454424154237756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03454424154237756}
{"step": 135168, "time": 15759.097111940384, "episode/length": 288.0, "episode/score": 0.04671645757657927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04671645757657927}
{"step": 135440, "time": 15790.779568910599, "episode/length": 288.0, "episode/score": 0.0395578970809396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0395578970809396}
{"step": 135840, "time": 15836.986516952515, "episode/length": 163.0, "episode/score": 0.5182314695861407, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.02760646885272422}
{"step": 135968, "time": 15851.821469068527, "episode/length": 288.0, "episode/score": 0.037520819420720386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037520819420720386}
{"step": 136248, "time": 15884.193306922913, "episode/length": 170.0, "episode/score": 0.48865090919957765, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.01990092335859117}
{"step": 136264, "time": 15886.042518138885, "episode/length": 288.0, "episode/score": 0.034096596423154324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034096596423154324}
{"step": 136264, "time": 15886.050355911255, "episode/length": 288.0, "episode/score": 0.019650627677506805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019650627677506805}
{"step": 136496, "time": 15912.8976624012, "episode/length": 288.0, "episode/score": 0.0336731055296724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0336731055296724}
{"step": 136744, "time": 15941.68014550209, "episode/length": 96.0, "episode/score": 0.7112943854382792, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.011294367964339358}
{"step": 137256, "time": 16001.120642900467, "episode/length": 94.0, "episode/score": 0.7115326817979053, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.005282696099527584}
{"step": 137480, "time": 16027.059591054916, "episode/length": 288.0, "episode/score": 0.02414692810850738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02414692810850738}
{"step": 137752, "time": 16058.580300569534, "episode/length": 288.0, "episode/score": 0.034424712455830786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034424712455830786}
{"step": 138152, "time": 16104.7584502697, "episode/length": 288.0, "episode/score": 0.037329437726143055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037329437726143055}
{"step": 138560, "time": 16152.100578546524, "episode/length": 288.0, "episode/score": 0.037376020655642606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037376020655642606}
{"step": 138576, "time": 16153.94240784645, "episode/length": 288.0, "episode/score": 0.022928111819922492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022928111819922492}
{"step": 138576, "time": 16153.949398517609, "episode/length": 288.0, "episode/score": 0.018856036653829733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018856036653829733}
{"step": 138936, "time": 16195.638132333755, "episode/length": 46.0, "episode/score": 0.862672127866901, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.006422148853673093}
{"step": 139056, "time": 16209.585646390915, "episode/length": 288.0, "episode/score": 0.020736849391880696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020736849391880696}
{"step": 139085, "time": 16213.82502412796, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9311709933810763, "train/action_min": 0.0, "train/action_std": 1.5542065545364663, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004657406773832109, "train/actor_opt_grad_steps": 33305.0, "train/actor_opt_loss": -5.661134216865456, "train/adv_mag": 0.4587676974910277, "train/adv_max": 0.16416333326035076, "train/adv_mean": -0.0018005075089183298, "train/adv_min": -0.44412018317315316, "train/adv_std": 0.01691972826396253, "train/cont_avg": 0.9964237919560185, "train/cont_loss_mean": 0.0059927917979991805, "train/cont_loss_std": 0.12058528978566217, "train/cont_neg_acc": 0.7067553095310648, "train/cont_neg_loss": 1.2978229430857333, "train/cont_pos_acc": 0.9998819828033447, "train/cont_pos_loss": 0.0011958710009046761, "train/cont_pred": 0.99645163146434, "train/cont_rate": 0.9964237919560185, "train/dyn_loss_mean": 1.0000053070209645, "train/dyn_loss_std": 0.00013707564438744966, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.23761761405815682, "train/extr_critic_critic_opt_grad_steps": 33305.0, "train/extr_critic_critic_opt_loss": 12167.292367440683, "train/extr_critic_mag": 0.5831926851360886, "train/extr_critic_max": 0.5831926851360886, "train/extr_critic_mean": 0.5251005701720715, "train/extr_critic_min": 0.5040165031397784, "train/extr_critic_std": 0.007131298053233574, "train/extr_return_normed_mag": 0.45313676060349856, "train/extr_return_normed_max": 0.19914950099256304, "train/extr_return_normed_mean": 0.009066697963758256, "train/extr_return_normed_min": -0.4254328005567745, "train/extr_return_normed_std": 0.018393696619939334, "train/extr_return_rate": 0.9141397055462692, "train/extr_return_raw_mag": 0.7133828669234559, "train/extr_return_raw_max": 0.7133828669234559, "train/extr_return_raw_mean": 0.5233000907357093, "train/extr_return_raw_min": 0.08880056551209202, "train/extr_return_raw_std": 0.018393696617783496, "train/extr_reward_mag": 0.20860808425479466, "train/extr_reward_max": 0.20860808425479466, "train/extr_reward_mean": 0.0007542356027746185, "train/extr_reward_min": 2.023798448068124e-06, "train/extr_reward_std": 0.00483736058649137, "train/image_loss_mean": 0.08183607726392371, "train/image_loss_std": 0.10174750022728134, "train/model_loss_mean": 0.6987597776783837, "train/model_loss_std": 0.2057477878406644, "train/model_opt_grad_norm": 23.138157537050336, "train/model_opt_grad_steps": 33275.273148148146, "train/model_opt_loss": 3034.4303102846497, "train/model_opt_model_opt_grad_overflow": 0.009259259259259259, "train/model_opt_model_opt_grad_scale": 4305.555555555556, "train/policy_entropy_mag": 1.2355456423980218, "train/policy_entropy_max": 1.2355456423980218, "train/policy_entropy_mean": 0.12839826534467716, "train/policy_entropy_min": 0.0646866538596374, "train/policy_entropy_std": 0.16143635322374325, "train/policy_logprob_mag": 6.551080065744895, "train/policy_logprob_max": -0.00860814788137321, "train/policy_logprob_mean": -0.12808325293439407, "train/policy_logprob_min": -6.551080065744895, "train/policy_logprob_std": 0.661786937603244, "train/policy_randomness_mag": 0.634944895627322, "train/policy_randomness_max": 0.634944895627322, "train/policy_randomness_mean": 0.06598365989824136, "train/policy_randomness_min": 0.03324236613870771, "train/policy_randomness_std": 0.08296188005004768, "train/post_ent_mag": 33.17811837019744, "train/post_ent_max": 33.17811837019744, "train/post_ent_mean": 32.716244573946355, "train/post_ent_min": 32.36746619365834, "train/post_ent_std": 0.1558768224247076, "train/prior_ent_mag": 33.78841073424728, "train/prior_ent_max": 33.78841073424728, "train/prior_ent_mean": 32.37697782339873, "train/prior_ent_min": 31.16051326857673, "train/prior_ent_std": 0.43803265042327066, "train/rep_loss_mean": 1.0000053070209645, "train/rep_loss_std": 0.00013707564438744966, "train/reward_avg": 0.00036549248552883337, "train/reward_loss_mean": 0.010927702985807426, "train/reward_loss_std": 0.049454749346262324, "train/reward_max_data": 0.13487100881563188, "train/reward_max_pred": 0.07063857383198208, "train/reward_neg_acc": 0.9999502408835623, "train/reward_neg_loss": 0.009655779482003439, "train/reward_pos_acc": 0.43283582134033316, "train/reward_pos_loss": 3.5768272463065474, "train/reward_pred": 0.00033454398820780354, "train/reward_rate": 0.00035264756944444444, "train_stats/mean_log_entropy": 0.12576851349424673, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.008450064808130264, "report/cont_loss_std": 0.16014355421066284, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.8358348608016968, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0012838508700951934, "report/cont_pred": 0.996901273727417, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06830677390098572, "report/image_loss_std": 0.0973358154296875, "report/model_loss_mean": 0.6852743625640869, "report/model_loss_std": 0.1896427869796753, "report/post_ent_mag": 33.35417556762695, "report/post_ent_max": 33.35417556762695, "report/post_ent_mean": 32.92903518676758, "report/post_ent_min": 32.5813102722168, "report/post_ent_std": 0.15995700657367706, "report/prior_ent_mag": 33.41838073730469, "report/prior_ent_max": 33.41838073730469, "report/prior_ent_mean": 32.122535705566406, "report/prior_ent_min": 30.9426326751709, "report/prior_ent_std": 0.4310856759548187, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001945415569934994, "report/reward_loss_mean": 0.00851751770824194, "report/reward_loss_std": 0.014031510800123215, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.012627482414245605, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00851751770824194, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00023523136042058468, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.027925055474042892, "eval/cont_loss_std": 0.512908399105072, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.769796371459961, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0022388522047549486, "eval/cont_pred": 0.9978020191192627, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23522008955478668, "eval/image_loss_std": 0.14621809124946594, "eval/model_loss_mean": 0.8640093803405762, "eval/model_loss_std": 0.5345147848129272, "eval/post_ent_mag": 33.392906188964844, "eval/post_ent_max": 33.392906188964844, "eval/post_ent_mean": 32.84950256347656, "eval/post_ent_min": 32.61070251464844, "eval/post_ent_std": 0.13012813031673431, "eval/prior_ent_mag": 33.32149124145508, "eval/prior_ent_max": 33.32149124145508, "eval/prior_ent_mean": 32.0079345703125, "eval/prior_ent_min": 31.15691375732422, "eval/prior_ent_std": 0.3743061125278473, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0008642645552754402, "eval/reward_loss_std": 0.0019576167687773705, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.012418627738952637, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0008642645552754402, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00017115729860961437, "eval/reward_rate": 0.0, "replay/size": 138581.0, "replay/inserts": 8612.0, "replay/samples": 34448.0, "replay/insert_wait_avg": 1.5346881017760239e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.748465398495219e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33424.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2574019432068, "timer/env.step_count": 1076.0, "timer/env.step_total": 10.162063837051392, "timer/env.step_frac": 0.010159448775194747, "timer/env.step_avg": 0.00944429724633029, "timer/env.step_min": 0.008374452590942383, "timer/env.step_max": 0.0288393497467041, "timer/replay._sample_count": 34448.0, "timer/replay._sample_total": 17.146405458450317, "timer/replay._sample_frac": 0.017141993076122086, "timer/replay._sample_avg": 0.0004977474877627241, "timer/replay._sample_min": 0.00035071372985839844, "timer/replay._sample_max": 0.020435094833374023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1076.0, "timer/agent.policy_total": 10.777940034866333, "timer/agent.policy_frac": 0.01077516648607444, "timer/agent.policy_avg": 0.010016672894857187, "timer/agent.policy_min": 0.008991003036499023, "timer/agent.policy_max": 0.04770302772521973, "timer/dataset_train_count": 2153.0, "timer/dataset_train_total": 0.3863670825958252, "timer/dataset_train_frac": 0.0003862676565504312, "timer/dataset_train_avg": 0.00017945521718338374, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.0012142658233642578, "timer/agent.train_count": 2153.0, "timer/agent.train_total": 966.8525359630585, "timer/agent.train_frac": 0.9666037302845722, "timer/agent.train_avg": 0.4490722415062975, "timer/agent.train_min": 0.4355466365814209, "timer/agent.train_max": 0.6080150604248047, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48179173469543457, "timer/agent.report_frac": 0.00048166775247996616, "timer/agent.report_avg": 0.24089586734771729, "timer/agent.report_min": 0.2346959114074707, "timer/agent.report_max": 0.24709582328796387, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.814697265625e-05, "timer/dataset_eval_frac": 3.81371560781671e-08, "timer/dataset_eval_avg": 3.814697265625e-05, "timer/dataset_eval_min": 3.814697265625e-05, "timer/dataset_eval_max": 3.814697265625e-05, "fps": 8.609662247897159}
{"step": 139184, "time": 16225.083178043365, "episode/length": 15.0, "episode/score": 0.959187717231103, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.006062687836234204}
{"step": 139568, "time": 16269.960930347443, "episode/length": 288.0, "episode/score": 0.015520849145588045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015520849145588045}
{"step": 139576, "time": 16270.883677721024, "episode/length": 177.0, "episode/score": 0.45816509295961794, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.011290087108292823}
{"step": 139792, "time": 16295.875984430313, "episode/length": 288.0, "episode/score": 0.023579038572222544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023579038572222544}
{"step": 140064, "time": 16327.380146741867, "episode/length": 288.0, "episode/score": 0.023986162862456695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023986162862456695}
{"step": 140088, "time": 16331.111824274063, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 140088, "time": 16331.490020751953, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 140088, "time": 16332.141850471497, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 140088, "time": 16335.393926858902, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 16335.402416229248, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 16335.408304452896, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 16335.414021968842, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 16335.41996216774, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140296, "time": 16359.47787117958, "episode/length": 90.0, "episode/score": 0.7317921497210733, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.013042121606773094}
{"step": 140312, "time": 16361.316551208496, "episode/length": 64.0, "episode/score": 0.8080834294993764, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.008083434720603577}
{"step": 140576, "time": 16391.907065153122, "episode/length": 249.0, "episode/score": 0.23194651064375194, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.010071506464441882}
{"step": 140888, "time": 16428.20495057106, "episode/length": 288.0, "episode/score": 0.038434314298740446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038434314298740446}
{"step": 141104, "time": 16453.240621566772, "episode/length": 129.0, "episode/score": 0.6049171307630274, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.008042138981949165}
{"step": 141248, "time": 16469.893822431564, "episode/length": 288.0, "episode/score": 0.03544317139783004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03544317139783004}
{"step": 141496, "time": 16498.827505350113, "episode/length": 288.0, "episode/score": 0.036245888594407916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036245888594407916}
{"step": 141888, "time": 16544.38827443123, "episode/length": 288.0, "episode/score": 0.03172445592839779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03172445592839779}
{"step": 142392, "time": 16602.966985464096, "episode/length": 160.0, "episode/score": 0.5330214617844007, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.03302148192425136}
{"step": 142608, "time": 16627.982745409012, "episode/length": 288.0, "episode/score": 0.03318469770320576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03318469770320576}
{"step": 142624, "time": 16629.840126514435, "episode/length": 288.0, "episode/score": 0.0521292874792465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0521292874792465}
{"step": 142888, "time": 16660.46271967888, "episode/length": 288.0, "episode/score": 0.03815276964873249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03815276964873249}
{"step": 143200, "time": 16696.500641345978, "episode/length": 288.0, "episode/score": 0.05328848493321914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05328848493321914}
{"step": 143560, "time": 16738.19818854332, "episode/length": 288.0, "episode/score": 0.04980129108986375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04980129108986375}
{"step": 143808, "time": 16766.77450299263, "episode/length": 288.0, "episode/score": 0.03438019761611599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03438019761611599}
{"step": 144200, "time": 16811.974959611893, "episode/length": 288.0, "episode/score": 0.06831882549253976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06831882549253976}
{"step": 144704, "time": 16870.079454421997, "episode/length": 288.0, "episode/score": 0.04933977577199755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04933977577199755}
{"step": 144920, "time": 16895.05064201355, "episode/length": 288.0, "episode/score": 0.059543037335757276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059543037335757276}
{"step": 144936, "time": 16896.900800704956, "episode/length": 288.0, "episode/score": 0.04309334934193032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04309334934193032}
{"step": 145200, "time": 16927.421035289764, "episode/length": 288.0, "episode/score": 0.05942426520289246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05942426520289246}
{"step": 145512, "time": 16963.701464653015, "episode/length": 288.0, "episode/score": 0.07824768101289692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07824768101289692}
{"step": 145872, "time": 17005.32300400734, "episode/length": 288.0, "episode/score": 0.021087323260871926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021087323260871926}
{"step": 146120, "time": 17034.255254983902, "episode/length": 288.0, "episode/score": 0.05945861141118769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05945861141118769}
{"step": 146512, "time": 17079.423756599426, "episode/length": 288.0, "episode/score": 0.038042676701579126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038042676701579126}
{"step": 147016, "time": 17137.615953207016, "episode/length": 288.0, "episode/score": 0.06713271377695662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06713271377695662}
{"step": 147232, "time": 17162.469595193863, "episode/length": 288.0, "episode/score": 0.0687826562556495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0687826562556495}
{"step": 147248, "time": 17164.321310043335, "episode/length": 288.0, "episode/score": 0.04655028120673421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04655028120673421}
{"step": 147512, "time": 17195.155615329742, "episode/length": 288.0, "episode/score": 0.050905406803863684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050905406803863684}
{"step": 147665, "time": 17213.835324287415, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4469245126314254, "train/action_min": 0.0, "train/action_std": 1.6695582281763308, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005192406792150131, "train/actor_opt_grad_steps": 35455.0, "train/actor_opt_loss": -7.361716831398901, "train/adv_mag": 0.42329796549872817, "train/adv_max": 0.18447537441677023, "train/adv_mean": -0.0008925443480918241, "train/adv_min": -0.3952338106442835, "train/adv_std": 0.017716630301046594, "train/cont_avg": 0.9964770735981309, "train/cont_loss_mean": 0.00563956424512326, "train/cont_loss_std": 0.11285683578946497, "train/cont_neg_acc": 0.7336864964813707, "train/cont_neg_loss": 1.1802231087075201, "train/cont_pos_acc": 0.9999084726115254, "train/cont_pos_loss": 0.0012134978556940245, "train/cont_pred": 0.9964001755291056, "train/cont_rate": 0.9964770735981309, "train/dyn_loss_mean": 1.0000778553641845, "train/dyn_loss_std": 0.0004510290252689297, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.25278686715081056, "train/extr_critic_critic_opt_grad_steps": 35455.0, "train/extr_critic_critic_opt_loss": 12421.75658495181, "train/extr_critic_mag": 0.5637469676053413, "train/extr_critic_max": 0.5637469676053413, "train/extr_critic_mean": 0.5176186518412884, "train/extr_critic_min": 0.49707469594812836, "train/extr_critic_std": 0.008479646694298102, "train/extr_return_normed_mag": 0.42779622387106175, "train/extr_return_normed_max": 0.22156028003893166, "train/extr_return_normed_mean": 0.013016358817086793, "train/extr_return_normed_min": -0.37283425214134647, "train/extr_return_normed_std": 0.020127729974060416, "train/extr_return_rate": 0.6554696946142395, "train/extr_return_raw_mag": 0.7252699628333065, "train/extr_return_raw_max": 0.7252699628333065, "train/extr_return_raw_mean": 0.5167260635121961, "train/extr_return_raw_min": 0.1308754305137652, "train/extr_return_raw_std": 0.020127730039340035, "train/extr_reward_mag": 0.22970374165294327, "train/extr_reward_max": 0.22970374165294327, "train/extr_reward_mean": 0.000878345912157027, "train/extr_reward_min": 1.3993165203344043e-06, "train/extr_reward_std": 0.005713072209809385, "train/image_loss_mean": 0.08217569592051974, "train/image_loss_std": 0.10304891822911869, "train/model_loss_mean": 0.698430446542312, "train/model_loss_std": 0.19626477708883375, "train/model_opt_grad_norm": 22.833892666290854, "train/model_opt_grad_steps": 35422.911214953274, "train/model_opt_loss": 1862.6789480904552, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2675.233644859813, "train/policy_entropy_mag": 1.410840584852985, "train/policy_entropy_max": 1.410840584852985, "train/policy_entropy_mean": 0.1627848139641998, "train/policy_entropy_min": 0.06468695283771675, "train/policy_entropy_std": 0.19958724833537486, "train/policy_logprob_mag": 6.551079830276632, "train/policy_logprob_max": -0.008608221472458584, "train/policy_logprob_mean": -0.16277926909589321, "train/policy_logprob_min": -6.551079830276632, "train/policy_logprob_std": 0.6983314886271397, "train/policy_randomness_mag": 0.7250286828134661, "train/policy_randomness_max": 0.7250286828134661, "train/policy_randomness_mean": 0.08365485072135925, "train/policy_randomness_min": 0.03324251963156406, "train/policy_randomness_std": 0.10256756215452034, "train/post_ent_mag": 33.75390539436697, "train/post_ent_max": 33.75390539436697, "train/post_ent_mean": 33.361186009701164, "train/post_ent_min": 33.03662941834637, "train/post_ent_std": 0.13686783434213878, "train/prior_ent_mag": 33.90527213622477, "train/prior_ent_max": 33.90527213622477, "train/prior_ent_mean": 32.70457745489673, "train/prior_ent_min": 31.67142415269513, "train/prior_ent_std": 0.35932711762524094, "train/rep_loss_mean": 1.0000778553641845, "train/rep_loss_std": 0.0004510290252689297, "train/reward_avg": 0.0003655294390100437, "train/reward_loss_mean": 0.010568454548298755, "train/reward_loss_std": 0.04235362787687472, "train/reward_max_data": 0.1378813754869451, "train/reward_max_pred": 0.07426634681559055, "train/reward_neg_acc": 0.9999543484126296, "train/reward_neg_loss": 0.009568019728742052, "train/reward_pos_acc": 0.5000000004730527, "train/reward_pos_loss": 3.0564852002121152, "train/reward_pred": 0.00034720913744226933, "train/reward_rate": 0.0003331264602803738, "train_stats/mean_log_entropy": 0.14605366122542005, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01469765231013298, "report/cont_loss_std": 0.26913025975227356, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.2622103691101074, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0019623078405857086, "report/cont_pred": 0.9967374801635742, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0790719985961914, "report/image_loss_std": 0.10292297601699829, "report/model_loss_mean": 0.7060438990592957, "report/model_loss_std": 0.3049991726875305, "report/post_ent_mag": 34.70158386230469, "report/post_ent_max": 34.70158386230469, "report/post_ent_mean": 34.47071838378906, "report/post_ent_min": 34.22878646850586, "report/post_ent_std": 0.08173277229070663, "report/prior_ent_mag": 34.442481994628906, "report/prior_ent_max": 34.442481994628906, "report/prior_ent_mean": 33.50178909301758, "report/prior_ent_min": 32.58885192871094, "report/prior_ent_std": 0.33150798082351685, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008184266043826938, "report/reward_loss_mean": 0.012274244800209999, "report/reward_loss_std": 0.05183178931474686, "report/reward_max_data": 0.5971527695655823, "report/reward_max_pred": 0.1961061954498291, "report/reward_neg_acc": 0.9980449676513672, "report/reward_neg_loss": 0.010751260444521904, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 1.570287823677063, "report/reward_pred": 0.0008406464476138353, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.06408404558897018, "eval/cont_loss_std": 0.74698406457901, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.918841361999512, "eval/cont_pos_acc": 0.9970559477806091, "eval/cont_pos_loss": 0.01572900451719761, "eval/cont_pred": 0.9962366223335266, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2883572578430176, "eval/image_loss_std": 0.15256741642951965, "eval/model_loss_mean": 0.9539260268211365, "eval/model_loss_std": 0.7575196623802185, "eval/post_ent_mag": 34.70064926147461, "eval/post_ent_max": 34.70064926147461, "eval/post_ent_mean": 34.439300537109375, "eval/post_ent_min": 34.234336853027344, "eval/post_ent_std": 0.09150004386901855, "eval/prior_ent_mag": 34.42364501953125, "eval/prior_ent_max": 34.42364501953125, "eval/prior_ent_mean": 33.45396423339844, "eval/prior_ent_min": 32.460872650146484, "eval/prior_ent_std": 0.3530615270137787, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014847447164356709, "eval/reward_loss_std": 0.0021049443166702986, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.006553173065185547, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014847447164356709, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00025047571398317814, "eval/reward_rate": 0.0, "replay/size": 147161.0, "replay/inserts": 8580.0, "replay/samples": 34320.0, "replay/insert_wait_avg": 1.5412732993528282e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.714424933586921e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 35736.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1111419506138996e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9990365505219, "timer/env.step_count": 1073.0, "timer/env.step_total": 10.214362621307373, "timer/env.step_frac": 0.010214372462339192, "timer/env.step_avg": 0.009519443263101, "timer/env.step_min": 0.008350849151611328, "timer/env.step_max": 0.034793853759765625, "timer/replay._sample_count": 34320.0, "timer/replay._sample_total": 16.91664958000183, "timer/replay._sample_frac": 0.016916665878354744, "timer/replay._sample_avg": 0.0004929093700466734, "timer/replay._sample_min": 0.00036454200744628906, "timer/replay._sample_max": 0.026168107986450195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1362.0, "timer/agent.policy_total": 13.506253004074097, "timer/agent.policy_frac": 0.013506266016679043, "timer/agent.policy_avg": 0.009916485318703448, "timer/agent.policy_min": 0.008894920349121094, "timer/agent.policy_max": 0.034410953521728516, "timer/dataset_train_count": 2145.0, "timer/dataset_train_total": 0.3885304927825928, "timer/dataset_train_frac": 0.00038853086711245394, "timer/dataset_train_avg": 0.00018113309686834162, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0053293704986572266, "timer/agent.train_count": 2145.0, "timer/agent.train_total": 961.256174325943, "timer/agent.train_frac": 0.9612571004485948, "timer/agent.train_avg": 0.44813807660883126, "timer/agent.train_min": 0.432783842086792, "timer/agent.train_max": 0.572883129119873, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4746079444885254, "timer/agent.report_frac": 0.00047460840174974237, "timer/agent.report_avg": 0.2373039722442627, "timer/agent.report_min": 0.23199176788330078, "timer/agent.report_max": 0.2426161766052246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7418163012694532e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 8.579892296812696}
{"step": 147824, "time": 17232.025155067444, "episode/length": 288.0, "episode/score": 0.04969719993567878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04969719993567878}
{"step": 148184, "time": 17273.546541929245, "episode/length": 288.0, "episode/score": 0.055594079615957526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055594079615957526}
{"step": 148432, "time": 17302.17960214615, "episode/length": 288.0, "episode/score": 0.04554717997554292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04554717997554292}
{"step": 148824, "time": 17347.496574163437, "episode/length": 288.0, "episode/score": 0.05288707403673243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05288707403673243}
{"step": 149328, "time": 17405.35186123848, "episode/length": 288.0, "episode/score": 0.04135643953223678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04135643953223678}
{"step": 149544, "time": 17430.141027212143, "episode/length": 288.0, "episode/score": 0.04640796930399915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04640796930399915}
{"step": 149560, "time": 17432.06602215767, "episode/length": 288.0, "episode/score": 0.03911240353406242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03911240353406242}
{"step": 149824, "time": 17462.43753170967, "episode/length": 288.0, "episode/score": 0.044438779918010596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044438779918010596}
{"step": 150072, "time": 17496.0813100338, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 17496.088743925095, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 17496.094186782837, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 17496.09954881668, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 17496.10477399826, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 17496.110062360764, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 17496.115362644196, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 17496.120663404465, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150136, "time": 17503.48051595688, "episode/length": 288.0, "episode/score": 0.06264925018155054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06264925018155054}
{"step": 150496, "time": 17544.896334171295, "episode/length": 288.0, "episode/score": 0.06522132723985408, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06522132723985408}
{"step": 150744, "time": 17573.530626296997, "episode/length": 288.0, "episode/score": 0.0286461433799019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0286461433799019}
{"step": 151136, "time": 17618.999895572662, "episode/length": 288.0, "episode/score": 0.04544666550077636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04544666550077636}
{"step": 151640, "time": 17677.156603336334, "episode/length": 288.0, "episode/score": 0.037966134004875585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037966134004875585}
{"step": 151856, "time": 17702.117330551147, "episode/length": 288.0, "episode/score": 0.04199556334808108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04199556334808108}
{"step": 151872, "time": 17703.94872021675, "episode/length": 288.0, "episode/score": 0.05554675946373777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05554675946373777}
{"step": 152136, "time": 17734.34236931801, "episode/length": 288.0, "episode/score": 0.03591359479182188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03591359479182188}
{"step": 152448, "time": 17770.371377706528, "episode/length": 288.0, "episode/score": 0.060617685227910556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060617685227910556}
{"step": 152808, "time": 17811.84145975113, "episode/length": 288.0, "episode/score": 0.03231977654637319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03231977654637319}
{"step": 153056, "time": 17840.6282453537, "episode/length": 288.0, "episode/score": 0.07345142152082929, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07345142152082929}
{"step": 153448, "time": 17885.821353435516, "episode/length": 288.0, "episode/score": 0.05506402524224541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05506402524224541}
{"step": 153952, "time": 17944.431616783142, "episode/length": 288.0, "episode/score": 0.07148917878907923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07148917878907923}
{"step": 154168, "time": 17969.267635822296, "episode/length": 288.0, "episode/score": 0.08434504821320843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08434504821320843}
{"step": 154184, "time": 17971.122757911682, "episode/length": 288.0, "episode/score": 0.05690325760588166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05690325760588166}
{"step": 154448, "time": 18001.562309503555, "episode/length": 288.0, "episode/score": 0.09857042978774189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09857042978774189}
{"step": 154760, "time": 18037.47817349434, "episode/length": 288.0, "episode/score": 0.05385194702125773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05385194702125773}
{"step": 155120, "time": 18079.118638038635, "episode/length": 288.0, "episode/score": 0.05884036231441314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05884036231441314}
{"step": 155368, "time": 18107.719440221786, "episode/length": 288.0, "episode/score": 0.06243195158549497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06243195158549497}
{"step": 155760, "time": 18153.4034781456, "episode/length": 288.0, "episode/score": 0.05202447506007957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05202447506007957}
{"step": 156264, "time": 18211.795572519302, "episode/length": 288.0, "episode/score": 0.039464185004931096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039464185004931096}
{"step": 156277, "time": 18214.203614234924, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4278366654007524, "train/action_min": 0.0, "train/action_std": 2.1217804898818335, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.001971187182115736, "train/actor_opt_grad_steps": 37605.0, "train/actor_opt_loss": -8.989926386762548, "train/adv_mag": 0.27801554677663026, "train/adv_max": 0.04831550615253272, "train/adv_mean": -0.00288659859506879, "train/adv_min": -0.2605633314836908, "train/adv_std": 0.005072667939303856, "train/cont_avg": 0.9961434823495371, "train/cont_loss_mean": 0.007024481494159705, "train/cont_loss_std": 0.14042167222996121, "train/cont_neg_acc": 0.661633451802786, "train/cont_neg_loss": 1.523040026055106, "train/cont_pos_acc": 0.9999137537346946, "train/cont_pos_loss": 0.001255149897689181, "train/cont_pred": 0.9962906070329525, "train/cont_rate": 0.9961434823495371, "train/dyn_loss_mean": 1.000000767133854, "train/dyn_loss_std": 2.4534968462022436e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0662957641546166, "train/extr_critic_critic_opt_grad_steps": 37605.0, "train/extr_critic_critic_opt_loss": 7866.337901362666, "train/extr_critic_mag": 0.4117318171041983, "train/extr_critic_max": 0.4117318171041983, "train/extr_critic_mean": 0.39597197704845005, "train/extr_critic_min": 0.3863500820265876, "train/extr_critic_std": 0.003225253801685068, "train/extr_return_normed_mag": 0.2783056865963671, "train/extr_return_normed_max": 0.054147287651344585, "train/extr_return_normed_mean": -6.038200476891857e-05, "train/extr_return_normed_min": -0.25789558583939515, "train/extr_return_normed_std": 0.006270006565265013, "train/extr_return_rate": 1.929012449653345e-05, "train/extr_return_raw_mag": 0.44729302520001374, "train/extr_return_raw_max": 0.44729302520001374, "train/extr_return_raw_mean": 0.3930853737725152, "train/extr_return_raw_min": 0.1352501515713003, "train/extr_return_raw_std": 0.0062700065555637355, "train/extr_reward_mag": 0.07800548992775104, "train/extr_reward_max": 0.07800548992775104, "train/extr_reward_mean": 0.00029522889013201673, "train/extr_reward_min": 1.1435261479130499e-06, "train/extr_reward_std": 0.0009096446353430145, "train/image_loss_mean": 0.08406925789528975, "train/image_loss_std": 0.10542595993589472, "train/model_loss_mean": 0.7016273196096774, "train/model_loss_std": 0.21953218575153086, "train/model_opt_grad_norm": 22.577040670094668, "train/model_opt_grad_steps": 37571.0, "train/model_opt_loss": 1056.8557147273311, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1504.6296296296296, "train/policy_entropy_mag": 1.4942620435246714, "train/policy_entropy_max": 1.4942620435246714, "train/policy_entropy_mean": 0.24825584377955506, "train/policy_entropy_min": 0.06469946095926894, "train/policy_entropy_std": 0.25629365292412265, "train/policy_logprob_mag": 6.5510770523989645, "train/policy_logprob_max": -0.008610275086808812, "train/policy_logprob_mean": -0.2487769403529388, "train/policy_logprob_min": -6.5510770523989645, "train/policy_logprob_std": 0.7610930433427846, "train/policy_randomness_mag": 0.7678988341380049, "train/policy_randomness_max": 0.7678988341380049, "train/policy_randomness_mean": 0.1275782746228355, "train/policy_randomness_min": 0.033248947743602375, "train/policy_randomness_std": 0.1317088909930101, "train/post_ent_mag": 34.64859950100934, "train/post_ent_max": 34.64859950100934, "train/post_ent_mean": 34.40000119032683, "train/post_ent_min": 34.15644016972295, "train/post_ent_std": 0.09027956436491674, "train/prior_ent_mag": 34.882340855068634, "train/prior_ent_max": 34.882340855068634, "train/prior_ent_mean": 33.587595268532084, "train/prior_ent_min": 32.49070829815335, "train/prior_ent_std": 0.32642026990652084, "train/rep_loss_mean": 1.000000767133854, "train/rep_loss_std": 2.4534968462022436e-05, "train/reward_avg": 0.0003896122421725455, "train/reward_loss_mean": 0.010533097652821906, "train/reward_loss_std": 0.04440458823875007, "train/reward_max_data": 0.15797669389737873, "train/reward_max_pred": 0.09431198294515963, "train/reward_neg_acc": 0.9999457288671423, "train/reward_neg_loss": 0.009418676100688538, "train/reward_pos_acc": 0.47761194029850745, "train/reward_pos_loss": 3.148317579458009, "train/reward_pred": 0.00035621099232230335, "train/reward_rate": 0.00035716869212962964, "train_stats/mean_log_entropy": 0.1878128837922524, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00482447724789381, "report/cont_loss_std": 0.09187143296003342, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 0.8552510738372803, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0014894709456712008, "report/cont_pred": 0.995983898639679, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08458680659532547, "report/image_loss_std": 0.109972283244133, "report/model_loss_mean": 0.6972757577896118, "report/model_loss_std": 0.14953942596912384, "report/post_ent_mag": 34.58416748046875, "report/post_ent_max": 34.58416748046875, "report/post_ent_mean": 34.32210922241211, "report/post_ent_min": 34.03764724731445, "report/post_ent_std": 0.09416471421718597, "report/prior_ent_mag": 34.89007568359375, "report/prior_ent_max": 34.89007568359375, "report/prior_ent_mean": 33.651512145996094, "report/prior_ent_min": 32.527442932128906, "report/prior_ent_std": 0.30707496404647827, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001773155527189374, "report/reward_loss_mean": 0.007864496670663357, "report/reward_loss_std": 0.012435941025614738, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.004452943801879883, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007864496670663357, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00016685901209712029, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.026223910972476006, "eval/cont_loss_std": 0.5701442360877991, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.882816314697266, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0010642418637871742, "eval/cont_pred": 0.9991037845611572, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20428411662578583, "eval/image_loss_std": 0.15136542916297913, "eval/model_loss_mean": 0.8315894603729248, "eval/model_loss_std": 0.5962164402008057, "eval/post_ent_mag": 34.5937614440918, "eval/post_ent_max": 34.5937614440918, "eval/post_ent_mean": 34.320274353027344, "eval/post_ent_min": 34.0450325012207, "eval/post_ent_std": 0.0995267778635025, "eval/prior_ent_mag": 35.00940704345703, "eval/prior_ent_max": 35.00940704345703, "eval/prior_ent_mean": 33.70151901245117, "eval/prior_ent_min": 32.499149322509766, "eval/prior_ent_std": 0.3147437274456024, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0010814056731760502, "eval/reward_loss_std": 0.0013343464815989137, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0010733604431152344, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010814056731760502, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0001721191219985485, "eval/reward_rate": 0.0, "replay/size": 155773.0, "replay/inserts": 8612.0, "replay/samples": 34448.0, "replay/insert_wait_avg": 1.5329439807259312e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.700017591548199e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38048.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0719555059518782e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3559341430664, "timer/env.step_count": 1076.0, "timer/env.step_total": 10.138384103775024, "timer/env.step_frac": 0.010134776790682863, "timer/env.step_avg": 0.009422290059270469, "timer/env.step_min": 0.008339881896972656, "timer/env.step_max": 0.03729581832885742, "timer/replay._sample_count": 34448.0, "timer/replay._sample_total": 16.77405309677124, "timer/replay._sample_frac": 0.016768084762890295, "timer/replay._sample_avg": 0.0004869383736870425, "timer/replay._sample_min": 0.0003495216369628906, "timer/replay._sample_max": 0.010704278945922852, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1365.0, "timer/agent.policy_total": 13.264808416366577, "timer/agent.policy_frac": 0.013260088698058848, "timer/agent.policy_avg": 0.009717808363638518, "timer/agent.policy_min": 0.008671760559082031, "timer/agent.policy_max": 0.035295724868774414, "timer/dataset_train_count": 2153.0, "timer/dataset_train_total": 0.38186144828796387, "timer/dataset_train_frac": 0.0003817255791210729, "timer/dataset_train_avg": 0.0001773624933989614, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0054035186767578125, "timer/agent.train_count": 2153.0, "timer/agent.train_total": 962.1326816082001, "timer/agent.train_frac": 0.9617903475850229, "timer/agent.train_avg": 0.4468800193256851, "timer/agent.train_min": 0.4331777095794678, "timer/agent.train_max": 0.5669136047363281, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4768350124359131, "timer/agent.report_frac": 0.00047666535096268874, "timer/agent.report_avg": 0.23841750621795654, "timer/agent.report_min": 0.23155927658081055, "timer/agent.report_max": 0.24527573585510254, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9553384749918075e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 8.608821666218928}
{"step": 156480, "time": 18237.3136241436, "episode/length": 288.0, "episode/score": 0.042694783636648026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042694783636648026}
{"step": 156496, "time": 18239.14810848236, "episode/length": 288.0, "episode/score": 0.07214178195113163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07214178195113163}
{"step": 156760, "time": 18269.747470140457, "episode/length": 288.0, "episode/score": 0.07403648380420691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07403648380420691}
{"step": 157072, "time": 18305.845742702484, "episode/length": 288.0, "episode/score": 0.06178747386661598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06178747386661598}
{"step": 157432, "time": 18347.253214597702, "episode/length": 288.0, "episode/score": 0.059741628516121636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059741628516121636}
{"step": 157680, "time": 18375.75924015045, "episode/length": 288.0, "episode/score": 0.06953174162083542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06953174162083542}
{"step": 158072, "time": 18420.907771110535, "episode/length": 288.0, "episode/score": 0.034456156727628695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034456156727628695}
{"step": 158576, "time": 18479.120272636414, "episode/length": 288.0, "episode/score": 0.09558530806214094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09558530806214094}
{"step": 158792, "time": 18504.175339460373, "episode/length": 288.0, "episode/score": 0.06914638457715228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06914638457715228}
{"step": 158808, "time": 18506.06525993347, "episode/length": 288.0, "episode/score": 0.09179215452536482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09179215452536482}
{"step": 159072, "time": 18536.448087453842, "episode/length": 288.0, "episode/score": 0.11286149031411696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11286149031411696}
{"step": 159384, "time": 18572.450098514557, "episode/length": 288.0, "episode/score": 0.1225010465525429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1225010465525429}
{"step": 159744, "time": 18614.134944200516, "episode/length": 288.0, "episode/score": 0.08645057259002442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08645057259002442}
{"step": 159992, "time": 18642.709968805313, "episode/length": 288.0, "episode/score": 0.12507019086331184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12507019086331184}
{"step": 160056, "time": 18655.095554351807, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 18655.10163974762, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 18655.107073307037, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 18655.11243414879, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 18655.117666244507, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 18655.122977256775, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 18655.128304958344, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 18655.133283615112, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160384, "time": 18693.020785808563, "episode/length": 288.0, "episode/score": 0.10005380799032082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10005380799032082}
{"step": 160888, "time": 18751.1066968441, "episode/length": 288.0, "episode/score": 0.13900148188406547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13900148188406547}
{"step": 161104, "time": 18775.953644037247, "episode/length": 288.0, "episode/score": 0.12840014225969298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12840014225969298}
{"step": 161120, "time": 18777.808787107468, "episode/length": 288.0, "episode/score": 0.1183840919712793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1183840919712793}
{"step": 161384, "time": 18808.132618665695, "episode/length": 288.0, "episode/score": 0.09443289499574803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09443289499574803}
{"step": 161696, "time": 18844.20451951027, "episode/length": 288.0, "episode/score": 0.10224169050286491, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10224169050286491}
{"step": 162056, "time": 18885.574893951416, "episode/length": 288.0, "episode/score": 0.08582336358449538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08582336358449538}
{"step": 162304, "time": 18914.246241807938, "episode/length": 288.0, "episode/score": 0.10970491499369928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10970491499369928}
{"step": 162696, "time": 18959.47714281082, "episode/length": 288.0, "episode/score": 0.08690911835242332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08690911835242332}
{"step": 163200, "time": 19017.90379858017, "episode/length": 288.0, "episode/score": 0.11029179018373725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11029179018373725}
{"step": 163416, "time": 19042.753582954407, "episode/length": 288.0, "episode/score": 0.08506749757407306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08506749757407306}
{"step": 163432, "time": 19044.596405267715, "episode/length": 288.0, "episode/score": 0.12181125308870833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12181125308870833}
{"step": 163696, "time": 19074.930440425873, "episode/length": 288.0, "episode/score": 0.10671008185545361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10671008185545361}
{"step": 164008, "time": 19111.479036331177, "episode/length": 288.0, "episode/score": 0.06628961623732721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06628961623732721}
{"step": 164368, "time": 19152.930866241455, "episode/length": 288.0, "episode/score": 0.0915729788155204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0915729788155204}
{"step": 164616, "time": 19181.55116534233, "episode/length": 288.0, "episode/score": 0.11696183023809681, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11696183023809681}
{"step": 164893, "time": 19214.4559776783, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.0068328147710757, "train/action_min": 0.0, "train/action_std": 1.9183443806892218, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0015654716684028159, "train/actor_opt_grad_steps": 39760.0, "train/actor_opt_loss": -14.068934817646825, "train/adv_mag": 0.2043471961520439, "train/adv_max": 0.07647453477216322, "train/adv_mean": -0.0017266535836401894, "train/adv_min": -0.17366767983103906, "train/adv_std": 0.003744391137517469, "train/cont_avg": 0.9964752906976744, "train/cont_loss_mean": 0.006617314173558424, "train/cont_loss_std": 0.1309934781528576, "train/cont_neg_acc": 0.6704374547535774, "train/cont_neg_loss": 1.4890168736872003, "train/cont_pos_acc": 0.9999316789383113, "train/cont_pos_loss": 0.0012550177242130387, "train/cont_pred": 0.9964875096498533, "train/cont_rate": 0.9964752906976744, "train/dyn_loss_mean": 1.0000006304230802, "train/dyn_loss_std": 1.8246228763357152e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03706716912971853, "train/extr_critic_critic_opt_grad_steps": 39760.0, "train/extr_critic_critic_opt_loss": 12015.499831940408, "train/extr_critic_mag": 0.33144251967585364, "train/extr_critic_max": 0.33144251967585364, "train/extr_critic_mean": 0.29797512708708296, "train/extr_critic_min": 0.29065652503523715, "train/extr_critic_std": 0.0023035089127979307, "train/extr_return_normed_mag": 0.2103951350201008, "train/extr_return_normed_max": 0.08831400455430496, "train/extr_return_normed_mean": 0.0003765590365600114, "train/extr_return_normed_min": -0.16705391628797664, "train/extr_return_normed_std": 0.004430957760683499, "train/extr_return_rate": 4.935804517603977e-05, "train/extr_return_raw_mag": 0.38418586753135503, "train/extr_return_raw_max": 0.38418586753135503, "train/extr_return_raw_mean": 0.2962484344493511, "train/extr_return_raw_min": 0.12881794710491978, "train/extr_return_raw_std": 0.004430957777468964, "train/extr_reward_mag": 0.10800908055416374, "train/extr_reward_max": 0.10800908055416374, "train/extr_reward_mean": 0.0003859221318000278, "train/extr_reward_min": 9.93595566860465e-07, "train/extr_reward_std": 0.00140839658507016, "train/image_loss_mean": 0.08942970782518386, "train/image_loss_std": 0.10829312357791634, "train/model_loss_mean": 0.706654523694238, "train/model_loss_std": 0.215445712174094, "train/model_opt_grad_norm": 21.885629414403162, "train/model_opt_grad_steps": 39725.274418604655, "train/model_opt_loss": 2694.6407686455304, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3813.953488372093, "train/policy_entropy_mag": 1.6735058169032253, "train/policy_entropy_max": 1.6735058169032253, "train/policy_entropy_mean": 0.6019715420035429, "train/policy_entropy_min": 0.06562870082467101, "train/policy_entropy_std": 0.34619214936744336, "train/policy_logprob_mag": 6.550898960024812, "train/policy_logprob_max": -0.008755039393382017, "train/policy_logprob_mean": -0.6020381643328556, "train/policy_logprob_min": -6.550898960024812, "train/policy_logprob_std": 0.9301307528517967, "train/policy_randomness_mag": 0.8600119161051373, "train/policy_randomness_max": 0.8600119161051373, "train/policy_randomness_mean": 0.30935219408467757, "train/policy_randomness_min": 0.03372648243987283, "train/policy_randomness_std": 0.17790758235510004, "train/post_ent_mag": 34.54883114127226, "train/post_ent_max": 34.54883114127226, "train/post_ent_mean": 34.27693818558094, "train/post_ent_min": 34.01982020888217, "train/post_ent_std": 0.0964360565293667, "train/prior_ent_mag": 34.92583524127339, "train/prior_ent_max": 34.92583524127339, "train/prior_ent_mean": 33.715260793996414, "train/prior_ent_min": 32.64073456165402, "train/prior_ent_std": 0.31838385143945386, "train/rep_loss_mean": 1.0000006304230802, "train/rep_loss_std": 1.8246228763357152e-05, "train/reward_avg": 0.00038923023533899077, "train/reward_loss_mean": 0.010607100319290576, "train/reward_loss_std": 0.04568609789360401, "train/reward_max_data": 0.1673601791305944, "train/reward_max_pred": 0.0805741731510606, "train/reward_neg_acc": 0.9999636361765307, "train/reward_neg_loss": 0.00945615977871903, "train/reward_pos_acc": 0.39303482601891704, "train/reward_pos_loss": 3.3217977841398607, "train/reward_pred": 0.0003416932837734389, "train/reward_rate": 0.00035428779069767444, "train_stats/mean_log_entropy": 0.4783424367507299, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.009270774200558662, "report/cont_loss_std": 0.18542617559432983, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.2624588012695312, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0018845985177904367, "report/cont_pred": 0.9942639470100403, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08177261054515839, "report/image_loss_std": 0.09098849445581436, "report/model_loss_mean": 0.706881046295166, "report/model_loss_std": 0.4354303777217865, "report/post_ent_mag": 34.35752868652344, "report/post_ent_max": 34.35752868652344, "report/post_ent_mean": 34.087059020996094, "report/post_ent_min": 33.822601318359375, "report/post_ent_std": 0.10216554254293442, "report/prior_ent_mag": 34.6326904296875, "report/prior_ent_max": 34.6326904296875, "report/prior_ent_mean": 33.77214813232422, "report/prior_ent_min": 32.64665222167969, "report/prior_ent_std": 0.2825167179107666, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0009596970630809665, "report/reward_loss_mean": 0.015837622806429863, "report/reward_loss_std": 0.23368169367313385, "report/reward_max_data": 0.7911249995231628, "report/reward_max_pred": 0.08205115795135498, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008545633405447006, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 7.475544452667236, "report/reward_pred": 0.0003484919434413314, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.02350575290620327, "eval/cont_loss_std": 0.5187596082687378, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.750007629394531, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0005576070980168879, "eval/cont_pred": 0.9994471073150635, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2757348120212555, "eval/image_loss_std": 0.1651269644498825, "eval/model_loss_mean": 0.900486409664154, "eval/model_loss_std": 0.5365207195281982, "eval/post_ent_mag": 34.377559661865234, "eval/post_ent_max": 34.377559661865234, "eval/post_ent_mean": 34.04618835449219, "eval/post_ent_min": 33.81597137451172, "eval/post_ent_std": 0.1087985560297966, "eval/prior_ent_mag": 34.74309158325195, "eval/prior_ent_max": 34.74309158325195, "eval/prior_ent_mean": 33.71300506591797, "eval/prior_ent_min": 32.67458724975586, "eval/prior_ent_std": 0.32618215680122375, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012458134442567825, "eval/reward_loss_std": 0.0016680139815434813, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.001258254051208496, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012458134442567825, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00019816425628960133, "eval/reward_rate": 0.0, "replay/size": 164389.0, "replay/inserts": 8616.0, "replay/samples": 34464.0, "replay/insert_wait_avg": 1.5681223838331529e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.689109862459514e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 40360.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.030603494611166e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2351484298706, "timer/env.step_count": 1077.0, "timer/env.step_total": 10.060918092727661, "timer/env.step_frac": 0.010058552839820607, "timer/env.step_avg": 0.009341613827973686, "timer/env.step_min": 0.00830531120300293, "timer/env.step_max": 0.03783726692199707, "timer/replay._sample_count": 34464.0, "timer/replay._sample_total": 16.745141983032227, "timer/replay._sample_frac": 0.016741205314888288, "timer/replay._sample_avg": 0.00048587343265529907, "timer/replay._sample_min": 0.0003604888916015625, "timer/replay._sample_max": 0.02830672264099121, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1366.0, "timer/agent.policy_total": 13.265653133392334, "timer/agent.policy_frac": 0.013262534469235789, "timer/agent.policy_avg": 0.009711312689159835, "timer/agent.policy_min": 0.008771419525146484, "timer/agent.policy_max": 0.040191650390625, "timer/dataset_train_count": 2154.0, "timer/dataset_train_total": 0.380265474319458, "timer/dataset_train_frac": 0.00038017607651199187, "timer/dataset_train_avg": 0.00017653921741850418, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.0007812976837158203, "timer/agent.train_count": 2154.0, "timer/agent.train_total": 962.5088965892792, "timer/agent.train_frac": 0.9622826173427192, "timer/agent.train_avg": 0.4468472129012438, "timer/agent.train_min": 0.4341163635253906, "timer/agent.train_max": 0.6162209510803223, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47459912300109863, "timer/agent.report_frac": 0.0004744875479991935, "timer/agent.report_avg": 0.23729956150054932, "timer/agent.report_min": 0.23111605644226074, "timer/agent.report_max": 0.2434830665588379, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.574920654296875e-05, "timer/dataset_eval_frac": 2.5743153080941846e-08, "timer/dataset_eval_avg": 2.574920654296875e-05, "timer/dataset_eval_min": 2.574920654296875e-05, "timer/dataset_eval_max": 2.574920654296875e-05, "fps": 8.613858038285379}
{"step": 165008, "time": 19227.458206892014, "episode/length": 288.0, "episode/score": 0.07709024917880924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07709024917880924}
{"step": 165512, "time": 19285.386641025543, "episode/length": 288.0, "episode/score": 0.1269028677629649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1269028677629649}
{"step": 165728, "time": 19310.437108039856, "episode/length": 288.0, "episode/score": 0.10517302396226569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10517302396226569}
{"step": 165744, "time": 19312.268303871155, "episode/length": 288.0, "episode/score": 0.06717930439276643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06717930439276643}
{"step": 166008, "time": 19342.53447175026, "episode/length": 288.0, "episode/score": 0.10430351416050598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10430351416050598}
{"step": 166320, "time": 19378.285486221313, "episode/length": 288.0, "episode/score": 0.10926012244738104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10926012244738104}
{"step": 166680, "time": 19419.895725011826, "episode/length": 288.0, "episode/score": 0.11299695843933932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11299695843933932}
{"step": 166928, "time": 19448.345945119858, "episode/length": 288.0, "episode/score": 0.13713523734054434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13713523734054434}
{"step": 167320, "time": 19493.253100156784, "episode/length": 288.0, "episode/score": 0.06814416365352827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06814416365352827}
{"step": 167552, "time": 19519.755133867264, "episode/length": 28.0, "episode/score": 0.9275186481024775, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.015018595622450448}
{"step": 167824, "time": 19550.924263477325, "episode/length": 288.0, "episode/score": 0.08465599938631385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08465599938631385}
{"step": 168000, "time": 19571.133019447327, "episode/length": 164.0, "episode/score": 0.5503739393912497, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.06287392863447394}
{"step": 168040, "time": 19575.853099822998, "episode/length": 288.0, "episode/score": 0.09590403615243304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09590403615243304}
{"step": 168056, "time": 19577.716751098633, "episode/length": 288.0, "episode/score": 0.07213276949551073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07213276949551073}
{"step": 168320, "time": 19608.14578318596, "episode/length": 288.0, "episode/score": 0.07708847215968717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07708847215968717}
{"step": 168616, "time": 19642.371567487717, "episode/length": 286.0, "episode/score": 0.19429271979595342, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.08804271763062843}
{"step": 169240, "time": 19715.148977279663, "episode/length": 288.0, "episode/score": 0.06032206075229851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06032206075229851}
{"step": 169472, "time": 19742.142790079117, "episode/length": 28.0, "episode/score": 0.9254298755386685, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.012929852511717854}
{"step": 169864, "time": 19787.219141721725, "episode/length": 288.0, "episode/score": 0.032704979933669165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032704979933669165}
{"step": 170040, "time": 19809.11731648445, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 170040, "time": 19809.265352725983, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 170040, "time": 19809.35932779312, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 170040, "time": 19809.69498205185, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 170040, "time": 19809.80478477478, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 170040, "time": 19811.647560358047, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 170040, "time": 19811.97376036644, "eval_episode/length": 220.0, "eval_episode/score": 0.3125, "eval_episode/reward_rate": 0.004524886877828055}
{"step": 170040, "time": 19812.090366363525, "eval_episode/length": 226.0, "eval_episode/score": 0.29374998807907104, "eval_episode/reward_rate": 0.004405286343612335}
{"step": 170136, "time": 19823.093084573746, "episode/length": 288.0, "episode/score": 0.05601680835826528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05601680835826528}
{"step": 170312, "time": 19843.444893836975, "episode/length": 288.0, "episode/score": 0.053140023115361146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053140023115361146}
{"step": 170352, "time": 19848.076346874237, "episode/length": 288.0, "episode/score": 0.03418927094725177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03418927094725177}
{"step": 170368, "time": 19849.937384605408, "episode/length": 288.0, "episode/score": 0.04501193985225882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04501193985225882}
{"step": 170544, "time": 19870.238722085953, "episode/length": 50.0, "episode/score": 0.8659201737171998, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.022170150375927733}
{"step": 170632, "time": 19880.45156145096, "episode/length": 288.0, "episode/score": 0.035966219330987315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035966219330987315}
{"step": 170824, "time": 19902.829394817352, "episode/length": 168.0, "episode/score": 0.5068780123248189, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.031878010107107}
{"step": 170928, "time": 19914.81183695793, "episode/length": 288.0, "episode/score": 0.06076878563050059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06076878563050059}
{"step": 171664, "time": 19999.789626598358, "episode/length": 139.0, "episode/score": 0.5965358146449944, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.030910774085896264}
{"step": 171752, "time": 20009.91920351982, "episode/length": 102.0, "episode/score": 0.7012292690612298, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.019979284724911395}
{"step": 172056, "time": 20045.5917263031, "episode/length": 48.0, "episode/score": 0.8647355767059821, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.014735544685947843}
{"step": 172176, "time": 20059.408425569534, "episode/length": 288.0, "episode/score": 0.023279415216734378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023279415216734378}
{"step": 172624, "time": 20111.151203155518, "episode/length": 288.0, "episode/score": 0.042444632850248354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042444632850248354}
{"step": 172664, "time": 20115.767506837845, "episode/length": 288.0, "episode/score": 0.03682757406699011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03682757406699011}
{"step": 172680, "time": 20117.626551151276, "episode/length": 288.0, "episode/score": 0.04543424531431128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04543424531431128}
{"step": 172760, "time": 20126.881460905075, "episode/length": 87.0, "episode/score": 0.7525638782507258, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.02443889493304141}
{"step": 172904, "time": 20143.74606204033, "episode/length": 27.0, "episode/score": 0.9264363481924249, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.010811392174133516}
{"step": 172944, "time": 20148.43715596199, "episode/length": 288.0, "episode/score": 0.03509009221355086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03509009221355086}
{"step": 173136, "time": 20170.698628902435, "episode/length": 288.0, "episode/score": 0.032051032226888765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032051032226888765}
{"step": 173192, "time": 20177.136654376984, "episode/length": 126.0, "episode/score": 0.647588962495206, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.04133897523104224}
{"step": 173509, "time": 20214.547012090683, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8489044899164244, "train/action_min": 0.0, "train/action_std": 1.5816970719847567, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002579025192549019, "train/actor_opt_grad_steps": 41910.0, "train/actor_opt_loss": -6.704078586018363, "train/adv_mag": 0.2809348615796067, "train/adv_max": 0.1545264639826708, "train/adv_mean": 0.0012455423654458616, "train/adv_min": -0.24322784951953, "train/adv_std": 0.012537914184788458, "train/cont_avg": 0.9962708938953488, "train/cont_loss_mean": 0.0069513823980530505, "train/cont_loss_std": 0.13809709697474487, "train/cont_neg_acc": 0.6739078093772737, "train/cont_neg_loss": 1.5097135937324981, "train/cont_pos_acc": 0.9998905861100486, "train/cont_pos_loss": 0.0013610432995212545, "train/cont_pred": 0.9962796546692072, "train/cont_rate": 0.9962708938953488, "train/dyn_loss_mean": 1.0000001153280569, "train/dyn_loss_std": 3.6944459235772144e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.19433978019000658, "train/extr_critic_critic_opt_grad_steps": 41910.0, "train/extr_critic_critic_opt_loss": 11856.494862827034, "train/extr_critic_mag": 0.33918727109598557, "train/extr_critic_max": 0.33918727109598557, "train/extr_critic_mean": 0.2979546379211337, "train/extr_critic_min": 0.28463030748589097, "train/extr_critic_std": 0.005532772610028989, "train/extr_return_normed_mag": 0.2882751011571219, "train/extr_return_normed_max": 0.18196107564970504, "train/extr_return_normed_mean": 0.01315800332082861, "train/extr_return_normed_min": -0.22461526712705923, "train/extr_return_normed_std": 0.014227718154921435, "train/extr_return_rate": 0.003148013684116196, "train/extr_return_raw_mag": 0.468003274257793, "train/extr_return_raw_max": 0.468003274257793, "train/extr_return_raw_mean": 0.29920021655947665, "train/extr_return_raw_min": 0.06142693175825962, "train/extr_return_raw_std": 0.014227718137594504, "train/extr_reward_mag": 0.2376762406770573, "train/extr_reward_max": 0.2376762406770573, "train/extr_reward_mean": 0.0008336471692864719, "train/extr_reward_min": 1.1815581210823946e-06, "train/extr_reward_std": 0.006486774266962785, "train/image_loss_mean": 0.09003116353306659, "train/image_loss_std": 0.10867116842852083, "train/model_loss_mean": 0.7075881830481596, "train/model_loss_std": 0.21292432262453923, "train/model_opt_grad_norm": 21.50228411652321, "train/model_opt_grad_steps": 41873.47441860465, "train/model_opt_loss": 2520.607919808321, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3558.139534883721, "train/policy_entropy_mag": 1.3884474388388701, "train/policy_entropy_max": 1.3884474388388701, "train/policy_entropy_mean": 0.32867199605287506, "train/policy_entropy_min": 0.06490627506444621, "train/policy_entropy_std": 0.2183256916875063, "train/policy_logprob_mag": 6.551004241233648, "train/policy_logprob_max": -0.00864246838487858, "train/policy_logprob_mean": -0.32801243836103483, "train/policy_logprob_min": -6.551004241233648, "train/policy_logprob_std": 0.7469435971836711, "train/policy_randomness_mag": 0.7135208795236987, "train/policy_randomness_max": 0.7135208795236987, "train/policy_randomness_mean": 0.16890400336232297, "train/policy_randomness_min": 0.0333552292613096, "train/policy_randomness_std": 0.11219721741454546, "train/post_ent_mag": 34.3366879662802, "train/post_ent_max": 34.3366879662802, "train/post_ent_mean": 34.019417713963705, "train/post_ent_min": 33.724876386065816, "train/post_ent_std": 0.11179967813713607, "train/prior_ent_mag": 34.80114983846975, "train/prior_ent_max": 34.80114983846975, "train/prior_ent_mean": 33.6718583217887, "train/prior_ent_min": 32.56829436546148, "train/prior_ent_std": 0.33044922130052434, "train/rep_loss_mean": 1.0000001153280569, "train/rep_loss_std": 3.6944459235772144e-06, "train/reward_avg": 0.000394463864409603, "train/reward_loss_mean": 0.010605542690948, "train/reward_loss_std": 0.03707439832735893, "train/reward_max_data": 0.15566377367521095, "train/reward_max_pred": 0.09455247479815816, "train/reward_neg_acc": 0.9999227207760478, "train/reward_neg_loss": 0.009717703196978154, "train/reward_pos_acc": 0.5666666668194991, "train/reward_pos_loss": 2.4439019249035763, "train/reward_pred": 0.00037505038699871577, "train/reward_rate": 0.0003497456395348837, "train_stats/mean_log_entropy": 0.3656546072318004, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.01024292130023241, "report/cont_loss_std": 0.2205590307712555, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 2.000253438949585, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0004783933109138161, "report/cont_pred": 0.9965932965278625, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07112953811883926, "report/image_loss_std": 0.10325580090284348, "report/model_loss_mean": 0.696330189704895, "report/model_loss_std": 0.4202250838279724, "report/post_ent_mag": 34.219329833984375, "report/post_ent_max": 34.219329833984375, "report/post_ent_mean": 33.836456298828125, "report/post_ent_min": 33.512508392333984, "report/post_ent_std": 0.12435567378997803, "report/prior_ent_mag": 34.40747833251953, "report/prior_ent_max": 34.40747833251953, "report/prior_ent_mean": 33.48619079589844, "report/prior_ent_min": 32.33351516723633, "report/prior_ent_std": 0.32277798652648926, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007849211106076837, "report/reward_loss_mean": 0.014957735314965248, "report/reward_loss_std": 0.20562869310379028, "report/reward_max_data": 0.6034027338027954, "report/reward_max_pred": 0.0043773651123046875, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008541782386600971, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.578476905822754, "report/reward_pred": 0.00021694495808333158, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.05236416682600975, "eval/cont_loss_std": 0.7887743711471558, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.623050689697266, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0030673544388264418, "eval/cont_pred": 0.9975951910018921, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.29689472913742065, "eval/image_loss_std": 0.17222006618976593, "eval/model_loss_mean": 0.9505999088287354, "eval/model_loss_std": 0.8046914339065552, "eval/post_ent_mag": 34.22292709350586, "eval/post_ent_max": 34.22292709350586, "eval/post_ent_mean": 33.825408935546875, "eval/post_ent_min": 33.507904052734375, "eval/post_ent_std": 0.12335763871669769, "eval/prior_ent_mag": 34.91111755371094, "eval/prior_ent_max": 34.91111755371094, "eval/prior_ent_mean": 33.537540435791016, "eval/prior_ent_min": 32.57041931152344, "eval/prior_ent_std": 0.31470656394958496, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013409885577857494, "eval/reward_loss_std": 0.0018007216276600957, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.013818979263305664, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013409885577857494, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00025812454987317324, "eval/reward_rate": 0.0, "replay/size": 173005.0, "replay/inserts": 8616.0, "replay/samples": 34464.0, "replay/insert_wait_avg": 1.4697498155060806e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.532142663068426e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 42176.0, "eval_replay/inserts": 1816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.061592858268301e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0820093154907, "timer/env.step_count": 1077.0, "timer/env.step_total": 10.059579849243164, "timer/env.step_frac": 0.01005875493763604, "timer/env.step_avg": 0.00934037126206422, "timer/env.step_min": 0.008329391479492188, "timer/env.step_max": 0.04324984550476074, "timer/replay._sample_count": 34464.0, "timer/replay._sample_total": 16.412855863571167, "timer/replay._sample_frac": 0.016411509966872614, "timer/replay._sample_avg": 0.0004762318901918282, "timer/replay._sample_min": 0.00034737586975097656, "timer/replay._sample_max": 0.028867721557617188, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1304.0, "timer/agent.policy_total": 13.108783483505249, "timer/agent.policy_frac": 0.013107708529301109, "timer/agent.policy_avg": 0.010052748070172738, "timer/agent.policy_min": 0.008733510971069336, "timer/agent.policy_max": 0.0811765193939209, "timer/dataset_train_count": 2154.0, "timer/dataset_train_total": 0.3741142749786377, "timer/dataset_train_frac": 0.00037408359663894104, "timer/dataset_train_avg": 0.00017368350741812336, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0011425018310546875, "timer/agent.train_count": 2154.0, "timer/agent.train_total": 962.5670874118805, "timer/agent.train_frac": 0.9624881544171688, "timer/agent.train_avg": 0.4468742281392203, "timer/agent.train_min": 0.43445754051208496, "timer/agent.train_max": 1.111793041229248, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47083139419555664, "timer/agent.report_frac": 0.0004707927848015371, "timer/agent.report_avg": 0.23541569709777832, "timer/agent.report_min": 0.2230668067932129, "timer/agent.report_max": 0.24776458740234375, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.099187366085842e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 8.615186737253383}
{"step": 174064, "time": 20278.47154378891, "episode/length": 288.0, "episode/score": 0.045372562464365274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045372562464365274}
{"step": 174416, "time": 20318.871178388596, "episode/length": 43.0, "episode/score": 0.8838353807641397, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.01821032828411262}
{"step": 174872, "time": 20371.502542972565, "episode/length": 240.0, "episode/score": 0.29538412090857946, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.04538412207273268}
{"step": 174936, "time": 20378.9169986248, "episode/length": 288.0, "episode/score": 0.019310515441588905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019310515441588905}
{"step": 174976, "time": 20383.5429251194, "episode/length": 288.0, "episode/score": 0.015860633853492345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015860633853492345}
{"step": 175072, "time": 20394.625324964523, "episode/length": 288.0, "episode/score": 0.044903037972801485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044903037972801485}
{"step": 175216, "time": 20411.372128725052, "episode/length": 288.0, "episode/score": 0.02511853802147357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02511853802147357}
{"step": 175448, "time": 20438.268979549408, "episode/length": 288.0, "episode/score": 0.043842482431841745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043842482431841745}
{"step": 175504, "time": 20444.74475002289, "episode/length": 288.0, "episode/score": 0.02419819508781984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02419819508781984}
{"step": 175992, "time": 20501.316903591156, "episode/length": 114.0, "episode/score": 0.6684601092996445, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.024710098193622798}
{"step": 176304, "time": 20537.262612581253, "episode/length": 165.0, "episode/score": 0.5003471103954098, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.01597211685646016}
{"step": 176544, "time": 20565.003658294678, "episode/length": 208.0, "episode/score": 0.3795638251089031, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.029563837530417914}
{"step": 176728, "time": 20586.193611383438, "episode/length": 288.0, "episode/score": 0.04552027458214525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04552027458214525}
{"step": 177248, "time": 20646.134973049164, "episode/length": 288.0, "episode/score": 0.04202919035407149, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04202919035407149}
{"step": 177472, "time": 20672.12322974205, "episode/length": 115.0, "episode/score": 0.6755031695897742, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.034878155270689604}
{"step": 177528, "time": 20678.56847333908, "episode/length": 288.0, "episode/score": 0.026836161889946197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026836161889946197}
{"step": 177600, "time": 20686.860059976578, "episode/length": 108.0, "episode/score": 0.6905637715252624, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.028063748498311725}
{"step": 177640, "time": 20691.465733528137, "episode/length": 205.0, "episode/score": 0.3968072505727491, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.03743225703379949}
{"step": 177760, "time": 20705.253388643265, "episode/length": 288.0, "episode/score": 0.04714889080537432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04714889080537432}
{"step": 177816, "time": 20711.666620254517, "episode/length": 288.0, "episode/score": 0.04221873202322968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04221873202322968}
{"step": 177880, "time": 20719.02839899063, "episode/length": 34.0, "episode/score": 0.9028298581270064, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.009079839046535199}
{"step": 178296, "time": 20766.97789978981, "episode/length": 81.0, "episode/score": 0.7679871893924428, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.021112202128279023}
{"step": 178368, "time": 20775.249771356583, "episode/length": 68.0, "episode/score": 0.7958134929035623, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.008313445720432355}
{"step": 178616, "time": 20803.882993221283, "episode/length": 288.0, "episode/score": 0.03881581148561963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03881581148561963}
{"step": 179056, "time": 20854.865798950195, "episode/length": 54.0, "episode/score": 0.840319381072959, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.009069345810758023}
{"step": 179440, "time": 20898.842663764954, "episode/length": 47.0, "episode/score": 0.866033992526809, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.012909017183574178}
{"step": 179544, "time": 20910.88499546051, "episode/length": 251.0, "episode/score": 0.25235030466592434, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.036725302500599355}
{"step": 179560, "time": 20912.830384254456, "episode/length": 288.0, "episode/score": 0.019010705057098676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019010705057098676}
{"step": 179784, "time": 20938.49374485016, "episode/length": 288.0, "episode/score": 0.03992184363596607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03992184363596607}
{"step": 180024, "time": 20967.775703668594, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 180024, "time": 20971.508006095886, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 20971.514015436172, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 20971.51950097084, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 20971.524866580963, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 20971.53012752533, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 20971.53531718254, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 20971.540697813034, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180056, "time": 20975.23584485054, "episode/length": 63.0, "episode/score": 0.8151848884440369, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.012059856424002646}
{"step": 180072, "time": 20977.0695707798, "episode/length": 288.0, "episode/score": 0.02511721915891485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02511721915891485}
{"step": 180192, "time": 20990.939707040787, "episode/length": 288.0, "episode/score": 0.011866865575825614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.011866865575825614}
{"step": 180608, "time": 21039.299515008926, "episode/length": 288.0, "episode/score": 0.029190870981210537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029190870981210537}
{"step": 180640, "time": 21043.041101694107, "episode/length": 55.0, "episode/score": 0.8392030801154533, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.011078072955911011}
{"step": 180680, "time": 21047.641528129578, "episode/length": 288.0, "episode/score": 0.010829669259123875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010829669259123875}
{"step": 181152, "time": 21102.02091050148, "episode/length": 63.0, "episode/score": 0.8161613692418541, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.013036363531682582}
{"step": 181752, "time": 21171.34674835205, "episode/length": 288.0, "episode/score": 0.0312072737683593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0312072737683593}
{"step": 181872, "time": 21185.28658556938, "episode/length": 288.0, "episode/score": 0.02817015808142287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02817015808142287}
{"step": 182096, "time": 21211.309912919998, "episode/length": 288.0, "episode/score": 0.016316722325655064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.016316722325655064}
{"step": 182104, "time": 21212.23591732979, "episode/length": 43.0, "episode/score": 0.8764693391424316, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.010844330405461733}
{"step": 182117, "time": 21214.60975575447, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0126430370189525, "train/action_min": 0.0, "train/action_std": 1.5462201480512265, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00215063592919183, "train/actor_opt_grad_steps": 44065.0, "train/actor_opt_loss": -3.5056925869150155, "train/adv_mag": 0.2907546888347025, "train/adv_max": 0.14228005141571717, "train/adv_mean": 0.0009101930558949158, "train/adv_min": -0.25308031409426973, "train/adv_std": 0.009588878115647714, "train/cont_avg": 0.9964418764467593, "train/cont_loss_mean": 0.007206168798869907, "train/cont_loss_std": 0.13558613069903072, "train/cont_neg_acc": 0.618559081669686, "train/cont_neg_loss": 1.6013174555410963, "train/cont_pos_acc": 0.9998728801254873, "train/cont_pos_loss": 0.001523481250640341, "train/cont_pred": 0.9964339371632647, "train/cont_rate": 0.9964418764467593, "train/dyn_loss_mean": 1.000000007726528, "train/dyn_loss_std": 2.497656034258263e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08571474448156853, "train/extr_critic_critic_opt_grad_steps": 44065.0, "train/extr_critic_critic_opt_loss": 7844.87478185583, "train/extr_critic_mag": 0.373153336070202, "train/extr_critic_max": 0.373153336070202, "train/extr_critic_mean": 0.3389490107419314, "train/extr_critic_min": 0.32011787482985743, "train/extr_critic_std": 0.008512785932031908, "train/extr_return_normed_mag": 0.29433278187557504, "train/extr_return_normed_max": 0.17556355769435564, "train/extr_return_normed_mean": 0.014633639530209755, "train/extr_return_normed_min": -0.23921459927051156, "train/extr_return_normed_std": 0.013415926153323165, "train/extr_return_rate": 0.00048677423779332056, "train/extr_return_raw_mag": 0.5007891149984466, "train/extr_return_raw_max": 0.5007891149984466, "train/extr_return_raw_mean": 0.3398592134040815, "train/extr_return_raw_min": 0.08601095817155308, "train/extr_return_raw_std": 0.013415926088647986, "train/extr_reward_mag": 0.1989196147079821, "train/extr_reward_max": 0.1989196147079821, "train/extr_reward_mean": 0.0005094731169703193, "train/extr_reward_min": 1.3035756570321542e-06, "train/extr_reward_std": 0.0037688940837041526, "train/image_loss_mean": 0.0838555803315507, "train/image_loss_std": 0.10555498671062567, "train/model_loss_mean": 0.7023627661444523, "train/model_loss_std": 0.22010193910035822, "train/model_opt_grad_norm": 19.747234408799994, "train/model_opt_grad_steps": 44027.35648148148, "train/model_opt_loss": 3735.9530481409142, "train/model_opt_model_opt_grad_overflow": 0.004629629629629629, "train/model_opt_model_opt_grad_scale": 5300.925925925926, "train/policy_entropy_mag": 1.4731777569761983, "train/policy_entropy_max": 1.4731777569761983, "train/policy_entropy_mean": 0.10890619446420008, "train/policy_entropy_min": 0.06468699468920629, "train/policy_entropy_std": 0.1453098116994456, "train/policy_logprob_mag": 6.551079745645876, "train/policy_logprob_max": -0.00860823330434936, "train/policy_logprob_mean": -0.10799927826694868, "train/policy_logprob_min": -6.551079745645876, "train/policy_logprob_std": 0.6493904769972518, "train/policy_randomness_mag": 0.7570636506985735, "train/policy_randomness_max": 0.7570636506985735, "train/policy_randomness_mean": 0.05596671603551066, "train/policy_randomness_min": 0.03324254103763788, "train/policy_randomness_std": 0.07467447573112117, "train/post_ent_mag": 34.106656039202655, "train/post_ent_max": 34.106656039202655, "train/post_ent_mean": 33.74245982699924, "train/post_ent_min": 33.417469059979474, "train/post_ent_std": 0.12280338147172222, "train/prior_ent_mag": 34.529529324284304, "train/prior_ent_max": 34.529529324284304, "train/prior_ent_mean": 33.54322913840965, "train/prior_ent_min": 32.478725283234205, "train/prior_ent_std": 0.31628389215027847, "train/rep_loss_mean": 1.000000007726528, "train/rep_loss_std": 2.497656034258263e-07, "train/reward_avg": 0.0004488593689597177, "train/reward_loss_mean": 0.011300989008439635, "train/reward_loss_std": 0.05222362239362189, "train/reward_max_data": 0.20108188672370655, "train/reward_max_pred": 0.10432011330569232, "train/reward_neg_acc": 0.9999004779038606, "train/reward_neg_loss": 0.009848868681324853, "train/reward_pos_acc": 0.49166666679084303, "train/reward_pos_loss": 3.0653981152921914, "train/reward_pred": 0.0004129971208318171, "train/reward_rate": 0.00043854890046296296, "train_stats/mean_log_entropy": 0.08800929635763169, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.003112248843535781, "report/cont_loss_std": 0.015649570152163506, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.007091486360877752, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0031083589419722557, "report/cont_pred": 0.9960458278656006, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06512625515460968, "report/image_loss_std": 0.09600421786308289, "report/model_loss_mean": 0.6791532039642334, "report/model_loss_std": 0.10413695126771927, "report/post_ent_mag": 34.042030334472656, "report/post_ent_max": 34.042030334472656, "report/post_ent_mean": 33.63437271118164, "report/post_ent_min": 33.350074768066406, "report/post_ent_std": 0.10490647703409195, "report/prior_ent_mag": 34.371864318847656, "report/prior_ent_max": 34.371864318847656, "report/prior_ent_mean": 33.65465545654297, "report/prior_ent_min": 32.82900619506836, "report/prior_ent_std": 0.2854594588279724, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006272275932133198, "report/reward_loss_mean": 0.010914658196270466, "report/reward_loss_std": 0.022366922348737717, "report/reward_max_data": 0.4127083420753479, "report/reward_max_pred": 0.42352402210235596, "report/reward_neg_acc": 0.9990224838256836, "report/reward_neg_loss": 0.010428391396999359, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.5083648562431335, "report/reward_pred": 0.0009935012785717845, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03519723564386368, "eval/cont_loss_std": 0.6296743154525757, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.630220413208008, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0011276284931227565, "eval/cont_pred": 0.9988936185836792, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2020384669303894, "eval/image_loss_std": 0.14461646974086761, "eval/model_loss_mean": 0.8387242555618286, "eval/model_loss_std": 0.6452856659889221, "eval/post_ent_mag": 34.03462219238281, "eval/post_ent_max": 34.03462219238281, "eval/post_ent_mean": 33.6036376953125, "eval/post_ent_min": 33.275142669677734, "eval/post_ent_std": 0.13797637820243835, "eval/prior_ent_mag": 34.924827575683594, "eval/prior_ent_max": 34.924827575683594, "eval/prior_ent_mean": 33.60577392578125, "eval/prior_ent_min": 32.61552810668945, "eval/prior_ent_std": 0.32574576139450073, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001488477922976017, "eval/reward_loss_std": 0.005833665374666452, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.07125937938690186, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001488477922976017, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00031592976301908493, "eval/reward_rate": 0.0, "replay/size": 181613.0, "replay/inserts": 8608.0, "replay/samples": 34432.0, "replay/insert_wait_avg": 1.523352910151712e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.45653552193624e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44488.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.04854676137746e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0496869087219, "timer/env.step_count": 1076.0, "timer/env.step_total": 10.090179204940796, "timer/env.step_frac": 0.010089677880036937, "timer/env.step_avg": 0.009377489967417097, "timer/env.step_min": 0.008131027221679688, "timer/env.step_max": 0.03451108932495117, "timer/replay._sample_count": 34432.0, "timer/replay._sample_total": 16.43290400505066, "timer/replay._sample_frac": 0.01643208754541668, "timer/replay._sample_avg": 0.00047725673806490066, "timer/replay._sample_min": 0.00034999847412109375, "timer/replay._sample_max": 0.02073812484741211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1365.0, "timer/agent.policy_total": 13.384348630905151, "timer/agent.policy_frac": 0.013383683637037914, "timer/agent.policy_avg": 0.009805383612384727, "timer/agent.policy_min": 0.008782625198364258, "timer/agent.policy_max": 0.03901791572570801, "timer/dataset_train_count": 2152.0, "timer/dataset_train_total": 0.373018741607666, "timer/dataset_train_frac": 0.000373000208380359, "timer/dataset_train_avg": 0.00017333584647196375, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.0007214546203613281, "timer/agent.train_count": 2152.0, "timer/agent.train_total": 961.9383542537689, "timer/agent.train_frac": 0.9618905608852697, "timer/agent.train_avg": 0.4469973765119744, "timer/agent.train_min": 0.4340982437133789, "timer/agent.train_max": 0.5728142261505127, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4689188003540039, "timer/agent.report_frac": 0.0004688955023859767, "timer/agent.report_avg": 0.23445940017700195, "timer/agent.report_min": 0.22398018836975098, "timer/agent.report_max": 0.24493861198425293, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0516061876219006e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 8.60746347211062}
{"step": 182248, "time": 21229.441366672516, "episode/length": 46.0, "episode/score": 0.8718959418533814, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.015645930433038302}
{"step": 182368, "time": 21243.318038225174, "episode/length": 288.0, "episode/score": 0.03957494866847355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03957494866847355}
{"step": 182384, "time": 21245.152770280838, "episode/length": 288.0, "episode/score": 0.039968134094351626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039968134094351626}
{"step": 182864, "time": 21300.453843832016, "episode/length": 281.0, "episode/score": 0.14007358638190226, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.01819858267407426}
{"step": 182992, "time": 21315.306561231613, "episode/length": 288.0, "episode/score": 0.03770193672204414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03770193672204414}
{"step": 183464, "time": 21369.736835241318, "episode/length": 288.0, "episode/score": 0.03976903711236446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03976903711236446}
{"step": 184120, "time": 21445.294018268585, "episode/length": 156.0, "episode/score": 0.5323783304900189, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.019878319069675854}
{"step": 184152, "time": 21448.9649040699, "episode/length": 85.0, "episode/score": 0.7525391525587679, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.018164167663655917}
{"step": 184408, "time": 21478.517337560654, "episode/length": 288.0, "episode/score": 0.02328391632659077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02328391632659077}
{"step": 184416, "time": 21479.441022634506, "episode/length": 288.0, "episode/score": 0.03963059346432374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03963059346432374}
{"step": 184560, "time": 21496.04993224144, "episode/length": 288.0, "episode/score": 0.03225292455414319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03225292455414319}
{"step": 184680, "time": 21509.852969169617, "episode/length": 288.0, "episode/score": 0.025858683368426227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025858683368426227}
{"step": 184696, "time": 21511.74346971512, "episode/length": 288.0, "episode/score": 0.03338132019115392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03338132019115392}
{"step": 185008, "time": 21547.697144031525, "episode/length": 40.0, "episode/score": 0.8819009566907994, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0069009485126230175}
{"step": 185152, "time": 21564.245675086975, "episode/length": 56.0, "episode/score": 0.8375389065608374, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.012538919296673612}
{"step": 185304, "time": 21581.74655532837, "episode/length": 288.0, "episode/score": 0.014046146090208822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014046146090208822}
{"step": 185720, "time": 21629.76914215088, "episode/length": 70.0, "episode/score": 0.8033835236340678, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.02213353571215748}
{"step": 185776, "time": 21636.220661878586, "episode/length": 58.0, "episode/score": 0.8259386840546199, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.007188674371775505}
{"step": 186432, "time": 21711.958303689957, "episode/length": 288.0, "episode/score": 0.017481547499301087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017481547499301087}
{"step": 186464, "time": 21715.669172286987, "episode/length": 288.0, "episode/score": 0.02039079944381683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02039079944381683}
{"step": 186720, "time": 21745.23863530159, "episode/length": 288.0, "episode/score": 0.03618599453920979, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03618599453920979}
{"step": 186728, "time": 21746.179441452026, "episode/length": 288.0, "episode/score": 0.03893179061253704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03893179061253704}
{"step": 186872, "time": 21762.88414955139, "episode/length": 288.0, "episode/score": 0.030625987378357422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030625987378357422}
{"step": 187208, "time": 21801.883815050125, "episode/length": 274.0, "episode/score": 0.1802397512107632, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.03648975010190725}
{"step": 188032, "time": 21896.693602323532, "episode/length": 288.0, "episode/score": 0.018034368713983895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018034368713983895}
{"step": 188088, "time": 21903.29607987404, "episode/length": 288.0, "episode/score": 0.019093839130931656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019093839130931656}
{"step": 188656, "time": 21968.828205108643, "episode/length": 70.0, "episode/score": 0.7894246912135827, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.00817471743613396}
{"step": 188744, "time": 21978.94229531288, "episode/length": 288.0, "episode/score": 0.017839707447961928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017839707447961928}
{"step": 188776, "time": 21982.633150577545, "episode/length": 288.0, "episode/score": 0.034872599103067614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034872599103067614}
{"step": 189032, "time": 22012.07465982437, "episode/length": 288.0, "episode/score": 0.01871657694223927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01871657694223927}
{"step": 189040, "time": 22013.012667894363, "episode/length": 288.0, "episode/score": 0.013213645680338004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013213645680338004}
{"step": 189184, "time": 22029.5141851902, "episode/length": 288.0, "episode/score": 0.029142573527508375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029142573527508375}
{"step": 189520, "time": 22068.0272731781, "episode/length": 288.0, "episode/score": 0.010301700538832392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010301700538832392}
{"step": 189632, "time": 22080.884649038315, "episode/length": 121.0, "episode/score": 0.6439409511120004, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.022065934394760234}
{"step": 189888, "time": 22110.334115982056, "episode/length": 106.0, "episode/score": 0.6849734469430189, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.016223479003798502}
{"step": 190008, "time": 22124.71615743637, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 190008, "time": 22126.692225694656, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 190008, "time": 22126.767087697983, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 190008, "time": 22127.931569576263, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 190008, "time": 22128.53612589836, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 190008, "time": 22128.95298600197, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 22128.959003925323, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 22128.964572668076, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 22128.97004008293, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 22128.97527217865, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 22128.98053431511, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190344, "time": 22167.54340004921, "episode/length": 288.0, "episode/score": 0.023939486426598933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023939486426598933}
{"step": 190648, "time": 22202.547388792038, "episode/length": 140.0, "episode/score": 0.5935202754864122, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.031020246091543413}
{"step": 190749, "time": 22214.962448596954, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.952369867369186, "train/action_min": 0.0, "train/action_std": 1.574155973279199, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.003102229033640131, "train/actor_opt_grad_steps": 46220.0, "train/actor_opt_loss": -4.49469929128712, "train/adv_mag": 0.32903428895528924, "train/adv_max": 0.16808660404626713, "train/adv_mean": 0.0008100287141005961, "train/adv_min": -0.3032003502513087, "train/adv_std": 0.012331293930494508, "train/cont_avg": 0.9962845203488372, "train/cont_loss_mean": 0.007475194961189964, "train/cont_loss_std": 0.14538619733025687, "train/cont_neg_acc": 0.6215824878243642, "train/cont_neg_loss": 1.5922414541917906, "train/cont_pos_acc": 0.9999316176702809, "train/cont_pos_loss": 0.0014382962447450345, "train/cont_pred": 0.9963759760523951, "train/cont_rate": 0.9962845203488372, "train/dyn_loss_mean": 1.0000043059504309, "train/dyn_loss_std": 8.412468312091606e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13594879231653934, "train/extr_critic_critic_opt_grad_steps": 46220.0, "train/extr_critic_critic_opt_loss": 4034.8287790697673, "train/extr_critic_mag": 0.47923408608103907, "train/extr_critic_max": 0.47923408608103907, "train/extr_critic_mean": 0.3748143247393675, "train/extr_critic_min": 0.3539577938789545, "train/extr_critic_std": 0.011655119795698759, "train/extr_return_normed_mag": 0.3379787626654603, "train/extr_return_normed_max": 0.23083073510680088, "train/extr_return_normed_mean": 0.01677183340801749, "train/extr_return_normed_min": -0.2778018311012623, "train/extr_return_normed_std": 0.01770594988104909, "train/extr_return_rate": 0.0017880936089272308, "train/extr_return_raw_mag": 0.5896832439788552, "train/extr_return_raw_max": 0.5896832439788552, "train/extr_return_raw_mean": 0.3756243619807931, "train/extr_return_raw_min": 0.08105067777079206, "train/extr_return_raw_std": 0.017705949833400028, "train/extr_reward_mag": 0.23793649174446282, "train/extr_reward_max": 0.23793649174446282, "train/extr_reward_mean": 0.0006007756895743051, "train/extr_reward_min": 1.3512234355128089e-06, "train/extr_reward_std": 0.004675663506536376, "train/image_loss_mean": 0.0802917031701221, "train/image_loss_std": 0.10435621572095294, "train/model_loss_mean": 0.6989724012308343, "train/model_loss_std": 0.23786697987207148, "train/model_opt_grad_norm": 19.637946554671885, "train/model_opt_grad_steps": 46180.34418604651, "train/model_opt_loss": 3689.978868777253, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5302.325581395349, "train/policy_entropy_mag": 1.516008077111355, "train/policy_entropy_max": 1.516008077111355, "train/policy_entropy_mean": 0.1269348703498064, "train/policy_entropy_min": 0.0646870878546737, "train/policy_entropy_std": 0.17679198869439058, "train/policy_logprob_mag": 6.551079732318257, "train/policy_logprob_max": -0.0086082783029523, "train/policy_logprob_mean": -0.12705741167761558, "train/policy_logprob_min": -6.551079732318257, "train/policy_logprob_std": 0.6724070995352989, "train/policy_randomness_mag": 0.7790740842042967, "train/policy_randomness_max": 0.7790740842042967, "train/policy_randomness_mean": 0.0652316237431626, "train/policy_randomness_min": 0.03324258906203647, "train/policy_randomness_std": 0.09085311577763669, "train/post_ent_mag": 33.9242666909861, "train/post_ent_max": 33.9242666909861, "train/post_ent_mean": 33.52149704334348, "train/post_ent_min": 33.163374381841614, "train/post_ent_std": 0.13424526927776115, "train/prior_ent_mag": 34.43696384873501, "train/prior_ent_max": 34.43696384873501, "train/prior_ent_mean": 33.568802713793374, "train/prior_ent_min": 32.478134829499, "train/prior_ent_std": 0.30413414738899053, "train/rep_loss_mean": 1.0000043059504309, "train/rep_loss_std": 8.412468312091606e-05, "train/reward_avg": 0.0004839928283323642, "train/reward_loss_mean": 0.011202899624355311, "train/reward_loss_std": 0.06475169937624488, "train/reward_max_data": 0.24285712681147595, "train/reward_max_pred": 0.09509319926417151, "train/reward_neg_acc": 0.999936382992323, "train/reward_neg_loss": 0.00936796680785889, "train/reward_pos_acc": 0.3389513114195191, "train/reward_pos_loss": 3.8824566231015023, "train/reward_pred": 0.0004211486858683963, "train/reward_rate": 0.0004996366279069768, "train_stats/mean_log_entropy": 0.08346965788183985, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.005256675183773041, "report/cont_loss_std": 0.11063142865896225, "report/cont_neg_acc": 0.800000011920929, "report/cont_neg_loss": 0.7064506411552429, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.001816076459363103, "report/cont_pred": 0.9943227171897888, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08659570664167404, "report/image_loss_std": 0.11001502722501755, "report/model_loss_mean": 0.700384259223938, "report/model_loss_std": 0.16094210743904114, "report/post_ent_mag": 33.780303955078125, "report/post_ent_max": 33.780303955078125, "report/post_ent_mean": 33.393638610839844, "report/post_ent_min": 33.0562629699707, "report/post_ent_std": 0.13704469799995422, "report/prior_ent_mag": 34.19380187988281, "report/prior_ent_max": 34.19380187988281, "report/prior_ent_mean": 33.40944290161133, "report/prior_ent_min": 32.06682586669922, "report/prior_ent_std": 0.34149184823036194, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00019001011969521642, "report/reward_loss_mean": 0.008531870320439339, "report/reward_loss_std": 0.013912037946283817, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.023943781852722168, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008531870320439339, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0003725150600075722, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.043968986719846725, "eval/cont_loss_std": 0.7074622511863708, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.020830154418945, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0009224697714671493, "eval/cont_pred": 0.9990957975387573, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24672114849090576, "eval/image_loss_std": 0.16961513459682465, "eval/model_loss_mean": 0.891876220703125, "eval/model_loss_std": 0.7312688827514648, "eval/post_ent_mag": 33.81944274902344, "eval/post_ent_max": 33.81944274902344, "eval/post_ent_mean": 33.35392761230469, "eval/post_ent_min": 32.986656188964844, "eval/post_ent_std": 0.1501939296722412, "eval/prior_ent_mag": 34.26823425292969, "eval/prior_ent_max": 34.26823425292969, "eval/prior_ent_mean": 33.39596176147461, "eval/prior_ent_min": 32.04841995239258, "eval/prior_ent_std": 0.34414756298065186, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001186116598546505, "eval/reward_loss_std": 0.0017035657074302435, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.006575822830200195, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001186116598546505, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002139155985787511, "eval/reward_rate": 0.0, "replay/size": 190245.0, "replay/inserts": 8632.0, "replay/samples": 34528.0, "replay/insert_wait_avg": 1.5445281445040981e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.477510406310299e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 46800.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0108040278345655e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.335186958313, "timer/env.step_count": 1079.0, "timer/env.step_total": 9.980620384216309, "timer/env.step_frac": 0.009977276131377583, "timer/env.step_avg": 0.009249879874157839, "timer/env.step_min": 0.00815272331237793, "timer/env.step_max": 0.03525996208190918, "timer/replay._sample_count": 34528.0, "timer/replay._sample_total": 16.444286584854126, "timer/replay._sample_frac": 0.016438776521353546, "timer/replay._sample_avg": 0.00047625945855115054, "timer/replay._sample_min": 0.00036454200744628906, "timer/replay._sample_max": 0.0285794734954834, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1368.0, "timer/agent.policy_total": 13.084605693817139, "timer/agent.policy_frac": 0.01308022137420066, "timer/agent.policy_avg": 0.009564770244018377, "timer/agent.policy_min": 0.008617877960205078, "timer/agent.policy_max": 0.02660679817199707, "timer/dataset_train_count": 2158.0, "timer/dataset_train_total": 0.369948148727417, "timer/dataset_train_frac": 0.00036982418848256895, "timer/dataset_train_avg": 0.00017143102350668073, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.0011794567108154297, "timer/agent.train_count": 2158.0, "timer/agent.train_total": 962.6428248882294, "timer/agent.train_frac": 0.9623202676847812, "timer/agent.train_avg": 0.4460810124597912, "timer/agent.train_min": 0.4328782558441162, "timer/agent.train_max": 0.5667836666107178, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4689509868621826, "timer/agent.report_frac": 0.00046879385327642706, "timer/agent.report_avg": 0.2344754934310913, "timer/agent.report_min": 0.22429776191711426, "timer/agent.report_max": 0.24465322494506836, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.026901376724266e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 8.628989305854306}
{"step": 191056, "time": 22250.148918628693, "episode/length": 288.0, "episode/score": 0.019580197071434213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019580197071434213}
{"step": 191088, "time": 22253.829884529114, "episode/length": 288.0, "episode/score": 0.02533515302022238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02533515302022238}
{"step": 191352, "time": 22284.16158556938, "episode/length": 288.0, "episode/score": 0.024619230210902288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024619230210902288}
{"step": 191496, "time": 22300.70520424843, "episode/length": 288.0, "episode/score": 0.03789623756176752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03789623756176752}
{"step": 191944, "time": 22352.15779232979, "episode/length": 288.0, "episode/score": 0.025245765021509214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025245765021509214}
{"step": 192024, "time": 22361.343572854996, "episode/length": 83.0, "episode/score": 0.7546608844219236, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.014035831185196912}
{"step": 192200, "time": 22381.61248731613, "episode/length": 288.0, "episode/score": 0.013123858306926195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013123858306926195}
{"step": 192656, "time": 22433.88518834114, "episode/length": 288.0, "episode/score": 0.010413241698188358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010413241698188358}
{"step": 192816, "time": 22452.267466545105, "episode/length": 108.0, "episode/score": 0.6792598586876011, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.016759826667566813}
{"step": 192960, "time": 22468.79778623581, "episode/length": 288.0, "episode/score": 0.020774970817228677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020774970817228677}
{"step": 193368, "time": 22515.945325613022, "episode/length": 288.0, "episode/score": 0.027593854229792214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027593854229792214}
{"step": 193400, "time": 22519.650900363922, "episode/length": 288.0, "episode/score": 0.030006596339887892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030006596339887892}
{"step": 193464, "time": 22527.0818567276, "episode/length": 11.0, "episode/score": 0.9710428517548735, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0054178644907096896}
{"step": 193808, "time": 22567.02573442459, "episode/length": 288.0, "episode/score": 0.03200944805001882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03200944805001882}
{"step": 194336, "time": 22627.925493717194, "episode/length": 288.0, "episode/score": 0.01172920523515586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01172920523515586}
{"step": 194512, "time": 22648.15137219429, "episode/length": 288.0, "episode/score": 0.010137764397541105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010137764397541105}
{"step": 194968, "time": 22700.98546409607, "episode/length": 288.0, "episode/score": 0.018065042719513258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018065042719513258}
{"step": 195128, "time": 22719.66768860817, "episode/length": 288.0, "episode/score": 0.010641154289714905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010641154289714905}
{"step": 195272, "time": 22736.3109061718, "episode/length": 288.0, "episode/score": 0.02694550138323848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02694550138323848}
{"step": 195288, "time": 22738.1639919281, "episode/length": 96.0, "episode/score": 0.7140013008779533, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.014001330930568656}
{"step": 195384, "time": 22749.259459495544, "episode/length": 51.0, "episode/score": 0.8547690316219132, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.014144036383299863}
{"step": 195712, "time": 22786.909611225128, "episode/length": 288.0, "episode/score": 0.007566521497096801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.007566521497096801}
{"step": 195776, "time": 22794.287411928177, "episode/length": 288.0, "episode/score": 0.017192195518759945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017192195518759945}
{"step": 196120, "time": 22833.954916715622, "episode/length": 288.0, "episode/score": 0.007520585264273905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.007520585264273905}
{"step": 196408, "time": 22867.059638261795, "episode/length": 78.0, "episode/score": 0.7752114489891255, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.018961410828183034}
{"step": 196560, "time": 22884.51768374443, "episode/length": 54.0, "episode/score": 0.8404317652612008, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.009181746180729533}
{"step": 196648, "time": 22895.080733060837, "episode/length": 288.0, "episode/score": 0.014200260554957822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014200260554957822}
{"step": 196800, "time": 22912.541158676147, "episode/length": 135.0, "episode/score": 0.5936577012303133, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.01553267183544449}
{"step": 197120, "time": 22949.351011037827, "episode/length": 58.0, "episode/score": 0.8400790037369461, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.02132899802677457}
{"step": 197248, "time": 22964.112466812134, "episode/length": 85.0, "episode/score": 0.7573780631466889, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.023003039805416847}
{"step": 197352, "time": 22976.06351542473, "episode/length": 28.0, "episode/score": 0.9249917854835985, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.012491738300468569}
{"step": 197440, "time": 22986.26804637909, "episode/length": 288.0, "episode/score": 0.008432016869505787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.008432016869505787}
{"step": 197584, "time": 23002.82688474655, "episode/length": 288.0, "episode/score": 0.037404338566148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037404338566148}
{"step": 197600, "time": 23004.6810901165, "episode/length": 288.0, "episode/score": 0.013868571569560117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013868571569560117}
{"step": 197656, "time": 23011.136255979538, "episode/length": 37.0, "episode/score": 0.8943426575517606, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.009967696498506484}
{"step": 197696, "time": 23015.81640601158, "episode/length": 288.0, "episode/score": 0.010626058229604496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010626058229604496}
{"step": 197944, "time": 23044.38514494896, "episode/length": 44.0, "episode/score": 0.8691401364045532, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.006640124701903005}
{"step": 198184, "time": 23071.93891119957, "episode/length": 60.0, "episode/score": 0.8298694160035893, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.01736938660872056}
{"step": 198352, "time": 23091.186626434326, "episode/length": 86.0, "episode/score": 0.7497426263989837, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.018492631160370365}
{"step": 198400, "time": 23096.73322534561, "episode/length": 56.0, "episode/score": 0.8420689048996337, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.017068917635469916}
{"step": 198720, "time": 23133.85040831566, "episode/length": 288.0, "episode/score": 0.01960939900533276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01960939900533276}
{"step": 199112, "time": 23179.317712545395, "episode/length": 288.0, "episode/score": 0.008906149677955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.008906149677955}
{"step": 199304, "time": 23201.339096069336, "episode/length": 232.0, "episode/score": 0.296276112517603, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.021276094886502506}
{"step": 199417, "time": 23215.245595932007, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8953353952152936, "train/action_min": 0.0, "train/action_std": 1.6150688290046658, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.003081337547182934, "train/actor_opt_grad_steps": 48380.0, "train/actor_opt_loss": -5.703303396753315, "train/adv_mag": 0.3306922791740312, "train/adv_max": 0.14008906318844738, "train/adv_mean": 0.0002929036613503979, "train/adv_min": -0.30333935349218305, "train/adv_std": 0.010975643438780637, "train/cont_avg": 0.9962332589285714, "train/cont_loss_mean": 0.007965524227053683, "train/cont_loss_std": 0.14678276415585972, "train/cont_neg_acc": 0.6071875769067818, "train/cont_neg_loss": 1.726634279808397, "train/cont_pos_acc": 0.999941220206599, "train/cont_pos_loss": 0.001575725568857576, "train/cont_pred": 0.9962001915351586, "train/cont_rate": 0.9962332589285714, "train/dyn_loss_mean": 1.00000702510781, "train/dyn_loss_std": 0.00015617531835861195, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1294385100830741, "train/extr_critic_critic_opt_grad_steps": 48380.0, "train/extr_critic_critic_opt_loss": 4510.082248951433, "train/extr_critic_mag": 0.4493881095938968, "train/extr_critic_max": 0.4493881095938968, "train/extr_critic_mean": 0.3844112407776617, "train/extr_critic_min": 0.3611311324730447, "train/extr_critic_std": 0.011273899956816626, "train/extr_return_normed_mag": 0.33244983158353286, "train/extr_return_normed_max": 0.1770034899360024, "train/extr_return_normed_mean": 0.014873762065137002, "train/extr_return_normed_min": -0.28823130416430637, "train/extr_return_normed_std": 0.01622941621798112, "train/extr_return_rate": 0.0010386665320439128, "train/extr_return_raw_mag": 0.5468338502716908, "train/extr_return_raw_max": 0.5468338502716908, "train/extr_return_raw_mean": 0.3847041425342384, "train/extr_return_raw_min": 0.08159905672073364, "train/extr_return_raw_std": 0.01622941619008436, "train/extr_reward_mag": 0.23657410815014818, "train/extr_reward_max": 0.23657410815014818, "train/extr_reward_mean": 0.0005451710612383297, "train/extr_reward_min": 1.1855006767308107e-06, "train/extr_reward_std": 0.004023711828376523, "train/image_loss_mean": 0.07768665029225262, "train/image_loss_std": 0.10348868843871876, "train/model_loss_mean": 0.6967333890326012, "train/model_loss_std": 0.2341982715415515, "train/model_opt_grad_norm": 18.984509490052677, "train/model_opt_grad_steps": 48338.24884792627, "train/model_opt_loss": 3547.1682500180013, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5115.207373271889, "train/policy_entropy_mag": 1.4855859307100148, "train/policy_entropy_max": 1.4855859307100148, "train/policy_entropy_mean": 0.13504627710937905, "train/policy_entropy_min": 0.0646868814040439, "train/policy_entropy_std": 0.1902923820205548, "train/policy_logprob_mag": 6.551079772035098, "train/policy_logprob_max": -0.008608246496814187, "train/policy_logprob_mean": -0.13529200436470146, "train/policy_logprob_min": -6.551079772035098, "train/policy_logprob_std": 0.681359550095923, "train/policy_randomness_mag": 0.7634401925697855, "train/policy_randomness_max": 0.7634401925697855, "train/policy_randomness_mean": 0.06940006157426241, "train/policy_randomness_min": 0.03324248344736165, "train/policy_randomness_std": 0.09779094475480268, "train/post_ent_mag": 34.101443963116765, "train/post_ent_max": 34.101443963116765, "train/post_ent_mean": 33.667284073368194, "train/post_ent_min": 33.29117941087292, "train/post_ent_std": 0.14432778621461534, "train/prior_ent_mag": 34.28702782485892, "train/prior_ent_max": 34.28702782485892, "train/prior_ent_mean": 33.41862362980293, "train/prior_ent_min": 32.32702437194261, "train/prior_ent_std": 0.3016148752743198, "train/rep_loss_mean": 1.00000702510781, "train/rep_loss_std": 0.00015617531835861195, "train/reward_avg": 0.0005038897191042356, "train/reward_loss_mean": 0.011076976940001485, "train/reward_loss_std": 0.059249115725850454, "train/reward_max_data": 0.23754808876431688, "train/reward_max_pred": 0.10671508696771437, "train/reward_neg_acc": 0.9999054409391869, "train/reward_neg_loss": 0.009287266627228754, "train/reward_pos_acc": 0.3995983938136733, "train/reward_pos_loss": 3.48849204721221, "train/reward_pred": 0.00046725636766579705, "train/reward_rate": 0.0005130328341013824, "train_stats/mean_log_entropy": 0.08155722006462342, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.024230429902672768, "report/cont_loss_std": 0.34725069999694824, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 3.3968193531036377, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.001016939408145845, "report/cont_pred": 0.9969074726104736, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0650215893983841, "report/image_loss_std": 0.10304093360900879, "report/model_loss_mean": 0.7027685642242432, "report/model_loss_std": 0.3991055488586426, "report/post_ent_mag": 33.85236358642578, "report/post_ent_max": 33.85236358642578, "report/post_ent_mean": 33.430633544921875, "report/post_ent_min": 33.06501770019531, "report/post_ent_std": 0.13528375327587128, "report/prior_ent_mag": 33.895790100097656, "report/prior_ent_max": 33.895790100097656, "report/prior_ent_mean": 33.16552734375, "report/prior_ent_min": 31.847599029541016, "report/prior_ent_std": 0.2879629135131836, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0010167475556954741, "report/reward_loss_mean": 0.013516522012650967, "report/reward_loss_std": 0.10408611595630646, "report/reward_max_data": 0.6816071271896362, "report/reward_max_pred": 0.11763167381286621, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00981675460934639, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 1.9040980339050293, "report/reward_pred": 0.0004944383399561048, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03712175786495209, "eval/cont_loss_std": 0.6602505445480347, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.208338737487793, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0013591174501925707, "eval/cont_pred": 0.9987876415252686, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22887101769447327, "eval/image_loss_std": 0.1675102412700653, "eval/model_loss_mean": 0.8676317930221558, "eval/model_loss_std": 0.6857035160064697, "eval/post_ent_mag": 33.89707946777344, "eval/post_ent_max": 33.89707946777344, "eval/post_ent_mean": 33.43888854980469, "eval/post_ent_min": 33.06208038330078, "eval/post_ent_std": 0.14523465931415558, "eval/prior_ent_mag": 33.98158264160156, "eval/prior_ent_max": 33.98158264160156, "eval/prior_ent_mean": 33.199554443359375, "eval/prior_ent_min": 32.12005615234375, "eval/prior_ent_std": 0.30457058548927307, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0016389982774853706, "eval/reward_loss_std": 0.005184898618608713, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.039794206619262695, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0016389982774853706, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0003089616075158119, "eval/reward_rate": 0.0, "replay/size": 198913.0, "replay/inserts": 8668.0, "replay/samples": 34672.0, "replay/insert_wait_avg": 1.5373982533805647e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.461961671400577e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 46800.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2715890407562, "timer/env.step_count": 1084.0, "timer/env.step_total": 10.098433017730713, "timer/env.step_frac": 0.010095691138658594, "timer/env.step_avg": 0.00931589761783276, "timer/env.step_min": 0.008140802383422852, "timer/env.step_max": 0.03341078758239746, "timer/replay._sample_count": 34672.0, "timer/replay._sample_total": 16.649296760559082, "timer/replay._sample_frac": 0.016644776221751416, "timer/replay._sample_avg": 0.0004801942997392444, "timer/replay._sample_min": 0.0003724098205566406, "timer/replay._sample_max": 0.026115894317626953, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1084.0, "timer/agent.policy_total": 10.624504804611206, "timer/agent.policy_frac": 0.010621620088999957, "timer/agent.policy_avg": 0.00980120369429078, "timer/agent.policy_min": 0.008827686309814453, "timer/agent.policy_max": 0.035802602767944336, "timer/dataset_train_count": 2167.0, "timer/dataset_train_total": 0.37662220001220703, "timer/dataset_train_frac": 0.0003765199413225177, "timer/dataset_train_avg": 0.00017379889248371344, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.0007677078247070312, "timer/agent.train_count": 2167.0, "timer/agent.train_total": 967.1623361110687, "timer/agent.train_frac": 0.9668997367390603, "timer/agent.train_avg": 0.446313952981573, "timer/agent.train_min": 0.43335437774658203, "timer/agent.train_max": 0.5704605579376221, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47507357597351074, "timer/agent.report_frac": 0.0004749445862289245, "timer/agent.report_avg": 0.23753678798675537, "timer/agent.report_min": 0.2315356731414795, "timer/agent.report_max": 0.24353790283203125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.0985999825233714e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 8.665525717197038}
{"step": 199560, "time": 23231.589676380157, "episode/length": 288.0, "episode/score": 0.03460075281122954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03460075281122954}
{"step": 199768, "time": 23255.5579226017, "episode/length": 81.0, "episode/score": 0.761285632446743, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.01441064458595065}
{"step": 199912, "time": 23272.14578127861, "episode/length": 288.0, "episode/score": 0.025127128925191755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025127128925191755}
{"step": 200096, "time": 23294.59010744095, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 200096, "time": 23294.731358766556, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 200096, "time": 23295.30818772316, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 200096, "time": 23296.175190925598, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 200096, "time": 23298.98509645462, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 23298.991512060165, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 23298.996989011765, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 23299.002351522446, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 23299.007746696472, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200496, "time": 23345.13974428177, "episode/length": 288.0, "episode/score": 0.02366071833012029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02366071833012029}
{"step": 200664, "time": 23364.428946971893, "episode/length": 288.0, "episode/score": 0.03728944878770335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03728944878770335}
{"step": 200712, "time": 23369.94834947586, "episode/length": 288.0, "episode/score": 0.02040172704903398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02040172704903398}
{"step": 200912, "time": 23393.13102579117, "episode/length": 168.0, "episode/score": 0.5051147070730053, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.030114705873927505}
{"step": 201032, "time": 23407.041286706924, "episode/length": 288.0, "episode/score": 0.02913367223465002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02913367223465002}
{"step": 201088, "time": 23413.4958384037, "episode/length": 73.0, "episode/score": 0.7898068194196526, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.01793181571764535}
{"step": 201344, "time": 23443.023854494095, "episode/length": 31.0, "episode/score": 0.9147437115673824, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.01161869485014222}
{"step": 201616, "time": 23474.422552108765, "episode/length": 288.0, "episode/score": 0.039388922899775025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039388922899775025}
{"step": 202080, "time": 23528.140205860138, "episode/length": 288.0, "episode/score": 0.018080295106187805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018080295106187805}
{"step": 202224, "time": 23544.679295778275, "episode/length": 288.0, "episode/score": 0.027077843876952556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027077843876952556}
{"step": 202976, "time": 23631.443890571594, "episode/length": 288.0, "episode/score": 0.016813936499204374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.016813936499204374}
{"step": 203024, "time": 23636.961085796356, "episode/length": 288.0, "episode/score": 0.03922360053320517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03922360053320517}
{"step": 203224, "time": 23660.009986400604, "episode/length": 288.0, "episode/score": 0.031990538150580505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031990538150580505}
{"step": 203344, "time": 23673.9015481472, "episode/length": 288.0, "episode/score": 0.050105726140316165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050105726140316165}
{"step": 203656, "time": 23709.918786764145, "episode/length": 288.0, "episode/score": 0.05340683924401901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05340683924401901}
{"step": 203872, "time": 23734.81364917755, "episode/length": 65.0, "episode/score": 0.8220948910252446, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.025219911165095255}
{"step": 203928, "time": 23741.25901865959, "episode/length": 288.0, "episode/score": 0.04866225304397176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04866225304397176}
{"step": 204392, "time": 23794.6933927536, "episode/length": 288.0, "episode/score": 0.036556450612465596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036556450612465596}
{"step": 204536, "time": 23811.234986305237, "episode/length": 288.0, "episode/score": 0.02492635501891982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02492635501891982}
{"step": 205288, "time": 23898.527856349945, "episode/length": 288.0, "episode/score": 0.03621883381816815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03621883381816815}
{"step": 205336, "time": 23904.049282073975, "episode/length": 288.0, "episode/score": 0.06500742361819789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06500742361819789}
{"step": 205528, "time": 23926.192447185516, "episode/length": 199.0, "episode/score": 0.4416022146438934, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.06347720388711764}
{"step": 205536, "time": 23927.11551117897, "episode/length": 288.0, "episode/score": 0.05212380550017315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05212380550017315}
{"step": 205968, "time": 23976.907758951187, "episode/length": 288.0, "episode/score": 0.06801042240792299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06801042240792299}
{"step": 206056, "time": 23986.978099822998, "episode/length": 65.0, "episode/score": 0.823991455205487, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.027116456020394253}
{"step": 206136, "time": 23996.156510829926, "episode/length": 74.0, "episode/score": 0.8014861738540731, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.032736133294974934}
{"step": 206184, "time": 24001.712239980698, "episode/length": 288.0, "episode/score": 0.07227438820530097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07227438820530097}
{"step": 206704, "time": 24061.50820350647, "episode/length": 288.0, "episode/score": 0.06599538558435825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06599538558435825}
{"step": 206848, "time": 24078.17131137848, "episode/length": 288.0, "episode/score": 0.03991384781227225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03991384781227225}
{"step": 206856, "time": 24079.106021642685, "episode/length": 195.0, "episode/score": 0.435624349562886, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.04499935602393634}
{"step": 207240, "time": 24123.49272608757, "episode/length": 237.0, "episode/score": 0.3168127495658837, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.05743774442032645}
{"step": 208029, "time": 24215.45318031311, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0501163926235466, "train/action_min": 0.0, "train/action_std": 1.647809757188309, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0033019559363141483, "train/actor_opt_grad_steps": 50540.0, "train/actor_opt_loss": -5.601906226956567, "train/adv_mag": 0.3261013951412467, "train/adv_max": 0.15699779280396395, "train/adv_mean": 0.0012096303606635639, "train/adv_min": -0.28980321163354916, "train/adv_std": 0.011999234115315038, "train/cont_avg": 0.9962981468023255, "train/cont_loss_mean": 0.008711617447565809, "train/cont_loss_std": 0.15985695335764957, "train/cont_neg_acc": 0.5716316935151674, "train/cont_neg_loss": 1.8591483127171564, "train/cont_pos_acc": 0.9999133384504983, "train/cont_pos_loss": 0.0017099629079132493, "train/cont_pred": 0.9962720926417861, "train/cont_rate": 0.9962981468023255, "train/dyn_loss_mean": 1.0000017753867216, "train/dyn_loss_std": 5.680383629772032e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10900872850487399, "train/extr_critic_critic_opt_grad_steps": 50540.0, "train/extr_critic_critic_opt_loss": 9441.63370162609, "train/extr_critic_mag": 0.5075199482052826, "train/extr_critic_max": 0.5075199482052826, "train/extr_critic_mean": 0.41957239896752113, "train/extr_critic_min": 0.38212082607801573, "train/extr_critic_std": 0.013167320770146542, "train/extr_return_normed_mag": 0.3362117625946222, "train/extr_return_normed_max": 0.20855691294337428, "train/extr_return_normed_mean": 0.01966271575020496, "train/extr_return_normed_min": -0.2662920953229416, "train/extr_return_normed_std": 0.018012974367931832, "train/extr_return_rate": 0.018608891410241444, "train/extr_return_raw_mag": 0.6096762101317561, "train/extr_return_raw_max": 0.6096762101317561, "train/extr_return_raw_mean": 0.4207820368367572, "train/extr_return_raw_min": 0.13482720228128656, "train/extr_return_raw_std": 0.018012974476225154, "train/extr_reward_mag": 0.2499393429867057, "train/extr_reward_max": 0.2499393429867057, "train/extr_reward_mean": 0.0005521513213035326, "train/extr_reward_min": 1.5297601389330487e-06, "train/extr_reward_std": 0.004265951399615597, "train/image_loss_mean": 0.07868481079159781, "train/image_loss_std": 0.10394616605237472, "train/model_loss_mean": 0.6991941446481749, "train/model_loss_std": 0.26301898776098737, "train/model_opt_grad_norm": 19.345057540716127, "train/model_opt_grad_steps": 50496.24186046512, "train/model_opt_loss": 3772.1600449672965, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5395.3488372093025, "train/policy_entropy_mag": 1.5427668455035188, "train/policy_entropy_max": 1.5427668455035188, "train/policy_entropy_mean": 0.12784213960863824, "train/policy_entropy_min": 0.06468676813813143, "train/policy_entropy_std": 0.17711556948894677, "train/policy_logprob_mag": 6.551079743407493, "train/policy_logprob_max": -0.00860826840061088, "train/policy_logprob_mean": -0.12785087033759715, "train/policy_logprob_min": -6.551079743407493, "train/policy_logprob_std": 0.6716526167337284, "train/policy_randomness_mag": 0.792825371997301, "train/policy_randomness_max": 0.792825371997301, "train/policy_randomness_mean": 0.0656978675445845, "train/policy_randomness_min": 0.03324242404033972, "train/policy_randomness_std": 0.0910194032414015, "train/post_ent_mag": 33.753747363423194, "train/post_ent_max": 33.753747363423194, "train/post_ent_mean": 33.316154763864915, "train/post_ent_min": 32.931688344201376, "train/post_ent_std": 0.1462101476483567, "train/prior_ent_mag": 33.743634583229245, "train/prior_ent_max": 33.743634583229245, "train/prior_ent_mean": 33.01462737682254, "train/prior_ent_min": 32.17363383270973, "train/prior_ent_std": 0.23413120813147967, "train/rep_loss_mean": 1.0000017753867216, "train/rep_loss_std": 5.680383629772032e-05, "train/reward_avg": 0.0006011009550664228, "train/reward_loss_mean": 0.011796627732990093, "train/reward_loss_std": 0.08137474770462791, "train/reward_max_data": 0.3033458145833466, "train/reward_max_pred": 0.10065291870472043, "train/reward_neg_acc": 0.9999181786248851, "train/reward_neg_loss": 0.009126562661989484, "train/reward_pos_acc": 0.2581329569958224, "train/reward_pos_loss": 4.118376711660092, "train/reward_pred": 0.0004890541069556114, "train/reward_rate": 0.0006631540697674418, "train_stats/mean_log_entropy": 0.08728984589962398, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.008023513481020927, "report/cont_loss_std": 0.22313888370990753, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 1.786208987236023, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0010502379154786468, "report/cont_pred": 0.9960783123970032, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06745733320713043, "report/image_loss_std": 0.10253804177045822, "report/model_loss_mean": 0.6882194876670837, "report/model_loss_std": 0.24690692126750946, "report/post_ent_mag": 33.570152282714844, "report/post_ent_max": 33.570152282714844, "report/post_ent_mean": 33.1623649597168, "report/post_ent_min": 32.776519775390625, "report/post_ent_std": 0.1358841359615326, "report/prior_ent_mag": 33.67346954345703, "report/prior_ent_max": 33.67346954345703, "report/prior_ent_mean": 32.77130126953125, "report/prior_ent_min": 31.985164642333984, "report/prior_ent_std": 0.24623335897922516, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0003027640050277114, "report/reward_loss_mean": 0.012738618068397045, "report/reward_loss_std": 0.01695251278579235, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0068579912185668945, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01273861899971962, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0003933776170015335, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0323697105050087, "eval/cont_loss_std": 0.5768503546714783, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.43508529663086, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0018034526146948338, "eval/cont_pred": 0.9984102249145508, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2754667401313782, "eval/image_loss_std": 0.17879901826381683, "eval/model_loss_mean": 0.9095751047134399, "eval/model_loss_std": 0.6005609631538391, "eval/post_ent_mag": 33.62541580200195, "eval/post_ent_max": 33.62541580200195, "eval/post_ent_mean": 33.18468475341797, "eval/post_ent_min": 32.768123626708984, "eval/post_ent_std": 0.14268989861011505, "eval/prior_ent_mag": 33.59150695800781, "eval/prior_ent_max": 33.59150695800781, "eval/prior_ent_mean": 32.72153091430664, "eval/prior_ent_min": 31.97124671936035, "eval/prior_ent_std": 0.2344588339328766, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0017386428080499172, "eval/reward_loss_std": 0.002557705622166395, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.012173056602478027, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0017386428080499172, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00031061144545674324, "eval/reward_rate": 0.0, "replay/size": 207525.0, "replay/inserts": 8612.0, "replay/samples": 34448.0, "replay/insert_wait_avg": 1.4605491149165272e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.602222232668e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 49112.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0604058169988612e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1950137615204, "timer/env.step_count": 1076.0, "timer/env.step_total": 9.99111533164978, "timer/env.step_frac": 0.009989167306558872, "timer/env.step_avg": 0.009285423170678235, "timer/env.step_min": 0.008262872695922852, "timer/env.step_max": 0.034487009048461914, "timer/replay._sample_count": 34448.0, "timer/replay._sample_total": 16.45940351486206, "timer/replay._sample_frac": 0.01645619433050536, "timer/replay._sample_avg": 0.0004778043286943236, "timer/replay._sample_min": 0.000339508056640625, "timer/replay._sample_max": 0.010267257690429688, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1365.0, "timer/agent.policy_total": 13.675718069076538, "timer/agent.policy_frac": 0.01367305163584557, "timer/agent.policy_avg": 0.010018841076246548, "timer/agent.policy_min": 0.008710622787475586, "timer/agent.policy_max": 0.09956550598144531, "timer/dataset_train_count": 2153.0, "timer/dataset_train_total": 0.3957362174987793, "timer/dataset_train_frac": 0.00039565905853749427, "timer/dataset_train_avg": 0.0001838068822567484, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.02567148208618164, "timer/agent.train_count": 2153.0, "timer/agent.train_total": 961.8882694244385, "timer/agent.train_frac": 0.9617007245486874, "timer/agent.train_avg": 0.44676649764256315, "timer/agent.train_min": 0.4248638153076172, "timer/agent.train_max": 0.5896143913269043, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4630608558654785, "timer/agent.report_frac": 0.0004629705702331041, "timer/agent.report_avg": 0.23153042793273926, "timer/agent.report_min": 0.22161650657653809, "timer/agent.report_max": 0.24144434928894043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.955813956461371e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 8.610202531867573}
{"step": 208280, "time": 24244.239951133728, "episode/length": 288.0, "episode/score": 0.046616007634384005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046616007634384005}
{"step": 208368, "time": 24254.35670518875, "episode/length": 288.0, "episode/score": 0.06357924885264765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06357924885264765}
{"step": 208448, "time": 24263.54606628418, "episode/length": 288.0, "episode/score": 0.07521118138674865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07521118138674865}
{"step": 208496, "time": 24269.063011169434, "episode/length": 288.0, "episode/score": 0.06395057209510924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06395057209510924}
{"step": 208744, "time": 24297.732493638992, "episode/length": 57.0, "episode/score": 0.8487487954478183, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.026873804970591664}
{"step": 208880, "time": 24313.491308689117, "episode/length": 63.0, "episode/score": 0.826101259311713, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.02297621212858303}
{"step": 209016, "time": 24329.154094934464, "episode/length": 288.0, "episode/score": 0.055440458466932796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055440458466932796}
{"step": 209160, "time": 24345.823137760162, "episode/length": 288.0, "episode/score": 0.05250082561099134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05250082561099134}
{"step": 209168, "time": 24346.744490385056, "episode/length": 288.0, "episode/score": 0.049273465172973374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049273465172973374}
{"step": 209280, "time": 24359.63456106186, "episode/length": 103.0, "episode/score": 0.7041751590144258, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.026050111831295908}
{"step": 209552, "time": 24390.98292517662, "episode/length": 288.0, "episode/score": 0.07115864834105423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07115864834105423}
{"step": 209792, "time": 24418.756465673447, "episode/length": 29.0, "episode/score": 0.9231438409501038, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.013768799634306106}
{"step": 210080, "time": 24452.993627548218, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 210080, "time": 24453.218948841095, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 210080, "time": 24454.837249040604, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 210080, "time": 24455.127007246017, "eval_episode/length": 186.0, "eval_episode/score": 0.41874998807907104, "eval_episode/reward_rate": 0.0053475935828877}
{"step": 210080, "time": 24456.49158668518, "eval_episode/length": 267.0, "eval_episode/score": 0.16562500596046448, "eval_episode/reward_rate": 0.0037313432835820895}
{"step": 210080, "time": 24456.770750045776, "eval_episode/length": 283.0, "eval_episode/score": 0.11562500149011612, "eval_episode/reward_rate": 0.0035211267605633804}
{"step": 210080, "time": 24456.859272241592, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 24456.86518383026, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 24456.87073659897, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210568, "time": 24513.088923215866, "episode/length": 193.0, "episode/score": 0.4445428071718993, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.04766781429651701}
{"step": 210808, "time": 24540.894144058228, "episode/length": 288.0, "episode/score": 0.061292021346673664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061292021346673664}
{"step": 210928, "time": 24554.898865699768, "episode/length": 205.0, "episode/score": 0.4214236676938867, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.062048668858039946}
{"step": 211056, "time": 24569.599214076996, "episode/length": 288.0, "episode/score": 0.05455693689924601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05455693689924601}
{"step": 211192, "time": 24585.304955005646, "episode/length": 288.0, "episode/score": 0.06195564040598356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06195564040598356}
{"step": 211472, "time": 24617.551294326782, "episode/length": 288.0, "episode/score": 0.06300100360130045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06300100360130045}
{"step": 211480, "time": 24618.492673158646, "episode/length": 288.0, "episode/score": 0.06574211472440084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06574211472440084}
{"step": 211520, "time": 24623.092787981033, "episode/length": 118.0, "episode/score": 0.6667886421059848, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.035538589625957684}
{"step": 211672, "time": 24640.666243076324, "episode/length": 107.0, "episode/score": 0.693958802690986, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.02833382734775114}
{"step": 212104, "time": 24690.461138010025, "episode/length": 288.0, "episode/score": 0.06524480746952577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06524480746952577}
{"step": 212424, "time": 24727.42250776291, "episode/length": 112.0, "episode/score": 0.677770645409737, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.027770670066502134}
{"step": 212456, "time": 24731.10038280487, "episode/length": 157.0, "episode/score": 0.5514607101138154, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.04208573477058053}
{"step": 212712, "time": 24760.617530345917, "episode/length": 206.0, "episode/score": 0.4101063965258618, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.05385639412770615}
{"step": 213240, "time": 24821.770359039307, "episode/length": 288.0, "episode/score": 0.062165584890749415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062165584890749415}
{"step": 213784, "time": 24884.420326948166, "episode/length": 288.0, "episode/score": 0.07718620153946176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07718620153946176}
{"step": 213792, "time": 24885.34387731552, "episode/length": 288.0, "episode/score": 0.07188615664131248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07188615664131248}
{"step": 213984, "time": 24907.47553062439, "episode/length": 288.0, "episode/score": 0.06509416216294994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06509416216294994}
{"step": 214152, "time": 24926.78590798378, "episode/length": 179.0, "episode/score": 0.49137639058915283, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.05075138512927424}
{"step": 214416, "time": 24957.55247235298, "episode/length": 288.0, "episode/score": 0.051648690335923675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051648690335923675}
{"step": 214736, "time": 24994.7570912838, "episode/length": 288.0, "episode/score": 0.0753377910485824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0753377910485824}
{"step": 214768, "time": 24998.449667692184, "episode/length": 288.0, "episode/score": 0.06910114357208386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06910114357208386}
{"step": 215080, "time": 25034.376039505005, "episode/length": 160.0, "episode/score": 0.5420799724773815, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.04207994308251273}
{"step": 215192, "time": 25047.25079202652, "episode/length": 52.0, "episode/score": 0.8529370967011118, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.015437106223885166}
{"step": 215288, "time": 25058.374398469925, "episode/length": 25.0, "episode/score": 0.93415507297982, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.012280058660735449}
{"step": 215312, "time": 25061.125149965286, "episode/length": 144.0, "episode/score": 0.5886259008630077, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.03862588076390239}
{"step": 215552, "time": 25088.815692424774, "episode/length": 288.0, "episode/score": 0.04560849105342868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04560849105342868}
{"step": 215760, "time": 25112.857043027878, "episode/length": 25.0, "episode/score": 0.9321375853089648, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.01026260544881552}
{"step": 216096, "time": 25151.906497001648, "episode/length": 288.0, "episode/score": 0.03187341348109385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03187341348109385}
{"step": 216296, "time": 25174.96026611328, "episode/length": 288.0, "episode/score": 0.05067289119256202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05067289119256202}
{"step": 216641, "time": 25215.568342208862, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.083655180754485, "train/action_min": 0.0, "train/action_std": 1.7458640955112599, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.003212858105177508, "train/actor_opt_grad_steps": 52695.0, "train/actor_opt_loss": -5.328048677632102, "train/adv_mag": 0.32751227142634215, "train/adv_max": 0.1513223740513678, "train/adv_mean": 0.0010121451885433325, "train/adv_min": -0.28576853526411233, "train/adv_std": 0.01036967716128048, "train/cont_avg": 0.9961073133680556, "train/cont_loss_mean": 0.009403035088595331, "train/cont_loss_std": 0.16642602669566664, "train/cont_neg_acc": 0.5534596544616099, "train/cont_neg_loss": 1.9064534939284534, "train/cont_pos_acc": 0.9999092190905854, "train/cont_pos_loss": 0.001785423927045755, "train/cont_pred": 0.9961823404387191, "train/cont_rate": 0.9961073133680556, "train/dyn_loss_mean": 1.0000077370140288, "train/dyn_loss_std": 0.0001828631098356305, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08380605774948856, "train/extr_critic_critic_opt_grad_steps": 52695.0, "train/extr_critic_critic_opt_loss": 12260.321822554977, "train/extr_critic_mag": 0.5258982341598581, "train/extr_critic_max": 0.5258982341598581, "train/extr_critic_mean": 0.44515684992074966, "train/extr_critic_min": 0.4061708704189018, "train/extr_critic_std": 0.012128993890386212, "train/extr_return_normed_mag": 0.3409754553878749, "train/extr_return_normed_max": 0.19315577119036956, "train/extr_return_normed_mean": 0.015956674730491446, "train/extr_return_normed_min": -0.2649069360836788, "train/extr_return_normed_std": 0.01643634976224146, "train/extr_return_rate": 0.02084870623915507, "train/extr_return_raw_mag": 0.6233681000217244, "train/extr_return_raw_max": 0.6233681000217244, "train/extr_return_raw_mean": 0.4461690228846338, "train/extr_return_raw_min": 0.16530539260970223, "train/extr_return_raw_std": 0.016436349833384156, "train/extr_reward_mag": 0.250274486011929, "train/extr_reward_max": 0.250274486011929, "train/extr_reward_mean": 0.000773635030378096, "train/extr_reward_min": 1.532612023530183e-06, "train/extr_reward_std": 0.00475372465088084, "train/image_loss_mean": 0.07617925181639967, "train/image_loss_std": 0.1020061310932592, "train/model_loss_mean": 0.6973849245243602, "train/model_loss_std": 0.2665700834520437, "train/model_opt_grad_norm": 18.277269694540237, "train/model_opt_grad_steps": 52649.32407407407, "train/model_opt_loss": 3890.6555458351418, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5578.7037037037035, "train/policy_entropy_mag": 1.5038419520413433, "train/policy_entropy_max": 1.5038419520413433, "train/policy_entropy_mean": 0.1392617620596731, "train/policy_entropy_min": 0.06468676613574778, "train/policy_entropy_std": 0.1856255062200405, "train/policy_logprob_mag": 6.551079546963727, "train/policy_logprob_max": -0.008608244256012969, "train/policy_logprob_mean": -0.13920439334793222, "train/policy_logprob_min": -6.551079546963727, "train/policy_logprob_std": 0.6809931195996426, "train/policy_randomness_mag": 0.7728219288918707, "train/policy_randomness_max": 0.7728219288918707, "train/policy_randomness_mean": 0.07156639244338428, "train/policy_randomness_min": 0.03324242327707233, "train/policy_randomness_std": 0.09539264492276642, "train/post_ent_mag": 33.618145324565745, "train/post_ent_max": 33.618145324565745, "train/post_ent_mean": 33.222501542833115, "train/post_ent_min": 32.87541789478726, "train/post_ent_std": 0.13417838203410307, "train/prior_ent_mag": 33.64360796963727, "train/prior_ent_max": 33.64360796963727, "train/prior_ent_mean": 32.70539269623933, "train/prior_ent_min": 31.82584203614129, "train/prior_ent_std": 0.256204493412817, "train/rep_loss_mean": 1.0000077370140288, "train/rep_loss_std": 0.0001828631098356305, "train/reward_avg": 0.0005878637363181311, "train/reward_loss_mean": 0.011797972006240377, "train/reward_loss_std": 0.08073429796085865, "train/reward_max_data": 0.3170664949047258, "train/reward_max_pred": 0.11158631134916235, "train/reward_neg_acc": 0.9999321205196557, "train/reward_neg_loss": 0.009217764949426055, "train/reward_pos_acc": 0.28730158777464004, "train/reward_pos_loss": 4.084472845281874, "train/reward_pred": 0.0005171737165828408, "train/reward_rate": 0.0006374782986111111, "train_stats/mean_log_entropy": 0.11268508089024847, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.018154270946979523, "report/cont_loss_std": 0.26674383878707886, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 3.1920249462127686, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0025808142963796854, "report/cont_pred": 0.9963840246200562, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08327613770961761, "report/image_loss_std": 0.10236247628927231, "report/model_loss_mean": 0.714370608329773, "report/model_loss_std": 0.33165088295936584, "report/post_ent_mag": 33.853424072265625, "report/post_ent_max": 33.853424072265625, "report/post_ent_mean": 33.534507751464844, "report/post_ent_min": 33.227813720703125, "report/post_ent_std": 0.1104549765586853, "report/prior_ent_mag": 34.23240280151367, "report/prior_ent_max": 34.23240280151367, "report/prior_ent_mean": 32.45671844482422, "report/prior_ent_min": 31.496000289916992, "report/prior_ent_std": 0.28912732005119324, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005704493378289044, "report/reward_loss_mean": 0.012940216809511185, "report/reward_loss_std": 0.08473379164934158, "report/reward_max_data": 0.3606249988079071, "report/reward_max_pred": 0.06727564334869385, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01034401822835207, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 2.668851375579834, "report/reward_pred": 0.0005712794372811913, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.047029461711645126, "eval/cont_loss_std": 0.6703510284423828, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.550833702087402, "eval/cont_pos_acc": 0.9980391263961792, "eval/cont_pos_loss": 0.005838075187057257, "eval/cont_pred": 0.9966796636581421, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2052900493144989, "eval/image_loss_std": 0.15179157257080078, "eval/model_loss_mean": 0.854121208190918, "eval/model_loss_std": 0.6887590885162354, "eval/post_ent_mag": 33.884033203125, "eval/post_ent_max": 33.884033203125, "eval/post_ent_mean": 33.512489318847656, "eval/post_ent_min": 33.23661804199219, "eval/post_ent_std": 0.112787626683712, "eval/prior_ent_mag": 33.832725524902344, "eval/prior_ent_max": 33.832725524902344, "eval/prior_ent_mean": 32.41191864013672, "eval/prior_ent_min": 31.403778076171875, "eval/prior_ent_std": 0.3289553225040436, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0018016793765127659, "eval/reward_loss_std": 0.002534962957724929, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.025214195251464844, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0018016793765127659, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0003397832624614239, "eval/reward_rate": 0.0, "replay/size": 216137.0, "replay/inserts": 8612.0, "replay/samples": 34448.0, "replay/insert_wait_avg": 1.4809802472176133e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.714967200548993e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 51424.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1044390061322382e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0992023944855, "timer/env.step_count": 1077.0, "timer/env.step_total": 10.029194355010986, "timer/env.step_frac": 0.010028199533604875, "timer/env.step_avg": 0.009312158175497666, "timer/env.step_min": 0.008250951766967773, "timer/env.step_max": 0.02662491798400879, "timer/replay._sample_count": 34448.0, "timer/replay._sample_total": 16.60416531562805, "timer/replay._sample_frac": 0.016602518306057603, "timer/replay._sample_avg": 0.00048200665686333173, "timer/replay._sample_min": 0.000347137451171875, "timer/replay._sample_max": 0.03814697265625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1366.0, "timer/agent.policy_total": 13.188626527786255, "timer/agent.policy_frac": 0.013187318314232642, "timer/agent.policy_avg": 0.009654924251673686, "timer/agent.policy_min": 0.008637428283691406, "timer/agent.policy_max": 0.035918235778808594, "timer/dataset_train_count": 2153.0, "timer/dataset_train_total": 0.36540865898132324, "timer/dataset_train_frac": 0.00036537241316305855, "timer/dataset_train_avg": 0.00016972069622913296, "timer/dataset_train_min": 8.654594421386719e-05, "timer/dataset_train_max": 0.001753091812133789, "timer/agent.train_count": 2153.0, "timer/agent.train_total": 962.3928921222687, "timer/agent.train_frac": 0.962297429913014, "timer/agent.train_avg": 0.4470008788305939, "timer/agent.train_min": 0.43541526794433594, "timer/agent.train_max": 0.5756704807281494, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47878122329711914, "timer/agent.report_frac": 0.00047873373176460715, "timer/agent.report_avg": 0.23939061164855957, "timer/agent.report_min": 0.23157954216003418, "timer/agent.report_max": 0.24720168113708496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.5985047343153054e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 8.611025115371207}
{"step": 216728, "time": 25225.5376932621, "episode/length": 288.0, "episode/score": 0.06925591636917261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06925591636917261}
{"step": 217032, "time": 25260.576144456863, "episode/length": 229.0, "episode/score": 0.3232857912518625, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.03891078014584082}
{"step": 217048, "time": 25262.474551916122, "episode/length": 288.0, "episode/score": 0.04506147699964913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04506147699964913}
{"step": 217600, "time": 25326.521080970764, "episode/length": 288.0, "episode/score": 0.08659734564105293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08659734564105293}
{"step": 217624, "time": 25329.288991451263, "episode/length": 288.0, "episode/score": 0.05604513402448674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05604513402448674}
{"step": 217800, "time": 25349.611293315887, "episode/length": 95.0, "episode/score": 0.7399664756899256, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.036841476504832826}
{"step": 217960, "time": 25368.148898601532, "episode/length": 207.0, "episode/score": 0.42319698582900855, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0700719810326973}
{"step": 218072, "time": 25381.06966662407, "episode/length": 288.0, "episode/score": 0.07685411739981873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07685411739981873}
{"step": 218400, "time": 25419.10014438629, "episode/length": 99.0, "episode/score": 0.7252283999359861, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.034603359376887965}
{"step": 218408, "time": 25420.02651166916, "episode/length": 288.0, "episode/score": 0.03834854978822477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03834854978822477}
{"step": 218624, "time": 25444.886488199234, "episode/length": 82.0, "episode/score": 0.7781464156291804, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.03439644028594557}
{"step": 218752, "time": 25459.58477783203, "episode/length": 43.0, "episode/score": 0.8855185163615715, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.019893469178441592}
{"step": 218776, "time": 25462.35184597969, "episode/length": 143.0, "episode/score": 0.5984203444647846, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.04529529728165471}
{"step": 218888, "time": 25475.272805690765, "episode/length": 32.0, "episode/score": 0.9115597275380196, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.011559728038605499}
{"step": 219040, "time": 25492.727677583694, "episode/length": 288.0, "episode/score": 0.0887318764301881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0887318764301881}
{"step": 219240, "time": 25515.710577487946, "episode/length": 179.0, "episode/score": 0.4997912011488097, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.05916619568893111}
{"step": 219360, "time": 25529.583465099335, "episode/length": 288.0, "episode/score": 0.0368831351127028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0368831351127028}
{"step": 220064, "time": 25612.279737710953, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 220064, "time": 25612.683007478714, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 220064, "time": 25613.49757695198, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 220064, "time": 25614.25728702545, "eval_episode/length": 200.0, "eval_episode/score": 0.375, "eval_episode/reward_rate": 0.004975124378109453}
{"step": 220064, "time": 25614.328411102295, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 220064, "time": 25615.702140569687, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 25615.710345506668, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 25615.71579170227, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 25615.721670627594, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220384, "time": 25652.556224822998, "episode/length": 288.0, "episode/score": 0.05766766475790064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05766766475790064}
{"step": 220640, "time": 25681.99460697174, "episode/length": 159.0, "episode/score": 0.5422850173641791, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.039159976048381395}
{"step": 220720, "time": 25691.207181692123, "episode/length": 288.0, "episode/score": 0.04901108469573501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04901108469573501}
{"step": 221064, "time": 25730.885093450546, "episode/length": 288.0, "episode/score": 0.07411342065648796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07411342065648796}
{"step": 221088, "time": 25733.67109298706, "episode/length": 288.0, "episode/score": 0.06831293195705257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06831293195705257}
{"step": 221200, "time": 25747.027386426926, "episode/length": 288.0, "episode/score": 0.06566191493993756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06566191493993756}
{"step": 221352, "time": 25764.61058139801, "episode/length": 288.0, "episode/score": 0.054502428040621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054502428040621}
{"step": 221552, "time": 25787.759791374207, "episode/length": 288.0, "episode/score": 0.0703206158881926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0703206158881926}
{"step": 222040, "time": 25843.926258325577, "episode/length": 104.0, "episode/score": 0.7082095649520852, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.03320952439298708}
{"step": 222232, "time": 25866.224870204926, "episode/length": 109.0, "episode/score": 0.6899403666502621, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.030565326091164025}
{"step": 222496, "time": 25896.72735619545, "episode/length": 178.0, "episode/score": 0.48082140105907456, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.03707140783444629}
{"step": 222496, "time": 25896.733520030975, "episode/length": 175.0, "episode/score": 0.4799268000522261, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.026801785733141514}
{"step": 222696, "time": 25919.772925138474, "episode/length": 288.0, "episode/score": 0.047741102012139436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047741102012139436}
{"step": 222952, "time": 25949.44194674492, "episode/length": 288.0, "episode/score": 0.06190392390988109, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06190392390988109}
{"step": 223032, "time": 25958.74312734604, "episode/length": 288.0, "episode/score": 0.07754446289635553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07754446289635553}
{"step": 223864, "time": 26054.516452550888, "episode/length": 288.0, "episode/score": 0.025992903371502507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025992903371502507}
{"step": 224128, "time": 26084.936206817627, "episode/length": 178.0, "episode/score": 0.5020118208958593, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.058261827671231003}
{"step": 224280, "time": 26102.46751856804, "episode/length": 279.0, "episode/score": 0.16352296243098863, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.03539797187227123}
{"step": 224544, "time": 26132.889791965485, "episode/length": 288.0, "episode/score": 0.04707591582348414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04707591582348414}
{"step": 224808, "time": 26163.300349473953, "episode/length": 288.0, "episode/score": 0.03647088398770393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03647088398770393}
{"step": 224808, "time": 26163.307128429413, "episode/length": 288.0, "episode/score": 0.020042340956138105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020042340956138105}
{"step": 225257, "time": 26215.83976316452, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0364365688590116, "train/action_min": 0.0, "train/action_std": 1.8703100925268128, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004367104997360256, "train/actor_opt_grad_steps": 54850.0, "train/actor_opt_loss": -5.502519762550675, "train/adv_mag": 0.3657530639060708, "train/adv_max": 0.15561108741649363, "train/adv_mean": 0.0020554117378535097, "train/adv_min": -0.33325841496157094, "train/adv_std": 0.013645646157999371, "train/cont_avg": 0.9962073037790697, "train/cont_loss_mean": 0.008920910714605693, "train/cont_loss_std": 0.15845844715151416, "train/cont_neg_acc": 0.554676212965043, "train/cont_neg_loss": 1.8896084199449061, "train/cont_pos_acc": 0.9999133212621822, "train/cont_pos_loss": 0.001815583956222115, "train/cont_pred": 0.9961279564125594, "train/cont_rate": 0.9962073037790697, "train/dyn_loss_mean": 1.000001040170359, "train/dyn_loss_std": 3.3259513073189316e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15122642975603773, "train/extr_critic_critic_opt_grad_steps": 54850.0, "train/extr_critic_critic_opt_loss": 12142.795053597383, "train/extr_critic_mag": 0.5914771340614141, "train/extr_critic_max": 0.5914771340614141, "train/extr_critic_mean": 0.5148298741773117, "train/extr_critic_min": 0.4690423200296801, "train/extr_critic_std": 0.012315254220955594, "train/extr_return_normed_mag": 0.37530167088952177, "train/extr_return_normed_max": 0.20100325248962225, "train/extr_return_normed_mean": 0.02164192666884425, "train/extr_return_normed_min": -0.307469571468442, "train/extr_return_normed_std": 0.019090132941600196, "train/extr_return_rate": 0.7033251865647819, "train/extr_return_raw_mag": 0.696246647557547, "train/extr_return_raw_max": 0.696246647557547, "train/extr_return_raw_mean": 0.5168853483920873, "train/extr_return_raw_min": 0.18777382346086724, "train/extr_return_raw_std": 0.01909013294593193, "train/extr_reward_mag": 0.24321270987044932, "train/extr_reward_max": 0.24321270987044932, "train/extr_reward_mean": 0.0010365446107624488, "train/extr_reward_min": 1.7016433006109194e-06, "train/extr_reward_std": 0.0060270375377217, "train/image_loss_mean": 0.07934536836868109, "train/image_loss_std": 0.10404063993415168, "train/model_loss_mean": 0.6999384089957836, "train/model_loss_std": 0.25661066933426746, "train/model_opt_grad_norm": 17.84549207022024, "train/model_opt_grad_steps": 54802.288372093026, "train/model_opt_loss": 3677.850320221657, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5255.813953488372, "train/policy_entropy_mag": 1.4874787713206092, "train/policy_entropy_max": 1.4874787713206092, "train/policy_entropy_mean": 0.1290665557564691, "train/policy_entropy_min": 0.06468663898318312, "train/policy_entropy_std": 0.1810848643613416, "train/policy_logprob_mag": 6.551080042816872, "train/policy_logprob_max": -0.008608178729408009, "train/policy_logprob_mean": -0.1284225966694743, "train/policy_logprob_min": -6.551080042816872, "train/policy_logprob_std": 0.6695168248442717, "train/policy_randomness_mag": 0.7644129215284835, "train/policy_randomness_max": 0.7644129215284835, "train/policy_randomness_mean": 0.06632709277923717, "train/policy_randomness_min": 0.03324235852721125, "train/policy_randomness_std": 0.09305921695953191, "train/post_ent_mag": 33.5204555245333, "train/post_ent_max": 33.5204555245333, "train/post_ent_mean": 33.18158109797988, "train/post_ent_min": 32.87612938104674, "train/post_ent_std": 0.11644786620555922, "train/prior_ent_mag": 33.49167430788972, "train/prior_ent_max": 33.49167430788972, "train/prior_ent_mean": 32.70367071462232, "train/prior_ent_min": 31.71739527680153, "train/prior_ent_std": 0.28204916001752367, "train/rep_loss_mean": 1.000001040170359, "train/rep_loss_std": 3.3259513073189316e-05, "train/reward_avg": 0.0005987513689919873, "train/reward_loss_mean": 0.01167148394120294, "train/reward_loss_std": 0.07462319357450618, "train/reward_max_data": 0.31595830357698507, "train/reward_max_pred": 0.12804605794507404, "train/reward_neg_acc": 0.9999409115591714, "train/reward_neg_loss": 0.009288959194321272, "train/reward_pos_acc": 0.35598705549841947, "train/reward_pos_loss": 3.7023263925198213, "train/reward_pred": 0.0005475074994962575, "train/reward_rate": 0.0006404433139534884, "train_stats/mean_log_entropy": 0.1165622386493181, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.02221285179257393, "report/cont_loss_std": 0.3299788236618042, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 2.990443468093872, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0017825536197051406, "report/cont_pred": 0.9959412813186646, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07602694630622864, "report/image_loss_std": 0.10230743139982224, "report/model_loss_mean": 0.7188892960548401, "report/model_loss_std": 0.5178314447402954, "report/post_ent_mag": 33.60270690917969, "report/post_ent_max": 33.60270690917969, "report/post_ent_mean": 33.27940368652344, "report/post_ent_min": 32.95259094238281, "report/post_ent_std": 0.12001893669366837, "report/prior_ent_mag": 33.368797302246094, "report/prior_ent_max": 33.368797302246094, "report/prior_ent_mean": 32.66878128051758, "report/prior_ent_min": 31.710895538330078, "report/prior_ent_std": 0.27783530950546265, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0014210056979209185, "report/reward_loss_mean": 0.020649459213018417, "report/reward_loss_std": 0.23459666967391968, "report/reward_max_data": 0.8539583086967468, "report/reward_max_pred": 0.01816880702972412, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010399333201348782, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.258462905883789, "report/reward_pred": 0.00031044590286910534, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.029543954879045486, "eval/cont_loss_std": 0.5360180139541626, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.562524795532227, "eval/cont_pos_acc": 0.9980430603027344, "eval/cont_pos_loss": 0.006974521558731794, "eval/cont_pred": 0.9973261952400208, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24155065417289734, "eval/image_loss_std": 0.17808054387569427, "eval/model_loss_mean": 0.8725383281707764, "eval/model_loss_std": 0.5675944685935974, "eval/post_ent_mag": 33.640777587890625, "eval/post_ent_max": 33.640777587890625, "eval/post_ent_mean": 33.24351501464844, "eval/post_ent_min": 32.96319580078125, "eval/post_ent_std": 0.11353595554828644, "eval/prior_ent_mag": 33.33182907104492, "eval/prior_ent_max": 33.33182907104492, "eval/prior_ent_mean": 32.60630798339844, "eval/prior_ent_min": 31.6629638671875, "eval/prior_ent_std": 0.2716113328933716, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001443709246814251, "eval/reward_loss_std": 0.0018127115909010172, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.016822218894958496, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001443709246814251, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00024877116084098816, "eval/reward_rate": 0.0, "replay/size": 224753.0, "replay/inserts": 8616.0, "replay/samples": 34464.0, "replay/insert_wait_avg": 1.4874873165743376e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.668563693125378e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 53736.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0083290944874906e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2582452297211, "timer/env.step_count": 1077.0, "timer/env.step_total": 10.057204008102417, "timer/env.step_frac": 0.010054607453690783, "timer/env.step_avg": 0.009338165281432142, "timer/env.step_min": 0.008230924606323242, "timer/env.step_max": 0.034607648849487305, "timer/replay._sample_count": 34464.0, "timer/replay._sample_total": 16.599412202835083, "timer/replay._sample_frac": 0.016595126590556456, "timer/replay._sample_avg": 0.0004816449687452148, "timer/replay._sample_min": 0.0003521442413330078, "timer/replay._sample_max": 0.0227203369140625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1366.0, "timer/agent.policy_total": 13.250866889953613, "timer/agent.policy_frac": 0.013247445800269705, "timer/agent.policy_avg": 0.009700488206408208, "timer/agent.policy_min": 0.008466005325317383, "timer/agent.policy_max": 0.043855905532836914, "timer/dataset_train_count": 2154.0, "timer/dataset_train_total": 0.39212489128112793, "timer/dataset_train_frac": 0.0003920236530427918, "timer/dataset_train_avg": 0.00018204498202466479, "timer/dataset_train_min": 8.535385131835938e-05, "timer/dataset_train_max": 0.02254772186279297, "timer/agent.train_count": 2154.0, "timer/agent.train_total": 962.4823031425476, "timer/agent.train_frac": 0.962233810851019, "timer/agent.train_avg": 0.4468348668256953, "timer/agent.train_min": 0.4341442584991455, "timer/agent.train_max": 0.5900771617889404, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4732644557952881, "timer/agent.report_frac": 0.0004731422690613236, "timer/agent.report_avg": 0.23663222789764404, "timer/agent.report_min": 0.2305278778076172, "timer/agent.report_max": 0.2427365779876709, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.003298509166267e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 8.613659759819035}
{"step": 225264, "time": 26216.445180892944, "episode/length": 288.0, "episode/score": 0.030399888377019124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030399888377019124}
{"step": 225344, "time": 26225.801691770554, "episode/length": 288.0, "episode/score": 0.05151114851400962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05151114851400962}
{"step": 225504, "time": 26244.246487617493, "episode/length": 86.0, "episode/score": 0.7513083898908235, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.020058393633576088}
{"step": 226176, "time": 26321.495318889618, "episode/length": 288.0, "episode/score": 0.048728316370670655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048728316370670655}
{"step": 226440, "time": 26351.76883006096, "episode/length": 288.0, "episode/score": 0.06019679179922832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06019679179922832}
{"step": 226592, "time": 26369.194700956345, "episode/length": 288.0, "episode/score": 0.03238775095638857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03238775095638857}
{"step": 226800, "time": 26393.11413192749, "episode/length": 44.0, "episode/score": 0.8748605150449862, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.012360479782785205}
{"step": 226856, "time": 26399.531997919083, "episode/length": 288.0, "episode/score": 0.06715598967065262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06715598967065262}
{"step": 227120, "time": 26429.9588599205, "episode/length": 288.0, "episode/score": 0.05908068945763034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05908068945763034}
{"step": 227576, "time": 26482.354731321335, "episode/length": 288.0, "episode/score": 0.052872590790343565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052872590790343565}
{"step": 227624, "time": 26487.909362077713, "episode/length": 284.0, "episode/score": 0.15346513012269725, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.04096513339396779}
{"step": 227816, "time": 26510.009140253067, "episode/length": 288.0, "episode/score": 0.06225709822570025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06225709822570025}
{"step": 228488, "time": 26587.575387001038, "episode/length": 288.0, "episode/score": 0.07609218894663172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07609218894663172}
{"step": 228648, "time": 26606.168458223343, "episode/length": 133.0, "episode/score": 0.6035945379791201, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.01921949079599017}
{"step": 228768, "time": 26620.045025587082, "episode/length": 245.0, "episode/score": 0.28786805423231954, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0534930606933699}
{"step": 228904, "time": 26635.662912130356, "episode/length": 288.0, "episode/score": 0.042276907765426586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042276907765426586}
{"step": 229168, "time": 26665.98832821846, "episode/length": 288.0, "episode/score": 0.04294431727714709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04294431727714709}
{"step": 229432, "time": 26697.35526061058, "episode/length": 288.0, "episode/score": 0.023884605078251298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023884605078251298}
{"step": 229616, "time": 26718.516180753708, "episode/length": 140.0, "episode/score": 0.6047972438303759, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.04229722048910389}
{"step": 229936, "time": 26755.508903503418, "episode/length": 288.0, "episode/score": 0.03700057325670514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03700057325670514}
{"step": 230048, "time": 26771.691325187683, "eval_episode/length": 193.0, "eval_episode/score": 0.3968749940395355, "eval_episode/reward_rate": 0.005154639175257732}
{"step": 230048, "time": 26772.464724063873, "eval_episode/length": 238.0, "eval_episode/score": 0.2562499940395355, "eval_episode/reward_rate": 0.0041841004184100415}
{"step": 230048, "time": 26772.685666561127, "eval_episode/length": 250.0, "eval_episode/score": 0.21875, "eval_episode/reward_rate": 0.00398406374501992}
{"step": 230048, "time": 26772.816702842712, "eval_episode/length": 257.0, "eval_episode/score": 0.19687500596046448, "eval_episode/reward_rate": 0.003875968992248062}
{"step": 230048, "time": 26773.10179233551, "eval_episode/length": 273.0, "eval_episode/score": 0.14687499403953552, "eval_episode/reward_rate": 0.0036496350364963502}
{"step": 230048, "time": 26773.363707304, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 26773.371186494827, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 26773.376823425293, "eval_episode/length": 288.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.0034602076124567475}
{"step": 230128, "time": 26782.666491508484, "episode/length": 288.0, "episode/score": 0.06186054696985366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06186054696985366}
{"step": 230480, "time": 26823.340955495834, "episode/length": 213.0, "episode/score": 0.37236599831692274, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.03799099609921086}
{"step": 230496, "time": 26825.197174549103, "episode/length": 165.0, "episode/score": 0.5048287906305404, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.020453782452364067}
{"step": 230960, "time": 26878.833964824677, "episode/length": 288.0, "episode/score": 0.03464420246857003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03464420246857003}
{"step": 231216, "time": 26908.303708553314, "episode/length": 288.0, "episode/score": 0.033971407122947994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033971407122947994}
{"step": 231744, "time": 26969.385400295258, "episode/length": 288.0, "episode/score": 0.047343891204775446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047343891204775446}
{"step": 231864, "time": 26983.171205997467, "episode/length": 170.0, "episode/score": 0.5028907416000834, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.03414074806113376}
{"step": 231928, "time": 26990.513665914536, "episode/length": 288.0, "episode/score": 0.04013901176531931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04013901176531931}
{"step": 232248, "time": 27027.226636648178, "episode/length": 288.0, "episode/score": 0.04451667069008636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04451667069008636}
{"step": 232440, "time": 27049.349741220474, "episode/length": 288.0, "episode/score": 0.03575100622870764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03575100622870764}
{"step": 232712, "time": 27080.6236307621, "episode/length": 120.0, "episode/score": 0.6689103316434739, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.04391033245838116}
{"step": 232792, "time": 27089.828861951828, "episode/length": 288.0, "episode/score": 0.06071149309926227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06071149309926227}
{"step": 232984, "time": 27111.83031630516, "episode/length": 33.0, "episode/score": 0.91385361859966, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.016978566119632887}
{"step": 233272, "time": 27144.711861133575, "episode/length": 288.0, "episode/score": 0.05976833279893867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05976833279893867}
{"step": 233416, "time": 27161.298159837723, "episode/length": 53.0, "episode/score": 0.8418318255223767, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.007456787361434181}
{"step": 233528, "time": 27174.173102617264, "episode/length": 288.0, "episode/score": 0.06372767903857834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06372767903857834}
{"step": 233885, "time": 27216.123003721237, "train_stats/mean_log_entropy": 0.10197701222366756, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8647839581524885, "train/action_min": 0.0, "train/action_std": 1.842747860484653, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004513049359687742, "train/actor_opt_grad_steps": 57005.0, "train/actor_opt_loss": -9.262624676304835, "train/adv_mag": 0.39036319722180013, "train/adv_max": 0.1397724253711877, "train/adv_mean": -0.0004538604455825003, "train/adv_min": -0.3638745569796474, "train/adv_std": 0.014009292284889077, "train/cont_avg": 0.9962836371527778, "train/cont_loss_mean": 0.008899892275318658, "train/cont_loss_std": 0.16013315189047717, "train/cont_neg_acc": 0.5593513282232506, "train/cont_neg_loss": 1.8820512686151931, "train/cont_pos_acc": 0.9998956339226829, "train/cont_pos_loss": 0.0018374600918765213, "train/cont_pred": 0.9961869079205725, "train/cont_rate": 0.9962836371527778, "train/dyn_loss_mean": 1.0000005623808614, "train/dyn_loss_std": 1.4874069839371023e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10971635235990915, "train/extr_critic_critic_opt_grad_steps": 57005.0, "train/extr_critic_critic_opt_loss": 9914.20723243996, "train/extr_critic_mag": 0.6074684797613709, "train/extr_critic_max": 0.6074684797613709, "train/extr_critic_mean": 0.5510962942132244, "train/extr_critic_min": 0.4971207247840034, "train/extr_critic_std": 0.015148609458399867, "train/extr_return_normed_mag": 0.39695896208286285, "train/extr_return_normed_max": 0.17739355067412058, "train/extr_return_normed_mean": 0.019165292815563992, "train/extr_return_normed_min": -0.34590836131462344, "train/extr_return_normed_std": 0.021247414294285356, "train/extr_return_rate": 0.9989451131335011, "train/extr_return_raw_mag": 0.7088706722414052, "train/extr_return_raw_max": 0.7088706722414052, "train/extr_return_raw_mean": 0.550642437129109, "train/extr_return_raw_min": 0.18556876025266117, "train/extr_return_raw_std": 0.021247414203740104, "train/extr_reward_mag": 0.23503667005786189, "train/extr_reward_max": 0.23503667005786189, "train/extr_reward_mean": 0.0008735278206586372, "train/extr_reward_min": 1.4575543227019133e-06, "train/extr_reward_std": 0.005425332231593698, "train/image_loss_mean": 0.07752144892044642, "train/image_loss_std": 0.10363579293092091, "train/model_loss_mean": 0.6981047872040007, "train/model_loss_std": 0.25530233361792787, "train/model_opt_grad_norm": 17.713649248635328, "train/model_opt_grad_steps": 56955.2037037037, "train/model_opt_loss": 3523.3725020797165, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5046.2962962962965, "train/policy_entropy_mag": 1.4279720225819834, "train/policy_entropy_max": 1.4279720225819834, "train/policy_entropy_mean": 0.11601778933847393, "train/policy_entropy_min": 0.06468650450309117, "train/policy_entropy_std": 0.15387148975774093, "train/policy_logprob_mag": 6.551080189369343, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1158349063868324, "train/policy_logprob_min": -6.551080189369343, "train/policy_logprob_std": 0.6561042856838968, "train/policy_randomness_mag": 0.7338324972876796, "train/policy_randomness_max": 0.7338324972876796, "train/policy_randomness_mean": 0.0596213531507938, "train/policy_randomness_min": 0.03324228794210487, "train/policy_randomness_std": 0.07907430784500859, "train/post_ent_mag": 33.502151242008914, "train/post_ent_max": 33.502151242008914, "train/post_ent_mean": 33.17385463361387, "train/post_ent_min": 32.87513964264481, "train/post_ent_std": 0.11678832641768234, "train/prior_ent_mag": 33.48112120451751, "train/prior_ent_max": 33.48112120451751, "train/prior_ent_mean": 32.778107201611554, "train/prior_ent_min": 31.944784120277124, "train/prior_ent_std": 0.26372320356744305, "train/rep_loss_mean": 1.0000005623808614, "train/rep_loss_std": 1.4874069839371023e-05, "train/reward_avg": 0.0005665191427531816, "train/reward_loss_mean": 0.011683086552053553, "train/reward_loss_std": 0.07289808428484118, "train/reward_max_data": 0.2881809233168261, "train/reward_max_pred": 0.12059848783192811, "train/reward_neg_acc": 0.9998823666462192, "train/reward_neg_loss": 0.009330046248915433, "train/reward_pos_acc": 0.313573883366339, "train/reward_pos_loss": 3.7413243765069035, "train/reward_pred": 0.0005160305386029735, "train/reward_rate": 0.0006058304398148148, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.021098555997014046, "report/cont_loss_std": 0.2919442355632782, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 2.8388655185699463, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0017039001686498523, "report/cont_pred": 0.9963799715042114, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08851718157529831, "report/image_loss_std": 0.11529158055782318, "report/model_loss_mean": 0.7252408862113953, "report/model_loss_std": 0.41249850392341614, "report/post_ent_mag": 33.2591552734375, "report/post_ent_max": 33.2591552734375, "report/post_ent_mean": 32.94341278076172, "report/post_ent_min": 32.5806884765625, "report/post_ent_std": 0.11947351694107056, "report/prior_ent_mag": 33.51081466674805, "report/prior_ent_max": 33.51081466674805, "report/prior_ent_mean": 32.64727783203125, "report/prior_ent_min": 31.7716064453125, "report/prior_ent_std": 0.30563801527023315, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0009627988911233842, "report/reward_loss_mean": 0.01562510058283806, "report/reward_loss_std": 0.16036419570446014, "report/reward_max_data": 0.7477083206176758, "report/reward_max_pred": 0.035396695137023926, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010633282363414764, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.122256278991699, "report/reward_pred": 0.0005242808256298304, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.06950609385967255, "eval/cont_loss_std": 0.8342660069465637, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.755255699157715, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0028391899541020393, "eval/cont_pred": 0.9973506927490234, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.215311199426651, "eval/image_loss_std": 0.14327716827392578, "eval/model_loss_mean": 0.8985545635223389, "eval/model_loss_std": 0.9719749093055725, "eval/post_ent_mag": 33.24369812011719, "eval/post_ent_max": 33.24369812011719, "eval/post_ent_mean": 32.91563415527344, "eval/post_ent_min": 32.63018798828125, "eval/post_ent_std": 0.12440274655818939, "eval/prior_ent_mag": 33.587432861328125, "eval/prior_ent_max": 33.587432861328125, "eval/prior_ent_mean": 32.60984802246094, "eval/prior_ent_min": 31.702253341674805, "eval/prior_ent_std": 0.3016771972179413, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0014373778831213713, "eval/reward_loss_mean": 0.01373729296028614, "eval/reward_loss_std": 0.2703835070133209, "eval/reward_max_data": 0.7718750238418579, "eval/reward_max_pred": 0.07198941707611084, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0017860198859125376, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.120838165283203, "eval/reward_pred": 0.00047957501374185085, "eval/reward_rate": 0.001953125, "replay/size": 233381.0, "replay/inserts": 8628.0, "replay/samples": 34512.0, "replay/insert_wait_avg": 1.5144332669982769e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.567192372979529e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 56048.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0132789611816406e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.258487701416016e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2719540596008, "timer/env.step_count": 1078.0, "timer/env.step_total": 10.00518798828125, "timer/env.step_frac": 0.010002467776563388, "timer/env.step_avg": 0.009281250452951067, "timer/env.step_min": 0.007908821105957031, "timer/env.step_max": 0.03484916687011719, "timer/replay._sample_count": 34512.0, "timer/replay._sample_total": 16.435972452163696, "timer/replay._sample_frac": 0.01643150383798961, "timer/replay._sample_avg": 0.0004762393501438252, "timer/replay._sample_min": 0.00036215782165527344, "timer/replay._sample_max": 0.026027202606201172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1367.0, "timer/agent.policy_total": 13.227257013320923, "timer/agent.policy_frac": 0.013223660785087634, "timer/agent.policy_avg": 0.00967612071201238, "timer/agent.policy_min": 0.00870203971862793, "timer/agent.policy_max": 0.0362703800201416, "timer/dataset_train_count": 2157.0, "timer/dataset_train_total": 0.3580813407897949, "timer/dataset_train_frac": 0.0003579839855916412, "timer/dataset_train_avg": 0.00016600896652285346, "timer/dataset_train_min": 8.249282836914062e-05, "timer/dataset_train_max": 0.0003437995910644531, "timer/agent.train_count": 2157.0, "timer/agent.train_total": 962.4077377319336, "timer/agent.train_frac": 0.9621460782000381, "timer/agent.train_avg": 0.44617883065921815, "timer/agent.train_min": 0.43358802795410156, "timer/agent.train_max": 1.2248053550720215, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47445106506347656, "timer/agent.report_frac": 0.0004743220712506417, "timer/agent.report_avg": 0.23722553253173828, "timer/agent.report_min": 0.23093843460083008, "timer/agent.report_max": 0.24351263046264648, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.884080469736946e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 8.625537593673215}
{"step": 234136, "time": 27244.750854730606, "episode/length": 167.0, "episode/score": 0.5152773769125361, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.03715237741312194}
{"step": 234176, "time": 27249.342198610306, "episode/length": 288.0, "episode/score": 0.059729410994350474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059729410994350474}
{"step": 234240, "time": 27256.70724272728, "episode/length": 288.0, "episode/score": 0.038501334302623036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038501334302623036}
{"step": 234560, "time": 27293.540494918823, "episode/length": 288.0, "episode/score": 0.050402554578568015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050402554578568015}
{"step": 234752, "time": 27315.678325414658, "episode/length": 288.0, "episode/score": 0.042427839266338196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042427839266338196}
{"step": 235584, "time": 27411.34118294716, "episode/length": 288.0, "episode/score": 0.0532049283174274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0532049283174274}
{"step": 235728, "time": 27427.933095932007, "episode/length": 288.0, "episode/score": 0.028834115377549097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028834115377549097}
{"step": 235840, "time": 27440.833203792572, "episode/length": 288.0, "episode/score": 0.05046262294490589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05046262294490589}
{"step": 236448, "time": 27510.880827188492, "episode/length": 288.0, "episode/score": 0.026231728150264644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026231728150264644}
{"step": 236488, "time": 27515.550616025925, "episode/length": 288.0, "episode/score": 0.028646789668073325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028646789668073325}
{"step": 236552, "time": 27522.86562848091, "episode/length": 288.0, "episode/score": 0.050160035851945395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050160035851945395}
{"step": 236872, "time": 27559.699521780014, "episode/length": 288.0, "episode/score": 0.042192595994492876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042192595994492876}
{"step": 236928, "time": 27566.148462057114, "episode/length": 46.0, "episode/score": 0.8682276893365497, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.01197767791620663}
{"step": 237064, "time": 27581.74296784401, "episode/length": 288.0, "episode/score": 0.05816130523476204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05816130523476204}
{"step": 237104, "time": 27586.317502260208, "episode/length": 189.0, "episode/score": 0.431965606363633, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0225905862645277}
{"step": 238040, "time": 27694.264070510864, "episode/length": 288.0, "episode/score": 0.03122094214944582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03122094214944582}
{"step": 238152, "time": 27707.09294438362, "episode/length": 288.0, "episode/score": 0.02657087746479192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02657087746479192}
{"step": 238208, "time": 27713.535449028015, "episode/length": 159.0, "episode/score": 0.5316634012407349, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.028538365978533875}
{"step": 238760, "time": 27777.17033982277, "episode/length": 288.0, "episode/score": 0.05958582542120894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05958582542120894}
{"step": 238800, "time": 27781.868849277496, "episode/length": 288.0, "episode/score": 0.05022808052547134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05022808052547134}
{"step": 238872, "time": 27790.138459920883, "episode/length": 103.0, "episode/score": 0.6919501912043415, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.013825187502334302}
{"step": 239184, "time": 27825.983433008194, "episode/length": 288.0, "episode/score": 0.06663759355433285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06663759355433285}
{"step": 239376, "time": 27848.02596974373, "episode/length": 288.0, "episode/score": 0.020276528600106758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020276528600106758}
{"step": 239416, "time": 27852.6405210495, "episode/length": 288.0, "episode/score": 0.06999051494676678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06999051494676678}
{"step": 239512, "time": 27863.711856126785, "episode/length": 169.0, "episode/score": 0.511393687353177, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.03951867624715533}
{"step": 239792, "time": 27895.948714256287, "episode/length": 46.0, "episode/score": 0.8699338591986248, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.013683871337832443}
{"step": 239976, "time": 27917.057626247406, "episode/length": 74.0, "episode/score": 0.7816050958333562, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.012855069593342705}
{"step": 240032, "time": 27925.95442867279, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 240032, "time": 27926.722713947296, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 240032, "time": 27926.7831056118, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 240032, "time": 27927.215556144714, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 240032, "time": 27927.535758972168, "eval_episode/length": 200.0, "eval_episode/score": 0.375, "eval_episode/reward_rate": 0.004975124378109453}
{"step": 240032, "time": 27928.663103818893, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 240032, "time": 27929.074968099594, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 27929.0814974308, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 27929.08756685257, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240312, "time": 27961.143215179443, "episode/length": 188.0, "episode/score": 0.4368887303102724, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.02438872809256054}
{"step": 240392, "time": 27970.382867097855, "episode/length": 109.0, "episode/score": 0.6732075929460848, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.013832551630287071}
{"step": 240520, "time": 27985.070731639862, "episode/length": 288.0, "episode/score": 0.028848332805921473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028848332805921473}
{"step": 240840, "time": 28021.80704689026, "episode/length": 65.0, "episode/score": 0.8073318840199022, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.010456904159752867}
{"step": 240920, "time": 28030.936126232147, "episode/length": 269.0, "episode/score": 0.19517856233551356, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.03580356589782241}
{"step": 241128, "time": 28054.884306907654, "episode/length": 25.0, "episode/score": 0.9332704195053338, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.011395396164061822}
{"step": 241184, "time": 28061.29629468918, "episode/length": 288.0, "episode/score": 0.06403766250036824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06403766250036824}
{"step": 241216, "time": 28064.97092437744, "episode/length": 177.0, "episode/score": 0.4645051452752682, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.01763013113662737}
{"step": 241432, "time": 28089.783125400543, "episode/length": 280.0, "episode/score": 0.1624507294092723, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.037450722715391294}
{"step": 241960, "time": 28150.603806495667, "episode/length": 92.0, "episode/score": 0.7279096995860925, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.015409735506040079}
{"step": 242192, "time": 28177.280031442642, "episode/length": 94.0, "episode/score": 0.7192901271208143, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.013040115418164078}
{"step": 242288, "time": 28188.295114517212, "episode/length": 288.0, "episode/score": 0.014851114980388047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014851114980388047}
{"step": 242525, "time": 28216.46679019928, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9683026914243347, "train/action_min": 0.0, "train/action_std": 1.8178761623523854, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0054637971431172145, "train/actor_opt_grad_steps": 59165.0, "train/actor_opt_loss": -10.122770035708392, "train/adv_mag": 0.3989844643683345, "train/adv_max": 0.1669927672655494, "train/adv_mean": -0.00019101417368532297, "train/adv_min": -0.37279688691099483, "train/adv_std": 0.015344495885074139, "train/cont_avg": 0.9960485387731481, "train/cont_loss_mean": 0.009460987024390811, "train/cont_loss_std": 0.17012942782430737, "train/cont_neg_acc": 0.5549343637773924, "train/cont_neg_loss": 1.9252288551453314, "train/cont_pos_acc": 0.999891121354368, "train/cont_pos_loss": 0.0018654662467101676, "train/cont_pred": 0.996057050647559, "train/cont_rate": 0.9960485387731481, "train/dyn_loss_mean": 1.000000755544062, "train/dyn_loss_std": 2.4155258735710823e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10025858582445869, "train/extr_critic_critic_opt_grad_steps": 59165.0, "train/extr_critic_critic_opt_loss": 11011.805094401041, "train/extr_critic_mag": 0.6223712188226206, "train/extr_critic_max": 0.6223712188226206, "train/extr_critic_mean": 0.538012843992975, "train/extr_critic_min": 0.46701990564664203, "train/extr_critic_std": 0.01988070466797109, "train/extr_return_normed_mag": 0.41008810892149256, "train/extr_return_normed_max": 0.21425445433016177, "train/extr_return_normed_mean": 0.021958873245037265, "train/extr_return_normed_min": -0.35209900485696616, "train/extr_return_normed_std": 0.025808220026428224, "train/extr_return_rate": 0.9944167584180832, "train/extr_return_raw_mag": 0.7301174049024228, "train/extr_return_raw_max": 0.7301174049024228, "train/extr_return_raw_mean": 0.5378218500150574, "train/extr_return_raw_min": 0.16376394571529496, "train/extr_return_raw_std": 0.02580822000918151, "train/extr_reward_mag": 0.2683065014856833, "train/extr_reward_max": 0.2683065014856833, "train/extr_reward_mean": 0.0008873107439689597, "train/extr_reward_min": 1.5276449697989005e-06, "train/extr_reward_std": 0.0063907876368224, "train/image_loss_mean": 0.08130153470362227, "train/image_loss_std": 0.10589650790724489, "train/model_loss_mean": 0.7026662244289009, "train/model_loss_std": 0.2691092752955026, "train/model_opt_grad_norm": 16.80861086315579, "train/model_opt_grad_steps": 59113.069444444445, "train/model_opt_loss": 3529.3937479654946, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5046.2962962962965, "train/policy_entropy_mag": 1.46830445141704, "train/policy_entropy_max": 1.46830445141704, "train/policy_entropy_mean": 0.11348852815313472, "train/policy_entropy_min": 0.06468649684555, "train/policy_entropy_std": 0.15108862677933993, "train/policy_logprob_mag": 6.5510802224830345, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11369515275927605, "train/policy_logprob_min": -6.5510802224830345, "train/policy_logprob_std": 0.6536182755673373, "train/policy_randomness_mag": 0.7545592691059466, "train/policy_randomness_max": 0.7545592691059466, "train/policy_randomness_mean": 0.05832157001175262, "train/policy_randomness_min": 0.03324228394086714, "train/policy_randomness_std": 0.07764419954684046, "train/post_ent_mag": 33.68794420030382, "train/post_ent_max": 33.68794420030382, "train/post_ent_mean": 33.36578241984049, "train/post_ent_min": 33.06821528187505, "train/post_ent_std": 0.11870518306063281, "train/prior_ent_mag": 33.55166292190552, "train/prior_ent_max": 33.55166292190552, "train/prior_ent_mean": 32.93342164710716, "train/prior_ent_min": 32.12421013690807, "train/prior_ent_std": 0.2506893780772333, "train/rep_loss_mean": 1.000000755544062, "train/rep_loss_std": 2.4155258735710823e-05, "train/reward_avg": 0.0005889542586643343, "train/reward_loss_mean": 0.011903229223443541, "train/reward_loss_std": 0.0804836762016984, "train/reward_max_data": 0.32748794005601667, "train/reward_max_pred": 0.1540819842506338, "train/reward_neg_acc": 0.9998461399917249, "train/reward_neg_loss": 0.009369514128020793, "train/reward_pos_acc": 0.3807588079111363, "train/reward_pos_loss": 3.4817247630619423, "train/reward_pred": 0.000555738554491351, "train/reward_rate": 0.0007233796296296296, "train_stats/mean_log_entropy": 0.08690724483667275, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.017513355240225792, "report/cont_loss_std": 0.25398313999176025, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 3.1864945888519287, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.001963888993486762, "report/cont_pred": 0.9970250725746155, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07456045597791672, "report/image_loss_std": 0.0936361700296402, "report/model_loss_mean": 0.7039123177528381, "report/model_loss_std": 0.3351929485797882, "report/post_ent_mag": 33.657814025878906, "report/post_ent_max": 33.657814025878906, "report/post_ent_mean": 33.33592224121094, "report/post_ent_min": 32.99376678466797, "report/post_ent_std": 0.13722802698612213, "report/prior_ent_mag": 33.570499420166016, "report/prior_ent_max": 33.570499420166016, "report/prior_ent_mean": 33.11052703857422, "report/prior_ent_min": 32.287025451660156, "report/prior_ent_std": 0.24155734479427338, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0010182959958910942, "report/reward_loss_mean": 0.011838485486805439, "report/reward_loss_std": 0.11304143816232681, "report/reward_max_data": 0.8567500114440918, "report/reward_max_pred": 0.02813589572906494, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00833158753812313, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.599393844604492, "report/reward_pred": 0.00042855856008827686, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.02576560340821743, "eval/cont_loss_std": 0.5560855269432068, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.585941314697266, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0011860025115311146, "eval/cont_pred": 0.9988404512405396, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2675415873527527, "eval/image_loss_std": 0.15807732939720154, "eval/model_loss_mean": 0.8945900201797485, "eval/model_loss_std": 0.5817915201187134, "eval/post_ent_mag": 33.644256591796875, "eval/post_ent_max": 33.644256591796875, "eval/post_ent_mean": 33.29296112060547, "eval/post_ent_min": 33.0189323425293, "eval/post_ent_std": 0.1277427226305008, "eval/prior_ent_mag": 33.713111877441406, "eval/prior_ent_max": 33.713111877441406, "eval/prior_ent_mean": 33.058921813964844, "eval/prior_ent_min": 32.242469787597656, "eval/prior_ent_std": 0.23007133603096008, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012828083708882332, "eval/reward_loss_std": 0.002228040946647525, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.015222907066345215, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012828083708882332, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00025649566669017076, "eval/reward_rate": 0.0, "replay/size": 242021.0, "replay/inserts": 8640.0, "replay/samples": 34560.0, "replay/insert_wait_avg": 1.4863632343433521e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.494939146218477e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 58360.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0609214281128353e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.33021068573, "timer/env.step_count": 1080.0, "timer/env.step_total": 10.03740906715393, "timer/env.step_frac": 0.010034095701531647, "timer/env.step_avg": 0.009293897284401787, "timer/env.step_min": 0.008351802825927734, "timer/env.step_max": 0.037642717361450195, "timer/replay._sample_count": 34560.0, "timer/replay._sample_total": 16.22513198852539, "timer/replay._sample_frac": 0.016219776045155135, "timer/replay._sample_avg": 0.0004694771987420541, "timer/replay._sample_min": 0.0003528594970703125, "timer/replay._sample_max": 0.029315948486328125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1369.0, "timer/agent.policy_total": 13.666017055511475, "timer/agent.policy_frac": 0.013661505880286641, "timer/agent.policy_avg": 0.00998248141381408, "timer/agent.policy_min": 0.008752107620239258, "timer/agent.policy_max": 0.07224583625793457, "timer/dataset_train_count": 2160.0, "timer/dataset_train_total": 0.35819268226623535, "timer/dataset_train_frac": 0.0003580744422591146, "timer/dataset_train_avg": 0.00016582994549362747, "timer/dataset_train_min": 8.320808410644531e-05, "timer/dataset_train_max": 0.0008854866027832031, "timer/agent.train_count": 2160.0, "timer/agent.train_total": 961.8806524276733, "timer/agent.train_frac": 0.9615631340058206, "timer/agent.train_avg": 0.4453151168646636, "timer/agent.train_min": 0.4341247081756592, "timer/agent.train_max": 0.5675463676452637, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4712543487548828, "timer/agent.report_frac": 0.00047109878690141353, "timer/agent.report_avg": 0.2356271743774414, "timer/agent.report_min": 0.22824740409851074, "timer/agent.report_max": 0.24300694465637207, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.869171142578125e-05, "timer/dataset_eval_frac": 8.866243414260454e-08, "timer/dataset_eval_avg": 8.869171142578125e-05, "timer/dataset_eval_min": 8.869171142578125e-05, "timer/dataset_eval_max": 8.869171142578125e-05, "fps": 8.63702861829328}
{"step": 242704, "time": 28236.94768834114, "episode/length": 288.0, "episode/score": 0.03542361869531874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03542361869531874}
{"step": 242832, "time": 28251.672890901566, "episode/length": 288.0, "episode/score": 0.04763253530484235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04763253530484235}
{"step": 242880, "time": 28257.185292482376, "episode/length": 73.0, "episode/score": 0.7937353531561655, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.021860321136131233}
{"step": 242928, "time": 28262.775425195694, "episode/length": 91.0, "episode/score": 0.747290038834592, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.03166502136065219}
{"step": 243152, "time": 28288.427844524384, "episode/length": 288.0, "episode/score": 0.0356566387207522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0356566387207522}
{"step": 243440, "time": 28321.502373218536, "episode/length": 288.0, "episode/score": 0.0336708457599002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0336708457599002}
{"step": 243496, "time": 28327.910091638565, "episode/length": 288.0, "episode/score": 0.02773356440002317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02773356440002317}
{"step": 243936, "time": 28378.5602145195, "episode/length": 61.0, "episode/score": 0.8230938871173237, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.013718891878710338}
{"step": 243976, "time": 28383.258009910583, "episode/length": 59.0, "episode/score": 0.842201059493874, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.02657606267783308}
{"step": 244272, "time": 28417.395755052567, "episode/length": 288.0, "episode/score": 0.03583778096663082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03583778096663082}
{"step": 244288, "time": 28419.251523971558, "episode/length": 169.0, "episode/score": 0.5289143982430176, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.057039378143912245}
{"step": 244312, "time": 28421.991053819656, "episode/length": 46.0, "episode/score": 0.8703761842009214, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.014126214253536773}
{"step": 244384, "time": 28430.259144067764, "episode/length": 153.0, "episode/score": 0.5615414869621702, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.03966648622875368}
{"step": 244928, "time": 28492.782677412033, "episode/length": 81.0, "episode/score": 0.7761555075545914, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.029280512315978058}
{"step": 245016, "time": 28502.940850019455, "episode/length": 288.0, "episode/score": 0.038691521223398695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038691521223398695}
{"step": 245144, "time": 28517.61882209778, "episode/length": 288.0, "episode/score": 0.0705330047669861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0705330047669861}
{"step": 245192, "time": 28523.13437604904, "episode/length": 288.0, "episode/score": 0.060852967076186815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060852967076186815}
{"step": 246288, "time": 28649.60131931305, "episode/length": 288.0, "episode/score": 0.05937042848452734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05937042848452734}
{"step": 246592, "time": 28684.64722967148, "episode/length": 180.0, "episode/score": 0.5030952546194385, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.06559524294880248}
{"step": 246600, "time": 28685.58788061142, "episode/length": 288.0, "episode/score": 0.09522782204416558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09522782204416558}
{"step": 246624, "time": 28688.357553720474, "episode/length": 288.0, "episode/score": 0.06251745533353414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06251745533353414}
{"step": 246696, "time": 28696.609659433365, "episode/length": 288.0, "episode/score": 0.04037678068388573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04037678068388573}
{"step": 247240, "time": 28759.343237638474, "episode/length": 288.0, "episode/score": 0.0182606953391371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0182606953391371}
{"step": 247240, "time": 28759.35059261322, "episode/length": 76.0, "episode/score": 0.7803719005132166, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.017871924512235182}
{"step": 247248, "time": 28760.28648853302, "episode/length": 68.0, "episode/score": 0.8133162242643834, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.025816215527413533}
{"step": 247328, "time": 28769.579127073288, "episode/length": 288.0, "episode/score": 0.07592867088786193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07592867088786193}
{"step": 247504, "time": 28789.807914733887, "episode/length": 288.0, "episode/score": 0.03820888092084829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03820888092084829}
{"step": 247656, "time": 28807.33582997322, "episode/length": 131.0, "episode/score": 0.626107002871521, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.035482026870539585}
{"step": 247888, "time": 28833.970697641373, "episode/length": 80.0, "episode/score": 0.7766139475303646, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.02661396263525262}
{"step": 248008, "time": 28847.74166560173, "episode/length": 62.0, "episode/score": 0.8173119692695536, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.011062005189501178}
{"step": 248200, "time": 28869.87987136841, "episode/length": 238.0, "episode/score": 0.304595437205478, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.04834545732495599}
{"step": 248456, "time": 28899.31304860115, "episode/length": 150.0, "episode/score": 0.560479222170045, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.02922924839259622}
{"step": 248904, "time": 28950.86387515068, "episode/length": 288.0, "episode/score": 0.052177018057818714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052177018057818714}
{"step": 248920, "time": 28952.830728054047, "episode/length": 113.0, "episode/score": 0.683604392696509, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0367293950772023}
{"step": 249152, "time": 28979.554697752, "episode/length": 86.0, "episode/score": 0.755963397138089, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.024713423218031494}
{"step": 249512, "time": 29021.01037836075, "episode/length": 73.0, "episode/score": 0.7823353745389738, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.010460322582815706}
{"step": 249552, "time": 29025.603196144104, "episode/length": 288.0, "episode/score": 0.033299380848006876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033299380848006876}
{"step": 249576, "time": 29028.362575531006, "episode/length": 239.0, "episode/score": 0.31111225923160646, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.05798724899869967}
{"step": 249640, "time": 29035.751873731613, "episode/length": 288.0, "episode/score": 0.028891023209013156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028891023209013156}
{"step": 250016, "time": 29080.2761425972, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 250016, "time": 29080.8485827446, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 250016, "time": 29081.7192299366, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 250016, "time": 29082.70236134529, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 250016, "time": 29083.849180698395, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 29083.856977939606, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 29083.862444877625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 29083.867929935455, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 29083.87315750122, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 29083.87831234932, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250184, "time": 29103.09044957161, "episode/length": 83.0, "episode/score": 0.7645834308214603, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.023958421138615904}
{"step": 250200, "time": 29104.92937231064, "episode/length": 288.0, "episode/score": 0.02272667672579587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02272667672579587}
{"step": 250224, "time": 29107.656058073044, "episode/length": 83.0, "episode/score": 0.75660160098235, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.015976549026191833}
{"step": 250512, "time": 29140.64899277687, "episode/length": 288.0, "episode/score": 0.012858233893041415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012858233893041415}
{"step": 250744, "time": 29167.41633629799, "episode/length": 137.0, "episode/score": 0.5940929288809684, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.022217929505245593}
{"step": 250984, "time": 29194.89585208893, "episode/length": 97.0, "episode/score": 0.7070104657657623, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.010135473011160911}
{"step": 251128, "time": 29211.399265527725, "episode/length": 193.0, "episode/score": 0.42898720066060037, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.03211221568690803}
{"step": 251165, "time": 29216.504224300385, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.912653605143229, "train/action_min": 0.0, "train/action_std": 1.7624425413431946, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006069952077706586, "train/actor_opt_grad_steps": 61325.0, "train/actor_opt_loss": -9.746574844751093, "train/adv_mag": 0.4135608119821107, "train/adv_max": 0.19051443357710485, "train/adv_mean": 0.0015226022998386195, "train/adv_min": -0.38387802491585415, "train/adv_std": 0.01682371703726757, "train/cont_avg": 0.9960123697916666, "train/cont_loss_mean": 0.010620502442179713, "train/cont_loss_std": 0.17957546698205448, "train/cont_neg_acc": 0.523390557114468, "train/cont_neg_loss": 2.078845621467985, "train/cont_pos_acc": 0.999895592254621, "train/cont_pos_loss": 0.002028837122014482, "train/cont_pred": 0.9960958902482633, "train/cont_rate": 0.9960123697916666, "train/dyn_loss_mean": 1.0000031695321754, "train/dyn_loss_std": 8.912487869060392e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10843440832535702, "train/extr_critic_critic_opt_grad_steps": 61325.0, "train/extr_critic_critic_opt_loss": 10094.603559705945, "train/extr_critic_mag": 0.6540408073752014, "train/extr_critic_max": 0.6540408073752014, "train/extr_critic_mean": 0.5393898528483179, "train/extr_critic_min": 0.4593890662546511, "train/extr_critic_std": 0.024549693895365904, "train/extr_return_normed_mag": 0.4338561833180763, "train/extr_return_normed_max": 0.26923516516884166, "train/extr_return_normed_mean": 0.032978375899364, "train/extr_return_normed_min": -0.35424441982198646, "train/extr_return_normed_std": 0.030519726392985495, "train/extr_return_rate": 0.7076292775433373, "train/extr_return_raw_mag": 0.7771692234608862, "train/extr_return_raw_max": 0.7771692234608862, "train/extr_return_raw_mean": 0.5409124653648447, "train/extr_return_raw_min": 0.1536896384700581, "train/extr_return_raw_std": 0.030519726311063602, "train/extr_reward_mag": 0.315915709844342, "train/extr_reward_max": 0.315915709844342, "train/extr_reward_mean": 0.0007435654859162039, "train/extr_reward_min": 1.9277687425966618e-06, "train/extr_reward_std": 0.00611681689069546, "train/image_loss_mean": 0.08314509153435076, "train/image_loss_std": 0.10586379903058211, "train/model_loss_mean": 0.7066867285304599, "train/model_loss_std": 0.3011550025462552, "train/model_opt_grad_norm": 16.591885883863583, "train/model_opt_grad_steps": 61271.0, "train/model_opt_loss": 3680.0136424877023, "train/model_opt_model_opt_grad_overflow": 0.004629629629629629, "train/model_opt_model_opt_grad_scale": 5185.185185185185, "train/policy_entropy_mag": 1.4180548273854785, "train/policy_entropy_max": 1.4180548273854785, "train/policy_entropy_mean": 0.1227998302007715, "train/policy_entropy_min": 0.06468649791484629, "train/policy_entropy_std": 0.1633249354997167, "train/policy_logprob_mag": 6.5510802158602965, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.12310757377633343, "train/policy_logprob_min": -6.5510802158602965, "train/policy_logprob_std": 0.6626621708273888, "train/policy_randomness_mag": 0.728736067811648, "train/policy_randomness_max": 0.728736067811648, "train/policy_randomness_mean": 0.06310663275696614, "train/policy_randomness_min": 0.033242284699722575, "train/policy_randomness_std": 0.08393241899708907, "train/post_ent_mag": 33.2856221375642, "train/post_ent_max": 33.2856221375642, "train/post_ent_mean": 32.93933478108159, "train/post_ent_min": 32.60765473047892, "train/post_ent_std": 0.13041318249371317, "train/prior_ent_mag": 33.380557431115044, "train/prior_ent_max": 33.380557431115044, "train/prior_ent_mean": 32.66858624528955, "train/prior_ent_min": 31.836688977700693, "train/prior_ent_std": 0.25940613765959386, "train/rep_loss_mean": 1.0000031695321754, "train/rep_loss_std": 8.912487869060392e-05, "train/reward_avg": 0.0007079489393988668, "train/reward_loss_mean": 0.012919212018864023, "train/reward_loss_std": 0.10406343187895362, "train/reward_max_data": 0.385758830454304, "train/reward_max_pred": 0.1317859689394633, "train/reward_neg_acc": 0.9998823263578944, "train/reward_neg_loss": 0.009272529118418417, "train/reward_pos_acc": 0.2600806454016316, "train/reward_pos_loss": 4.25178340221605, "train/reward_pred": 0.0005728611253693493, "train/reward_rate": 0.0008544921875, "train_stats/mean_log_entropy": 0.09343486570793649, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.008423634804785252, "report/cont_loss_std": 0.17288464307785034, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 1.2585108280181885, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002289742697030306, "report/cont_pred": 0.9945288896560669, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07160098850727081, "report/image_loss_std": 0.09983665496110916, "report/model_loss_mean": 0.6895174980163574, "report/model_loss_std": 0.20488211512565613, "report/post_ent_mag": 32.91038131713867, "report/post_ent_max": 32.91038131713867, "report/post_ent_mean": 32.54924011230469, "report/post_ent_min": 32.254886627197266, "report/post_ent_std": 0.13924330472946167, "report/prior_ent_mag": 32.98609161376953, "report/prior_ent_max": 32.98609161376953, "report/prior_ent_mean": 32.24339294433594, "report/prior_ent_min": 31.513126373291016, "report/prior_ent_std": 0.26365435123443604, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0010200431570410728, "report/reward_loss_mean": 0.009492903016507626, "report/reward_loss_std": 0.02728179097175598, "report/reward_max_data": 0.8567500114440918, "report/reward_max_pred": 0.48552000522613525, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008811109699308872, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7069677114486694, "report/reward_pred": 0.0010609021410346031, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04578035697340965, "eval/cont_loss_std": 0.7509758472442627, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.282840728759766, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0017134519293904305, "eval/cont_pred": 0.9983125925064087, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20303252339363098, "eval/image_loss_std": 0.17452825605869293, "eval/model_loss_mean": 0.864504337310791, "eval/model_loss_std": 1.1061251163482666, "eval/post_ent_mag": 32.912315368652344, "eval/post_ent_max": 32.912315368652344, "eval/post_ent_mean": 32.545989990234375, "eval/post_ent_min": 32.27180480957031, "eval/post_ent_std": 0.13059654831886292, "eval/prior_ent_mag": 32.98609161376953, "eval/prior_ent_max": 32.98609161376953, "eval/prior_ent_mean": 32.21080017089844, "eval/prior_ent_min": 31.447845458984375, "eval/prior_ent_std": 0.2805376946926117, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005310058477334678, "eval/reward_loss_mean": 0.01569145917892456, "eval/reward_loss_std": 0.44830045104026794, "eval/reward_max_data": 0.543749988079071, "eval/reward_max_pred": 0.03909456729888916, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0016755592077970505, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 14.353959083557129, "eval/reward_pred": 0.0004163945559412241, "eval/reward_rate": 0.0009765625, "replay/size": 250661.0, "replay/inserts": 8640.0, "replay/samples": 34560.0, "replay/insert_wait_avg": 1.5039686803464536e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.501354923954717e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 60672.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0171976056478429e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0225989818573, "timer/env.step_count": 1080.0, "timer/env.step_total": 10.052281856536865, "timer/env.step_frac": 0.01005205469033529, "timer/env.step_avg": 0.009307668385682283, "timer/env.step_min": 0.008158683776855469, "timer/env.step_max": 0.030464649200439453, "timer/replay._sample_count": 34560.0, "timer/replay._sample_total": 16.233567237854004, "timer/replay._sample_frac": 0.01623320038405304, "timer/replay._sample_avg": 0.00046972127424346077, "timer/replay._sample_min": 0.0003497600555419922, "timer/replay._sample_max": 0.010442256927490234, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1369.0, "timer/agent.policy_total": 13.176745414733887, "timer/agent.policy_frac": 0.013176447640432716, "timer/agent.policy_avg": 0.009625087958169383, "timer/agent.policy_min": 0.008553266525268555, "timer/agent.policy_max": 0.035132408142089844, "timer/dataset_train_count": 2160.0, "timer/dataset_train_total": 0.36109280586242676, "timer/dataset_train_frac": 0.00036108464571706924, "timer/dataset_train_avg": 0.00016717259530667905, "timer/dataset_train_min": 8.535385131835938e-05, "timer/dataset_train_max": 0.0007481575012207031, "timer/agent.train_count": 2160.0, "timer/agent.train_total": 962.3618023395538, "timer/agent.train_frac": 0.9623400544341231, "timer/agent.train_avg": 0.44553787145349716, "timer/agent.train_min": 0.4321556091308594, "timer/agent.train_max": 0.5865387916564941, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4791295528411865, "timer/agent.report_frac": 0.0004791187252458072, "timer/agent.report_avg": 0.23956477642059326, "timer/agent.report_min": 0.23295950889587402, "timer/agent.report_max": 0.2461700439453125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 9.632110595703125e-05, "timer/dataset_eval_frac": 9.631892924729668e-08, "timer/dataset_eval_avg": 9.632110595703125e-05, "timer/dataset_eval_min": 9.632110595703125e-05, "timer/dataset_eval_max": 9.632110595703125e-05, "fps": 8.639680194333016}
{"step": 251216, "time": 29222.195888757706, "episode/length": 288.0, "episode/score": 0.021421348428532383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021421348428532383}
{"step": 251464, "time": 29250.62384057045, "episode/length": 288.0, "episode/score": 0.05211780435169544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05211780435169544}
{"step": 251512, "time": 29256.28307247162, "episode/length": 165.0, "episode/score": 0.5174206801609955, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.033045689226838704}
{"step": 251616, "time": 29268.408978700638, "episode/length": 137.0, "episode/score": 0.6075307166610173, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.03565575863456161}
{"step": 251720, "time": 29280.424365758896, "episode/length": 12.0, "episode/score": 0.9674159820080774, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.004916006068214074}
{"step": 251968, "time": 29309.015752077103, "episode/length": 152.0, "episode/score": 0.549322825217871, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.02432283474064434}
{"step": 252296, "time": 29346.818794727325, "episode/length": 97.0, "episode/score": 0.7223810245454558, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.025506034068229155}
{"step": 252536, "time": 29374.43174958229, "episode/length": 288.0, "episode/score": 0.012960718710445462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012960718710445462}
{"step": 252848, "time": 29410.355479240417, "episode/length": 172.0, "episode/score": 0.4906508156762186, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.02815079804511811}
{"step": 253264, "time": 29458.100353479385, "episode/length": 161.0, "episode/score": 0.5418198739648687, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.04494488704995092}
{"step": 253296, "time": 29461.92178463936, "episode/length": 288.0, "episode/score": 0.04437471407371163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04437471407371163}
{"step": 253440, "time": 29478.503321647644, "episode/length": 288.0, "episode/score": 0.03938742362515768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03938742362515768}
{"step": 253512, "time": 29486.793135404587, "episode/length": 82.0, "episode/score": 0.767872135799962, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.024122151463643604}
{"step": 253528, "time": 29488.65476512909, "episode/length": 288.0, "episode/score": 0.06451301359962258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06451301359962258}
{"step": 254032, "time": 29547.199717760086, "episode/length": 288.0, "episode/score": 0.05765140181449624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05765140181449624}
{"step": 254152, "time": 29561.097693681717, "episode/length": 88.0, "episode/score": 0.7421953249421449, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.017195293940744705}
{"step": 254608, "time": 29613.803525209427, "episode/length": 288.0, "episode/score": 0.06791500985116272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06791500985116272}
{"step": 254704, "time": 29624.848522663116, "episode/length": 83.0, "episode/score": 0.7487917957563468, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.008166790046175265}
{"step": 254712, "time": 29625.779551267624, "episode/length": 149.0, "episode/score": 0.553249605797987, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.01887459409533676}
{"step": 254848, "time": 29641.507677316666, "episode/length": 288.0, "episode/score": 0.01806045305272619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01806045305272619}
{"step": 254856, "time": 29642.430197238922, "episode/length": 87.0, "episode/score": 0.7458523171613933, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.017727326684166655}
{"step": 255208, "time": 29683.004162549973, "episode/length": 44.0, "episode/score": 0.8698986596366467, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.007398648530624996}
{"step": 255576, "time": 29725.41405105591, "episode/length": 288.0, "episode/score": 0.06792847320707551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06792847320707551}
{"step": 255608, "time": 29729.15857052803, "episode/length": 288.0, "episode/score": 0.027068252765388934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027068252765388934}
{"step": 255816, "time": 29753.255589723587, "episode/length": 137.0, "episode/score": 0.603349243297771, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.031474238501459695}
{"step": 255840, "time": 29756.031538009644, "episode/length": 288.0, "episode/score": 0.024736806271448586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024736806271448586}
{"step": 255944, "time": 29768.157500982285, "episode/length": 166.0, "episode/score": 0.5206362625858674, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.03938628096784669}
{"step": 256624, "time": 29846.684541225433, "episode/length": 126.0, "episode/score": 0.629171919127657, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.022921901653717214}
{"step": 256664, "time": 29851.38820028305, "episode/length": 135.0, "episode/score": 0.5941850431497642, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.016060035990221877}
{"step": 257016, "time": 29892.1409034729, "episode/length": 288.0, "episode/score": 0.03179270242378607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03179270242378607}
{"step": 257168, "time": 29909.616461992264, "episode/length": 288.0, "episode/score": 0.046762550651010315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046762550651010315}
{"step": 257184, "time": 29911.503712892532, "episode/length": 64.0, "episode/score": 0.818041770705122, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.018041778924043683}
{"step": 257520, "time": 29950.213711500168, "episode/length": 288.0, "episode/score": 0.03223734461653294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03223734461653294}
{"step": 257832, "time": 29986.227368831635, "episode/length": 80.0, "episode/score": 0.7735705801209178, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.02357058093582509}
{"step": 258128, "time": 30020.488577365875, "episode/length": 288.0, "episode/score": 0.05490125134951995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05490125134951995}
{"step": 258152, "time": 30023.249408006668, "episode/length": 288.0, "episode/score": 0.06069528255602563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06069528255602563}
{"step": 258200, "time": 30028.78435921669, "episode/length": 147.0, "episode/score": 0.5779233089787112, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.03729831850148457}
{"step": 258208, "time": 30029.707333803177, "episode/length": 129.0, "episode/score": 0.6412604777154911, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.044385442453290125}
{"step": 258256, "time": 30035.29337120056, "episode/length": 288.0, "episode/score": 0.03766902588540688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03766902588540688}
{"step": 258936, "time": 30113.584793567657, "episode/length": 288.0, "episode/score": 0.02444866891391939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02444866891391939}
{"step": 259304, "time": 30155.84725356102, "episode/length": 183.0, "episode/score": 0.48662443424734647, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.05849944137196417}
{"step": 259504, "time": 30178.793692827225, "episode/length": 70.0, "episode/score": 0.7974684198229625, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0162184116447861}
{"step": 259704, "time": 30201.830934524536, "episode/length": 186.0, "episode/score": 0.4766360448705882, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.057886057198970775}
{"step": 259825, "time": 30216.618803977966, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.067080744990596, "train/action_min": 0.0, "train/action_std": 1.747850325924379, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005475243646220339, "train/actor_opt_grad_steps": 63485.0, "train/actor_opt_loss": -8.10584921831334, "train/adv_mag": 0.4722073630050377, "train/adv_max": 0.17231461681701518, "train/adv_mean": 0.0012175942414134827, "train/adv_min": -0.4387252356995035, "train/adv_std": 0.014988106543939837, "train/cont_avg": 0.9960621021412037, "train/cont_loss_mean": 0.009600097623155711, "train/cont_loss_std": 0.16546422050925214, "train/cont_neg_acc": 0.5327428046137236, "train/cont_neg_loss": 1.961546560623479, "train/cont_pos_acc": 0.999904655471996, "train/cont_pos_loss": 0.0019222530479762806, "train/cont_pred": 0.9960400600124288, "train/cont_rate": 0.9960621021412037, "train/dyn_loss_mean": 1.000000454209469, "train/dyn_loss_std": 1.4521483400905574e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15409318413757891, "train/extr_critic_critic_opt_grad_steps": 63485.0, "train/extr_critic_critic_opt_loss": 4278.062219690393, "train/extr_critic_mag": 0.6936823085502342, "train/extr_critic_max": 0.6936823085502342, "train/extr_critic_mean": 0.6113020167858513, "train/extr_critic_min": 0.5148971417435894, "train/extr_critic_std": 0.014891093070791275, "train/extr_return_normed_mag": 0.48484179377555847, "train/extr_return_normed_max": 0.2188360125378326, "train/extr_return_normed_mean": 0.025485476729011646, "train/extr_return_normed_min": -0.4280042108838205, "train/extr_return_normed_std": 0.021995083521620405, "train/extr_return_rate": 0.9990494008417483, "train/extr_return_raw_mag": 0.8058701309340971, "train/extr_return_raw_max": 0.8058701309340971, "train/extr_return_raw_mean": 0.612519629575588, "train/extr_return_raw_min": 0.15902990751244403, "train/extr_return_raw_std": 0.021995083629412368, "train/extr_reward_mag": 0.25423695809311336, "train/extr_reward_max": 0.25423695809311336, "train/extr_reward_mean": 0.0006900813068905673, "train/extr_reward_min": 1.8074556633278175e-06, "train/extr_reward_std": 0.0052084935744426695, "train/image_loss_mean": 0.07970216972063537, "train/image_loss_std": 0.10352282098459976, "train/model_loss_mean": 0.7020962765371358, "train/model_loss_std": 0.2812216591641859, "train/model_opt_grad_norm": 17.051094368652063, "train/model_opt_grad_steps": 63428.976851851854, "train/model_opt_loss": 3866.8780065465858, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5509.259259259259, "train/policy_entropy_mag": 1.4362621655066807, "train/policy_entropy_max": 1.4362621655066807, "train/policy_entropy_mean": 0.12107451839579476, "train/policy_entropy_min": 0.06468649781136601, "train/policy_entropy_std": 0.16232984933864186, "train/policy_logprob_mag": 6.551080235728511, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.12080933346792504, "train/policy_logprob_min": -6.551080235728511, "train/policy_logprob_std": 0.65986778145587, "train/policy_randomness_mag": 0.7380927886675905, "train/policy_randomness_max": 0.7380927886675905, "train/policy_randomness_mean": 0.06221999788518857, "train/policy_randomness_min": 0.03324228457899557, "train/policy_randomness_std": 0.08342104550037119, "train/post_ent_mag": 33.04335988009417, "train/post_ent_max": 33.04335988009417, "train/post_ent_mean": 32.676629613946986, "train/post_ent_min": 32.33391003255491, "train/post_ent_std": 0.13812431813804088, "train/prior_ent_mag": 33.11146146279794, "train/prior_ent_max": 33.11146146279794, "train/prior_ent_mean": 32.34060863212303, "train/prior_ent_min": 31.577170628088492, "train/prior_ent_std": 0.25917417038646007, "train/rep_loss_mean": 1.000000454209469, "train/rep_loss_std": 1.4521483400905574e-05, "train/reward_avg": 0.0007275826593724088, "train/reward_loss_mean": 0.01279371436814674, "train/reward_loss_std": 0.09659962647991185, "train/reward_max_data": 0.39240179656836616, "train/reward_max_pred": 0.1432859229820746, "train/reward_neg_acc": 0.9998416188690398, "train/reward_neg_loss": 0.00935064179012207, "train/reward_pos_acc": 0.3059796445242321, "train/reward_pos_loss": 3.81714117538383, "train/reward_pred": 0.0006222741568409321, "train/reward_rate": 0.0008997034143518518, "train_stats/mean_log_entropy": 0.0977032408118248, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.011266883462667465, "report/cont_loss_std": 0.18778033554553986, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.247143745422363, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0029774976428598166, "report/cont_pred": 0.9970365166664124, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08813335746526718, "report/image_loss_std": 0.10872425138950348, "report/model_loss_mean": 0.714759886264801, "report/model_loss_std": 0.3795604109764099, "report/post_ent_mag": 33.288211822509766, "report/post_ent_max": 33.288211822509766, "report/post_ent_mean": 32.93859100341797, "report/post_ent_min": 32.61542510986328, "report/post_ent_std": 0.1365227848291397, "report/prior_ent_mag": 33.02408218383789, "report/prior_ent_max": 33.02408218383789, "report/prior_ent_mean": 32.28790283203125, "report/prior_ent_min": 31.64433479309082, "report/prior_ent_std": 0.24966605007648468, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0010476120514795184, "report/reward_loss_mean": 0.0153596680611372, "report/reward_loss_std": 0.1839032918214798, "report/reward_max_data": 0.8753571510314941, "report/reward_max_pred": 0.0527498722076416, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009630603715777397, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.876193523406982, "report/reward_pred": 0.0008077272213995457, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03511922061443329, "eval/cont_loss_std": 0.5666189193725586, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.480846405029297, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0019987202249467373, "eval/cont_pred": 0.9980325698852539, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17787054181098938, "eval/image_loss_std": 0.1553562879562378, "eval/model_loss_mean": 0.8400565981864929, "eval/model_loss_std": 1.138067603111267, "eval/post_ent_mag": 33.29818344116211, "eval/post_ent_max": 33.29818344116211, "eval/post_ent_mean": 32.924102783203125, "eval/post_ent_min": 32.5664176940918, "eval/post_ent_std": 0.13818350434303284, "eval/prior_ent_mag": 33.27655029296875, "eval/prior_ent_max": 33.27655029296875, "eval/prior_ent_mean": 32.31562805175781, "eval/prior_ent_min": 31.584590911865234, "eval/prior_ent_std": 0.27842438220977783, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0016143799293786287, "eval/reward_loss_mean": 0.02706681564450264, "eval/reward_loss_std": 0.5743786692619324, "eval/reward_max_data": 0.890625, "eval/reward_max_pred": 0.021702051162719727, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002016145968809724, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 12.827958106994629, "eval/reward_pred": 0.00047453760635107756, "eval/reward_rate": 0.001953125, "replay/size": 259321.0, "replay/inserts": 8660.0, "replay/samples": 34640.0, "replay/insert_wait_avg": 1.5151418108863037e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.626779084943458e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 60672.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.100011587143, "timer/env.step_count": 1083.0, "timer/env.step_total": 10.087100982666016, "timer/env.step_frac": 0.010086092256571366, "timer/env.step_avg": 0.009314035995074807, "timer/env.step_min": 0.008339643478393555, "timer/env.step_max": 0.014585018157958984, "timer/replay._sample_count": 34640.0, "timer/replay._sample_total": 16.494261264801025, "timer/replay._sample_frac": 0.016492611812517523, "timer/replay._sample_avg": 0.00047616227669748917, "timer/replay._sample_min": 0.0003342628479003906, "timer/replay._sample_max": 0.024130582809448242, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1083.0, "timer/agent.policy_total": 10.66891860961914, "timer/agent.policy_frac": 0.010667851700839134, "timer/agent.policy_avg": 0.009851263720793297, "timer/agent.policy_min": 0.008865118026733398, "timer/agent.policy_max": 0.04374217987060547, "timer/dataset_train_count": 2165.0, "timer/dataset_train_total": 0.37071800231933594, "timer/dataset_train_frac": 0.0003706809299312099, "timer/dataset_train_avg": 0.0001712323336347972, "timer/dataset_train_min": 8.678436279296875e-05, "timer/dataset_train_max": 0.0005054473876953125, "timer/agent.train_count": 2165.0, "timer/agent.train_total": 967.0172030925751, "timer/agent.train_frac": 0.9669204998387452, "timer/agent.train_avg": 0.4466592162090416, "timer/agent.train_min": 0.4321274757385254, "timer/agent.train_max": 0.5722155570983887, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47840261459350586, "timer/agent.report_frac": 0.00047835477357338336, "timer/agent.report_avg": 0.23920130729675293, "timer/agent.report_min": 0.23325204849243164, "timer/agent.report_max": 0.24515056610107422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.670021052894295e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 8.659015383996213}
{"step": 259832, "time": 30217.209834098816, "episode/length": 288.0, "episode/score": 0.08436133737131968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08436133737131968}
{"step": 259976, "time": 30233.750150442123, "episode/length": 221.0, "episode/score": 0.33870715180421485, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.02933215406267209}
{"step": 260000, "time": 30237.136825084686, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 260000, "time": 30237.724356889725, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 260000, "time": 30238.34106040001, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 260000, "time": 30238.472120046616, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 260000, "time": 30238.550812721252, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 260000, "time": 30240.231534719467, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 260000, "time": 30240.96910214424, "eval_episode/length": 176.0, "eval_episode/score": 0.44999998807907104, "eval_episode/reward_rate": 0.005649717514124294}
{"step": 260000, "time": 30241.82503080368, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 30241.832953453064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 30241.838726997375, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 30241.844670295715, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260216, "time": 30266.634256362915, "episode/length": 63.0, "episode/score": 0.8244330155239368, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.021307983503902506}
{"step": 260440, "time": 30292.435992002487, "episode/length": 288.0, "episode/score": 0.055208883644411344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055208883644411344}
{"step": 260464, "time": 30295.19489645958, "episode/length": 288.0, "episode/score": 0.05999807245967759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05999807245967759}
{"step": 260568, "time": 30307.24214553833, "episode/length": 288.0, "episode/score": 0.08468603386921814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08468603386921814}
{"step": 261616, "time": 30427.877938985825, "episode/length": 288.0, "episode/score": 0.05641739133795909, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05641739133795909}
{"step": 261816, "time": 30450.877762317657, "episode/length": 288.0, "episode/score": 0.05990839794742442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05990839794742442}
{"step": 262144, "time": 30489.168668985367, "episode/length": 288.0, "episode/score": 0.0440003216959326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0440003216959326}
{"step": 262288, "time": 30505.848048210144, "episode/length": 288.0, "episode/score": 0.05035599342710384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05035599342710384}
{"step": 262528, "time": 30533.559349536896, "episode/length": 288.0, "episode/score": 0.05222143777552901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05222143777552901}
{"step": 262752, "time": 30559.480262756348, "episode/length": 288.0, "episode/score": 0.0547769165009413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0547769165009413}
{"step": 262776, "time": 30562.304490566254, "episode/length": 288.0, "episode/score": 0.049357970234382265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049357970234382265}
{"step": 262880, "time": 30574.534778356552, "episode/length": 288.0, "episode/score": 0.04646378766864245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04646378766864245}
{"step": 263048, "time": 30593.892288446426, "episode/length": 94.0, "episode/score": 0.7415984275372693, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.03534838697817122}
{"step": 263584, "time": 30655.711332798004, "episode/length": 103.0, "episode/score": 0.7091100772549908, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0309850542280401}
{"step": 263832, "time": 30684.42441177368, "episode/length": 30.0, "episode/score": 0.9238259638373165, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.017575935199147352}
{"step": 263928, "time": 30695.60877776146, "episode/length": 288.0, "episode/score": 0.04820497922355571, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04820497922355571}
{"step": 263992, "time": 30703.038769245148, "episode/length": 230.0, "episode/score": 0.32887810554672114, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0476281063616284}
{"step": 264128, "time": 30718.856128931046, "episode/length": 288.0, "episode/score": 0.05423110084052496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05423110084052496}
{"step": 264592, "time": 30772.32868218422, "episode/length": 94.0, "episode/score": 0.732674386936992, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.02642436069697851}
{"step": 264808, "time": 30797.262010097504, "episode/length": 219.0, "episode/score": 0.3708637557804195, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.055238744266944195}
{"step": 264840, "time": 30801.015318870544, "episode/length": 288.0, "episode/score": 0.0653860554551784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0653860554551784}
{"step": 265088, "time": 30829.637098550797, "episode/length": 288.0, "episode/score": 0.04896234472141714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04896234472141714}
{"step": 265192, "time": 30841.622323274612, "episode/length": 288.0, "episode/score": 0.050949988563729676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050949988563729676}
{"step": 265464, "time": 30872.85461640358, "episode/length": 166.0, "episode/score": 0.5213721810457628, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.040122193374145354}
{"step": 266240, "time": 30962.474187850952, "episode/length": 288.0, "episode/score": 0.03956761824815658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03956761824815658}
{"step": 266304, "time": 30969.811800718307, "episode/length": 288.0, "episode/score": 0.033156859509517744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033156859509517744}
{"step": 266632, "time": 31007.582434892654, "episode/length": 48.0, "episode/score": 0.8583298371082719, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.008329833406264697}
{"step": 266728, "time": 31018.650332689285, "episode/length": 204.0, "episode/score": 0.40326623060252587, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.04076621984575013}
{"step": 266904, "time": 31038.952637195587, "episode/length": 288.0, "episode/score": 0.030950499977620893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030950499977620893}
{"step": 266912, "time": 31039.879892349243, "episode/length": 214.0, "episode/score": 0.39059659122528956, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.05934656964188889}
{"step": 267080, "time": 31059.304790258408, "episode/length": 96.0, "episode/score": 0.7279226657229856, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.027922663324829955}
{"step": 267120, "time": 31063.917160749435, "episode/length": 288.0, "episode/score": 0.06838221300665737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06838221300665737}
{"step": 267152, "time": 31067.61548924446, "episode/length": 288.0, "episode/score": 0.06780958438002926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06780958438002926}
{"step": 267224, "time": 31076.015003204346, "episode/length": 39.0, "episode/score": 0.8874838474046669, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.009358850588625955}
{"step": 267296, "time": 31084.40760564804, "episode/length": 82.0, "episode/score": 0.7745784185214006, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.03082841902198652}
{"step": 267608, "time": 31120.4235329628, "episode/length": 60.0, "episode/score": 0.8331194787082268, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.020619496839913154}
{"step": 267776, "time": 31139.756060123444, "episode/length": 288.0, "episode/score": 0.04249224694387976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04249224694387976}
{"step": 267904, "time": 31154.525446891785, "episode/length": 123.0, "episode/score": 0.6467766142586697, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.031151561021943053}
{"step": 268437, "time": 31216.902719020844, "train_stats/mean_log_entropy": 0.07615009173750878, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.1019470779984086, "train/action_min": 0.0, "train/action_std": 1.6754049046172037, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00584926155796792, "train/actor_opt_grad_steps": 65645.0, "train/actor_opt_loss": -9.530793675669917, "train/adv_mag": 0.4581742718539856, "train/adv_max": 0.20411609140811143, "train/adv_mean": 0.0017324726434590385, "train/adv_min": -0.4265731327511646, "train/adv_std": 0.01657006262232446, "train/cont_avg": 0.9960575810185185, "train/cont_loss_mean": 0.009908217956156781, "train/cont_loss_std": 0.17112538903623958, "train/cont_neg_acc": 0.5089922211361382, "train/cont_neg_loss": 2.011090334722607, "train/cont_pos_acc": 0.9998819499656006, "train/cont_pos_loss": 0.0021088890676360782, "train/cont_pred": 0.9959703027098267, "train/cont_rate": 0.9960575810185185, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09371942933217657, "train/extr_critic_critic_opt_grad_steps": 65645.0, "train/extr_critic_critic_opt_loss": 10352.317441587094, "train/extr_critic_mag": 0.7653716052020038, "train/extr_critic_max": 0.7653716052020038, "train/extr_critic_mean": 0.6667496379878786, "train/extr_critic_min": 0.5235921481141338, "train/extr_critic_std": 0.02162140380608401, "train/extr_return_normed_mag": 0.4822550771964921, "train/extr_return_normed_max": 0.24047295307671582, "train/extr_return_normed_mean": 0.03190524844211285, "train/extr_return_normed_min": -0.41725324618595616, "train/extr_return_normed_std": 0.02793748969108694, "train/extr_return_rate": 0.9992751520540979, "train/extr_return_raw_mag": 0.8770497913161913, "train/extr_return_raw_max": 0.8770497913161913, "train/extr_return_raw_mean": 0.6684821214940813, "train/extr_return_raw_min": 0.21932359205351937, "train/extr_return_raw_std": 0.02793748966521687, "train/extr_reward_mag": 0.28787620807135544, "train/extr_reward_max": 0.28787620807135544, "train/extr_reward_mean": 0.0007086204970147702, "train/extr_reward_min": 1.5922166683055736e-06, "train/extr_reward_std": 0.005732219408619804, "train/image_loss_mean": 0.08097562330119588, "train/image_loss_std": 0.10489517350301698, "train/model_loss_mean": 0.703049191446216, "train/model_loss_std": 0.2749464615696558, "train/model_opt_grad_norm": 16.46342263839863, "train/model_opt_grad_steps": 65587.02314814815, "train/model_opt_loss": 3828.5010952419707, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5439.814814814815, "train/policy_entropy_mag": 1.4744133253892262, "train/policy_entropy_max": 1.4744133253892262, "train/policy_entropy_mean": 0.1135872554861837, "train/policy_entropy_min": 0.06468649277532543, "train/policy_entropy_std": 0.15069252494032737, "train/policy_logprob_mag": 6.55108024014367, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1133631398142488, "train/policy_logprob_min": -6.55108024014367, "train/policy_logprob_std": 0.6505384983287917, "train/policy_randomness_mag": 0.7576986104249954, "train/policy_randomness_max": 0.7576986104249954, "train/policy_randomness_mean": 0.058372305533676234, "train/policy_randomness_min": 0.03324228187126142, "train/policy_randomness_std": 0.07744064328640148, "train/post_ent_mag": 33.48873254987929, "train/post_ent_max": 33.48873254987929, "train/post_ent_mean": 33.13124338785807, "train/post_ent_min": 32.79412186587298, "train/post_ent_std": 0.13713142869097214, "train/prior_ent_mag": 33.27870927033601, "train/prior_ent_max": 33.27870927033601, "train/prior_ent_mean": 32.54639902821294, "train/prior_ent_min": 31.84527431594001, "train/prior_ent_std": 0.2448306124381445, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0006668959376838757, "train/reward_loss_mean": 0.01216532726323715, "train/reward_loss_std": 0.08587168268341985, "train/reward_max_data": 0.3568772464361111, "train/reward_max_pred": 0.15766068851506268, "train/reward_neg_acc": 0.9999139960165377, "train/reward_neg_loss": 0.009258800539774474, "train/reward_pos_acc": 0.3575268822812265, "train/reward_pos_loss": 3.588469137107172, "train/reward_pred": 0.0006343836791563297, "train/reward_rate": 0.000804759837962963, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.009821216575801373, "report/cont_loss_std": 0.22140103578567505, "report/cont_neg_acc": 0.8333333730697632, "report/cont_neg_loss": 1.1372438669204712, "report/cont_pos_acc": 0.9990177154541016, "report/cont_pos_loss": 0.003176289377734065, "report/cont_pred": 0.9935104250907898, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07526067644357681, "report/image_loss_std": 0.09441091865301132, "report/model_loss_mean": 0.6964417695999146, "report/model_loss_std": 0.24604377150535583, "report/post_ent_mag": 33.89653778076172, "report/post_ent_max": 33.89653778076172, "report/post_ent_mean": 33.52874755859375, "report/post_ent_min": 33.21385955810547, "report/post_ent_std": 0.14646464586257935, "report/prior_ent_mag": 33.277740478515625, "report/prior_ent_max": 33.277740478515625, "report/prior_ent_mean": 32.59160614013672, "report/prior_ent_min": 31.987812042236328, "report/prior_ent_std": 0.2483532577753067, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.000714602880179882, "report/reward_loss_mean": 0.01135985180735588, "report/reward_loss_std": 0.0299761313945055, "report/reward_max_data": 0.47862499952316284, "report/reward_max_pred": 0.41023969650268555, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01056756917387247, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8218660354614258, "report/reward_pred": 0.0007274356903508306, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.027020612731575966, "eval/cont_loss_std": 0.5770662426948547, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 13.070314407348633, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0014955736696720123, "eval/cont_pred": 0.9985262751579285, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26273801922798157, "eval/image_loss_std": 0.16405929625034332, "eval/model_loss_mean": 0.8911492824554443, "eval/model_loss_std": 0.6043371558189392, "eval/post_ent_mag": 33.8969841003418, "eval/post_ent_max": 33.8969841003418, "eval/post_ent_mean": 33.513710021972656, "eval/post_ent_min": 33.197906494140625, "eval/post_ent_std": 0.13280989229679108, "eval/prior_ent_mag": 33.27392578125, "eval/prior_ent_max": 33.27392578125, "eval/prior_ent_mean": 32.62550354003906, "eval/prior_ent_min": 31.946033477783203, "eval/prior_ent_std": 0.23675192892551422, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013906355015933514, "eval/reward_loss_std": 0.0023203545715659857, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.020180106163024902, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013906355015933514, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00030005164444446564, "eval/reward_rate": 0.0, "replay/size": 267933.0, "replay/inserts": 8612.0, "replay/samples": 34448.0, "replay/insert_wait_avg": 1.5241680065532425e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.654545864170781e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 62984.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1006234838888307e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2691264152527, "timer/env.step_count": 1076.0, "timer/env.step_total": 9.997637271881104, "timer/env.step_frac": 0.009994947367525443, "timer/env.step_avg": 0.0092914844534211, "timer/env.step_min": 0.007769107818603516, "timer/env.step_max": 0.034397125244140625, "timer/replay._sample_count": 34448.0, "timer/replay._sample_total": 16.379844427108765, "timer/replay._sample_frac": 0.0163754373643527, "timer/replay._sample_avg": 0.0004754947871315828, "timer/replay._sample_min": 0.00036334991455078125, "timer/replay._sample_max": 0.010089635848999023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1365.0, "timer/agent.policy_total": 13.461031675338745, "timer/agent.policy_frac": 0.01345740993084547, "timer/agent.policy_avg": 0.009861561666914832, "timer/agent.policy_min": 0.008780241012573242, "timer/agent.policy_max": 0.03693079948425293, "timer/dataset_train_count": 2153.0, "timer/dataset_train_total": 0.3716411590576172, "timer/dataset_train_frac": 0.00037154116751508505, "timer/dataset_train_avg": 0.00017261549422090906, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.0005044937133789062, "timer/agent.train_count": 2153.0, "timer/agent.train_total": 962.0731189250946, "timer/agent.train_frac": 0.9618142692986594, "timer/agent.train_avg": 0.44685235435443316, "timer/agent.train_min": 0.43480825424194336, "timer/agent.train_max": 0.5726370811462402, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47606611251831055, "timer/agent.report_frac": 0.00047593802502375344, "timer/agent.report_avg": 0.23803305625915527, "timer/agent.report_min": 0.23209381103515625, "timer/agent.report_max": 0.2439723014831543, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9317595090221726e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 8.609564634564277}
{"step": 268440, "time": 31216.912405490875, "episode/length": 66.0, "episode/score": 0.8041886443472777, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.01043864194912203}
{"step": 268584, "time": 31233.921763658524, "episode/length": 187.0, "episode/score": 0.4634720199254616, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.04784701512915035}
{"step": 268696, "time": 31246.79621195793, "episode/length": 245.0, "episode/score": 0.2910488609364279, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.05667386739747826}
{"step": 269144, "time": 31298.443596839905, "episode/length": 230.0, "episode/score": 0.32723848702761416, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.04598847270852957}
{"step": 269304, "time": 31316.955953121185, "episode/length": 190.0, "episode/score": 0.4356921353103189, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.029442120991234333}
{"step": 269376, "time": 31325.305307149887, "episode/length": 116.0, "episode/score": 0.6859266967726398, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.048426694374484214}
{"step": 269464, "time": 31335.436309099197, "episode/length": 288.0, "episode/score": 0.03965458543547129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03965458543547129}
{"step": 269536, "time": 31343.723821401596, "episode/length": 288.0, "episode/score": 0.046401459329842965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046401459329842965}
{"step": 269920, "time": 31388.062720775604, "episode/length": 288.0, "episode/score": 0.03568285007787608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03568285007787608}
{"step": 269936, "time": 31389.90179824829, "episode/length": 49.0, "episode/score": 0.8621952547343881, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.015320213418590356}
{"step": 270064, "time": 31404.610205888748, "episode/length": 74.0, "episode/score": 0.7768970439551595, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.008147017715145921}
{"step": 270088, "time": 31408.509334802628, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 270088, "time": 31409.15560078621, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 270088, "time": 31409.694441318512, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 270088, "time": 31410.2421104908, "eval_episode/length": 164.0, "eval_episode/score": 0.48750001192092896, "eval_episode/reward_rate": 0.006060606060606061}
{"step": 270088, "time": 31410.502239227295, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 270088, "time": 31410.76412987709, "eval_episode/length": 194.0, "eval_episode/score": 0.39375001192092896, "eval_episode/reward_rate": 0.005128205128205128}
{"step": 270088, "time": 31411.411359786987, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 270088, "time": 31411.702912807465, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 270096, "time": 31412.621124267578, "episode/length": 188.0, "episode/score": 0.4318265699710082, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.019326576338926316}
{"step": 270312, "time": 31437.460371017456, "episode/length": 46.0, "episode/score": 0.8655284860301435, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.009278518090923171}
{"step": 270360, "time": 31443.436936616898, "episode/length": 151.0, "episode/score": 0.5484505034928588, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.02032550723561144}
{"step": 270680, "time": 31480.236619234085, "episode/length": 39.0, "episode/score": 0.8911812356533346, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.013056243872256346}
{"step": 270864, "time": 31501.448865175247, "episode/length": 95.0, "episode/score": 0.7234975458409281, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.020372565980778745}
{"step": 271008, "time": 31517.960179805756, "episode/length": 288.0, "episode/score": 0.03716148726971369, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03716148726971369}
{"step": 271072, "time": 31525.286203622818, "episode/length": 48.0, "episode/score": 0.8588024153787046, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.008802391755125427}
{"step": 271616, "time": 31587.74789404869, "episode/length": 288.0, "episode/score": 0.03647645140813438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03647645140813438}
{"step": 271672, "time": 31594.204951524734, "episode/length": 100.0, "episode/score": 0.6935189837780626, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.006019001909749022}
{"step": 271688, "time": 31596.067756175995, "episode/length": 288.0, "episode/score": 0.03832634731611506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03832634731611506}
{"step": 272184, "time": 31653.082829475403, "episode/length": 233.0, "episode/score": 0.29787084370661887, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.025995835347998764}
{"step": 272232, "time": 31658.6055662632, "episode/length": 288.0, "episode/score": 0.02138289298716245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02138289298716245}
{"step": 272376, "time": 31675.113482952118, "episode/length": 288.0, "episode/score": 0.026836321292876164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026836321292876164}
{"step": 272464, "time": 31685.256414175034, "episode/length": 96.0, "episode/score": 0.7138607891896527, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.01386081621546964}
{"step": 272768, "time": 31720.165881872177, "episode/length": 211.0, "episode/score": 0.368368400748011, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.027743408579851803}
{"step": 272848, "time": 31729.34008693695, "episode/length": 146.0, "episode/score": 0.5911841013501089, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.04743408992976583}
{"step": 273320, "time": 31783.83275294304, "episode/length": 288.0, "episode/score": 0.04152010196304445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04152010196304445}
{"step": 273624, "time": 31818.70200896263, "episode/length": 250.0, "episode/score": 0.24524434915639404, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.02649434997130129}
{"step": 273664, "time": 31823.28970336914, "episode/length": 42.0, "episode/score": 0.8818109997819192, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.013060994228908385}
{"step": 273936, "time": 31854.62501192093, "episode/length": 33.0, "episode/score": 0.9062338378666936, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.009358790683563711}
{"step": 274264, "time": 31892.45017337799, "episode/length": 186.0, "episode/score": 0.4634015623976211, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.04465157472600367}
{"step": 274304, "time": 31897.04847741127, "episode/length": 240.0, "episode/score": 0.27129683873920385, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.021296839554111102}
{"step": 274496, "time": 31919.163095235825, "episode/length": 288.0, "episode/score": 0.040144389182216855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040144389182216855}
{"step": 274544, "time": 31924.75885605812, "episode/length": 288.0, "episode/score": 0.043693982022602995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043693982022602995}
{"step": 274632, "time": 31934.891850709915, "episode/length": 222.0, "episode/score": 0.330235226272805, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.023985220719794142}
{"step": 274776, "time": 31951.731823205948, "episode/length": 288.0, "episode/score": 0.056292092231501556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056292092231501556}
{"step": 275176, "time": 31997.88981294632, "episode/length": 67.0, "episode/score": 0.8075387963422145, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.01691379078920363}
{"step": 275480, "time": 32032.871391773224, "episode/length": 122.0, "episode/score": 0.6444215804235682, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.025671589946341555}
{"step": 275536, "time": 32039.362376451492, "episode/length": 153.0, "episode/score": 0.5651087346795975, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.04323368749646761}
{"step": 275672, "time": 32054.962784528732, "episode/length": 61.0, "episode/score": 0.8337438159915109, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.024368799274270714}
{"step": 275760, "time": 32065.110924482346, "episode/length": 151.0, "episode/score": 0.555568761012978, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.02744379307375766}
{"step": 275936, "time": 32085.406339883804, "episode/length": 288.0, "episode/score": 0.027151241051456054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027151241051456054}
{"step": 275984, "time": 32090.923766374588, "episode/length": 38.0, "episode/score": 0.8906559141400976, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.00940588313869739}
{"step": 276248, "time": 32121.254573106766, "episode/length": 288.0, "episode/score": 0.050118243636916304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050118243636916304}
{"step": 276384, "time": 32136.96679019928, "episode/length": 105.0, "episode/score": 0.6791354885888268, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.007260481429284482}
{"step": 276576, "time": 32159.069489002228, "episode/length": 288.0, "episode/score": 0.05706713957442844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05706713957442844}
{"step": 276760, "time": 32180.375631332397, "episode/length": 247.0, "episode/score": 0.2672505130241234, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.03912549990411662}
{"step": 277069, "time": 32217.071999311447, "train_stats/mean_log_entropy": 0.08766743928814928, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.864964117005814, "train/action_min": 0.0, "train/action_std": 1.7748129118320555, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005896536151467021, "train/actor_opt_grad_steps": 67800.0, "train/actor_opt_loss": -14.109486344803212, "train/adv_mag": 0.4295266574205354, "train/adv_max": 0.1691425739332687, "train/adv_mean": -0.00047297971311287935, "train/adv_min": -0.40492697302685227, "train/adv_std": 0.016178203623222056, "train/cont_avg": 0.9958075944767442, "train/cont_loss_mean": 0.011566866517099443, "train/cont_loss_std": 0.19395278777688915, "train/cont_neg_acc": 0.45866556548795034, "train/cont_neg_loss": 2.269405421837799, "train/cont_pos_acc": 0.9998996113621912, "train/cont_pos_loss": 0.002177394996126464, "train/cont_pred": 0.9959369509719139, "train/cont_rate": 0.9958075944767442, "train/dyn_loss_mean": 1.0000006026999895, "train/dyn_loss_std": 1.927502372107187e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09766881070857825, "train/extr_critic_critic_opt_grad_steps": 67800.0, "train/extr_critic_critic_opt_loss": 11747.769862827035, "train/extr_critic_mag": 0.7938553837842719, "train/extr_critic_max": 0.7938553837842719, "train/extr_critic_mean": 0.6884455045988394, "train/extr_critic_min": 0.5666144692620566, "train/extr_critic_std": 0.027037759497761726, "train/extr_return_normed_mag": 0.45754293009292246, "train/extr_return_normed_max": 0.22121461990267732, "train/extr_return_normed_mean": 0.03307346503228642, "train/extr_return_normed_min": -0.39308193478473397, "train/extr_return_normed_std": 0.03212020613772924, "train/extr_return_rate": 0.999335671857346, "train/extr_return_raw_mag": 0.8761136473611344, "train/extr_return_raw_max": 0.8761136473611344, "train/extr_return_raw_mean": 0.687972522890845, "train/extr_return_raw_min": 0.2618170926737231, "train/extr_return_raw_std": 0.0321202062243639, "train/extr_reward_mag": 0.2375345695850461, "train/extr_reward_max": 0.2375345695850461, "train/extr_reward_mean": 0.0006382209909430077, "train/extr_reward_min": 1.8707541532294695e-06, "train/extr_reward_std": 0.004799899708230569, "train/image_loss_mean": 0.08356081730751104, "train/image_loss_std": 0.10594238302735395, "train/model_loss_mean": 0.7087975346764853, "train/model_loss_std": 0.31838974931905434, "train/model_opt_grad_norm": 16.352233625012776, "train/model_opt_grad_steps": 67740.02790697674, "train/model_opt_loss": 3828.2611612009446, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5395.3488372093025, "train/policy_entropy_mag": 1.4558190118434817, "train/policy_entropy_max": 1.4558190118434817, "train/policy_entropy_mean": 0.11910490040169205, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1591066212155098, "train/policy_logprob_mag": 6.551080244640971, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11952718981476718, "train/policy_logprob_min": -6.551080244640971, "train/policy_logprob_std": 0.6589259397151859, "train/policy_randomness_mag": 0.7481430225594099, "train/policy_randomness_max": 0.7481430225594099, "train/policy_randomness_mean": 0.0612078140814637, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.081764633780302, "train/post_ent_mag": 33.50566931436228, "train/post_ent_max": 33.50566931436228, "train/post_ent_mean": 33.15308202699173, "train/post_ent_min": 32.81269786746003, "train/post_ent_std": 0.13830192903446598, "train/prior_ent_mag": 33.5152387219806, "train/prior_ent_max": 33.5152387219806, "train/prior_ent_mean": 32.81522795211437, "train/prior_ent_min": 31.96760481900947, "train/prior_ent_std": 0.27522366843944374, "train/rep_loss_mean": 1.0000006026999895, "train/rep_loss_std": 1.927502372107187e-05, "train/reward_avg": 0.0008716612598089891, "train/reward_loss_mean": 0.013669463786361523, "train/reward_loss_std": 0.11417071954455486, "train/reward_max_data": 0.46727347086660215, "train/reward_max_pred": 0.15115975557371628, "train/reward_neg_acc": 0.999849937960159, "train/reward_neg_loss": 0.009391372135385524, "train/reward_pos_acc": 0.3009259266157945, "train/reward_pos_loss": 3.8717468718273773, "train/reward_pred": 0.0006710120742100962, "train/reward_rate": 0.0010719476744186047, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.009680052287876606, "report/cont_loss_std": 0.18697893619537354, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.3212275505065918, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0019499107729643583, "report/cont_pred": 0.9946225881576538, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08410374075174332, "report/image_loss_std": 0.10338833928108215, "report/model_loss_mean": 0.7057235836982727, "report/model_loss_std": 0.2316916137933731, "report/post_ent_mag": 33.81747055053711, "report/post_ent_max": 33.81747055053711, "report/post_ent_mean": 33.482810974121094, "report/post_ent_min": 33.18799591064453, "report/post_ent_std": 0.12336388230323792, "report/prior_ent_mag": 33.54428482055664, "report/prior_ent_max": 33.54428482055664, "report/prior_ent_mean": 32.9043083190918, "report/prior_ent_min": 32.141395568847656, "report/prior_ent_std": 0.2146715521812439, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0011456494685262442, "report/reward_loss_mean": 0.01193974632769823, "report/reward_loss_std": 0.03309360519051552, "report/reward_max_data": 0.9285417199134827, "report/reward_max_pred": 0.4984290599822998, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01102553028613329, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.9471837282180786, "report/reward_pred": 0.0010861657792702317, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.052033666521310806, "eval/cont_loss_std": 0.6474595665931702, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.418886184692383, "eval/cont_pos_acc": 0.9980372786521912, "eval/cont_pos_loss": 0.010979438200592995, "eval/cont_pred": 0.9946544170379639, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22636358439922333, "eval/image_loss_std": 0.18508897721767426, "eval/model_loss_mean": 0.8907363414764404, "eval/model_loss_std": 0.8623350858688354, "eval/post_ent_mag": 33.825138092041016, "eval/post_ent_max": 33.825138092041016, "eval/post_ent_mean": 33.48932647705078, "eval/post_ent_min": 33.1803092956543, "eval/post_ent_std": 0.13914833962917328, "eval/prior_ent_mag": 33.410186767578125, "eval/prior_ent_max": 33.410186767578125, "eval/prior_ent_mean": 32.88409423828125, "eval/prior_ent_min": 32.09484100341797, "eval/prior_ent_std": 0.22416283190250397, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.00030517578125, "eval/reward_loss_mean": 0.012339089997112751, "eval/reward_loss_std": 0.32587721943855286, "eval/reward_max_data": 0.3125, "eval/reward_max_pred": 0.040973544120788574, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0021516375709325075, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.434102058410645, "eval/reward_pred": 0.0007290043868124485, "eval/reward_rate": 0.0009765625, "replay/size": 276565.0, "replay/inserts": 8632.0, "replay/samples": 34528.0, "replay/insert_wait_avg": 1.4919666806451692e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.675479030697516e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 64936.0, "eval_replay/inserts": 1952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.030256513689385e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1533710956573, "timer/env.step_count": 1079.0, "timer/env.step_total": 10.031990051269531, "timer/env.step_frac": 0.01003045166990698, "timer/env.step_avg": 0.009297488462715043, "timer/env.step_min": 0.007581949234008789, "timer/env.step_max": 0.030383825302124023, "timer/replay._sample_count": 34528.0, "timer/replay._sample_total": 16.5721538066864, "timer/replay._sample_frac": 0.016569612507061574, "timer/replay._sample_avg": 0.00047996274926686753, "timer/replay._sample_min": 0.0003459453582763672, "timer/replay._sample_max": 0.010518550872802734, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1323.0, "timer/agent.policy_total": 12.911752462387085, "timer/agent.policy_frac": 0.012909772476437686, "timer/agent.policy_avg": 0.009759450084948666, "timer/agent.policy_min": 0.008767843246459961, "timer/agent.policy_max": 0.03525996208190918, "timer/dataset_train_count": 2158.0, "timer/dataset_train_total": 0.3710815906524658, "timer/dataset_train_frac": 0.000371024686189829, "timer/dataset_train_avg": 0.00017195625146082755, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0012030601501464844, "timer/agent.train_count": 2158.0, "timer/agent.train_total": 962.6389195919037, "timer/agent.train_frac": 0.9624913012464709, "timer/agent.train_avg": 0.4460792027766004, "timer/agent.train_min": 0.43364453315734863, "timer/agent.train_max": 0.5715763568878174, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47665834426879883, "timer/agent.report_frac": 0.0004765852498668526, "timer/agent.report_avg": 0.23832917213439941, "timer/agent.report_min": 0.23349261283874512, "timer/agent.report_max": 0.2431657314300537, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6698786037307736e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 8.630541225307748}
{"step": 277792, "time": 32300.163670301437, "episode/length": 288.0, "episode/score": 0.042738025829521575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042738025829521575}
{"step": 278072, "time": 32332.4258081913, "episode/length": 288.0, "episode/score": 0.029634802319947084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029634802319947084}
{"step": 278248, "time": 32352.676496744156, "episode/length": 288.0, "episode/score": 0.05002933291103773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05002933291103773}
{"step": 278296, "time": 32358.196328401566, "episode/length": 288.0, "episode/score": 0.04200382209512554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04200382209512554}
{"step": 278560, "time": 32388.99467253685, "episode/length": 288.0, "episode/score": 0.09256523558343588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09256523558343588}
{"step": 278696, "time": 32404.70087814331, "episode/length": 288.0, "episode/score": 0.03862864188579351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03862864188579351}
{"step": 278888, "time": 32426.811795949936, "episode/length": 288.0, "episode/score": 0.03210908551398006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03210908551398006}
{"step": 279072, "time": 32448.058997392654, "episode/length": 288.0, "episode/score": 0.037830711139292816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037830711139292816}
{"step": 279128, "time": 32454.5284011364, "episode/length": 53.0, "episode/score": 0.8508642455906852, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.016489213570650918}
{"step": 279344, "time": 32479.500643014908, "episode/length": 56.0, "episode/score": 0.8461512465071905, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.021151235086847464}
{"step": 280072, "time": 32565.27167725563, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 280072, "time": 32565.955323457718, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 280072, "time": 32566.15604186058, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 280072, "time": 32566.974289655685, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 280072, "time": 32567.209208011627, "eval_episode/length": 188.0, "eval_episode/score": 0.4124999940395355, "eval_episode/reward_rate": 0.005291005291005291}
{"step": 280072, "time": 32567.381020069122, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 280072, "time": 32567.4834523201, "eval_episode/length": 204.0, "eval_episode/score": 0.36250001192092896, "eval_episode/reward_rate": 0.004878048780487805}
{"step": 280072, "time": 32568.203198194504, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 280080, "time": 32569.139370441437, "episode/length": 228.0, "episode/score": 0.3370347450631357, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.04953474386405787}
{"step": 280104, "time": 32571.885031223297, "episode/length": 288.0, "episode/score": 0.060960420768196855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060960420768196855}
{"step": 280384, "time": 32604.093435049057, "episode/length": 288.0, "episode/score": 0.06749532390830382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06749532390830382}
{"step": 280608, "time": 32629.906923532486, "episode/length": 288.0, "episode/score": 0.04213818547992787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04213818547992787}
{"step": 280760, "time": 32647.46601653099, "episode/length": 176.0, "episode/score": 0.4844603896157196, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.034460393358472174}
{"step": 280872, "time": 32660.349068403244, "episode/length": 288.0, "episode/score": 0.06031711216837721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06031711216837721}
{"step": 281384, "time": 32719.379712581635, "episode/length": 288.0, "episode/score": 0.05212060012581787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05212060012581787}
{"step": 281440, "time": 32725.903185129166, "episode/length": 288.0, "episode/score": 0.09344051736769643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09344051736769643}
{"step": 282392, "time": 32835.77109289169, "episode/length": 288.0, "episode/score": 0.0648615908766601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0648615908766601}
{"step": 282416, "time": 32838.56277370453, "episode/length": 288.0, "episode/score": 0.10096606347639181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10096606347639181}
{"step": 282696, "time": 32870.83014011383, "episode/length": 288.0, "episode/score": 0.06520910045298933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06520910045298933}
{"step": 282728, "time": 32874.51267552376, "episode/length": 264.0, "episode/score": 0.25772695199873397, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.08272696021765569}
{"step": 283000, "time": 32905.876953125, "episode/length": 194.0, "episode/score": 0.4348861670310953, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.041136143439530315}
{"step": 283072, "time": 32914.22696232796, "episode/length": 288.0, "episode/score": 0.047587491924815595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047587491924815595}
{"step": 283184, "time": 32927.16385889053, "episode/length": 288.0, "episode/score": 0.07137932316825868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07137932316825868}
{"step": 283408, "time": 32952.988291978836, "episode/length": 27.0, "episode/score": 0.9261858495567594, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.01056084400374857}
{"step": 283648, "time": 32980.701080560684, "episode/length": 80.0, "episode/score": 0.7699298611155427, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.019929861333821464}
{"step": 283696, "time": 32986.2283642292, "episode/length": 288.0, "episode/score": 0.0633706141389041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0633706141389041}
{"step": 283920, "time": 33012.10757303238, "episode/length": 190.0, "episode/score": 0.45758624787245594, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.05133624071291365}
{"step": 284072, "time": 33029.57717871666, "episode/length": 167.0, "episode/score": 0.5186494584258412, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.040524437767942345}
{"step": 284728, "time": 33105.29542851448, "episode/length": 288.0, "episode/score": 0.05030886146977309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05030886146977309}
{"step": 284776, "time": 33110.84729933739, "episode/length": 87.0, "episode/score": 0.7523926812087893, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.02426772815908862}
{"step": 284944, "time": 33130.2932510376, "episode/length": 191.0, "episode/score": 0.4423481875038817, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.03922321150290031}
{"step": 285008, "time": 33137.77407050133, "episode/length": 288.0, "episode/score": 0.06590478939617128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06590478939617128}
{"step": 285384, "time": 33181.434591293335, "episode/length": 288.0, "episode/score": 0.06295242877607166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06295242877607166}
{"step": 285689, "time": 33217.454354047775, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.372807820638021, "train/action_min": 0.0, "train/action_std": 1.7578466954054657, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005825875857866507, "train/actor_opt_grad_steps": 69955.0, "train/actor_opt_loss": -13.48842484752337, "train/adv_mag": 0.4817786431974835, "train/adv_max": 0.2838743246263928, "train/adv_mean": -3.1960142593142655e-05, "train/adv_min": -0.4279785139693154, "train/adv_std": 0.018677487212698907, "train/cont_avg": 0.9959490740740741, "train/cont_loss_mean": 0.01112278249261349, "train/cont_loss_std": 0.18928484637742965, "train/cont_neg_acc": 0.4875797442743711, "train/cont_neg_loss": 2.230656408617302, "train/cont_pos_acc": 0.9998593330383301, "train/cont_pos_loss": 0.002180507409826128, "train/cont_pred": 0.995978480135953, "train/cont_rate": 0.9959490740740741, "train/dyn_loss_mean": 1.0000004139211442, "train/dyn_loss_std": 7.010227784997335e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12405966702607218, "train/extr_critic_critic_opt_grad_steps": 69955.0, "train/extr_critic_critic_opt_loss": 9126.979722764758, "train/extr_critic_mag": 0.8373865998453565, "train/extr_critic_max": 0.8373865998453565, "train/extr_critic_mean": 0.6572476247394526, "train/extr_critic_min": 0.5530953285870729, "train/extr_critic_std": 0.030218101654167252, "train/extr_return_normed_mag": 0.5333381045471739, "train/extr_return_normed_max": 0.3792828666391196, "train/extr_return_normed_mean": 0.033129754732794094, "train/extr_return_normed_min": -0.3824209332190178, "train/extr_return_normed_std": 0.0364394894482016, "train/extr_return_rate": 0.9993034833007388, "train/extr_return_raw_mag": 1.0033687096503046, "train/extr_return_raw_max": 1.0033687096503046, "train/extr_return_raw_mean": 0.657215633602054, "train/extr_return_raw_min": 0.2416649092402723, "train/extr_return_raw_std": 0.0364394893878381, "train/extr_reward_mag": 0.44155151424584566, "train/extr_reward_max": 0.44155151424584566, "train/extr_reward_mean": 0.0008008627295634209, "train/extr_reward_min": 1.7853798689665617e-06, "train/extr_reward_std": 0.007292038346619207, "train/image_loss_mean": 0.08294337453251635, "train/image_loss_std": 0.10605804825684538, "train/model_loss_mean": 0.7073606815603044, "train/model_loss_std": 0.3093629736729242, "train/model_opt_grad_norm": 15.851264465738225, "train/model_opt_grad_steps": 69893.01388888889, "train/model_opt_loss": 3685.926427770544, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5208.333333333333, "train/policy_entropy_mag": 1.3334305849340227, "train/policy_entropy_max": 1.3334305849340227, "train/policy_entropy_mean": 0.10808584525215405, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13917814674614756, "train/policy_logprob_mag": 6.55108024014367, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10824150667974243, "train/policy_logprob_min": -6.55108024014367, "train/policy_logprob_std": 0.646484500280133, "train/policy_randomness_mag": 0.6852478078669972, "train/policy_randomness_max": 0.6852478078669972, "train/policy_randomness_mean": 0.05554514000606206, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0715234233583841, "train/post_ent_mag": 33.6466517801638, "train/post_ent_max": 33.6466517801638, "train/post_ent_mean": 33.331476582421196, "train/post_ent_min": 33.034230603112114, "train/post_ent_std": 0.12090673835741149, "train/prior_ent_mag": 33.669751432206894, "train/prior_ent_max": 33.669751432206894, "train/prior_ent_mean": 32.71912135018243, "train/prior_ent_min": 31.915853173644454, "train/prior_ent_std": 0.2814865044697567, "train/rep_loss_mean": 1.0000004139211442, "train/rep_loss_std": 7.010227784997335e-06, "train/reward_avg": 0.000788385186145509, "train/reward_loss_mean": 0.013294253944574544, "train/reward_loss_std": 0.10877511338589506, "train/reward_max_data": 0.4203890570853319, "train/reward_max_pred": 0.17905933934229393, "train/reward_neg_acc": 0.999809970734296, "train/reward_neg_loss": 0.009466657382694798, "train/reward_pos_acc": 0.3069852952133207, "train/reward_pos_loss": 3.9623500573284485, "train/reward_pred": 0.0007107940888360005, "train/reward_rate": 0.0009765625, "train_stats/mean_log_entropy": 0.0916299516601222, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0016957230400294065, "report/cont_loss_std": 0.007147857919335365, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.007680032402276993, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.001666359486989677, "report/cont_pred": 0.9935214519500732, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08125212788581848, "report/image_loss_std": 0.09741625934839249, "report/model_loss_mean": 0.6909745931625366, "report/model_loss_std": 0.10089455544948578, "report/post_ent_mag": 33.61104202270508, "report/post_ent_max": 33.61104202270508, "report/post_ent_mean": 33.30128479003906, "report/post_ent_min": 33.00159454345703, "report/post_ent_std": 0.12515796720981598, "report/prior_ent_mag": 33.56935119628906, "report/prior_ent_max": 33.56935119628906, "report/prior_ent_mean": 32.68656921386719, "report/prior_ent_min": 31.944656372070312, "report/prior_ent_std": 0.29143190383911133, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00017526745796203613, "report/reward_loss_mean": 0.008026756346225739, "report/reward_loss_std": 0.012970484793186188, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.01225888729095459, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008026756346225739, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00036985694896429777, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.020150937139987946, "eval/cont_loss_std": 0.4208548665046692, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.414073944091797, "eval/cont_pos_acc": 0.9980449676513672, "eval/cont_pos_loss": 0.009013181552290916, "eval/cont_pred": 0.997299313545227, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1996724009513855, "eval/image_loss_std": 0.16919535398483276, "eval/model_loss_mean": 0.8214914798736572, "eval/model_loss_std": 0.45119521021842957, "eval/post_ent_mag": 33.62721633911133, "eval/post_ent_max": 33.62721633911133, "eval/post_ent_mean": 33.297481536865234, "eval/post_ent_min": 33.03400802612305, "eval/post_ent_std": 0.11400392651557922, "eval/prior_ent_mag": 33.5759162902832, "eval/prior_ent_max": 33.5759162902832, "eval/prior_ent_mean": 32.703617095947266, "eval/prior_ent_min": 31.994224548339844, "eval/prior_ent_std": 0.2763446271419525, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001668127253651619, "eval/reward_loss_std": 0.0020944764837622643, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.010332345962524414, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001668127253651619, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00035357929300516844, "eval/reward_rate": 0.0, "replay/size": 285185.0, "replay/inserts": 8620.0, "replay/samples": 34480.0, "replay/insert_wait_avg": 1.4851375411668675e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.698818038621801e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 66920.0, "eval_replay/inserts": 1984.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0435619661884923e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3705549240112, "timer/env.step_count": 1078.0, "timer/env.step_total": 10.000383853912354, "timer/env.step_frac": 0.009996679535086865, "timer/env.step_avg": 0.00927679392756248, "timer/env.step_min": 0.008341312408447266, "timer/env.step_max": 0.033736228942871094, "timer/replay._sample_count": 34480.0, "timer/replay._sample_total": 16.567809104919434, "timer/replay._sample_frac": 0.016561672095774485, "timer/replay._sample_avg": 0.0004805049044350184, "timer/replay._sample_min": 0.00037097930908203125, "timer/replay._sample_max": 0.01770305633544922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1326.0, "timer/agent.policy_total": 13.262843370437622, "timer/agent.policy_frac": 0.013257930578979383, "timer/agent.policy_avg": 0.010002144321597, "timer/agent.policy_min": 0.008502960205078125, "timer/agent.policy_max": 0.06986474990844727, "timer/dataset_train_count": 2155.0, "timer/dataset_train_total": 0.37387561798095703, "timer/dataset_train_frac": 0.00037373712784794714, "timer/dataset_train_avg": 0.00017349216611645338, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.0012159347534179688, "timer/agent.train_count": 2155.0, "timer/agent.train_total": 962.9062514305115, "timer/agent.train_frac": 0.9625495739462808, "timer/agent.train_avg": 0.4468242466034856, "timer/agent.train_min": 0.4328944683074951, "timer/agent.train_max": 0.5715823173522949, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47501516342163086, "timer/agent.report_frac": 0.00047483920941446874, "timer/agent.report_avg": 0.23750758171081543, "timer/agent.report_min": 0.23221731185913086, "timer/agent.report_max": 0.2427978515625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.93146225517601e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 8.616694329981978}
{"step": 285864, "time": 33237.46401166916, "episode/length": 242.0, "episode/score": 0.29932270670570915, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.05557269358570238}
{"step": 285960, "time": 33248.61608195305, "episode/length": 288.0, "episode/score": 0.02583000055463458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02583000055463458}
{"step": 286008, "time": 33254.163667440414, "episode/length": 288.0, "episode/score": 0.0478982465709521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0478982465709521}
{"step": 287040, "time": 33373.40894627571, "episode/length": 288.0, "episode/score": 0.0695725530973732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0695725530973732}
{"step": 287088, "time": 33378.934985637665, "episode/length": 288.0, "episode/score": 0.08719733030378052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08719733030378052}
{"step": 287256, "time": 33398.368997097015, "episode/length": 288.0, "episode/score": 0.06564512010317003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06564512010317003}
{"step": 287320, "time": 33405.7188706398, "episode/length": 288.0, "episode/score": 0.06655377594685774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06655377594685774}
{"step": 287696, "time": 33448.98482775688, "episode/length": 288.0, "episode/score": 0.08479508393961055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08479508393961055}
{"step": 287912, "time": 33473.81770801544, "episode/length": 26.0, "episode/score": 0.9310268915269262, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.012276874809685978}
{"step": 288080, "time": 33493.15667915344, "episode/length": 276.0, "episode/score": 0.21922204621444052, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0817220443983615}
{"step": 288272, "time": 33515.18601036072, "episode/length": 288.0, "episode/score": 0.07691443694909594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07691443694909594}
{"step": 288320, "time": 33520.72703695297, "episode/length": 288.0, "episode/score": 0.09136224035748342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09136224035748342}
{"step": 288488, "time": 33540.054367780685, "episode/length": 174.0, "episode/score": 0.5079796952663855, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.05172968416036383}
{"step": 288568, "time": 33549.38930630684, "episode/length": 36.0, "episode/score": 0.9021175652079592, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.014617548490718946}
{"step": 288576, "time": 33550.31987762451, "episode/length": 61.0, "episode/score": 0.8389704865679732, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.029595499303809447}
{"step": 288792, "time": 33575.29827475548, "episode/length": 183.0, "episode/score": 0.4877786145339087, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.05965360617528859}
{"step": 289352, "time": 33639.82635593414, "episode/length": 288.0, "episode/score": 0.049547781062528884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049547781062528884}
{"step": 289568, "time": 33664.95711994171, "episode/length": 288.0, "episode/score": 0.07082144435378268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07082144435378268}
{"step": 289624, "time": 33671.3853199482, "episode/length": 213.0, "episode/score": 0.36642128220171344, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.03204628897708517}
{"step": 289760, "time": 33687.06636810303, "episode/length": 23.0, "episode/score": 0.9408270243683319, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.01270197718520194}
{"step": 290056, "time": 33726.379997730255, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 33726.38657236099, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 33726.392193078995, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 33726.397688150406, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 33726.40299105644, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 33726.40827989578, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 33726.414301157, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 33726.41953039169, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290168, "time": 33739.32478761673, "episode/length": 101.0, "episode/score": 0.7185130219528446, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.034138004478904804}
{"step": 290632, "time": 33793.06713962555, "episode/length": 288.0, "episode/score": 0.05068446063438614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05068446063438614}
{"step": 290800, "time": 33812.50733590126, "episode/length": 288.0, "episode/score": 0.06697183950342378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06697183950342378}
{"step": 290880, "time": 33821.72933769226, "episode/length": 288.0, "episode/score": 0.04709917417511633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04709917417511633}
{"step": 290888, "time": 33822.65235042572, "episode/length": 288.0, "episode/score": 0.08621223338747086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08621223338747086}
{"step": 291104, "time": 33847.68525934219, "episode/length": 288.0, "episode/score": 0.06194375606958147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06194375606958147}
{"step": 291936, "time": 33943.58629488945, "episode/length": 288.0, "episode/score": 0.07331401408129068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07331401408129068}
{"step": 292072, "time": 33959.174397706985, "episode/length": 288.0, "episode/score": 0.0612200605754083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0612200605754083}
{"step": 292480, "time": 34006.18176436424, "episode/length": 288.0, "episode/score": 0.07019531117430233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07019531117430233}
{"step": 292944, "time": 34059.618032455444, "episode/length": 288.0, "episode/score": 0.07884355806874055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07884355806874055}
{"step": 293112, "time": 34078.91035747528, "episode/length": 288.0, "episode/score": 0.06423093086624476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06423093086624476}
{"step": 293192, "time": 34088.11805319786, "episode/length": 288.0, "episode/score": 0.052104701617111004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052104701617111004}
{"step": 293200, "time": 34089.05716252327, "episode/length": 288.0, "episode/score": 0.08667313605729987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08667313605729987}
{"step": 293416, "time": 34113.942578077316, "episode/length": 288.0, "episode/score": 0.05876820690224349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05876820690224349}
{"step": 294248, "time": 34209.757779598236, "episode/length": 288.0, "episode/score": 0.053937898361766656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053937898361766656}
{"step": 294309, "time": 34217.61375308037, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.522187840661337, "train/action_min": 0.0, "train/action_std": 1.644395988486534, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007662766665588458, "train/actor_opt_grad_steps": 72110.0, "train/actor_opt_loss": -11.68066371956537, "train/adv_mag": 0.6161675081696621, "train/adv_max": 0.4045145284297854, "train/adv_mean": 0.0011781449165408598, "train/adv_min": -0.5010021736455518, "train/adv_std": 0.02762925077316373, "train/cont_avg": 0.9961936773255814, "train/cont_loss_mean": 0.01057857844929839, "train/cont_loss_std": 0.18044092729146224, "train/cont_neg_acc": 0.47508159600128635, "train/cont_neg_loss": 2.207976469903251, "train/cont_pos_acc": 0.9998996878779212, "train/cont_pos_loss": 0.0021832128426298326, "train/cont_pred": 0.9961156079935473, "train/cont_rate": 0.9961936773255814, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.24372614462275144, "train/extr_critic_critic_opt_grad_steps": 72110.0, "train/extr_critic_critic_opt_loss": 10743.408645984739, "train/extr_critic_mag": 0.8761771052382713, "train/extr_critic_max": 0.8761771052382713, "train/extr_critic_mean": 0.6905577238215956, "train/extr_critic_min": 0.5771524213081183, "train/extr_critic_std": 0.026825726149213868, "train/extr_return_normed_mag": 0.7012329198593317, "train/extr_return_normed_max": 0.5113285815993021, "train/extr_return_normed_mean": 0.035386784296742704, "train/extr_return_normed_min": -0.4688679345818453, "train/extr_return_normed_std": 0.03971613652484361, "train/extr_return_rate": 0.9989650360373563, "train/extr_return_raw_mag": 1.1676776253899863, "train/extr_return_raw_max": 1.1676776253899863, "train/extr_return_raw_mean": 0.6917358678440715, "train/extr_return_raw_min": 0.18748111114945523, "train/extr_return_raw_std": 0.0397161367327668, "train/extr_reward_mag": 0.5448430710060652, "train/extr_reward_max": 0.5448430710060652, "train/extr_reward_mean": 0.0010366799244873744, "train/extr_reward_min": 1.4765318049940952e-06, "train/extr_reward_std": 0.011935674243465845, "train/image_loss_mean": 0.08487782471401747, "train/image_loss_std": 0.10770140019960181, "train/model_loss_mean": 0.7087643917216812, "train/model_loss_std": 0.3057414488736973, "train/model_opt_grad_norm": 15.843342900830645, "train/model_opt_grad_steps": 72045.95348837209, "train/model_opt_loss": 3626.9772404160612, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5162.790697674419, "train/policy_entropy_mag": 1.3391780542772869, "train/policy_entropy_max": 1.3391780542772869, "train/policy_entropy_mean": 0.10557520150445228, "train/policy_entropy_min": 0.06468649218941844, "train/policy_entropy_std": 0.1364867532322573, "train/policy_logprob_mag": 6.5510802468588185, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10558354424875836, "train/policy_logprob_min": -6.5510802468588185, "train/policy_logprob_std": 0.6440797559050626, "train/policy_randomness_mag": 0.6882014241329459, "train/policy_randomness_max": 0.6882014241329459, "train/policy_randomness_mean": 0.05425492429802584, "train/policy_randomness_min": 0.03324228157830793, "train/policy_randomness_std": 0.07014032061709914, "train/post_ent_mag": 33.591631370367004, "train/post_ent_max": 33.591631370367004, "train/post_ent_mean": 33.29422119495481, "train/post_ent_min": 33.002967834472656, "train/post_ent_std": 0.11722643389258273, "train/prior_ent_mag": 33.66490751754406, "train/prior_ent_max": 33.66490751754406, "train/prior_ent_mean": 32.718008724478786, "train/prior_ent_min": 31.921723893631338, "train/prior_ent_std": 0.2752656473669895, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0008048766541029435, "train/reward_loss_mean": 0.013307965128834165, "train/reward_loss_std": 0.1097046157778349, "train/reward_max_data": 0.4225188654749979, "train/reward_max_pred": 0.14565114586852318, "train/reward_neg_acc": 0.9998863209125608, "train/reward_neg_loss": 0.00928554440480332, "train/reward_pos_acc": 0.2754975139205135, "train/reward_pos_loss": 4.037300561012617, "train/reward_pred": 0.0006688697599307742, "train/reward_rate": 0.001008357558139535, "train_stats/mean_log_entropy": 0.08932305553129741, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0049844784662127495, "report/cont_loss_std": 0.0890296995639801, "report/cont_neg_acc": 0.800000011920929, "report/cont_neg_loss": 0.6450517773628235, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0018438148545101285, "report/cont_pred": 0.9946017265319824, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0849689394235611, "report/image_loss_std": 0.10361992567777634, "report/model_loss_mean": 0.700293779373169, "report/model_loss_std": 0.14665602147579193, "report/post_ent_mag": 33.39409637451172, "report/post_ent_max": 33.39409637451172, "report/post_ent_mean": 33.09758758544922, "report/post_ent_min": 32.78312683105469, "report/post_ent_std": 0.12417615950107574, "report/prior_ent_mag": 33.492408752441406, "report/prior_ent_max": 33.492408752441406, "report/prior_ent_mean": 32.72637939453125, "report/prior_ent_min": 32.12884521484375, "report/prior_ent_std": 0.2630919814109802, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008895790670067072, "report/reward_loss_mean": 0.010340353474020958, "report/reward_loss_std": 0.04377133399248123, "report/reward_max_data": 0.5035417079925537, "report/reward_max_pred": 0.4413501024246216, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00852864421904087, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.936123788356781, "report/reward_pred": 0.0010405685752630234, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.05199882760643959, "eval/cont_loss_std": 0.741885244846344, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.16240406036377, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0023893790785223246, "eval/cont_pred": 0.9976720809936523, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18100133538246155, "eval/image_loss_std": 0.1523582488298416, "eval/model_loss_mean": 0.839466392993927, "eval/model_loss_std": 0.8060309290885925, "eval/post_ent_mag": 33.392391204833984, "eval/post_ent_max": 33.392391204833984, "eval/post_ent_mean": 33.07311248779297, "eval/post_ent_min": 32.792938232421875, "eval/post_ent_std": 0.12498514354228973, "eval/prior_ent_mag": 33.470558166503906, "eval/prior_ent_max": 33.470558166503906, "eval/prior_ent_mean": 32.695220947265625, "eval/prior_ent_min": 31.74977684020996, "eval/prior_ent_std": 0.2530202567577362, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005065918085165322, "eval/reward_loss_mean": 0.006466216407716274, "eval/reward_loss_std": 0.15419578552246094, "eval/reward_max_data": 0.518750011920929, "eval/reward_max_pred": 0.05065715312957764, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0016477021854370832, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.9358062744140625, "eval/reward_pred": 0.00046389014460146427, "eval/reward_rate": 0.0009765625, "replay/size": 293805.0, "replay/inserts": 8620.0, "replay/samples": 34480.0, "replay/insert_wait_avg": 1.5145111526524662e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.75268348906267e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 69232.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0481342724862808e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1428089141846, "timer/env.step_count": 1077.0, "timer/env.step_total": 10.079715490341187, "timer/env.step_frac": 0.010078276222656977, "timer/env.step_avg": 0.009359067307651984, "timer/env.step_min": 0.008232355117797852, "timer/env.step_max": 0.034415483474731445, "timer/replay._sample_count": 34480.0, "timer/replay._sample_total": 16.567768335342407, "timer/replay._sample_frac": 0.016565402648177192, "timer/replay._sample_avg": 0.0004805037220226916, "timer/replay._sample_min": 0.00036144256591796875, "timer/replay._sample_max": 0.021775245666503906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1366.0, "timer/agent.policy_total": 13.378848314285278, "timer/agent.policy_frac": 0.013376937968298912, "timer/agent.policy_avg": 0.009794178853795958, "timer/agent.policy_min": 0.008814334869384766, "timer/agent.policy_max": 0.03975677490234375, "timer/dataset_train_count": 2155.0, "timer/dataset_train_total": 0.37468433380126953, "timer/dataset_train_frac": 0.0003746308331787632, "timer/dataset_train_avg": 0.00017386744027901138, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.0005676746368408203, "timer/agent.train_count": 2155.0, "timer/agent.train_total": 962.0574653148651, "timer/agent.train_frac": 0.96192009455063, "timer/agent.train_avg": 0.44643037833636434, "timer/agent.train_min": 0.43441033363342285, "timer/agent.train_max": 0.5890851020812988, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4777829647064209, "timer/agent.report_frac": 0.00047771474278271415, "timer/agent.report_avg": 0.23889148235321045, "timer/agent.report_min": 0.2321605682373047, "timer/agent.report_max": 0.2456223964691162, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075160510076769e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 8.618634528325806}
{"step": 294384, "time": 34226.06164479256, "episode/length": 288.0, "episode/score": 0.07278348330635254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07278348330635254}
{"step": 294792, "time": 34273.196808338165, "episode/length": 288.0, "episode/score": 0.056028598419118225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056028598419118225}
{"step": 295256, "time": 34327.19696998596, "episode/length": 288.0, "episode/score": 0.032959858162485034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032959858162485034}
{"step": 295424, "time": 34346.5511367321, "episode/length": 288.0, "episode/score": 0.07415670565995924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07415670565995924}
{"step": 295504, "time": 34355.84070253372, "episode/length": 288.0, "episode/score": 0.05481042713415718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05481042713415718}
{"step": 295512, "time": 34356.76816701889, "episode/length": 288.0, "episode/score": 0.05382153079835916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05382153079835916}
{"step": 295728, "time": 34382.62638545036, "episode/length": 288.0, "episode/score": 0.03803144851548268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03803144851548268}
{"step": 295896, "time": 34401.99938416481, "episode/length": 20.0, "episode/score": 0.9500668879836667, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.012566864642394648}
{"step": 296560, "time": 34478.82654976845, "episode/length": 288.0, "episode/score": 0.07238619009564218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07238619009564218}
{"step": 296696, "time": 34494.46441102028, "episode/length": 288.0, "episode/score": 0.06742766700696734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06742766700696734}
{"step": 297104, "time": 34541.633564949036, "episode/length": 288.0, "episode/score": 0.04824890255036962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04824890255036962}
{"step": 297568, "time": 34595.23084235191, "episode/length": 288.0, "episode/score": 0.06736848368038295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06736848368038295}
{"step": 297736, "time": 34614.58306026459, "episode/length": 288.0, "episode/score": 0.07945311378119868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07945311378119868}
{"step": 297816, "time": 34623.84510397911, "episode/length": 288.0, "episode/score": 0.06390012924111943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06390012924111943}
{"step": 297824, "time": 34624.763790369034, "episode/length": 288.0, "episode/score": 0.05402635028352165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05402635028352165}
{"step": 298208, "time": 34669.13934659958, "episode/length": 288.0, "episode/score": 0.07092809122804056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07092809122804056}
{"step": 298872, "time": 34745.71762752533, "episode/length": 288.0, "episode/score": 0.06786328308535872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06786328308535872}
{"step": 299008, "time": 34761.36607313156, "episode/length": 288.0, "episode/score": 0.0764564453112655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0764564453112655}
{"step": 299416, "time": 34808.60508584976, "episode/length": 288.0, "episode/score": 0.060792105189193535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060792105189193535}
{"step": 299880, "time": 34862.107023477554, "episode/length": 288.0, "episode/score": 0.046456443373358525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046456443373358525}
{"step": 299976, "time": 34873.174980163574, "episode/length": 69.0, "episode/score": 0.8019750806911361, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.017600040132037975}
{"step": 300040, "time": 34881.18895959854, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 300040, "time": 34881.458938360214, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 300040, "time": 34881.512770175934, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 300040, "time": 34882.18505740166, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 300040, "time": 34882.51597213745, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 300040, "time": 34882.85976314545, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 300040, "time": 34884.49514126778, "eval_episode/length": 231.0, "eval_episode/score": 0.27812498807907104, "eval_episode/reward_rate": 0.004310344827586207}
{"step": 300040, "time": 34885.03728103638, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 300048, "time": 34885.96397590637, "episode/length": 288.0, "episode/score": 0.0723818650907333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0723818650907333}
{"step": 300096, "time": 34891.51636838913, "episode/length": 235.0, "episode/score": 0.3284433238317206, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.062818309512636}
{"step": 300128, "time": 34895.21446609497, "episode/length": 288.0, "episode/score": 0.056779537408942815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056779537408942815}
{"step": 300136, "time": 34896.13454413414, "episode/length": 288.0, "episode/score": 0.048545646482239135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048545646482239135}
{"step": 300560, "time": 34945.03917169571, "episode/length": 52.0, "episode/score": 0.8505770529399115, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.013077062462684808}
{"step": 300944, "time": 34989.470054626465, "episode/length": 101.0, "episode/score": 0.7125700591716395, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.028195056773483884}
{"step": 301184, "time": 35017.148228406906, "episode/length": 288.0, "episode/score": 0.051982742066343235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051982742066343235}
{"step": 301320, "time": 35032.88905477524, "episode/length": 288.0, "episode/score": 0.08225785640729555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08225785640729555}
{"step": 301496, "time": 35053.23207807541, "episode/length": 68.0, "episode/score": 0.7976011114043331, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.010101088377382439}
{"step": 301648, "time": 35070.72751832008, "episode/length": 135.0, "episode/score": 0.6083402199374177, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.030215190542548953}
{"step": 301816, "time": 35090.11348223686, "episode/length": 229.0, "episode/score": 0.3404939497918349, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0561189443319563}
{"step": 302192, "time": 35133.52647829056, "episode/length": 288.0, "episode/score": 0.05681063953318244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05681063953318244}
{"step": 302320, "time": 35148.274629831314, "episode/length": 283.0, "episode/score": 0.19789996645016572, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.08227496397051937}
{"step": 302408, "time": 35158.41384649277, "episode/length": 288.0, "episode/score": 0.037551327857954675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037551327857954675}
{"step": 302880, "time": 35212.95048165321, "episode/length": 85.0, "episode/score": 0.7569515777371407, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.022576554395868698}
{"step": 302913, "time": 35217.62093877792, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.595590706758721, "train/action_min": 0.0, "train/action_std": 1.636654599877291, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006152714231203115, "train/actor_opt_grad_steps": 74260.0, "train/actor_opt_loss": -14.636531282025715, "train/adv_mag": 0.45251833533131797, "train/adv_max": 0.21439537835675618, "train/adv_mean": -0.0027244273581218718, "train/adv_min": -0.411953425823256, "train/adv_std": 0.017382066242050295, "train/cont_avg": 0.9961028343023256, "train/cont_loss_mean": 0.010932527519329343, "train/cont_loss_std": 0.1825943952382997, "train/cont_neg_acc": 0.47555062488505717, "train/cont_neg_loss": 2.1766632054646946, "train/cont_pos_acc": 0.9998494403306828, "train/cont_pos_loss": 0.0022747097382603515, "train/cont_pred": 0.9960208138754202, "train/cont_rate": 0.9961028343023256, "train/dyn_loss_mean": 1.000000026059705, "train/dyn_loss_std": 8.341960533153872e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11289905102620292, "train/extr_critic_critic_opt_grad_steps": 74260.0, "train/extr_critic_critic_opt_loss": 7799.122026026526, "train/extr_critic_mag": 0.745246089336484, "train/extr_critic_max": 0.745246089336484, "train/extr_critic_mean": 0.6248208874879881, "train/extr_critic_min": 0.500993042768434, "train/extr_critic_std": 0.02493409154893354, "train/extr_return_normed_mag": 0.4795540463092715, "train/extr_return_normed_max": 0.2580024830130644, "train/extr_return_normed_mean": 0.021429649240142384, "train/extr_return_normed_min": -0.39771043283994806, "train/extr_return_normed_std": 0.03155731051986994, "train/extr_return_rate": 0.9991473253383193, "train/extr_return_raw_mag": 0.8586692859960157, "train/extr_return_raw_max": 0.8586692859960157, "train/extr_return_raw_mean": 0.6220964914144471, "train/extr_return_raw_min": 0.20295637014300325, "train/extr_return_raw_std": 0.03155731051553821, "train/extr_reward_mag": 0.2839422525361527, "train/extr_reward_max": 0.2839422525361527, "train/extr_reward_mean": 0.0007725455217485771, "train/extr_reward_min": 1.4160954675009084e-06, "train/extr_reward_std": 0.006036737157291798, "train/image_loss_mean": 0.08516535798824111, "train/image_loss_std": 0.10660149836262992, "train/model_loss_mean": 0.7094312972800676, "train/model_loss_std": 0.30705084336358446, "train/model_opt_grad_norm": 15.445455741882324, "train/model_opt_grad_steps": 74193.84651162791, "train/model_opt_loss": 3597.7817098928053, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5069.767441860465, "train/policy_entropy_mag": 1.36377017997032, "train/policy_entropy_max": 1.36377017997032, "train/policy_entropy_mean": 0.11019312146791192, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1453221164470495, "train/policy_logprob_mag": 6.551080244640971, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10992616716512414, "train/policy_logprob_min": -6.551080244640971, "train/policy_logprob_std": 0.6471013310343721, "train/policy_randomness_mag": 0.7008392763692279, "train/policy_randomness_max": 0.7008392763692279, "train/policy_randomness_mean": 0.05662806619738424, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07468079931514207, "train/post_ent_mag": 33.303036907107334, "train/post_ent_max": 33.303036907107334, "train/post_ent_mean": 32.999249640176465, "train/post_ent_min": 32.694326844326284, "train/post_ent_std": 0.12438242941401725, "train/prior_ent_mag": 33.47550813541856, "train/prior_ent_max": 33.47550813541856, "train/prior_ent_mean": 32.700030712748685, "train/prior_ent_min": 31.928465687951377, "train/prior_ent_std": 0.2512813699106837, "train/rep_loss_mean": 1.000000026059705, "train/rep_loss_std": 8.341960533153872e-07, "train/reward_avg": 0.0008138361889165069, "train/reward_loss_mean": 0.013333373256894045, "train/reward_loss_std": 0.11062889662679545, "train/reward_max_data": 0.44729217508439584, "train/reward_max_pred": 0.18001031043917634, "train/reward_neg_acc": 0.9998226187949957, "train/reward_neg_loss": 0.009437077871502138, "train/reward_pos_acc": 0.318493151297308, "train/reward_pos_loss": 3.8134648724369806, "train/reward_pred": 0.0007157746951507274, "train/reward_rate": 0.001035610465116279, "train_stats/mean_log_entropy": 0.08889774905724658, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.007615602109581232, "report/cont_loss_std": 0.12719190120697021, "report/cont_neg_acc": 0.8333333730697632, "report/cont_neg_loss": 0.7805806994438171, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0030598165467381477, "report/cont_pred": 0.9927968978881836, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07561469078063965, "report/image_loss_std": 0.10142108052968979, "report/model_loss_mean": 0.6951653957366943, "report/model_loss_std": 0.1736120879650116, "report/post_ent_mag": 33.61207962036133, "report/post_ent_max": 33.61207962036133, "report/post_ent_mean": 33.344417572021484, "report/post_ent_min": 33.03301239013672, "report/post_ent_std": 0.10981199890375137, "report/prior_ent_mag": 33.37455749511719, "report/prior_ent_max": 33.37455749511719, "report/prior_ent_mean": 32.621238708496094, "report/prior_ent_min": 31.841625213623047, "report/prior_ent_std": 0.2392643243074417, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007091591251082718, "report/reward_loss_mean": 0.011935051530599594, "report/reward_loss_std": 0.02929484099149704, "report/reward_max_data": 0.48473215103149414, "report/reward_max_pred": 0.4186244010925293, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.011163064278662205, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8016777038574219, "report/reward_pred": 0.0011175917461514473, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04953255504369736, "eval/cont_loss_std": 0.7257810235023499, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.583999633789062, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.004299349617213011, "eval/cont_pred": 0.9964579343795776, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23524092137813568, "eval/image_loss_std": 0.159396693110466, "eval/model_loss_mean": 0.9004143476486206, "eval/model_loss_std": 1.0510703325271606, "eval/post_ent_mag": 33.617740631103516, "eval/post_ent_max": 33.617740631103516, "eval/post_ent_mean": 33.31806182861328, "eval/post_ent_min": 33.03363037109375, "eval/post_ent_std": 0.11608703434467316, "eval/prior_ent_mag": 33.381229400634766, "eval/prior_ent_max": 33.381229400634766, "eval/prior_ent_mean": 32.637454986572266, "eval/prior_ent_min": 31.795692443847656, "eval/prior_ent_std": 0.2567600607872009, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007293701055459678, "eval/reward_loss_mean": 0.015640873461961746, "eval/reward_loss_std": 0.45195186138153076, "eval/reward_max_data": 0.746874988079071, "eval/reward_max_pred": 0.02281796932220459, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001510912086814642, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 14.470590591430664, "eval/reward_pred": 0.0004109650617465377, "eval/reward_rate": 0.0009765625, "replay/size": 302409.0, "replay/inserts": 8604.0, "replay/samples": 34416.0, "replay/insert_wait_avg": 1.5298525492350261e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.703574742344245e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 71336.0, "eval_replay/inserts": 2104.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.026763662185959e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9940867424011, "timer/env.step_count": 1076.0, "timer/env.step_total": 10.013605833053589, "timer/env.step_frac": 0.010013665046434517, "timer/env.step_avg": 0.009306325123655751, "timer/env.step_min": 0.00830984115600586, "timer/env.step_max": 0.034271955490112305, "timer/replay._sample_count": 34416.0, "timer/replay._sample_total": 16.47019386291504, "timer/replay._sample_frac": 0.016470291255989963, "timer/replay._sample_avg": 0.00047856211828553694, "timer/replay._sample_min": 0.0003447532653808594, "timer/replay._sample_max": 0.028129100799560547, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1339.0, "timer/agent.policy_total": 13.057325839996338, "timer/agent.policy_frac": 0.013057403051784156, "timer/agent.policy_avg": 0.009751550291259401, "timer/agent.policy_min": 0.00865626335144043, "timer/agent.policy_max": 0.03874778747558594, "timer/dataset_train_count": 2151.0, "timer/dataset_train_total": 0.3706200122833252, "timer/dataset_train_frac": 0.00037062220386788853, "timer/dataset_train_avg": 0.000172301260940644, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0004596710205078125, "timer/agent.train_count": 2151.0, "timer/agent.train_total": 962.6022329330444, "timer/agent.train_frac": 0.9626079250816721, "timer/agent.train_avg": 0.4475138228419546, "timer/agent.train_min": 0.43559908866882324, "timer/agent.train_max": 1.3546371459960938, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4760887622833252, "timer/agent.report_frac": 0.00047609157753546384, "timer/agent.report_avg": 0.2380443811416626, "timer/agent.report_min": 0.2330772876739502, "timer/agent.report_max": 0.243011474609375, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9802498617546725e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 8.603934588989677}
{"step": 302936, "time": 35220.077155828476, "episode/length": 160.0, "episode/score": 0.5252522055569102, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.025252206371817465}
{"step": 303496, "time": 35284.69065642357, "episode/length": 288.0, "episode/score": 0.0791422511886708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0791422511886708}
{"step": 303632, "time": 35300.24730801582, "episode/length": 288.0, "episode/score": 0.0785230422898735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0785230422898735}
{"step": 303808, "time": 35320.50699687004, "episode/length": 288.0, "episode/score": 0.06022875191700905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06022875191700905}
{"step": 304128, "time": 35357.387811899185, "episode/length": 288.0, "episode/score": 0.04887849635781549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04887849635781549}
{"step": 304632, "time": 35415.28218793869, "episode/length": 288.0, "episode/score": 0.06047553870558886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06047553870558886}
{"step": 304720, "time": 35425.399631261826, "episode/length": 288.0, "episode/score": 0.07224557466815895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07224557466815895}
{"step": 305136, "time": 35473.23768091202, "episode/length": 281.0, "episode/score": 0.16837049411418548, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.046495491541406864}
{"step": 305248, "time": 35486.07457113266, "episode/length": 288.0, "episode/score": 0.033683100589826154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033683100589826154}
{"step": 305456, "time": 35509.96338224411, "episode/length": 227.0, "episode/score": 0.3247410358749221, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.03411603032191124}
{"step": 305592, "time": 35525.60104584694, "episode/length": 42.0, "episode/score": 0.8897535870194133, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.02100360268309487}
{"step": 305672, "time": 35534.793704748154, "episode/length": 129.0, "episode/score": 0.6316708196529817, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.03479579955387635}
{"step": 305784, "time": 35547.62355184555, "episode/length": 285.0, "episode/score": 0.18801905023394738, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.07864405052498569}
{"step": 306120, "time": 35586.31656169891, "episode/length": 288.0, "episode/score": 0.050800672913680955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050800672913680955}
{"step": 306440, "time": 35623.15377283096, "episode/length": 288.0, "episode/score": 0.05344348318357106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05344348318357106}
{"step": 306752, "time": 35658.88216781616, "episode/length": 134.0, "episode/score": 0.6108765866297858, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.029626592840543253}
{"step": 306912, "time": 35677.36629843712, "episode/length": 19.0, "episode/score": 0.9506357313828175, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.010010737593574959}
{"step": 307032, "time": 35691.17981386185, "episode/length": 288.0, "episode/score": 0.02787157223019676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02787157223019676}
{"step": 307448, "time": 35739.16980218887, "episode/length": 288.0, "episode/score": 0.02883017080660011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02883017080660011}
{"step": 307768, "time": 35775.94488072395, "episode/length": 288.0, "episode/score": 0.0252431432741389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0252431432741389}
{"step": 307904, "time": 35791.61029791832, "episode/length": 288.0, "episode/score": 0.02952623461462167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02952623461462167}
{"step": 308096, "time": 35813.708789110184, "episode/length": 288.0, "episode/score": 0.019263114861672648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019263114861672648}
{"step": 308432, "time": 35852.51051449776, "episode/length": 288.0, "episode/score": 0.05157298326230375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05157298326230375}
{"step": 308752, "time": 35889.19507622719, "episode/length": 288.0, "episode/score": 0.05574841693015742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05574841693015742}
{"step": 309224, "time": 35943.33898425102, "episode/length": 288.0, "episode/score": 0.027804630599348457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027804630599348457}
{"step": 309344, "time": 35957.13086795807, "episode/length": 288.0, "episode/score": 0.04955265607256365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04955265607256365}
{"step": 309760, "time": 36005.386857032776, "episode/length": 288.0, "episode/score": 0.02781034930291071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02781034930291071}
{"step": 310016, "time": 36034.89808297157, "episode/length": 157.0, "episode/score": 0.5295354518941906, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.02016047595432724}
{"step": 310024, "time": 36036.275735616684, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 310024, "time": 36036.280024290085, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 310024, "time": 36036.28447151184, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 310024, "time": 36037.90086174011, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 310024, "time": 36038.68629360199, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 310024, "time": 36038.89665007591, "eval_episode/length": 183.0, "eval_episode/score": 0.4281249940395355, "eval_episode/reward_rate": 0.005434782608695652}
{"step": 310024, "time": 36041.02647614479, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 310024, "time": 36041.247148513794, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 36041.25319981575, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 36041.2587082386, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310080, "time": 36047.70613574982, "episode/length": 288.0, "episode/score": 0.04640920209422461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04640920209422461}
{"step": 310216, "time": 36063.39228749275, "episode/length": 288.0, "episode/score": 0.03583567383989816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03583567383989816}
{"step": 310408, "time": 36085.36243367195, "episode/length": 288.0, "episode/score": 0.021526634951527512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021526634951527512}
{"step": 310720, "time": 36121.17426300049, "episode/length": 186.0, "episode/score": 0.4513865404007049, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.03263655348578709}
{"step": 310744, "time": 36123.960210084915, "episode/length": 288.0, "episode/score": 0.04011639697458236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04011639697458236}
{"step": 310928, "time": 36145.06737494469, "episode/length": 197.0, "episode/score": 0.4251489510834574, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.04077393842911192}
{"step": 311064, "time": 36160.69130849838, "episode/length": 122.0, "episode/score": 0.6536201627630192, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.034870209713318445}
{"step": 311549, "time": 36217.91283226013, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9044890227141202, "train/action_min": 0.0, "train/action_std": 1.6320312376375552, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0061701967960861685, "train/actor_opt_grad_steps": 76415.0, "train/actor_opt_loss": -15.130974275094491, "train/adv_mag": 0.38147081627889917, "train/adv_max": 0.17873994633555412, "train/adv_mean": -0.0005945989098984648, "train/adv_min": -0.3496689534297696, "train/adv_std": 0.01606503373477608, "train/cont_avg": 0.9960485387731481, "train/cont_loss_mean": 0.01099728431425454, "train/cont_loss_std": 0.18192693111443617, "train/cont_neg_acc": 0.4694592863599831, "train/cont_neg_loss": 2.1726623457931886, "train/cont_pos_acc": 0.9999047021071116, "train/cont_pos_loss": 0.0022317850094555913, "train/cont_pred": 0.99600417415301, "train/cont_rate": 0.9960485387731481, "train/dyn_loss_mean": 1.000014082701118, "train/dyn_loss_std": 0.0004504276439547539, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1049411870987603, "train/extr_critic_critic_opt_grad_steps": 76415.0, "train/extr_critic_critic_opt_loss": 10088.938815646701, "train/extr_critic_mag": 0.6915481073988808, "train/extr_critic_max": 0.6915481073988808, "train/extr_critic_mean": 0.5469159856438637, "train/extr_critic_min": 0.44829840075086663, "train/extr_critic_std": 0.0331916810548002, "train/extr_return_normed_mag": 0.41792168509629035, "train/extr_return_normed_max": 0.26815806618995136, "train/extr_return_normed_mean": 0.035537346757741436, "train/extr_return_normed_min": -0.3109538368880749, "train/extr_return_normed_std": 0.03749536337434418, "train/extr_return_rate": 0.9790777961413065, "train/extr_return_raw_mag": 0.7789420441344932, "train/extr_return_raw_max": 0.7789420441344932, "train/extr_return_raw_mean": 0.5463213545304758, "train/extr_return_raw_min": 0.199830141056467, "train/extr_return_raw_std": 0.03749536333985075, "train/extr_reward_mag": 0.3221969466518473, "train/extr_reward_max": 0.3221969466518473, "train/extr_reward_mean": 0.0007239102404936501, "train/extr_reward_min": 1.3891193601820205e-06, "train/extr_reward_std": 0.006695758092165407, "train/image_loss_mean": 0.08546262920868618, "train/image_loss_std": 0.10648664735533574, "train/model_loss_mean": 0.7098080493785717, "train/model_loss_std": 0.30205721587494566, "train/model_opt_grad_norm": 15.12726127659833, "train/model_opt_grad_steps": 76346.81481481482, "train/model_opt_loss": 3793.8741975007233, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5393.518518518518, "train/policy_entropy_mag": 1.3391109511808112, "train/policy_entropy_max": 1.3391109511808112, "train/policy_entropy_mean": 0.10561286247576829, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1368158329968099, "train/policy_logprob_mag": 6.551080253389147, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1054020001794453, "train/policy_logprob_min": -6.551080253389147, "train/policy_logprob_std": 0.6419187108123744, "train/policy_randomness_mag": 0.6881669403778182, "train/policy_randomness_max": 0.6881669403778182, "train/policy_randomness_mean": 0.0542742774511377, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07030943415507122, "train/post_ent_mag": 33.458357652028404, "train/post_ent_max": 33.458357652028404, "train/post_ent_mean": 33.1821292064808, "train/post_ent_min": 32.90763030228791, "train/post_ent_std": 0.11187634158327624, "train/prior_ent_mag": 33.53907187779745, "train/prior_ent_max": 33.53907187779745, "train/prior_ent_mean": 32.72649538958514, "train/prior_ent_min": 31.864036524737323, "train/prior_ent_std": 0.2618632480778076, "train/rep_loss_mean": 1.000014082701118, "train/rep_loss_std": 0.0004504276439547539, "train/reward_avg": 0.0008028978508163062, "train/reward_loss_mean": 0.01333966399801688, "train/reward_loss_std": 0.1066981191807254, "train/reward_max_data": 0.4157312088117814, "train/reward_max_pred": 0.17921112532968875, "train/reward_neg_acc": 0.9998143966551181, "train/reward_neg_loss": 0.009509361305929444, "train/reward_pos_acc": 0.2656641613720055, "train/reward_pos_loss": 3.9965340416682396, "train/reward_pred": 0.0007048181098609886, "train/reward_rate": 0.000999168113425926, "train_stats/mean_log_entropy": 0.08739384551133428, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.0018281156662851572, "report/cont_loss_std": 0.009492795914411545, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0018281156662851572, "report/cont_pred": 0.9982166290283203, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07822476327419281, "report/image_loss_std": 0.1050642654299736, "report/model_loss_mean": 0.689133882522583, "report/model_loss_std": 0.10977084189653397, "report/post_ent_mag": 33.229530334472656, "report/post_ent_max": 33.229530334472656, "report/post_ent_mean": 32.9395751953125, "report/post_ent_min": 32.67087936401367, "report/post_ent_std": 0.10551787167787552, "report/prior_ent_mag": 33.44809341430664, "report/prior_ent_max": 33.44809341430664, "report/prior_ent_mean": 32.74265670776367, "report/prior_ent_min": 31.92350196838379, "report/prior_ent_std": 0.28759193420410156, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00020050565944984555, "report/reward_loss_mean": 0.009080968797206879, "report/reward_loss_std": 0.013126706704497337, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.013472437858581543, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009080968797206879, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00032716512214392424, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.04229836165904999, "eval/cont_loss_std": 0.6933923363685608, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.635420799255371, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.005296040792018175, "eval/cont_pred": 0.9975944757461548, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25213032960891724, "eval/image_loss_std": 0.19667814671993256, "eval/model_loss_mean": 0.8958519697189331, "eval/model_loss_std": 0.7219440340995789, "eval/post_ent_mag": 33.2298698425293, "eval/post_ent_max": 33.2298698425293, "eval/post_ent_mean": 32.92665100097656, "eval/post_ent_min": 32.68138885498047, "eval/post_ent_std": 0.1042303517460823, "eval/prior_ent_mag": 33.47254943847656, "eval/prior_ent_max": 33.47254943847656, "eval/prior_ent_mean": 32.70909118652344, "eval/prior_ent_min": 31.927698135375977, "eval/prior_ent_std": 0.2899163067340851, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014232904650270939, "eval/reward_loss_std": 0.0023967570159584284, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.027923941612243652, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014232904650270939, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002988027408719063, "eval/reward_rate": 0.0, "replay/size": 311045.0, "replay/inserts": 8636.0, "replay/samples": 34544.0, "replay/insert_wait_avg": 1.5198218154377162e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.707399590913208e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 73648.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0374095613156223e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2783756256104, "timer/env.step_count": 1079.0, "timer/env.step_total": 10.095920085906982, "timer/env.step_frac": 0.010093110409982248, "timer/env.step_avg": 0.009356737799728437, "timer/env.step_min": 0.008305072784423828, "timer/env.step_max": 0.034050703048706055, "timer/replay._sample_count": 34544.0, "timer/replay._sample_total": 16.423325538635254, "timer/replay._sample_frac": 0.01641875495745223, "timer/replay._sample_avg": 0.0004754320732583156, "timer/replay._sample_min": 0.00036025047302246094, "timer/replay._sample_max": 0.009413957595825195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1368.0, "timer/agent.policy_total": 13.666693687438965, "timer/agent.policy_frac": 0.013662890271811903, "timer/agent.policy_avg": 0.009990273163332576, "timer/agent.policy_min": 0.008715629577636719, "timer/agent.policy_max": 0.06863689422607422, "timer/dataset_train_count": 2159.0, "timer/dataset_train_total": 0.37192797660827637, "timer/dataset_train_frac": 0.00037182446973889555, "timer/dataset_train_avg": 0.00017226863205570928, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0012066364288330078, "timer/agent.train_count": 2159.0, "timer/agent.train_total": 961.7965104579926, "timer/agent.train_frac": 0.9615288442644281, "timer/agent.train_avg": 0.4454824041028219, "timer/agent.train_min": 0.42989134788513184, "timer/agent.train_max": 0.5865864753723145, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4765026569366455, "timer/agent.report_frac": 0.0004763700471267546, "timer/agent.report_avg": 0.23825132846832275, "timer/agent.report_min": 0.23314905166625977, "timer/agent.report_max": 0.24335360527038574, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5510787963867188e-05, "timer/dataset_eval_frac": 2.5503688358664972e-08, "timer/dataset_eval_avg": 2.5510787963867188e-05, "timer/dataset_eval_min": 2.5510787963867188e-05, "timer/dataset_eval_max": 2.5510787963867188e-05, "fps": 8.63346947967015}
{"step": 311560, "time": 36218.99921250343, "episode/length": 192.0, "episode/score": 0.43504594925801143, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.03504592897846237}
{"step": 311752, "time": 36241.11200642586, "episode/length": 102.0, "episode/score": 0.7067737031994739, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.025523722952243588}
{"step": 312072, "time": 36278.00795125961, "episode/length": 288.0, "episode/score": 0.06010896839882207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06010896839882207}
{"step": 312528, "time": 36330.50242853165, "episode/length": 288.0, "episode/score": 0.06350771060820648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06350771060820648}
{"step": 312560, "time": 36334.276106119156, "episode/length": 100.0, "episode/score": 0.7131297880761167, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.02562978091657442}
{"step": 312720, "time": 36352.71931695938, "episode/length": 288.0, "episode/score": 0.04899330297016036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04899330297016036}
{"step": 312808, "time": 36362.88186979294, "episode/length": 155.0, "episode/score": 0.5521896964543771, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.03656470853246674}
{"step": 313032, "time": 36388.58040881157, "episode/length": 288.0, "episode/score": 0.0417278176210516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0417278176210516}
{"step": 313056, "time": 36391.44739174843, "episode/length": 288.0, "episode/score": 0.034443111024756945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034443111024756945}
{"step": 313376, "time": 36428.22298145294, "episode/length": 288.0, "episode/score": 0.05195517846328812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05195517846328812}
{"step": 313896, "time": 36488.445360183716, "episode/length": 107.0, "episode/score": 0.6884387839553483, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.022813821956219726}
{"step": 314008, "time": 36501.41300916672, "episode/length": 241.0, "episode/score": 0.3101071428716864, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.06323214513014364}
{"step": 314784, "time": 36591.343240737915, "episode/length": 175.0, "episode/score": 0.4827701613665738, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.02964516158485253}
{"step": 314840, "time": 36597.83546304703, "episode/length": 288.0, "episode/score": 0.018550094399074624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018550094399074624}
{"step": 314872, "time": 36601.639300107956, "episode/length": 288.0, "episode/score": 0.058975894928408934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058975894928408934}
{"step": 315032, "time": 36620.06024694443, "episode/length": 288.0, "episode/score": 0.036952878676686396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036952878676686396}
{"step": 315120, "time": 36630.2196085453, "episode/length": 288.0, "episode/score": 0.03375871426908361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03375871426908361}
{"step": 315368, "time": 36658.77290081978, "episode/length": 288.0, "episode/score": 0.03848767933726549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03848767933726549}
{"step": 315400, "time": 36662.52748417854, "episode/length": 173.0, "episode/score": 0.5048865246427567, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.045511544762234735}
{"step": 315568, "time": 36681.8936958313, "episode/length": 97.0, "episode/score": 0.7194920331229753, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.02261702885053296}
{"step": 315616, "time": 36687.398978710175, "episode/length": 92.0, "episode/score": 0.7461075097787386, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.03360753383887527}
{"step": 315728, "time": 36700.27571392059, "episode/length": 86.0, "episode/score": 0.7408802951493954, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.009630324212480446}
{"step": 315856, "time": 36714.87169933319, "episode/length": 29.0, "episode/score": 0.9216001534098268, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.012225118147625835}
{"step": 316208, "time": 36755.38650679588, "episode/length": 288.0, "episode/score": 0.04222627609038909, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04222627609038909}
{"step": 316432, "time": 36781.20515918732, "episode/length": 107.0, "episode/score": 0.6962966403820303, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.030671634829019467}
{"step": 316488, "time": 36787.70887470245, "episode/length": 135.0, "episode/score": 0.5993413111660573, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.021216304006514974}
{"step": 316896, "time": 36834.685618162155, "episode/length": 190.0, "episode/score": 0.4483109310776854, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.042060931186824746}
{"step": 316952, "time": 36841.13040781021, "episode/length": 92.0, "episode/score": 0.7260613293302356, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.013561370314249643}
{"step": 317152, "time": 36864.20371770859, "episode/length": 288.0, "episode/score": 0.02460064820652974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02460064820652974}
{"step": 317224, "time": 36872.54576468468, "episode/length": 262.0, "episode/score": 0.23932758472163584, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.05807757206729036}
{"step": 318040, "time": 36967.02859091759, "episode/length": 288.0, "episode/score": 0.03592033861013988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03592033861013988}
{"step": 318056, "time": 36968.86143755913, "episode/length": 103.0, "episode/score": 0.7015256961094707, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.02340064905003203}
{"step": 318168, "time": 36981.733523368835, "episode/length": 288.0, "episode/score": 0.0329987442767532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0329987442767532}
{"step": 318168, "time": 36981.74025082588, "episode/length": 126.0, "episode/score": 0.6135502101840302, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.007300205508499857}
{"step": 318744, "time": 37048.13341379166, "episode/length": 288.0, "episode/score": 0.03181387505541977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03181387505541977}
{"step": 318800, "time": 37054.7019200325, "episode/length": 288.0, "episode/score": 0.03298491846453544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03298491846453544}
{"step": 319208, "time": 37101.886670827866, "episode/length": 288.0, "episode/score": 0.05146524153752807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05146524153752807}
{"step": 319264, "time": 37108.31154727936, "episode/length": 288.0, "episode/score": 0.020871059899647548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020871059899647548}
{"step": 320008, "time": 37195.016751527786, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 320008, "time": 37195.16269946098, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 320008, "time": 37196.26514840126, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 320008, "time": 37196.72168803215, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 320008, "time": 37197.67353963852, "eval_episode/length": 188.0, "eval_episode/score": 0.4124999940395355, "eval_episode/reward_rate": 0.005291005291005291}
{"step": 320008, "time": 37199.01870536804, "eval_episode/length": 268.0, "eval_episode/score": 0.16249999403953552, "eval_episode/reward_rate": 0.0037174721189591076}
{"step": 320008, "time": 37199.282106637955, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 320008, "time": 37199.376197338104, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 37199.382361888885, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320161, "time": 37217.9849383831, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0087675871672452, "train/action_min": 0.0, "train/action_std": 1.6411986588327974, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0068479429238424115, "train/actor_opt_grad_steps": 78575.0, "train/actor_opt_loss": -16.38317490507055, "train/adv_mag": 0.4107570442612524, "train/adv_max": 0.1967129998460964, "train/adv_mean": 0.001410403321930563, "train/adv_min": -0.38871079062422115, "train/adv_std": 0.019277662086231565, "train/cont_avg": 0.9957184968171297, "train/cont_loss_mean": 0.011509012563490413, "train/cont_loss_std": 0.18919835537585808, "train/cont_neg_acc": 0.4840732168092906, "train/cont_neg_loss": 2.201448150290927, "train/cont_pos_acc": 0.9999045975230358, "train/cont_pos_loss": 0.002162381822590423, "train/cont_pred": 0.9958502150796078, "train/cont_rate": 0.9957184968171297, "train/dyn_loss_mean": 1.0000013996053625, "train/dyn_loss_std": 4.475594808657964e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1192843884108933, "train/extr_critic_critic_opt_grad_steps": 78575.0, "train/extr_critic_critic_opt_loss": 9294.828403049045, "train/extr_critic_mag": 0.7278177423609627, "train/extr_critic_max": 0.7278177423609627, "train/extr_critic_mean": 0.565460363747897, "train/extr_critic_min": 0.44989154901769424, "train/extr_critic_std": 0.037351293937751544, "train/extr_return_normed_mag": 0.43710970230124613, "train/extr_return_normed_max": 0.2965741434858905, "train/extr_return_normed_mean": 0.04836576358691134, "train/extr_return_normed_min": -0.3461936418381002, "train/extr_return_normed_std": 0.04256782860115722, "train/extr_return_rate": 0.9868294119283005, "train/extr_return_raw_mag": 0.8150791476170222, "train/extr_return_raw_max": 0.8150791476170222, "train/extr_return_raw_mean": 0.5668707950799553, "train/extr_return_raw_min": 0.17231136284492635, "train/extr_return_raw_std": 0.04256782858391051, "train/extr_reward_mag": 0.32920220990975696, "train/extr_reward_max": 0.32920220990975696, "train/extr_reward_mean": 0.0008519563448822333, "train/extr_reward_min": 1.1131719306663231e-06, "train/extr_reward_std": 0.007028248207967004, "train/image_loss_mean": 0.08647576943729762, "train/image_loss_std": 0.10650637463011124, "train/model_loss_mean": 0.7123546062244309, "train/model_loss_std": 0.3259914214895279, "train/model_opt_grad_norm": 14.932666561215424, "train/model_opt_grad_steps": 78504.76388888889, "train/model_opt_loss": 3677.3240661621094, "train/model_opt_model_opt_grad_overflow": 0.004629629629629629, "train/model_opt_model_opt_grad_scale": 5162.037037037037, "train/policy_entropy_mag": 1.3948772566186056, "train/policy_entropy_max": 1.3948772566186056, "train/policy_entropy_mean": 0.10626154437799144, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1407503576397344, "train/policy_logprob_mag": 6.551080242351249, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10565001686552057, "train/policy_logprob_min": -6.551080242351249, "train/policy_logprob_std": 0.641039406535802, "train/policy_randomness_mag": 0.7168251524368922, "train/policy_randomness_max": 0.7168251524368922, "train/policy_randomness_mean": 0.05460763369100513, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07233137963339686, "train/post_ent_mag": 33.42048899332682, "train/post_ent_max": 33.42048899332682, "train/post_ent_mean": 33.146906835061536, "train/post_ent_min": 32.88229822229456, "train/post_ent_std": 0.10977376114439082, "train/prior_ent_mag": 33.58177789052328, "train/prior_ent_max": 33.58177789052328, "train/prior_ent_mean": 32.8170728860078, "train/prior_ent_min": 31.822729490421438, "train/prior_ent_std": 0.32214356938170063, "train/rep_loss_mean": 1.0000013996053625, "train/rep_loss_std": 4.475594808657964e-05, "train/reward_avg": 0.0009227420501971479, "train/reward_loss_mean": 0.014368960937847279, "train/reward_loss_std": 0.12461778532748145, "train/reward_max_data": 0.47649405155054947, "train/reward_max_pred": 0.19103395662925862, "train/reward_neg_acc": 0.9998777732253075, "train/reward_neg_loss": 0.009586050709778512, "train/reward_pos_acc": 0.3064692990952416, "train/reward_pos_loss": 3.891037807750859, "train/reward_pred": 0.0007450709570009538, "train/reward_rate": 0.001216182002314815, "train_stats/mean_log_entropy": 0.08250861340447475, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.009189190343022346, "report/cont_loss_std": 0.22266097366809845, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 2.519868850708008, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.001812071306630969, "report/cont_pred": 0.9966124296188354, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07536790519952774, "report/image_loss_std": 0.10666459798812866, "report/model_loss_mean": 0.7003417015075684, "report/model_loss_std": 0.44297662377357483, "report/post_ent_mag": 33.37401580810547, "report/post_ent_max": 33.37401580810547, "report/post_ent_mean": 33.09758758544922, "report/post_ent_min": 32.8366584777832, "report/post_ent_std": 0.10744127631187439, "report/prior_ent_mag": 33.897918701171875, "report/prior_ent_max": 33.897918701171875, "report/prior_ent_mean": 33.32539367675781, "report/prior_ent_min": 32.35454559326172, "report/prior_ent_std": 0.22270946204662323, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006064828485250473, "report/reward_loss_mean": 0.015784580260515213, "report/reward_loss_std": 0.1923591047525406, "report/reward_max_data": 0.4063636362552643, "report/reward_max_pred": 0.026778697967529297, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009785681031644344, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.152657508850098, "report/reward_pred": 0.0005305389640852809, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03193509206175804, "eval/cont_loss_std": 0.539208173751831, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.6600542068481445, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0020208992063999176, "eval/cont_pred": 0.9979798793792725, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24131335318088531, "eval/image_loss_std": 0.15731574594974518, "eval/model_loss_mean": 0.8853247165679932, "eval/model_loss_std": 0.6749635338783264, "eval/post_ent_mag": 33.372840881347656, "eval/post_ent_max": 33.372840881347656, "eval/post_ent_mean": 33.096431732177734, "eval/post_ent_min": 32.7977294921875, "eval/post_ent_std": 0.12547799944877625, "eval/prior_ent_mag": 33.897918701171875, "eval/prior_ent_max": 33.897918701171875, "eval/prior_ent_mean": 33.30309295654297, "eval/prior_ent_min": 32.358036041259766, "eval/prior_ent_std": 0.24715659022331238, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0014709472889080644, "eval/reward_loss_mean": 0.012076273560523987, "eval/reward_loss_std": 0.23157484829425812, "eval/reward_max_data": 0.753125011920929, "eval/reward_max_pred": 0.02756631374359131, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0018380136461928487, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.2438273429870605, "eval/reward_pred": 0.0005857773358002305, "eval/reward_rate": 0.001953125, "replay/size": 319657.0, "replay/inserts": 8612.0, "replay/samples": 34448.0, "replay/insert_wait_avg": 1.530563117070249e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.622293466974622e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 75960.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0097728056066177e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0577392578125, "timer/env.step_count": 1077.0, "timer/env.step_total": 10.08744740486145, "timer/env.step_frac": 0.010086864996762882, "timer/env.step_avg": 0.00936624642976922, "timer/env.step_min": 0.00830841064453125, "timer/env.step_max": 0.038222551345825195, "timer/replay._sample_count": 34448.0, "timer/replay._sample_total": 16.4768226146698, "timer/replay._sample_frac": 0.01647587131008854, "timer/replay._sample_avg": 0.0004783099922976602, "timer/replay._sample_min": 0.0003426074981689453, "timer/replay._sample_max": 0.019699811935424805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1366.0, "timer/agent.policy_total": 13.223009824752808, "timer/agent.policy_frac": 0.013222246382060094, "timer/agent.policy_avg": 0.009680095040082583, "timer/agent.policy_min": 0.008758544921875, "timer/agent.policy_max": 0.03716015815734863, "timer/dataset_train_count": 2153.0, "timer/dataset_train_total": 0.3757364749908447, "timer/dataset_train_frac": 0.0003757147814982118, "timer/dataset_train_avg": 0.0001745176381750324, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.0007436275482177734, "timer/agent.train_count": 2153.0, "timer/agent.train_total": 962.1400952339172, "timer/agent.train_frac": 0.9620845451863252, "timer/agent.train_avg": 0.4468834627189583, "timer/agent.train_min": 0.43418192863464355, "timer/agent.train_max": 0.5746932029724121, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.476409912109375, "timer/agent.report_frac": 0.0004763824061428094, "timer/agent.report_avg": 0.2382049560546875, "timer/agent.report_min": 0.23349523544311523, "timer/agent.report_max": 0.24291467666625977, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9562196909284902e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 8.611383107078543}
{"step": 320352, "time": 37239.78759455681, "episode/length": 288.0, "episode/score": 0.05956082416039976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05956082416039976}
{"step": 320368, "time": 37241.65041804314, "episode/length": 288.0, "episode/score": 0.022550222217034843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022550222217034843}
{"step": 320480, "time": 37254.55458569527, "episode/length": 288.0, "episode/score": 0.025640567902939893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025640567902939893}
{"step": 320480, "time": 37254.56154632568, "episode/length": 288.0, "episode/score": 0.023374974524784875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023374974524784875}
{"step": 320792, "time": 37290.482363939285, "episode/length": 38.0, "episode/score": 0.8938934275686279, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.012643426835211358}
{"step": 321056, "time": 37321.16363310814, "episode/length": 288.0, "episode/score": 0.02097660096339382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02097660096339382}
{"step": 321112, "time": 37327.71994185448, "episode/length": 288.0, "episode/score": 0.013758457094539267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013758457094539267}
{"step": 321192, "time": 37336.94743561745, "episode/length": 104.0, "episode/score": 0.6944888249883974, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.01948879081759003}
{"step": 321520, "time": 37375.2402818203, "episode/length": 288.0, "episode/score": 0.017480527786418065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017480527786418065}
{"step": 321576, "time": 37381.77279424667, "episode/length": 288.0, "episode/score": 0.0319500568630815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0319500568630815}
{"step": 321848, "time": 37413.318484544754, "episode/length": 40.0, "episode/score": 0.8821017610070356, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.007101773085125274}
{"step": 322016, "time": 37432.68532180786, "episode/length": 102.0, "episode/score": 0.6951306278428717, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.013880665843743145}
{"step": 322136, "time": 37446.62728881836, "episode/length": 167.0, "episode/score": 0.4992260309857244, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.02110101536278819}
{"step": 322144, "time": 37447.55182361603, "episode/length": 36.0, "episode/score": 0.8958291971609356, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.008329229221715195}
{"step": 322160, "time": 37449.41765213013, "episode/length": 223.0, "episode/score": 0.33502926969489977, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.031904260957929864}
{"step": 322568, "time": 37496.57809519768, "episode/length": 50.0, "episode/score": 0.8502426925505944, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.006492706709607887}
{"step": 322792, "time": 37522.43261599541, "episode/length": 288.0, "episode/score": 0.04871986299795594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04871986299795594}
{"step": 323000, "time": 37546.44133687019, "episode/length": 122.0, "episode/score": 0.6420420081255145, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.023292029922828306}
{"step": 323128, "time": 37561.226231098175, "episode/length": 41.0, "episode/score": 0.8819669502528313, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.010091934059460073}
{"step": 323160, "time": 37564.934556245804, "episode/length": 197.0, "episode/score": 0.4061894972772677, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.02181449735584806}
{"step": 323368, "time": 37588.91111159325, "episode/length": 288.0, "episode/score": 0.027642305467452388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027642305467452388}
{"step": 323424, "time": 37595.40126514435, "episode/length": 288.0, "episode/score": 0.04590406876384634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04590406876384634}
{"step": 324024, "time": 37664.53301358223, "episode/length": 107.0, "episode/score": 0.6758232805417492, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.010198321525763276}
{"step": 324048, "time": 37667.32358574867, "episode/length": 238.0, "episode/score": 0.2838677799193903, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.02761777118242037}
{"step": 324272, "time": 37693.18319892883, "episode/length": 158.0, "episode/score": 0.5328926986344555, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.026642651575016885}
{"step": 324352, "time": 37702.44026470184, "episode/length": 115.0, "episode/score": 0.6636364017250429, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.023011428304116066}
{"step": 324456, "time": 37714.46837282181, "episode/length": 288.0, "episode/score": 0.034257803889857996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034257803889857996}
{"step": 324880, "time": 37763.3767015934, "episode/length": 288.0, "episode/score": 0.046459847428849343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046459847428849343}
{"step": 325088, "time": 37787.348840236664, "episode/length": 91.0, "episode/score": 0.7347351699282854, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0191101909150575}
{"step": 325128, "time": 37791.95834326744, "episode/length": 137.0, "episode/score": 0.5873893367897836, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.015514358587097377}
{"step": 325440, "time": 37827.98835372925, "episode/length": 288.0, "episode/score": 0.04046161462990483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04046161462990483}
{"step": 325440, "time": 37827.9950170517, "episode/length": 122.0, "episode/score": 0.6511594772779858, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.03240951826199989}
{"step": 325680, "time": 37855.673283576965, "episode/length": 288.0, "episode/score": 0.04840731519746555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04840731519746555}
{"step": 325888, "time": 37879.69679784775, "episode/length": 99.0, "episode/score": 0.7206498507526788, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.03002481019358072}
{"step": 325904, "time": 37881.56441998482, "episode/length": 96.0, "episode/score": 0.7304590355503962, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.030459033152240522}
{"step": 326280, "time": 37925.189276218414, "episode/length": 174.0, "episode/score": 0.5097475611798359, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.05349755042306015}
{"step": 326296, "time": 37927.03510069847, "episode/length": 76.0, "episode/score": 0.78278667907216, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.02028667667400441}
{"step": 326360, "time": 37934.40560269356, "episode/length": 288.0, "episode/score": 0.06265159735568204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06265159735568204}
{"step": 326584, "time": 37960.25101184845, "episode/length": 288.0, "episode/score": 0.05748324632547508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05748324632547508}
{"step": 327088, "time": 38018.56908726692, "episode/length": 149.0, "episode/score": 0.5728845444343733, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.03850951819435977}
{"step": 327752, "time": 38095.66300415993, "episode/length": 288.0, "episode/score": 0.06430582964166831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06430582964166831}
{"step": 327752, "time": 38095.67000436783, "episode/length": 288.0, "episode/score": 0.04619551911594044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04619551911594044}
{"step": 328216, "time": 38149.1873459816, "episode/length": 288.0, "episode/score": 0.07238789977247961, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07238789977247961}
{"step": 328592, "time": 38192.50387430191, "episode/length": 288.0, "episode/score": 0.07654837456061614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07654837456061614}
{"step": 328608, "time": 38194.361199617386, "episode/length": 288.0, "episode/score": 0.05975780021481114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05975780021481114}
{"step": 328672, "time": 38201.72117805481, "episode/length": 288.0, "episode/score": 0.057047668422569586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057047668422569586}
{"step": 328809, "time": 38218.39611983299, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7588498150860823, "train/action_min": 0.0, "train/action_std": 1.7117750103826876, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007194325181276158, "train/actor_opt_grad_steps": 80735.0, "train/actor_opt_loss": -17.74365950513769, "train/adv_mag": 0.42725118884333857, "train/adv_max": 0.24229344835987798, "train/adv_mean": 0.00014178118065636362, "train/adv_min": -0.378522836499744, "train/adv_std": 0.02059455312512539, "train/cont_avg": 0.9959671585648148, "train/cont_loss_mean": 0.011571573987128903, "train/cont_loss_std": 0.18930360383173037, "train/cont_neg_acc": 0.4440594811534658, "train/cont_neg_loss": 2.2897873821592767, "train/cont_pos_acc": 0.9998955668674575, "train/cont_pos_loss": 0.0023724021744716017, "train/cont_pred": 0.995920263506748, "train/cont_rate": 0.9959671585648148, "train/dyn_loss_mean": 1.0000001937150955, "train/dyn_loss_std": 6.192855868936965e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14437645434022503, "train/extr_critic_critic_opt_grad_steps": 80735.0, "train/extr_critic_critic_opt_loss": 8001.1205806025755, "train/extr_critic_mag": 0.740896827644772, "train/extr_critic_max": 0.740896827644772, "train/extr_critic_mean": 0.588212707804309, "train/extr_critic_min": 0.4902999268637763, "train/extr_critic_std": 0.03696328511082188, "train/extr_return_normed_mag": 0.4556191111052478, "train/extr_return_normed_max": 0.3377328835151814, "train/extr_return_normed_mean": 0.04328349806126897, "train/extr_return_normed_min": -0.32274062241669055, "train/extr_return_normed_std": 0.04291940162268778, "train/extr_return_rate": 0.9988375043979397, "train/extr_return_raw_mag": 0.8828038407696618, "train/extr_return_raw_max": 0.8828038407696618, "train/extr_return_raw_mean": 0.5883544871100673, "train/extr_return_raw_min": 0.22233033456184245, "train/extr_return_raw_std": 0.04291940157094763, "train/extr_reward_mag": 0.38597159970689704, "train/extr_reward_max": 0.38597159970689704, "train/extr_reward_mean": 0.0008645370419091907, "train/extr_reward_min": 1.054119180749964e-06, "train/extr_reward_std": 0.007351213851102835, "train/image_loss_mean": 0.08580684372120434, "train/image_loss_std": 0.10631500984783526, "train/model_loss_mean": 0.7111045541586699, "train/model_loss_std": 0.3099870141250668, "train/model_opt_grad_norm": 14.822209023320397, "train/model_opt_grad_steps": 80663.00462962964, "train/model_opt_loss": 4189.757259792752, "train/model_opt_model_opt_grad_overflow": 0.004629629629629629, "train/model_opt_model_opt_grad_scale": 5879.62962962963, "train/policy_entropy_mag": 1.3855401614197977, "train/policy_entropy_max": 1.3855401614197977, "train/policy_entropy_mean": 0.10450252731917081, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13783761158723523, "train/policy_logprob_mag": 6.551080246766408, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1046109286447366, "train/policy_logprob_min": -6.551080246766408, "train/policy_logprob_std": 0.6434575473820722, "train/policy_randomness_mag": 0.7120268339360202, "train/policy_randomness_max": 0.7120268339360202, "train/policy_randomness_mean": 0.0537036779957513, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0708345247225629, "train/post_ent_mag": 33.439471297793915, "train/post_ent_max": 33.439471297793915, "train/post_ent_mean": 33.168326731081365, "train/post_ent_min": 32.908187283409966, "train/post_ent_std": 0.10924449373312571, "train/prior_ent_mag": 33.61510414547391, "train/prior_ent_max": 33.61510414547391, "train/prior_ent_mean": 32.995513403857196, "train/prior_ent_min": 32.11228578178971, "train/prior_ent_std": 0.23871545203857952, "train/rep_loss_mean": 1.0000001937150955, "train/rep_loss_std": 6.192855868936965e-06, "train/reward_avg": 0.0008855221122522144, "train/reward_loss_mean": 0.013725995226263034, "train/reward_loss_std": 0.11010173708200455, "train/reward_max_data": 0.4742813206987059, "train/reward_max_pred": 0.191624680602992, "train/reward_neg_acc": 0.9998234714622851, "train/reward_neg_loss": 0.009509763497152124, "train/reward_pos_acc": 0.3173289190459725, "train/reward_pos_loss": 3.548608333563173, "train/reward_pred": 0.0007539543962425172, "train/reward_rate": 0.0011302806712962963, "train_stats/mean_log_entropy": 0.08178778235679088, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.016705350950360298, "report/cont_loss_std": 0.2681254744529724, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.9171230792999268, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0024736663326621056, "report/cont_pred": 0.9955953359603882, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1015687808394432, "report/image_loss_std": 0.1230531558394432, "report/model_loss_mean": 0.7268085479736328, "report/model_loss_std": 0.3005574345588684, "report/post_ent_mag": 33.62570571899414, "report/post_ent_max": 33.62570571899414, "report/post_ent_mean": 33.347686767578125, "report/post_ent_min": 33.069053649902344, "report/post_ent_std": 0.11364760994911194, "report/prior_ent_mag": 33.39373779296875, "report/prior_ent_max": 33.39373779296875, "report/prior_ent_mean": 32.737510681152344, "report/prior_ent_min": 31.596454620361328, "report/prior_ent_std": 0.27483201026916504, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001680642453720793, "report/reward_loss_mean": 0.008534422144293785, "report/reward_loss_std": 0.014602349139750004, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.08663046360015869, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008534422144293785, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0007328923093155026, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03303183242678642, "eval/cont_loss_std": 0.5964601635932922, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.243413925170898, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003030714811757207, "eval/cont_pred": 0.997096061706543, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23931768536567688, "eval/image_loss_std": 0.16067823767662048, "eval/model_loss_mean": 0.8882697820663452, "eval/model_loss_std": 0.9885534644126892, "eval/post_ent_mag": 33.62422561645508, "eval/post_ent_max": 33.62422561645508, "eval/post_ent_mean": 33.336769104003906, "eval/post_ent_min": 33.05760955810547, "eval/post_ent_std": 0.11834008991718292, "eval/prior_ent_mag": 33.39373779296875, "eval/prior_ent_max": 33.39373779296875, "eval/prior_ent_mean": 32.69841384887695, "eval/prior_ent_min": 31.665313720703125, "eval/prior_ent_std": 0.2842719852924347, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007293701055459678, "eval/reward_loss_mean": 0.015920238569378853, "eval/reward_loss_std": 0.4578840434551239, "eval/reward_max_data": 0.746874988079071, "eval/reward_max_pred": 0.04501187801361084, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0016052774153649807, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 14.660124778747559, "eval/reward_pred": 0.00048720790073275566, "eval/reward_rate": 0.0009765625, "replay/size": 328305.0, "replay/inserts": 8648.0, "replay/samples": 34592.0, "replay/insert_wait_avg": 1.5191465037272663e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.671134324122313e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 75960.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3946409225464, "timer/env.step_count": 1081.0, "timer/env.step_total": 10.283865451812744, "timer/env.step_frac": 0.010279808618655878, "timer/env.step_avg": 0.009513289039604758, "timer/env.step_min": 0.008333206176757812, "timer/env.step_max": 0.05446028709411621, "timer/replay._sample_count": 34592.0, "timer/replay._sample_total": 16.680127143859863, "timer/replay._sample_frac": 0.016673547079858148, "timer/replay._sample_avg": 0.0004821960899589461, "timer/replay._sample_min": 0.0003311634063720703, "timer/replay._sample_max": 0.03316688537597656, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1081.0, "timer/agent.policy_total": 10.738134145736694, "timer/agent.policy_frac": 0.010733898110283933, "timer/agent.policy_avg": 0.009933519098738847, "timer/agent.policy_min": 0.008852958679199219, "timer/agent.policy_max": 0.03665280342102051, "timer/dataset_train_count": 2162.0, "timer/dataset_train_total": 0.38428664207458496, "timer/dataset_train_frac": 0.00038413504666538653, "timer/dataset_train_avg": 0.00017774590290221321, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0008473396301269531, "timer/agent.train_count": 2162.0, "timer/agent.train_total": 966.8660356998444, "timer/agent.train_frac": 0.9664846213172609, "timer/agent.train_avg": 0.44720908219234246, "timer/agent.train_min": 0.43662190437316895, "timer/agent.train_max": 0.5966649055480957, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4771707057952881, "timer/agent.report_frac": 0.000476982468993686, "timer/agent.report_avg": 0.23858535289764404, "timer/agent.report_min": 0.23347997665405273, "timer/agent.report_max": 0.24369072914123535, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.050553939079204e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 8.644464571318899}
{"step": 328896, "time": 38228.30967068672, "episode/length": 288.0, "episode/score": 0.06151922102867502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06151922102867502}
{"step": 329376, "time": 38283.36053800583, "episode/length": 87.0, "episode/score": 0.7498479872954249, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.021723011952190063}
{"step": 329400, "time": 38286.15881562233, "episode/length": 288.0, "episode/score": 0.09703446867649745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09703446867649745}
{"step": 329736, "time": 38324.734679698944, "episode/length": 247.0, "episode/score": 0.3008846080708736, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.07275960327456232}
{"step": 329960, "time": 38350.43383049965, "episode/length": 217.0, "episode/score": 0.3914845765557402, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.06960957175942895}
{"step": 330064, "time": 38362.335079193115, "episode/length": 288.0, "episode/score": 0.09278741067078045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09278741067078045}
{"step": 330096, "time": 38366.4537525177, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 330096, "time": 38367.12248015404, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 330096, "time": 38368.608848810196, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 330096, "time": 38371.67774248123, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 38371.68624019623, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 38371.69257521629, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 38371.69881606102, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 38371.70494389534, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330576, "time": 38426.743691921234, "episode/length": 76.0, "episode/score": 0.7784811902417914, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.015981202977627618}
{"step": 330680, "time": 38438.79214715958, "episode/length": 258.0, "episode/score": 0.26128638611294264, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.06753639288831437}
{"step": 330800, "time": 38452.53401660919, "episode/length": 177.0, "episode/score": 0.4956885516639886, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.04881353138443956}
{"step": 330904, "time": 38464.449211359024, "episode/length": 288.0, "episode/score": 0.08330298102566758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08330298102566758}
{"step": 331208, "time": 38499.39732456207, "episode/length": 288.0, "episode/score": 0.03596642190018429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03596642190018429}
{"step": 331712, "time": 38557.431470394135, "episode/length": 288.0, "episode/score": 0.06655631697083209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06655631697083209}
{"step": 331752, "time": 38562.01244020462, "episode/length": 118.0, "episode/score": 0.6673431784453214, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.03609315541837077}
{"step": 332048, "time": 38596.0777323246, "episode/length": 288.0, "episode/score": 0.060695352832453864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060695352832453864}
{"step": 332376, "time": 38633.67117905617, "episode/length": 288.0, "episode/score": 0.021821188570925187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021821188570925187}
{"step": 332424, "time": 38639.16617226601, "episode/length": 83.0, "episode/score": 0.7745325008460213, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.033907453662891385}
{"step": 332888, "time": 38692.27188587189, "episode/length": 288.0, "episode/score": 0.052042762558187405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052042762558187405}
{"step": 332992, "time": 38704.357147693634, "episode/length": 288.0, "episode/score": 0.0223975481306411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0223975481306411}
{"step": 333216, "time": 38730.08206987381, "episode/length": 288.0, "episode/score": 0.059845940743969095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059845940743969095}
{"step": 333456, "time": 38757.58497095108, "episode/length": 57.0, "episode/score": 0.8402528008473951, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.01837781037016839}
{"step": 333520, "time": 38764.98457980156, "episode/length": 288.0, "episode/score": 0.049563166605310016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049563166605310016}
{"step": 333536, "time": 38766.808163166046, "episode/length": 39.0, "episode/score": 0.8892929636348299, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.011167922319032186}
{"step": 333776, "time": 38794.24490022659, "episode/length": 39.0, "episode/score": 0.8925896701215947, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.014464634859393755}
{"step": 334016, "time": 38821.87945461273, "episode/length": 29.0, "episode/score": 0.9224949284770219, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.013119887161224142}
{"step": 334024, "time": 38822.794429302216, "episode/length": 288.0, "episode/score": 0.03680267466523901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03680267466523901}
{"step": 334056, "time": 38826.44161581993, "episode/length": 203.0, "episode/score": 0.3992315919612679, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.033606598329186}
{"step": 334360, "time": 38861.26697683334, "episode/length": 288.0, "episode/score": 0.049218721506804286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049218721506804286}
{"step": 334416, "time": 38867.67576980591, "episode/length": 190.0, "episode/score": 0.4501031135812923, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.04385310540311593}
{"step": 334520, "time": 38879.568375349045, "episode/length": 57.0, "episode/score": 0.8394610430071907, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.017586043507776594}
{"step": 334640, "time": 38893.37343287468, "episode/length": 77.0, "episode/score": 0.7839598808176333, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.024584897499948966}
{"step": 334640, "time": 38893.379999399185, "episode/length": 27.0, "episode/score": 0.9278518187563236, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.012226834420005162}
{"step": 334688, "time": 38898.8769299984, "episode/length": 288.0, "episode/score": 0.039518686772510137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039518686772510137}
{"step": 335024, "time": 38937.279124975204, "episode/length": 62.0, "episode/score": 0.8278056882965075, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.021555730270051754}
{"step": 335280, "time": 38966.577278375626, "episode/length": 31.0, "episode/score": 0.9139959034752678, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.010870908236654486}
{"step": 335568, "time": 38999.544821977615, "episode/length": 192.0, "episode/score": 0.4401505219129831, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.040150504281882604}
{"step": 335600, "time": 39003.34107017517, "episode/length": 39.0, "episode/score": 0.8888757568709593, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.010750760054918373}
{"step": 335776, "time": 39023.56215381622, "episode/length": 281.0, "episode/score": 0.1952729082179303, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0733979056451517}
{"step": 335848, "time": 39031.89342236519, "episode/length": 288.0, "episode/score": 0.052972738510959516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052972738510959516}
{"step": 336056, "time": 39055.95699262619, "episode/length": 211.0, "episode/score": 0.3941935001826664, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.053568497406160986}
{"step": 336464, "time": 39102.656692028046, "episode/length": 85.0, "episode/score": 0.7517323948105172, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.017357386632340877}
{"step": 336920, "time": 39154.91732740402, "episode/length": 164.0, "episode/score": 0.5224672569780751, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.034967245872053354}
{"step": 336952, "time": 39158.571442604065, "episode/length": 288.0, "episode/score": 0.03171320493430585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03171320493430585}
{"step": 336952, "time": 39158.57866835594, "episode/length": 288.0, "episode/score": 0.07799778662553081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07799778662553081}
{"step": 337000, "time": 39164.09217596054, "episode/length": 288.0, "episode/score": 0.05859113362981816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05859113362981816}
{"step": 337160, "time": 39182.43919157982, "episode/length": 137.0, "episode/score": 0.5983005617595722, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.026425556963260988}
{"step": 337408, "time": 39210.76617145538, "episode/length": 56.0, "episode/score": 0.8378573779923499, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.012857390728186147}
{"step": 337424, "time": 39212.6185529232, "episode/length": 231.0, "episode/score": 0.30889150670856225, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.030766504310406617}
{"step": 337469, "time": 39218.62708425522, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.606636329933449, "train/action_min": 0.0, "train/action_std": 1.6493838981345847, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007686513692735591, "train/actor_opt_grad_steps": 82895.0, "train/actor_opt_loss": -17.066326083960355, "train/adv_mag": 0.47154514491558075, "train/adv_max": 0.23006695370983193, "train/adv_mean": 0.0012214979560183194, "train/adv_min": -0.44269326687962923, "train/adv_std": 0.020863310903897165, "train/cont_avg": 0.9959083839699074, "train/cont_loss_mean": 0.011798068176614362, "train/cont_loss_std": 0.1925007371012018, "train/cont_neg_acc": 0.4321244072775508, "train/cont_neg_loss": 2.3219383413002888, "train/cont_pos_acc": 0.9999046093887753, "train/cont_pos_loss": 0.002330370041211912, "train/cont_pred": 0.9959509836302863, "train/cont_rate": 0.9959083839699074, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11697004507813188, "train/extr_critic_critic_opt_grad_steps": 82895.0, "train/extr_critic_critic_opt_loss": 7057.987139666522, "train/extr_critic_mag": 0.7826035519440969, "train/extr_critic_max": 0.7826035519440969, "train/extr_critic_mean": 0.6226957153390955, "train/extr_critic_min": 0.5141307065884272, "train/extr_critic_std": 0.0355640382040292, "train/extr_return_normed_mag": 0.48876494610751114, "train/extr_return_normed_max": 0.32699176531147073, "train/extr_return_normed_mean": 0.044215235945389224, "train/extr_return_normed_min": -0.4000155920231784, "train/extr_return_normed_std": 0.041798700440537045, "train/extr_return_rate": 0.9989282334292376, "train/extr_return_raw_mag": 0.9066937022187092, "train/extr_return_raw_max": 0.9066937022187092, "train/extr_return_raw_mean": 0.6239172021547953, "train/extr_return_raw_min": 0.17968634488406005, "train/extr_return_raw_std": 0.041798700449160404, "train/extr_reward_mag": 0.3759286751349767, "train/extr_reward_max": 0.3759286751349767, "train/extr_reward_mean": 0.0009072114998060796, "train/extr_reward_min": 1.3482791406136972e-06, "train/extr_reward_std": 0.007607903086830414, "train/image_loss_mean": 0.08507363967321536, "train/image_loss_std": 0.1060844121362876, "train/model_loss_mean": 0.7106920571790801, "train/model_loss_std": 0.31867857632675656, "train/model_opt_grad_norm": 14.766893678241306, "train/model_opt_grad_steps": 82820.9074074074, "train/model_opt_loss": 3685.721120198568, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5185.185185185185, "train/policy_entropy_mag": 1.3462417092588213, "train/policy_entropy_max": 1.3462417092588213, "train/policy_entropy_mean": 0.10456708687599059, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13337244528035322, "train/policy_logprob_mag": 6.551080262219465, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10425849538296461, "train/policy_logprob_min": -6.551080262219465, "train/policy_logprob_std": 0.6407235468979235, "train/policy_randomness_mag": 0.6918314253842389, "train/policy_randomness_max": 0.6918314253842389, "train/policy_randomness_mean": 0.053736855155201976, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06853988266515511, "train/post_ent_mag": 33.57008151654844, "train/post_ent_max": 33.57008151654844, "train/post_ent_mean": 33.29742458131578, "train/post_ent_min": 33.03271503801699, "train/post_ent_std": 0.11042679359929429, "train/prior_ent_mag": 33.462834746749316, "train/prior_ent_max": 33.462834746749316, "train/prior_ent_mean": 32.80645338694254, "train/prior_ent_min": 31.800964911778767, "train/prior_ent_std": 0.27839284762740135, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0008271026315048437, "train/reward_loss_mean": 0.013820327005642294, "train/reward_loss_std": 0.11981380163450484, "train/reward_max_data": 0.44685201473637587, "train/reward_max_pred": 0.1524932743222625, "train/reward_neg_acc": 0.9998415645073961, "train/reward_neg_loss": 0.009491118865467055, "train/reward_pos_acc": 0.24843750111758708, "train/reward_pos_loss": 3.919153421372175, "train/reward_pred": 0.0007318395569368645, "train/reward_rate": 0.0011348017939814814, "train_stats/mean_log_entropy": 0.07743374781405672, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.003147624898701906, "report/cont_loss_std": 0.031587764620780945, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.06196758896112442, "report/cont_pos_acc": 0.9990224838256836, "report/cont_pos_loss": 0.003090127371251583, "report/cont_pred": 0.9964123964309692, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08684074878692627, "report/image_loss_std": 0.10896392911672592, "report/model_loss_mean": 0.6985384225845337, "report/model_loss_std": 0.11670245230197906, "report/post_ent_mag": 33.307762145996094, "report/post_ent_max": 33.307762145996094, "report/post_ent_mean": 33.03169250488281, "report/post_ent_min": 32.75580596923828, "report/post_ent_std": 0.10492106527090073, "report/prior_ent_mag": 33.58916091918945, "report/prior_ent_max": 33.58916091918945, "report/prior_ent_mean": 32.883209228515625, "report/prior_ent_min": 32.00428771972656, "report/prior_ent_std": 0.2838009297847748, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00018416209786664695, "report/reward_loss_mean": 0.008550005033612251, "report/reward_loss_std": 0.011884626001119614, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.018275976181030273, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008550004102289677, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0003798736725002527, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.030554715543985367, "eval/cont_loss_std": 0.5788816809654236, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.724303245544434, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0020716136787086725, "eval/cont_pred": 0.9979901313781738, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18598321080207825, "eval/image_loss_std": 0.16512201726436615, "eval/model_loss_mean": 0.8225970268249512, "eval/model_loss_std": 0.644662618637085, "eval/post_ent_mag": 33.32025146484375, "eval/post_ent_max": 33.32025146484375, "eval/post_ent_mean": 33.03204345703125, "eval/post_ent_min": 32.72770690917969, "eval/post_ent_std": 0.11717013269662857, "eval/prior_ent_mag": 33.58916091918945, "eval/prior_ent_max": 33.58916091918945, "eval/prior_ent_mean": 32.91969299316406, "eval/prior_ent_min": 31.978878021240234, "eval/prior_ent_std": 0.2744649648666382, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0004211425839457661, "eval/reward_loss_mean": 0.006059099454432726, "eval/reward_loss_std": 0.13572393357753754, "eval/reward_max_data": 0.4312500059604645, "eval/reward_max_pred": 0.035106778144836426, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001817104290239513, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.345620155334473, "eval/reward_pred": 0.0005301786586642265, "eval/reward_rate": 0.0009765625, "replay/size": 336965.0, "replay/inserts": 8660.0, "replay/samples": 34640.0, "replay/insert_wait_avg": 1.503743971192534e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.758514985751885e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 78272.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1535251841825597e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2181236743927, "timer/env.step_count": 1082.0, "timer/env.step_total": 10.212528705596924, "timer/env.step_frac": 0.010210301597095907, "timer/env.step_avg": 0.00943856627134651, "timer/env.step_min": 0.00843954086303711, "timer/env.step_max": 0.03484463691711426, "timer/replay._sample_count": 34640.0, "timer/replay._sample_total": 16.7431743144989, "timer/replay._sample_frac": 0.0167395230282284, "timer/replay._sample_avg": 0.0004833479882938482, "timer/replay._sample_min": 0.00037479400634765625, "timer/replay._sample_max": 0.028528690338134766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1371.0, "timer/agent.policy_total": 13.575008630752563, "timer/agent.policy_frac": 0.013572048245720171, "timer/agent.policy_avg": 0.009901538023889543, "timer/agent.policy_min": 0.008904695510864258, "timer/agent.policy_max": 0.04180598258972168, "timer/dataset_train_count": 2165.0, "timer/dataset_train_total": 0.3853437900543213, "timer/dataset_train_frac": 0.00038525975578079476, "timer/dataset_train_avg": 0.00017798789378952484, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.005338907241821289, "timer/agent.train_count": 2165.0, "timer/agent.train_total": 961.1788349151611, "timer/agent.train_frac": 0.9609692247768745, "timer/agent.train_avg": 0.44396251035342316, "timer/agent.train_min": 0.4308149814605713, "timer/agent.train_max": 0.5755095481872559, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.473097562789917, "timer/agent.report_frac": 0.00047299439151527253, "timer/agent.report_avg": 0.2365487813949585, "timer/agent.report_min": 0.23090815544128418, "timer/agent.report_max": 0.2421894073486328, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9080723456136376e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 8.657979408336262}
{"step": 337680, "time": 39242.83585214615, "episode/length": 84.0, "episode/score": 0.7701139801019963, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.03261393954289815}
{"step": 338160, "time": 39298.0463681221, "episode/length": 288.0, "episode/score": 0.03642598942190034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03642598942190034}
{"step": 338776, "time": 39368.85729980469, "episode/length": 288.0, "episode/score": 0.06654340663953917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06654340663953917}
{"step": 338920, "time": 39385.66502523422, "episode/length": 94.0, "episode/score": 0.7310592371056828, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.024809201843481787}
{"step": 339232, "time": 39421.94361162186, "episode/length": 288.0, "episode/score": 0.06878670539913401, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06878670539913401}
{"step": 339264, "time": 39425.63371992111, "episode/length": 288.0, "episode/score": 0.0435275565887423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0435275565887423}
{"step": 339416, "time": 39443.061398506165, "episode/length": 79.0, "episode/score": 0.7681922271286794, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.01506718581288169}
{"step": 339472, "time": 39449.49459147453, "episode/length": 288.0, "episode/score": 0.0830271563477254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0830271563477254}
{"step": 339632, "time": 39468.00980591774, "episode/length": 88.0, "episode/score": 0.7445237655957726, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.01952371235904593}
{"step": 339720, "time": 39478.14844942093, "episode/length": 288.0, "episode/score": 0.05401310606794141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05401310606794141}
{"step": 339736, "time": 39479.983801841736, "episode/length": 288.0, "episode/score": 0.06768165509879509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06768165509879509}
{"step": 339936, "time": 39503.04523015022, "episode/length": 281.0, "episode/score": 0.16290759152434475, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.04103258781651675}
{"step": 340064, "time": 39517.85128378868, "episode/length": 73.0, "episode/score": 0.779058358206953, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0071833545049457825}
{"step": 340080, "time": 39521.2619304657, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 340080, "time": 39521.26651239395, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 340080, "time": 39521.79817557335, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 340080, "time": 39522.60889363289, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 340080, "time": 39522.919266700745, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 340080, "time": 39524.26198887825, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 340080, "time": 39524.65802526474, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 39524.66416788101, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 39524.66971492767, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 39524.675335645676, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340792, "time": 39606.66476035118, "episode/length": 106.0, "episode/score": 0.7049876122081287, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.036237642260743996}
{"step": 340872, "time": 39615.87757754326, "episode/length": 181.0, "episode/score": 0.47879973747046733, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.04442475020630354}
{"step": 340904, "time": 39619.55843091011, "episode/length": 158.0, "episode/score": 0.5609571401980702, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.054707117171119535}
{"step": 341280, "time": 39663.322731256485, "episode/length": 46.0, "episode/score": 0.8693062101567648, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.013056207758609162}
{"step": 341544, "time": 39693.76797270775, "episode/length": 288.0, "episode/score": 0.040199868106810754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040199868106810754}
{"step": 341576, "time": 39697.46603536606, "episode/length": 288.0, "episode/score": 0.06515292468941425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06515292468941425}
{"step": 341984, "time": 39744.61394548416, "episode/length": 87.0, "episode/score": 0.7457439739937399, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.017618998053876567}
{"step": 342016, "time": 39748.29122924805, "episode/length": 58.0, "episode/score": 0.8329361945048959, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.01418618879472433}
{"step": 342032, "time": 39750.13685679436, "episode/length": 288.0, "episode/score": 0.0544473738316924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0544473738316924}
{"step": 342048, "time": 39752.07907342911, "episode/length": 288.0, "episode/score": 0.04852685748494423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04852685748494423}
{"step": 342160, "time": 39764.97187709808, "episode/length": 160.0, "episode/score": 0.535557455212313, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0355574783207544}
{"step": 342296, "time": 39780.56871366501, "episode/length": 34.0, "episode/score": 0.9025074520930616, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.008757431993956288}
{"step": 342376, "time": 39789.83307552338, "episode/length": 288.0, "episode/score": 0.037215738572342616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037215738572342616}
{"step": 342680, "time": 39824.80636835098, "episode/length": 78.0, "episode/score": 0.7826697826260443, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.02641972938931758}
{"step": 342984, "time": 39859.91061735153, "episode/length": 85.0, "episode/score": 0.7671326725804306, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.032757692720281284}
{"step": 343104, "time": 39873.76378917694, "episode/length": 288.0, "episode/score": 0.06680792571444272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06680792571444272}
{"step": 343192, "time": 39883.89809513092, "episode/length": 128.0, "episode/score": 0.6153629395103621, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.015362935808354905}
{"step": 343888, "time": 39964.235226631165, "episode/length": 288.0, "episode/score": 0.047062114260882026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047062114260882026}
{"step": 344296, "time": 40011.70557165146, "episode/length": 288.0, "episode/score": 0.02086983218993055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02086983218993055}
{"step": 344344, "time": 40017.262434244156, "episode/length": 288.0, "episode/score": 0.025859551840881068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025859551840881068}
{"step": 344512, "time": 40036.58563017845, "episode/length": 228.0, "episode/score": 0.3111085268879492, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.023608526154532683}
{"step": 344688, "time": 40056.98631024361, "episode/length": 288.0, "episode/score": 0.023599521615153662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023599521615153662}
{"step": 344968, "time": 40089.165170907974, "episode/length": 56.0, "episode/score": 0.8425562539573548, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.01755628898672512}
{"step": 345096, "time": 40103.82642650604, "episode/length": 93.0, "episode/score": 0.736457316622591, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.02708229299901177}
{"step": 345144, "time": 40109.322030067444, "episode/length": 56.0, "episode/score": 0.8373247712544298, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.012324795253448428}
{"step": 345296, "time": 40126.84700393677, "episode/length": 288.0, "episode/score": 0.013406232443173849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013406232443173849}
{"step": 345416, "time": 40140.63811826706, "episode/length": 288.0, "episode/score": 0.02770622754735541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02770622754735541}
{"step": 345504, "time": 40150.79672050476, "episode/length": 288.0, "episode/score": 0.01963236702084714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01963236702084714}
{"step": 345688, "time": 40172.03905797005, "episode/length": 67.0, "episode/score": 0.8171734079217572, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.026548431981893827}
{"step": 346085, "time": 40218.63015508652, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5522432680483216, "train/action_min": 0.0, "train/action_std": 1.6415611720747418, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007901381482413315, "train/actor_opt_grad_steps": 85055.0, "train/actor_opt_loss": -19.63170255555047, "train/adv_mag": 0.46621360409039037, "train/adv_max": 0.24562335621427606, "train/adv_mean": 0.0012101893526892968, "train/adv_min": -0.42933151843371214, "train/adv_std": 0.024319988192507514, "train/cont_avg": 0.9958631727430556, "train/cont_loss_mean": 0.011576944214606623, "train/cont_loss_std": 0.18946012037297436, "train/cont_neg_acc": 0.459370335268083, "train/cont_neg_loss": 2.2028598963336994, "train/cont_pos_acc": 0.9999227962560124, "train/cont_pos_loss": 0.002304709696747725, "train/cont_pred": 0.9958738941285346, "train/cont_rate": 0.9958631727430556, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1485847771357469, "train/extr_critic_critic_opt_grad_steps": 85055.0, "train/extr_critic_critic_opt_loss": 8643.491084346066, "train/extr_critic_mag": 0.8444423057414867, "train/extr_critic_max": 0.8444423057414867, "train/extr_critic_mean": 0.6581469490020363, "train/extr_critic_min": 0.5427768969977343, "train/extr_critic_std": 0.04141727273559405, "train/extr_return_normed_mag": 0.5095776918309706, "train/extr_return_normed_max": 0.37148793869548374, "train/extr_return_normed_mean": 0.04701400346433123, "train/extr_return_normed_min": -0.3653157440324624, "train/extr_return_normed_std": 0.04926817225188845, "train/extr_return_rate": 0.9987901838289367, "train/extr_return_raw_mag": 0.9838310422168838, "train/extr_return_raw_max": 0.9838310422168838, "train/extr_return_raw_mean": 0.6593571399097089, "train/extr_return_raw_min": 0.2470273594889376, "train/extr_return_raw_std": 0.04926817241573223, "train/extr_reward_mag": 0.462985435017833, "train/extr_reward_max": 0.462985435017833, "train/extr_reward_mean": 0.0011563742299148107, "train/extr_reward_min": 1.5519283435962819e-06, "train/extr_reward_std": 0.010803605039621255, "train/image_loss_mean": 0.0864303533712195, "train/image_loss_std": 0.10746760511149962, "train/model_loss_mean": 0.7120140586738233, "train/model_loss_std": 0.31696708296874054, "train/model_opt_grad_norm": 14.208810888334762, "train/model_opt_grad_steps": 84978.85185185185, "train/model_opt_loss": 3737.639170328776, "train/model_opt_model_opt_grad_overflow": 0.004629629629629629, "train/model_opt_model_opt_grad_scale": 5231.481481481482, "train/policy_entropy_mag": 1.361217510369089, "train/policy_entropy_max": 1.361217510369089, "train/policy_entropy_mean": 0.10170449361343074, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13112974415222803, "train/policy_logprob_mag": 6.551080242351249, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10215748915517772, "train/policy_logprob_min": -6.551080242351249, "train/policy_logprob_std": 0.6418276970033292, "train/policy_randomness_mag": 0.6995274620475592, "train/policy_randomness_max": 0.6995274620475592, "train/policy_randomness_mean": 0.05226577318238991, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06738736214875071, "train/post_ent_mag": 33.55506596741853, "train/post_ent_max": 33.55506596741853, "train/post_ent_mean": 33.27767663531833, "train/post_ent_min": 33.007238917880585, "train/post_ent_std": 0.11382550363325411, "train/prior_ent_mag": 33.57158531966033, "train/prior_ent_max": 33.57158531966033, "train/prior_ent_mean": 32.93369404474894, "train/prior_ent_min": 31.89828070004781, "train/prior_ent_std": 0.27947138505125485, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0009757540282643513, "train/reward_loss_mean": 0.014006742045576512, "train/reward_loss_std": 0.11702003227374344, "train/reward_max_data": 0.4982587709759914, "train/reward_max_pred": 0.22453804038189076, "train/reward_neg_acc": 0.9998596790764067, "train/reward_neg_loss": 0.00950447946821374, "train/reward_pos_acc": 0.33209876660947446, "train/reward_pos_loss": 3.467958571182357, "train/reward_pred": 0.0008160866833619635, "train/reward_rate": 0.0012749565972222222, "train_stats/mean_log_entropy": 0.07860564671102024, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.006189730018377304, "report/cont_loss_std": 0.058027662336826324, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 0.6914212703704834, "report/cont_pos_acc": 0.9990215301513672, "report/cont_pos_loss": 0.0048487684689462185, "report/cont_pred": 0.9945619106292725, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08344977349042892, "report/image_loss_std": 0.09825952351093292, "report/model_loss_mean": 0.6989215016365051, "report/model_loss_std": 0.11572624742984772, "report/post_ent_mag": 33.40797424316406, "report/post_ent_max": 33.40797424316406, "report/post_ent_mean": 33.13949966430664, "report/post_ent_min": 32.872344970703125, "report/post_ent_std": 0.10492866486310959, "report/prior_ent_mag": 33.59576416015625, "report/prior_ent_max": 33.59576416015625, "report/prior_ent_mean": 32.91967010498047, "report/prior_ent_min": 32.04351043701172, "report/prior_ent_std": 0.2861974835395813, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001925246324390173, "report/reward_loss_mean": 0.00928197056055069, "report/reward_loss_std": 0.013981236144900322, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.03773856163024902, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00928197056055069, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0005705486983060837, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.05339362472295761, "eval/cont_loss_std": 0.7635861039161682, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.67480182647705, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0012768044834956527, "eval/cont_pred": 0.9987365007400513, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19533592462539673, "eval/image_loss_std": 0.15458674728870392, "eval/model_loss_mean": 0.8632792234420776, "eval/model_loss_std": 1.0367616415023804, "eval/post_ent_mag": 33.41154479980469, "eval/post_ent_max": 33.41154479980469, "eval/post_ent_mean": 33.12263488769531, "eval/post_ent_min": 32.87696838378906, "eval/post_ent_std": 0.11597087234258652, "eval/prior_ent_mag": 33.59576416015625, "eval/prior_ent_max": 33.59576416015625, "eval/prior_ent_mean": 32.90038299560547, "eval/prior_ent_min": 31.958436965942383, "eval/prior_ent_std": 0.2856568694114685, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0004760742303915322, "eval/reward_loss_mean": 0.014549636282026768, "eval/reward_loss_std": 0.41000524163246155, "eval/reward_max_data": 0.48750001192092896, "eval/reward_max_pred": 0.01235663890838623, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0017309216782450676, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 13.128095626831055, "eval/reward_pred": 0.0003818758996203542, "eval/reward_rate": 0.0009765625, "replay/size": 345581.0, "replay/inserts": 8616.0, "replay/samples": 34464.0, "replay/insert_wait_avg": 1.4876810178340533e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.733522794151483e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 80584.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0196725389949178e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9881978034973, "timer/env.step_count": 1077.0, "timer/env.step_total": 10.031729221343994, "timer/env.step_frac": 0.01003184761918088, "timer/env.step_avg": 0.009314511811832864, "timer/env.step_min": 0.008210420608520508, "timer/env.step_max": 0.034105539321899414, "timer/replay._sample_count": 34464.0, "timer/replay._sample_total": 16.497800827026367, "timer/replay._sample_frac": 0.016497995539611628, "timer/replay._sample_avg": 0.0004786966349531792, "timer/replay._sample_min": 0.0003533363342285156, "timer/replay._sample_max": 0.010519981384277344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1366.0, "timer/agent.policy_total": 13.29598593711853, "timer/agent.policy_frac": 0.013296142860809301, "timer/agent.policy_avg": 0.009733518255577256, "timer/agent.policy_min": 0.008701801300048828, "timer/agent.policy_max": 0.0362093448638916, "timer/dataset_train_count": 2154.0, "timer/dataset_train_total": 0.37923312187194824, "timer/dataset_train_frac": 0.0003792375977085976, "timer/dataset_train_avg": 0.00017605994515875034, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.0012280941009521484, "timer/agent.train_count": 2154.0, "timer/agent.train_total": 962.1328859329224, "timer/agent.train_frac": 0.9621442413483227, "timer/agent.train_avg": 0.44667264899392867, "timer/agent.train_min": 0.43515992164611816, "timer/agent.train_max": 0.5716507434844971, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47452211380004883, "timer/agent.report_frac": 0.0004745277142693786, "timer/agent.report_avg": 0.23726105690002441, "timer/agent.report_min": 0.2304065227508545, "timer/agent.report_max": 0.24411559104919434, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.980267412471164e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 8.615975446044324}
{"step": 346200, "time": 40231.70319318771, "episode/length": 288.0, "episode/score": 0.07777169363515668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07777169363515668}
{"step": 346608, "time": 40278.53034758568, "episode/length": 288.0, "episode/score": 0.019385323504309326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019385323504309326}
{"step": 346656, "time": 40284.07357978821, "episode/length": 169.0, "episode/score": 0.48275174088158224, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.010876720782476923}
{"step": 347064, "time": 40331.345992565155, "episode/length": 50.0, "episode/score": 0.854945822642776, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.011195837747663973}
{"step": 347280, "time": 40356.31961250305, "episode/length": 288.0, "episode/score": 0.04834050447570348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04834050447570348}
{"step": 347408, "time": 40371.074511766434, "episode/length": 288.0, "episode/score": 0.02101251771628654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02101251771628654}
{"step": 347728, "time": 40407.93384742737, "episode/length": 288.0, "episode/score": 0.04188084811644899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04188084811644899}
{"step": 347816, "time": 40418.234330654144, "episode/length": 288.0, "episode/score": 0.031001917959514458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031001917959514458}
{"step": 347920, "time": 40430.302278757095, "episode/length": 214.0, "episode/score": 0.36489976513846045, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.03364975967858186}
{"step": 347992, "time": 40438.57747530937, "episode/length": 32.0, "episode/score": 0.913793199781253, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.013793200281838836}
{"step": 348000, "time": 40439.5246989727, "episode/length": 288.0, "episode/score": 0.030655791031136914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030655791031136914}
{"step": 348192, "time": 40461.70982313156, "episode/length": 113.0, "episode/score": 0.659474419216906, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0125993659801793}
{"step": 348600, "time": 40508.55235028267, "episode/length": 74.0, "episode/score": 0.7793896256800963, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.010639584364298571}
{"step": 348648, "time": 40514.07868504524, "episode/length": 197.0, "episode/score": 0.4291085310077847, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.044733525454773826}
{"step": 348920, "time": 40545.36732053757, "episode/length": 288.0, "episode/score": 0.02106563348783652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02106563348783652}
{"step": 349720, "time": 40637.24225854874, "episode/length": 288.0, "episode/score": 0.04630542352339262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04630542352339262}
{"step": 350056, "time": 40675.83488821983, "episode/length": 141.0, "episode/score": 0.5748490416717686, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.015474030251425575}
{"step": 350064, "time": 40679.367879629135, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 350064, "time": 40679.57597064972, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 350064, "time": 40679.89280319214, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 350064, "time": 40681.15441775322, "eval_episode/length": 222.0, "eval_episode/score": 0.3062500059604645, "eval_episode/reward_rate": 0.004484304932735426}
{"step": 350064, "time": 40682.28904724121, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 350064, "time": 40682.31126451492, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 40682.316764354706, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 40682.32210469246, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 40682.32728385925, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350128, "time": 40689.694365262985, "episode/length": 288.0, "episode/score": 0.04383038865717026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04383038865717026}
{"step": 350232, "time": 40701.645176410675, "episode/length": 288.0, "episode/score": 0.03924867670457388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03924867670457388}
{"step": 350304, "time": 40709.94761252403, "episode/length": 288.0, "episode/score": 0.044173776165052914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044173776165052914}
{"step": 350504, "time": 40733.03239655495, "episode/length": 288.0, "episode/score": 0.025619255620085823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025619255620085823}
{"step": 350912, "time": 40780.08197927475, "episode/length": 288.0, "episode/score": 0.02670937596985823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02670937596985823}
{"step": 350960, "time": 40785.63517451286, "episode/length": 288.0, "episode/score": 0.03414300682220528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03414300682220528}
{"step": 351112, "time": 40803.12503862381, "episode/length": 131.0, "episode/score": 0.621529124611925, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.03090412221376937}
{"step": 351344, "time": 40829.71204996109, "episode/length": 138.0, "episode/score": 0.5881433413426294, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.019393309322595087}
{"step": 351728, "time": 40873.80286550522, "episode/length": 47.0, "episode/score": 0.8679940768624874, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.014869077363073302}
{"step": 351920, "time": 40895.88589549065, "episode/length": 176.0, "episode/score": 0.4876805785917213, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.037680590920103896}
{"step": 352032, "time": 40908.73562288284, "episode/length": 288.0, "episode/score": 0.039796375033233744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039796375033233744}
{"step": 352376, "time": 40948.73074889183, "episode/length": 182.0, "episode/score": 0.4558519938157133, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.02460197967707245}
{"step": 352384, "time": 40949.65419101715, "episode/length": 281.0, "episode/score": 0.16342487132669703, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0415498689285414}
{"step": 352616, "time": 40976.38856077194, "episode/length": 288.0, "episode/score": 0.04425087188951693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04425087188951693}
{"step": 353120, "time": 41034.44212079048, "episode/length": 149.0, "episode/score": 0.5496048235203261, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.015229831739247857}
{"step": 353272, "time": 41052.22532701492, "episode/length": 288.0, "episode/score": 0.021722741255757683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021722741255757683}
{"step": 353344, "time": 41060.5498650074, "episode/length": 120.0, "episode/score": 0.6510300719880888, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.02603004259322006}
{"step": 353424, "time": 41069.79486489296, "episode/length": 288.0, "episode/score": 0.04676676896940535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04676676896940535}
{"step": 353824, "time": 41116.00459885597, "episode/length": 150.0, "episode/score": 0.5457276620246603, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.014477647705575691}
{"step": 354040, "time": 41140.8534181118, "episode/length": 288.0, "episode/score": 0.022006036364871306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022006036364871306}
{"step": 354168, "time": 41155.49887800217, "episode/length": 92.0, "episode/score": 0.7483266132379072, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.03582660768489632}
{"step": 354344, "time": 41175.66063427925, "episode/length": 288.0, "episode/score": 0.03696631770310432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03696631770310432}
{"step": 354696, "time": 41216.02228307724, "episode/length": 288.0, "episode/score": 0.06122632366572134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06122632366572134}
{"step": 354713, "time": 41218.84620332718, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.745736339480378, "train/action_min": 0.0, "train/action_std": 1.5688225363576136, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010893641044060851, "train/actor_opt_grad_steps": 87210.0, "train/actor_opt_loss": -21.022774736271348, "train/adv_mag": 0.5491879992706831, "train/adv_max": 0.32436901913132776, "train/adv_mean": 0.002513010942121307, "train/adv_min": -0.4968800731869631, "train/adv_std": 0.028281755801723447, "train/cont_avg": 0.9959120639534884, "train/cont_loss_mean": 0.01181055412053802, "train/cont_loss_std": 0.18890755188456454, "train/cont_neg_acc": 0.42286011618431485, "train/cont_neg_loss": 2.31167054100715, "train/cont_pos_acc": 0.9999406648236652, "train/cont_pos_loss": 0.002435605795674979, "train/cont_pred": 0.9958875570186349, "train/cont_rate": 0.9959120639534884, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17544375008275342, "train/extr_critic_critic_opt_grad_steps": 87210.0, "train/extr_critic_critic_opt_loss": 11206.418563771802, "train/extr_critic_mag": 0.9698869865994121, "train/extr_critic_max": 0.9698869865994121, "train/extr_critic_mean": 0.7675540081290312, "train/extr_critic_min": 0.6031893846600554, "train/extr_critic_std": 0.04286575794739779, "train/extr_return_normed_mag": 0.6092528467954591, "train/extr_return_normed_max": 0.4687002883401028, "train/extr_return_normed_mean": 0.06085360894889333, "train/extr_return_normed_min": -0.43559923781905063, "train/extr_return_normed_std": 0.051952817126415494, "train/extr_return_rate": 0.9992039486419323, "train/extr_return_raw_mag": 1.1779136211373085, "train/extr_return_raw_max": 1.1779136211373085, "train/extr_return_raw_mean": 0.7700669793195503, "train/extr_return_raw_min": 0.2736140949781551, "train/extr_return_raw_std": 0.05195281716973282, "train/extr_reward_mag": 0.5123791944148929, "train/extr_reward_max": 0.5123791944148929, "train/extr_reward_mean": 0.0009959006334146008, "train/extr_reward_min": 1.4449274817178416e-06, "train/extr_reward_std": 0.010319779989807758, "train/image_loss_mean": 0.08697290550484214, "train/image_loss_std": 0.10746077947145284, "train/model_loss_mean": 0.7136194567347682, "train/model_loss_std": 0.33252892064493755, "train/model_opt_grad_norm": 14.229051297209983, "train/model_opt_grad_steps": 87131.81395348837, "train/model_opt_loss": 3733.0857319676597, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5232.558139534884, "train/policy_entropy_mag": 1.3785755029944486, "train/policy_entropy_max": 1.3785755029944486, "train/policy_entropy_mean": 0.10504684968050136, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.137430070444595, "train/policy_logprob_mag": 6.551080244640971, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10537936680538709, "train/policy_logprob_min": -6.551080244640971, "train/policy_logprob_std": 0.6446971366571825, "train/policy_randomness_mag": 0.708447704481524, "train/policy_randomness_max": 0.708447704481524, "train/policy_randomness_mean": 0.053983405353718025, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07062508916092473, "train/post_ent_mag": 33.732623645871186, "train/post_ent_max": 33.732623645871186, "train/post_ent_mean": 33.46544292361237, "train/post_ent_min": 33.20814980795217, "train/post_ent_std": 0.10841565617295199, "train/prior_ent_mag": 33.58246105105378, "train/prior_ent_max": 33.58246105105378, "train/prior_ent_mean": 32.95459420847338, "train/prior_ent_min": 31.9713946142862, "train/prior_ent_std": 0.2693598257247792, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0010006263762100621, "train/reward_loss_mean": 0.014835973601615014, "train/reward_loss_std": 0.13211433194404423, "train/reward_max_data": 0.5098784478218836, "train/reward_max_pred": 0.18613088463628014, "train/reward_neg_acc": 0.9998044912205186, "train/reward_neg_loss": 0.009664575526014317, "train/reward_pos_acc": 0.22721519066563137, "train/reward_pos_loss": 4.049988073827345, "train/reward_pred": 0.0007919901873656484, "train/reward_rate": 0.0012718023255813954, "train_stats/mean_log_entropy": 0.0806928949430585, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.014569301158189774, "report/cont_loss_std": 0.22224505245685577, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 2.3956217765808105, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0028860210441052914, "report/cont_pred": 0.9956001043319702, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10281920433044434, "report/image_loss_std": 0.10329379141330719, "report/model_loss_mean": 0.7358711957931519, "report/model_loss_std": 0.36306414008140564, "report/post_ent_mag": 33.55265808105469, "report/post_ent_max": 33.55265808105469, "report/post_ent_mean": 33.30813217163086, "report/post_ent_min": 33.033023834228516, "report/post_ent_std": 0.10439147800207138, "report/prior_ent_mag": 33.62767791748047, "report/prior_ent_max": 33.62767791748047, "report/prior_ent_mean": 32.981910705566406, "report/prior_ent_min": 32.13292694091797, "report/prior_ent_std": 0.24944841861724854, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002395953517407179, "report/reward_loss_mean": 0.018482645973563194, "report/reward_loss_std": 0.1502501666545868, "report/reward_max_data": 0.9223750233650208, "report/reward_max_pred": 0.4074758291244507, "report/reward_neg_acc": 0.999020516872406, "report/reward_neg_loss": 0.01198494154959917, "report/reward_pos_acc": 0.6666666865348816, "report/reward_pos_loss": 2.2298686504364014, "report/reward_pred": 0.0016659765969961882, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0196120273321867, "eval/cont_loss_std": 0.3484342694282532, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.922405242919922, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0022678738459944725, "eval/cont_pred": 0.997719407081604, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22830840945243835, "eval/image_loss_std": 0.14432939887046814, "eval/model_loss_mean": 0.85469651222229, "eval/model_loss_std": 0.44587767124176025, "eval/post_ent_mag": 33.548927307128906, "eval/post_ent_max": 33.548927307128906, "eval/post_ent_mean": 33.294891357421875, "eval/post_ent_min": 33.045963287353516, "eval/post_ent_std": 0.1025845855474472, "eval/prior_ent_mag": 33.63235855102539, "eval/prior_ent_max": 33.63235855102539, "eval/prior_ent_mean": 32.97594451904297, "eval/prior_ent_min": 32.210235595703125, "eval/prior_ent_std": 0.2427743524312973, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006042480235919356, "eval/reward_loss_mean": 0.006776036228984594, "eval/reward_loss_std": 0.15325698256492615, "eval/reward_max_data": 0.6187499761581421, "eval/reward_max_pred": 0.05634129047393799, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0019885068759322166, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.904418468475342, "eval/reward_pred": 0.000544524984434247, "eval/reward_rate": 0.0009765625, "replay/size": 354209.0, "replay/inserts": 8628.0, "replay/samples": 34512.0, "replay/insert_wait_avg": 1.4822959457772387e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.616586579069474e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 82896.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0289535390464493e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1919364929199, "timer/env.step_count": 1079.0, "timer/env.step_total": 9.992679357528687, "timer/env.step_frac": 0.009990761765753768, "timer/env.step_avg": 0.009261055938395447, "timer/env.step_min": 0.008132696151733398, "timer/env.step_max": 0.021558046340942383, "timer/replay._sample_count": 34512.0, "timer/replay._sample_total": 16.446711778640747, "timer/replay._sample_frac": 0.016443555660236187, "timer/replay._sample_avg": 0.0004765505267339113, "timer/replay._sample_min": 0.00035572052001953125, "timer/replay._sample_max": 0.02764439582824707, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1368.0, "timer/agent.policy_total": 13.641685247421265, "timer/agent.policy_frac": 0.013639067412655382, "timer/agent.policy_avg": 0.009971992139927825, "timer/agent.policy_min": 0.008538246154785156, "timer/agent.policy_max": 0.07722926139831543, "timer/dataset_train_count": 2157.0, "timer/dataset_train_total": 0.37993669509887695, "timer/dataset_train_frac": 0.00037986378537612457, "timer/dataset_train_avg": 0.00017614125873846869, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0046651363372802734, "timer/agent.train_count": 2157.0, "timer/agent.train_total": 961.8926069736481, "timer/agent.train_frac": 0.9617080201090554, "timer/agent.train_avg": 0.44594001250516835, "timer/agent.train_min": 0.43378210067749023, "timer/agent.train_max": 0.572206974029541, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47464418411254883, "timer/agent.report_frac": 0.00047455310005482, "timer/agent.report_avg": 0.23732209205627441, "timer/agent.report_min": 0.23085951805114746, "timer/agent.report_max": 0.24378466606140137, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9558230505493606e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 8.62622657924035}
{"step": 355320, "time": 41288.525572776794, "episode/length": 246.0, "episode/score": 0.30601794330482335, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.07476794678564147}
{"step": 355432, "time": 41301.32690358162, "episode/length": 288.0, "episode/score": 0.04199257877922946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04199257877922946}
{"step": 355512, "time": 41310.49021434784, "episode/length": 23.0, "episode/score": 0.9412585540117675, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.01313350077504083}
{"step": 355584, "time": 41318.80977463722, "episode/length": 288.0, "episode/score": 0.03486260896124804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03486260896124804}
{"step": 355840, "time": 41348.09059548378, "episode/length": 50.0, "episode/score": 0.8662981909920973, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0225481615972285}
{"step": 356056, "time": 41372.85990476608, "episode/length": 58.0, "episode/score": 0.8407172363074551, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.021967204287420827}
{"step": 356136, "time": 41382.02339196205, "episode/length": 288.0, "episode/score": 0.04321304226431266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04321304226431266}
{"step": 356160, "time": 41384.78400039673, "episode/length": 248.0, "episode/score": 0.2858475383011978, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.060847544669115905}
{"step": 356352, "time": 41406.78695607185, "episode/length": 288.0, "episode/score": 0.049534405700455864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049534405700455864}
{"step": 356432, "time": 41415.940415382385, "episode/length": 114.0, "episode/score": 0.687120253481396, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.043370233382290735}
{"step": 356656, "time": 41441.64710068703, "episode/length": 288.0, "episode/score": 0.07357197457940856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07357197457940856}
{"step": 356984, "time": 41479.25872159004, "episode/length": 68.0, "episode/score": 0.8063917116737684, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.01889168067236824}
{"step": 357008, "time": 41482.01654100418, "episode/length": 288.0, "episode/score": 0.08344058407385546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08344058407385546}
{"step": 357160, "time": 41499.52697992325, "episode/length": 124.0, "episode/score": 0.6437735986135067, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.031273579533035445}
{"step": 357440, "time": 41531.89356088638, "episode/length": 199.0, "episode/score": 0.45140555508373836, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0732805335003377}
{"step": 358200, "time": 41619.009984731674, "episode/length": 230.0, "episode/score": 0.3180206963261867, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.03677068465555067}
{"step": 358368, "time": 41638.22385454178, "episode/length": 288.0, "episode/score": 0.04984170107536556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04984170107536556}
{"step": 358448, "time": 41647.43147087097, "episode/length": 288.0, "episode/score": 0.08559410289007019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08559410289007019}
{"step": 358632, "time": 41668.47056245804, "episode/length": 202.0, "episode/score": 0.4233923806456801, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.05464236502274389}
{"step": 358888, "time": 41697.75718164444, "episode/length": 85.0, "episode/score": 0.7580749591458584, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.023699959364137158}
{"step": 358920, "time": 41701.502826690674, "episode/length": 219.0, "episode/score": 0.38438824807184346, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.06876322797273815}
{"step": 358968, "time": 41707.05985355377, "episode/length": 288.0, "episode/score": 0.04198667904904596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04198667904904596}
{"step": 359136, "time": 41726.27904343605, "episode/length": 85.0, "episode/score": 0.7498217290741422, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.015446752182583623}
{"step": 359152, "time": 41728.11210370064, "episode/length": 28.0, "episode/score": 0.9210082812650171, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.008508253334071014}
{"step": 359296, "time": 41744.69004702568, "episode/length": 288.0, "episode/score": 0.03036308635324758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03036308635324758}
{"step": 359752, "time": 41797.1704556942, "episode/length": 288.0, "episode/score": 0.040964634451796655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040964634451796655}
{"step": 360048, "time": 41832.40302538872, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 360048, "time": 41832.57988214493, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 360048, "time": 41832.6551527977, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 360048, "time": 41832.696430921555, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 360048, "time": 41833.35759115219, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 360048, "time": 41833.36345911026, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 360048, "time": 41834.22880291939, "eval_episode/length": 176.0, "eval_episode/score": 0.44999998807907104, "eval_episode/reward_rate": 0.005649717514124294}
{"step": 360048, "time": 41834.86975264549, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 360624, "time": 41901.349682569504, "episode/length": 185.0, "episode/score": 0.46186740770147594, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.03999240054193365}
{"step": 360680, "time": 41907.77184844017, "episode/length": 288.0, "episode/score": 0.029537833475927755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029537833475927755}
{"step": 360944, "time": 41938.0518784523, "episode/length": 288.0, "episode/score": 0.03291363593234564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03291363593234564}
{"step": 361000, "time": 41944.54406476021, "episode/length": 253.0, "episode/score": 0.26606042898950477, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.05668544018865873}
{"step": 361008, "time": 41945.45993518829, "episode/length": 156.0, "episode/score": 0.5395580142750589, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.027058044327674224}
{"step": 361200, "time": 41967.37673664093, "episode/length": 288.0, "episode/score": 0.0321367003504065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0321367003504065}
{"step": 361464, "time": 41997.53926730156, "episode/length": 288.0, "episode/score": 0.04091369169776726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04091369169776726}
{"step": 361608, "time": 42014.04890370369, "episode/length": 288.0, "episode/score": 0.0237158502847592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0237158502847592}
{"step": 361720, "time": 42026.871782541275, "episode/length": 31.0, "episode/score": 0.9084756007154056, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.005350638858885759}
{"step": 361960, "time": 42054.40245938301, "episode/length": 166.0, "episode/score": 0.5094354184547001, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.028185444534642556}
{"step": 362152, "time": 42076.443476200104, "episode/length": 118.0, "episode/score": 0.6557501440068734, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0245001463875667}
{"step": 362832, "time": 42154.64819788933, "episode/length": 228.0, "episode/score": 0.3092686748518645, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.021768690882254305}
{"step": 362992, "time": 42172.96626353264, "episode/length": 288.0, "episode/score": 0.03224755823225678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03224755823225678}
{"step": 363256, "time": 42203.36814069748, "episode/length": 288.0, "episode/score": 0.018754778617392276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018754778617392276}
{"step": 363320, "time": 42210.69655418396, "episode/length": 288.0, "episode/score": 0.0303916439988825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0303916439988825}
{"step": 363385, "time": 42219.07638978958, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6674073390697006, "train/action_min": 0.0, "train/action_std": 1.5047460162694553, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008699747256308038, "train/actor_opt_grad_steps": 89370.0, "train/actor_opt_loss": -23.949544475924583, "train/adv_mag": 0.5038631171125421, "train/adv_max": 0.26791162177714334, "train/adv_mean": -0.001128928438392988, "train/adv_min": -0.46267219457758185, "train/adv_std": 0.023786864754173062, "train/cont_avg": 0.9958507344470046, "train/cont_loss_mean": 0.012027088313981513, "train/cont_loss_std": 0.19371278852885288, "train/cont_neg_acc": 0.4249853104077004, "train/cont_neg_loss": 2.33963165100485, "train/cont_pos_acc": 0.9999005624226162, "train/cont_pos_loss": 0.002414243401742802, "train/cont_pred": 0.9958812242828756, "train/cont_rate": 0.9958507344470046, "train/dyn_loss_mean": 1.0000011618785594, "train/dyn_loss_std": 1.761229887973809e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1371842043534402, "train/extr_critic_critic_opt_grad_steps": 89370.0, "train/extr_critic_critic_opt_loss": 12304.427284346199, "train/extr_critic_mag": 0.9176499634843818, "train/extr_critic_max": 0.9176499634843818, "train/extr_critic_mean": 0.7520956949154902, "train/extr_critic_min": 0.6096225350683185, "train/extr_critic_std": 0.04430335745524426, "train/extr_return_normed_mag": 0.5398265974862235, "train/extr_return_normed_max": 0.38145907957982356, "train/extr_return_normed_mean": 0.053456409958787775, "train/extr_return_normed_min": -0.4019805099557622, "train/extr_return_normed_std": 0.05121997160158948, "train/extr_return_rate": 0.9993396909555532, "train/extr_return_raw_mag": 1.0789694448220566, "train/extr_return_raw_max": 1.0789694448220566, "train/extr_return_raw_mean": 0.750966807389589, "train/extr_return_raw_min": 0.29552985528647074, "train/extr_return_raw_std": 0.05121997168742567, "train/extr_reward_mag": 0.4111049197236514, "train/extr_reward_max": 0.4111049197236514, "train/extr_reward_mean": 0.0009986141253711253, "train/extr_reward_min": 1.4464426699871291e-06, "train/extr_reward_std": 0.00891762837812665, "train/image_loss_mean": 0.08684771945742968, "train/image_loss_std": 0.10759660296039097, "train/model_loss_mean": 0.7132751905973056, "train/model_loss_std": 0.3286995766555659, "train/model_opt_grad_norm": 13.744205512382367, "train/model_opt_grad_steps": 89289.7741935484, "train/model_opt_loss": 3746.0890066964284, "train/model_opt_model_opt_grad_overflow": 0.004608294930875576, "train/model_opt_model_opt_grad_scale": 5230.414746543779, "train/policy_entropy_mag": 1.3484228931813746, "train/policy_entropy_max": 1.3484228931813746, "train/policy_entropy_mean": 0.10363850454168935, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13347322037143092, "train/policy_logprob_mag": 6.551080255464475, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10356043385607856, "train/policy_logprob_min": -6.551080255464475, "train/policy_logprob_std": 0.640206848970756, "train/policy_randomness_mag": 0.6929523313100436, "train/policy_randomness_max": 0.6929523313100436, "train/policy_randomness_mean": 0.05325965928385884, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06859167100441071, "train/post_ent_mag": 33.61515906549269, "train/post_ent_max": 33.61515906549269, "train/post_ent_mean": 33.43409660444831, "train/post_ent_min": 33.25530541767173, "train/post_ent_std": 0.07546891083228423, "train/prior_ent_mag": 34.62126358313495, "train/prior_ent_max": 34.62126358313495, "train/prior_ent_mean": 33.690077838809806, "train/prior_ent_min": 32.787414990262505, "train/prior_ent_std": 0.2715217204687233, "train/rep_loss_mean": 1.0000011618785594, "train/rep_loss_std": 1.761229887973809e-05, "train/reward_avg": 0.0009570445866465637, "train/reward_loss_mean": 0.014399660618177481, "train/reward_loss_std": 0.12507565106235205, "train/reward_max_data": 0.5134904504461806, "train/reward_max_pred": 0.18445631930355652, "train/reward_neg_acc": 0.9997792903179398, "train/reward_neg_loss": 0.009607955006547788, "train/reward_pos_acc": 0.28637316673056884, "train/reward_pos_loss": 3.858747646212578, "train/reward_pred": 0.0008060616743643575, "train/reward_rate": 0.0012465797811059907, "train_stats/mean_log_entropy": 0.07921226740610308, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01021790411323309, "report/cont_loss_std": 0.14605239033699036, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 1.7173008918762207, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0035234608221799135, "report/cont_pred": 0.9950920343399048, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0787767544388771, "report/image_loss_std": 0.1084992066025734, "report/model_loss_mean": 0.6980783939361572, "report/model_loss_std": 0.18686744570732117, "report/post_ent_mag": 33.586708068847656, "report/post_ent_max": 33.586708068847656, "report/post_ent_mean": 33.40809631347656, "report/post_ent_min": 33.22810363769531, "report/post_ent_std": 0.07839712500572205, "report/prior_ent_mag": 34.51713943481445, "report/prior_ent_max": 34.51713943481445, "report/prior_ent_mean": 33.67197036743164, "report/prior_ent_min": 32.711273193359375, "report/prior_ent_std": 0.281126469373703, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00017819755885284394, "report/reward_loss_mean": 0.009083721786737442, "report/reward_loss_std": 0.016161901876330376, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.10775148868560791, "report/reward_neg_acc": 0.9990234375, "report/reward_neg_loss": 0.009083721786737442, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0007364524062722921, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.030432041734457016, "eval/cont_loss_std": 0.5338502526283264, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.862044334411621, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.004482155200093985, "eval/cont_pred": 0.9958340525627136, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21543344855308533, "eval/image_loss_std": 0.18825222551822662, "eval/model_loss_mean": 0.8811541199684143, "eval/model_loss_std": 1.1573864221572876, "eval/post_ent_mag": 33.59359359741211, "eval/post_ent_max": 33.59359359741211, "eval/post_ent_mean": 33.39595031738281, "eval/post_ent_min": 33.21150588989258, "eval/post_ent_std": 0.07833915948867798, "eval/prior_ent_mag": 34.51713943481445, "eval/prior_ent_max": 34.51713943481445, "eval/prior_ent_mean": 33.66468811035156, "eval/prior_ent_min": 32.72887420654297, "eval/prior_ent_std": 0.2847892642021179, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002066040178760886, "eval/reward_loss_mean": 0.03528860956430435, "eval/reward_loss_std": 0.6164451837539673, "eval/reward_max_data": 0.8187500238418579, "eval/reward_max_pred": 0.020215630531311035, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0019949881825596094, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 11.366216659545898, "eval/reward_pred": 0.0006126625230535865, "eval/reward_rate": 0.0029296875, "replay/size": 362881.0, "replay/inserts": 8672.0, "replay/samples": 34688.0, "replay/insert_wait_avg": 1.50677682728785e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.680283921231203e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 84616.0, "eval_replay/inserts": 1720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0008035704146985e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2277579307556, "timer/env.step_count": 1084.0, "timer/env.step_total": 10.102487802505493, "timer/env.step_frac": 0.01010018740472195, "timer/env.step_avg": 0.009319638194193259, "timer/env.step_min": 0.008223295211791992, "timer/env.step_max": 0.03366994857788086, "timer/replay._sample_count": 34688.0, "timer/replay._sample_total": 16.581305027008057, "timer/replay._sample_frac": 0.016577529363223247, "timer/replay._sample_avg": 0.0004780127141088577, "timer/replay._sample_min": 0.000347137451171875, "timer/replay._sample_max": 0.015623092651367188, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1299.0, "timer/agent.policy_total": 12.520904779434204, "timer/agent.policy_frac": 0.012518053693427901, "timer/agent.policy_avg": 0.009638879737824638, "timer/agent.policy_min": 0.008701801300048828, "timer/agent.policy_max": 0.0354456901550293, "timer/dataset_train_count": 2168.0, "timer/dataset_train_total": 0.37689852714538574, "timer/dataset_train_frac": 0.0003768127050633981, "timer/dataset_train_avg": 0.00017384618410765026, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0005450248718261719, "timer/agent.train_count": 2168.0, "timer/agent.train_total": 963.6036105155945, "timer/agent.train_frac": 0.9633841921254733, "timer/agent.train_avg": 0.44446661001641813, "timer/agent.train_min": 0.43453264236450195, "timer/agent.train_max": 0.5920102596282959, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4774973392486572, "timer/agent.report_frac": 0.00047738861020663026, "timer/agent.report_avg": 0.2387486696243286, "timer/agent.report_min": 0.23504948616027832, "timer/agent.report_max": 0.2424478530883789, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7173529030834733e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 8.66990595398748}
{"step": 363800, "time": 42266.41587924957, "episode/length": 205.0, "episode/score": 0.39591432603290855, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.036539326251187276}
{"step": 363920, "time": 42280.308815956116, "episode/length": 288.0, "episode/score": 0.052459259925342394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052459259925342394}
{"step": 364032, "time": 42293.13739490509, "episode/length": 288.0, "episode/score": 0.029839181679506055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029839181679506055}
{"step": 364272, "time": 42320.64328765869, "episode/length": 288.0, "episode/score": 0.03403920909809699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03403920909809699}
{"step": 364432, "time": 42338.973355293274, "episode/length": 146.0, "episode/score": 0.5642208226486503, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.02047084463950455}
{"step": 365088, "time": 42414.34569120407, "episode/length": 261.0, "episode/score": 0.2240222386933226, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.03964723894361555}
{"step": 365144, "time": 42420.7409491539, "episode/length": 288.0, "episode/score": 0.033941519051722935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033941519051722935}
{"step": 365248, "time": 42432.74036812782, "episode/length": 121.0, "episode/score": 0.6505792379597608, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.028704264985577765}
{"step": 365632, "time": 42476.8660299778, "episode/length": 288.0, "episode/score": 0.03161790382853269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03161790382853269}
{"step": 366112, "time": 42531.951359272, "episode/length": 288.0, "episode/score": 0.022617731081339798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022617731081339798}
{"step": 366232, "time": 42545.78261876106, "episode/length": 288.0, "episode/score": 0.055674265215174046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055674265215174046}
{"step": 366344, "time": 42558.650629758835, "episode/length": 288.0, "episode/score": 0.04283899398294011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04283899398294011}
{"step": 366408, "time": 42566.07944369316, "episode/length": 96.0, "episode/score": 0.7259536169198668, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.02595360072649555}
{"step": 366744, "time": 42604.75207948685, "episode/length": 288.0, "episode/score": 0.05409487985545525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05409487985545525}
{"step": 367400, "time": 42680.15190911293, "episode/length": 288.0, "episode/score": 0.03480911002498033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03480911002498033}
{"step": 367456, "time": 42686.558765888214, "episode/length": 288.0, "episode/score": 0.04152885007806617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04152885007806617}
{"step": 367560, "time": 42698.538564920425, "episode/length": 288.0, "episode/score": 0.053355727060449, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053355727060449}
{"step": 368120, "time": 42762.79199361801, "episode/length": 213.0, "episode/score": 0.3897199618634204, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.05534496898803809}
{"step": 368424, "time": 42797.69474387169, "episode/length": 288.0, "episode/score": 0.027819628185341116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027819628185341116}
{"step": 368544, "time": 42811.480426073074, "episode/length": 288.0, "episode/score": 0.0545112844282869, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0545112844282869}
{"step": 368656, "time": 42824.65887093544, "episode/length": 288.0, "episode/score": 0.03587247430368734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03587247430368734}
{"step": 368704, "time": 42830.14012646675, "episode/length": 34.0, "episode/score": 0.9134375187950354, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.019687478235937306}
{"step": 368904, "time": 42853.24937868118, "episode/length": 97.0, "episode/score": 0.7207669453421204, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.02389194054580912}
{"step": 369040, "time": 42868.84096646309, "episode/length": 61.0, "episode/score": 0.8294914112407241, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.020116423976560327}
{"step": 369056, "time": 42870.696320295334, "episode/length": 288.0, "episode/score": 0.07377208071144992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07377208071144992}
{"step": 369608, "time": 42933.99447488785, "episode/length": 112.0, "episode/score": 0.6811082349215667, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.031108259578331854}
{"step": 369696, "time": 42944.07582426071, "episode/length": 279.0, "episode/score": 0.19505249146800452, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.06692749503031337}
{"step": 369712, "time": 42945.89687156677, "episode/length": 288.0, "episode/score": 0.07458295067169729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07458295067169729}
{"step": 369752, "time": 42950.47608947754, "episode/length": 136.0, "episode/score": 0.5914071332151707, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.016407121794827617}
{"step": 369872, "time": 42964.239750146866, "episode/length": 288.0, "episode/score": 0.03590013809264292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03590013809264292}
{"step": 370032, "time": 42983.71609997749, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 370032, "time": 42983.894803762436, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 370032, "time": 42983.96647787094, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 370032, "time": 42984.04366135597, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 370032, "time": 42984.319033145905, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 370032, "time": 42986.04412293434, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 370032, "time": 42986.18412089348, "eval_episode/length": 206.0, "eval_episode/score": 0.35624998807907104, "eval_episode/reward_rate": 0.004830917874396135}
{"step": 370032, "time": 42988.63571715355, "eval_episode/length": 190.0, "eval_episode/score": 0.40625, "eval_episode/reward_rate": 0.005235602094240838}
{"step": 370920, "time": 43090.40301775932, "episode/length": 234.0, "episode/score": 0.3144488999166697, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.04569887367665615}
{"step": 371216, "time": 43124.305725336075, "episode/length": 288.0, "episode/score": 0.030414241073344783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030414241073344783}
{"step": 371368, "time": 43141.73105573654, "episode/length": 288.0, "episode/score": 0.05636865707379002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05636865707379002}
{"step": 371920, "time": 43204.970242500305, "episode/length": 288.0, "episode/score": 0.0389309794240944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0389309794240944}
{"step": 372008, "time": 43215.075649261475, "episode/length": 288.0, "episode/score": 0.05001442972127279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05001442972127279}
{"step": 372024, "time": 43216.91858673096, "episode/length": 288.0, "episode/score": 0.04005232964817651, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04005232964817651}
{"step": 372037, "time": 43219.3000729084, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.93830808296731, "train/action_min": 0.0, "train/action_std": 1.8312597977950276, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006881007083481358, "train/actor_opt_grad_steps": 91540.0, "train/actor_opt_loss": -18.984403157563804, "train/adv_mag": 0.4526153323562464, "train/adv_max": 0.19787587355908162, "train/adv_mean": -0.0015660042326538213, "train/adv_min": -0.4184310757619445, "train/adv_std": 0.019746774150925572, "train/cont_avg": 0.9960037442396313, "train/cont_loss_mean": 0.012198138975619858, "train/cont_loss_std": 0.19788971765198604, "train/cont_neg_acc": 0.4329161169790776, "train/cont_neg_loss": 2.4083780083393855, "train/cont_pos_acc": 0.9998237125335201, "train/cont_pos_loss": 0.002535564192701646, "train/cont_pred": 0.99585258301502, "train/cont_rate": 0.9960037442396313, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10406898217455994, "train/extr_critic_critic_opt_grad_steps": 91540.0, "train/extr_critic_critic_opt_loss": 11624.234969038018, "train/extr_critic_mag": 0.8467946431603849, "train/extr_critic_max": 0.8467946431603849, "train/extr_critic_mean": 0.6949483491308678, "train/extr_critic_min": 0.5771277747395951, "train/extr_critic_std": 0.035361585675090686, "train/extr_return_normed_mag": 0.47517222550607496, "train/extr_return_normed_max": 0.2880551026713464, "train/extr_return_normed_mean": 0.0414163551125933, "train/extr_return_normed_min": -0.36568697888730306, "train/extr_return_normed_std": 0.04049024377275722, "train/extr_return_rate": 0.9990933748983568, "train/extr_return_raw_mag": 0.9400210756860021, "train/extr_return_raw_max": 0.9400210756860021, "train/extr_return_raw_mean": 0.6933823565733598, "train/extr_return_raw_min": 0.2862789941273527, "train/extr_return_raw_std": 0.04049024391009511, "train/extr_reward_mag": 0.3360051960439726, "train/extr_reward_max": 0.3360051960439726, "train/extr_reward_mean": 0.0007978718304547399, "train/extr_reward_min": 9.685068086545039e-07, "train/extr_reward_std": 0.006689219930303639, "train/image_loss_mean": 0.0850034739804982, "train/image_loss_std": 0.10554905393705939, "train/model_loss_mean": 0.711061752611591, "train/model_loss_std": 0.3228008932850328, "train/model_opt_grad_norm": 14.222060823220811, "train/model_opt_grad_steps": 91457.82488479263, "train/model_opt_loss": 4209.363830285139, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5921.658986175115, "train/policy_entropy_mag": 1.4001957947208035, "train/policy_entropy_max": 1.4001957947208035, "train/policy_entropy_mean": 0.112799992621769, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.15075375507092145, "train/policy_logprob_mag": 6.551080237885225, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11298953789857126, "train/policy_logprob_min": -6.551080237885225, "train/policy_logprob_std": 0.6514794005226979, "train/policy_randomness_mag": 0.7195583400638422, "train/policy_randomness_max": 0.7195583400638422, "train/policy_randomness_mean": 0.05796773287077104, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0774721093647491, "train/post_ent_mag": 33.56680046468286, "train/post_ent_max": 33.56680046468286, "train/post_ent_mean": 33.3843755414409, "train/post_ent_min": 33.20416725615752, "train/post_ent_std": 0.07569181747425537, "train/prior_ent_mag": 34.470607107136104, "train/prior_ent_max": 34.470607107136104, "train/prior_ent_mean": 33.68529267904396, "train/prior_ent_min": 32.80167654362692, "train/prior_ent_std": 0.2588101457890278, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0008696756366367263, "train/reward_loss_mean": 0.013860117075406873, "train/reward_loss_std": 0.1172597883870044, "train/reward_max_data": 0.4479783252385887, "train/reward_max_pred": 0.17010747177809615, "train/reward_neg_acc": 0.9998107626690843, "train/reward_neg_loss": 0.009421027662481443, "train/reward_pos_acc": 0.2973333344856898, "train/reward_pos_loss": 3.7786170335114004, "train/reward_pred": 0.0007858388168814545, "train/reward_rate": 0.0011475734447004607, "train_stats/mean_log_entropy": 0.08271371718082163, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.01071749348193407, "report/cont_loss_std": 0.18869656324386597, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.2502875328063965, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0011986790923401713, "report/cont_pred": 0.9985606670379639, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0668230876326561, "report/image_loss_std": 0.10398188978433609, "report/model_loss_mean": 0.6950072050094604, "report/model_loss_std": 0.46112218499183655, "report/post_ent_mag": 33.56533432006836, "report/post_ent_max": 33.56533432006836, "report/post_ent_mean": 33.342132568359375, "report/post_ent_min": 33.188995361328125, "report/post_ent_std": 0.08172641694545746, "report/prior_ent_mag": 34.17321014404297, "report/prior_ent_max": 34.17321014404297, "report/prior_ent_mean": 33.70659637451172, "report/prior_ent_min": 32.80142593383789, "report/prior_ent_std": 0.2022823542356491, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0011637654388323426, "report/reward_loss_mean": 0.01746663637459278, "report/reward_loss_std": 0.25070351362228394, "report/reward_max_data": 0.6002777814865112, "report/reward_max_pred": 0.03716433048248291, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.006491141393780708, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.625945091247559, "report/reward_pred": 0.0003650470171123743, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.011582016944885254, "eval/cont_loss_std": 0.23006893694400787, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.028507232666016, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001764158601872623, "eval/cont_pred": 0.9982253313064575, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18614408373832703, "eval/image_loss_std": 0.17557275295257568, "eval/model_loss_mean": 0.8116587996482849, "eval/model_loss_std": 0.5566607713699341, "eval/post_ent_mag": 33.56689453125, "eval/post_ent_max": 33.56689453125, "eval/post_ent_mean": 33.35761260986328, "eval/post_ent_min": 33.17499923706055, "eval/post_ent_std": 0.08343427628278732, "eval/prior_ent_mag": 34.27638626098633, "eval/prior_ent_max": 34.27638626098633, "eval/prior_ent_mean": 33.6353874206543, "eval/prior_ent_min": 32.60699462890625, "eval/prior_ent_std": 0.26921334862709045, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0013031006092205644, "eval/reward_loss_mean": 0.013932683505117893, "eval/reward_loss_std": 0.2909835875034332, "eval/reward_max_data": 0.815625011920929, "eval/reward_max_pred": 0.01861703395843506, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013538250932469964, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.441729545593262, "eval/reward_pred": 0.0003828260814771056, "eval/reward_rate": 0.001953125, "replay/size": 371533.0, "replay/inserts": 8652.0, "replay/samples": 34608.0, "replay/insert_wait_avg": 1.5059335332086556e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.74199026798243e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 86912.0, "eval_replay/inserts": 2296.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.93029996493137e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2068965435028, "timer/env.step_count": 1081.0, "timer/env.step_total": 10.07109785079956, "timer/env.step_frac": 0.010069014606481, "timer/env.step_avg": 0.009316464246808103, "timer/env.step_min": 0.008121728897094727, "timer/env.step_max": 0.03339123725891113, "timer/replay._sample_count": 34608.0, "timer/replay._sample_total": 16.62199568748474, "timer/replay._sample_frac": 0.016618557365407835, "timer/replay._sample_avg": 0.000480293449129818, "timer/replay._sample_min": 0.0003733634948730469, "timer/replay._sample_max": 0.028245925903320312, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1368.0, "timer/agent.policy_total": 14.353044033050537, "timer/agent.policy_frac": 0.014350075052123247, "timer/agent.policy_avg": 0.010491991252229925, "timer/agent.policy_min": 0.008778572082519531, "timer/agent.policy_max": 1.1018075942993164, "timer/dataset_train_count": 2163.0, "timer/dataset_train_total": 0.3795332908630371, "timer/dataset_train_frac": 0.00037945478298002293, "timer/dataset_train_avg": 0.00017546615388952248, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0010023117065429688, "timer/agent.train_count": 2163.0, "timer/agent.train_total": 961.2363979816437, "timer/agent.train_frac": 0.9610375626317588, "timer/agent.train_avg": 0.44439962921019127, "timer/agent.train_min": 0.4330155849456787, "timer/agent.train_max": 0.5851361751556396, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4797391891479492, "timer/agent.report_frac": 0.0004796399532994857, "timer/agent.report_avg": 0.2398695945739746, "timer/agent.report_min": 0.23193860054016113, "timer/agent.report_max": 0.24780058860778809, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 9.608268737792969e-05, "timer/dataset_eval_frac": 9.606281231410274e-08, "timer/dataset_eval_avg": 9.608268737792969e-05, "timer/dataset_eval_min": 9.608268737792969e-05, "timer/dataset_eval_max": 9.608268737792969e-05, "fps": 8.650085240092203}
{"step": 372064, "time": 43222.206679821014, "episode/length": 288.0, "episode/score": 0.06832143069908625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06832143069908625}
{"step": 372184, "time": 43236.1919400692, "episode/length": 288.0, "episode/score": 0.03182084265819185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03182084265819185}
{"step": 372368, "time": 43257.3005232811, "episode/length": 143.0, "episode/score": 0.5937255902548486, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.04060053701812194}
{"step": 372712, "time": 43296.74225473404, "episode/length": 98.0, "episode/score": 0.7260626059274955, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.032312552690768825}
{"step": 373168, "time": 43349.22510313988, "episode/length": 122.0, "episode/score": 0.6548051189324156, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.03605511943300144}
{"step": 373232, "time": 43356.64683532715, "episode/length": 288.0, "episode/score": 0.05697295885664744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05697295885664744}
{"step": 373496, "time": 43386.98625874519, "episode/length": 97.0, "episode/score": 0.7319020492858499, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.035027093267558485}
{"step": 373680, "time": 43408.032860040665, "episode/length": 288.0, "episode/score": 0.0365327071996262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0365327071996262}
{"step": 374224, "time": 43470.488918066025, "episode/length": 123.0, "episode/score": 0.6473834153621851, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.03175838436078493}
{"step": 374320, "time": 43481.55519080162, "episode/length": 288.0, "episode/score": 0.05294651795043137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05294651795043137}
{"step": 374336, "time": 43483.38589859009, "episode/length": 288.0, "episode/score": 0.062061669784952755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062061669784952755}
{"step": 374376, "time": 43487.982741355896, "episode/length": 288.0, "episode/score": 0.082594172859217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.082594172859217}
{"step": 374680, "time": 43522.90060377121, "episode/length": 288.0, "episode/score": 0.06548342309349664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06548342309349664}
{"step": 375480, "time": 43615.217808008194, "episode/length": 288.0, "episode/score": 0.03709056139734912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03709056139734912}
{"step": 375808, "time": 43653.12609863281, "episode/length": 288.0, "episode/score": 0.05152504441690553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05152504441690553}
{"step": 375904, "time": 43664.15564870834, "episode/length": 197.0, "episode/score": 0.4162529038020466, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.03187789865648938}
{"step": 375992, "time": 43674.23709654808, "episode/length": 288.0, "episode/score": 0.028876354981889563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028876354981889563}
{"step": 376536, "time": 43736.768428087234, "episode/length": 288.0, "episode/score": 0.03951635372840201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03951635372840201}
{"step": 376576, "time": 43741.4689514637, "episode/length": 279.0, "episode/score": 0.17561647864295082, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.04749148220525967}
{"step": 376688, "time": 43754.33804488182, "episode/length": 288.0, "episode/score": 0.05474380649360455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05474380649360455}
{"step": 376992, "time": 43789.66842365265, "episode/length": 288.0, "episode/score": 0.044634128129928285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044634128129928285}
{"step": 377040, "time": 43795.190705537796, "episode/length": 130.0, "episode/score": 0.6080979639034467, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0143479405621747}
{"step": 377248, "time": 43819.08366560936, "episode/length": 220.0, "episode/score": 0.3529409767052698, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.04044096238618522}
{"step": 377968, "time": 43901.986016750336, "episode/length": 173.0, "episode/score": 0.4896881247127567, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.03031313713427153}
{"step": 378120, "time": 43919.37671613693, "episode/length": 288.0, "episode/score": 0.035350512398167666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035350512398167666}
{"step": 378216, "time": 43930.468054533005, "episode/length": 288.0, "episode/score": 0.04733563473507729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04733563473507729}
{"step": 378848, "time": 44002.87437915802, "episode/length": 288.0, "episode/score": 0.059379003589015156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059379003589015156}
{"step": 379000, "time": 44020.45343875885, "episode/length": 288.0, "episode/score": 0.026339172261145904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026339172261145904}
{"step": 379056, "time": 44026.929047584534, "episode/length": 116.0, "episode/score": 0.6629530522388905, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.025453055981643047}
{"step": 379304, "time": 44055.50983285904, "episode/length": 288.0, "episode/score": 0.055710072618808226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055710072618808226}
{"step": 379352, "time": 44061.028378248215, "episode/length": 288.0, "episode/score": 0.03657935891737907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03657935891737907}
{"step": 379560, "time": 44085.04374670982, "episode/length": 288.0, "episode/score": 0.057678546986267065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057678546986267065}
{"step": 379840, "time": 44117.16085958481, "episode/length": 202.0, "episode/score": 0.4206072203517124, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.05185720007216332}
{"step": 380016, "time": 44138.21028494835, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 380016, "time": 44138.64898896217, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 380016, "time": 44139.32642579079, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 380016, "time": 44140.48980474472, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 380016, "time": 44142.20819711685, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 44142.21510505676, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 44142.22075462341, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 44142.226320028305, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 44142.23177027702, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380280, "time": 44172.551752090454, "episode/length": 288.0, "episode/score": 0.057099962780853275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057099962780853275}
{"step": 380360, "time": 44181.79964733124, "episode/length": 162.0, "episode/score": 0.5171928752507142, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.023442869697703372}
{"step": 380488, "time": 44196.53577709198, "episode/length": 141.0, "episode/score": 0.5867516222653535, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.027376604791413683}
{"step": 380608, "time": 44210.262281894684, "episode/length": 130.0, "episode/score": 0.6301127763339309, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.03636276201484634}
{"step": 380681, "time": 44219.527863025665, "train_stats/mean_log_entropy": 0.09422842231956688, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7493823016131365, "train/action_min": 0.0, "train/action_std": 1.9506135157964848, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00617414709348749, "train/actor_opt_grad_steps": 93705.0, "train/actor_opt_loss": -13.906783035507909, "train/adv_mag": 0.4338714800499104, "train/adv_max": 0.23861962887975904, "train/adv_mean": -0.0008669123680449418, "train/adv_min": -0.39203671945465934, "train/adv_std": 0.01851703966881528, "train/cont_avg": 0.9959083839699074, "train/cont_loss_mean": 0.012835399008407775, "train/cont_loss_std": 0.20266833532756814, "train/cont_neg_acc": 0.4070450414751851, "train/cont_neg_loss": 2.506864620058941, "train/cont_pos_acc": 0.9998865593914632, "train/cont_pos_loss": 0.002575199942199375, "train/cont_pred": 0.995878210498227, "train/cont_rate": 0.9959083839699074, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11367464624345303, "train/extr_critic_critic_opt_grad_steps": 93705.0, "train/extr_critic_critic_opt_loss": 8451.698531539352, "train/extr_critic_mag": 0.800808988235615, "train/extr_critic_max": 0.800808988235615, "train/extr_critic_mean": 0.6500503351842916, "train/extr_critic_min": 0.5366671918718903, "train/extr_critic_std": 0.025807956173257145, "train/extr_return_normed_mag": 0.46461562205243995, "train/extr_return_normed_max": 0.3073982877863778, "train/extr_return_normed_mean": 0.02877827461257025, "train/extr_return_normed_min": -0.3567897895420039, "train/extr_return_normed_std": 0.03245933815250518, "train/extr_return_rate": 0.9990605491179007, "train/extr_return_raw_mag": 0.9278033969027025, "train/extr_return_raw_max": 0.9278033969027025, "train/extr_return_raw_mean": 0.6491834179118827, "train/extr_return_raw_min": 0.26361531957432077, "train/extr_return_raw_std": 0.03245933805764825, "train/extr_reward_mag": 0.39815781348281437, "train/extr_reward_max": 0.39815781348281437, "train/extr_reward_mean": 0.0009117978212695258, "train/extr_reward_min": 8.686825081154152e-07, "train/extr_reward_std": 0.008028461299276117, "train/image_loss_mean": 0.0875162756656883, "train/image_loss_std": 0.10703628599919655, "train/model_loss_mean": 0.7145074710801795, "train/model_loss_std": 0.3338209865614772, "train/model_opt_grad_norm": 13.894902604597586, "train/model_opt_grad_steps": 93620.91666666667, "train/model_opt_loss": 3736.0599534776475, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5231.481481481482, "train/policy_entropy_mag": 1.3637371366774593, "train/policy_entropy_max": 1.3637371366774593, "train/policy_entropy_mean": 0.11485819473724675, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.15505809078199995, "train/policy_logprob_mag": 6.551080271049782, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11520494296456929, "train/policy_logprob_min": -6.551080271049782, "train/policy_logprob_std": 0.6550775639436863, "train/policy_randomness_mag": 0.7008222945862346, "train/policy_randomness_max": 0.7008222945862346, "train/policy_randomness_mean": 0.05902543914055935, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0796841009416514, "train/post_ent_mag": 33.48135310632211, "train/post_ent_max": 33.48135310632211, "train/post_ent_mean": 33.29569482803345, "train/post_ent_min": 33.110165984542284, "train/post_ent_std": 0.07741950842103472, "train/prior_ent_mag": 34.28402623423823, "train/prior_ent_max": 34.28402623423823, "train/prior_ent_mean": 33.72170658464785, "train/prior_ent_min": 32.85288618229054, "train/prior_ent_std": 0.23052721173950919, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.000875469900940381, "train/reward_loss_mean": 0.014155774224221844, "train/reward_loss_std": 0.12193527061888879, "train/reward_max_data": 0.44203830010546546, "train/reward_max_pred": 0.17435741203802604, "train/reward_neg_acc": 0.9997872837163784, "train/reward_neg_loss": 0.009481903971862738, "train/reward_pos_acc": 0.24551724205757008, "train/reward_pos_loss": 4.118254012691564, "train/reward_pred": 0.0007986859440010179, "train/reward_rate": 0.0011528862847222222, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.017731020227074623, "report/cont_loss_std": 0.2325918972492218, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.2754719257354736, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0017460319213569164, "report/cont_pred": 0.9980531334877014, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11695241928100586, "report/image_loss_std": 0.1203262060880661, "report/model_loss_mean": 0.7605017423629761, "report/model_loss_std": 0.5082336664199829, "report/post_ent_mag": 33.557884216308594, "report/post_ent_max": 33.557884216308594, "report/post_ent_mean": 33.39421081542969, "report/post_ent_min": 33.21417236328125, "report/post_ent_std": 0.07670747488737106, "report/prior_ent_mag": 34.318275451660156, "report/prior_ent_max": 34.318275451660156, "report/prior_ent_mean": 33.699424743652344, "report/prior_ent_min": 33.00199890136719, "report/prior_ent_std": 0.20086249709129333, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0018506073392927647, "report/reward_loss_mean": 0.02581823244690895, "report/reward_loss_std": 0.2684241831302643, "report/reward_max_data": 0.7910416722297668, "report/reward_max_pred": 0.031017780303955078, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.011313053779304028, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.962413787841797, "report/reward_pred": 0.0005890935426577926, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.053530119359493256, "eval/cont_loss_std": 0.7587538361549377, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.610743522644043, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0017282846383750439, "eval/cont_pred": 0.9983452558517456, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2513449192047119, "eval/image_loss_std": 0.16703177988529205, "eval/model_loss_mean": 0.9072097539901733, "eval/model_loss_std": 0.7743445634841919, "eval/post_ent_mag": 33.568885803222656, "eval/post_ent_max": 33.568885803222656, "eval/post_ent_mean": 33.376251220703125, "eval/post_ent_min": 33.186668395996094, "eval/post_ent_std": 0.07958658039569855, "eval/prior_ent_mag": 34.25198745727539, "eval/prior_ent_max": 34.25198745727539, "eval/prior_ent_mean": 33.73680877685547, "eval/prior_ent_min": 32.77776336669922, "eval/prior_ent_std": 0.20898611843585968, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.002334736054763198, "eval/reward_loss_std": 0.016282886266708374, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.06615567207336426, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002334736054763198, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0004608817398548126, "eval/reward_rate": 0.0, "replay/size": 380177.0, "replay/inserts": 8644.0, "replay/samples": 34576.0, "replay/insert_wait_avg": 1.4932604643659755e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.722538855824963e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 89224.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.775986720946422e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2112662792206, "timer/env.step_count": 1081.0, "timer/env.step_total": 10.05800747871399, "timer/env.step_frac": 0.010055883009726247, "timer/env.step_avg": 0.00930435474441627, "timer/env.step_min": 0.008266448974609375, "timer/env.step_max": 0.044866085052490234, "timer/replay._sample_count": 34576.0, "timer/replay._sample_total": 16.56817889213562, "timer/replay._sample_frac": 0.01656467933396625, "timer/replay._sample_avg": 0.0004791814811469117, "timer/replay._sample_min": 0.00035381317138671875, "timer/replay._sample_max": 0.010321855545043945, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1370.0, "timer/agent.policy_total": 13.176212072372437, "timer/agent.policy_frac": 0.013173428971049147, "timer/agent.policy_avg": 0.009617673045527325, "timer/agent.policy_min": 0.008683204650878906, "timer/agent.policy_max": 0.05807232856750488, "timer/dataset_train_count": 2161.0, "timer/dataset_train_total": 0.41820478439331055, "timer/dataset_train_frac": 0.00041811645048653534, "timer/dataset_train_avg": 0.00019352373178774203, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.041579246520996094, "timer/agent.train_count": 2161.0, "timer/agent.train_total": 962.400496006012, "timer/agent.train_frac": 0.9621972161802732, "timer/agent.train_avg": 0.4453496048153688, "timer/agent.train_min": 0.4336686134338379, "timer/agent.train_max": 0.5657854080200195, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.473372220993042, "timer/agent.report_frac": 0.00047327223452899465, "timer/agent.report_avg": 0.236686110496521, "timer/agent.report_min": 0.2320084571838379, "timer/agent.report_max": 0.2413637638092041, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.979602749183156e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 8.642055894701679}
{"step": 381160, "time": 44274.496198415756, "episode/length": 288.0, "episode/score": 0.04425412012915331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04425412012915331}
{"step": 381296, "time": 44290.18375635147, "episode/length": 85.0, "episode/score": 0.7626383374712873, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.028263308076418525}
{"step": 381312, "time": 44292.02672839165, "episode/length": 288.0, "episode/score": 0.04626119768903436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04626119768903436}
{"step": 381504, "time": 44314.07277679443, "episode/length": 23.0, "episode/score": 0.9351936216001491, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.007068617898141838}
{"step": 381616, "time": 44326.9309823513, "episode/length": 288.0, "episode/score": 0.0401926534290169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0401926534290169}
{"step": 382152, "time": 44388.63934183121, "episode/length": 288.0, "episode/score": 0.037650910614956956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037650910614956956}
{"step": 382432, "time": 44421.019928216934, "episode/length": 258.0, "episode/score": 0.23066119632215987, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.03691120900560918}
{"step": 382592, "time": 44439.48279309273, "episode/length": 288.0, "episode/score": 0.04542449183571762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04542449183571762}
{"step": 382800, "time": 44463.35848546028, "episode/length": 288.0, "episode/score": 0.025758434249098627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025758434249098627}
{"step": 383368, "time": 44528.68292951584, "episode/length": 70.0, "episode/score": 0.7879063873145924, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.006656357919723632}
{"step": 383376, "time": 44529.59679102898, "episode/length": 219.0, "episode/score": 0.34693119335554456, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.03130617325643925}
{"step": 383472, "time": 44540.60272860527, "episode/length": 288.0, "episode/score": 0.02587762272770533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02587762272770533}
{"step": 383608, "time": 44556.28712916374, "episode/length": 288.0, "episode/score": 0.030162605499242545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030162605499242545}
{"step": 383640, "time": 44559.96357536316, "episode/length": 150.0, "episode/score": 0.5462836128800745, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.015033604701898184}
{"step": 383816, "time": 44580.17486023903, "episode/length": 288.0, "episode/score": 0.03240301840975235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03240301840975235}
{"step": 384192, "time": 44623.663061380386, "episode/length": 101.0, "episode/score": 0.704439655353724, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.020064687414503624}
{"step": 384464, "time": 44655.16756391525, "episode/length": 288.0, "episode/score": 0.01770637572593614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01770637572593614}
{"step": 384560, "time": 44666.3415915966, "episode/length": 45.0, "episode/score": 0.8741709311026966, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.014795931320975342}
{"step": 384904, "time": 44706.08862948418, "episode/length": 288.0, "episode/score": 0.03782253107448241, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03782253107448241}
{"step": 385232, "time": 44744.06939673424, "episode/length": 95.0, "episode/score": 0.7265637299357195, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.02343875007557017}
{"step": 385280, "time": 44749.584849357605, "episode/length": 89.0, "episode/score": 0.7429078998083014, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.021032879709196095}
{"step": 385680, "time": 44795.63273501396, "episode/length": 288.0, "episode/score": 0.02576260615867909, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02576260615867909}
{"step": 385784, "time": 44807.55810189247, "episode/length": 288.0, "episode/score": 0.026219425791879303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026219425791879303}
{"step": 385920, "time": 44823.30978059769, "episode/length": 288.0, "episode/score": 0.035670286048627986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035670286048627986}
{"step": 385952, "time": 44826.988466501236, "episode/length": 288.0, "episode/score": 0.04502259772522166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04502259772522166}
{"step": 386128, "time": 44847.24071455002, "episode/length": 288.0, "episode/score": 0.07337667596428332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07337667596428332}
{"step": 386376, "time": 44875.8017244339, "episode/length": 183.0, "episode/score": 0.4743832595860056, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.046258258386927764}
{"step": 386528, "time": 44893.32475757599, "episode/length": 161.0, "episode/score": 0.5328714297890258, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.03599643455041246}
{"step": 386584, "time": 44899.76167297363, "episode/length": 99.0, "episode/score": 0.7075987617519388, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.01697376796269623}
{"step": 386688, "time": 44911.78793478012, "episode/length": 95.0, "episode/score": 0.7226698850678872, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.019544905207737884}
{"step": 387440, "time": 44998.159534692764, "episode/length": 219.0, "episode/score": 0.35968219962208536, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.04405718791943514}
{"step": 387456, "time": 44999.98561954498, "episode/length": 165.0, "episode/score": 0.5186219634597933, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.03424696367807201}
{"step": 387592, "time": 45015.67220211029, "episode/length": 288.0, "episode/score": 0.04223576112880778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04223576112880778}
{"step": 387648, "time": 45022.202318906784, "episode/length": 23.0, "episode/score": 0.9389213782462491, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.010796325766222026}
{"step": 387880, "time": 45048.909116744995, "episode/length": 187.0, "episode/score": 0.4549950168708108, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.039370004216465304}
{"step": 388264, "time": 45093.04397940636, "episode/length": 288.0, "episode/score": 0.027932078546939465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027932078546939465}
{"step": 388840, "time": 45159.27245473862, "episode/length": 288.0, "episode/score": 0.10073728946966298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10073728946966298}
{"step": 388896, "time": 45165.684930086136, "episode/length": 288.0, "episode/score": 0.08876311072813792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08876311072813792}
{"step": 389000, "time": 45177.61129450798, "episode/length": 288.0, "episode/score": 0.06475798373139696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06475798373139696}
{"step": 389357, "time": 45219.54741072655, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.477034748973934, "train/action_min": 0.0, "train/action_std": 1.9042414119166713, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006851163236767672, "train/actor_opt_grad_steps": 95870.0, "train/actor_opt_loss": -14.330232853164322, "train/adv_mag": 0.4316838794314916, "train/adv_max": 0.24319004875174316, "train/adv_mean": 0.0027293566937686494, "train/adv_min": -0.3815457076520964, "train/adv_std": 0.021592918641796584, "train/cont_avg": 0.9958507344470046, "train/cont_loss_mean": 0.012188484077341855, "train/cont_loss_std": 0.19678051582825143, "train/cont_neg_acc": 0.44035310870795336, "train/cont_neg_loss": 2.3459728242690256, "train/cont_pos_acc": 0.9999096168351064, "train/cont_pos_loss": 0.002362980815519746, "train/cont_pred": 0.9958902841888815, "train/cont_rate": 0.9958507344470046, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.27397646451978364, "train/extr_critic_critic_opt_grad_steps": 95870.0, "train/extr_critic_critic_opt_loss": 7995.808204475086, "train/extr_critic_mag": 0.7812317708670269, "train/extr_critic_max": 0.7812317708670269, "train/extr_critic_mean": 0.6366721880600749, "train/extr_critic_min": 0.546153820055421, "train/extr_critic_std": 0.03053669462813073, "train/extr_return_normed_mag": 0.4744267661450645, "train/extr_return_normed_max": 0.3356139338510926, "train/extr_return_normed_mean": 0.04642343457170209, "train/extr_return_normed_min": -0.321046446600268, "train/extr_return_normed_std": 0.038362075836496416, "train/extr_return_rate": 0.9993462916892795, "train/extr_return_raw_mag": 0.9285920265083489, "train/extr_return_raw_max": 0.9285920265083489, "train/extr_return_raw_mean": 0.6394015589068013, "train/extr_return_raw_min": 0.2719316460569883, "train/extr_return_raw_std": 0.038362075729201195, "train/extr_reward_mag": 0.4234541281027728, "train/extr_reward_max": 0.4234541281027728, "train/extr_reward_mean": 0.00097005271601216, "train/extr_reward_min": 1.026188722953269e-06, "train/extr_reward_std": 0.0093229984118086, "train/image_loss_mean": 0.0858603403967921, "train/image_loss_std": 0.10634127503029213, "train/model_loss_mean": 0.7123768821290012, "train/model_loss_std": 0.33384568872539677, "train/model_opt_grad_norm": 13.645954271157583, "train/model_opt_grad_steps": 95783.82488479263, "train/model_opt_loss": 3677.2155682963707, "train/model_opt_model_opt_grad_overflow": 0.004608294930875576, "train/model_opt_model_opt_grad_scale": 5138.248847926267, "train/policy_entropy_mag": 1.353279451071392, "train/policy_entropy_max": 1.353279451071392, "train/policy_entropy_mean": 0.10590799159717999, "train/policy_entropy_min": 0.0646864921541258, "train/policy_entropy_std": 0.13767400085239367, "train/policy_logprob_mag": 6.551080303807413, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10584531848057074, "train/policy_logprob_min": -6.551080303807413, "train/policy_logprob_std": 0.6435532987392443, "train/policy_randomness_mag": 0.6954481071590828, "train/policy_randomness_max": 0.6954481071590828, "train/policy_randomness_mean": 0.05442594508490255, "train/policy_randomness_min": 0.033242281560661606, "train/policy_randomness_std": 0.07075044438929602, "train/post_ent_mag": 33.39656599545808, "train/post_ent_max": 33.39656599545808, "train/post_ent_mean": 33.19426609513946, "train/post_ent_min": 32.99215845907888, "train/post_ent_std": 0.08372190965485463, "train/prior_ent_mag": 34.266154381536666, "train/prior_ent_max": 34.266154381536666, "train/prior_ent_mean": 33.70492973855014, "train/prior_ent_min": 32.893249740249004, "train/prior_ent_std": 0.21524093399674113, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0009403844218602412, "train/reward_loss_mean": 0.014328033742730931, "train/reward_loss_std": 0.1277680482655283, "train/reward_max_data": 0.49851209067520663, "train/reward_max_pred": 0.1705760406458982, "train/reward_neg_acc": 0.9998512809177698, "train/reward_neg_loss": 0.009426347490760588, "train/reward_pos_acc": 0.25613497060500773, "train/reward_pos_loss": 3.92294288458634, "train/reward_pred": 0.0007536371173079594, "train/reward_rate": 0.0012555803571428572, "train_stats/mean_log_entropy": 0.08331111656167568, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.007858915254473686, "report/cont_loss_std": 0.12458792328834534, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 1.8391773700714111, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0024779601953923702, "report/cont_pred": 0.9966367483139038, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08748224377632141, "report/image_loss_std": 0.1092868521809578, "report/model_loss_mean": 0.7113361954689026, "report/model_loss_std": 0.29963448643684387, "report/post_ent_mag": 33.400543212890625, "report/post_ent_max": 33.400543212890625, "report/post_ent_mean": 33.177024841308594, "report/post_ent_min": 32.96321105957031, "report/post_ent_std": 0.09205856919288635, "report/prior_ent_mag": 34.28570556640625, "report/prior_ent_max": 34.28570556640625, "report/prior_ent_mean": 33.712528228759766, "report/prior_ent_min": 32.986812591552734, "report/prior_ent_std": 0.21205273270606995, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0012697421479970217, "report/reward_loss_mean": 0.015995001420378685, "report/reward_loss_std": 0.14564529061317444, "report/reward_max_data": 0.700208306312561, "report/reward_max_pred": 0.5468939542770386, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010715075768530369, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.714036464691162, "report/reward_pred": 0.001180271035991609, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.05975324660539627, "eval/cont_loss_std": 0.7857216596603394, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.792713165283203, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0023880687076598406, "eval/cont_pred": 0.997696578502655, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20749914646148682, "eval/image_loss_std": 0.15586385130882263, "eval/model_loss_mean": 0.8805609941482544, "eval/model_loss_std": 1.0282038450241089, "eval/post_ent_mag": 33.407474517822266, "eval/post_ent_max": 33.407474517822266, "eval/post_ent_mean": 33.16579055786133, "eval/post_ent_min": 32.928985595703125, "eval/post_ent_std": 0.09343833476305008, "eval/prior_ent_mag": 34.2999153137207, "eval/prior_ent_max": 34.2999153137207, "eval/prior_ent_mean": 33.6973876953125, "eval/prior_ent_min": 32.95168685913086, "eval/prior_ent_std": 0.20808972418308258, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0004760742303915322, "eval/reward_loss_mean": 0.013308562338352203, "eval/reward_loss_std": 0.3693653345108032, "eval/reward_max_data": 0.48750001192092896, "eval/reward_max_pred": 0.05761730670928955, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0017617970006540418, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 11.82564926147461, "eval/reward_pred": 0.00044353154953569174, "eval/reward_rate": 0.0009765625, "replay/size": 388853.0, "replay/inserts": 8676.0, "replay/samples": 34704.0, "replay/insert_wait_avg": 1.5177887230218418e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.64356059597186e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 89224.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0100719928741, "timer/env.step_count": 1084.0, "timer/env.step_total": 10.092565536499023, "timer/env.step_frac": 0.010092463885274688, "timer/env.step_avg": 0.009310484812268472, "timer/env.step_min": 0.008170127868652344, "timer/env.step_max": 0.03419995307922363, "timer/replay._sample_count": 34704.0, "timer/replay._sample_total": 16.790462732315063, "timer/replay._sample_frac": 0.016790293620597363, "timer/replay._sample_avg": 0.0004838192350252151, "timer/replay._sample_min": 0.00035071372985839844, "timer/replay._sample_max": 0.036520957946777344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1084.0, "timer/agent.policy_total": 10.691503763198853, "timer/agent.policy_frac": 0.010691396079533726, "timer/agent.policy_avg": 0.009863010851659458, "timer/agent.policy_min": 0.008795738220214844, "timer/agent.policy_max": 0.036061763763427734, "timer/dataset_train_count": 2169.0, "timer/dataset_train_total": 0.3822016716003418, "timer/dataset_train_frac": 0.00038219782210660103, "timer/dataset_train_avg": 0.00017621100580928622, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0011334419250488281, "timer/agent.train_count": 2169.0, "timer/agent.train_total": 966.9106488227844, "timer/agent.train_frac": 0.9669009102037068, "timer/agent.train_avg": 0.44578637566748935, "timer/agent.train_min": 0.4358551502227783, "timer/agent.train_max": 0.5764167308807373, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4730691909790039, "timer/agent.report_frac": 0.0004730644262774734, "timer/agent.report_avg": 0.23653459548950195, "timer/agent.report_min": 0.2303485870361328, "timer/agent.report_max": 0.2427206039428711, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8133108977511225e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 8.675794927677936}
{"step": 389752, "time": 45264.68728899956, "episode/length": 288.0, "episode/score": 0.053308674027505276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053308674027505276}
{"step": 389904, "time": 45282.17073726654, "episode/length": 288.0, "episode/score": 0.07889827410716066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07889827410716066}
{"step": 389960, "time": 45288.61741518974, "episode/length": 288.0, "episode/score": 0.08188439676058579, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08188439676058579}
{"step": 390000, "time": 45296.52795791626, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 390000, "time": 45298.28486728668, "eval_episode/length": 264.0, "eval_episode/score": 0.17499999701976776, "eval_episode/reward_rate": 0.0037735849056603774}
{"step": 390000, "time": 45298.69593381882, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 45298.70209622383, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 45298.707386016846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 45298.71274995804, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 45298.71787953377, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 45298.72313928604, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390192, "time": 45320.70486783981, "episode/length": 288.0, "episode/score": 0.05572277170708162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05572277170708162}
{"step": 390376, "time": 45341.87390804291, "episode/length": 191.0, "episode/score": 0.44358226108869303, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0404572586905374}
{"step": 390576, "time": 45364.838148117065, "episode/length": 288.0, "episode/score": 0.04886473353926135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04886473353926135}
{"step": 391208, "time": 45437.596502542496, "episode/length": 288.0, "episode/score": 0.056378802051909815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056378802051909815}
{"step": 391312, "time": 45449.490902900696, "episode/length": 288.0, "episode/score": 0.03504291030264994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03504291030264994}
{"step": 391536, "time": 45475.25968050957, "episode/length": 222.0, "episode/score": 0.33349621802753404, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.02724620039643355}
{"step": 391680, "time": 45491.79536151886, "episode/length": 137.0, "episode/score": 0.5954634448642935, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.023588468924430117}
{"step": 392072, "time": 45536.771508693695, "episode/length": 94.0, "episode/score": 0.7214295679943348, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.015179579181847203}
{"step": 392216, "time": 45553.40602636337, "episode/length": 288.0, "episode/score": 0.036177201025992645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036177201025992645}
{"step": 392272, "time": 45559.83112502098, "episode/length": 288.0, "episode/score": 0.058575690659154134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058575690659154134}
{"step": 392504, "time": 45586.52979660034, "episode/length": 288.0, "episode/score": 0.041218819048964406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041218819048964406}
{"step": 392520, "time": 45588.38435983658, "episode/length": 122.0, "episode/score": 0.6376522978052037, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.01890234475550301}
{"step": 392688, "time": 45607.67258691788, "episode/length": 288.0, "episode/score": 0.03057181684496868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03057181684496868}
{"step": 393160, "time": 45661.809136390686, "episode/length": 243.0, "episode/score": 0.28153244915830555, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.04090745102968185}
{"step": 393992, "time": 45757.51319169998, "episode/length": 288.0, "episode/score": 0.04759197969900697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04759197969900697}
{"step": 394384, "time": 45803.01026415825, "episode/length": 288.0, "episode/score": 0.03763688608248117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03763688608248117}
{"step": 394528, "time": 45819.7464120388, "episode/length": 288.0, "episode/score": 0.02703865290214935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02703865290214935}
{"step": 394584, "time": 45826.1809694767, "episode/length": 288.0, "episode/score": 0.05063681013024279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05063681013024279}
{"step": 394816, "time": 45852.93632912636, "episode/length": 288.0, "episode/score": 0.03947732284268568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03947732284268568}
{"step": 394832, "time": 45854.760348558426, "episode/length": 288.0, "episode/score": 0.04641065648036147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04641065648036147}
{"step": 395000, "time": 45874.024455070496, "episode/length": 288.0, "episode/score": 0.030355993268898374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030355993268898374}
{"step": 395184, "time": 45895.06321501732, "episode/length": 99.0, "episode/score": 0.71442631985704, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.02380132606779739}
{"step": 395472, "time": 45928.140729665756, "episode/length": 288.0, "episode/score": 0.05351870251186597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05351870251186597}
{"step": 395616, "time": 45944.82739543915, "episode/length": 53.0, "episode/score": 0.8543261154408697, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.01995109181729049}
{"step": 395888, "time": 45976.12214565277, "episode/length": 169.0, "episode/score": 0.5060880162068884, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.034213016364049054}
{"step": 396304, "time": 46023.942427396774, "episode/length": 288.0, "episode/score": 0.034732249530833315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034732249530833315}
{"step": 396896, "time": 46091.956954717636, "episode/length": 288.0, "episode/score": 0.035286538016080726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035286538016080726}
{"step": 397040, "time": 46108.49339032173, "episode/length": 277.0, "episode/score": 0.16962413557008915, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.03524912981335149}
{"step": 397144, "time": 46120.45110321045, "episode/length": 288.0, "episode/score": 0.04938896633363754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04938896633363754}
{"step": 397312, "time": 46139.62210178375, "episode/length": 288.0, "episode/score": 0.029271143984104242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029271143984104242}
{"step": 397696, "time": 46183.56825494766, "episode/length": 259.0, "episode/score": 0.2436116466469258, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.05298664293327704}
{"step": 397784, "time": 46193.63777279854, "episode/length": 288.0, "episode/score": 0.03449197154054673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03449197154054673}
{"step": 397808, "time": 46196.40529727936, "episode/length": 113.0, "episode/score": 0.6668724271119544, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.01999742949264771}
{"step": 397976, "time": 46215.7276198864, "episode/length": 34.0, "episode/score": 0.9051448686068824, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.011394866755878752}
{"step": 398005, "time": 46219.94648742676, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7096080073603876, "train/action_min": 0.0, "train/action_std": 2.057045648495356, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00762971056866701, "train/actor_opt_grad_steps": 98035.0, "train/actor_opt_loss": -26.21285738326885, "train/adv_mag": 0.5044073984026909, "train/adv_max": 0.2586746613184611, "train/adv_mean": -0.00121514400012125, "train/adv_min": -0.4666630520864769, "train/adv_std": 0.030545560931959363, "train/cont_avg": 0.9956099898726852, "train/cont_loss_mean": 0.012837091404772192, "train/cont_loss_std": 0.20334885655514276, "train/cont_neg_acc": 0.4176079804121062, "train/cont_neg_loss": 2.3364784894283686, "train/cont_pos_acc": 0.9998955345816083, "train/cont_pos_loss": 0.0025305314920842648, "train/cont_pred": 0.9956551152798865, "train/cont_rate": 0.9956099898726852, "train/dyn_loss_mean": 1.0000012511456455, "train/dyn_loss_std": 3.287411514234177e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15040112957703294, "train/extr_critic_critic_opt_grad_steps": 98035.0, "train/extr_critic_critic_opt_loss": 10581.150894730179, "train/extr_critic_mag": 0.933574660508721, "train/extr_critic_max": 0.933574660508721, "train/extr_critic_mean": 0.6954966800080405, "train/extr_critic_min": 0.6040067921082178, "train/extr_critic_std": 0.06550380074488069, "train/extr_return_normed_mag": 0.5489751583448162, "train/extr_return_normed_max": 0.421382298624074, "train/extr_return_normed_mean": 0.0519262457533774, "train/extr_return_normed_min": -0.36989953258523234, "train/extr_return_normed_std": 0.0747949281465952, "train/extr_return_rate": 0.9994047526960019, "train/extr_return_raw_mag": 1.0637375218448815, "train/extr_return_raw_max": 1.0637375218448815, "train/extr_return_raw_mean": 0.6942815054897908, "train/extr_return_raw_min": 0.2724556906355752, "train/extr_return_raw_std": 0.07479492818108863, "train/extr_reward_mag": 0.4278839925924937, "train/extr_reward_max": 0.4278839925924937, "train/extr_reward_mean": 0.0013628614066908118, "train/extr_reward_min": 1.0717798162389684e-06, "train/extr_reward_std": 0.01374046702834743, "train/image_loss_mean": 0.08937357474739353, "train/image_loss_std": 0.1080246886100482, "train/model_loss_mean": 0.7168074970444044, "train/model_loss_std": 0.3423570717374484, "train/model_opt_grad_norm": 13.219677691106442, "train/model_opt_grad_steps": 97946.75, "train/model_opt_loss": 3681.6507941351997, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5138.888888888889, "train/policy_entropy_mag": 1.3425219296305269, "train/policy_entropy_max": 1.3425219296305269, "train/policy_entropy_mean": 0.11113441566488257, "train/policy_entropy_min": 0.06468649222343056, "train/policy_entropy_std": 0.143185007420403, "train/policy_logprob_mag": 6.551080332862006, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11085012130853203, "train/policy_logprob_min": -6.551080332862006, "train/policy_logprob_std": 0.6470808886267521, "train/policy_randomness_mag": 0.6899198343356451, "train/policy_randomness_max": 0.6899198343356451, "train/policy_randomness_mean": 0.05711179611238616, "train/policy_randomness_min": 0.03324228159531399, "train/policy_randomness_std": 0.07358254240480838, "train/post_ent_mag": 33.3428507204409, "train/post_ent_max": 33.3428507204409, "train/post_ent_mean": 33.10153290077492, "train/post_ent_min": 32.860507241001834, "train/post_ent_std": 0.09987313807424572, "train/prior_ent_mag": 34.044103693079066, "train/prior_ent_max": 34.044103693079066, "train/prior_ent_mean": 33.40406680990149, "train/prior_ent_min": 32.426898611916435, "train/prior_ent_std": 0.2786816483432496, "train/rep_loss_mean": 1.0000012511456455, "train/rep_loss_std": 3.287411514234177e-05, "train/reward_avg": 0.0009614579749823962, "train/reward_loss_mean": 0.014596058607653336, "train/reward_loss_std": 0.13160276661316553, "train/reward_max_data": 0.5027653413212478, "train/reward_max_pred": 0.18546834643240329, "train/reward_neg_acc": 0.9998597063952022, "train/reward_neg_loss": 0.009459234142451789, "train/reward_pos_acc": 0.30965447262292956, "train/reward_pos_loss": 3.8751876634068605, "train/reward_pred": 0.0007882798527134582, "train/reward_rate": 0.0013020833333333333, "train_stats/mean_log_entropy": 0.09943787250164393, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.010633708909153938, "report/cont_loss_std": 0.19407740235328674, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 1.7070016860961914, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0023100189864635468, "report/cont_pred": 0.9947548508644104, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0986555740237236, "report/image_loss_std": 0.11530960351228714, "report/model_loss_mean": 0.7250690460205078, "report/model_loss_std": 0.3120400607585907, "report/post_ent_mag": 33.398895263671875, "report/post_ent_max": 33.398895263671875, "report/post_ent_mean": 33.139244079589844, "report/post_ent_min": 32.874717712402344, "report/post_ent_std": 0.10770833492279053, "report/prior_ent_mag": 33.552940368652344, "report/prior_ent_max": 33.552940368652344, "report/prior_ent_mean": 32.65753173828125, "report/prior_ent_min": 31.609851837158203, "report/prior_ent_std": 0.34456387162208557, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001930559054017067, "report/reward_loss_mean": 0.015779735520482063, "report/reward_loss_std": 0.1269523650407791, "report/reward_max_data": 0.687749981880188, "report/reward_max_pred": 0.7933052778244019, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010249245911836624, "report/reward_pos_acc": 0.6666666865348816, "report/reward_pos_loss": 1.8979896306991577, "report/reward_pred": 0.002207798883318901, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03255850821733475, "eval/cont_loss_std": 0.5104773044586182, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.625797271728516, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.002781104063615203, "eval/cont_pred": 0.9972916841506958, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1792345941066742, "eval/image_loss_std": 0.15070922672748566, "eval/model_loss_mean": 0.8195090889930725, "eval/model_loss_std": 0.594523549079895, "eval/post_ent_mag": 33.39667510986328, "eval/post_ent_max": 33.39667510986328, "eval/post_ent_mean": 33.130489349365234, "eval/post_ent_min": 32.8598747253418, "eval/post_ent_std": 0.11493495106697083, "eval/prior_ent_mag": 33.53215408325195, "eval/prior_ent_max": 33.53215408325195, "eval/prior_ent_mean": 32.67189025878906, "eval/prior_ent_min": 31.633014678955078, "eval/prior_ent_std": 0.3430567681789398, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006103515625, "eval/reward_loss_mean": 0.00771597633138299, "eval/reward_loss_std": 0.16269098222255707, "eval/reward_max_data": 0.625, "eval/reward_max_pred": 0.04862713813781738, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0026337229646742344, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.2068610191345215, "eval/reward_pred": 0.0009740691166371107, "eval/reward_rate": 0.0009765625, "replay/size": 397501.0, "replay/inserts": 8648.0, "replay/samples": 34592.0, "replay/insert_wait_avg": 1.4825070157964178e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.673684476593046e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 91536.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1038202727954694e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3843574523926, "timer/env.step_count": 1081.0, "timer/env.step_total": 9.954362869262695, "timer/env.step_frac": 0.009950538305709578, "timer/env.step_avg": 0.009208476289789727, "timer/env.step_min": 0.008220672607421875, "timer/env.step_max": 0.033667802810668945, "timer/replay._sample_count": 34592.0, "timer/replay._sample_total": 16.644593715667725, "timer/replay._sample_frac": 0.01663819870000299, "timer/replay._sample_avg": 0.0004811688747591271, "timer/replay._sample_min": 0.0003414154052734375, "timer/replay._sample_max": 0.02245926856994629, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1370.0, "timer/agent.policy_total": 13.67406940460205, "timer/agent.policy_frac": 0.013668815693424902, "timer/agent.policy_avg": 0.009981072558103687, "timer/agent.policy_min": 0.008443117141723633, "timer/agent.policy_max": 0.07554316520690918, "timer/dataset_train_count": 2162.0, "timer/dataset_train_total": 0.38050079345703125, "timer/dataset_train_frac": 0.0003803546013314577, "timer/dataset_train_avg": 0.00017599481658512085, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.005412578582763672, "timer/agent.train_count": 2162.0, "timer/agent.train_total": 962.1164915561676, "timer/agent.train_frac": 0.9617468369920548, "timer/agent.train_avg": 0.4450122532637223, "timer/agent.train_min": 0.4330453872680664, "timer/agent.train_max": 0.5663034915924072, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47969508171081543, "timer/agent.report_frac": 0.0004795107781697233, "timer/agent.report_avg": 0.23984754085540771, "timer/agent.report_min": 0.23450803756713867, "timer/agent.report_max": 0.24518704414367676, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.002919902036402e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 8.644554248883889}
{"step": 398200, "time": 46242.308775663376, "episode/length": 288.0, "episode/score": 0.03570201686204655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03570201686204655}
{"step": 398616, "time": 46290.38562941551, "episode/length": 288.0, "episode/score": 0.03435979361596253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03435979361596253}
{"step": 398952, "time": 46329.326489925385, "episode/length": 204.0, "episode/score": 0.3819644699213427, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.019464453911325563}
{"step": 399352, "time": 46375.63190841675, "episode/length": 288.0, "episode/score": 0.03598701279584304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03598701279584304}
{"step": 399456, "time": 46387.72684311867, "episode/length": 288.0, "episode/score": 0.03636795417513383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03636795417513383}
{"step": 400088, "time": 46463.06033158302, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 400088, "time": 46464.293407440186, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 400088, "time": 46464.66847586632, "eval_episode/length": 222.0, "eval_episode/score": 0.3062500059604645, "eval_episode/reward_rate": 0.004484304932735426}
{"step": 400088, "time": 46464.81190752983, "eval_episode/length": 230.0, "eval_episode/score": 0.28125, "eval_episode/reward_rate": 0.004329004329004329}
{"step": 400088, "time": 46465.792345285416, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 46465.800483465195, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 46465.80644631386, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 46465.81215715408, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 46465.81771016121, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400096, "time": 46466.7433078289, "episode/length": 288.0, "episode/score": 0.02566547033367783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02566547033367783}
{"step": 400120, "time": 46469.543576955795, "episode/length": 288.0, "episode/score": 0.025112061780092176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025112061780092176}
{"step": 400288, "time": 46489.02770090103, "episode/length": 288.0, "episode/score": 0.04501698776670082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04501698776670082}
{"step": 400512, "time": 46515.09798645973, "episode/length": 288.0, "episode/score": 0.01786982508868107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01786982508868107}
{"step": 400672, "time": 46533.58463859558, "episode/length": 47.0, "episode/score": 0.8655175072559445, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.012392543175892001}
{"step": 400928, "time": 46563.20594620705, "episode/length": 288.0, "episode/score": 0.030946614048076526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030946614048076526}
{"step": 401264, "time": 46602.10060143471, "episode/length": 288.0, "episode/score": 0.047131086081847684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047131086081847684}
{"step": 401288, "time": 46604.87508893013, "episode/length": 228.0, "episode/score": 0.3255600976712003, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.038060113701590126}
{"step": 401320, "time": 46608.575103998184, "episode/length": 48.0, "episode/score": 0.8573045543650011, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.007304556745694413}
{"step": 401352, "time": 46612.254868745804, "episode/length": 84.0, "episode/score": 0.7574765948651248, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.019976592010038985}
{"step": 401664, "time": 46648.74100160599, "episode/length": 288.0, "episode/score": 0.04003572671392419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04003572671392419}
{"step": 401864, "time": 46671.83543300629, "episode/length": 74.0, "episode/score": 0.7791856753945012, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.010435673543497614}
{"step": 402168, "time": 46707.132961034775, "episode/length": 206.0, "episode/score": 0.379472699899452, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.023222721890306275}
{"step": 402344, "time": 46727.54379439354, "episode/length": 84.0, "episode/score": 0.7549746990160457, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.01747469616095998}
{"step": 402408, "time": 46734.945741176605, "episode/length": 288.0, "episode/score": 0.03725925452879153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03725925452879153}
{"step": 402432, "time": 46737.71156334877, "episode/length": 288.0, "episode/score": 0.02701489715008165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02701489715008165}
{"step": 402536, "time": 46749.87041282654, "episode/length": 45.0, "episode/score": 0.8677031156247352, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.00832808593155221}
{"step": 402576, "time": 46754.55891394615, "episode/length": 88.0, "episode/score": 0.7404051267970431, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.01540507973760441}
{"step": 403576, "time": 46870.30767917633, "episode/length": 281.0, "episode/score": 0.16888028294333424, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.047005278267803874}
{"step": 403592, "time": 46872.149117946625, "episode/length": 155.0, "episode/score": 0.5466487693024078, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.031023747052529416}
{"step": 403600, "time": 46873.09231543541, "episode/length": 288.0, "episode/score": 0.029000912665026135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029000912665026135}
{"step": 403664, "time": 46880.55887770653, "episode/length": 288.0, "episode/score": 0.061517757865303224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061517757865303224}
{"step": 403992, "time": 46918.491926431656, "episode/length": 40.0, "episode/score": 0.8945343439698235, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.01953432965073887}
{"step": 404144, "time": 46936.34438729286, "episode/length": 200.0, "episode/score": 0.4122397997013536, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.03723980051626086}
{"step": 404520, "time": 46980.24007296562, "episode/length": 263.0, "episode/score": 0.20898748550773405, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.03086249228310578}
{"step": 404744, "time": 47006.37989640236, "episode/length": 288.0, "episode/score": 0.04764590400199609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04764590400199609}
{"step": 404888, "time": 47023.107482910156, "episode/length": 288.0, "episode/score": 0.06527785040650258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06527785040650258}
{"step": 405720, "time": 47119.34517621994, "episode/length": 267.0, "episode/score": 0.19341783813813151, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.027792832759743646}
{"step": 405904, "time": 47140.678116083145, "episode/length": 288.0, "episode/score": 0.04944397920331767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04944397920331767}
{"step": 405912, "time": 47141.60086131096, "episode/length": 288.0, "episode/score": 0.04971092430145063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04971092430145063}
{"step": 406208, "time": 47176.12621426582, "episode/length": 276.0, "episode/score": 0.212161931262699, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.07466193474351712}
{"step": 406312, "time": 47188.125475645065, "episode/length": 177.0, "episode/score": 0.4777329662725833, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.030857953152576556}
{"step": 406408, "time": 47199.321521520615, "episode/length": 85.0, "episode/score": 0.7606492868316082, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.026274287646515404}
{"step": 406456, "time": 47204.86091685295, "episode/length": 288.0, "episode/score": 0.05809695772256873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05809695772256873}
{"step": 406581, "time": 47220.17647123337, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.663567944107769, "train/action_min": 0.0, "train/action_std": 1.9788557402441436, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006282347985586831, "train/actor_opt_grad_steps": 100185.0, "train/actor_opt_loss": -19.64418179966579, "train/adv_mag": 0.39899015635530527, "train/adv_max": 0.21165736702000984, "train/adv_mean": -0.0008925986222508395, "train/adv_min": -0.36064914606999016, "train/adv_std": 0.018285422320434144, "train/cont_avg": 0.9958518910630841, "train/cont_loss_mean": 0.012839812470956872, "train/cont_loss_std": 0.2054823679919137, "train/cont_neg_acc": 0.40711187029108753, "train/cont_neg_loss": 2.494472515713828, "train/cont_pos_acc": 0.9998579576750782, "train/cont_pos_loss": 0.0026938857523741843, "train/cont_pred": 0.9957460655230228, "train/cont_rate": 0.9958518910630841, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1081198238349894, "train/extr_critic_critic_opt_grad_steps": 100185.0, "train/extr_critic_critic_opt_loss": 7065.70518536434, "train/extr_critic_mag": 0.7760404443072382, "train/extr_critic_max": 0.7760404443072382, "train/extr_critic_mean": 0.6170284569820511, "train/extr_critic_min": 0.5126011973229524, "train/extr_critic_std": 0.03584392071118422, "train/extr_return_normed_mag": 0.4311256756849378, "train/extr_return_normed_max": 0.2929955080290821, "train/extr_return_normed_mean": 0.04075011425155485, "train/extr_return_normed_min": -0.3146591920440442, "train/extr_return_normed_std": 0.04092954845977164, "train/extr_return_rate": 0.9992312563356952, "train/extr_return_raw_mag": 0.86838123118766, "train/extr_return_raw_max": 0.86838123118766, "train/extr_return_raw_mean": 0.6161358690707484, "train/extr_return_raw_min": 0.2607265311145337, "train/extr_return_raw_std": 0.04092954839014004, "train/extr_reward_mag": 0.396415000764009, "train/extr_reward_max": 0.396415000764009, "train/extr_reward_mean": 0.0008404599430603106, "train/extr_reward_min": 1.12691772318332e-06, "train/extr_reward_std": 0.007077272696350919, "train/image_loss_mean": 0.0899027133726071, "train/image_loss_std": 0.10805763843878408, "train/model_loss_mean": 0.717960671565243, "train/model_loss_std": 0.3544175419086051, "train/model_opt_grad_norm": 13.261394828279442, "train/model_opt_grad_steps": 100094.72429906542, "train/model_opt_loss": 3927.5617858316295, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5467.289719626168, "train/policy_entropy_mag": 1.5167568225726904, "train/policy_entropy_max": 1.5167568225726904, "train/policy_entropy_mean": 0.11179648033369367, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.15287703738730646, "train/policy_logprob_mag": 6.551080282603468, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11198859759301782, "train/policy_logprob_min": -6.551080282603468, "train/policy_logprob_std": 0.6535098549918593, "train/policy_randomness_mag": 0.7794588637129168, "train/policy_randomness_max": 0.7794588637129168, "train/policy_randomness_mean": 0.05745202974877625, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07856326092417552, "train/post_ent_mag": 33.488986469874874, "train/post_ent_max": 33.488986469874874, "train/post_ent_mean": 33.195128360641334, "train/post_ent_min": 32.89455549293589, "train/post_ent_std": 0.12167718202293476, "train/prior_ent_mag": 33.54432842218987, "train/prior_ent_max": 33.54432842218987, "train/prior_ent_mean": 32.917819620292875, "train/prior_ent_min": 32.29666641271003, "train/prior_ent_std": 0.21595512428016306, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0010653410350879933, "train/reward_loss_mean": 0.015218124374590605, "train/reward_loss_std": 0.1444938786971931, "train/reward_max_data": 0.5385614169530883, "train/reward_max_pred": 0.22240202114960858, "train/reward_neg_acc": 0.9998308921528754, "train/reward_neg_loss": 0.00945621912550425, "train/reward_pos_acc": 0.29494047732580275, "train/reward_pos_loss": 3.972624573147013, "train/reward_pred": 0.0008832908564064408, "train/reward_rate": 0.0015059141355140188, "train_stats/mean_log_entropy": 0.08749576944571275, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.009738929569721222, "report/cont_loss_std": 0.17238181829452515, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.9458034038543701, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0021465192548930645, "report/cont_pred": 0.9958919286727905, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1110529750585556, "report/image_loss_std": 0.12117115408182144, "report/model_loss_mean": 0.7411564588546753, "report/model_loss_std": 0.4191461503505707, "report/post_ent_mag": 33.308799743652344, "report/post_ent_max": 33.308799743652344, "report/post_ent_mean": 33.0267333984375, "report/post_ent_min": 32.72986602783203, "report/post_ent_std": 0.11945032328367233, "report/prior_ent_mag": 33.41743469238281, "report/prior_ent_max": 33.41743469238281, "report/prior_ent_mean": 32.93694305419922, "report/prior_ent_min": 32.355751037597656, "report/prior_ent_std": 0.1961732655763626, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001621768344193697, "report/reward_loss_mean": 0.02036452293395996, "report/reward_loss_std": 0.20938801765441895, "report/reward_max_data": 0.7442499995231628, "report/reward_max_pred": 0.04829967021942139, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.011156918480992317, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.72545051574707, "report/reward_pred": 0.0007031062850728631, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.05943131819367409, "eval/cont_loss_std": 0.74463951587677, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.13076400756836, "eval/cont_pos_acc": 0.9990177154541016, "eval/cont_pos_loss": 0.005965705960988998, "eval/cont_pred": 0.9964030981063843, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23339535295963287, "eval/image_loss_std": 0.17548109591007233, "eval/model_loss_mean": 0.9147233963012695, "eval/model_loss_std": 0.9898562431335449, "eval/post_ent_mag": 33.308448791503906, "eval/post_ent_max": 33.308448791503906, "eval/post_ent_mean": 33.00477600097656, "eval/post_ent_min": 32.72408676147461, "eval/post_ent_std": 0.120785191655159, "eval/prior_ent_mag": 33.515098571777344, "eval/prior_ent_max": 33.515098571777344, "eval/prior_ent_mean": 32.920467376708984, "eval/prior_ent_min": 32.36532974243164, "eval/prior_ent_std": 0.19817674160003662, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0013397217262536287, "eval/reward_loss_mean": 0.021896742284297943, "eval/reward_loss_std": 0.40975114703178406, "eval/reward_max_data": 0.753125011920929, "eval/reward_max_pred": 0.47307634353637695, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.005730301607400179, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.28294849395752, "eval/reward_pred": 0.0011037212098017335, "eval/reward_rate": 0.001953125, "replay/size": 406077.0, "replay/inserts": 8576.0, "replay/samples": 34304.0, "replay/insert_wait_avg": 1.4823319307014123e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.78210363281307e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 93848.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0543216058539684e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.213392496109, "timer/env.step_count": 1072.0, "timer/env.step_total": 10.02952766418457, "timer/env.step_frac": 0.010027387894852234, "timer/env.step_avg": 0.009355902671813965, "timer/env.step_min": 0.008300542831420898, "timer/env.step_max": 0.04387402534484863, "timer/replay._sample_count": 34304.0, "timer/replay._sample_total": 16.658140659332275, "timer/replay._sample_frac": 0.01665458669550566, "timer/replay._sample_avg": 0.0004856034473919157, "timer/replay._sample_min": 0.00038433074951171875, "timer/replay._sample_max": 0.018735408782958984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1361.0, "timer/agent.policy_total": 13.242427587509155, "timer/agent.policy_frac": 0.013239602355714978, "timer/agent.policy_avg": 0.0097299247520273, "timer/agent.policy_min": 0.008791923522949219, "timer/agent.policy_max": 0.03620481491088867, "timer/dataset_train_count": 2144.0, "timer/dataset_train_total": 0.37766075134277344, "timer/dataset_train_frac": 0.000377580178565988, "timer/dataset_train_avg": 0.0001761477384994279, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0011887550354003906, "timer/agent.train_count": 2144.0, "timer/agent.train_total": 962.4026305675507, "timer/agent.train_frac": 0.9621973048829123, "timer/agent.train_avg": 0.44888182395874565, "timer/agent.train_min": 0.43456482887268066, "timer/agent.train_max": 0.586240291595459, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47954726219177246, "timer/agent.report_frac": 0.0004794449522366678, "timer/agent.report_avg": 0.23977363109588623, "timer/agent.report_min": 0.2310042381286621, "timer/agent.report_max": 0.24854302406311035, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.693555159388787e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 8.57404813900799}
{"step": 406784, "time": 47243.60123348236, "episode/length": 40.0, "episode/score": 0.8881482536339718, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.01314824647442947}
{"step": 406832, "time": 47249.20943951607, "episode/length": 288.0, "episode/score": 0.04657814293057072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04657814293057072}
{"step": 406848, "time": 47251.11179757118, "episode/length": 116.0, "episode/score": 0.6636071978732616, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.02610718645291854}
{"step": 407056, "time": 47275.142339229584, "episode/length": 288.0, "episode/score": 0.054215454764175774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054215454764175774}
{"step": 407112, "time": 47281.61617350578, "episode/length": 150.0, "episode/score": 0.5697186204688478, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.03846864060869848}
{"step": 407528, "time": 47329.386999607086, "episode/length": 58.0, "episode/score": 0.8311635682805445, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.012413515043817824}
{"step": 407928, "time": 47375.78858804703, "episode/length": 214.0, "episode/score": 0.36603044544710883, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.03478043998723024}
{"step": 408264, "time": 47414.37038183212, "episode/length": 41.0, "episode/score": 0.8840229164685525, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.012147948529332098}
{"step": 408624, "time": 47455.7624437809, "episode/length": 288.0, "episode/score": 0.030422084799226923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030422084799226923}
{"step": 408720, "time": 47466.9220058918, "episode/length": 288.0, "episode/score": 0.036440237593694746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036440237593694746}
{"step": 409096, "time": 47510.2859184742, "episode/length": 288.0, "episode/score": 0.03028248242230802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03028248242230802}
{"step": 409144, "time": 47515.85055065155, "episode/length": 288.0, "episode/score": 0.043563275900510234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043563275900510234}
{"step": 409160, "time": 47517.70560860634, "episode/length": 288.0, "episode/score": 0.028022819858733783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028022819858733783}
{"step": 409208, "time": 47523.32585525513, "episode/length": 72.0, "episode/score": 0.7847913732009602, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.009791420151259445}
{"step": 409424, "time": 47548.27716755867, "episode/length": 288.0, "episode/score": 0.02096239682475698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02096239682475698}
{"step": 409840, "time": 47596.659386873245, "episode/length": 288.0, "episode/score": 0.0733022149225917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0733022149225917}
{"step": 409968, "time": 47611.480892419815, "episode/length": 102.0, "episode/score": 0.7244804985692213, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.043230493772909995}
{"step": 410072, "time": 47624.88266634941, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 410072, "time": 47625.610466718674, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 410072, "time": 47625.916004657745, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 410072, "time": 47626.84304141998, "eval_episode/length": 208.0, "eval_episode/score": 0.3499999940395355, "eval_episode/reward_rate": 0.004784688995215311}
{"step": 410072, "time": 47627.681235313416, "eval_episode/length": 259.0, "eval_episode/score": 0.19062499701976776, "eval_episode/reward_rate": 0.0038461538461538464}
{"step": 410072, "time": 47628.16444063187, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 47628.170635938644, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 47628.1759057045, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 47628.181208372116, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410576, "time": 47686.28656744957, "episode/length": 288.0, "episode/score": 0.0538329267114932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0538329267114932}
{"step": 411032, "time": 47738.85876584053, "episode/length": 288.0, "episode/score": 0.06048051355850248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06048051355850248}
{"step": 411408, "time": 47782.07062935829, "episode/length": 288.0, "episode/score": 0.05110781218786542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05110781218786542}
{"step": 411472, "time": 47789.41170692444, "episode/length": 288.0, "episode/score": 0.055880162648065834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055880162648065834}
{"step": 411504, "time": 47793.14090204239, "episode/length": 58.0, "episode/score": 0.8393491226411243, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.020599070161097188}
{"step": 411520, "time": 47795.000336408615, "episode/length": 288.0, "episode/score": 0.058415217635740646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058415217635740646}
{"step": 411720, "time": 47817.97159028053, "episode/length": 24.0, "episode/score": 0.936062133039286, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.011062092480187857}
{"step": 411736, "time": 47819.80639195442, "episode/length": 288.0, "episode/score": 0.06196549264200257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06196549264200257}
{"step": 412152, "time": 47867.66995692253, "episode/length": 288.0, "episode/score": 0.07374918033497124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07374918033497124}
{"step": 412280, "time": 47882.592483997345, "episode/length": 288.0, "episode/score": 0.042332844098154965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042332844098154965}
{"step": 412888, "time": 47952.78599238396, "episode/length": 288.0, "episode/score": 0.06171678189969043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06171678189969043}
{"step": 413720, "time": 48049.069601774216, "episode/length": 288.0, "episode/score": 0.03886144200009767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03886144200009767}
{"step": 413784, "time": 48056.50672221184, "episode/length": 288.0, "episode/score": 0.03762405714473971, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03762405714473971}
{"step": 413816, "time": 48060.224180698395, "episode/length": 288.0, "episode/score": 0.04191023863143073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04191023863143073}
{"step": 414032, "time": 48085.18517279625, "episode/length": 288.0, "episode/score": 0.05488473823743334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05488473823743334}
{"step": 414048, "time": 48087.03668761253, "episode/length": 288.0, "episode/score": 0.03294030988581653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03294030988581653}
{"step": 414216, "time": 48106.436576128006, "episode/length": 165.0, "episode/score": 0.5030351502598478, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.01866015107475505}
{"step": 414464, "time": 48134.99685692787, "episode/length": 288.0, "episode/score": 0.04659480889131373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04659480889131373}
{"step": 414592, "time": 48149.643460989, "episode/length": 288.0, "episode/score": 0.03086801753704549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03086801753704549}
{"step": 415197, "time": 48220.28843784332, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9690673262984664, "train/action_min": 0.0, "train/action_std": 1.6810148507356644, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006459448728559504, "train/actor_opt_grad_steps": 102335.0, "train/actor_opt_loss": -14.201598982016245, "train/adv_mag": 0.4292257443346359, "train/adv_max": 0.16518750372860166, "train/adv_mean": 0.0016509512414586425, "train/adv_min": -0.39658181631454714, "train/adv_std": 0.01811441988253069, "train/cont_avg": 0.9957320601851852, "train/cont_loss_mean": 0.012390453511249722, "train/cont_loss_std": 0.1942935584833052, "train/cont_neg_acc": 0.4291872518583083, "train/cont_neg_loss": 2.323987489114141, "train/cont_pos_acc": 0.9998728721230118, "train/cont_pos_loss": 0.0024800277196509006, "train/cont_pred": 0.9957557403379016, "train/cont_rate": 0.9957320601851852, "train/dyn_loss_mean": 1.0000029112453814, "train/dyn_loss_std": 6.455933908000588e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15277131747764847, "train/extr_critic_critic_opt_grad_steps": 102335.0, "train/extr_critic_critic_opt_loss": 9648.18194127966, "train/extr_critic_mag": 0.7740012937121921, "train/extr_critic_max": 0.7740012937121921, "train/extr_critic_mean": 0.6505099576380518, "train/extr_critic_min": 0.5510203126404021, "train/extr_critic_std": 0.02568983626379459, "train/extr_return_normed_mag": 0.45129374304303416, "train/extr_return_normed_max": 0.23365424656205708, "train/extr_return_normed_mean": 0.04163872019422275, "train/extr_return_normed_min": -0.35720758981726786, "train/extr_return_normed_std": 0.031135525006835384, "train/extr_return_rate": 0.999206727301633, "train/extr_return_raw_mag": 0.8441764461221518, "train/extr_return_raw_max": 0.8441764461221518, "train/extr_return_raw_mean": 0.6521609549721082, "train/extr_return_raw_min": 0.2533146100187743, "train/extr_return_raw_std": 0.031135525062887207, "train/extr_reward_mag": 0.2697510757931956, "train/extr_reward_max": 0.2697510757931956, "train/extr_reward_mean": 0.000613731416335752, "train/extr_reward_min": 1.2732214397854275e-06, "train/extr_reward_std": 0.0048527797480346635, "train/image_loss_mean": 0.08886175795837685, "train/image_loss_std": 0.10707028410225003, "train/model_loss_mean": 0.7159535068052786, "train/model_loss_std": 0.3348069305152253, "train/model_opt_grad_norm": 13.127824800985831, "train/model_opt_grad_steps": 102242.70833333333, "train/model_opt_loss": 3714.0154678909867, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5185.185185185185, "train/policy_entropy_mag": 1.371583601390874, "train/policy_entropy_max": 1.371583601390874, "train/policy_entropy_mean": 0.10570446156931144, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1389056940873464, "train/policy_logprob_mag": 6.551080248973988, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10541789285424683, "train/policy_logprob_min": -6.551080248973988, "train/policy_logprob_std": 0.6441732948576963, "train/policy_randomness_mag": 0.7048545808151916, "train/policy_randomness_max": 0.7048545808151916, "train/policy_randomness_mean": 0.05432135040906293, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07138341053009585, "train/post_ent_mag": 33.637062584912336, "train/post_ent_max": 33.637062584912336, "train/post_ent_mean": 33.383271058400474, "train/post_ent_min": 33.13671583599515, "train/post_ent_std": 0.10324552396519317, "train/prior_ent_mag": 33.60655528527719, "train/prior_ent_max": 33.60655528527719, "train/prior_ent_mean": 32.93342217692622, "train/prior_ent_min": 32.31555343557287, "train/prior_ent_std": 0.19380964787194022, "train/rep_loss_mean": 1.0000029112453814, "train/rep_loss_std": 6.455933908000588e-05, "train/reward_avg": 0.0010252845738621006, "train/reward_loss_mean": 0.014699523272510204, "train/reward_loss_std": 0.13128407915657456, "train/reward_max_data": 0.5057776185071647, "train/reward_max_pred": 0.21531489381083735, "train/reward_neg_acc": 0.999818926608121, "train/reward_neg_loss": 0.009525262418685964, "train/reward_pos_acc": 0.3066056924985676, "train/reward_pos_loss": 3.7281101440511097, "train/reward_pred": 0.0008449039467248238, "train/reward_rate": 0.001365379050925926, "train_stats/mean_log_entropy": 0.08193816948268148, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.013402513228356838, "report/cont_loss_std": 0.19309839606285095, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.1617724895477295, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002860954264178872, "report/cont_pred": 0.9953240752220154, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07807643711566925, "report/image_loss_std": 0.09846927970647812, "report/model_loss_mean": 0.7102479934692383, "report/model_loss_std": 0.4050979018211365, "report/post_ent_mag": 33.57423400878906, "report/post_ent_max": 33.57423400878906, "report/post_ent_mean": 33.34571838378906, "report/post_ent_min": 33.11820983886719, "report/post_ent_std": 0.09796859323978424, "report/prior_ent_mag": 33.45343780517578, "report/prior_ent_max": 33.45343780517578, "report/prior_ent_mean": 32.89104461669922, "report/prior_ent_min": 32.39869689941406, "report/prior_ent_std": 0.189878448843956, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0018588005332276225, "report/reward_loss_mean": 0.0187690332531929, "report/reward_loss_std": 0.19743864238262177, "report/reward_max_data": 0.8785417079925537, "report/reward_max_pred": 0.7463079690933228, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010039795190095901, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 2.989619255065918, "report/reward_pred": 0.001654558116570115, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.05079621821641922, "eval/cont_loss_std": 0.6716008186340332, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.209242820739746, "eval/cont_pos_acc": 0.9980372786521912, "eval/cont_pos_loss": 0.005857822485268116, "eval/cont_pred": 0.9958130121231079, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18646180629730225, "eval/image_loss_std": 0.16956110298633575, "eval/model_loss_mean": 0.8601549863815308, "eval/model_loss_std": 1.0153218507766724, "eval/post_ent_mag": 33.56481170654297, "eval/post_ent_max": 33.56481170654297, "eval/post_ent_mean": 33.346134185791016, "eval/post_ent_min": 33.075401306152344, "eval/post_ent_std": 0.0939551591873169, "eval/prior_ent_mag": 33.45153045654297, "eval/prior_ent_max": 33.45153045654297, "eval/prior_ent_mean": 32.86362075805664, "eval/prior_ent_min": 32.29911804199219, "eval/prior_ent_std": 0.18343281745910645, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0012908935314044356, "eval/reward_loss_mean": 0.022896988317370415, "eval/reward_loss_std": 0.4408396780490875, "eval/reward_max_data": 0.890625, "eval/reward_max_pred": 0.3407498598098755, "eval/reward_neg_acc": 0.9980430603027344, "eval/reward_neg_loss": 0.004143138416111469, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.60611343383789, "eval/reward_pred": 0.001478566904552281, "eval/reward_rate": 0.001953125, "replay/size": 414693.0, "replay/inserts": 8616.0, "replay/samples": 34464.0, "replay/insert_wait_avg": 1.4902544774274197e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.706681333876586e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 96160.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.06597441702978e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0989053249359, "timer/env.step_count": 1077.0, "timer/env.step_total": 10.087250709533691, "timer/env.step_frac": 0.010086253125390939, "timer/env.step_avg": 0.009366063797152917, "timer/env.step_min": 0.008253097534179688, "timer/env.step_max": 0.034898996353149414, "timer/replay._sample_count": 34464.0, "timer/replay._sample_total": 16.81095314025879, "timer/replay._sample_frac": 0.016809290611908875, "timer/replay._sample_avg": 0.00048778299501679403, "timer/replay._sample_min": 0.00036263465881347656, "timer/replay._sample_max": 0.02010655403137207, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1366.0, "timer/agent.policy_total": 13.311187505722046, "timer/agent.policy_frac": 0.013309871088597174, "timer/agent.policy_avg": 0.009744646783105451, "timer/agent.policy_min": 0.008766412734985352, "timer/agent.policy_max": 0.04101681709289551, "timer/dataset_train_count": 2154.0, "timer/dataset_train_total": 0.4179506301879883, "timer/dataset_train_frac": 0.00041790929673320116, "timer/dataset_train_avg": 0.00019403464725533347, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.03475141525268555, "timer/agent.train_count": 2154.0, "timer/agent.train_total": 962.0739145278931, "timer/agent.train_frac": 0.9619787697050939, "timer/agent.train_avg": 0.4466452713685669, "timer/agent.train_min": 0.43300795555114746, "timer/agent.train_max": 0.5944585800170898, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47738218307495117, "timer/agent.report_frac": 0.0004773349721044319, "timer/agent.report_avg": 0.23869109153747559, "timer/agent.report_min": 0.2321643829345703, "timer/agent.report_max": 0.24521780014038086, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9799375070821045e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 8.615026079655651}
{"step": 415288, "time": 48230.57741308212, "episode/length": 195.0, "episode/score": 0.4112990307890527, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.02067403195320594}
{"step": 415712, "time": 48279.51730179787, "episode/length": 207.0, "episode/score": 0.40999703092694517, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.05687202578138795}
{"step": 416096, "time": 48323.57767701149, "episode/length": 288.0, "episode/score": 0.04133331027685472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04133331027685472}
{"step": 416128, "time": 48327.25187134743, "episode/length": 288.0, "episode/score": 0.04279439757522141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04279439757522141}
{"step": 416344, "time": 48352.094816446304, "episode/length": 288.0, "episode/score": 0.030000566052592603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030000566052592603}
{"step": 416528, "time": 48373.41710948944, "episode/length": 288.0, "episode/score": 0.03172213683501468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03172213683501468}
{"step": 416776, "time": 48402.107328891754, "episode/length": 288.0, "episode/score": 0.01995895370009748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01995895370009748}
{"step": 416904, "time": 48416.86435651779, "episode/length": 288.0, "episode/score": 0.04391451744237429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04391451744237429}
{"step": 417136, "time": 48443.74586772919, "episode/length": 98.0, "episode/score": 0.7264950014563851, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.03274496329544263}
{"step": 417600, "time": 48497.54495763779, "episode/length": 288.0, "episode/score": 0.033926915294614446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033926915294614446}
{"step": 417856, "time": 48527.606967926025, "episode/length": 89.0, "episode/score": 0.7516455890286693, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.029770548469571168}
{"step": 417984, "time": 48542.4239654541, "episode/length": 150.0, "episode/score": 0.5677672052834737, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.03651717664530452}
{"step": 418024, "time": 48547.03977584839, "episode/length": 288.0, "episode/score": 0.048439990521501386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048439990521501386}
{"step": 418408, "time": 48591.516971349716, "episode/length": 288.0, "episode/score": 0.026967484591295943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026967484591295943}
{"step": 418440, "time": 48595.20462346077, "episode/length": 288.0, "episode/score": 0.034335050006689016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034335050006689016}
{"step": 418840, "time": 48641.42992448807, "episode/length": 288.0, "episode/score": 0.043124063648122046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043124063648122046}
{"step": 418848, "time": 48642.36141514778, "episode/length": 242.0, "episode/score": 0.2758277564859668, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.03207775134040958}
{"step": 419304, "time": 48695.177227020264, "episode/length": 57.0, "episode/score": 0.842348487333993, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.020473482537681775}
{"step": 419880, "time": 48762.192546606064, "episode/length": 179.0, "episode/score": 0.49824699908413095, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.057621987978109246}
{"step": 419912, "time": 48765.88975763321, "episode/length": 288.0, "episode/score": 0.03841312671761443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03841312671761443}
{"step": 420056, "time": 48784.54519414902, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 420056, "time": 48786.984646081924, "eval_episode/length": 225.0, "eval_episode/score": 0.296875, "eval_episode/reward_rate": 0.004424778761061947}
{"step": 420056, "time": 48788.02750372887, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 48788.033482313156, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 48788.03904771805, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 48788.04435300827, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 48788.04953503609, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 48788.05783009529, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420080, "time": 48790.859750032425, "episode/length": 153.0, "episode/score": 0.5438036105146011, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.021928563331471196}
{"step": 420136, "time": 48797.38784480095, "episode/length": 284.0, "episode/score": 0.16996921078964533, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.057469212780347334}
{"step": 420296, "time": 48816.06483626366, "episode/length": 288.0, "episode/score": 0.036908239982153646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036908239982153646}
{"step": 420336, "time": 48820.65555715561, "episode/length": 288.0, "episode/score": 0.041686775999437486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041686775999437486}
{"step": 420680, "time": 48860.16305065155, "episode/length": 42.0, "episode/score": 0.8834588577706199, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.014708882427385106}
{"step": 420720, "time": 48864.76644515991, "episode/length": 288.0, "episode/score": 0.06067531063081333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06067531063081333}
{"step": 421408, "time": 48943.75463795662, "episode/length": 165.0, "episode/score": 0.5229969591753729, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.038621959990280175}
{"step": 421616, "time": 48967.60402393341, "episode/length": 288.0, "episode/score": 0.05798097303261329, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05798097303261329}
{"step": 422192, "time": 49034.066400527954, "episode/length": 288.0, "episode/score": 0.07112283207294468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07112283207294468}
{"step": 422224, "time": 49037.75394487381, "episode/length": 288.0, "episode/score": 0.05332708281474652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05332708281474652}
{"step": 422264, "time": 49042.34192967415, "episode/length": 106.0, "episode/score": 0.6841342594049706, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.015384247984627564}
{"step": 422272, "time": 49043.260046720505, "episode/length": 193.0, "episode/score": 0.4284629710600143, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0315879774279324}
{"step": 422448, "time": 49063.50072813034, "episode/length": 288.0, "episode/score": 0.06123148197337969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06123148197337969}
{"step": 422608, "time": 49081.934341430664, "episode/length": 288.0, "episode/score": 0.047093936734881936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047093936734881936}
{"step": 422640, "time": 49085.62141895294, "episode/length": 244.0, "episode/score": 0.27218019639769864, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.03468020461662036}
{"step": 422912, "time": 49116.95061588287, "episode/length": 85.0, "episode/score": 0.7487958259390552, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.014420826157333977}
{"step": 422960, "time": 49122.455726623535, "episode/length": 39.0, "episode/score": 0.8879054131708699, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.009780393071764593}
{"step": 423400, "time": 49173.11465191841, "episode/length": 141.0, "episode/score": 0.6071564787712873, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.04778147637313168}
{"step": 423805, "time": 49220.38973879814, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6888092750726744, "train/action_min": 0.0, "train/action_std": 1.4813816724821578, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0058947550576873295, "train/actor_opt_grad_steps": 104490.0, "train/actor_opt_loss": -16.683319930143135, "train/adv_mag": 0.4030833263729894, "train/adv_max": 0.1573377761729928, "train/adv_mean": -0.001173168639432037, "train/adv_min": -0.37191384670346284, "train/adv_std": 0.01573010026368984, "train/cont_avg": 0.9957985101744186, "train/cont_loss_mean": 0.01222478733289727, "train/cont_loss_std": 0.19337438236662122, "train/cont_neg_acc": 0.44047248836989716, "train/cont_neg_loss": 2.286040591802524, "train/cont_pos_acc": 0.9998859452646832, "train/cont_pos_loss": 0.002540007383064475, "train/cont_pred": 0.9957315716632577, "train/cont_rate": 0.9957985101744186, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09391528646526641, "train/extr_critic_critic_opt_grad_steps": 104490.0, "train/extr_critic_critic_opt_loss": 10280.797581304505, "train/extr_critic_mag": 0.8128342007481775, "train/extr_critic_max": 0.8128342007481775, "train/extr_critic_mean": 0.6716249438219293, "train/extr_critic_min": 0.582480325255283, "train/extr_critic_std": 0.027432126538871334, "train/extr_return_normed_mag": 0.43305249158726183, "train/extr_return_normed_max": 0.23391171943309697, "train/extr_return_normed_mean": 0.029399516472462996, "train/extr_return_normed_min": -0.32536017562067787, "train/extr_return_normed_std": 0.03271905405143666, "train/extr_return_rate": 0.999633930450262, "train/extr_return_raw_mag": 0.8749639419622199, "train/extr_return_raw_max": 0.8749639419622199, "train/extr_return_raw_mean": 0.6704517711040585, "train/extr_return_raw_min": 0.31569204690844516, "train/extr_return_raw_std": 0.032719053956138534, "train/extr_reward_mag": 0.28111176158106604, "train/extr_reward_max": 0.28111176158106604, "train/extr_reward_mean": 0.0007860874498620369, "train/extr_reward_min": 1.0701112968977108e-06, "train/extr_reward_std": 0.005389674072868602, "train/image_loss_mean": 0.08734994520281636, "train/image_loss_std": 0.10619517024173293, "train/model_loss_mean": 0.7140041634093883, "train/model_loss_std": 0.3283755811840989, "train/model_opt_grad_norm": 13.11579615570778, "train/model_opt_grad_steps": 104395.86046511628, "train/model_opt_loss": 4317.067528161338, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6046.511627906977, "train/policy_entropy_mag": 1.281157781356989, "train/policy_entropy_max": 1.281157781356989, "train/policy_entropy_mean": 0.09657811903676321, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12009784035211386, "train/policy_logprob_mag": 6.551080266819444, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09642568864794665, "train/policy_logprob_min": -6.551080266819444, "train/policy_logprob_std": 0.6337316546329232, "train/policy_randomness_mag": 0.658384898374247, "train/policy_randomness_max": 0.658384898374247, "train/policy_randomness_mean": 0.049631338826445645, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06171808450721031, "train/post_ent_mag": 33.829112598507905, "train/post_ent_max": 33.829112598507905, "train/post_ent_mean": 33.60561794902003, "train/post_ent_min": 33.393993555113326, "train/post_ent_std": 0.08892902652191562, "train/prior_ent_mag": 33.48035249931868, "train/prior_ent_max": 33.48035249931868, "train/prior_ent_mean": 32.8763691214628, "train/prior_ent_min": 32.24631644847781, "train/prior_ent_std": 0.20494789266309074, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0009947089072273568, "train/reward_loss_mean": 0.014429407107622125, "train/reward_loss_std": 0.12541665119054013, "train/reward_max_data": 0.495732547038473, "train/reward_max_pred": 0.20958534562310507, "train/reward_neg_acc": 0.9998544493386912, "train/reward_neg_loss": 0.00944485312630964, "train/reward_pos_acc": 0.31153846360169923, "train/reward_pos_loss": 3.701765316419112, "train/reward_pred": 0.0008411572033236193, "train/reward_rate": 0.0013581031976744185, "train_stats/mean_log_entropy": 0.08382994171820189, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.017334595322608948, "report/cont_loss_std": 0.28025922179222107, "report/cont_neg_acc": 0.5714285969734192, "report/cont_neg_loss": 2.2458550930023193, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.001995714381337166, "report/cont_pred": 0.9947051405906677, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08962827920913696, "report/image_loss_std": 0.10774529725313187, "report/model_loss_mean": 0.7274808287620544, "report/model_loss_std": 0.5313370823860168, "report/post_ent_mag": 33.757476806640625, "report/post_ent_max": 33.757476806640625, "report/post_ent_mean": 33.548919677734375, "report/post_ent_min": 33.33982467651367, "report/post_ent_std": 0.08964809030294418, "report/prior_ent_mag": 33.513362884521484, "report/prior_ent_max": 33.513362884521484, "report/prior_ent_mean": 32.809471130371094, "report/prior_ent_min": 32.05268096923828, "report/prior_ent_std": 0.2736321985721588, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0026069674640893936, "report/reward_loss_mean": 0.020517954602837563, "report/reward_loss_std": 0.25702008605003357, "report/reward_max_data": 0.8973750472068787, "report/reward_max_pred": 0.8856639862060547, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009084843099117279, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.9115867614746094, "report/reward_pred": 0.001322643831372261, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.019637783989310265, "eval/cont_loss_std": 0.23911085724830627, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.7621569633483887, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.008641155436635017, "eval/cont_pred": 0.9942812919616699, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1588878482580185, "eval/image_loss_std": 0.13931280374526978, "eval/model_loss_mean": 0.7954413890838623, "eval/model_loss_std": 0.5232458114624023, "eval/post_ent_mag": 33.76145935058594, "eval/post_ent_max": 33.76145935058594, "eval/post_ent_mean": 33.570579528808594, "eval/post_ent_min": 33.36769485473633, "eval/post_ent_std": 0.07933500409126282, "eval/prior_ent_mag": 33.494815826416016, "eval/prior_ent_max": 33.494815826416016, "eval/prior_ent_mean": 32.85053253173828, "eval/prior_ent_min": 31.8591365814209, "eval/prior_ent_std": 0.26688259840011597, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.001712036202661693, "eval/reward_loss_mean": 0.016915732994675636, "eval/reward_loss_std": 0.2666260004043579, "eval/reward_max_data": 0.7718750238418579, "eval/reward_max_pred": 0.11068689823150635, "eval/reward_neg_acc": 0.9980410933494568, "eval/reward_neg_loss": 0.002720545744523406, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.848011016845703, "eval/reward_pred": 0.001018745475448668, "eval/reward_rate": 0.0029296875, "replay/size": 423301.0, "replay/inserts": 8608.0, "replay/samples": 34432.0, "replay/insert_wait_avg": 1.5073715532579387e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.682753429093768e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 98472.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0194662945493282e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0891401767731, "timer/env.step_count": 1076.0, "timer/env.step_total": 10.097911834716797, "timer/env.step_frac": 0.010097011785301375, "timer/env.step_avg": 0.009384676426316726, "timer/env.step_min": 0.008332490921020508, "timer/env.step_max": 0.034432411193847656, "timer/replay._sample_count": 34432.0, "timer/replay._sample_total": 16.908398151397705, "timer/replay._sample_frac": 0.016906891068139206, "timer/replay._sample_avg": 0.0004910663961256304, "timer/replay._sample_min": 0.0003616809844970703, "timer/replay._sample_max": 0.05166125297546387, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1365.0, "timer/agent.policy_total": 13.696800947189331, "timer/agent.policy_frac": 0.013695580120756357, "timer/agent.policy_avg": 0.010034286408197313, "timer/agent.policy_min": 0.008750438690185547, "timer/agent.policy_max": 0.07626152038574219, "timer/dataset_train_count": 2152.0, "timer/dataset_train_total": 0.40124964714050293, "timer/dataset_train_frac": 0.0004012138828640606, "timer/dataset_train_avg": 0.00018645429699837496, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.018087387084960938, "timer/agent.train_count": 2152.0, "timer/agent.train_total": 961.5859181880951, "timer/agent.train_frac": 0.9615002098894182, "timer/agent.train_avg": 0.4468336051059921, "timer/agent.train_min": 0.43040013313293457, "timer/agent.train_max": 0.5748963356018066, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4775216579437256, "timer/agent.report_frac": 0.00047747909537275863, "timer/agent.report_avg": 0.2387608289718628, "timer/agent.report_min": 0.23183465003967285, "timer/agent.report_max": 0.24568700790405273, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.981590270996094e-05, "timer/dataset_eval_frac": 3.981235382970281e-08, "timer/dataset_eval_avg": 3.981590270996094e-05, "timer/dataset_eval_min": 3.981590270996094e-05, "timer/dataset_eval_max": 3.981590270996094e-05, "fps": 8.607113389981448}
{"step": 423848, "time": 49225.14247560501, "episode/length": 116.0, "episode/score": 0.6725254564436796, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.03502545404552393}
{"step": 423928, "time": 49234.400580883026, "episode/length": 288.0, "episode/score": 0.03225775564806099, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03225775564806099}
{"step": 424504, "time": 49300.63575077057, "episode/length": 288.0, "episode/score": 0.026141874112397545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026141874112397545}
{"step": 424584, "time": 49309.7831993103, "episode/length": 288.0, "episode/score": 0.05559670334037037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05559670334037037}
{"step": 424656, "time": 49318.072665929794, "episode/length": 156.0, "episode/score": 0.5412550234985929, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.028755027241345488}
{"step": 424760, "time": 49330.25206851959, "episode/length": 288.0, "episode/score": 0.03398677220394575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03398677220394575}
{"step": 424920, "time": 49348.59143567085, "episode/length": 288.0, "episode/score": 0.04991345648858214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04991345648858214}
{"step": 425136, "time": 49373.51732254028, "episode/length": 46.0, "episode/score": 0.8697541864491427, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.013504216501758037}
{"step": 425160, "time": 49376.298058748245, "episode/length": 274.0, "episode/score": 0.18118793652513432, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.037437939723645286}
{"step": 425176, "time": 49378.15170097351, "episode/length": 155.0, "episode/score": 0.551913670611782, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.03628868571666999}
{"step": 425704, "time": 49439.12513709068, "episode/length": 70.0, "episode/score": 0.7997578858008865, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.01850788171179829}
{"step": 425856, "time": 49456.65884804726, "episode/length": 250.0, "episode/score": 0.26184726942338443, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.04309726660031288}
{"step": 426520, "time": 49534.030974149704, "episode/length": 101.0, "episode/score": 0.7132300627723396, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.028855045298399773}
{"step": 426624, "time": 49546.03005194664, "episode/length": 182.0, "episode/score": 0.4588018026397833, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.027551793099547695}
{"step": 426816, "time": 49568.28037261963, "episode/length": 288.0, "episode/score": 0.025562353246925795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025562353246925795}
{"step": 426896, "time": 49577.49878025055, "episode/length": 288.0, "episode/score": 0.05303363632367564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05303363632367564}
{"step": 426960, "time": 49584.95354819298, "episode/length": 54.0, "episode/score": 0.8488086949319325, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.017558674832827137}
{"step": 426968, "time": 49585.88181972504, "episode/length": 288.0, "episode/score": 0.020464200956752165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020464200956752165}
{"step": 427232, "time": 49616.29042482376, "episode/length": 288.0, "episode/score": 0.024490735933511587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024490735933511587}
{"step": 427480, "time": 49644.864518880844, "episode/length": 30.0, "episode/score": 0.9211400186677849, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.014890030745874583}
{"step": 427488, "time": 49645.78208613396, "episode/length": 288.0, "episode/score": 0.038183876389041416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038183876389041416}
{"step": 427504, "time": 49647.60915350914, "episode/length": 75.0, "episode/score": 0.7813856960839871, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.015760722306538355}
{"step": 428128, "time": 49719.50127053261, "episode/length": 187.0, "episode/score": 0.4446400720264023, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.029015076135863183}
{"step": 428152, "time": 49722.24120736122, "episode/length": 148.0, "episode/score": 0.5834504235824909, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.04595039258109068}
{"step": 428168, "time": 49724.09003853798, "episode/length": 288.0, "episode/score": 0.06081968255813308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06081968255813308}
{"step": 428392, "time": 49749.8562912941, "episode/length": 113.0, "episode/score": 0.6846572090130678, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.03778217085212532}
{"step": 428760, "time": 49792.41980814934, "episode/length": 242.0, "episode/score": 0.3075845985743513, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.06383459785257628}
{"step": 429280, "time": 49852.546649456024, "episode/length": 288.0, "episode/score": 0.04123038292780734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04123038292780734}
{"step": 429664, "time": 49897.000762701035, "episode/length": 191.0, "episode/score": 0.4352201114942602, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.03209511174455315}
{"step": 429800, "time": 49912.64795875549, "episode/length": 288.0, "episode/score": 0.05475488024072206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05475488024072206}
{"step": 429816, "time": 49914.478813409805, "episode/length": 288.0, "episode/score": 0.08025314720015331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08025314720015331}
{"step": 430000, "time": 49935.74414753914, "episode/length": 228.0, "episode/score": 0.33502724595660993, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.04752726198699975}
{"step": 430040, "time": 49940.971267700195, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 430040, "time": 49941.64863586426, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 430040, "time": 49941.8322892189, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 430040, "time": 49942.00541853905, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 430040, "time": 49942.294911146164, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 430040, "time": 49944.12234401703, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 430040, "time": 49944.70863842964, "eval_episode/length": 232.0, "eval_episode/score": 0.2750000059604645, "eval_episode/reward_rate": 0.004291845493562232}
{"step": 430040, "time": 49945.63982820511, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 49945.646226882935, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430184, "time": 49962.34825754166, "episode/length": 177.0, "episode/score": 0.49448281367963887, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.04760780888332761}
{"step": 430464, "time": 49994.87710213661, "episode/length": 288.0, "episode/score": 0.05799215971535432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05799215971535432}
{"step": 430664, "time": 50017.97081232071, "episode/length": 283.0, "episode/score": 0.16705962872740088, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.05143462781936137}
{"step": 431000, "time": 50056.88167834282, "episode/length": 149.0, "episode/score": 0.585979310890167, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.05160427033106885}
{"step": 431400, "time": 50103.0798869133, "episode/length": 216.0, "episode/score": 0.37487581423593497, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.04987582656431755}
{"step": 431440, "time": 50107.70281267166, "episode/length": 54.0, "episode/score": 0.8558280955735427, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.024578084467520966}
{"step": 431480, "time": 50112.314596414566, "episode/length": 184.0, "episode/score": 0.47595125700294716, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.05095123076293362}
{"step": 431592, "time": 50125.201553821564, "episode/length": 288.0, "episode/score": 0.0645698183981267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0645698183981267}
{"step": 431776, "time": 50146.38604974747, "episode/length": 36.0, "episode/score": 0.9057534694127298, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.018253457992386757}
{"step": 431912, "time": 50162.14291572571, "episode/length": 215.0, "episode/score": 0.3926874610278901, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.06456246219204331}
{"step": 432128, "time": 50186.88683080673, "episode/length": 288.0, "episode/score": 0.05622054737787607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05622054737787607}
{"step": 432413, "time": 50220.52483558655, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.679570539607558, "train/action_min": 0.0, "train/action_std": 1.5493595766466717, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005902511883137185, "train/actor_opt_grad_steps": 106640.0, "train/actor_opt_loss": -21.93756657977437, "train/adv_mag": 0.36931642266206965, "train/adv_max": 0.16499250156934872, "train/adv_mean": -0.0010684671040465663, "train/adv_min": -0.3482610362906789, "train/adv_std": 0.017914905065540658, "train/cont_avg": 0.9960483284883721, "train/cont_loss_mean": 0.012120716935456839, "train/cont_loss_std": 0.1908730820254531, "train/cont_neg_acc": 0.4184016300495281, "train/cont_neg_loss": 2.380028328529375, "train/cont_pos_acc": 0.9999179199684498, "train/cont_pos_loss": 0.002534403895071253, "train/cont_pred": 0.9958934345910716, "train/cont_rate": 0.9960483284883721, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10949943890405256, "train/extr_critic_critic_opt_grad_steps": 106640.0, "train/extr_critic_critic_opt_loss": 7468.16632903343, "train/extr_critic_mag": 0.7668733419373978, "train/extr_critic_max": 0.7668733419373978, "train/extr_critic_mean": 0.6049823483755422, "train/extr_critic_min": 0.5168199494827626, "train/extr_critic_std": 0.04093361007439536, "train/extr_return_normed_mag": 0.39295701176621195, "train/extr_return_normed_max": 0.2660565287567848, "train/extr_return_normed_mean": 0.04275304377945357, "train/extr_return_normed_min": -0.27738641777703926, "train/extr_return_normed_std": 0.04482551690104396, "train/extr_return_rate": 0.9995009987853294, "train/extr_return_raw_mag": 0.8272173510041347, "train/extr_return_raw_max": 0.8272173510041347, "train/extr_return_raw_mean": 0.6039138918699221, "train/extr_return_raw_min": 0.28377440447031066, "train/extr_return_raw_std": 0.044825516944361286, "train/extr_reward_mag": 0.3097549654716669, "train/extr_reward_max": 0.3097549654716669, "train/extr_reward_mean": 0.0008387120682908612, "train/extr_reward_min": 1.2547470802484557e-06, "train/extr_reward_std": 0.006127673536972251, "train/image_loss_mean": 0.0870065092347389, "train/image_loss_std": 0.10564675209827201, "train/model_loss_mean": 0.7131229292514712, "train/model_loss_std": 0.32333477749380957, "train/model_opt_grad_norm": 13.031684494914023, "train/model_opt_grad_steps": 106543.93488372093, "train/model_opt_loss": 3795.4227414153343, "train/model_opt_model_opt_grad_overflow": 0.009302325581395349, "train/model_opt_model_opt_grad_scale": 5279.069767441861, "train/policy_entropy_mag": 1.348191331708154, "train/policy_entropy_max": 1.348191331708154, "train/policy_entropy_mean": 0.10121944266003231, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13073762339908024, "train/policy_logprob_mag": 6.551080262383749, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10102154529371928, "train/policy_logprob_min": -6.551080262383749, "train/policy_logprob_std": 0.6379267235134923, "train/policy_randomness_mag": 0.6928333310193794, "train/policy_randomness_max": 0.6928333310193794, "train/policy_randomness_mean": 0.052016507435676665, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06718585177562958, "train/post_ent_mag": 33.85259289408839, "train/post_ent_max": 33.85259289408839, "train/post_ent_mean": 33.632387400782385, "train/post_ent_min": 33.42009955117869, "train/post_ent_std": 0.08885755691417428, "train/prior_ent_mag": 33.81734645754792, "train/prior_ent_max": 33.81734645754792, "train/prior_ent_mean": 33.27819543882858, "train/prior_ent_min": 32.64783557625704, "train/prior_ent_std": 0.18280449142289718, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0009109166561799167, "train/reward_loss_mean": 0.013995679844777252, "train/reward_loss_std": 0.12273359543448964, "train/reward_max_data": 0.4857368857967992, "train/reward_max_pred": 0.1888362629469051, "train/reward_neg_acc": 0.9997999523961267, "train/reward_neg_loss": 0.009302262805922086, "train/reward_pos_acc": 0.2984276740993344, "train/reward_pos_loss": 3.7893315827321707, "train/reward_pred": 0.0008205771392081366, "train/reward_rate": 0.0012400072674418605, "train_stats/mean_log_entropy": 0.0784838033276935, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.01083000935614109, "report/cont_loss_std": 0.15251821279525757, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 1.6331754922866821, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0028695310465991497, "report/cont_pred": 0.9950146675109863, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09072186797857285, "report/image_loss_std": 0.09833493828773499, "report/model_loss_mean": 0.7161970138549805, "report/model_loss_std": 0.31643566489219666, "report/post_ent_mag": 33.77386474609375, "report/post_ent_max": 33.77386474609375, "report/post_ent_mean": 33.57649230957031, "report/post_ent_min": 33.29644775390625, "report/post_ent_std": 0.08315419405698776, "report/prior_ent_mag": 33.87110137939453, "report/prior_ent_max": 33.87110137939453, "report/prior_ent_mean": 33.288291931152344, "report/prior_ent_min": 32.720977783203125, "report/prior_ent_std": 0.1770995408296585, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008502306300215423, "report/reward_loss_mean": 0.01464505959302187, "report/reward_loss_std": 0.16506437957286835, "report/reward_max_data": 0.44729167222976685, "report/reward_max_pred": 0.4469165802001953, "report/reward_neg_acc": 0.9990215301513672, "report/reward_neg_loss": 0.008920970372855663, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.93965482711792, "report/reward_pred": 0.0011483795242384076, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.045508041977882385, "eval/cont_loss_std": 0.6207060217857361, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.646322727203369, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.008212581276893616, "eval/cont_pred": 0.9966567754745483, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22286099195480347, "eval/image_loss_std": 0.17179429531097412, "eval/model_loss_mean": 0.8752185702323914, "eval/model_loss_std": 0.6861165761947632, "eval/post_ent_mag": 33.7875862121582, "eval/post_ent_max": 33.7875862121582, "eval/post_ent_mean": 33.563514709472656, "eval/post_ent_min": 33.32880401611328, "eval/post_ent_std": 0.08980996161699295, "eval/prior_ent_mag": 33.794036865234375, "eval/prior_ent_max": 33.794036865234375, "eval/prior_ent_mean": 33.25617218017578, "eval/prior_ent_min": 32.60039520263672, "eval/prior_ent_std": 0.1928812712430954, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.000579833984375, "eval/reward_loss_mean": 0.006849553901702166, "eval/reward_loss_std": 0.14505784213542938, "eval/reward_max_data": 0.59375, "eval/reward_max_pred": 0.05615115165710449, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002319790655747056, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.6407976150512695, "eval/reward_pred": 0.0007380290189757943, "eval/reward_rate": 0.0009765625, "replay/size": 431909.0, "replay/inserts": 8608.0, "replay/samples": 34432.0, "replay/insert_wait_avg": 1.5116923360576417e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.698679391336264e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0606120614444508e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1201910972595, "timer/env.step_count": 1076.0, "timer/env.step_total": 10.051418542861938, "timer/env.step_frac": 0.010050210597022593, "timer/env.step_avg": 0.00934146704726946, "timer/env.step_min": 0.008206367492675781, "timer/env.step_max": 0.03540635108947754, "timer/replay._sample_count": 34432.0, "timer/replay._sample_total": 16.822824239730835, "timer/replay._sample_frac": 0.016820802529018086, "timer/replay._sample_avg": 0.0004885810943230377, "timer/replay._sample_min": 0.00035953521728515625, "timer/replay._sample_max": 0.019626379013061523, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1365.0, "timer/agent.policy_total": 13.314832925796509, "timer/agent.policy_frac": 0.013313232793738958, "timer/agent.policy_avg": 0.009754456355894878, "timer/agent.policy_min": 0.008722305297851562, "timer/agent.policy_max": 0.036457061767578125, "timer/dataset_train_count": 2152.0, "timer/dataset_train_total": 0.36939120292663574, "timer/dataset_train_frac": 0.000369346810728185, "timer/dataset_train_avg": 0.00017165018723356678, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.0011456012725830078, "timer/agent.train_count": 2152.0, "timer/agent.train_total": 962.0185379981995, "timer/agent.train_frac": 0.9619029258300869, "timer/agent.train_avg": 0.4470346366162637, "timer/agent.train_min": 0.433398962020874, "timer/agent.train_max": 0.6789064407348633, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4750528335571289, "timer/agent.report_frac": 0.0004749957432975484, "timer/agent.report_avg": 0.23752641677856445, "timer/agent.report_min": 0.23102545738220215, "timer/agent.report_max": 0.24402737617492676, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7176451650034686e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 8.606846688158146}
{"step": 432776, "time": 50262.30184173584, "episode/length": 288.0, "episode/score": 0.04356112917207611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04356112917207611}
{"step": 432856, "time": 50271.53686141968, "episode/length": 117.0, "episode/score": 0.6655380647702032, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.03116307429297649}
{"step": 432976, "time": 50285.42466545105, "episode/length": 288.0, "episode/score": 0.03520820803362312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03520820803362312}
{"step": 433080, "time": 50297.48477983475, "episode/length": 204.0, "episode/score": 0.39947767001285683, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.03697764991375152}
{"step": 433136, "time": 50304.01143908501, "episode/length": 19.0, "episode/score": 0.9464345896880104, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.005809570607539172}
{"step": 433712, "time": 50370.49650001526, "episode/length": 288.0, "episode/score": 0.05843733593928846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05843733593928846}
{"step": 433904, "time": 50392.72506690025, "episode/length": 288.0, "episode/score": 0.05017499099596989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05017499099596989}
{"step": 434088, "time": 50413.97554755211, "episode/length": 288.0, "episode/score": 0.07002720156060604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07002720156060604}
{"step": 434176, "time": 50424.371269226074, "episode/length": 174.0, "episode/score": 0.4932144950331576, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.03696447144159265}
{"step": 434440, "time": 50455.1038749218, "episode/length": 288.0, "episode/score": 0.03476047505603219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03476047505603219}
{"step": 435040, "time": 50524.831243276596, "episode/length": 74.0, "episode/score": 0.7893175492793603, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.020567557498281985}
{"step": 435168, "time": 50539.61233687401, "episode/length": 288.0, "episode/score": 0.06185680698780516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06185680698780516}
{"step": 435168, "time": 50539.61825346947, "episode/length": 123.0, "episode/score": 0.641217379368527, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.025592341207584468}
{"step": 435392, "time": 50565.54589986801, "episode/length": 288.0, "episode/score": 0.057017828429081874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057017828429081874}
{"step": 435448, "time": 50572.12269949913, "episode/length": 288.0, "episode/score": 0.046807628134558854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046807628134558854}
{"step": 435640, "time": 50594.39833068848, "episode/length": 74.0, "episode/score": 0.7803331486349521, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.011583156853873788}
{"step": 436024, "time": 50639.22647500038, "episode/length": 288.0, "episode/score": 0.038357195884941575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038357195884941575}
{"step": 436216, "time": 50661.62115764618, "episode/length": 288.0, "episode/score": 0.0884974600219266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0884974600219266}
{"step": 436400, "time": 50682.93651485443, "episode/length": 288.0, "episode/score": 0.0859685684959004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0859685684959004}
{"step": 436472, "time": 50691.229850530624, "episode/length": 103.0, "episode/score": 0.7026096570731966, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.024484633449617377}
{"step": 436656, "time": 50712.52918219566, "episode/length": 150.0, "episode/score": 0.5751546366937532, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.04390463691203195}
{"step": 436824, "time": 50731.96654677391, "episode/length": 206.0, "episode/score": 0.40386731191944136, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.04761733030142068}
{"step": 437168, "time": 50771.643134355545, "episode/length": 86.0, "episode/score": 0.7595171011974458, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.028267089777102683}
{"step": 437192, "time": 50774.40042877197, "episode/length": 66.0, "episode/score": 0.8172980756439188, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.02354805892667855}
{"step": 437328, "time": 50790.04968357086, "episode/length": 115.0, "episode/score": 0.6849813105959583, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.04435628725468632}
{"step": 437480, "time": 50807.60389709473, "episode/length": 288.0, "episode/score": 0.09098347061689083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09098347061689083}
{"step": 437704, "time": 50833.46565580368, "episode/length": 288.0, "episode/score": 0.03286413366345187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03286413366345187}
{"step": 438336, "time": 50906.58173751831, "episode/length": 288.0, "episode/score": 0.08430531227838856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08430531227838856}
{"step": 438384, "time": 50912.17489671707, "episode/length": 270.0, "episode/score": 0.22478758139709498, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.06853758221200223}
{"step": 438448, "time": 50919.57216954231, "episode/length": 139.0, "episode/score": 0.5918825787384776, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.02625753817937948}
{"step": 438520, "time": 50927.86161971092, "episode/length": 16.0, "episode/score": 0.9589356689302804, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0089356575099373}
{"step": 438544, "time": 50930.60960769653, "episode/length": 104.0, "episode/score": 0.7022432897440467, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.027243254481845725}
{"step": 438560, "time": 50932.4692606926, "episode/length": 134.0, "episode/score": 0.6129614517258233, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.03171142548580974}
{"step": 438704, "time": 50949.06020331383, "episode/length": 19.0, "episode/score": 0.9507747666382329, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.010149731376031923}
{"step": 438800, "time": 50960.126987457275, "episode/length": 203.0, "episode/score": 0.4213664274570874, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.055741433825005515}
{"step": 439136, "time": 50999.16438913345, "episode/length": 288.0, "episode/score": 0.06853461685182083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06853461685182083}
{"step": 439352, "time": 51024.08635139465, "episode/length": 112.0, "episode/score": 0.6808688874116342, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.030868904093949823}
{"step": 439352, "time": 51024.09171509743, "episode/length": 98.0, "episode/score": 0.7407562571478365, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.04700620391110988}
{"step": 439416, "time": 51031.56262254715, "episode/length": 88.0, "episode/score": 0.7600551217091152, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.03505508968908089}
{"step": 439504, "time": 51041.834656476974, "episode/length": 288.0, "episode/score": 0.09367959312930907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09367959312930907}
{"step": 439640, "time": 51057.486805438995, "episode/length": 16.0, "episode/score": 0.9581033494699795, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.008103332752739334}
{"step": 440024, "time": 51102.13845491409, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 440024, "time": 51102.2566280365, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 440024, "time": 51103.48727726936, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 440024, "time": 51104.314422369, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 440024, "time": 51104.76339030266, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 440024, "time": 51104.904057741165, "eval_episode/length": 188.0, "eval_episode/score": 0.4124999940395355, "eval_episode/reward_rate": 0.005291005291005291}
{"step": 440024, "time": 51104.958419799805, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 440024, "time": 51105.29259800911, "eval_episode/length": 186.0, "eval_episode/score": 0.41874998807907104, "eval_episode/reward_rate": 0.0053475935828877}
{"step": 440152, "time": 51119.99908208847, "episode/length": 63.0, "episode/score": 0.8201898781142063, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0170648399532638}
{"step": 440576, "time": 51168.95160865784, "episode/length": 152.0, "episode/score": 0.5530337323198182, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.028033726766807376}
{"step": 440648, "time": 51177.24129152298, "episode/length": 288.0, "episode/score": 0.1060246947114365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1060246947114365}
{"step": 440832, "time": 51198.62115097046, "episode/length": 288.0, "episode/score": 0.06342039901744556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06342039901744556}
{"step": 440904, "time": 51206.90675544739, "episode/length": 31.0, "episode/score": 0.9149736913741435, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.011848721426758857}
{"step": 441016, "time": 51219.83659648895, "episode/length": 107.0, "episode/score": 0.7020829532032167, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.03645799517676096}
{"step": 441017, "time": 51220.84122920036, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.653097179324128, "train/action_min": 0.0, "train/action_std": 1.6449966214423957, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006154600515701743, "train/actor_opt_grad_steps": 108790.0, "train/actor_opt_loss": -22.359865348283634, "train/adv_mag": 0.36497545311617297, "train/adv_max": 0.1683245999868526, "train/adv_mean": -0.00025229131021639427, "train/adv_min": -0.3351777536924495, "train/adv_std": 0.01836843280078367, "train/cont_avg": 0.9957530886627907, "train/cont_loss_mean": 0.013275750557523827, "train/cont_loss_std": 0.2029240791642562, "train/cont_neg_acc": 0.4125018781226761, "train/cont_neg_loss": 2.376007673123892, "train/cont_pos_acc": 0.9998722797216371, "train/cont_pos_loss": 0.0026351702610723847, "train/cont_pred": 0.9957910629205926, "train/cont_rate": 0.9957530886627907, "train/dyn_loss_mean": 1.0000001896259396, "train/dyn_loss_std": 6.0756820752177125e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10513952079034129, "train/extr_critic_critic_opt_grad_steps": 108790.0, "train/extr_critic_critic_opt_loss": 8806.501996275436, "train/extr_critic_mag": 0.7289459566737331, "train/extr_critic_max": 0.7289459566737331, "train/extr_critic_mean": 0.5749671528505724, "train/extr_critic_min": 0.47136991855710053, "train/extr_critic_std": 0.0402793631564046, "train/extr_return_normed_mag": 0.38093869630680527, "train/extr_return_normed_max": 0.256054024363673, "train/extr_return_normed_mean": 0.047541943547684096, "train/extr_return_normed_min": -0.2665675032970517, "train/extr_return_normed_std": 0.044736452262068904, "train/extr_return_rate": 0.99891900295435, "train/extr_return_raw_mag": 0.7832269444022067, "train/extr_return_raw_max": 0.7832269444022067, "train/extr_return_raw_mean": 0.5747148907461832, "train/extr_return_raw_min": 0.260605416741482, "train/extr_return_raw_std": 0.044736452262068904, "train/extr_reward_mag": 0.29135504600613615, "train/extr_reward_max": 0.29135504600613615, "train/extr_reward_mean": 0.0008967323659182807, "train/extr_reward_min": 1.2259150660315225e-06, "train/extr_reward_std": 0.0057725720676095335, "train/image_loss_mean": 0.09055733507455782, "train/image_loss_std": 0.10759429779163626, "train/model_loss_mean": 0.7189231692358505, "train/model_loss_std": 0.35241193223831263, "train/model_opt_grad_norm": 13.053423043184502, "train/model_opt_grad_steps": 108691.89767441861, "train/model_opt_loss": 3678.629606876817, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5116.279069767442, "train/policy_entropy_mag": 1.3996151580366978, "train/policy_entropy_max": 1.3996151580366978, "train/policy_entropy_mean": 0.11678487280773563, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.15919961153074752, "train/policy_logprob_mag": 6.551080251294513, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11685743186362954, "train/policy_logprob_min": -6.551080251294513, "train/policy_logprob_std": 0.6554526179335838, "train/policy_randomness_mag": 0.7192599521126858, "train/policy_randomness_max": 0.7192599521126858, "train/policy_randomness_mean": 0.06001555618158606, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.08181242076463477, "train/post_ent_mag": 33.8937811030898, "train/post_ent_max": 33.8937811030898, "train/post_ent_mean": 33.68093364626862, "train/post_ent_min": 33.47284373793491, "train/post_ent_std": 0.08663416747436967, "train/prior_ent_mag": 33.9058663833973, "train/prior_ent_max": 33.9058663833973, "train/prior_ent_mean": 33.32628431098406, "train/prior_ent_min": 32.67217278591422, "train/prior_ent_std": 0.2117793059626291, "train/rep_loss_mean": 1.0000001896259396, "train/rep_loss_std": 6.0756820752177125e-06, "train/reward_avg": 0.0010603476577671245, "train/reward_loss_mean": 0.015089944921174022, "train/reward_loss_std": 0.14227807015007318, "train/reward_max_data": 0.5346040477413078, "train/reward_max_pred": 0.18303819811621377, "train/reward_neg_acc": 0.9998362477435622, "train/reward_neg_loss": 0.009327774349773346, "train/reward_pos_acc": 0.24971485655464812, "train/reward_pos_loss": 3.987061485648155, "train/reward_pred": 0.0008569865211367954, "train/reward_rate": 0.0014444040697674419, "train_stats/mean_log_entropy": 0.07744777583061381, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.014633720740675926, "report/cont_loss_std": 0.23301857709884644, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.284911155700684, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002086383057758212, "report/cont_pred": 0.9978947043418884, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07583938539028168, "report/image_loss_std": 0.0905924141407013, "report/model_loss_mean": 0.7119384407997131, "report/model_loss_std": 0.5079811215400696, "report/post_ent_mag": 34.12282943725586, "report/post_ent_max": 34.12282943725586, "report/post_ent_mean": 33.909698486328125, "report/post_ent_min": 33.718624114990234, "report/post_ent_std": 0.08558633178472519, "report/prior_ent_mag": 33.887935638427734, "report/prior_ent_max": 33.887935638427734, "report/prior_ent_mean": 33.3055305480957, "report/prior_ent_min": 32.65081787109375, "report/prior_ent_std": 0.2210915982723236, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001426532631739974, "report/reward_loss_mean": 0.02146531082689762, "report/reward_loss_std": 0.26875799894332886, "report/reward_max_data": 0.8532916307449341, "report/reward_max_pred": 0.04160583019256592, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0096411919221282, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.063590049743652, "report/reward_pred": 0.0007491706637665629, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.042791787534952164, "eval/cont_loss_std": 0.6386442184448242, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.649404525756836, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.00511879613623023, "eval/cont_pred": 0.9964395761489868, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21954205632209778, "eval/image_loss_std": 0.16999442875385284, "eval/model_loss_mean": 0.8922302722930908, "eval/model_loss_std": 1.1380553245544434, "eval/post_ent_mag": 34.122623443603516, "eval/post_ent_max": 34.122623443603516, "eval/post_ent_mean": 33.913604736328125, "eval/post_ent_min": 33.71513366699219, "eval/post_ent_std": 0.08497721701860428, "eval/prior_ent_mag": 33.85215377807617, "eval/prior_ent_max": 33.85215377807617, "eval/prior_ent_mean": 33.291175842285156, "eval/prior_ent_min": 32.600685119628906, "eval/prior_ent_std": 0.21662652492523193, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.00213623046875, "eval/reward_loss_mean": 0.029896384105086327, "eval/reward_loss_std": 0.5343977212905884, "eval/reward_max_data": 0.746874988079071, "eval/reward_max_pred": 0.03158104419708252, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0020998804830014706, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.489974021911621, "eval/reward_pred": 0.0006432358641177416, "eval/reward_rate": 0.0029296875, "replay/size": 440513.0, "replay/inserts": 8604.0, "replay/samples": 34416.0, "replay/insert_wait_avg": 1.5300465206499158e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.664572632850352e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 1696.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.386325782200075e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3032867908478, "timer/env.step_count": 1076.0, "timer/env.step_total": 10.015033721923828, "timer/env.step_frac": 0.010011997215418386, "timer/env.step_avg": 0.009307652157921774, "timer/env.step_min": 0.008178949356079102, "timer/env.step_max": 0.03395843505859375, "timer/replay._sample_count": 34416.0, "timer/replay._sample_total": 16.856337070465088, "timer/replay._sample_frac": 0.016851226316113823, "timer/replay._sample_avg": 0.0004897819929819005, "timer/replay._sample_min": 0.0003688335418701172, "timer/replay._sample_max": 0.02190089225769043, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1288.0, "timer/agent.policy_total": 12.56734848022461, "timer/agent.policy_frac": 0.012563538125064964, "timer/agent.policy_avg": 0.00975725813682035, "timer/agent.policy_min": 0.008693695068359375, "timer/agent.policy_max": 0.03568887710571289, "timer/dataset_train_count": 2151.0, "timer/dataset_train_total": 0.3718407154083252, "timer/dataset_train_frac": 0.00037172797522365126, "timer/dataset_train_avg": 0.00017286876588020698, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0011734962463378906, "timer/agent.train_count": 2151.0, "timer/agent.train_total": 963.7731511592865, "timer/agent.train_frac": 0.9634809401169154, "timer/agent.train_avg": 0.44805818277977055, "timer/agent.train_min": 0.4373183250427246, "timer/agent.train_max": 0.6110799312591553, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4751601219177246, "timer/agent.report_frac": 0.000475016055822553, "timer/agent.report_avg": 0.2375800609588623, "timer/agent.report_min": 0.2313060760498047, "timer/agent.report_max": 0.24385404586791992, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.6743621826171875e-05, "timer/dataset_eval_frac": 5.672641745306624e-08, "timer/dataset_eval_avg": 5.6743621826171875e-05, "timer/dataset_eval_min": 5.6743621826171875e-05, "timer/dataset_eval_max": 5.6743621826171875e-05, "fps": 8.601272201906749}
{"step": 441112, "time": 51231.59764623642, "episode/length": 288.0, "episode/score": 0.08629083692244421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08629083692244421}
{"step": 441448, "time": 51270.557163238525, "episode/length": 288.0, "episode/score": 0.06375714882369721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06375714882369721}
{"step": 441664, "time": 51295.45672416687, "episode/length": 288.0, "episode/score": 0.0841175546327122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0841175546327122}
{"step": 441728, "time": 51302.8979537487, "episode/length": 288.0, "episode/score": 0.08523575251649618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08523575251649618}
{"step": 441848, "time": 51316.698311805725, "episode/length": 117.0, "episode/score": 0.6630059664822738, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.028630961685962575}
{"step": 442312, "time": 51370.26252627373, "episode/length": 184.0, "episode/score": 0.4821979981620643, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.05719798705604262}
{"step": 442720, "time": 51417.96766066551, "episode/length": 131.0, "episode/score": 0.6187120052693444, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.028087018005180653}
{"step": 442888, "time": 51437.438732624054, "episode/length": 288.0, "episode/score": 0.07769588887992995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07769588887992995}
{"step": 443128, "time": 51465.3593583107, "episode/length": 174.0, "episode/score": 0.4899797156729164, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.03372971021303783}
{"step": 443288, "time": 51483.81802892685, "episode/length": 19.0, "episode/score": 0.9481394795213873, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.007514438205589613}
{"step": 443328, "time": 51488.42551231384, "episode/length": 288.0, "episode/score": 0.0464816519033775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0464816519033775}
{"step": 443376, "time": 51493.960788965225, "episode/length": 240.0, "episode/score": 0.31315556546610424, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.06315556663025745}
{"step": 443424, "time": 51499.50783491135, "episode/length": 288.0, "episode/score": 0.10293537090205973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10293537090205973}
{"step": 443448, "time": 51502.2868874073, "episode/length": 90.0, "episode/score": 0.7327135922739672, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.013963568932695125}
{"step": 443608, "time": 51520.78467106819, "episode/length": 34.0, "episode/score": 0.9132317747955767, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.019481748555563172}
{"step": 444160, "time": 51584.83654665947, "episode/length": 288.0, "episode/score": 0.0723789292761694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0723789292761694}
{"step": 444352, "time": 51607.028034210205, "episode/length": 121.0, "episode/score": 0.6593649201785183, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.03748990875817526}
{"step": 444624, "time": 51638.408850193024, "episode/length": 288.0, "episode/score": 0.05303533936057647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05303533936057647}
{"step": 445200, "time": 51705.25924038887, "episode/length": 288.0, "episode/score": 0.04788783977505773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04788783977505773}
{"step": 445296, "time": 51716.48680615425, "episode/length": 117.0, "episode/score": 0.6600150507576927, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.025640066421374286}
{"step": 445504, "time": 51740.57069659233, "episode/length": 256.0, "episode/score": 0.27389875753488013, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.07389875496210152}
{"step": 445560, "time": 51747.060405254364, "episode/length": 116.0, "episode/score": 0.657100243572927, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.019600275633706588}
{"step": 445600, "time": 51751.71177959442, "episode/length": 288.0, "episode/score": 0.07716492581835155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07716492581835155}
{"step": 445736, "time": 51767.35957121849, "episode/length": 288.0, "episode/score": 0.057732816528641706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057732816528641706}
{"step": 445920, "time": 51788.64028143883, "episode/length": 288.0, "episode/score": 0.07656106796321183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07656106796321183}
{"step": 446416, "time": 51845.837618112564, "episode/length": 151.0, "episode/score": 0.5496847988055151, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.021559802548267726}
{"step": 446472, "time": 51852.280728816986, "episode/length": 288.0, "episode/score": 0.06980962055473583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06980962055473583}
{"step": 446640, "time": 51871.717713832855, "episode/length": 89.0, "episode/score": 0.7438142842160573, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.021939265135586083}
{"step": 446968, "time": 51909.5312936306, "episode/length": 182.0, "episode/score": 0.46046163184405486, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.029211618724048094}
{"step": 447112, "time": 51926.1347219944, "episode/length": 188.0, "episode/score": 0.46318373026616655, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.050683729067088734}
{"step": 447232, "time": 51939.99836182594, "episode/length": 241.0, "episode/score": 0.3032383378517238, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.05636334133254195}
{"step": 447872, "time": 52013.70160460472, "episode/length": 288.0, "episode/score": 0.07240854668958718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07240854668958718}
{"step": 447928, "time": 52020.16060900688, "episode/length": 160.0, "episode/score": 0.5400335393907767, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.04003355953062737}
{"step": 448048, "time": 52034.06306600571, "episode/length": 288.0, "episode/score": 0.07972878563560926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07972878563560926}
{"step": 448728, "time": 52112.58580851555, "episode/length": 288.0, "episode/score": 0.08760079065973514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08760079065973514}
{"step": 448784, "time": 52119.11556553841, "episode/length": 288.0, "episode/score": 0.08116065881029044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08116065881029044}
{"step": 449280, "time": 52176.60837697983, "episode/length": 288.0, "episode/score": 0.06775161289874632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06775161289874632}
{"step": 449296, "time": 52178.449404001236, "episode/length": 155.0, "episode/score": 0.5606280800486729, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.045003050653804166}
{"step": 449424, "time": 52193.15436005592, "episode/length": 288.0, "episode/score": 0.09362882551147322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09362882551147322}
{"step": 449544, "time": 52207.041759729385, "episode/length": 288.0, "episode/score": 0.10715786765177882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10715786765177882}
{"step": 449616, "time": 52215.338668346405, "episode/length": 103.0, "episode/score": 0.7042504511017, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0261254453915285}
{"step": 449657, "time": 52220.95264291763, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.648288302951389, "train/action_min": 0.0, "train/action_std": 1.705283639607606, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006180627512987013, "train/actor_opt_grad_steps": 110945.0, "train/actor_opt_loss": -19.212709576995284, "train/adv_mag": 0.3697422266834312, "train/adv_max": 0.2228953187112455, "train/adv_mean": 1.3539297936159966e-05, "train/adv_min": -0.3236328269596453, "train/adv_std": 0.017809554731852754, "train/cont_avg": 0.9959445529513888, "train/cont_loss_mean": 0.01260994492838142, "train/cont_loss_std": 0.19965714404652654, "train/cont_neg_acc": 0.3967639233724612, "train/cont_neg_loss": 2.4945008486824, "train/cont_pos_acc": 0.9998773954532765, "train/cont_pos_loss": 0.0026453663767487916, "train/cont_pred": 0.9958001024745129, "train/cont_rate": 0.9959445529513888, "train/dyn_loss_mean": 1.0000000761614904, "train/dyn_loss_std": 2.4433724724480676e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10167403946872111, "train/extr_critic_critic_opt_grad_steps": 110945.0, "train/extr_critic_critic_opt_loss": 9007.346663863571, "train/extr_critic_mag": 0.757934660271362, "train/extr_critic_max": 0.757934660271362, "train/extr_critic_mean": 0.5651503028693022, "train/extr_critic_min": 0.46911185372758796, "train/extr_critic_std": 0.03622645060359328, "train/extr_return_normed_mag": 0.41634599422966995, "train/extr_return_normed_max": 0.3302963916902189, "train/extr_return_normed_mean": 0.040599612760599015, "train/extr_return_normed_min": -0.2529341138347431, "train/extr_return_normed_std": 0.0410659689783912, "train/extr_return_rate": 0.9989336527608059, "train/extr_return_raw_mag": 0.8548606275408356, "train/extr_return_raw_max": 0.8548606275408356, "train/extr_return_raw_mean": 0.5651638709284641, "train/extr_return_raw_min": 0.27163012229182104, "train/extr_return_raw_std": 0.041065968909404345, "train/extr_reward_mag": 0.3728696058193843, "train/extr_reward_max": 0.3728696058193843, "train/extr_reward_mean": 0.0009681926487785488, "train/extr_reward_min": 1.5000502268473308e-06, "train/extr_reward_std": 0.006957590042643629, "train/image_loss_mean": 0.08914175510613455, "train/image_loss_std": 0.10798636820443251, "train/model_loss_mean": 0.7166227667971894, "train/model_loss_std": 0.34430167596373296, "train/model_opt_grad_norm": 12.40174283583959, "train/model_opt_grad_steps": 110844.88425925926, "train/model_opt_loss": 3816.207871048539, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5324.074074074074, "train/policy_entropy_mag": 1.4098354997458282, "train/policy_entropy_max": 1.4098354997458282, "train/policy_entropy_mean": 0.11766180596141904, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.15939005516055557, "train/policy_logprob_mag": 6.551080257804306, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1179847355104155, "train/policy_logprob_min": -6.551080257804306, "train/policy_logprob_std": 0.6575539065180002, "train/policy_randomness_mag": 0.724512168654689, "train/policy_randomness_max": 0.724512168654689, "train/policy_randomness_mean": 0.06046621096147983, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.08191029009995637, "train/post_ent_mag": 33.989417535287366, "train/post_ent_max": 33.989417535287366, "train/post_ent_mean": 33.77853517179136, "train/post_ent_min": 33.576845734207716, "train/post_ent_std": 0.08547484453905511, "train/prior_ent_mag": 33.87606989895856, "train/prior_ent_max": 33.87606989895856, "train/prior_ent_mean": 33.42498095830282, "train/prior_ent_min": 32.900883745264125, "train/prior_ent_std": 0.15541540120762806, "train/rep_loss_mean": 1.0000000761614904, "train/rep_loss_std": 2.4433724724480676e-06, "train/reward_avg": 0.00103139373937598, "train/reward_loss_mean": 0.014870999613776803, "train/reward_loss_std": 0.13672933668001658, "train/reward_max_data": 0.5299095835103395, "train/reward_max_pred": 0.20212657915221321, "train/reward_neg_acc": 0.9998505703277059, "train/reward_neg_loss": 0.009432700005601402, "train/reward_pos_acc": 0.2890532558133616, "train/reward_pos_loss": 3.7773377400707213, "train/reward_pred": 0.000893559523521819, "train/reward_rate": 0.001442238136574074, "train_stats/mean_log_entropy": 0.08128834179625279, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.011846356093883514, "report/cont_loss_std": 0.15136978030204773, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 1.8177570104599, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002985166385769844, "report/cont_pred": 0.9955624341964722, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08943924307823181, "report/image_loss_std": 0.10829246789216995, "report/model_loss_mean": 0.7224745750427246, "report/model_loss_std": 0.39833828806877136, "report/post_ent_mag": 33.99009323120117, "report/post_ent_max": 33.99009323120117, "report/post_ent_mean": 33.785911560058594, "report/post_ent_min": 33.56928253173828, "report/post_ent_std": 0.09065517038106918, "report/prior_ent_mag": 34.04872131347656, "report/prior_ent_max": 34.04872131347656, "report/prior_ent_mean": 33.563663482666016, "report/prior_ent_min": 32.962188720703125, "report/prior_ent_std": 0.16837359964847565, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002609885996207595, "report/reward_loss_mean": 0.021188884973526, "report/reward_loss_std": 0.2189238965511322, "report/reward_max_data": 0.906416654586792, "report/reward_max_pred": 0.781566858291626, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.00918539147824049, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.0820798873901367, "report/reward_pred": 0.0017190288053825498, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.05417399853467941, "eval/cont_loss_std": 0.774126410484314, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.55888843536377, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002629769966006279, "eval/cont_pred": 0.997533917427063, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19089624285697937, "eval/image_loss_std": 0.1380416452884674, "eval/model_loss_mean": 0.852483332157135, "eval/model_loss_std": 0.8346038460731506, "eval/post_ent_mag": 33.98987579345703, "eval/post_ent_max": 33.98987579345703, "eval/post_ent_mean": 33.765987396240234, "eval/post_ent_min": 33.58266830444336, "eval/post_ent_std": 0.08801490068435669, "eval/prior_ent_mag": 33.970245361328125, "eval/prior_ent_max": 33.970245361328125, "eval/prior_ent_mean": 33.539337158203125, "eval/prior_ent_min": 33.018409729003906, "eval/prior_ent_std": 0.1609075367450714, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0004211425839457661, "eval/reward_loss_mean": 0.007413051091134548, "eval/reward_loss_std": 0.16338224709033966, "eval/reward_max_data": 0.4312500059604645, "eval/reward_max_pred": 0.17488253116607666, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.002322167856618762, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.215386390686035, "eval/reward_pred": 0.0007410828256979585, "eval/reward_rate": 0.0009765625, "replay/size": 449153.0, "replay/inserts": 8640.0, "replay/samples": 34560.0, "replay/insert_wait_avg": 1.4958834206616436e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.67430497540368e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0997760295868, "timer/env.step_count": 1080.0, "timer/env.step_total": 10.106333494186401, "timer/env.step_frac": 0.010105325224957771, "timer/env.step_avg": 0.009357716198320742, "timer/env.step_min": 0.008257865905761719, "timer/env.step_max": 0.03446388244628906, "timer/replay._sample_count": 34560.0, "timer/replay._sample_total": 16.895339488983154, "timer/replay._sample_frac": 0.016893653907271072, "timer/replay._sample_avg": 0.0004888697768802996, "timer/replay._sample_min": 0.0003743171691894531, "timer/replay._sample_max": 0.011021614074707031, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1080.0, "timer/agent.policy_total": 10.647711277008057, "timer/agent.policy_frac": 0.010646648996642768, "timer/agent.policy_avg": 0.009858991923155608, "timer/agent.policy_min": 0.008840322494506836, "timer/agent.policy_max": 0.03519606590270996, "timer/dataset_train_count": 2160.0, "timer/dataset_train_total": 0.3743741512298584, "timer/dataset_train_frac": 0.0003743368013900875, "timer/dataset_train_avg": 0.00017332136631011962, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.0009868144989013672, "timer/agent.train_count": 2160.0, "timer/agent.train_total": 967.066636800766, "timer/agent.train_frac": 0.9669701563578357, "timer/agent.train_avg": 0.44771603555591016, "timer/agent.train_min": 0.43679261207580566, "timer/agent.train_max": 0.5906367301940918, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47920918464660645, "timer/agent.report_frac": 0.0004791613758269951, "timer/agent.report_avg": 0.23960459232330322, "timer/agent.report_min": 0.23379230499267578, "timer/agent.report_max": 0.24541687965393066, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8368980368861306e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 8.63902060297661}
{"step": 449768, "time": 52233.57346749306, "episode/length": 129.0, "episode/score": 0.6350246567149611, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.038149645012310884}
{"step": 449784, "time": 52235.42205643654, "episode/length": 231.0, "episode/score": 0.3379419794267733, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.059816983169525884}
{"step": 450008, "time": 52261.80578660965, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 450008, "time": 52262.107749938965, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 450008, "time": 52262.72305083275, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 450008, "time": 52263.03897404671, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 450008, "time": 52264.3325445652, "eval_episode/length": 176.0, "eval_episode/score": 0.44999998807907104, "eval_episode/reward_rate": 0.005649717514124294}
{"step": 450008, "time": 52264.43662762642, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 450008, "time": 52264.80071234703, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 450008, "time": 52266.16857457161, "eval_episode/length": 188.0, "eval_episode/score": 0.4124999940395355, "eval_episode/reward_rate": 0.005291005291005291}
{"step": 450184, "time": 52286.48944425583, "episode/length": 288.0, "episode/score": 0.057381047595299606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057381047595299606}
{"step": 450416, "time": 52313.29755735397, "episode/length": 80.0, "episode/score": 0.7804673937396842, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.030467394554591465}
{"step": 450624, "time": 52337.662502765656, "episode/length": 134.0, "episode/score": 0.6158205132124408, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.034570472653342676}
{"step": 451272, "time": 52412.828234910965, "episode/length": 135.0, "episode/score": 0.6204704349306667, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.04234543574557392}
{"step": 451352, "time": 52422.05608177185, "episode/length": 116.0, "episode/score": 0.6720241483458267, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.03452413692548362}
{"step": 451592, "time": 52449.89053416252, "episode/length": 288.0, "episode/score": 0.06315805337692382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06315805337692382}
{"step": 451608, "time": 52451.7843375206, "episode/length": 288.0, "episode/score": 0.07946179510548745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07946179510548745}
{"step": 451688, "time": 52461.062697172165, "episode/length": 132.0, "episode/score": 0.6323884672144686, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.04488849187123378}
{"step": 451736, "time": 52466.58768105507, "episode/length": 288.0, "episode/score": 0.0614129770111731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0614129770111731}
{"step": 451928, "time": 52488.73024177551, "episode/length": 288.0, "episode/score": 0.05761537184099552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05761537184099552}
{"step": 452096, "time": 52508.24154663086, "episode/length": 288.0, "episode/score": 0.06900538649483678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06900538649483678}
{"step": 452136, "time": 52512.85649347305, "episode/length": 67.0, "episode/score": 0.8268723043361206, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.03624730483670646}
{"step": 452224, "time": 52523.150284051895, "episode/length": 10.0, "episode/score": 0.9752198138019139, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.00646979948282933}
{"step": 452464, "time": 52550.92978644371, "episode/length": 66.0, "episode/score": 0.8157498255379778, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.021999808064038007}
{"step": 452536, "time": 52559.23411846161, "episode/length": 157.0, "episode/score": 0.555638935132265, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.04626392957925418}
{"step": 452568, "time": 52562.99602150917, "episode/length": 119.0, "episode/score": 0.6598787724890371, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.03175373192993902}
{"step": 453216, "time": 52639.42915272713, "episode/length": 80.0, "episode/score": 0.785144730492334, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.03514473130724127}
{"step": 453544, "time": 52677.30097913742, "episode/length": 231.0, "episode/score": 0.3326230524113498, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0544980647397324}
{"step": 453664, "time": 52691.18530464172, "episode/length": 288.0, "episode/score": 0.06298448341408402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06298448341408402}
{"step": 454048, "time": 52735.70908808708, "episode/length": 288.0, "episode/score": 0.09723586101745241, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09723586101745241}
{"step": 454408, "time": 52777.210456848145, "episode/length": 288.0, "episode/score": 0.0743475409143457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0743475409143457}
{"step": 454536, "time": 52791.93870282173, "episode/length": 288.0, "episode/score": 0.1094627063422422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1094627063422422}
{"step": 454680, "time": 52808.78713345528, "episode/length": 276.0, "episode/score": 0.22370906927301348, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.08620906687485785}
{"step": 454848, "time": 52828.2983083725, "episode/length": 288.0, "episode/score": 0.07684976209361594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07684976209361594}
{"step": 455528, "time": 52907.091166973114, "episode/length": 288.0, "episode/score": 0.08552235230843053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08552235230843053}
{"step": 455608, "time": 52916.317234277725, "episode/length": 115.0, "episode/score": 0.6791413637960204, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.038516355617844056}
{"step": 455856, "time": 52945.118903160095, "episode/length": 288.0, "episode/score": 0.07893404316121178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07893404316121178}
{"step": 455872, "time": 52946.9661757946, "episode/length": 227.0, "episode/score": 0.3504109316049835, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.05978591848497672}
{"step": 455976, "time": 52959.03910923004, "episode/length": 288.0, "episode/score": 0.07263175093839891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07263175093839891}
{"step": 456408, "time": 53008.89468407631, "episode/length": 53.0, "episode/score": 0.8492581896445586, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.014883157624524301}
{"step": 456720, "time": 53044.93189907074, "episode/length": 288.0, "episode/score": 0.07956279346052497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07956279346052497}
{"step": 456848, "time": 53059.68604707718, "episode/length": 288.0, "episode/score": 0.07420194991260587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07420194991260587}
{"step": 456920, "time": 53067.98765540123, "episode/length": 173.0, "episode/score": 0.5121796589514247, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.05280467137293954}
{"step": 456936, "time": 53069.83529257774, "episode/length": 260.0, "episode/score": 0.24581990899281436, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.05831991015696758}
{"step": 456968, "time": 53073.60224723816, "episode/length": 169.0, "episode/score": 0.5058101811129063, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.03393516203243507}
{"step": 457192, "time": 53099.57746839523, "episode/length": 166.0, "episode/score": 0.5253585633636249, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.044108565622082097}
{"step": 457504, "time": 53135.87208914757, "episode/length": 97.0, "episode/score": 0.7210678640607853, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.024192888120921907}
{"step": 457672, "time": 53155.18663454056, "episode/length": 102.0, "episode/score": 0.7122283341177535, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.030978358177890186}
{"step": 457848, "time": 53175.48368597031, "episode/length": 113.0, "episode/score": 0.6771140468518979, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.03023899361517124}
{"step": 458184, "time": 53214.263085365295, "episode/length": 288.0, "episode/score": 0.07485693316891684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07485693316891684}
{"step": 458237, "time": 53221.26912665367, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8834154705668604, "train/action_min": 0.0, "train/action_std": 1.723601634557857, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006406240766261553, "train/actor_opt_grad_steps": 113100.0, "train/actor_opt_loss": -21.81552603965582, "train/adv_mag": 0.40063051220982576, "train/adv_max": 0.20344487511834433, "train/adv_mean": 1.9184282722943504e-05, "train/adv_min": -0.3720696019571881, "train/adv_std": 0.02028978808761336, "train/cont_avg": 0.9958393895348837, "train/cont_loss_mean": 0.01381266446307648, "train/cont_loss_std": 0.21185623721414526, "train/cont_neg_acc": 0.3674862835660716, "train/cont_neg_loss": 2.643435630009637, "train/cont_pos_acc": 0.9999132949252462, "train/cont_pos_loss": 0.002674320715392918, "train/cont_pred": 0.9959365894628126, "train/cont_rate": 0.9958393895348837, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10743938240894052, "train/extr_critic_critic_opt_grad_steps": 113100.0, "train/extr_critic_critic_opt_loss": 8949.51644258721, "train/extr_critic_mag": 0.8058494939360508, "train/extr_critic_max": 0.8058494939360508, "train/extr_critic_mean": 0.5712147823599882, "train/extr_critic_min": 0.47359469990397607, "train/extr_critic_std": 0.044518835288147596, "train/extr_return_normed_mag": 0.44882584311241325, "train/extr_return_normed_max": 0.35923525205878326, "train/extr_return_normed_mean": 0.04750607022365858, "train/extr_return_normed_min": -0.29209565839102103, "train/extr_return_normed_std": 0.04956211808115937, "train/extr_return_rate": 0.9987421642902286, "train/extr_return_raw_mag": 0.8829631051351857, "train/extr_return_raw_max": 0.8829631051351857, "train/extr_return_raw_mean": 0.5712339509365171, "train/extr_return_raw_min": 0.23163219468538152, "train/extr_return_raw_std": 0.04956211816779403, "train/extr_reward_mag": 0.37858308304187865, "train/extr_reward_max": 0.37858308304187865, "train/extr_reward_mean": 0.0009438170631805998, "train/extr_reward_min": 1.183221506517987e-06, "train/extr_reward_std": 0.00762148657705375, "train/image_loss_mean": 0.08970208897493606, "train/image_loss_std": 0.1064906667138255, "train/model_loss_mean": 0.718633803378704, "train/model_loss_std": 0.3500386187850043, "train/model_opt_grad_norm": 12.453426605047182, "train/model_opt_grad_steps": 112998.10232558139, "train/model_opt_loss": 4796.204966842297, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6674.418604651163, "train/policy_entropy_mag": 1.437235797837723, "train/policy_entropy_max": 1.437235797837723, "train/policy_entropy_mean": 0.1127400981478913, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.15389439810154049, "train/policy_logprob_mag": 6.551080249076666, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1122330066769622, "train/policy_logprob_min": -6.551080249076666, "train/policy_logprob_std": 0.6497120665949444, "train/policy_randomness_mag": 0.7385931400365607, "train/policy_randomness_max": 0.7385931400365607, "train/policy_randomness_mean": 0.057936954342348634, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07908608017619266, "train/post_ent_mag": 34.00870134220567, "train/post_ent_max": 34.00870134220567, "train/post_ent_mean": 33.80424304341161, "train/post_ent_min": 33.611175625823265, "train/post_ent_std": 0.08274485836195392, "train/prior_ent_mag": 33.99004002061001, "train/prior_ent_max": 33.99004002061001, "train/prior_ent_mean": 33.574674579709075, "train/prior_ent_min": 33.01378392064294, "train/prior_ent_std": 0.1578445038130117, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0009827205227000292, "train/reward_loss_mean": 0.015119031279586082, "train/reward_loss_std": 0.13596822829527216, "train/reward_max_data": 0.5122478900065776, "train/reward_max_pred": 0.15325412362120872, "train/reward_neg_acc": 0.9997907921325329, "train/reward_neg_loss": 0.009689604252750098, "train/reward_pos_acc": 0.19679089084915494, "train/reward_pos_loss": 4.102851648045623, "train/reward_pred": 0.0008200382765079307, "train/reward_rate": 0.0013263081395348836, "train_stats/mean_log_entropy": 0.08082187876460098, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.0023458697833120823, "report/cont_loss_std": 0.007616964168846607, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0023458697833120823, "report/cont_pred": 0.9976852536201477, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05390912666916847, "report/image_loss_std": 0.07409362494945526, "report/model_loss_mean": 0.665381669998169, "report/model_loss_std": 0.07710396498441696, "report/post_ent_mag": 34.192405700683594, "report/post_ent_max": 34.192405700683594, "report/post_ent_mean": 33.99628829956055, "report/post_ent_min": 33.78153991699219, "report/post_ent_std": 0.07752431929111481, "report/prior_ent_mag": 33.978309631347656, "report/prior_ent_max": 33.978309631347656, "report/prior_ent_mean": 33.59114074707031, "report/prior_ent_min": 33.1007194519043, "report/prior_ent_std": 0.15814872086048126, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00017978239338845015, "report/reward_loss_mean": 0.009126611985266209, "report/reward_loss_std": 0.012779194861650467, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.03295314311981201, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009126611985266209, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0006394635420292616, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04735850542783737, "eval/cont_loss_std": 0.6781035661697388, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.247445106506348, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.007358161732554436, "eval/cont_pred": 0.9973333477973938, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1834373027086258, "eval/image_loss_std": 0.14562258124351501, "eval/model_loss_mean": 0.8446500301361084, "eval/model_loss_std": 0.9404078125953674, "eval/post_ent_mag": 34.20448303222656, "eval/post_ent_max": 34.20448303222656, "eval/post_ent_mean": 33.992401123046875, "eval/post_ent_min": 33.79092025756836, "eval/post_ent_std": 0.08799035847187042, "eval/prior_ent_mag": 34.07704162597656, "eval/prior_ent_max": 34.07704162597656, "eval/prior_ent_mean": 33.582271575927734, "eval/prior_ent_min": 33.058048248291016, "eval/prior_ent_std": 0.1578906923532486, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0002716064336709678, "eval/reward_loss_mean": 0.013854172080755234, "eval/reward_loss_std": 0.38215354084968567, "eval/reward_max_data": 0.27812498807907104, "eval/reward_max_pred": 0.019079923629760742, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0019066082313656807, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 12.236212730407715, "eval/reward_pred": 0.0005406273994594812, "eval/reward_rate": 0.0009765625, "replay/size": 457733.0, "replay/inserts": 8580.0, "replay/samples": 34320.0, "replay/insert_wait_avg": 1.5090673397748898e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.67079822389118e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2304.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.533638755480448e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2981870174408, "timer/env.step_count": 1072.0, "timer/env.step_total": 10.031760215759277, "timer/env.step_frac": 0.01002876976681391, "timer/env.step_avg": 0.009357985275894848, "timer/env.step_min": 0.008125543594360352, "timer/env.step_max": 0.03483223915100098, "timer/replay._sample_count": 34320.0, "timer/replay._sample_total": 16.884971857070923, "timer/replay._sample_frac": 0.016879938478561417, "timer/replay._sample_avg": 0.0004919863594717635, "timer/replay._sample_min": 0.0003540515899658203, "timer/replay._sample_max": 0.025586605072021484, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1360.0, "timer/agent.policy_total": 13.163253784179688, "timer/agent.policy_frac": 0.013159329842862324, "timer/agent.policy_avg": 0.009678863076602711, "timer/agent.policy_min": 0.008481502532958984, "timer/agent.policy_max": 0.040019989013671875, "timer/dataset_train_count": 2145.0, "timer/dataset_train_total": 0.37853121757507324, "timer/dataset_train_frac": 0.0003784183781275546, "timer/dataset_train_avg": 0.00017647143010492925, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0007681846618652344, "timer/agent.train_count": 2145.0, "timer/agent.train_total": 962.6253650188446, "timer/agent.train_frac": 0.962338408199135, "timer/agent.train_avg": 0.4487763939481793, "timer/agent.train_min": 0.4360802173614502, "timer/agent.train_max": 1.7336089611053467, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.49837779998779297, "timer/agent.report_frac": 0.000498229234498356, "timer/agent.report_avg": 0.24918889999389648, "timer/agent.report_min": 0.22878146171569824, "timer/agent.report_max": 0.2695963382720947, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5510787963867188e-05, "timer/dataset_eval_frac": 2.55031832457199e-08, "timer/dataset_eval_avg": 2.5510787963867188e-05, "timer/dataset_eval_min": 2.5510787963867188e-05, "timer/dataset_eval_max": 2.5510787963867188e-05, "fps": 8.577313147920213}
{"step": 458720, "time": 53276.837655067444, "episode/length": 288.0, "episode/score": 0.0638972495611938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0638972495611938}
{"step": 459232, "time": 53336.473850250244, "episode/length": 288.0, "episode/score": 0.04442595044957898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04442595044957898}
{"step": 459280, "time": 53342.0992307663, "episode/length": 288.0, "episode/score": 0.07259006792116907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07259006792116907}
{"step": 459504, "time": 53367.89708042145, "episode/length": 288.0, "episode/score": 0.03915398643107437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03915398643107437}
{"step": 459520, "time": 53369.76175451279, "episode/length": 208.0, "episode/score": 0.3989253110339632, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0489253103005467}
{"step": 459520, "time": 53369.76857662201, "episode/length": 251.0, "episode/score": 0.27597016139651487, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.060345151722401624}
{"step": 459776, "time": 53399.31815338135, "episode/length": 31.0, "episode/score": 0.9125300670526144, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.009405074884455189}
{"step": 459984, "time": 53423.504887104034, "episode/length": 288.0, "episode/score": 0.0652215844570776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0652215844570776}
{"step": 460096, "time": 53437.0959277153, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 460096, "time": 53438.05906558037, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 460096, "time": 53438.3509311676, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 460096, "time": 53438.86193943024, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 460096, "time": 53438.88585782051, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 460096, "time": 53440.68795990944, "eval_episode/length": 207.0, "eval_episode/score": 0.3531250059604645, "eval_episode/reward_rate": 0.004807692307692308}
{"step": 460096, "time": 53441.17048573494, "eval_episode/length": 235.0, "eval_episode/score": 0.265625, "eval_episode/reward_rate": 0.00423728813559322}
{"step": 460096, "time": 53441.562870025635, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 460496, "time": 53487.6805768013, "episode/length": 288.0, "episode/score": 0.07942914050394734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07942914050394734}
{"step": 460672, "time": 53508.12041735649, "episode/length": 85.0, "episode/score": 0.7631381026529027, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.028763122792753393}
{"step": 461016, "time": 53547.80904841423, "episode/length": 286.0, "episode/score": 0.1584973820792186, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.052247379317265086}
{"step": 461032, "time": 53549.64815950394, "episode/length": 190.0, "episode/score": 0.43610051139549455, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.029850507815723404}
{"step": 461544, "time": 53608.79520153999, "episode/length": 288.0, "episode/score": 0.07872513317587959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07872513317587959}
{"step": 461592, "time": 53614.47483468056, "episode/length": 288.0, "episode/score": 0.07015318628197065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07015318628197065}
{"step": 461832, "time": 53642.34008002281, "episode/length": 288.0, "episode/score": 0.04196521926019159, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04196521926019159}
{"step": 461880, "time": 53647.91932439804, "episode/length": 107.0, "episode/score": 0.6805159882474356, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.014891003911117195}
{"step": 461984, "time": 53659.93532681465, "episode/length": 18.0, "episode/score": 0.9470747438893454, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0033247462700387587}
{"step": 462088, "time": 53672.02962112427, "episode/length": 288.0, "episode/score": 0.03762597832775327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03762597832775327}
{"step": 462128, "time": 53676.65572810173, "episode/length": 66.0, "episode/score": 0.8114352397596463, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.01768525189885395}
{"step": 462448, "time": 53713.67963504791, "episode/length": 112.0, "episode/score": 0.681921539828295, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.03192157877504087}
{"step": 462808, "time": 53755.19746637344, "episode/length": 288.0, "episode/score": 0.058587426461087944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058587426461087944}
{"step": 462872, "time": 53762.64929151535, "episode/length": 97.0, "episode/score": 0.71463465348603, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.017759673238799678}
{"step": 462984, "time": 53775.532462358475, "episode/length": 288.0, "episode/score": 0.07052225747102625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07052225747102625}
{"step": 463104, "time": 53789.34944605827, "episode/length": 28.0, "episode/score": 0.9253278215533953, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.012827798526444667}
{"step": 463192, "time": 53799.55268239975, "episode/length": 150.0, "episode/score": 0.5795889585724865, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.04833897273150001}
{"step": 463344, "time": 53817.04672265053, "episode/length": 288.0, "episode/score": 0.08664896508963693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08664896508963693}
{"step": 463472, "time": 53831.93945288658, "episode/length": 45.0, "episode/score": 0.8691834009788124, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.009808372864512194}
{"step": 464008, "time": 53894.36786055565, "episode/length": 101.0, "episode/score": 0.7052004776827232, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.020825501681741798}
{"step": 464104, "time": 53905.52693319321, "episode/length": 78.0, "episode/score": 0.7721804360780027, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.015930424314234415}
{"step": 464192, "time": 53915.70549416542, "episode/length": 288.0, "episode/score": 0.04271312080024359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04271312080024359}
{"step": 464296, "time": 53927.68756842613, "episode/length": 185.0, "episode/score": 0.4657061547907517, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.04383116486067706}
{"step": 464440, "time": 53944.474469423294, "episode/length": 288.0, "episode/score": 0.08388757621932541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08388757621932541}
{"step": 464704, "time": 53975.03875517845, "episode/length": 32.0, "episode/score": 0.9099070697619709, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.009907110745984937}
{"step": 464736, "time": 53978.73455452919, "episode/length": 67.0, "episode/score": 0.8047111596785896, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.014086197679461065}
{"step": 464760, "time": 53981.50957298279, "episode/length": 288.0, "episode/score": 0.04511712044521232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04511712044521232}
{"step": 464976, "time": 54006.52595567703, "episode/length": 108.0, "episode/score": 0.6853925943654247, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.022892587665722886}
{"step": 465264, "time": 54039.781601667404, "episode/length": 156.0, "episode/score": 0.5316233768594145, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.019123381620801183}
{"step": 465296, "time": 54043.46593594551, "episode/length": 288.0, "episode/score": 0.042929843185021355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042929843185021355}
{"step": 465488, "time": 54065.60533261299, "episode/length": 63.0, "episode/score": 0.8223152349748943, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.019190221202961766}
{"step": 465656, "time": 54084.90386033058, "episode/length": 288.0, "episode/score": 0.03012696742865728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03012696742865728}
{"step": 466096, "time": 54135.67984890938, "episode/length": 173.0, "episode/score": 0.49266973271832626, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.033294747744633924}
{"step": 466608, "time": 54194.6225707531, "episode/length": 288.0, "episode/score": 0.020333389764942922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020333389764942922}
{"step": 466833, "time": 54221.459285497665, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.872446505822868, "train/action_min": 0.0, "train/action_std": 1.8308994452529979, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00760091605996626, "train/actor_opt_grad_steps": 115245.0, "train/actor_opt_loss": -17.023289150166736, "train/adv_mag": 0.44522248709870277, "train/adv_max": 0.25983407424989147, "train/adv_mean": 0.0023848625817910057, "train/adv_min": -0.3938744451119521, "train/adv_std": 0.02254884253543253, "train/cont_avg": 0.9956921728971962, "train/cont_loss_mean": 0.014010531941502764, "train/cont_loss_std": 0.21252166661520916, "train/cont_neg_acc": 0.3426924288483723, "train/cont_neg_loss": 2.6111778862508594, "train/cont_pos_acc": 0.9998762532372341, "train/cont_pos_loss": 0.0027555338151657206, "train/cont_pred": 0.9958182378350017, "train/cont_rate": 0.9956921728971962, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1374786828392159, "train/extr_critic_critic_opt_grad_steps": 115245.0, "train/extr_critic_critic_opt_loss": 9627.968352986274, "train/extr_critic_mag": 0.7633733125490563, "train/extr_critic_max": 0.7633733125490563, "train/extr_critic_mean": 0.5728368550260491, "train/extr_critic_min": 0.4636436672968285, "train/extr_critic_std": 0.03889777629731971, "train/extr_return_normed_mag": 0.48015635008009794, "train/extr_return_normed_max": 0.36899976836186704, "train/extr_return_normed_mean": 0.046836555865810856, "train/extr_return_normed_min": -0.3327782258530643, "train/extr_return_normed_std": 0.04575943201780319, "train/extr_return_rate": 0.9686295685367049, "train/extr_return_raw_mag": 0.8973849549471775, "train/extr_return_raw_max": 0.8973849549471775, "train/extr_return_raw_mean": 0.5752217713917527, "train/extr_return_raw_min": 0.19560696045371972, "train/extr_return_raw_std": 0.045759431939467646, "train/extr_reward_mag": 0.46838080938731397, "train/extr_reward_max": 0.46838080938731397, "train/extr_reward_mean": 0.0014362005817716958, "train/extr_reward_min": 1.173153101840866e-06, "train/extr_reward_std": 0.013455192235877267, "train/image_loss_mean": 0.08949066583659047, "train/image_loss_std": 0.10701933402185128, "train/model_loss_mean": 0.7191876445975259, "train/model_loss_std": 0.35782517510179046, "train/model_opt_grad_norm": 12.42277138478288, "train/model_opt_grad_steps": 115141.33177570094, "train/model_opt_loss": 3733.583491530374, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5186.915887850468, "train/policy_entropy_mag": 1.4841101041464049, "train/policy_entropy_max": 1.4841101041464049, "train/policy_entropy_mean": 0.10960652125633766, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.149278088568527, "train/policy_logprob_mag": 6.551080244723882, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10925979202038774, "train/policy_logprob_min": -6.551080244723882, "train/policy_logprob_std": 0.6485206264758778, "train/policy_randomness_mag": 0.7626817688763698, "train/policy_randomness_max": 0.7626817688763698, "train/policy_randomness_mean": 0.05632661377018857, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07671376688527727, "train/post_ent_mag": 34.05410618648351, "train/post_ent_max": 34.05410618648351, "train/post_ent_mean": 33.841418720851436, "train/post_ent_min": 33.637567377536094, "train/post_ent_std": 0.08706447140914257, "train/prior_ent_mag": 34.001362666905486, "train/prior_ent_max": 34.001362666905486, "train/prior_ent_mean": 33.560348492916496, "train/prior_ent_min": 32.96918908235069, "train/prior_ent_std": 0.16642209803946664, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0010913875681308977, "train/reward_loss_mean": 0.015686422919367102, "train/reward_loss_std": 0.14184743472348862, "train/reward_max_data": 0.5239180063994201, "train/reward_max_pred": 0.1821049747065963, "train/reward_neg_acc": 0.9998216935407336, "train/reward_neg_loss": 0.009782661437970873, "train/reward_pos_acc": 0.2538653749190731, "train/reward_pos_loss": 3.9681380030549604, "train/reward_pred": 0.000895651506159942, "train/reward_rate": 0.0014876606308411216, "train_stats/mean_log_entropy": 0.08180597903473037, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.0218197014182806, "report/cont_loss_std": 0.30314746499061584, "report/cont_neg_acc": 0.375, "report/cont_neg_loss": 2.470156192779541, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0025414624251425266, "report/cont_pred": 0.9941802620887756, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10603462159633636, "report/image_loss_std": 0.11213967204093933, "report/model_loss_mean": 0.7486718893051147, "report/model_loss_std": 0.4883197546005249, "report/post_ent_mag": 34.00035095214844, "report/post_ent_max": 34.00035095214844, "report/post_ent_mean": 33.80157470703125, "report/post_ent_min": 33.567893981933594, "report/post_ent_std": 0.09944477677345276, "report/prior_ent_mag": 34.03638458251953, "report/prior_ent_max": 34.03638458251953, "report/prior_ent_mean": 33.45843505859375, "report/prior_ent_min": 32.859588623046875, "report/prior_ent_std": 0.19814085960388184, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0016616673674434423, "report/reward_loss_mean": 0.020817521959543228, "report/reward_loss_std": 0.21889956295490265, "report/reward_max_data": 0.6470312476158142, "report/reward_max_pred": 0.12912249565124512, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009878446348011494, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.7437493801116943, "report/reward_pred": 0.0009201568318530917, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.050382405519485474, "eval/cont_loss_std": 0.6608313322067261, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.387234687805176, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.00947538297623396, "eval/cont_pred": 0.996873140335083, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18394502997398376, "eval/image_loss_std": 0.1528497338294983, "eval/model_loss_mean": 0.8627071976661682, "eval/model_loss_std": 1.0770736932754517, "eval/post_ent_mag": 34.00482940673828, "eval/post_ent_max": 34.00482940673828, "eval/post_ent_mean": 33.80643081665039, "eval/post_ent_min": 33.59611511230469, "eval/post_ent_std": 0.08727078884840012, "eval/prior_ent_mag": 34.02606964111328, "eval/prior_ent_max": 34.02606964111328, "eval/prior_ent_mean": 33.45917892456055, "eval/prior_ent_min": 32.82635498046875, "eval/prior_ent_std": 0.21318162977695465, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008392333984375, "eval/reward_loss_mean": 0.0283797699958086, "eval/reward_loss_std": 0.49231547117233276, "eval/reward_max_data": 0.36250001192092896, "eval/reward_max_pred": 0.021813035011291504, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0021256455220282078, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.963534355163574, "eval/reward_pred": 0.0006955958670005202, "eval/reward_rate": 0.0029296875, "replay/size": 466329.0, "replay/inserts": 8596.0, "replay/samples": 34384.0, "replay/insert_wait_avg": 1.5105575447916818e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.6732312651111e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2072.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0083310852639924e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1789791584015, "timer/env.step_count": 1075.0, "timer/env.step_total": 9.976531505584717, "timer/env.step_frac": 0.009974746233898506, "timer/env.step_avg": 0.009280494423799737, "timer/env.step_min": 0.008176088333129883, "timer/env.step_max": 0.03475189208984375, "timer/replay._sample_count": 34384.0, "timer/replay._sample_total": 16.783601760864258, "timer/replay._sample_frac": 0.016780598383488107, "timer/replay._sample_avg": 0.00048812243371522385, "timer/replay._sample_min": 0.000392913818359375, "timer/replay._sample_max": 0.02603435516357422, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1334.0, "timer/agent.policy_total": 13.407593488693237, "timer/agent.policy_frac": 0.013405194238310256, "timer/agent.policy_avg": 0.010050669781629114, "timer/agent.policy_min": 0.008806467056274414, "timer/agent.policy_max": 0.08515429496765137, "timer/dataset_train_count": 2149.0, "timer/dataset_train_total": 0.38084864616394043, "timer/dataset_train_frac": 0.00038078049439151855, "timer/dataset_train_avg": 0.000177221333719842, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0011944770812988281, "timer/agent.train_count": 2149.0, "timer/agent.train_total": 962.4166922569275, "timer/agent.train_frac": 0.9622444705514117, "timer/agent.train_avg": 0.4478439703382631, "timer/agent.train_min": 0.4373490810394287, "timer/agent.train_max": 0.616490364074707, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4779543876647949, "timer/agent.report_frac": 0.0004778688590985672, "timer/agent.report_avg": 0.23897719383239746, "timer/agent.report_min": 0.23430585861206055, "timer/agent.report_max": 0.24364852905273438, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.62213506259047e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 8.59434287916677}
{"step": 467048, "time": 54246.3979203701, "episode/length": 288.0, "episode/score": 0.04018013247025465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04018013247025465}
{"step": 467072, "time": 54249.13516950607, "episode/length": 288.0, "episode/score": 0.023486647616891787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023486647616891787}
{"step": 467576, "time": 54307.182326078415, "episode/length": 288.0, "episode/score": 0.035278004790654904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035278004790654904}
{"step": 467608, "time": 54310.90445590019, "episode/length": 288.0, "episode/score": 0.040935186449303274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040935186449303274}
{"step": 467800, "time": 54333.04781341553, "episode/length": 288.0, "episode/score": 0.04595139989410768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04595139989410768}
{"step": 467968, "time": 54352.3131172657, "episode/length": 288.0, "episode/score": 0.022810089109270848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022810089109270848}
{"step": 468408, "time": 54403.04622530937, "episode/length": 288.0, "episode/score": 0.028699494274889048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028699494274889048}
{"step": 468416, "time": 54403.97521305084, "episode/length": 100.0, "episode/score": 0.7046020048670698, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.017101981649489062}
{"step": 468720, "time": 54439.131801605225, "episode/length": 208.0, "episode/score": 0.3704567963555121, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.020456809868420578}
{"step": 468720, "time": 54439.13703894615, "episode/length": 93.0, "episode/score": 0.7232967908159083, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.013921744724171958}
{"step": 468920, "time": 54462.18195796013, "episode/length": 288.0, "episode/score": 0.04522861391376409, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04522861391376409}
{"step": 469384, "time": 54515.57310581207, "episode/length": 288.0, "episode/score": 0.025725397638609593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025725397638609593}
{"step": 469888, "time": 54573.513006448746, "episode/length": 288.0, "episode/score": 0.04832410354340766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04832410354340766}
{"step": 469928, "time": 54578.10571503639, "episode/length": 189.0, "episode/score": 0.4587887074062422, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.04941370207005491}
{"step": 470080, "time": 54598.118998765945, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 470080, "time": 54599.1411216259, "eval_episode/length": 207.0, "eval_episode/score": 0.3531250059604645, "eval_episode/reward_rate": 0.004807692307692308}
{"step": 470080, "time": 54599.87045049667, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 470080, "time": 54600.514930963516, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 54600.52270722389, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 54600.52811193466, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 54600.53329205513, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 54600.53842520714, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 54600.54362797737, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470112, "time": 54604.24898433685, "episode/length": 288.0, "episode/score": 0.05100379680224876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05100379680224876}
{"step": 470120, "time": 54605.188039302826, "episode/length": 212.0, "episode/score": 0.3857506619965676, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.048250667590323815}
{"step": 471032, "time": 54710.51941561699, "episode/length": 288.0, "episode/score": 0.020007017155023732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020007017155023732}
{"step": 471032, "time": 54710.52813100815, "episode/length": 288.0, "episode/score": 0.03623838556096359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03623838556096359}
{"step": 471232, "time": 54733.53907442093, "episode/length": 288.0, "episode/score": 0.03271185060545179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03271185060545179}
{"step": 471512, "time": 54765.7308716774, "episode/length": 34.0, "episode/score": 0.9011525295308189, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.00740251556534588}
{"step": 471696, "time": 54786.95514512062, "episode/length": 288.0, "episode/score": 0.03551194631141641, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03551194631141641}
{"step": 471840, "time": 54803.51155638695, "episode/length": 243.0, "episode/score": 0.2772789933407438, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.03665399760591015}
{"step": 472032, "time": 54825.715601205826, "episode/length": 124.0, "episode/score": 0.6432755187259573, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0307754924859438}
{"step": 472240, "time": 54849.85897684097, "episode/length": 288.0, "episode/score": 0.017877948456415993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017877948456415993}
{"step": 472424, "time": 54871.04347062111, "episode/length": 288.0, "episode/score": 0.040618184382978484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040618184382978484}
{"step": 472432, "time": 54872.01882195473, "episode/length": 288.0, "episode/score": 0.0452971200856922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0452971200856922}
{"step": 472840, "time": 54919.2710916996, "episode/length": 124.0, "episode/score": 0.6305029643394988, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.018002923780400693}
{"step": 473344, "time": 54977.077775001526, "episode/length": 288.0, "episode/score": 0.04587949817531012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04587949817531012}
{"step": 473824, "time": 55031.98112440109, "episode/length": 288.0, "episode/score": 0.032085561361540726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032085561361540726}
{"step": 474008, "time": 55053.122561216354, "episode/length": 288.0, "episode/score": 0.08940573070808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08940573070808}
{"step": 474136, "time": 55067.95000886917, "episode/length": 212.0, "episode/score": 0.39881348676976813, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.061313481973456874}
{"step": 474288, "time": 55085.463206768036, "episode/length": 180.0, "episode/score": 0.4878210658825992, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.05032106629005284}
{"step": 474344, "time": 55091.880905628204, "episode/length": 288.0, "episode/score": 0.07291620103569585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07291620103569585}
{"step": 474552, "time": 55115.74411392212, "episode/length": 288.0, "episode/score": 0.05325721857025201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05325721857025201}
{"step": 474736, "time": 55136.799751996994, "episode/length": 288.0, "episode/score": 0.07620722942158409, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07620722942158409}
{"step": 475465, "time": 55221.65671610832, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4872334798177085, "train/action_min": 0.0, "train/action_std": 1.8045205391115613, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009889248337087876, "train/actor_opt_grad_steps": 117395.0, "train/actor_opt_loss": -9.919680734616122, "train/adv_mag": 0.4811726448436578, "train/adv_max": 0.2885687356745755, "train/adv_mean": 0.003700993236937696, "train/adv_min": -0.44308645747326036, "train/adv_std": 0.02751124045311439, "train/cont_avg": 0.9957682291666666, "train/cont_loss_mean": 0.01372796145625654, "train/cont_loss_std": 0.20949391890705252, "train/cont_neg_acc": 0.3644903706055935, "train/cont_neg_loss": 2.6048244981712085, "train/cont_pos_acc": 0.9998955710066689, "train/cont_pos_loss": 0.0027362691013237323, "train/cont_pred": 0.9958313623512233, "train/cont_rate": 0.9957682291666666, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14017201375854374, "train/extr_critic_critic_opt_grad_steps": 117395.0, "train/extr_critic_critic_opt_loss": 12372.405219184027, "train/extr_critic_mag": 0.8565459759147079, "train/extr_critic_max": 0.8565459759147079, "train/extr_critic_mean": 0.7230925416504895, "train/extr_critic_min": 0.5971515239388855, "train/extr_critic_std": 0.025685679202002508, "train/extr_return_normed_mag": 0.5112258413875544, "train/extr_return_normed_max": 0.3623262177462931, "train/extr_return_normed_mean": 0.04545711111967211, "train/extr_return_normed_min": -0.4035710347471414, "train/extr_return_normed_std": 0.03883944929111749, "train/extr_return_rate": 0.998152703874641, "train/extr_return_raw_mag": 1.043662628641835, "train/extr_return_raw_max": 1.043662628641835, "train/extr_return_raw_mean": 0.7267935585092615, "train/extr_return_raw_min": 0.2777653764243479, "train/extr_return_raw_std": 0.03883944927387078, "train/extr_reward_mag": 0.4089876032537884, "train/extr_reward_max": 0.4089876032537884, "train/extr_reward_mean": 0.001523233060180684, "train/extr_reward_min": 1.118690879256637e-06, "train/extr_reward_std": 0.01208442264005835, "train/image_loss_mean": 0.09008542581081942, "train/image_loss_std": 0.10769123573684031, "train/model_loss_mean": 0.719438712630007, "train/model_loss_std": 0.35602303235619154, "train/model_opt_grad_norm": 12.555025963871568, "train/model_opt_grad_steps": 117289.39351851853, "train/model_opt_loss": 4168.178388807509, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5787.037037037037, "train/policy_entropy_mag": 1.455487177327827, "train/policy_entropy_max": 1.455487177327827, "train/policy_entropy_mean": 0.10886426052699487, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.14146352304076706, "train/policy_logprob_mag": 6.551080284295259, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10870608725343589, "train/policy_logprob_min": -6.551080284295259, "train/policy_logprob_std": 0.6460525432118663, "train/policy_randomness_mag": 0.7479724917146895, "train/policy_randomness_max": 0.7479724917146895, "train/policy_randomness_mean": 0.05594516655913106, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07269787455529526, "train/post_ent_mag": 34.16701710665667, "train/post_ent_max": 34.16701710665667, "train/post_ent_mean": 33.939294974009194, "train/post_ent_min": 33.7233460744222, "train/post_ent_std": 0.09148671019270464, "train/prior_ent_mag": 33.86603245911775, "train/prior_ent_max": 33.86603245911775, "train/prior_ent_mean": 33.4104194994326, "train/prior_ent_min": 32.82675610648261, "train/prior_ent_std": 0.17709964134350972, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0010668944461805815, "train/reward_loss_mean": 0.015625301683838997, "train/reward_loss_std": 0.14049961829678742, "train/reward_max_data": 0.4989236018920093, "train/reward_max_pred": 0.1797563968985169, "train/reward_neg_acc": 0.9998460652099715, "train/reward_neg_loss": 0.009674797492119035, "train/reward_pos_acc": 0.25656565779989415, "train/reward_pos_loss": 3.9533148922703485, "train/reward_pred": 0.0008756751210765085, "train/reward_rate": 0.0015190972222222222, "train_stats/mean_log_entropy": 0.08696900755167007, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.024782344698905945, "report/cont_loss_std": 0.3510250151157379, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 3.7357306480407715, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002910350216552615, "report/cont_pred": 0.9951978921890259, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10863061994314194, "report/image_loss_std": 0.1099993884563446, "report/model_loss_mean": 0.7497046589851379, "report/model_loss_std": 0.49810275435447693, "report/post_ent_mag": 34.36247253417969, "report/post_ent_max": 34.36247253417969, "report/post_ent_mean": 34.1375846862793, "report/post_ent_min": 33.877323150634766, "report/post_ent_std": 0.0919015184044838, "report/prior_ent_mag": 33.83720397949219, "report/prior_ent_max": 33.83720397949219, "report/prior_ent_mean": 33.38446044921875, "report/prior_ent_min": 32.67919158935547, "report/prior_ent_std": 0.18924589455127716, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004059517232235521, "report/reward_loss_mean": 0.0162916611880064, "report/reward_loss_std": 0.2158411592245102, "report/reward_max_data": 0.22843751311302185, "report/reward_max_pred": 0.028746366500854492, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009559357538819313, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.903440475463867, "report/reward_pred": 0.0008549258345738053, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.028346722945570946, "eval/cont_loss_std": 0.48802313208580017, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.597684860229492, "eval/cont_pos_acc": 0.9980430603027344, "eval/cont_pos_loss": 0.007663086988031864, "eval/cont_pred": 0.9959051012992859, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18057236075401306, "eval/image_loss_std": 0.14034484326839447, "eval/model_loss_mean": 0.8167034983634949, "eval/model_loss_std": 0.584418535232544, "eval/post_ent_mag": 34.36336898803711, "eval/post_ent_max": 34.36336898803711, "eval/post_ent_mean": 34.098411560058594, "eval/post_ent_min": 33.86649703979492, "eval/post_ent_std": 0.10122387111186981, "eval/prior_ent_mag": 33.94198226928711, "eval/prior_ent_max": 33.94198226928711, "eval/prior_ent_mean": 33.380367279052734, "eval/prior_ent_min": 32.77675247192383, "eval/prior_ent_std": 0.1788468211889267, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.007784358691424131, "eval/reward_loss_std": 0.18619367480278015, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.47213947772979736, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.007784359622746706, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.001073605613783002, "eval/reward_rate": 0.0, "replay/size": 474961.0, "replay/inserts": 8632.0, "replay/samples": 34528.0, "replay/insert_wait_avg": 1.5285359807761318e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.556297361464054e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0212193723368396e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.18376994133, "timer/env.step_count": 1079.0, "timer/env.step_total": 9.980360746383667, "timer/env.step_frac": 0.009978526993063593, "timer/env.step_avg": 0.009249639245953352, "timer/env.step_min": 0.008245468139648438, "timer/env.step_max": 0.03519916534423828, "timer/replay._sample_count": 34528.0, "timer/replay._sample_total": 16.740269899368286, "timer/replay._sample_frac": 0.016737194106189363, "timer/replay._sample_avg": 0.0004848317278547349, "timer/replay._sample_min": 0.0003409385681152344, "timer/replay._sample_max": 0.02595686912536621, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1368.0, "timer/agent.policy_total": 13.28025197982788, "timer/agent.policy_frac": 0.013277811917110883, "timer/agent.policy_avg": 0.0097077865349619, "timer/agent.policy_min": 0.008765697479248047, "timer/agent.policy_max": 0.03592419624328613, "timer/dataset_train_count": 2158.0, "timer/dataset_train_total": 0.38013410568237305, "timer/dataset_train_frac": 0.0003800642612953732, "timer/dataset_train_avg": 0.00017615111477403757, "timer/dataset_train_min": 8.749961853027344e-05, "timer/dataset_train_max": 0.0012164115905761719, "timer/agent.train_count": 2158.0, "timer/agent.train_total": 962.2448663711548, "timer/agent.train_frac": 0.9620680671788939, "timer/agent.train_avg": 0.4458966016548447, "timer/agent.train_min": 0.4332249164581299, "timer/agent.train_max": 0.5901534557342529, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4791092872619629, "timer/agent.report_frac": 0.00047902125755356647, "timer/agent.report_avg": 0.23955464363098145, "timer/agent.report_min": 0.23390483856201172, "timer/agent.report_max": 0.24520444869995117, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.6459599801170363e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 8.630303290945887}
{"step": 475560, "time": 55232.43672800064, "episode/length": 193.0, "episode/score": 0.4393067051936441, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.04243171196901585}
{"step": 475656, "time": 55243.492010593414, "episode/length": 288.0, "episode/score": 0.03262843556660755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03262843556660755}
{"step": 476136, "time": 55298.77912402153, "episode/length": 288.0, "episode/score": 0.06030637330536592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06030637330536592}
{"step": 476448, "time": 55334.63751888275, "episode/length": 288.0, "episode/score": 0.08236566784273691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08236566784273691}
{"step": 476600, "time": 55352.04405665398, "episode/length": 288.0, "episode/score": 0.05083348577704783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05083348577704783}
{"step": 476656, "time": 55358.45932507515, "episode/length": 288.0, "episode/score": 0.054572900793914414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054572900793914414}
{"step": 476864, "time": 55382.17850732803, "episode/length": 288.0, "episode/score": 0.05164552265569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05164552265569}
{"step": 477048, "time": 55403.11305427551, "episode/length": 288.0, "episode/score": 0.04418812911558234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04418812911558234}
{"step": 477536, "time": 55458.89979887009, "episode/length": 60.0, "episode/score": 0.8338048354180501, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.021304836232957314}
{"step": 477872, "time": 55497.13330388069, "episode/length": 288.0, "episode/score": 0.03228719286244086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03228719286244086}
{"step": 477968, "time": 55508.135915756226, "episode/length": 288.0, "episode/score": 0.041223164505197474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041223164505197474}
{"step": 478448, "time": 55562.923875808716, "episode/length": 288.0, "episode/score": 0.05989320078936089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05989320078936089}
{"step": 478472, "time": 55565.64979147911, "episode/length": 62.0, "episode/score": 0.8196636778625361, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.013413702519301296}
{"step": 478760, "time": 55598.51332330704, "episode/length": 288.0, "episode/score": 0.05213436595369103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05213436595369103}
{"step": 478912, "time": 55615.82482433319, "episode/length": 288.0, "episode/score": 0.05566755040570115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05566755040570115}
{"step": 478968, "time": 55622.292110681534, "episode/length": 288.0, "episode/score": 0.05070500255169463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05070500255169463}
{"step": 479176, "time": 55645.99655508995, "episode/length": 288.0, "episode/score": 0.05261499920800361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05261499920800361}
{"step": 479848, "time": 55722.62972974777, "episode/length": 288.0, "episode/score": 0.06265016645920696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06265016645920696}
{"step": 480064, "time": 55748.503294467926, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 480064, "time": 55748.623752355576, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 480064, "time": 55752.11978197098, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 55752.12640976906, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 55752.131705999374, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 55752.13692569733, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 55752.141971349716, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 55752.147106170654, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480184, "time": 55765.90942502022, "episode/length": 288.0, "episode/score": 0.06854163131572477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06854163131572477}
{"step": 480432, "time": 55794.24068689346, "episode/length": 30.0, "episode/score": 0.9109206942382571, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.004670695053164309}
{"step": 480488, "time": 55800.62266397476, "episode/length": 79.0, "episode/score": 0.7687656102233404, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.015640574961139464}
{"step": 480760, "time": 55831.94380569458, "episode/length": 288.0, "episode/score": 0.0350896829481826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0350896829481826}
{"step": 480784, "time": 55834.70389294624, "episode/length": 288.0, "episode/score": 0.051707670185919596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051707670185919596}
{"step": 481072, "time": 55867.58769130707, "episode/length": 288.0, "episode/score": 0.055838014492792354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055838014492792354}
{"step": 481120, "time": 55873.077689409256, "episode/length": 78.0, "episode/score": 0.7648364150725229, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.008586361835796197}
{"step": 481224, "time": 55884.896293878555, "episode/length": 288.0, "episode/score": 0.03907074636174457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03907074636174457}
{"step": 481280, "time": 55891.31903576851, "episode/length": 288.0, "episode/score": 0.05148869717345406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05148869717345406}
{"step": 481320, "time": 55895.86453318596, "episode/length": 69.0, "episode/score": 0.8002003980546988, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.015825356738901064}
{"step": 481488, "time": 55915.001416921616, "episode/length": 288.0, "episode/score": 0.04210893492273726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04210893492273726}
{"step": 482344, "time": 56012.590393304825, "episode/length": 152.0, "episode/score": 0.5414770433325202, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.016477058996201777}
{"step": 482744, "time": 56058.17829489708, "episode/length": 288.0, "episode/score": 0.048893378722425496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048893378722425496}
{"step": 483072, "time": 56095.58262848854, "episode/length": 90.0, "episode/score": 0.7324902071606516, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.013740198982475249}
{"step": 483096, "time": 56098.32623434067, "episode/length": 288.0, "episode/score": 0.022799441016275068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022799441016275068}
{"step": 483296, "time": 56121.168561935425, "episode/length": 68.0, "episode/score": 0.8008457607052151, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0133457074684884}
{"step": 483384, "time": 56131.62990403175, "episode/length": 288.0, "episode/score": 0.03997340760957968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03997340760957968}
{"step": 483536, "time": 56148.93666148186, "episode/length": 288.0, "episode/score": 0.037128483009439606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037128483009439606}
{"step": 483592, "time": 56155.31664133072, "episode/length": 288.0, "episode/score": 0.014682744755418753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014682744755418753}
{"step": 483632, "time": 56159.88296961784, "episode/length": 288.0, "episode/score": 0.042617516770519615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042617516770519615}
{"step": 483776, "time": 56176.338109493256, "episode/length": 285.0, "episode/score": 0.14540982173804196, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.03603481952615084}
{"step": 484169, "time": 56222.169206142426, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7912393272469895, "train/action_min": 0.0, "train/action_std": 1.9854663178461407, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005329158428389955, "train/actor_opt_grad_steps": 119565.0, "train/actor_opt_loss": -14.87944689365702, "train/adv_mag": 0.4263075430185423, "train/adv_max": 0.18952016409384, "train/adv_mean": -0.0030468088972915998, "train/adv_min": -0.38271638163185995, "train/adv_std": 0.014484212131435992, "train/cont_avg": 0.9955965094610092, "train/cont_loss_mean": 0.014104919667236097, "train/cont_loss_std": 0.21350159169251628, "train/cont_neg_acc": 0.3740723157011041, "train/cont_neg_loss": 2.5378396735479094, "train/cont_pos_acc": 0.9998919928292616, "train/cont_pos_loss": 0.0027811113427769086, "train/cont_pred": 0.9956968333743034, "train/cont_rate": 0.9955965094610092, "train/dyn_loss_mean": 1.0000019866392154, "train/dyn_loss_std": 4.0504034211295184e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08060733596751586, "train/extr_critic_critic_opt_grad_steps": 119565.0, "train/extr_critic_critic_opt_loss": 12114.253077515768, "train/extr_critic_mag": 0.8361981325193283, "train/extr_critic_max": 0.8361981325193283, "train/extr_critic_mean": 0.7177229023307835, "train/extr_critic_min": 0.5936371109901218, "train/extr_critic_std": 0.0223636711144461, "train/extr_return_normed_mag": 0.44944862870995056, "train/extr_return_normed_max": 0.21913008952359542, "train/extr_return_normed_mean": 0.019562834499984843, "train/extr_return_normed_min": -0.3635606702861436, "train/extr_return_normed_std": 0.027502580947422105, "train/extr_return_rate": 0.9995535584764743, "train/extr_return_raw_mag": 0.9142433172519054, "train/extr_return_raw_max": 0.9142433172519054, "train/extr_return_raw_mean": 0.7146760960784527, "train/extr_return_raw_min": 0.3315525574421664, "train/extr_return_raw_std": 0.027502580891884523, "train/extr_reward_mag": 0.32719142830699954, "train/extr_reward_max": 0.32719142830699954, "train/extr_reward_mean": 0.0008439873082193742, "train/extr_reward_min": 1.2112320016283507e-06, "train/extr_reward_std": 0.006193301624430497, "train/image_loss_mean": 0.09189353888392995, "train/image_loss_std": 0.10828911909543046, "train/model_loss_mean": 0.7220496915349173, "train/model_loss_std": 0.37023513111362766, "train/model_opt_grad_norm": 12.048131253741204, "train/model_opt_grad_steps": 119457.6743119266, "train/model_opt_loss": 4020.9440525999858, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5573.394495412844, "train/policy_entropy_mag": 1.4033683188464663, "train/policy_entropy_max": 1.4033683188464663, "train/policy_entropy_mean": 0.10089245021616647, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13121801542989706, "train/policy_logprob_mag": 6.551080277206701, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10086000286931292, "train/policy_logprob_min": -6.551080277206701, "train/policy_logprob_std": 0.6406414599046795, "train/policy_randomness_mag": 0.7211886953323259, "train/policy_randomness_max": 0.7211886953323259, "train/policy_randomness_mean": 0.0518484665679002, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06743272457169283, "train/post_ent_mag": 34.22060522026972, "train/post_ent_max": 34.22060522026972, "train/post_ent_mean": 33.993371018575964, "train/post_ent_min": 33.77007085467697, "train/post_ent_std": 0.09285752577792614, "train/prior_ent_mag": 33.9225820488886, "train/prior_ent_max": 33.9225820488886, "train/prior_ent_mean": 33.47385275254556, "train/prior_ent_min": 32.886209680399766, "train/prior_ent_std": 0.1639731231085751, "train/rep_loss_mean": 1.0000019866392154, "train/rep_loss_std": 4.0504034211295184e-05, "train/reward_avg": 0.0011506550569528363, "train/reward_loss_mean": 0.016050018897758575, "train/reward_loss_std": 0.15320819423645052, "train/reward_max_data": 0.5509968873438075, "train/reward_max_pred": 0.2093211472581286, "train/reward_neg_acc": 0.9998339917681632, "train/reward_neg_loss": 0.009654555975997804, "train/reward_pos_acc": 0.22556179912572497, "train/reward_pos_loss": 4.007820653279176, "train/reward_pred": 0.0009124186087544973, "train/reward_rate": 0.001612672018348624, "train_stats/mean_log_entropy": 0.09855012595653534, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.015544313937425613, "report/cont_loss_std": 0.24715736508369446, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.2384040355682373, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0024429806508123875, "report/cont_pred": 0.9946682453155518, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09128416329622269, "report/image_loss_std": 0.11396462470293045, "report/model_loss_mean": 0.7318426966667175, "report/model_loss_std": 0.6181727647781372, "report/post_ent_mag": 34.14157485961914, "report/post_ent_max": 34.14157485961914, "report/post_ent_mean": 33.911865234375, "report/post_ent_min": 33.697715759277344, "report/post_ent_std": 0.08461826294660568, "report/prior_ent_mag": 34.10336685180664, "report/prior_ent_max": 34.10336685180664, "report/prior_ent_mean": 33.62443542480469, "report/prior_ent_min": 33.09729766845703, "report/prior_ent_std": 0.16024066507816315, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0014291905099526048, "report/reward_loss_mean": 0.02501419000327587, "report/reward_loss_std": 0.3553973436355591, "report/reward_max_data": 0.8668750524520874, "report/reward_max_pred": 0.09420740604400635, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009311184287071228, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 8.049250602722168, "report/reward_pred": 0.0006722987163811922, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02591402269899845, "eval/cont_loss_std": 0.45865827798843384, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.889060974121094, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002809773897752166, "eval/cont_pred": 0.9972283840179443, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1903897523880005, "eval/image_loss_std": 0.15076829493045807, "eval/model_loss_mean": 0.8435191512107849, "eval/model_loss_std": 0.9632854461669922, "eval/post_ent_mag": 34.12593078613281, "eval/post_ent_max": 34.12593078613281, "eval/post_ent_mean": 33.92425537109375, "eval/post_ent_min": 33.69036865234375, "eval/post_ent_std": 0.09122494608163834, "eval/prior_ent_mag": 34.137264251708984, "eval/prior_ent_max": 34.137264251708984, "eval/prior_ent_mean": 33.6513786315918, "eval/prior_ent_min": 33.14258575439453, "eval/prior_ent_std": 0.14346908032894135, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008361816289834678, "eval/reward_loss_mean": 0.02721533738076687, "eval/reward_loss_std": 0.4772737920284271, "eval/reward_max_data": 0.4312500059604645, "eval/reward_max_pred": 0.046269893646240234, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0019989735446870327, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.609185218811035, "eval/reward_pred": 0.0005853015463799238, "eval/reward_rate": 0.0029296875, "replay/size": 483665.0, "replay/inserts": 8704.0, "replay/samples": 34816.0, "replay/insert_wait_avg": 1.547310282202328e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.350052542546217e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.918295388403236e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4994337558746, "timer/env.step_count": 1088.0, "timer/env.step_total": 10.147663831710815, "timer/env.step_frac": 0.010142598275759624, "timer/env.step_avg": 0.00932689690414597, "timer/env.step_min": 0.00825953483581543, "timer/env.step_max": 0.03906559944152832, "timer/replay._sample_count": 34816.0, "timer/replay._sample_total": 16.248114585876465, "timer/replay._sample_frac": 0.016240003779793306, "timer/replay._sample_avg": 0.000466685276478529, "timer/replay._sample_min": 0.0003345012664794922, "timer/replay._sample_max": 0.02796649932861328, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1377.0, "timer/agent.policy_total": 13.137345314025879, "timer/agent.policy_frac": 0.013130787355579291, "timer/agent.policy_avg": 0.009540555783606302, "timer/agent.policy_min": 0.008678913116455078, "timer/agent.policy_max": 0.033538818359375, "timer/dataset_train_count": 2176.0, "timer/dataset_train_total": 0.3704254627227783, "timer/dataset_train_frac": 0.0003702405520932693, "timer/dataset_train_avg": 0.00017023228985421797, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0053539276123046875, "timer/agent.train_count": 2176.0, "timer/agent.train_total": 962.7082884311676, "timer/agent.train_frac": 0.9622277194272474, "timer/agent.train_avg": 0.44242108843344097, "timer/agent.train_min": 0.43218016624450684, "timer/agent.train_max": 0.5734152793884277, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4842069149017334, "timer/agent.report_frac": 0.0004839652063410179, "timer/agent.report_avg": 0.2421034574508667, "timer/agent.report_min": 0.2364368438720703, "timer/agent.report_max": 0.24777007102966309, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9787445531895408e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 8.699533542650903}
{"step": 485000, "time": 56316.83786511421, "episode/length": 152.0, "episode/score": 0.5465943767299564, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.021594400790093005}
{"step": 485384, "time": 56360.69197392464, "episode/length": 288.0, "episode/score": 0.03892618293059513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03892618293059513}
{"step": 485408, "time": 56363.47179079056, "episode/length": 288.0, "episode/score": 0.024260902296759923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024260902296759923}
{"step": 485608, "time": 56386.49345302582, "episode/length": 288.0, "episode/score": 0.017134379092738072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017134379092738072}
{"step": 485696, "time": 56396.517776966095, "episode/length": 288.0, "episode/score": 0.031540220898818916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031540220898818916}
{"step": 485848, "time": 56413.93097162247, "episode/length": 288.0, "episode/score": 0.03046033483502697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03046033483502697}
{"step": 485904, "time": 56420.38526701927, "episode/length": 288.0, "episode/score": 0.03410415953368329, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03410415953368329}
{"step": 485944, "time": 56425.01538729668, "episode/length": 288.0, "episode/score": 0.043313832927651674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043313832927651674}
{"step": 486024, "time": 56434.29301714897, "episode/length": 21.0, "episode/score": 0.9402497775085976, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.005874790244433825}
{"step": 486576, "time": 56497.69275164604, "episode/length": 196.0, "episode/score": 0.40467257474517737, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.017172587073559953}
{"step": 486944, "time": 56539.74535560608, "episode/length": 166.0, "episode/score": 0.4922282674597227, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.010978271202475298}
{"step": 487320, "time": 56582.71918344498, "episode/length": 161.0, "episode/score": 0.52922061935692, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.032345632092756205}
{"step": 487696, "time": 56625.628402233124, "episode/length": 288.0, "episode/score": 0.03454856345047119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03454856345047119}
{"step": 487720, "time": 56628.38495540619, "episode/length": 288.0, "episode/score": 0.021579846752956655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021579846752956655}
{"step": 487944, "time": 56653.97715640068, "episode/length": 124.0, "episode/score": 0.6249219831610162, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.012421947898815233}
{"step": 488008, "time": 56661.2911901474, "episode/length": 288.0, "episode/score": 0.025944420533392076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025944420533392076}
{"step": 488216, "time": 56685.06260752678, "episode/length": 288.0, "episode/score": 0.05142576613775418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05142576613775418}
{"step": 488256, "time": 56689.61505460739, "episode/length": 288.0, "episode/score": 0.05105193798340224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05105193798340224}
{"step": 488448, "time": 56711.559530973434, "episode/length": 90.0, "episode/score": 0.738141538571881, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.01939153039370467}
{"step": 488888, "time": 56761.81863069534, "episode/length": 288.0, "episode/score": 0.029499318401576602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029499318401576602}
{"step": 489632, "time": 56846.79555892944, "episode/length": 288.0, "episode/score": 0.04473290379235095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04473290379235095}
{"step": 490008, "time": 56889.96907520294, "episode/length": 288.0, "episode/score": 0.01534523668874499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01534523668874499}
{"step": 490048, "time": 56894.539102077484, "episode/length": 262.0, "episode/score": 0.21788610807305986, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.03663610252004901}
{"step": 490048, "time": 56894.90454363823, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 490048, "time": 56895.624366045, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 490048, "time": 56899.33702135086, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 56899.343075037, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 56899.34855556488, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 56899.353924036026, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 56899.35905098915, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 56899.364230155945, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490320, "time": 56930.39023518562, "episode/length": 288.0, "episode/score": 0.05097714002641851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05097714002641851}
{"step": 490528, "time": 56954.15668010712, "episode/length": 288.0, "episode/score": 0.041293026930418364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041293026930418364}
{"step": 490568, "time": 56958.717049360275, "episode/length": 288.0, "episode/score": 0.04206539949996113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04206539949996113}
{"step": 490760, "time": 56980.66624093056, "episode/length": 288.0, "episode/score": 0.036860026880447094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036860026880447094}
{"step": 491024, "time": 57010.76997566223, "episode/length": 32.0, "episode/score": 0.9056741442774978, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.005674188259206403}
{"step": 491200, "time": 57030.867899894714, "episode/length": 288.0, "episode/score": 0.03726578958759319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03726578958759319}
{"step": 491496, "time": 57064.69673395157, "episode/length": 58.0, "episode/score": 0.8277222022796309, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.00897217865605171}
{"step": 491944, "time": 57116.185992240906, "episode/length": 288.0, "episode/score": 0.0399321641360757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0399321641360757}
{"step": 491976, "time": 57119.846646785736, "episode/length": 245.0, "episode/score": 0.26649522789051616, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.032120228094242975}
{"step": 492360, "time": 57163.71215629578, "episode/length": 288.0, "episode/score": 0.05357925456053181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05357925456053181}
{"step": 492536, "time": 57183.78039264679, "episode/length": 250.0, "episode/score": 0.24811125061108896, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.02936125082936769}
{"step": 492632, "time": 57194.6747944355, "episode/length": 288.0, "episode/score": 0.043152333984210145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043152333984210145}
{"step": 492640, "time": 57195.606521844864, "episode/length": 34.0, "episode/score": 0.9038612848236198, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.010111291034377246}
{"step": 492680, "time": 57200.15806770325, "episode/length": 91.0, "episode/score": 0.7299044045288383, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.01427940827159091}
{"step": 492865, "time": 57222.21399950981, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0008983699956797, "train/action_min": 0.0, "train/action_std": 1.9482584065555977, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00655796850788995, "train/actor_opt_grad_steps": 121740.0, "train/actor_opt_loss": -22.42860595861338, "train/adv_mag": 0.4250242990282823, "train/adv_max": 0.2300477093815254, "train/adv_mean": -0.00170987965473128, "train/adv_min": -0.3852223024664936, "train/adv_std": 0.019014364996847742, "train/cont_avg": 0.995688724078341, "train/cont_loss_mean": 0.013409281416671685, "train/cont_loss_std": 0.20472630754559545, "train/cont_neg_acc": 0.39637005967753275, "train/cont_neg_loss": 2.4506808747918334, "train/cont_pos_acc": 0.999923143793361, "train/cont_pos_loss": 0.0027861536704733418, "train/cont_pred": 0.9955788614563129, "train/cont_rate": 0.995688724078341, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09905131895112278, "train/extr_critic_critic_opt_grad_steps": 121740.0, "train/extr_critic_critic_opt_loss": 7490.741138932892, "train/extr_critic_mag": 0.8264499946673345, "train/extr_critic_max": 0.8264499946673345, "train/extr_critic_mean": 0.6117636190581431, "train/extr_critic_min": 0.5011389140159853, "train/extr_critic_std": 0.03954578363572672, "train/extr_return_normed_mag": 0.47199820730543357, "train/extr_return_normed_max": 0.347215286872354, "train/extr_return_normed_mean": 0.039830397969017384, "train/extr_return_normed_min": -0.3291578843571623, "train/extr_return_normed_std": 0.0444295549859649, "train/extr_return_rate": 0.9991569823933087, "train/extr_return_raw_mag": 0.9174386438686177, "train/extr_return_raw_max": 0.9174386438686177, "train/extr_return_raw_mean": 0.6100537823641905, "train/extr_return_raw_min": 0.24106547263910144, "train/extr_return_raw_std": 0.04442955490871234, "train/extr_reward_mag": 0.432895548882023, "train/extr_reward_max": 0.432895548882023, "train/extr_reward_mean": 0.001022846292203275, "train/extr_reward_min": 1.0009185509747623e-06, "train/extr_reward_std": 0.008663520952987095, "train/image_loss_mean": 0.09032386306175438, "train/image_loss_std": 0.10701327431037129, "train/model_loss_mean": 0.7189486889245873, "train/model_loss_std": 0.34507804024054706, "train/model_opt_grad_norm": 12.085312507119596, "train/model_opt_grad_steps": 121630.62211981567, "train/model_opt_loss": 3759.8551424791185, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5253.4562211981565, "train/policy_entropy_mag": 1.4489923177226898, "train/policy_entropy_max": 1.4489923177226898, "train/policy_entropy_mean": 0.10514623846875908, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.14176390927782806, "train/policy_logprob_mag": 6.551080255464475, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10502241998224214, "train/policy_logprob_min": -6.551080255464475, "train/policy_logprob_std": 0.6451941000701096, "train/policy_randomness_mag": 0.7446347936507194, "train/policy_randomness_max": 0.7446347936507194, "train/policy_randomness_mean": 0.05403448194952055, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07285224199981734, "train/post_ent_mag": 34.19866706039499, "train/post_ent_max": 34.19866706039499, "train/post_ent_mean": 33.969985135689306, "train/post_ent_min": 33.75024741036551, "train/post_ent_std": 0.09328025208640209, "train/prior_ent_mag": 34.111673469367666, "train/prior_ent_max": 34.111673469367666, "train/prior_ent_mean": 33.63766410933112, "train/prior_ent_min": 33.09431598153532, "train/prior_ent_std": 0.1515750760718974, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0010528709052891304, "train/reward_loss_mean": 0.015215520976617726, "train/reward_loss_std": 0.13595727961167076, "train/reward_max_data": 0.5143967916961536, "train/reward_max_pred": 0.18616822567952943, "train/reward_neg_acc": 0.9998512589437072, "train/reward_neg_loss": 0.009608630041596115, "train/reward_pos_acc": 0.27634730622796955, "train/reward_pos_loss": 3.7533703988897584, "train/reward_pred": 0.0009002247213682134, "train/reward_rate": 0.0014535930299539172, "train_stats/mean_log_entropy": 0.08466905375590196, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.004006138537079096, "report/cont_loss_std": 0.07967476546764374, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.2679611444473267, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0015326450811699033, "report/cont_pred": 0.997456967830658, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06708627939224243, "report/image_loss_std": 0.10411307215690613, "report/model_loss_mean": 0.6777976751327515, "report/model_loss_std": 0.1321621984243393, "report/post_ent_mag": 33.9403076171875, "report/post_ent_max": 33.9403076171875, "report/post_ent_mean": 33.656494140625, "report/post_ent_min": 33.44416046142578, "report/post_ent_std": 0.09643950313329697, "report/prior_ent_mag": 34.109230041503906, "report/prior_ent_max": 34.109230041503906, "report/prior_ent_mean": 33.61033630371094, "report/prior_ent_min": 32.91388702392578, "report/prior_ent_std": 0.15269121527671814, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00012901579611934721, "report/reward_loss_mean": 0.006705285049974918, "report/reward_loss_std": 0.013587335124611855, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.08992171287536621, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.006705285049974918, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0005540585843846202, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.04129666090011597, "eval/cont_loss_std": 0.5971881747245789, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.907676696777344, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002698134630918503, "eval/cont_pred": 0.997475802898407, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22546406090259552, "eval/image_loss_std": 0.14071902632713318, "eval/model_loss_mean": 0.8850802183151245, "eval/model_loss_std": 0.8310213088989258, "eval/post_ent_mag": 33.91794967651367, "eval/post_ent_max": 33.91794967651367, "eval/post_ent_mean": 33.66278076171875, "eval/post_ent_min": 33.413055419921875, "eval/post_ent_std": 0.11190813034772873, "eval/prior_ent_mag": 34.093116760253906, "eval/prior_ent_max": 34.093116760253906, "eval/prior_ent_mean": 33.60698699951172, "eval/prior_ent_min": 33.0836067199707, "eval/prior_ent_std": 0.14034609496593475, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0010559081565588713, "eval/reward_loss_mean": 0.018319446593523026, "eval/reward_loss_std": 0.3610081374645233, "eval/reward_max_data": 0.7749999761581421, "eval/reward_max_pred": 0.20770704746246338, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.0030765344854444265, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.807448387145996, "eval/reward_pred": 0.0007684475276619196, "eval/reward_rate": 0.001953125, "replay/size": 492361.0, "replay/inserts": 8696.0, "replay/samples": 34784.0, "replay/insert_wait_avg": 1.525209930476072e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.431799924581996e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.549117830797876e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0310518741608, "timer/env.step_count": 1087.0, "timer/env.step_total": 10.18435001373291, "timer/env.step_frac": 0.010184033780397513, "timer/env.step_avg": 0.009369227243544536, "timer/env.step_min": 0.00830698013305664, "timer/env.step_max": 0.03494000434875488, "timer/replay._sample_count": 34784.0, "timer/replay._sample_total": 16.130695104599, "timer/replay._sample_frac": 0.016130194231837522, "timer/replay._sample_avg": 0.0004637389346998332, "timer/replay._sample_min": 0.0003559589385986328, "timer/replay._sample_max": 0.01031637191772461, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1376.0, "timer/agent.policy_total": 13.209795236587524, "timer/agent.policy_frac": 0.013209385060424886, "timer/agent.policy_avg": 0.009600141887054887, "timer/agent.policy_min": 0.008712291717529297, "timer/agent.policy_max": 0.035158634185791016, "timer/dataset_train_count": 2174.0, "timer/dataset_train_total": 0.37775278091430664, "timer/dataset_train_frac": 0.00037774105134671487, "timer/dataset_train_avg": 0.00017375932884742715, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.006087541580200195, "timer/agent.train_count": 2174.0, "timer/agent.train_total": 962.0786612033844, "timer/agent.train_frac": 0.9620487877854895, "timer/agent.train_avg": 0.44253848261425227, "timer/agent.train_min": 0.4296596050262451, "timer/agent.train_max": 0.5859112739562988, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4754915237426758, "timer/agent.report_frac": 0.0004754767592981797, "timer/agent.report_avg": 0.2377457618713379, "timer/agent.report_min": 0.23206853866577148, "timer/agent.report_max": 0.2434229850769043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6702051710625447e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 8.695613454715486}
{"step": 492880, "time": 57223.762451171875, "episode/length": 288.0, "episode/score": 0.048257741525731035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048257741525731035}
{"step": 493008, "time": 57238.5590903759, "episode/length": 58.0, "episode/score": 0.8332277113368605, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.014477702599890563}
{"step": 493512, "time": 57296.67254638672, "episode/length": 288.0, "episode/score": 0.041938104005225796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041938104005225796}
{"step": 493600, "time": 57306.93781328201, "episode/length": 114.0, "episode/score": 0.6561737254327227, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.012423709422705542}
{"step": 493616, "time": 57308.75450491905, "episode/length": 121.0, "episode/score": 0.6399034109342381, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.018028442995017713}
{"step": 493800, "time": 57329.76837515831, "episode/length": 287.0, "episode/score": 0.13118316010132958, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.028058164210790437}
{"step": 493848, "time": 57335.315162181854, "episode/length": 151.0, "episode/score": 0.5479036458626751, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.01977867194261762}
{"step": 494288, "time": 57385.78715419769, "episode/length": 288.0, "episode/score": 0.03274087163811146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03274087163811146}
{"step": 494712, "time": 57434.9697830677, "episode/length": 52.0, "episode/score": 0.8519398305669483, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.014439825770637071}
{"step": 495192, "time": 57489.964314222336, "episode/length": 288.0, "episode/score": 0.014402854333894766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014402854333894766}
{"step": 495320, "time": 57504.60982584953, "episode/length": 288.0, "episode/score": 0.011261211676355742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.011261211676355742}
{"step": 495824, "time": 57562.64260554314, "episode/length": 288.0, "episode/score": 0.02440370462019814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02440370462019814}
{"step": 495912, "time": 57572.827490091324, "episode/length": 288.0, "episode/score": 0.010222010111021973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010222010111021973}
{"step": 495928, "time": 57574.67313551903, "episode/length": 288.0, "episode/score": 0.054934781518625186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054934781518625186}
{"step": 496112, "time": 57595.665977716446, "episode/length": 288.0, "episode/score": 0.02563228697880504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02563228697880504}
{"step": 496160, "time": 57601.207365989685, "episode/length": 288.0, "episode/score": 0.018237939963000827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018237939963000827}
{"step": 496256, "time": 57612.211945056915, "episode/length": 17.0, "episode/score": 0.9517997311651243, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.004924755821889448}
{"step": 496256, "time": 57612.24027514458, "episode/length": 116.0, "episode/score": 0.6557588605121509, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.01825886425490353}
{"step": 496864, "time": 57682.38184309006, "episode/length": 129.0, "episode/score": 0.6209439803604937, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.024068960261388384}
{"step": 496896, "time": 57686.1001625061, "episode/length": 79.0, "episode/score": 0.7715104656837184, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.018385471894475813}
{"step": 497016, "time": 57699.97324538231, "episode/length": 94.0, "episode/score": 0.7291471666547977, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.022897155548776027}
{"step": 497024, "time": 57700.905527591705, "episode/length": 288.0, "episode/score": 0.02204289870962839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02204289870962839}
{"step": 497304, "time": 57733.144953250885, "episode/length": 171.0, "episode/score": 0.490112239466157, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.02448725255123918}
{"step": 497504, "time": 57756.16065621376, "episode/length": 288.0, "episode/score": 0.03860543434711872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03860543434711872}
{"step": 498224, "time": 57838.94081115723, "episode/length": 288.0, "episode/score": 0.02240575877772244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02240575877772244}
{"step": 498328, "time": 57850.94359707832, "episode/length": 178.0, "episode/score": 0.46346112179344345, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.019711119575731573}
{"step": 498360, "time": 57854.62826156616, "episode/length": 166.0, "episode/score": 0.4965504201383055, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.015300432874141734}
{"step": 498472, "time": 57867.46658563614, "episode/length": 288.0, "episode/score": 0.03050659338487094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03050659338487094}
{"step": 499176, "time": 57948.43643927574, "episode/length": 288.0, "episode/score": 0.02905464085017684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02905464085017684}
{"step": 499328, "time": 57965.91779232025, "episode/length": 288.0, "episode/score": 0.02147198093962288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02147198093962288}
{"step": 499544, "time": 57990.69464921951, "episode/length": 164.0, "episode/score": 0.5013852021555749, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.01388518057217425}
{"step": 499592, "time": 57996.23780679703, "episode/length": 153.0, "episode/score": 0.5377980072543096, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0159229690933671}
{"step": 499616, "time": 57998.99712252617, "episode/length": 288.0, "episode/score": 0.01676900248514812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01676900248514812}
{"step": 499688, "time": 58007.25135803223, "episode/length": 169.0, "episode/score": 0.48093732305721915, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.009062317597340552}
{"step": 499816, "time": 58022.32144117355, "episode/length": 288.0, "episode/score": 0.025473954673316257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025473954673316257}
{"step": 500032, "time": 58048.99169278145, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 500032, "time": 58049.030457258224, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 500032, "time": 58049.6619412899, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 500032, "time": 58049.66713261604, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 500032, "time": 58050.47952365875, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 500032, "time": 58050.601793289185, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 500032, "time": 58051.46561908722, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 500032, "time": 58052.1420006752, "eval_episode/length": 253.0, "eval_episode/score": 0.20937499403953552, "eval_episode/reward_rate": 0.003937007874015748}
{"step": 500112, "time": 58061.31601500511, "episode/length": 204.0, "episode/score": 0.3855342606877912, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.023034248985140948}
{"step": 500152, "time": 58065.897105932236, "episode/length": 41.0, "episode/score": 0.8780559079682462, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.006180896547903103}
{"step": 500200, "time": 58071.424416303635, "episode/length": 81.0, "episode/score": 0.7679895266314816, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.021114515211138496}
{"step": 500360, "time": 58089.83994722366, "episode/length": 147.0, "episode/score": 0.5564739695629441, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.015848979085717474}
{"step": 500536, "time": 58110.034283638, "episode/length": 105.0, "episode/score": 0.6864140649138903, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.014539085053741019}
{"step": 500760, "time": 58135.80806350708, "episode/length": 80.0, "episode/score": 0.762051742866106, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.01205171952483397}
{"step": 501505, "time": 58222.48013186455, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.147061100712529, "train/action_min": 0.0, "train/action_std": 1.9695124604083873, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005665138910343457, "train/actor_opt_grad_steps": 123905.0, "train/actor_opt_loss": -20.176984639079482, "train/adv_mag": 0.3977487640524352, "train/adv_max": 0.204231271037349, "train/adv_mean": 0.0002623931890984413, "train/adv_min": -0.36241112083748533, "train/adv_std": 0.018871841633140488, "train/cont_avg": 0.9957456235532407, "train/cont_loss_mean": 0.013855779677181056, "train/cont_loss_std": 0.2104509094109138, "train/cont_neg_acc": 0.3525441386780449, "train/cont_neg_loss": 2.6122643586114065, "train/cont_pos_acc": 0.999881901398853, "train/cont_pos_loss": 0.0026916030161643263, "train/cont_pred": 0.9958588955578981, "train/cont_rate": 0.9957456235532407, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10642506256354628, "train/extr_critic_critic_opt_grad_steps": 123905.0, "train/extr_critic_critic_opt_loss": 8344.972400806568, "train/extr_critic_mag": 0.7780715094672309, "train/extr_critic_max": 0.7780715094672309, "train/extr_critic_mean": 0.5793335103878269, "train/extr_critic_min": 0.4591172734896342, "train/extr_critic_std": 0.039401541360550456, "train/extr_return_normed_mag": 0.4351876411173079, "train/extr_return_normed_max": 0.3294312352383578, "train/extr_return_normed_mean": 0.04681226387792439, "train/extr_return_normed_min": -0.2970550334839909, "train/extr_return_normed_std": 0.044087495654821396, "train/extr_return_rate": 0.997394362533534, "train/extr_return_raw_mag": 0.8622148652319555, "train/extr_return_raw_max": 0.8622148652319555, "train/extr_return_raw_mean": 0.5795959248035042, "train/extr_return_raw_min": 0.23572859650960676, "train/extr_return_raw_std": 0.04408749562032797, "train/extr_reward_mag": 0.429239136201364, "train/extr_reward_max": 0.429239136201364, "train/extr_reward_mean": 0.000981695152774962, "train/extr_reward_min": 1.1832625777633101e-06, "train/extr_reward_std": 0.008707184822048509, "train/image_loss_mean": 0.09059092276557176, "train/image_loss_std": 0.10788326365528284, "train/model_loss_mean": 0.719784806172053, "train/model_loss_std": 0.35616026767012143, "train/model_opt_grad_norm": 12.216800071575024, "train/model_opt_grad_steps": 123793.72222222222, "train/model_opt_loss": 4269.945670798973, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5949.074074074074, "train/policy_entropy_mag": 1.4117710353047759, "train/policy_entropy_max": 1.4117710353047759, "train/policy_entropy_mean": 0.0983777957175065, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13038875673104217, "train/policy_logprob_mag": 6.551080251181567, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09857545686126859, "train/policy_logprob_min": -6.551080251181567, "train/policy_logprob_std": 0.6396473436443894, "train/policy_randomness_mag": 0.7255068371693293, "train/policy_randomness_max": 0.7255068371693293, "train/policy_randomness_mean": 0.05055619008770144, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0670065699076211, "train/post_ent_mag": 34.04027426684344, "train/post_ent_max": 34.04027426684344, "train/post_ent_mean": 33.79209274715848, "train/post_ent_min": 33.55054744084676, "train/post_ent_std": 0.10113641298893425, "train/prior_ent_mag": 34.08659604743675, "train/prior_ent_max": 34.08659604743675, "train/prior_ent_mean": 33.59758491869326, "train/prior_ent_min": 33.03276982130828, "train/prior_ent_std": 0.15112952701747417, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.001044919701396591, "train/reward_loss_mean": 0.015338083804602286, "train/reward_loss_std": 0.14264316263574142, "train/reward_max_data": 0.5336144815880323, "train/reward_max_pred": 0.16824345566608287, "train/reward_neg_acc": 0.9998460668656561, "train/reward_neg_loss": 0.009528183779265318, "train/reward_pos_acc": 0.22596899359378703, "train/reward_pos_loss": 3.966799165447091, "train/reward_pred": 0.0008714316122846126, "train/reward_rate": 0.001460322627314815, "train_stats/mean_log_entropy": 0.08002238375384634, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.009404427371919155, "report/cont_loss_std": 0.19103701412677765, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 1.564064621925354, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0017760659102350473, "report/cont_pred": 0.9952195882797241, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07500361651182175, "report/image_loss_std": 0.10352310538291931, "report/model_loss_mean": 0.6956955194473267, "report/model_loss_std": 0.2619539201259613, "report/post_ent_mag": 34.128990173339844, "report/post_ent_max": 34.128990173339844, "report/post_ent_mean": 33.8461799621582, "report/post_ent_min": 33.56929397583008, "report/post_ent_std": 0.10951182246208191, "report/prior_ent_mag": 33.994895935058594, "report/prior_ent_max": 33.994895935058594, "report/prior_ent_mean": 33.53874969482422, "report/prior_ent_min": 32.73382568359375, "report/prior_ent_std": 0.15415003895759583, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008322131470777094, "report/reward_loss_mean": 0.011287417262792587, "report/reward_loss_std": 0.07896748930215836, "report/reward_max_data": 0.665772020816803, "report/reward_max_pred": 0.0841679573059082, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00885674636811018, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 2.497864007949829, "report/reward_pred": 0.0006850099889561534, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0313926562666893, "eval/cont_loss_std": 0.5068180561065674, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.4318156242370605, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.002371386392042041, "eval/cont_pred": 0.9978162050247192, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24033084511756897, "eval/image_loss_std": 0.18549305200576782, "eval/model_loss_mean": 0.889828085899353, "eval/model_loss_std": 0.8244083523750305, "eval/post_ent_mag": 34.135597229003906, "eval/post_ent_max": 34.135597229003906, "eval/post_ent_mean": 33.834877014160156, "eval/post_ent_min": 33.569583892822266, "eval/post_ent_std": 0.12491558492183685, "eval/prior_ent_mag": 33.99384689331055, "eval/prior_ent_max": 33.99384689331055, "eval/prior_ent_mean": 33.548091888427734, "eval/prior_ent_min": 32.927879333496094, "eval/prior_ent_std": 0.15721985697746277, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007293701055459678, "eval/reward_loss_mean": 0.018104545772075653, "eval/reward_loss_std": 0.37132471799850464, "eval/reward_max_data": 0.44999998807907104, "eval/reward_max_pred": 0.19743883609771729, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.0022366135381162167, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.126618385314941, "eval/reward_pred": 0.0007281330181285739, "eval/reward_rate": 0.001953125, "replay/size": 501001.0, "replay/inserts": 8640.0, "replay/samples": 34560.0, "replay/insert_wait_avg": 1.5432084048235857e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.478796221591808e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2032.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.895779016449696e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2519564628601, "timer/env.step_count": 1080.0, "timer/env.step_total": 10.041673421859741, "timer/env.step_frac": 0.010039143994648706, "timer/env.step_avg": 0.009297845760981242, "timer/env.step_min": 0.008166313171386719, "timer/env.step_max": 0.02808070182800293, "timer/replay._sample_count": 34560.0, "timer/replay._sample_total": 16.121586561203003, "timer/replay._sample_frac": 0.016117525646451067, "timer/replay._sample_avg": 0.0004664810926274017, "timer/replay._sample_min": 0.00036215782165527344, "timer/replay._sample_max": 0.0216372013092041, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1334.0, "timer/agent.policy_total": 13.460198879241943, "timer/agent.policy_frac": 0.01345680834940884, "timer/agent.policy_avg": 0.010090104107377769, "timer/agent.policy_min": 0.00879216194152832, "timer/agent.policy_max": 0.08342123031616211, "timer/dataset_train_count": 2160.0, "timer/dataset_train_total": 0.3751838207244873, "timer/dataset_train_frac": 0.00037508931454753727, "timer/dataset_train_avg": 0.00017369621329837374, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.0053386688232421875, "timer/agent.train_count": 2160.0, "timer/agent.train_total": 962.194331407547, "timer/agent.train_frac": 0.9619519613939128, "timer/agent.train_avg": 0.4454603386146051, "timer/agent.train_min": 0.43381166458129883, "timer/agent.train_max": 0.5782656669616699, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4757351875305176, "timer/agent.report_frac": 0.0004756153531684513, "timer/agent.report_avg": 0.2378675937652588, "timer/agent.report_min": 0.2330005168914795, "timer/agent.report_max": 0.24273467063903809, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.6934513113823546e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 8.63770689622432}
{"step": 501552, "time": 58227.63298153877, "episode/length": 126.0, "episode/score": 0.6177540860207955, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.011504118081575143}
{"step": 501640, "time": 58237.78390479088, "episode/length": 288.0, "episode/score": 0.03326517042467003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03326517042467003}
{"step": 501904, "time": 58268.02760505676, "episode/length": 288.0, "episode/score": 0.03736233887383378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03736233887383378}
{"step": 501928, "time": 58270.82662677765, "episode/length": 288.0, "episode/score": 0.04456387910113335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04456387910113335}
{"step": 501960, "time": 58274.528940200806, "episode/length": 50.0, "episode/score": 0.8530536089173211, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0093036091355998}
{"step": 502080, "time": 58288.37563061714, "episode/length": 164.0, "episode/score": 0.5040174448823791, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.01651741826401576}
{"step": 502464, "time": 58332.60750102997, "episode/length": 288.0, "episode/score": 0.060762327246038694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060762327246038694}
{"step": 502512, "time": 58338.13953065872, "episode/length": 288.0, "episode/score": 0.03583228082175083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03583228082175083}
{"step": 502528, "time": 58339.99234294891, "episode/length": 77.0, "episode/score": 0.7720978545542039, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.012722874306973608}
{"step": 502672, "time": 58356.63100862503, "episode/length": 288.0, "episode/score": 0.026589858625129636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026589858625129636}
{"step": 503712, "time": 58476.55607223511, "episode/length": 222.0, "episode/score": 0.3443444530601596, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.038094437437223405}
{"step": 503952, "time": 58504.24775195122, "episode/length": 288.0, "episode/score": 0.02479706919984892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02479706919984892}
{"step": 504272, "time": 58540.91276073456, "episode/length": 288.0, "episode/score": 0.037236797987475256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037236797987475256}
{"step": 504280, "time": 58541.866022109985, "episode/length": 200.0, "episode/score": 0.41090559031528073, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.03590559053355946}
{"step": 504392, "time": 58554.78953075409, "episode/length": 288.0, "episode/score": 0.05003900870923417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05003900870923417}
{"step": 504776, "time": 58598.779116630554, "episode/length": 288.0, "episode/score": 0.010970952680736445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010970952680736445}
{"step": 504824, "time": 58604.28308701515, "episode/length": 288.0, "episode/score": 0.038529693866394155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038529693866394155}
{"step": 504840, "time": 58606.13602924347, "episode/length": 288.0, "episode/score": 0.04994702866792977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04994702866792977}
{"step": 505240, "time": 58652.43679833412, "episode/length": 57.0, "episode/score": 0.8330395752955155, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.011164591977831151}
{"step": 505352, "time": 58665.33900761604, "episode/length": 133.0, "episode/score": 0.5975772858928394, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.013202274129071156}
{"step": 505432, "time": 58674.63755249977, "episode/length": 129.0, "episode/score": 0.6241090531714804, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.027234042065458652}
{"step": 506024, "time": 58743.35789132118, "episode/length": 288.0, "episode/score": 0.049975366776720875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049975366776720875}
{"step": 506264, "time": 58771.11388850212, "episode/length": 288.0, "episode/score": 0.058791214448490337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058791214448490337}
{"step": 506304, "time": 58775.87139058113, "episode/length": 108.0, "episode/score": 0.7031829339489946, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.040682895788052065}
{"step": 506584, "time": 58808.23999404907, "episode/length": 288.0, "episode/score": 0.06461180782304154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06461180782304154}
{"step": 506608, "time": 58811.016060352325, "episode/length": 156.0, "episode/score": 0.5623258011830785, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.049825783709138705}
{"step": 506736, "time": 58825.69584774971, "episode/length": 236.0, "episode/score": 0.3191102494907909, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.05661025425217758}
{"step": 506912, "time": 58845.88559579849, "episode/length": 80.0, "episode/score": 0.7779955795268734, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.027995599666724047}
{"step": 507096, "time": 58867.14545607567, "episode/length": 283.0, "episode/score": 0.18193004867987383, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.06630504835391093}
{"step": 507552, "time": 58919.40876913071, "episode/length": 288.0, "episode/score": 0.04627203657867085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04627203657867085}
{"step": 507944, "time": 58964.86031270027, "episode/length": 150.0, "episode/score": 0.5790565068452906, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.047806483504018615}
{"step": 508336, "time": 59010.00367593765, "episode/length": 288.0, "episode/score": 0.050011431103428095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050011431103428095}
{"step": 508584, "time": 59038.533674001694, "episode/length": 208.0, "episode/score": 0.39381368236900016, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.04381368854774337}
{"step": 508616, "time": 59042.26083946228, "episode/length": 288.0, "episode/score": 0.07020247756122444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07020247756122444}
{"step": 508688, "time": 59050.47837328911, "episode/length": 141.0, "episode/score": 0.5936460675439434, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.03427107968315113}
{"step": 508840, "time": 59067.8734126091, "episode/length": 111.0, "episode/score": 0.6764122833201327, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.023287287062885298}
{"step": 508896, "time": 59074.35096502304, "episode/length": 288.0, "episode/score": 0.04691487414186213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04691487414186213}
{"step": 508920, "time": 59077.10414266586, "episode/length": 288.0, "episode/score": 0.05500329161816353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05500329161816353}
{"step": 509016, "time": 59088.09595823288, "episode/length": 49.0, "episode/score": 0.8656956213633293, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.018820601264224024}
{"step": 509016, "time": 59088.14026379585, "episode/length": 84.0, "episode/score": 0.7580683772240491, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.02056835712494376}
{"step": 509408, "time": 59133.133088350296, "episode/length": 288.0, "episode/score": 0.06668510907758218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06668510907758218}
{"step": 509728, "time": 59170.17374920845, "episode/length": 88.0, "episode/score": 0.7477686972542301, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.022768666252829917}
{"step": 510016, "time": 59208.17230916023, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 59208.17838931084, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 59208.18466758728, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 59208.18978214264, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 59208.1948029995, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 59208.19992017746, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 59208.20498466492, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 59208.21028017998, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510133, "time": 59222.70023679733, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0417839332863137, "train/action_min": 0.0, "train/action_std": 1.9027261237303417, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006108970730026529, "train/actor_opt_grad_steps": 126065.0, "train/actor_opt_loss": -18.780076521414298, "train/adv_mag": 0.3567417563387641, "train/adv_max": 0.17642341885301802, "train/adv_mean": 0.0004874687738433918, "train/adv_min": -0.33612348249665014, "train/adv_std": 0.020479908167746745, "train/cont_avg": 0.9956461588541666, "train/cont_loss_mean": 0.014153868182027643, "train/cont_loss_std": 0.21213642001600452, "train/cont_neg_acc": 0.36344089248152667, "train/cont_neg_loss": 2.6021405010903798, "train/cont_pos_acc": 0.9998864989589762, "train/cont_pos_loss": 0.002767557109042105, "train/cont_pred": 0.9957183618788366, "train/cont_rate": 0.9956461588541666, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1156540641957825, "train/extr_critic_critic_opt_grad_steps": 126065.0, "train/extr_critic_critic_opt_loss": 8374.266355161313, "train/extr_critic_mag": 0.7271824534292575, "train/extr_critic_max": 0.7271824534292575, "train/extr_critic_mean": 0.5761690683386944, "train/extr_critic_min": 0.475177064538002, "train/extr_critic_std": 0.036038031034102594, "train/extr_return_normed_mag": 0.3749687089412301, "train/extr_return_normed_max": 0.2600024646079099, "train/extr_return_normed_mean": 0.04223295128731816, "train/extr_return_normed_min": -0.2669546435828562, "train/extr_return_normed_std": 0.042946435131684495, "train/extr_return_rate": 0.9964467309139393, "train/extr_return_raw_mag": 0.7944260104386894, "train/extr_return_raw_max": 0.7944260104386894, "train/extr_return_raw_mean": 0.5766565220223533, "train/extr_return_raw_min": 0.2674689022479234, "train/extr_return_raw_std": 0.042946435079944355, "train/extr_reward_mag": 0.30872660544183517, "train/extr_reward_max": 0.30872660544183517, "train/extr_reward_mean": 0.0012593013971464071, "train/extr_reward_min": 1.2158243744461625e-06, "train/extr_reward_std": 0.008462781180343073, "train/image_loss_mean": 0.09033924487798854, "train/image_loss_std": 0.10704838243071679, "train/model_loss_mean": 0.7201114296913147, "train/model_loss_std": 0.3620386402709065, "train/model_opt_grad_norm": 11.969113566257336, "train/model_opt_grad_steps": 125952.0925925926, "train/model_opt_loss": 4383.0592357494215, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6087.962962962963, "train/policy_entropy_mag": 1.3590648808964976, "train/policy_entropy_max": 1.3590648808964976, "train/policy_entropy_mean": 0.11132901403363105, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1485482162140586, "train/policy_logprob_mag": 6.551080273257361, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11111819937273308, "train/policy_logprob_min": -6.551080273257361, "train/policy_logprob_std": 0.6490986791473848, "train/policy_randomness_mag": 0.6984212301947452, "train/policy_randomness_max": 0.6984212301947452, "train/policy_randomness_mean": 0.05721179980577694, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07633868689407353, "train/post_ent_mag": 34.25196147848059, "train/post_ent_max": 34.25196147848059, "train/post_ent_mean": 33.935044553544785, "train/post_ent_min": 33.64197589732982, "train/post_ent_std": 0.12545185332634934, "train/prior_ent_mag": 34.08153355563128, "train/prior_ent_max": 34.08153355563128, "train/prior_ent_mean": 33.61267121632894, "train/prior_ent_min": 33.04934997911806, "train/prior_ent_std": 0.15600742496274136, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.001090433906668935, "train/reward_loss_mean": 0.015618292170714724, "train/reward_loss_std": 0.1463214410210235, "train/reward_max_data": 0.5236102043504447, "train/reward_max_pred": 0.18259045205734395, "train/reward_neg_acc": 0.9998958773083158, "train/reward_neg_loss": 0.009539025559745453, "train/reward_pos_acc": 0.2165974546657052, "train/reward_pos_loss": 3.946038149643776, "train/reward_pred": 0.0009064406476682052, "train/reward_rate": 0.0015417028356481482, "train_stats/mean_log_entropy": 0.08830746139089267, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.024444252252578735, "report/cont_loss_std": 0.3117670714855194, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.307823896408081, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0019257162930443883, "report/cont_pred": 0.9939581155776978, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10241915285587311, "report/image_loss_std": 0.10194108635187149, "report/model_loss_mean": 0.7515833377838135, "report/model_loss_std": 0.5431461334228516, "report/post_ent_mag": 34.586395263671875, "report/post_ent_max": 34.586395263671875, "report/post_ent_mean": 34.26274871826172, "report/post_ent_min": 33.92383575439453, "report/post_ent_std": 0.13532805442810059, "report/prior_ent_mag": 34.19710922241211, "report/prior_ent_max": 34.19710922241211, "report/prior_ent_mean": 33.79482650756836, "report/prior_ent_min": 33.10625457763672, "report/prior_ent_std": 0.17736726999282837, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002514922060072422, "report/reward_loss_mean": 0.024719877168536186, "report/reward_loss_std": 0.2614072263240814, "report/reward_max_data": 0.9408749938011169, "report/reward_max_pred": 0.06714200973510742, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.008564822375774384, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.144258975982666, "report/reward_pred": 0.0007022834615781903, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.013618716970086098, "eval/cont_loss_std": 0.23490199446678162, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.002475738525391, "eval/cont_pos_acc": 0.9990224838256836, "eval/cont_pos_loss": 0.007764507085084915, "eval/cont_pred": 0.9959409832954407, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20130078494548798, "eval/image_loss_std": 0.16906124353408813, "eval/model_loss_mean": 0.8167470693588257, "eval/model_loss_std": 0.2874166965484619, "eval/post_ent_mag": 34.58629608154297, "eval/post_ent_max": 34.58629608154297, "eval/post_ent_mean": 34.19147872924805, "eval/post_ent_min": 33.90385055541992, "eval/post_ent_std": 0.13723863661289215, "eval/prior_ent_mag": 34.21366882324219, "eval/prior_ent_max": 34.21366882324219, "eval/prior_ent_mean": 33.75184631347656, "eval/prior_ent_min": 33.143272399902344, "eval/prior_ent_std": 0.16593065857887268, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0018275496549904346, "eval/reward_loss_std": 0.004877975210547447, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.031072258949279785, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0018275496549904346, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0005107073811814189, "eval/reward_rate": 0.0, "replay/size": 509629.0, "replay/inserts": 8628.0, "replay/samples": 34512.0, "replay/insert_wait_avg": 1.562597799146402e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.447264622249258e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.439808274635394e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2037484645844, "timer/env.step_count": 1078.0, "timer/env.step_total": 10.033247709274292, "timer/env.step_frac": 0.01003120386688848, "timer/env.step_avg": 0.009307279878733109, "timer/env.step_min": 0.008203506469726562, "timer/env.step_max": 0.027458906173706055, "timer/replay._sample_count": 34512.0, "timer/replay._sample_total": 16.15625762939453, "timer/replay._sample_frac": 0.016152966487274267, "timer/replay._sample_avg": 0.00046813449320220595, "timer/replay._sample_min": 0.00034236907958984375, "timer/replay._sample_max": 0.025845050811767578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1367.0, "timer/agent.policy_total": 13.259655237197876, "timer/agent.policy_frac": 0.013256954153144108, "timer/agent.policy_avg": 0.00969982094893773, "timer/agent.policy_min": 0.008690357208251953, "timer/agent.policy_max": 0.03685784339904785, "timer/dataset_train_count": 2157.0, "timer/dataset_train_total": 0.3716893196105957, "timer/dataset_train_frac": 0.00037161360390938053, "timer/dataset_train_avg": 0.0001723177188737115, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0006749629974365234, "timer/agent.train_count": 2157.0, "timer/agent.train_total": 962.3997254371643, "timer/agent.train_frac": 0.9622036779151717, "timer/agent.train_avg": 0.4461751161043877, "timer/agent.train_min": 0.4338722229003906, "timer/agent.train_max": 0.5722172260284424, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47909021377563477, "timer/agent.report_frac": 0.00047899261976481046, "timer/agent.report_avg": 0.23954510688781738, "timer/agent.report_min": 0.2335033416748047, "timer/agent.report_max": 0.24558687210083008, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9557881435634872e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 8.626116124094006}
{"step": 510896, "time": 59310.57295751572, "episode/length": 288.0, "episode/score": 0.06595620766103139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06595620766103139}
{"step": 511000, "time": 59322.595341444016, "episode/length": 288.0, "episode/score": 0.06584103475512393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06584103475512393}
{"step": 511152, "time": 59340.10550570488, "episode/length": 288.0, "episode/score": 0.029059199761576338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029059199761576338}
{"step": 511208, "time": 59346.62957692146, "episode/length": 288.0, "episode/score": 0.03833428459597599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03833428459597599}
{"step": 511232, "time": 59349.39945888519, "episode/length": 288.0, "episode/score": 0.04871257566011877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04871257566011877}
{"step": 511328, "time": 59360.646440029144, "episode/length": 288.0, "episode/score": 0.03852439601493529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03852439601493529}
{"step": 511568, "time": 59388.591096162796, "episode/length": 269.0, "episode/score": 0.21398319058872062, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.05460819880764234}
{"step": 511816, "time": 59417.50939464569, "episode/length": 60.0, "episode/score": 0.8245936834257463, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.012093684240653602}
{"step": 511968, "time": 59435.07511162758, "episode/length": 91.0, "episode/score": 0.7414147773652644, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.025789765944921328}
{"step": 512040, "time": 59443.44515657425, "episode/length": 288.0, "episode/score": 0.038457242138832726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038457242138832726}
{"step": 512184, "time": 59460.282972574234, "episode/length": 128.0, "episode/score": 0.6272348467651625, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.027234799582032565}
{"step": 512280, "time": 59471.48744249344, "episode/length": 159.0, "episode/score": 0.5420564214562376, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.03893142766699498}
{"step": 512680, "time": 59517.761454582214, "episode/length": 107.0, "episode/score": 0.6928860288411158, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.02726104552343145}
{"step": 512712, "time": 59521.503772735596, "episode/length": 142.0, "episode/score": 0.5753050923120213, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.019055112064791047}
{"step": 512776, "time": 59528.885388851166, "episode/length": 234.0, "episode/score": 0.31276311550169567, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.044013093918295}
{"step": 513312, "time": 59591.24713730812, "episode/length": 78.0, "episode/score": 0.7869826638383017, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.03073261060157506}
{"step": 513520, "time": 59615.36714434624, "episode/length": 288.0, "episode/score": 0.05953923195770017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05953923195770017}
{"step": 514064, "time": 59678.25637626648, "episode/length": 234.0, "episode/score": 0.32049947708506465, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.05174945046670132}
{"step": 514160, "time": 59689.33900809288, "episode/length": 180.0, "episode/score": 0.48306744837699966, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.04556743367956528}
{"step": 514240, "time": 59698.570477962494, "episode/length": 89.0, "episode/score": 0.7406503524421169, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.01877534073946663}
{"step": 514280, "time": 59703.30750703812, "episode/length": 288.0, "episode/score": 0.04552502773128708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04552502773128708}
{"step": 514280, "time": 59703.31518864632, "episode/length": 187.0, "episode/score": 0.46403870205543285, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.04841369200588019}
{"step": 514352, "time": 59711.60577726364, "episode/length": 288.0, "episode/score": 0.05776558385483099, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05776558385483099}
{"step": 514592, "time": 59739.36360001564, "episode/length": 288.0, "episode/score": 0.05678820473312385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05678820473312385}
{"step": 515016, "time": 59788.55792379379, "episode/length": 91.0, "episode/score": 0.7409024660040018, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.025277469746754377}
{"step": 515104, "time": 59798.88097214699, "episode/length": 10.0, "episode/score": 0.9730544928951588, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.004304488806070594}
{"step": 515624, "time": 59859.047463178635, "episode/length": 288.0, "episode/score": 0.07031981988677671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07031981988677671}
{"step": 516376, "time": 59946.2914378643, "episode/length": 288.0, "episode/score": 0.04286959887190278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04286959887190278}
{"step": 516472, "time": 59957.35285925865, "episode/length": 288.0, "episode/score": 0.06474663595565744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06474663595565744}
{"step": 516552, "time": 59966.556962013245, "episode/length": 288.0, "episode/score": 0.036014752465661104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036014752465661104}
{"step": 516592, "time": 59971.213032245636, "episode/length": 288.0, "episode/score": 0.03193114945545972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03193114945545972}
{"step": 516664, "time": 59979.53050518036, "episode/length": 288.0, "episode/score": 0.07222865059000583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07222865059000583}
{"step": 516904, "time": 60007.43422937393, "episode/length": 288.0, "episode/score": 0.064040811800254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.064040811800254}
{"step": 517192, "time": 60040.7609128952, "episode/length": 101.0, "episode/score": 0.7294808720524486, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.04510585533520839}
{"step": 517416, "time": 60066.73320889473, "episode/length": 288.0, "episode/score": 0.04371357202779791, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04371357202779791}
{"step": 517704, "time": 60100.11597657204, "episode/length": 259.0, "episode/score": 0.2667503066511756, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.07612531079556106}
{"step": 517856, "time": 60117.71510100365, "episode/length": 148.0, "episode/score": 0.5957810748311658, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.058281022351138745}
{"step": 518144, "time": 60150.84823226929, "episode/length": 118.0, "episode/score": 0.6695690511076009, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.03831902808065024}
{"step": 518416, "time": 60182.15647816658, "episode/length": 88.0, "episode/score": 0.7589498450286101, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.03394982200165941}
{"step": 518761, "time": 60222.77027845383, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9515248051396124, "train/action_min": 0.0, "train/action_std": 2.0458269538702787, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007861752647268414, "train/actor_opt_grad_steps": 128225.0, "train/actor_opt_loss": -10.174278222783297, "train/adv_mag": 0.4615193975192529, "train/adv_max": 0.22297205279270807, "train/adv_mean": 0.0024889302325374484, "train/adv_min": -0.42645118413148103, "train/adv_std": 0.022852269182395604, "train/cont_avg": 0.9957591869212963, "train/cont_loss_mean": 0.013365299109460061, "train/cont_loss_std": 0.20445754506012978, "train/cont_neg_acc": 0.3862720933162941, "train/cont_neg_loss": 2.479545518395684, "train/cont_pos_acc": 0.9999182745814323, "train/cont_pos_loss": 0.0027859052912659805, "train/cont_pred": 0.9956210870985631, "train/cont_rate": 0.9957591869212963, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13512896058684284, "train/extr_critic_critic_opt_grad_steps": 128225.0, "train/extr_critic_critic_opt_loss": 10804.139302571615, "train/extr_critic_mag": 0.7974130770674458, "train/extr_critic_max": 0.7974130770674458, "train/extr_critic_mean": 0.6745697328889811, "train/extr_critic_min": 0.5221820054230867, "train/extr_critic_std": 0.024231187753482826, "train/extr_return_normed_mag": 0.47181696748292007, "train/extr_return_normed_max": 0.2654432825468205, "train/extr_return_normed_mean": 0.043780433315852726, "train/extr_return_normed_min": -0.39491198239503084, "train/extr_return_normed_std": 0.033627943877406696, "train/extr_return_rate": 0.9962556417341586, "train/extr_return_raw_mag": 0.8987214675656071, "train/extr_return_raw_max": 0.8987214675656071, "train/extr_return_raw_mean": 0.6770586495598158, "train/extr_return_raw_min": 0.238366202071861, "train/extr_return_raw_std": 0.03362794382135487, "train/extr_reward_mag": 0.289657077855534, "train/extr_reward_max": 0.289657077855534, "train/extr_reward_mean": 0.0014626238002232708, "train/extr_reward_min": 1.1175870895385742e-06, "train/extr_reward_std": 0.009146202989439998, "train/image_loss_mean": 0.09128007249630711, "train/image_loss_std": 0.10768896182654081, "train/model_loss_mean": 0.7202549405671932, "train/model_loss_std": 0.3556433997841345, "train/model_opt_grad_norm": 11.601743188169268, "train/model_opt_grad_steps": 128110.14814814815, "train/model_opt_loss": 4051.18148916739, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5625.0, "train/policy_entropy_mag": 1.3231803973515828, "train/policy_entropy_max": 1.3231803973515828, "train/policy_entropy_mean": 0.10590362921357155, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1340629361845829, "train/policy_logprob_mag": 6.551080301955894, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10556253521806663, "train/policy_logprob_min": -6.551080301955894, "train/policy_logprob_std": 0.6418014185296165, "train/policy_randomness_mag": 0.6799802542836578, "train/policy_randomness_max": 0.6799802542836578, "train/policy_randomness_mean": 0.054423703363648164, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06889472449957221, "train/post_ent_mag": 34.3504130575392, "train/post_ent_max": 34.3504130575392, "train/post_ent_mean": 33.9855891863505, "train/post_ent_min": 33.65694312696104, "train/post_ent_std": 0.14056141533095529, "train/prior_ent_mag": 34.2180533585725, "train/prior_ent_max": 34.2180533585725, "train/prior_ent_mean": 33.754324206599485, "train/prior_ent_min": 33.166554115436696, "train/prior_ent_std": 0.1798065724886126, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0011261599991283016, "train/reward_loss_mean": 0.015609547929165678, "train/reward_loss_std": 0.14598500725157834, "train/reward_max_data": 0.55225134518696, "train/reward_max_pred": 0.20045848853058285, "train/reward_neg_acc": 0.9998505565303343, "train/reward_neg_loss": 0.009614050034778538, "train/reward_pos_acc": 0.23256705101879163, "train/reward_pos_loss": 3.9532773840701445, "train/reward_pred": 0.0009440962145432692, "train/reward_rate": 0.0015417028356481482, "train_stats/mean_log_entropy": 0.09716893512851153, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.007391036953777075, "report/cont_loss_std": 0.08045763522386551, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 0.6964621543884277, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0033297145273536444, "report/cont_pred": 0.9930814504623413, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11032351851463318, "report/image_loss_std": 0.10943277180194855, "report/model_loss_mean": 0.7260600924491882, "report/model_loss_std": 0.13566617667675018, "report/post_ent_mag": 34.432762145996094, "report/post_ent_max": 34.432762145996094, "report/post_ent_mean": 34.11555862426758, "report/post_ent_min": 33.836181640625, "report/post_ent_std": 0.11641386896371841, "report/prior_ent_mag": 34.25788879394531, "report/prior_ent_max": 34.25788879394531, "report/prior_ent_mean": 33.758506774902344, "report/prior_ent_min": 33.082183837890625, "report/prior_ent_std": 0.17754718661308289, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00014378107152879238, "report/reward_loss_mean": 0.008345523849129677, "report/reward_loss_std": 0.014199153520166874, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.06017124652862549, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008345523849129677, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0009724840056151152, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.030635222792625427, "eval/cont_loss_std": 0.4136894643306732, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.69533109664917, "eval/cont_pos_acc": 0.9970587491989136, "eval/cont_pos_loss": 0.008420728147029877, "eval/cont_pred": 0.9944667220115662, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1676018238067627, "eval/image_loss_std": 0.13578353822231293, "eval/model_loss_mean": 0.8207829594612122, "eval/model_loss_std": 0.6867963671684265, "eval/post_ent_mag": 34.42778396606445, "eval/post_ent_max": 34.42778396606445, "eval/post_ent_mean": 34.1111946105957, "eval/post_ent_min": 33.81623077392578, "eval/post_ent_std": 0.1184205561876297, "eval/prior_ent_mag": 34.18733215332031, "eval/prior_ent_max": 34.18733215332031, "eval/prior_ent_mean": 33.765724182128906, "eval/prior_ent_min": 33.182518005371094, "eval/prior_ent_std": 0.17371143400669098, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0015869140625, "eval/reward_loss_mean": 0.022545892745256424, "eval/reward_loss_std": 0.32497990131378174, "eval/reward_max_data": 0.893750011920929, "eval/reward_max_pred": 0.6359102725982666, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.0058856564573943615, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.692580223083496, "eval/reward_pred": 0.0015676270704716444, "eval/reward_rate": 0.0029296875, "replay/size": 518257.0, "replay/inserts": 8628.0, "replay/samples": 34512.0, "replay/insert_wait_avg": 1.562266201678945e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.371757115597077e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 0.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": NaN, "eval_replay/insert_wait_frac": NaN, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0595116615295, "timer/env.step_count": 1079.0, "timer/env.step_total": 10.230015754699707, "timer/env.step_frac": 0.010229406985693527, "timer/env.step_avg": 0.009481015527988607, "timer/env.step_min": 0.008317708969116211, "timer/env.step_max": 0.03485608100891113, "timer/replay._sample_count": 34512.0, "timer/replay._sample_total": 16.339611768722534, "timer/replay._sample_frac": 0.016338639429142973, "timer/replay._sample_avg": 0.0004734472580181541, "timer/replay._sample_min": 0.0003552436828613281, "timer/replay._sample_max": 0.009804010391235352, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1079.0, "timer/agent.policy_total": 10.832512140274048, "timer/agent.policy_frac": 0.010831867517840594, "timer/agent.policy_avg": 0.010039399573933317, "timer/agent.policy_min": 0.008877277374267578, "timer/agent.policy_max": 0.04105687141418457, "timer/dataset_train_count": 2157.0, "timer/dataset_train_total": 0.40320587158203125, "timer/dataset_train_frac": 0.00040318187755859915, "timer/dataset_train_avg": 0.0001869290086147572, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.024677753448486328, "timer/agent.train_count": 2157.0, "timer/agent.train_total": 966.4086396694183, "timer/agent.train_frac": 0.9663511305080209, "timer/agent.train_avg": 0.4480336762491508, "timer/agent.train_min": 0.43511462211608887, "timer/agent.train_max": 0.5723950862884521, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4734339714050293, "timer/agent.report_frac": 0.00047340579823939834, "timer/agent.report_avg": 0.23671698570251465, "timer/agent.report_min": 0.23161768913269043, "timer/agent.report_max": 0.24181628227233887, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8370122559954596e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 8.627365498527837}
{"step": 518784, "time": 60225.21087050438, "episode/length": 288.0, "episode/score": 0.06399588275260726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06399588275260726}
{"step": 518864, "time": 60234.422875881195, "episode/length": 288.0, "episode/score": 0.06981780755094746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06981780755094746}
{"step": 518872, "time": 60235.34856033325, "episode/length": 245.0, "episode/score": 0.27801738523089625, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.043642386045803505}
{"step": 518904, "time": 60239.06810927391, "episode/length": 288.0, "episode/score": 0.09367327933412639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09367327933412639}
{"step": 519344, "time": 60290.15547513962, "episode/length": 149.0, "episode/score": 0.588420005768171, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.054044979528157455}
{"step": 519728, "time": 60334.80544400215, "episode/length": 288.0, "episode/score": 0.05917345663044671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05917345663044671}
{"step": 520000, "time": 60367.066853523254, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 520000, "time": 60368.53249526024, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 520000, "time": 60369.642968177795, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 520000, "time": 60369.701187849045, "eval_episode/length": 198.0, "eval_episode/score": 0.3812499940395355, "eval_episode/reward_rate": 0.005025125628140704}
{"step": 520000, "time": 60369.792041540146, "eval_episode/length": 200.0, "eval_episode/score": 0.375, "eval_episode/reward_rate": 0.004975124378109453}
{"step": 520000, "time": 60371.3259165287, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 60371.332837343216, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 60371.33825588226, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 60371.343849897385, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520168, "time": 60390.688876867294, "episode/length": 288.0, "episode/score": 0.03931490972274787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03931490972274787}
{"step": 520256, "time": 60400.86198472977, "episode/length": 183.0, "episode/score": 0.4631857108171289, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.035060717185047}
{"step": 520728, "time": 60455.74923944473, "episode/length": 288.0, "episode/score": 0.08138127171139331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08138127171139331}
{"step": 521016, "time": 60489.05258059502, "episode/length": 35.0, "episode/score": 0.901417658616424, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.010792644297339393}
{"step": 521048, "time": 60492.75460910797, "episode/length": 271.0, "episode/score": 0.21626067405952654, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.063135663919752}
{"step": 521176, "time": 60507.575538396835, "episode/length": 288.0, "episode/score": 0.04931563756747437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04931563756747437}
{"step": 521216, "time": 60512.25485539436, "episode/length": 288.0, "episode/score": 0.04863657158364276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04863657158364276}
{"step": 521464, "time": 60540.85279464722, "episode/length": 55.0, "episode/score": 0.8436356060385606, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.015510582697288555}
{"step": 521656, "time": 60563.2532389164, "episode/length": 288.0, "episode/score": 0.042351572098368706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042351572098368706}
{"step": 521808, "time": 60581.02366089821, "episode/length": 73.0, "episode/score": 0.7855073445737162, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.013632292093689102}
{"step": 521960, "time": 60598.611953258514, "episode/length": 37.0, "episode/score": 0.900529531364441, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.016154525811430176}
{"step": 522040, "time": 60607.94462132454, "episode/length": 288.0, "episode/score": 0.05088194015081626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05088194015081626}
{"step": 522416, "time": 60651.38578724861, "episode/length": 75.0, "episode/score": 0.7755576482149422, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.009932633895857634}
{"step": 522480, "time": 60658.78429675102, "episode/length": 288.0, "episode/score": 0.044685148672442665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044685148672442665}
{"step": 522568, "time": 60669.02615523338, "episode/length": 288.0, "episode/score": 0.05950996273304554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05950996273304554}
{"step": 522648, "time": 60678.278212308884, "episode/length": 75.0, "episode/score": 0.7847581609045733, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.01913315272639693}
{"step": 522696, "time": 60683.828819036484, "episode/length": 91.0, "episode/score": 0.7580130792401292, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.04238807684197354}
{"step": 523168, "time": 60738.28180646896, "episode/length": 58.0, "episode/score": 0.8364678374337018, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.017717790250571852}
{"step": 523224, "time": 60744.730436086655, "episode/length": 71.0, "episode/score": 0.8115157143242868, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.03339071192613119}
{"step": 523360, "time": 60760.543407678604, "episode/length": 288.0, "episode/score": 0.04246828215127607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04246828215127607}
{"step": 523488, "time": 60775.28669333458, "episode/length": 288.0, "episode/score": 0.06222394704661838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06222394704661838}
{"step": 523616, "time": 60790.187022686005, "episode/length": 141.0, "episode/score": 0.5834055806855076, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.02403056926516456}
{"step": 523736, "time": 60804.03319501877, "episode/length": 70.0, "episode/score": 0.800036669553208, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.018786640158339196}
{"step": 523776, "time": 60808.64174222946, "episode/length": 288.0, "episode/score": 0.08829657425400228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08829657425400228}
{"step": 524184, "time": 60855.821093797684, "episode/length": 70.0, "episode/score": 0.8058258021361553, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.02457579395797893}
{"step": 524512, "time": 60894.169063806534, "episode/length": 40.0, "episode/score": 0.8886309950520399, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.013630986873863549}
{"step": 524728, "time": 60919.26680803299, "episode/length": 288.0, "episode/score": 0.06343384858683976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06343384858683976}
{"step": 524784, "time": 60925.71922516823, "episode/length": 125.0, "episode/score": 0.6542779856263223, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.04490297846678004}
{"step": 524856, "time": 60934.11470603943, "episode/length": 139.0, "episode/score": 0.5916626577304669, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.026037638649995642}
{"step": 524880, "time": 60936.88690662384, "episode/length": 288.0, "episode/score": 0.041002897232601754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041002897232601754}
{"step": 525536, "time": 61012.71842432022, "episode/length": 288.0, "episode/score": 0.05831755286448015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05831755286448015}
{"step": 525600, "time": 61020.14253926277, "episode/length": 135.0, "episode/score": 0.6149262083210942, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.036801201161551944}
{"step": 525672, "time": 61028.516454935074, "episode/length": 288.0, "episode/score": 0.06667814054833343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06667814054833343}
{"step": 525672, "time": 61028.52179694176, "episode/length": 101.0, "episode/score": 0.716479820723805, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.03210485278458464}
{"step": 525800, "time": 61043.25723862648, "episode/length": 288.0, "episode/score": 0.049414354117800485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049414354117800485}
{"step": 526016, "time": 61068.50552535057, "episode/length": 160.0, "episode/score": 0.5429169700087186, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.042916940613849874}
{"step": 526808, "time": 61160.33823347092, "episode/length": 158.0, "episode/score": 0.5555168735095037, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.049266869807496505}
{"step": 526952, "time": 61177.020367622375, "episode/length": 159.0, "episode/score": 0.5624111027682659, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.05928610897902331}
{"step": 527064, "time": 61189.91983938217, "episode/length": 284.0, "episode/score": 0.1764661973586783, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.06396620055718927}
{"step": 527184, "time": 61203.78730201721, "episode/length": 28.0, "episode/score": 0.9226601790213351, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.010160170284365222}
{"step": 527192, "time": 61204.71149778366, "episode/length": 288.0, "episode/score": 0.06750968268011093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06750968268011093}
{"step": 527272, "time": 61213.931762456894, "episode/length": 208.0, "episode/score": 0.40728917961047273, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.057289173900301193}
{"step": 527341, "time": 61222.77878665924, "train_stats/mean_log_entropy": 0.08932909943784277, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7556996568341123, "train/action_min": 0.0, "train/action_std": 1.9786260089027548, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005941595674370564, "train/actor_opt_grad_steps": 130375.0, "train/actor_opt_loss": -14.194007505880338, "train/adv_mag": 0.43888978590475064, "train/adv_max": 0.18849703502432208, "train/adv_mean": 0.00016218134375445072, "train/adv_min": -0.40470424712261305, "train/adv_std": 0.016324741017317103, "train/cont_avg": 0.9958016939252337, "train/cont_loss_mean": 0.013875396310778283, "train/cont_loss_std": 0.21525034479030938, "train/cont_neg_acc": 0.3511567892823017, "train/cont_neg_loss": 2.668539725530416, "train/cont_pos_acc": 0.9999312613612024, "train/cont_pos_loss": 0.0027596596726346934, "train/cont_pred": 0.9957775596146271, "train/cont_rate": 0.9958016939252337, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08664403095510657, "train/extr_critic_critic_opt_grad_steps": 130375.0, "train/extr_critic_critic_opt_loss": 12108.79894677278, "train/extr_critic_mag": 0.8191622556927048, "train/extr_critic_max": 0.8191622556927048, "train/extr_critic_mean": 0.692017473071535, "train/extr_critic_min": 0.552663386982178, "train/extr_critic_std": 0.024365390825007008, "train/extr_return_normed_mag": 0.47261651319878123, "train/extr_return_normed_max": 0.23489395703110738, "train/extr_return_normed_mean": 0.032311168325211956, "train/extr_return_normed_min": -0.3801646112838638, "train/extr_return_normed_std": 0.03013478883620456, "train/extr_return_rate": 0.9994728114003333, "train/extr_return_raw_mag": 0.8947623853928575, "train/extr_return_raw_max": 0.8947623853928575, "train/extr_return_raw_mean": 0.6921796305714366, "train/extr_return_raw_min": 0.2797038167993599, "train/extr_return_raw_std": 0.030134788905836155, "train/extr_reward_mag": 0.28405329612928015, "train/extr_reward_max": 0.28405329612928015, "train/extr_reward_mean": 0.0009529182825304968, "train/extr_reward_min": 9.870974817008616e-07, "train/extr_reward_std": 0.006363594426912752, "train/image_loss_mean": 0.09341307581515512, "train/image_loss_std": 0.1089578942857056, "train/model_loss_mean": 0.7229564961428955, "train/model_loss_std": 0.3669315227002741, "train/model_opt_grad_norm": 11.958364843208098, "train/model_opt_grad_steps": 130258.35514018692, "train/model_opt_loss": 4380.5327262521905, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6074.7663551401865, "train/policy_entropy_mag": 1.3586350473288065, "train/policy_entropy_max": 1.3586350473288065, "train/policy_entropy_mean": 0.10813035600096266, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.14240346037756615, "train/policy_logprob_mag": 6.551080302657368, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10822377364351371, "train/policy_logprob_min": -6.551080302657368, "train/policy_logprob_std": 0.6461641763415292, "train/policy_randomness_mag": 0.6982003400258929, "train/policy_randomness_max": 0.6982003400258929, "train/policy_randomness_mean": 0.055568013705800626, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.0731809063701429, "train/post_ent_mag": 34.34587783456963, "train/post_ent_max": 34.34587783456963, "train/post_ent_mean": 33.97578604867525, "train/post_ent_min": 33.64934696660978, "train/post_ent_std": 0.14143062278489085, "train/prior_ent_mag": 34.21742562267268, "train/prior_ent_max": 34.21742562267268, "train/prior_ent_mean": 33.7396235777953, "train/prior_ent_min": 33.15926213130773, "train/prior_ent_std": 0.18297881535559057, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0011348847213318728, "train/reward_loss_mean": 0.01566799980301027, "train/reward_loss_std": 0.1498305670412205, "train/reward_max_data": 0.5817740581348695, "train/reward_max_pred": 0.2065664123151904, "train/reward_neg_acc": 0.9998628753367985, "train/reward_neg_loss": 0.0095249897447876, "train/reward_pos_acc": 0.25297297424561266, "train/reward_pos_loss": 3.850251779765696, "train/reward_pred": 0.000925581035678597, "train/reward_rate": 0.0015834915303738317, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.001381060341373086, "report/cont_loss_std": 0.00469163665547967, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002088296925649047, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0013789822114631534, "report/cont_pred": 0.9957132339477539, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.059458594769239426, "report/image_loss_std": 0.08588701486587524, "report/model_loss_mean": 0.671599805355072, "report/model_loss_std": 0.09285630285739899, "report/post_ent_mag": 34.13871383666992, "report/post_ent_max": 34.13871383666992, "report/post_ent_mean": 33.8228759765625, "report/post_ent_min": 33.581573486328125, "report/post_ent_std": 0.11103365570306778, "report/prior_ent_mag": 34.202857971191406, "report/prior_ent_max": 34.202857971191406, "report/prior_ent_mean": 33.74555969238281, "report/prior_ent_min": 33.162818908691406, "report/prior_ent_std": 0.19326607882976532, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00046584938536398113, "report/reward_loss_mean": 0.010760106146335602, "report/reward_loss_std": 0.025970350950956345, "report/reward_max_data": 0.2473749965429306, "report/reward_max_pred": 0.26639091968536377, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010084369219839573, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7020398378372192, "report/reward_pred": 0.0006484354380518198, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.05046956241130829, "eval/cont_loss_std": 0.6001179814338684, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.556487560272217, "eval/cont_pos_acc": 0.9960745573043823, "eval/cont_pos_loss": 0.013639253564178944, "eval/cont_pred": 0.9938148856163025, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1907283514738083, "eval/image_loss_std": 0.1602308452129364, "eval/model_loss_mean": 0.8443034887313843, "eval/model_loss_std": 0.6270263195037842, "eval/post_ent_mag": 34.193809509277344, "eval/post_ent_max": 34.193809509277344, "eval/post_ent_mean": 33.86286926269531, "eval/post_ent_min": 33.589141845703125, "eval/post_ent_std": 0.12329907715320587, "eval/prior_ent_mag": 34.25574493408203, "eval/prior_ent_max": 34.25574493408203, "eval/prior_ent_mean": 33.762489318847656, "eval/prior_ent_min": 33.27933883666992, "eval/prior_ent_std": 0.1851070374250412, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0031055540312081575, "eval/reward_loss_std": 0.03484247624874115, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.36710357666015625, "eval/reward_neg_acc": 0.9990234375, "eval/reward_neg_loss": 0.0031055540312081575, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0009271804010495543, "eval/reward_rate": 0.0, "replay/size": 526837.0, "replay/inserts": 8580.0, "replay/samples": 34320.0, "replay/insert_wait_avg": 1.5976823571122889e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.445370400702203e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.618209720070387e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9925699234009, "timer/env.step_count": 1072.0, "timer/env.step_total": 10.149595260620117, "timer/env.step_frac": 0.010149670673450677, "timer/env.step_avg": 0.009467906026697871, "timer/env.step_min": 0.008399009704589844, "timer/env.step_max": 0.03378891944885254, "timer/replay._sample_count": 34320.0, "timer/replay._sample_total": 16.234226942062378, "timer/replay._sample_frac": 0.016234347564508318, "timer/replay._sample_avg": 0.00047302526054960307, "timer/replay._sample_min": 0.00032830238342285156, "timer/replay._sample_max": 0.025685548782348633, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1361.0, "timer/agent.policy_total": 13.410987138748169, "timer/agent.policy_frac": 0.013411086784150253, "timer/agent.policy_avg": 0.009853774532511513, "timer/agent.policy_min": 0.008867025375366211, "timer/agent.policy_max": 0.025244474411010742, "timer/dataset_train_count": 2145.0, "timer/dataset_train_total": 0.3815450668334961, "timer/dataset_train_frac": 0.00038154790176363245, "timer/dataset_train_avg": 0.00017787648803426392, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0010786056518554688, "timer/agent.train_count": 2145.0, "timer/agent.train_total": 961.4918549060822, "timer/agent.train_frac": 0.9614989989172941, "timer/agent.train_avg": 0.4482479510051665, "timer/agent.train_min": 0.437530517578125, "timer/agent.train_max": 0.5762479305267334, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4784724712371826, "timer/agent.report_frac": 0.00047847602635070924, "timer/agent.report_avg": 0.2392362356185913, "timer/agent.report_min": 0.2332296371459961, "timer/agent.report_max": 0.24524283409118652, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8133601368797554e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 8.579943320019362}
{"step": 527640, "time": 61257.17019319534, "episode/length": 202.0, "episode/score": 0.40508601079736195, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.036336000747809294}
{"step": 527848, "time": 61281.2382543087, "episode/length": 97.0, "episode/score": 0.7143094674492261, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.017434503369173626}
{"step": 527872, "time": 61283.99323344231, "episode/length": 85.0, "episode/score": 0.7564098426936425, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.02203485779853054}
{"step": 527984, "time": 61297.12918829918, "episode/length": 288.0, "episode/score": 0.04247305950337932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04247305950337932}
{"step": 528040, "time": 61303.618654727936, "episode/length": 105.0, "episode/score": 0.6971351829676564, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.02526017478948006}
{"step": 528112, "time": 61311.90656423569, "episode/length": 288.0, "episode/score": 0.05872636558342492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05872636558342492}
{"step": 528384, "time": 61343.436458826065, "episode/length": 63.0, "episode/score": 0.8165256392400124, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.013400638506595897}
{"step": 528936, "time": 61407.03525686264, "episode/length": 207.0, "episode/score": 0.3909831554948937, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.03785816369344275}
{"step": 529016, "time": 61416.281428813934, "episode/length": 145.0, "episode/score": 0.5931677214562114, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.046292735615224956}
{"step": 529120, "time": 61428.23578572273, "episode/length": 288.0, "episode/score": 0.048777121764914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048777121764914}
{"step": 529792, "time": 61506.15198016167, "episode/length": 218.0, "episode/score": 0.36220070241904523, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.04345071006753187}
{"step": 529952, "time": 61524.53685092926, "episode/length": 288.0, "episode/score": 0.06228629952798315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06228629952798315}
{"step": 530032, "time": 61533.78688263893, "episode/length": 205.0, "episode/score": 0.4020967907312638, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.042721784037382804}
{"step": 530088, "time": 61540.54461026192, "eval_episode/length": 15.0, "eval_episode/score": 0.953125, "eval_episode/reward_rate": 0.0625}
{"step": 530088, "time": 61540.99094295502, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 530088, "time": 61542.34015727043, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 530088, "time": 61542.71425628662, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 530088, "time": 61544.603055000305, "eval_episode/length": 241.0, "eval_episode/score": 0.24687500298023224, "eval_episode/reward_rate": 0.004132231404958678}
{"step": 530088, "time": 61545.7495238781, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 61545.75566649437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 61545.76131987572, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 61545.766595602036, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 61545.77177429199, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530120, "time": 61549.46202802658, "episode/length": 250.0, "episode/score": 0.27647023113860314, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.05772022397906085}
{"step": 530256, "time": 61565.17538976669, "episode/length": 283.0, "episode/score": 0.1466251684326778, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.03100017017308687}
{"step": 530688, "time": 61614.9927918911, "episode/length": 111.0, "episode/score": 0.6729652357707891, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.019840262796606112}
{"step": 531248, "time": 61679.803441524506, "episode/length": 288.0, "episode/score": 0.033161179797900786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033161179797900786}
{"step": 531328, "time": 61689.07990384102, "episode/length": 288.0, "episode/score": 0.045933106734594276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045933106734594276}
{"step": 531432, "time": 61701.073239564896, "episode/length": 288.0, "episode/score": 0.027905654044616313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027905654044616313}
{"step": 531504, "time": 61709.35553646088, "episode/length": 183.0, "episode/score": 0.44723181828430825, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.019106830705823086}
{"step": 532264, "time": 61797.28208565712, "episode/length": 288.0, "episode/score": 0.05473518935110633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05473518935110633}
{"step": 532432, "time": 61816.67577242851, "episode/length": 288.0, "episode/score": 0.05077708506377121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05077708506377121}
{"step": 532568, "time": 61832.8250143528, "episode/length": 288.0, "episode/score": 0.033388570769602666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033388570769602666}
{"step": 533000, "time": 61882.72522521019, "episode/length": 288.0, "episode/score": 0.045000986284748024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045000986284748024}
{"step": 533560, "time": 61947.41935944557, "episode/length": 288.0, "episode/score": 0.048165374612153755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048165374612153755}
{"step": 533640, "time": 61956.72577834129, "episode/length": 288.0, "episode/score": 0.08102948551947975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08102948551947975}
{"step": 533744, "time": 61968.73057293892, "episode/length": 288.0, "episode/score": 0.046698620498546006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046698620498546006}
{"step": 533816, "time": 61977.07760930061, "episode/length": 288.0, "episode/score": 0.0627725257372731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0627725257372731}
{"step": 534088, "time": 62008.6558907032, "episode/length": 33.0, "episode/score": 0.9189219343106743, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.02204688183064718}
{"step": 534576, "time": 62065.46593952179, "episode/length": 288.0, "episode/score": 0.09674884989726706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09674884989726706}
{"step": 534744, "time": 62085.12023925781, "episode/length": 288.0, "episode/score": 0.0660276328069358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0660276328069358}
{"step": 534792, "time": 62090.76197504997, "episode/length": 130.0, "episode/score": 0.6556608828041135, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.06191085416594433}
{"step": 534880, "time": 62101.003776073456, "episode/length": 288.0, "episode/score": 0.06674090997557869, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06674090997557869}
{"step": 534888, "time": 62101.98788046837, "episode/length": 165.0, "episode/score": 0.549687350269096, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0653123514332492}
{"step": 534952, "time": 62109.362354040146, "episode/length": 243.0, "episode/score": 0.3353786102286449, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.09475361700401663}
{"step": 535304, "time": 62150.15805888176, "episode/length": 151.0, "episode/score": 0.5918726293812142, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.06374762698305858}
{"step": 535584, "time": 62182.61860013008, "episode/length": 34.0, "episode/score": 0.9100979020133764, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.016347860697578653}
{"step": 535904, "time": 62219.917832136154, "episode/length": 144.0, "episode/score": 0.5900673973319499, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.040067371091936366}
{"step": 535921, "time": 62222.902725458145, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.366852516351744, "train/action_min": 0.0, "train/action_std": 1.8544670803602352, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0057014071523363505, "train/actor_opt_grad_steps": 132520.0, "train/actor_opt_loss": -12.251286621980888, "train/adv_mag": 0.4412614893081576, "train/adv_max": 0.1522550807442776, "train/adv_mean": -0.000166317524451378, "train/adv_min": -0.4147863203702971, "train/adv_std": 0.015597398849853943, "train/cont_avg": 0.9955214389534883, "train/cont_loss_mean": 0.014099288539592783, "train/cont_loss_std": 0.21474442837196728, "train/cont_neg_acc": 0.387115177234938, "train/cont_neg_loss": 2.5330247277664673, "train/cont_pos_acc": 0.9999224091685095, "train/cont_pos_loss": 0.0027356207403246052, "train/cont_pred": 0.9956114059270814, "train/cont_rate": 0.9955214389534883, "train/dyn_loss_mean": 1.0000002179034921, "train/dyn_loss_std": 6.958024121474388e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0937352781682167, "train/extr_critic_critic_opt_grad_steps": 132520.0, "train/extr_critic_critic_opt_loss": 12813.347097565407, "train/extr_critic_mag": 0.8216979847397915, "train/extr_critic_max": 0.8216979847397915, "train/extr_critic_mean": 0.7117452457893726, "train/extr_critic_min": 0.5943328508110933, "train/extr_critic_std": 0.021083940604571687, "train/extr_return_normed_mag": 0.47044093054394387, "train/extr_return_normed_max": 0.19440837849018186, "train/extr_return_normed_mean": 0.030462911021137653, "train/extr_return_normed_min": -0.3938170549481414, "train/extr_return_normed_std": 0.02700502841278564, "train/extr_return_rate": 0.9994268131810565, "train/extr_return_raw_mag": 0.8755242649898972, "train/extr_return_raw_max": 0.8755242649898972, "train/extr_return_raw_mean": 0.7115788290666979, "train/extr_return_raw_min": 0.287298831551574, "train/extr_return_raw_std": 0.027005028490756835, "train/extr_reward_mag": 0.2536613153856854, "train/extr_reward_max": 0.2536613153856854, "train/extr_reward_mean": 0.000983513139735171, "train/extr_reward_min": 9.104262950808503e-07, "train/extr_reward_std": 0.006015182938426733, "train/image_loss_mean": 0.09340201266283213, "train/image_loss_std": 0.10869966901318971, "train/model_loss_mean": 0.7232478976249694, "train/model_loss_std": 0.3644287844036901, "train/model_opt_grad_norm": 11.80039904394815, "train/model_opt_grad_steps": 132402.1953488372, "train/model_opt_loss": 5045.950898210393, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 6976.7441860465115, "train/policy_entropy_mag": 1.2564991912176442, "train/policy_entropy_max": 1.2564991912176442, "train/policy_entropy_mean": 0.10347790115101393, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1299700520759405, "train/policy_logprob_mag": 6.5510803111763884, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10327096214128095, "train/policy_logprob_min": -6.5510803111763884, "train/policy_logprob_std": 0.6401700937470725, "train/policy_randomness_mag": 0.6457128885180451, "train/policy_randomness_max": 0.6457128885180451, "train/policy_randomness_mean": 0.053177124798990956, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06679139875395354, "train/post_ent_mag": 33.990371171818225, "train/post_ent_max": 33.990371171818225, "train/post_ent_mean": 33.73084370812705, "train/post_ent_min": 33.491696166992185, "train/post_ent_std": 0.10001409166427545, "train/prior_ent_mag": 34.100160909253496, "train/prior_ent_max": 34.100160909253496, "train/prior_ent_mean": 33.43258501984352, "train/prior_ent_min": 32.76612997720408, "train/prior_ent_std": 0.24851303280786027, "train/rep_loss_mean": 1.0000002179034921, "train/rep_loss_std": 6.958024121474388e-06, "train/reward_avg": 0.0011336629315845256, "train/reward_loss_mean": 0.01574644033125667, "train/reward_loss_std": 0.1475638304772072, "train/reward_max_data": 0.5607703869458461, "train/reward_max_pred": 0.2240914511126141, "train/reward_neg_acc": 0.999845337313275, "train/reward_neg_loss": 0.009657848165045644, "train/reward_pos_acc": 0.2639204559170387, "train/reward_pos_loss": 3.883010704493658, "train/reward_pred": 0.0009556223730405057, "train/reward_rate": 0.0015625, "train_stats/mean_log_entropy": 0.09100600508482833, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.02063971571624279, "report/cont_loss_std": 0.34525230526924133, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 3.9187378883361816, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0015126388752833009, "report/cont_pred": 0.996904194355011, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09455585479736328, "report/image_loss_std": 0.11376211792230606, "report/model_loss_mean": 0.7245895862579346, "report/model_loss_std": 0.3630451560020447, "report/post_ent_mag": 33.71742630004883, "report/post_ent_max": 33.71742630004883, "report/post_ent_mean": 33.56376647949219, "report/post_ent_min": 33.4315185546875, "report/post_ent_std": 0.06037227064371109, "report/prior_ent_mag": 34.03105163574219, "report/prior_ent_max": 34.03105163574219, "report/prior_ent_mean": 33.203468322753906, "report/prior_ent_min": 32.39463806152344, "report/prior_ent_std": 0.311716765165329, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00019394137780182064, "report/reward_loss_mean": 0.009394011460244656, "report/reward_loss_std": 0.014266346581280231, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.029361248016357422, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009394011460244656, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0006546218646690249, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.018782248720526695, "eval/cont_loss_std": 0.36252114176750183, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.708622455596924, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.005690584424883127, "eval/cont_pred": 0.996533989906311, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18136633932590485, "eval/image_loss_std": 0.1673429310321808, "eval/model_loss_mean": 0.8081413507461548, "eval/model_loss_std": 0.46677905321121216, "eval/post_ent_mag": 33.71285629272461, "eval/post_ent_max": 33.71285629272461, "eval/post_ent_mean": 33.5614128112793, "eval/post_ent_min": 33.377716064453125, "eval/post_ent_std": 0.06814061850309372, "eval/prior_ent_mag": 34.03105163574219, "eval/prior_ent_max": 34.03105163574219, "eval/prior_ent_mean": 33.11863708496094, "eval/prior_ent_min": 32.37415313720703, "eval/prior_ent_std": 0.30977433919906616, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008361816289834678, "eval/reward_loss_mean": 0.007992768660187721, "eval/reward_loss_std": 0.14626632630825043, "eval/reward_max_data": 0.856249988079071, "eval/reward_max_pred": 0.1456458568572998, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.0037026414647698402, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.396792411804199, "eval/reward_pred": 0.0008690580725669861, "eval/reward_rate": 0.0009765625, "replay/size": 535417.0, "replay/inserts": 8580.0, "replay/samples": 34320.0, "replay/insert_wait_avg": 1.5624753245106943e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.550685833661984e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 9.588304275459896e-07, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1074228286743, "timer/env.step_count": 1073.0, "timer/env.step_total": 10.144527673721313, "timer/env.step_frac": 0.010143438036914905, "timer/env.step_avg": 0.009454359434968605, "timer/env.step_min": 0.008297443389892578, "timer/env.step_max": 0.03323626518249512, "timer/replay._sample_count": 34320.0, "timer/replay._sample_total": 16.324360132217407, "timer/replay._sample_frac": 0.016322606711633107, "timer/replay._sample_avg": 0.00047565151900400373, "timer/replay._sample_min": 0.0003726482391357422, "timer/replay._sample_max": 0.01051950454711914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 1362.0, "timer/agent.policy_total": 13.760907173156738, "timer/agent.policy_frac": 0.013759429096362264, "timer/agent.policy_avg": 0.010103456074270732, "timer/agent.policy_min": 0.008825302124023438, "timer/agent.policy_max": 0.0725712776184082, "timer/dataset_train_count": 2145.0, "timer/dataset_train_total": 0.4051196575164795, "timer/dataset_train_frac": 0.00040507614309136014, "timer/dataset_train_avg": 0.00018886697320115594, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.02194690704345703, "timer/agent.train_count": 2145.0, "timer/agent.train_total": 961.2840242385864, "timer/agent.train_frac": 0.9611807714812466, "timer/agent.train_avg": 0.44815106025108925, "timer/agent.train_min": 0.42636919021606445, "timer/agent.train_max": 0.5936057567596436, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47664976119995117, "timer/agent.report_frac": 0.0004765985636341035, "timer/agent.report_avg": 0.23832488059997559, "timer/agent.report_min": 0.23306488990783691, "timer/agent.report_max": 0.24358487129211426, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.289822989510191e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 8.578947821473722}
{"step": 535952, "time": 62226.299798727036, "episode/length": 288.0, "episode/score": 0.06270244759730303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06270244759730303}
{"step": 536624, "time": 62304.12725186348, "episode/length": 83.0, "episode/score": 0.7632546590036782, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0226296057669515}
{"step": 536728, "time": 62316.10669565201, "episode/length": 268.0, "episode/score": 0.232496807187772, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.06999680598869418}
{"step": 537104, "time": 62359.332260131836, "episode/length": 288.0, "episode/score": 0.07141878333482055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07141878333482055}
{"step": 537192, "time": 62369.46246433258, "episode/length": 288.0, "episode/score": 0.05926468516588557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05926468516588557}
{"step": 537200, "time": 62370.4060857296, "episode/length": 288.0, "episode/score": 0.058401657783065275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058401657783065275}
{"step": 537264, "time": 62377.84663438797, "episode/length": 288.0, "episode/score": 0.0702405259016814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0702405259016814}
{"step": 537896, "time": 62450.73467040062, "episode/length": 288.0, "episode/score": 0.08429598459906629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08429598459906629}
{"step": 537984, "time": 62460.90736079216, "episode/length": 97.0, "episode/score": 0.7211828357333161, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.024307845256089422}
{"step": 538216, "time": 62487.97292590141, "episode/length": 288.0, "episode/score": 0.08134282210403398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08134282210403398}
{"step": 538320, "time": 62500.1107981205, "episode/length": 140.0, "episode/score": 0.6010894323856064, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.03858940299073765}
{"step": 538920, "time": 62569.692442178726, "episode/length": 273.0, "episode/score": 0.21424229897922942, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.06736730610384711}
{"step": 538936, "time": 62571.53154397011, "episode/length": 288.0, "episode/score": 0.04042852329030211, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04042852329030211}
{"step": 539416, "time": 62626.86475586891, "episode/length": 288.0, "episode/score": 0.05999606457527307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05999606457527307}
{"step": 539576, "time": 62645.40074777603, "episode/length": 288.0, "episode/score": 0.04486279234100721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04486279234100721}
{"step": 539584, "time": 62646.32969689369, "episode/length": 199.0, "episode/score": 0.40652461397661455, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0283995948961433}
{"step": 539928, "time": 62686.13873744011, "episode/length": 200.0, "episode/score": 0.41577359165961525, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.040773592067068876}
{"step": 540072, "time": 62704.41381907463, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 540072, "time": 62704.67910671234, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 540072, "time": 62706.260120630264, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 540072, "time": 62707.08303189278, "eval_episode/length": 226.0, "eval_episode/score": 0.29374998807907104, "eval_episode/reward_rate": 0.004405286343612335}
{"step": 540072, "time": 62707.65302705765, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 540072, "time": 62708.06496500969, "eval_episode/length": 183.0, "eval_episode/score": 0.4281249940395355, "eval_episode/reward_rate": 0.005434782608695652}
{"step": 540072, "time": 62708.24142622948, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 62708.290323495865, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 62708.33551597595, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 62708.341526031494, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540072, "time": 62708.34792518616, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 540208, "time": 62724.004980802536, "episode/length": 288.0, "episode/score": 0.04212057656161505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04212057656161505}
{"step": 540488, "time": 62756.4944729805, "episode/length": 283.0, "episode/score": 0.16292876249661958, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.047303764237028645}
{"step": 540992, "time": 62815.53410935402, "episode/length": 256.0, "episode/score": 0.2259104465348969, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.025910448793354135}
{"step": 541128, "time": 62831.340708732605, "episode/length": 193.0, "episode/score": 0.42339190179222896, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.02651689608205743}
{"step": 541232, "time": 62843.344475507736, "episode/length": 288.0, "episode/score": 0.0558961157818203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0558961157818203}
{"step": 541480, "time": 62872.210715293884, "episode/length": 30.0, "episode/score": 0.9174947155149198, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.011244730619807797}
{"step": 541728, "time": 62900.91349029541, "episode/length": 288.0, "episode/score": 0.02648850432740346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02648850432740346}
{"step": 541896, "time": 62920.41703701019, "episode/length": 288.0, "episode/score": 0.0430033317045968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0430033317045968}
{"step": 542064, "time": 62939.76022815704, "episode/length": 116.0, "episode/score": 0.6673400098994193, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.02984004196019896}
{"step": 542120, "time": 62946.28524518013, "episode/length": 140.0, "episode/score": 0.6109102880787418, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.04841028889364907}
{"step": 542224, "time": 62958.26269364357, "episode/length": 61.0, "episode/score": 0.8273560881276012, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.017981095959441973}
{"step": 542240, "time": 62960.14178442955, "episode/length": 288.0, "episode/score": 0.021728905865302295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021728905865302295}
{"step": 542520, "time": 62992.586525440216, "episode/length": 288.0, "episode/score": 0.043657464975069615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043657464975069615}
{"step": 542736, "time": 63017.60932683945, "episode/length": 61.0, "episode/score": 0.8381369495368745, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.02876197353589305}
{"step": 542800, "time": 63025.01580452919, "episode/length": 288.0, "episode/score": 0.03930939810857126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03930939810857126}
{"step": 542840, "time": 63029.62870430946, "episode/length": 96.0, "episode/score": 0.7215907233348275, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.021590749414770016}
{"step": 542872, "time": 63033.36857008934, "episode/length": 121.0, "episode/score": 0.6506385859280499, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.02876361295386687}
{"step": 543176, "time": 63068.442898750305, "episode/length": 54.0, "episode/score": 0.8435673325608946, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.012317338771651976}
{"step": 543184, "time": 63069.36530184746, "episode/length": 82.0, "episode/score": 0.7731831268424685, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.029433136365241808}
