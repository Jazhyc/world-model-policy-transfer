{"step": 328, "time": 109.56272602081299, "episode/length": 40.0, "episode/score": 0.03973511862568557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03973511862568557}
{"step": 792, "time": 114.13617897033691, "episode/length": 98.0, "episode/score": 0.10017767770477803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10017767770477803}
{"step": 1176, "time": 118.0780942440033, "episode/length": 146.0, "episode/score": 0.14599616164741747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14599616164741747}
{"step": 1224, "time": 119.70595455169678, "episode/length": 152.0, "episode/score": 0.11358147789178474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11358147789178474}
{"step": 1232, "time": 121.192795753479, "episode/length": 153.0, "episode/score": 0.13999252695975883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13999252695975883}
{"step": 1272, "time": 122.85394024848938, "episode/length": 158.0, "episode/score": 0.14931782180792652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14931782180792652}
{"step": 1464, "time": 125.58811545372009, "episode/length": 182.0, "episode/score": 0.16135008601122536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16135008601122536}
{"step": 1472, "time": 127.07555627822876, "episode/length": 142.0, "episode/score": 0.137471143851144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.137471143851144}
{"step": 1560, "time": 141.0494351387024, "eval_episode/length": 60.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9180327868852459}
{"step": 1560, "time": 144.50013971328735, "eval_episode/length": 150.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 1560, "time": 145.84677124023438, "eval_episode/length": 151.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 1560, "time": 147.51770067214966, "eval_episode/length": 163.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 1560, "time": 148.98395609855652, "eval_episode/length": 167.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 1560, "time": 150.89905095100403, "eval_episode/length": 187.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 1560, "time": 152.33691549301147, "train_stats/sum_log_reward": 0.8499999642372131, "train_stats/max_log_achievement_collect_sapling": 0.42857142857142855, "train_stats/max_log_achievement_collect_wood": 0.2857142857142857, "train_stats/max_log_achievement_place_plant": 0.2857142857142857, "train_stats/max_log_achievement_wake_up": 1.7142857142857142, "eval_stats/sum_log_reward": 1.2666666184862454, "eval_stats/max_log_achievement_collect_sapling": 0.3333333333333333, "eval_stats/max_log_achievement_collect_wood": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_place_plant": 0.3333333333333333, "eval_stats/max_log_achievement_wake_up": 1.6666666666666667}
{"step": 1560, "time": 192.10208225250244, "eval_episode/length": 135.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 1560, "time": 193.87095737457275, "eval_episode/length": 141.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9647887323943662}
{"step": 1560, "time": 196.28418254852295, "eval_episode/length": 159.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 1560, "time": 198.53617191314697, "eval_episode/length": 177.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 1560, "time": 198.54395508766174, "eval_episode/length": 177.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 1560, "time": 202.04431080818176, "eval_episode/length": 184.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 1560, "time": 203.98970985412598, "eval_episode/length": 196.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 1560, "time": 207.7888662815094, "eval_episode/length": 248.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9839357429718876}
{"step": 1561, "time": 338.53985595703125, "eval_stats/sum_log_reward": 1.5999999418854713, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/max_log_achievement_collect_drink": 2.5, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 8.48529052734375, "train/action_min": 0.0, "train/action_std": 4.7280049324035645, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00010337887943023816, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -0.5609630942344666, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9970703125, "train/cont_loss_mean": 1.31585693359375, "train/cont_loss_std": 0.43652641773223877, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.300468772649765, "train/cont_pos_acc": 0.0636630728840828, "train/cont_pos_loss": 1.318840503692627, "train/cont_pred": 0.29196852445602417, "train/cont_rate": 0.9970703125, "train/dyn_loss_mean": 10.826347351074219, "train/dyn_loss_std": 0.5462333559989929, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.9944604635238647, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 8055.970703125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3592.861572265625, "train/image_loss_std": 166.1953582763672, "train/model_loss_mean": 3606.21435546875, "train/model_loss_std": 166.3466339111328, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 36062144.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.784907817840576, "train/policy_entropy_max": 2.784907817840576, "train/policy_entropy_mean": 2.567074775695801, "train/policy_entropy_min": 1.7853009700775146, "train/policy_entropy_std": 0.09599467366933823, "train/policy_logprob_mag": 5.391092300415039, "train/policy_logprob_max": -0.5631906390190125, "train/policy_logprob_mean": -2.564807176589966, "train/policy_logprob_min": -5.391092300415039, "train/policy_logprob_std": 0.7053403258323669, "train/policy_randomness_mag": 0.9829502701759338, "train/policy_randomness_max": 0.9829502701759338, "train/policy_randomness_mean": 0.9060646295547485, "train/policy_randomness_min": 0.6301329135894775, "train/policy_randomness_std": 0.03388190269470215, "train/post_ent_mag": 106.3062744140625, "train/post_ent_max": 106.3062744140625, "train/post_ent_mean": 105.4007568359375, "train/post_ent_min": 104.7836685180664, "train/post_ent_std": 0.27630922198295593, "train/prior_ent_mag": 106.49067687988281, "train/prior_ent_max": 106.49067687988281, "train/prior_ent_mean": 105.57554626464844, "train/prior_ent_min": 104.55560302734375, "train/prior_ent_std": 0.3035397529602051, "train/rep_loss_mean": 10.826347351074219, "train/rep_loss_std": 0.5462333559989929, "train/reward_avg": 0.000942843034863472, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.799708777791238e-07, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.3049101829528809, "report/cont_loss_std": 0.4335775673389435, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.24251657724380493, "report/cont_pos_acc": 0.05582761764526367, "report/cont_pos_loss": 1.3080317974090576, "report/cont_pred": 0.2946023643016815, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 10.80720043182373, "report/dyn_loss_std": 0.4722674489021301, "report/image_loss_mean": 3593.63525390625, "report/image_loss_std": 165.5090789794922, "report/model_loss_mean": 3606.9658203125, "report/model_loss_std": 165.5527801513672, "report/post_ent_mag": 106.30413055419922, "report/post_ent_max": 106.30413055419922, "report/post_ent_mean": 105.42935180664062, "report/post_ent_min": 104.7773666381836, "report/post_ent_std": 0.2661350965499878, "report/prior_ent_mag": 106.48113250732422, "report/prior_ent_max": 106.48113250732422, "report/prior_ent_mean": 105.56205749511719, "report/prior_ent_min": 104.69935607910156, "report/prior_ent_std": 0.27680331468582153, "report/rep_loss_mean": 10.80720043182373, "report/rep_loss_std": 0.4722674489021301, "report/reward_avg": 0.000942843034863472, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.799708777791238e-07, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.3376034498214722, "eval/cont_loss_std": 0.441804438829422, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.15788735449314117, "eval/cont_pos_acc": 0.04305283725261688, "eval/cont_pos_loss": 1.3399120569229126, "eval/cont_pred": 0.2861362099647522, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 10.866109848022461, "eval/dyn_loss_std": 0.47379735112190247, "eval/image_loss_mean": 3590.96044921875, "eval/image_loss_std": 121.93197631835938, "eval/model_loss_mean": 3604.35888671875, "eval/model_loss_std": 121.92955017089844, "eval/post_ent_mag": 105.92100524902344, "eval/post_ent_max": 105.92100524902344, "eval/post_ent_mean": 105.37638854980469, "eval/post_ent_min": 104.89376831054688, "eval/post_ent_std": 0.1983111947774887, "eval/prior_ent_mag": 106.48919677734375, "eval/prior_ent_max": 106.48919677734375, "eval/prior_ent_mean": 105.56385803222656, "eval/prior_ent_min": 104.51814270019531, "eval/prior_ent_std": 0.300397127866745, "eval/rep_loss_mean": 10.866109848022461, "eval/rep_loss_std": 0.47379735112190247, "eval/reward_avg": 0.01806640625, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.021484375, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 2.526740703023371e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.770397731236049e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3048.0, "eval_replay/inserts": 3048.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.3691077395061182e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.068420955113002e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 242.32432436943054, "timer/env.step_count": 196.0, "timer/env.step_total": 26.779750108718872, "timer/env.step_frac": 0.1105120180502076, "timer/env.step_avg": 0.13663137810570852, "timer/env.step_min": 0.022770166397094727, "timer/env.step_max": 10.991583824157715, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.12903046607971191, "timer/replay._sample_frac": 0.0005324701365224944, "timer/replay._sample_avg": 0.0011520577328545706, "timer/replay._sample_min": 0.0003578662872314453, "timer/replay._sample_max": 0.010326147079467773, "timer/agent.save_count": 1.0, "timer/agent.save_total": 9.91273546218872, "timer/agent.save_frac": 0.04090689404781529, "timer/agent.save_avg": 9.91273546218872, "timer/agent.save_min": 9.91273546218872, "timer/agent.save_max": 9.91273546218872, "timer/agent.policy_count": 250.0, "timer/agent.policy_total": 25.178322792053223, "timer/agent.policy_frac": 0.10390340655058686, "timer/agent.policy_avg": 0.10071329116821288, "timer/agent.policy_min": 0.010166168212890625, "timer/agent.policy_max": 18.711280822753906, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.361701965332031e-05, "timer/dataset_train_frac": 1.3872738422276658e-07, "timer/dataset_train_avg": 3.361701965332031e-05, "timer/dataset_train_min": 3.361701965332031e-05, "timer/dataset_train_max": 3.361701965332031e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 95.34231400489807, "timer/agent.train_frac": 0.3934492100741233, "timer/agent.train_avg": 95.34231400489807, "timer/agent.train_min": 95.34231400489807, "timer/agent.train_max": 95.34231400489807, "timer/agent.report_count": 2.0, "timer/agent.report_total": 33.06841206550598, "timer/agent.report_frac": 0.1364634448132917, "timer/agent.report_avg": 16.53420603275299, "timer/agent.report_min": 8.137795448303223, "timer/agent.report_max": 24.93061661720276, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.790855407714844e-05, "timer/dataset_eval_frac": 1.5643726305971552e-07, "timer/dataset_eval_avg": 3.790855407714844e-05, "timer/dataset_eval_min": 3.790855407714844e-05, "timer/dataset_eval_max": 3.790855407714844e-05}
{"step": 1640, "time": 341.39937925338745, "episode/length": 204.0, "episode/score": 0.21338260356060346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21338260356060346}
{"step": 2352, "time": 371.4551661014557, "episode/length": 194.0, "episode/score": 0.17554991006909404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17554991006909404}
{"step": 2504, "time": 378.5080027580261, "episode/length": 153.0, "episode/score": 0.12455535655317362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12455535655317362}
{"step": 2528, "time": 381.2367730140686, "episode/length": 168.0, "episode/score": 0.16724080156109267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16724080156109267}
{"step": 2552, "time": 383.4327425956726, "episode/length": 164.0, "episode/score": 0.13525247511097405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13525247511097405}
{"step": 2640, "time": 388.6310701370239, "episode/length": 176.0, "episode/score": 0.16125068252313213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16125068252313213}
{"step": 2656, "time": 390.8420021533966, "episode/length": 147.0, "episode/score": 0.09320721513267927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09320721513267927}
{"step": 2680, "time": 393.0665669441223, "episode/length": 151.0, "episode/score": 0.11110689575434662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11110689575434662}
{"step": 3136, "time": 412.11883091926575, "episode/length": 186.0, "episode/score": 0.16082343563539325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16082343563539325}
{"step": 3424, "time": 424.9021735191345, "episode/length": 92.0, "episode/score": 0.10884301996156864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10884301996156864}
{"step": 3504, "time": 430.129465341568, "episode/length": 143.0, "episode/score": 0.133658087700951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.133658087700951}
{"step": 3632, "time": 437.09573245048523, "episode/length": 140.0, "episode/score": 0.1282029725166467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1282029725166467}
{"step": 3816, "time": 445.44947361946106, "episode/length": 144.0, "episode/score": 0.10924884716951055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10924884716951055}
{"step": 3984, "time": 453.5912721157074, "episode/length": 167.0, "episode/score": 0.15785549001884647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15785549001884647}
{"step": 4064, "time": 458.3085913658142, "episode/length": 188.0, "episode/score": 0.1718619500575187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1718619500575187}
{"step": 4416, "time": 473.0928747653961, "episode/length": 159.0, "episode/score": 0.12727746486007163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12727746486007163}
{"step": 4504, "time": 477.67483925819397, "episode/length": 246.0, "episode/score": 0.22710063419344806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22710063419344806}
{"step": 4752, "time": 488.96382188796997, "episode/length": 139.0, "episode/score": 0.12017552346605953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12017552346605953}
{"step": 4832, "time": 493.46400570869446, "episode/length": 165.0, "episode/score": 0.1425410881602147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1425410881602147}
{"step": 4944, "time": 499.2906222343445, "episode/length": 109.0, "episode/score": 0.1014219856924683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1014219856924683}
{"step": 5088, "time": 506.29430317878723, "episode/length": 207.0, "episode/score": 0.18574384373641806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18574384373641806}
{"step": 5160, "time": 510.3618152141571, "episode/length": 146.0, "episode/score": 0.10393084601128066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10393084601128066}
{"step": 5264, "time": 516.0891716480255, "episode/length": 180.0, "episode/score": 0.1486920079387346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1486920079387346}
{"step": 5672, "time": 532.9831268787384, "episode/length": 145.0, "episode/score": 0.14344245412939927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14344245412939927}
{"step": 6064, "time": 549.7455334663391, "episode/length": 153.0, "episode/score": 0.12116037568057436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12116037568057436}
{"step": 6072, "time": 551.8588497638702, "episode/length": 206.0, "episode/score": 0.1886781795060415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1886781795060415}
{"step": 6136, "time": 556.3768844604492, "episode/length": 148.0, "episode/score": 0.12703081286031193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12703081286031193}
{"step": 6152, "time": 558.611209154129, "episode/length": 174.0, "episode/score": 0.16921991380195323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16921991380195323}
{"step": 6400, "time": 569.8480045795441, "episode/length": 163.0, "episode/score": 0.12080897693454062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12080897693454062}
{"step": 6416, "time": 571.9764342308044, "episode/length": 42.0, "episode/score": 0.03582533409644384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03582533409644384}
{"step": 6456, "time": 574.740647315979, "episode/length": 148.0, "episode/score": 0.12209791459531516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12209791459531516}
{"step": 6728, "time": 586.7770102024078, "episode/length": 38.0, "episode/score": 0.03304904933179387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03304904933179387}
{"step": 6840, "time": 592.6668558120728, "episode/length": 145.0, "episode/score": 0.13051649482144967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13051649482144967}
{"step": 7096, "time": 604.4835283756256, "episode/length": 241.0, "episode/score": 0.25892496631695394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25892496631695394}
{"step": 7128, "time": 607.2833323478699, "episode/length": 123.0, "episode/score": 0.14516666397685185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14516666397685185}
{"step": 7368, "time": 617.921379327774, "episode/length": 162.0, "episode/score": 0.13123899688525853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13123899688525853}
{"step": 7792, "time": 635.8890137672424, "episode/length": 118.0, "episode/score": 0.1412976163555868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1412976163555868}
{"step": 7832, "time": 638.8817930221558, "episode/length": 178.0, "episode/score": 0.14091221294097522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14091221294097522}
{"step": 7928, "time": 644.0136065483093, "episode/length": 183.0, "episode/score": 0.19079810104517492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19079810104517492}
{"step": 8280, "time": 659.9330849647522, "episode/length": 265.0, "episode/score": 0.25463587515992003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25463587515992003}
{"step": 8336, "time": 663.8397986888885, "episode/length": 200.0, "episode/score": 0.19892342962134535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19892342962134535}
{"step": 8368, "time": 666.5641007423401, "episode/length": 158.0, "episode/score": 0.1781363300033263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1781363300033263}
{"step": 8944, "time": 690.0954151153564, "episode/length": 226.0, "episode/score": 0.22579415352083743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22579415352083743}
{"step": 8952, "time": 691.6873271465302, "episode/length": 144.0, "episode/score": 0.1556243201594043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1556243201594043}
{"step": 9088, "time": 698.6727812290192, "episode/length": 156.0, "episode/score": 0.131353538015901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.131353538015901}
{"step": 9128, "time": 701.5068068504333, "episode/length": 149.0, "episode/score": 0.11952058994938852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11952058994938852}
{"step": 9192, "time": 705.647332906723, "episode/length": 227.0, "episode/score": 0.26510633391080773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26510633391080773}
{"step": 9208, "time": 708.1976578235626, "episode/length": 108.0, "episode/score": 0.11482459753642615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11482459753642615}
{"step": 9616, "time": 725.8703236579895, "episode/length": 166.0, "episode/score": 0.16534866595247877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16534866595247877}
{"step": 9928, "time": 739.2551786899567, "episode/length": 99.0, "episode/score": 0.1087843450195578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1087843450195578}
{"step": 10056, "time": 746.1698949337006, "episode/length": 138.0, "episode/score": 0.11795836939563742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11795836939563742}
{"step": 10088, "time": 765.1910998821259, "eval_episode/length": 79.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9875}
{"step": 10088, "time": 767.5040140151978, "eval_episode/length": 98.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9595959595959596}
{"step": 10088, "time": 771.0025417804718, "eval_episode/length": 143.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 10088, "time": 772.5833175182343, "eval_episode/length": 145.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9657534246575342}
{"step": 10088, "time": 774.193451166153, "eval_episode/length": 148.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 10088, "time": 777.3792908191681, "eval_episode/length": 184.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 10088, "time": 780.1284422874451, "eval_episode/length": 211.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 10088, "time": 782.0113697052002, "eval_episode/length": 218.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 10144, "time": 784.3268892765045, "episode/length": 148.0, "episode/score": 0.13697772262821672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13697772262821672}
{"step": 10344, "time": 793.3006863594055, "episode/length": 156.0, "episode/score": 0.16314174780472968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16314174780472968}
{"step": 10464, "time": 799.5207874774933, "episode/length": 156.0, "episode/score": 0.1661372350581587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1661372350581587}
{"step": 10480, "time": 801.5652711391449, "episode/length": 263.0, "episode/score": 0.2647727342773578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2647727342773578}
{"step": 10808, "time": 815.275945186615, "episode/length": 148.0, "episode/score": 0.11855790263325616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11855790263325616}
{"step": 11352, "time": 837.8536295890808, "episode/length": 269.0, "episode/score": 0.266479600936691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.266479600936691}
{"step": 11400, "time": 841.1932170391083, "episode/length": 167.0, "episode/score": 0.19356864836390741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19356864836390741}
{"step": 11576, "time": 849.3877758979797, "episode/length": 138.0, "episode/score": 0.16481547299190424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16481547299190424}
{"step": 11616, "time": 852.6814472675323, "episode/length": 158.0, "episode/score": 0.17433537872875604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17433537872875604}
{"step": 11720, "time": 858.6341218948364, "episode/length": 223.0, "episode/score": 0.22387738815632474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22387738815632474}
{"step": 11728, "time": 861.1038656234741, "episode/length": 155.0, "episode/score": 0.1764734003427293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1764734003427293}
{"step": 11736, "time": 862.9179246425629, "episode/length": 198.0, "episode/score": 0.17206894569335418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17206894569335418}
{"step": 12376, "time": 888.7214522361755, "episode/length": 195.0, "episode/score": 0.17734382462822396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17734382462822396}
{"step": 12696, "time": 902.3536098003387, "episode/length": 167.0, "episode/score": 0.16880844207798873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16880844207798873}
{"step": 12736, "time": 905.5187201499939, "episode/length": 166.0, "episode/score": 0.14550696866535873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14550696866535873}
{"step": 12776, "time": 908.48162150383, "episode/length": 149.0, "episode/score": 0.1624013118421317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1624013118421317}
{"step": 12952, "time": 916.6464722156525, "episode/length": 151.0, "episode/score": 0.1278910356081724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1278910356081724}
{"step": 13040, "time": 921.7611932754517, "episode/length": 164.0, "episode/score": 0.12555964847842915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12555964847842915}
{"step": 13088, "time": 925.1051983833313, "episode/length": 183.0, "episode/score": 0.18956433490211566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18956433490211566}
{"step": 13560, "time": 944.2703223228455, "episode/length": 228.0, "episode/score": 0.2556543585710642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2556543585710642}
{"step": 13720, "time": 951.8863983154297, "episode/length": 167.0, "episode/score": 0.16466381234886285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16466381234886285}
{"step": 13928, "time": 961.395477771759, "episode/length": 153.0, "episode/score": 0.13896077871459056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13896077871459056}
{"step": 13992, "time": 965.2652659416199, "episode/length": 151.0, "episode/score": 0.11599673082992012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11599673082992012}
{"step": 14184, "time": 974.1071314811707, "episode/length": 142.0, "episode/score": 0.09878763037067984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09878763037067984}
{"step": 14208, "time": 976.7322542667389, "episode/length": 156.0, "episode/score": 0.15981574512397856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15981574512397856}
{"step": 14528, "time": 990.3191788196564, "episode/length": 223.0, "episode/score": 0.22388017405091887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22388017405091887}
{"step": 15048, "time": 1011.2485930919647, "episode/length": 165.0, "episode/score": 0.16471201366402966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16471201366402966}
{"step": 15256, "time": 1020.751091003418, "episode/length": 211.0, "episode/score": 0.22371864047909185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22371864047909185}
{"step": 15280, "time": 1023.3769810199738, "episode/length": 273.0, "episode/score": 0.3277474263190925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3277474263190925}
{"step": 15376, "time": 1028.6647653579712, "episode/length": 180.0, "episode/score": 0.17642759610043868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17642759610043868}
{"step": 15552, "time": 1036.7742974758148, "episode/length": 194.0, "episode/score": 0.16538282398232695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16538282398232695}
{"step": 15592, "time": 1039.6745932102203, "episode/length": 172.0, "episode/score": 0.17969067023204843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17969067023204843}
{"step": 15704, "time": 1045.4275481700897, "episode/length": 189.0, "episode/score": 0.16143380765970505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16143380765970505}
{"step": 15960, "time": 1056.6876413822174, "episode/length": 178.0, "episode/score": 0.16773346658010269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16773346658010269}
{"step": 16272, "time": 1070.567091703415, "episode/length": 152.0, "episode/score": 0.12592567197225435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12592567197225435}
{"step": 16472, "time": 1081.0730357170105, "episode/length": 151.0, "episode/score": 0.12038494643775266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12038494643775266}
{"step": 16760, "time": 1093.6309297084808, "episode/length": 184.0, "episode/score": 0.1401142650638576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1401142650638576}
{"step": 16816, "time": 1097.4319877624512, "episode/length": 179.0, "episode/score": 0.1508842471812386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1508842471812386}
{"step": 16976, "time": 1105.0056102275848, "episode/length": 172.0, "episode/score": 0.1701905124282348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1701905124282348}
{"step": 17024, "time": 1108.365888595581, "episode/length": 164.0, "episode/score": 0.16972830300437636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16972830300437636}
{"step": 17312, "time": 1120.8243753910065, "episode/length": 168.0, "episode/score": 0.14491680066930712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14491680066930712}
{"step": 17400, "time": 1125.4531733989716, "episode/length": 230.0, "episode/score": 0.24246185147057986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24246185147057986}
{"step": 17672, "time": 1137.2246222496033, "episode/length": 174.0, "episode/score": 0.19351685364927107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19351685364927107}
{"step": 17680, "time": 1139.376718044281, "episode/length": 150.0, "episode/score": 0.11578641153209901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11578641153209901}
{"step": 17904, "time": 1149.715179681778, "episode/length": 135.0, "episode/score": 0.10589706379050767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10589706379050767}
{"step": 18104, "time": 1158.9627089500427, "episode/length": 87.0, "episode/score": 0.09768898627771705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09768898627771705}
{"step": 18336, "time": 1169.3635249137878, "episode/length": 163.0, "episode/score": 0.10348160843295773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10348160843295773}
{"step": 18616, "time": 1181.4593615531921, "episode/length": 231.0, "episode/score": 0.2611142914975062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2611142914975062}
{"step": 18656, "time": 1184.6585593223572, "episode/length": 167.0, "episode/score": 0.1857514652720056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1857514652720056}
{"step": 18696, "time": 1187.456779241562, "episode/length": 214.0, "episode/score": 0.18734424940066674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18734424940066674}
{"step": 19448, "time": 1217.7197096347809, "episode/length": 221.0, "episode/score": 0.23443241076711274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23443241076711274}
{"step": 19448, "time": 1217.7284834384918, "episode/length": 220.0, "episode/score": 0.21308614072313503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21308614072313503}
{"step": 19544, "time": 1224.557609796524, "episode/length": 204.0, "episode/score": 0.17063426863023778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17063426863023778}
{"step": 19920, "time": 1240.665445804596, "episode/length": 152.0, "episode/score": 0.14579036832219572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14579036832219572}
{"step": 20024, "time": 1245.998372554779, "episode/length": 210.0, "episode/score": 0.20648652828958802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20648652828958802}
{"step": 20072, "time": 1264.9299137592316, "eval_episode/length": 58.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 20072, "time": 1271.3820719718933, "eval_episode/length": 168.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 20072, "time": 1272.8905279636383, "eval_episode/length": 169.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 20072, "time": 1275.4254229068756, "eval_episode/length": 188.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 20072, "time": 1277.5703234672546, "eval_episode/length": 201.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 20072, "time": 1279.4697732925415, "eval_episode/length": 208.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 20072, "time": 1281.7644028663635, "eval_episode/length": 166.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 20072, "time": 1281.7723972797394, "eval_episode/length": 225.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 20240, "time": 1288.3893043994904, "episode/length": 266.0, "episode/score": 0.2789099973060729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2789099973060729}
{"step": 20248, "time": 1290.0767014026642, "episode/length": 198.0, "episode/score": 0.21358000889449613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21358000889449613}
{"step": 20592, "time": 1305.081133365631, "episode/length": 246.0, "episode/score": 0.23506098824054789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23506098824054789}
{"step": 20593, "time": 1307.387130022049, "train_stats/sum_log_reward": 1.402752257610133, "train_stats/max_log_achievement_collect_drink": 0.14678899082568808, "train_stats/max_log_achievement_collect_sapling": 0.6972477064220184, "train_stats/max_log_achievement_collect_wood": 0.3394495412844037, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_place_plant": 0.6055045871559633, "train_stats/max_log_achievement_wake_up": 1.7431192660550459, "train_stats/mean_log_entropy": 2.7450373194633273, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 8.047224798122373, "train/action_min": 0.0, "train/action_std": 4.9274965093917205, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002828059437246445, "train/actor_opt_grad_steps": 600.0, "train/actor_opt_loss": 114.24174382205771, "train/adv_mag": 0.0409565247835478, "train/adv_max": 0.008721130402874155, "train/adv_mean": 0.0044507701660383165, "train/adv_min": -0.03651541687387723, "train/adv_std": 0.0035763791086790035, "train/cont_avg": 0.9945427389705882, "train/cont_loss_mean": 0.03087013159651591, "train/cont_loss_std": 0.22109060721988438, "train/cont_neg_acc": 0.11364212625918269, "train/cont_neg_loss": 2.722325936585915, "train/cont_pos_acc": 0.9917202689880583, "train/cont_pos_loss": 0.01607252283563775, "train/cont_pred": 0.9884515522407884, "train/cont_rate": 0.9945427389705882, "train/dyn_loss_mean": 6.149312381984807, "train/dyn_loss_std": 8.294278028381973, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.851274199470752, "train/extr_critic_critic_opt_grad_steps": 600.0, "train/extr_critic_critic_opt_loss": 18867.990398503152, "train/extr_critic_mag": 0.052340457419387434, "train/extr_critic_max": 0.052340455415869964, "train/extr_critic_mean": 0.05218096676839225, "train/extr_critic_min": 0.0519796048893648, "train/extr_critic_std": 5.2337942646817615e-05, "train/extr_return_normed_mag": 0.04054503834673336, "train/extr_return_normed_max": 0.015925834096279463, "train/extr_return_normed_mean": 0.011704125047608536, "train/extr_return_normed_min": -0.02923909258261272, "train/extr_return_normed_std": 0.0035780678258523022, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.06085344761225567, "train/extr_return_raw_max": 0.06085344761225567, "train/extr_return_raw_mean": 0.05663174108583519, "train/extr_return_raw_min": 0.015688520945225132, "train/extr_return_raw_std": 0.0035780678336174002, "train/extr_reward_mag": 0.0009913394431106182, "train/extr_reward_max": 0.0009913394431106182, "train/extr_reward_mean": 0.0008846951739144992, "train/extr_reward_min": 0.0007382120404924665, "train/extr_reward_std": 5.292800162455594e-05, "train/image_loss_mean": 96.61536146212025, "train/image_loss_std": 51.81872670790728, "train/model_loss_mean": 100.54091094521915, "train/model_loss_std": 53.47573062351772, "train/model_opt_grad_norm": 383.5941966080866, "train/model_opt_grad_steps": 591.0, "train/model_opt_loss": 2074.6487093372507, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 22.649684873949578, "train/policy_entropy_mag": 2.82440077757635, "train/policy_entropy_max": 2.82440077757635, "train/policy_entropy_mean": 2.764925836515026, "train/policy_entropy_min": 2.494896855674872, "train/policy_entropy_std": 0.03181058764770752, "train/policy_logprob_mag": 5.008782176410451, "train/policy_logprob_max": -1.3746167030655037, "train/policy_logprob_mean": -2.7648220382818653, "train/policy_logprob_min": -5.008782176410451, "train/policy_logprob_std": 0.3525462767907551, "train/policy_randomness_mag": 0.9968895296088788, "train/policy_randomness_max": 0.9968895296088788, "train/policy_randomness_mean": 0.9758974839659298, "train/policy_randomness_min": 0.8805891060027755, "train/policy_randomness_std": 0.01122774139531896, "train/post_ent_mag": 52.33416648672409, "train/post_ent_max": 52.33416648672409, "train/post_ent_mean": 32.65387939004337, "train/post_ent_min": 15.634684594739385, "train/post_ent_std": 7.5457779309328865, "train/prior_ent_mag": 60.28325095296908, "train/prior_ent_max": 60.28325095296908, "train/prior_ent_mean": 39.56569307792086, "train/prior_ent_min": 20.715890131076844, "train/prior_ent_std": 7.719463265994015, "train/rep_loss_mean": 6.149312381984807, "train/rep_loss_std": 8.294278028381973, "train/reward_avg": 0.0009087322856017834, "train/reward_loss_mean": 0.20509206234407024, "train/reward_loss_std": 0.013959919756224135, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.000984701789727732, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.20509205595785832, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0008763551160286204, "train/reward_rate": 0.0, "train_stats/max_log_achievement_place_table": 0.05952380952380952, "eval_stats/sum_log_reward": 0.9749999693594873, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.6875, "eval_stats/max_log_achievement_collect_wood": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.014582084491848946, "report/cont_loss_std": 0.25426194071769714, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.255920886993408, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.001371837453916669, "report/cont_pred": 0.9967584609985352, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 7.410984992980957, "report/dyn_loss_std": 6.841163635253906, "report/image_loss_mean": 29.310367584228516, "report/image_loss_std": 22.253917694091797, "report/model_loss_mean": 33.809104919433594, "report/model_loss_std": 24.269336700439453, "report/post_ent_mag": 44.13298416137695, "report/post_ent_max": 44.13298416137695, "report/post_ent_mean": 29.02176284790039, "report/post_ent_min": 12.344621658325195, "report/post_ent_std": 5.639249324798584, "report/prior_ent_mag": 54.8265266418457, "report/prior_ent_max": 54.8265266418457, "report/prior_ent_mean": 38.10018539428711, "report/prior_ent_min": 15.735090255737305, "report/prior_ent_std": 8.019064903259277, "report/rep_loss_mean": 7.410984992980957, "report/rep_loss_std": 6.841163635253906, "report/reward_avg": 0.0009436990949325264, "report/reward_loss_mean": 0.03756115585565567, "report/reward_loss_std": 0.014222566969692707, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012584924697875977, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03756115958094597, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0008936685044318438, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.013263583183288574, "eval/cont_loss_std": 0.33772891759872437, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.796895027160645, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002722400240600109, "eval/cont_pred": 0.9974604845046997, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 9.1043701171875, "eval/dyn_loss_std": 7.124037742614746, "eval/image_loss_mean": 63.76532745361328, "eval/image_loss_std": 58.4935302734375, "eval/model_loss_mean": 69.57759094238281, "eval/model_loss_std": 60.490596771240234, "eval/post_ent_mag": 48.46906280517578, "eval/post_ent_max": 48.46906280517578, "eval/post_ent_mean": 32.127262115478516, "eval/post_ent_min": 12.763765335083008, "eval/post_ent_std": 7.115140438079834, "eval/prior_ent_mag": 55.605934143066406, "eval/prior_ent_max": 55.605934143066406, "eval/prior_ent_mean": 39.082794189453125, "eval/prior_ent_min": 17.120018005371094, "eval/prior_ent_std": 7.706055641174316, "eval/rep_loss_mean": 9.1043701171875, "eval/rep_loss_std": 7.124037742614746, "eval/reward_avg": 0.02011718600988388, "eval/reward_loss_mean": 0.3363807201385498, "eval/reward_loss_std": 1.9856822490692139, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012744665145874023, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.07181225717067719, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 12.386271476745605, "eval/reward_pred": 0.0009166932431980968, "eval/reward_rate": 0.021484375, "replay/size": 20089.0, "replay/inserts": 19032.0, "replay/samples": 19024.0, "replay/insert_wait_avg": 1.3953600174341445e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.430342105579938e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6608.0, "eval_replay/inserts": 3560.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2675697883863127e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 968.8411455154419, "timer/env.step_count": 2379.0, "timer/env.step_total": 236.0075135231018, "timer/env.step_frac": 0.24359774005834706, "timer/env.step_avg": 0.09920450337246818, "timer/env.step_min": 0.02265310287475586, "timer/env.step_max": 3.222472667694092, "timer/replay._sample_count": 19024.0, "timer/replay._sample_total": 9.88556981086731, "timer/replay._sample_frac": 0.010203499156312152, "timer/replay._sample_avg": 0.0005196367646587106, "timer/replay._sample_min": 0.0003514289855957031, "timer/replay._sample_max": 0.011573553085327148, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2824.0, "timer/agent.policy_total": 47.13667607307434, "timer/agent.policy_frac": 0.04865263649387716, "timer/agent.policy_avg": 0.016691457532958337, "timer/agent.policy_min": 0.010231256484985352, "timer/agent.policy_max": 0.09590435028076172, "timer/dataset_train_count": 1189.0, "timer/dataset_train_total": 0.1361231803894043, "timer/dataset_train_frac": 0.00014050103158757174, "timer/dataset_train_avg": 0.0001144854334645957, "timer/dataset_train_min": 8.440017700195312e-05, "timer/dataset_train_max": 0.0003402233123779297, "timer/agent.train_count": 1189.0, "timer/agent.train_total": 537.7851419448853, "timer/agent.train_frac": 0.5550808245853074, "timer/agent.train_avg": 0.4523003716946049, "timer/agent.train_min": 0.4384143352508545, "timer/agent.train_max": 0.7262322902679443, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4882054328918457, "timer/agent.report_frac": 0.0005039065848427722, "timer/agent.report_avg": 0.24410271644592285, "timer/agent.report_min": 0.24048805236816406, "timer/agent.report_max": 0.24771738052368164, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.790855407714844e-05, "timer/dataset_eval_frac": 3.912772930074142e-08, "timer/dataset_eval_avg": 3.790855407714844e-05, "timer/dataset_eval_min": 3.790855407714844e-05, "timer/dataset_eval_max": 3.790855407714844e-05, "fps": 19.643859512858175}
{"step": 20912, "time": 1319.8724925518036, "episode/length": 170.0, "episode/score": 0.12685480141772132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12685480141772132}
{"step": 20944, "time": 1322.581200838089, "episode/length": 127.0, "episode/score": 0.13561007351017906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13561007351017906}
{"step": 20984, "time": 1325.387689113617, "episode/length": 191.0, "episode/score": 0.16779102909276844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16779102909276844}
{"step": 21424, "time": 1344.1639456748962, "episode/length": 174.0, "episode/score": 0.15855492931405024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15855492931405024}
{"step": 21456, "time": 1346.927128791809, "episode/length": 250.0, "episode/score": 0.23598049498832552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23598049498832552}
{"step": 21528, "time": 1351.0518896579742, "episode/length": 160.0, "episode/score": 0.12752508015546482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12752508015546482}
{"step": 21632, "time": 1356.8244795799255, "episode/length": 172.0, "episode/score": 0.1518433319806718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1518433319806718}
{"step": 22144, "time": 1377.8561959266663, "episode/length": 149.0, "episode/score": 0.14395477799098444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14395477799098444}
{"step": 22328, "time": 1386.072271347046, "episode/length": 167.0, "episode/score": 0.15144338166464877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15144338166464877}
{"step": 22472, "time": 1393.3019473552704, "episode/length": 234.0, "episode/score": 0.2367990552156698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2367990552156698}
{"step": 22512, "time": 1396.438931465149, "episode/length": 122.0, "episode/score": 0.12502909871818702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12502909871818702}
{"step": 22728, "time": 1405.996844291687, "episode/length": 162.0, "episode/score": 0.14906494043498242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14906494043498242}
{"step": 22864, "time": 1412.87069773674, "episode/length": 243.0, "episode/score": 0.24704116571865598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24704116571865598}
{"step": 23064, "time": 1421.8154919147491, "episode/length": 178.0, "episode/score": 0.14754631505365978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14754631505365978}
{"step": 23296, "time": 1432.3283116817474, "episode/length": 229.0, "episode/score": 0.21931261872850882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21931261872850882}
{"step": 23616, "time": 1445.9542315006256, "episode/length": 183.0, "episode/score": 0.15647613032342633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15647613032342633}
{"step": 23808, "time": 1455.054151058197, "episode/length": 166.0, "episode/score": 0.1712839559331769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1712839559331769}
{"step": 23848, "time": 1458.2804968357086, "episode/length": 166.0, "episode/score": 0.16368503839476034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16368503839476034}
{"step": 23944, "time": 1463.487773180008, "episode/length": 201.0, "episode/score": 0.20380363798904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20380363798904}
{"step": 24072, "time": 1469.8942592144012, "episode/length": 167.0, "episode/score": 0.16947331868868787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16947331868868787}
{"step": 24384, "time": 1483.6354749202728, "episode/length": 189.0, "episode/score": 0.18706840488448506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18706840488448506}
{"step": 24416, "time": 1486.361438035965, "episode/length": 168.0, "episode/score": 0.20259337919924292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20259337919924292}
{"step": 24536, "time": 1492.280293226242, "episode/length": 154.0, "episode/score": 0.1524450525703287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1524450525703287}
{"step": 24952, "time": 1511.277620792389, "episode/length": 166.0, "episode/score": 0.16618219265183143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16618219265183143}
{"step": 25152, "time": 1521.0855884552002, "episode/length": 150.0, "episode/score": 0.13116314638864424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13116314638864424}
{"step": 25232, "time": 1525.768354177475, "episode/length": 172.0, "episode/score": 0.19766491524569574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19766491524569574}
{"step": 25632, "time": 1542.7165036201477, "episode/length": 155.0, "episode/score": 0.1531172308641544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1531172308641544}
{"step": 25800, "time": 1550.4155297279358, "episode/length": 215.0, "episode/score": 0.23431141883520468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23431141883520468}
{"step": 25904, "time": 1556.1053357124329, "episode/length": 261.0, "episode/score": 0.25896338161510357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25896338161510357}
{"step": 26048, "time": 1563.1955420970917, "episode/length": 188.0, "episode/score": 0.22220708464283234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22220708464283234}
{"step": 26096, "time": 1566.552443265915, "episode/length": 142.0, "episode/score": 0.16624759780916065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16624759780916065}
{"step": 26424, "time": 1580.597974061966, "episode/length": 158.0, "episode/score": 0.17978358536402084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17978358536402084}
{"step": 26696, "time": 1592.564469575882, "episode/length": 182.0, "episode/score": 0.18406415597382875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18406415597382875}
{"step": 26792, "time": 1597.8710317611694, "episode/length": 296.0, "episode/score": 0.34666486624519166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34666486624519166}
{"step": 26920, "time": 1604.222162246704, "episode/length": 160.0, "episode/score": 0.18209622418453364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18209622418453364}
{"step": 27144, "time": 1614.288340806961, "episode/length": 154.0, "episode/score": 0.1604557784676217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1604557784676217}
{"step": 27216, "time": 1618.8179504871368, "episode/length": 145.0, "episode/score": 0.14911542510617437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14911542510617437}
{"step": 27224, "time": 1620.4826867580414, "episode/length": 177.0, "episode/score": 0.19031642193658627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19031642193658627}
{"step": 27392, "time": 1628.7009942531586, "episode/length": 161.0, "episode/score": 0.1834406157340709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1834406157340709}
{"step": 27456, "time": 1633.1537024974823, "episode/length": 128.0, "episode/score": 0.14064109949958947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14064109949958947}
{"step": 27752, "time": 1646.3532338142395, "episode/length": 66.0, "episode/score": 0.07656899392441119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07656899392441119}
{"step": 28072, "time": 1660.0602054595947, "episode/length": 171.0, "episode/score": 0.15791560237084923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15791560237084923}
{"step": 28088, "time": 1662.1699125766754, "episode/length": 145.0, "episode/score": 0.17253509031706926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17253509031706926}
{"step": 28136, "time": 1665.4636511802673, "episode/length": 167.0, "episode/score": 0.16973264567059232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16973264567059232}
{"step": 28456, "time": 1679.1339738368988, "episode/length": 153.0, "episode/score": 0.18364393581578042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18364393581578042}
{"step": 28648, "time": 1688.0735547542572, "episode/length": 156.0, "episode/score": 0.16886180707842868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16886180707842868}
{"step": 28832, "time": 1696.9025580883026, "episode/length": 210.0, "episode/score": 0.21317469718087523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21317469718087523}
{"step": 28952, "time": 1702.7678525447845, "episode/length": 109.0, "episode/score": 0.12463535679671622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12463535679671622}
{"step": 28984, "time": 1705.456579208374, "episode/length": 153.0, "episode/score": 0.17422373910630995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17422373910630995}
{"step": 28984, "time": 1705.4641478061676, "episode/length": 190.0, "episode/score": 0.18644196932564228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18644196932564228}
{"step": 29344, "time": 1722.7146537303925, "episode/length": 150.0, "episode/score": 0.15506742821662556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15506742821662556}
{"step": 29400, "time": 1726.1154680252075, "episode/length": 163.0, "episode/score": 0.19551605270635264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19551605270635264}
{"step": 30056, "time": 1773.2871923446655, "eval_episode/length": 157.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 30056, "time": 1775.2595143318176, "eval_episode/length": 168.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 30056, "time": 1777.0933585166931, "eval_episode/length": 173.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 30056, "time": 1779.559603214264, "eval_episode/length": 193.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 30056, "time": 1781.2644016742706, "eval_episode/length": 199.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.96}
{"step": 30056, "time": 1782.872670173645, "eval_episode/length": 200.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9800995024875622}
{"step": 30056, "time": 1784.8799726963043, "eval_episode/length": 210.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 30056, "time": 1786.5865199565887, "eval_episode/length": 214.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9813953488372092}
{"step": 30128, "time": 1789.5456490516663, "episode/length": 184.0, "episode/score": 0.20007333420153373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20007333420153373}
{"step": 30376, "time": 1800.294258594513, "episode/length": 173.0, "episode/score": 0.1871699184971476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1871699184971476}
{"step": 30416, "time": 1803.5209090709686, "episode/length": 182.0, "episode/score": 0.19236156170836693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19236156170836693}
{"step": 30568, "time": 1810.7460384368896, "episode/length": 197.0, "episode/score": 0.22044831637322204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22044831637322204}
{"step": 30672, "time": 1816.481100320816, "episode/length": 276.0, "episode/score": 0.3003729921720151, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3003729921720151}
{"step": 30736, "time": 1820.3883998394012, "episode/length": 173.0, "episode/score": 0.18624311271969418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18624311271969418}
{"step": 30736, "time": 1820.39741897583, "episode/length": 237.0, "episode/score": 0.25526949169989166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25526949169989166}
{"step": 30864, "time": 1828.1929001808167, "episode/length": 182.0, "episode/score": 0.20464705853555643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20464705853555643}
{"step": 31568, "time": 1856.4858503341675, "episode/length": 179.0, "episode/score": 0.1953704250699957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1953704250699957}
{"step": 31576, "time": 1858.1679294109344, "episode/length": 112.0, "episode/score": 0.11053558982166578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11053558982166578}
{"step": 31696, "time": 1864.4492180347443, "episode/length": 164.0, "episode/score": 0.16972378623177065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16972378623177065}
{"step": 31840, "time": 1871.690890789032, "episode/length": 177.0, "episode/score": 0.2084702340507647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2084702340507647}
{"step": 31872, "time": 1874.3891487121582, "episode/length": 162.0, "episode/score": 0.18801079122931696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18801079122931696}
{"step": 31984, "time": 1880.18683719635, "episode/length": 155.0, "episode/score": 0.15768135439429898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15768135439429898}
{"step": 32160, "time": 1888.339094877243, "episode/length": 161.0, "episode/score": 0.1534628847730346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1534628847730346}
{"step": 32200, "time": 1891.1242184638977, "episode/length": 182.0, "episode/score": 0.19649201309948694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19649201309948694}
{"step": 33096, "time": 1928.2086617946625, "episode/length": 190.0, "episode/score": 0.20332386131121893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20332386131121893}
{"step": 33160, "time": 1932.0948402881622, "episode/length": 182.0, "episode/score": 0.1888869729009457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1888869729009457}
{"step": 33192, "time": 1934.9722192287445, "episode/length": 168.0, "episode/score": 0.1654865261134546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1654865261134546}
{"step": 33312, "time": 1941.3096532821655, "episode/length": 179.0, "episode/score": 0.19076657753248583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19076657753248583}
{"step": 33408, "time": 1946.5354611873627, "episode/length": 155.0, "episode/score": 0.14929560144992138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14929560144992138}
{"step": 33496, "time": 1951.1212096214294, "episode/length": 188.0, "episode/score": 0.20609930185128178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20609930185128178}
{"step": 33568, "time": 1955.5843305587769, "episode/length": 248.0, "episode/score": 0.2964012823831581, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2964012823831581}
{"step": 34496, "time": 1992.3502292633057, "episode/length": 286.0, "episode/score": 0.28969089530437486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28969089530437486}
{"step": 34536, "time": 1995.1387128829956, "episode/length": 167.0, "episode/score": 0.1823423718306003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1823423718306003}
{"step": 34672, "time": 2002.0594191551208, "episode/length": 169.0, "episode/score": 0.17629579382992233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17629579382992233}
{"step": 34704, "time": 2005.4356772899628, "episode/length": 161.0, "episode/score": 0.15555293139823334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15555293139823334}
{"step": 34704, "time": 2005.4437878131866, "episode/length": 192.0, "episode/score": 0.21875361911588698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21875361911588698}
{"step": 34808, "time": 2013.0807754993439, "episode/length": 213.0, "episode/score": 0.24624568160834315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24624568160834315}
{"step": 35128, "time": 2026.7596793174744, "episode/length": 203.0, "episode/score": 0.20025848652130662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20025848652130662}
{"step": 35232, "time": 2032.4590084552765, "episode/length": 207.0, "episode/score": 0.20468315736707154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20468315736707154}
{"step": 35704, "time": 2051.5659215450287, "episode/length": 145.0, "episode/score": 0.15212926545063965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15212926545063965}
{"step": 35880, "time": 2059.6831772327423, "episode/length": 172.0, "episode/score": 0.18338752309136908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18338752309136908}
{"step": 36136, "time": 2070.847382545471, "episode/length": 178.0, "episode/score": 0.19440847122496052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19440847122496052}
{"step": 36152, "time": 2072.985389471054, "episode/length": 184.0, "episode/score": 0.20785487000193825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20785487000193825}
{"step": 36304, "time": 2080.587676048279, "episode/length": 186.0, "episode/score": 0.18508520394152583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18508520394152583}
{"step": 36376, "time": 2084.6628561019897, "episode/length": 208.0, "episode/score": 0.2017974600812522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2017974600812522}
{"step": 36400, "time": 2087.335121870041, "episode/length": 145.0, "episode/score": 0.1534298454225791, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1534298454225791}
{"step": 36752, "time": 2102.1377389431, "episode/length": 202.0, "episode/score": 0.23731371409030544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23731371409030544}
{"step": 36888, "time": 2108.6071343421936, "episode/length": 125.0, "episode/score": 0.1548193439048191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1548193439048191}
{"step": 36936, "time": 2111.88547706604, "episode/length": 78.0, "episode/score": 0.09142261726083234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09142261726083234}
{"step": 36944, "time": 2114.039978981018, "episode/length": 154.0, "episode/score": 0.1644147658480506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1644147658480506}
{"step": 37280, "time": 2128.1560139656067, "episode/length": 48.0, "episode/score": 0.05281553363965941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05281553363965941}
{"step": 37584, "time": 2141.19181227684, "episode/length": 178.0, "episode/score": 0.18766435945144622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18766435945144622}
{"step": 37624, "time": 2144.013172864914, "episode/length": 155.0, "episode/score": 0.15230099963446264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15230099963446264}
{"step": 37784, "time": 2151.520007610321, "episode/length": 205.0, "episode/score": 0.2164839131073677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2164839131073677}
{"step": 38008, "time": 2161.662266731262, "episode/length": 200.0, "episode/score": 0.20719690313126193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20719690313126193}
{"step": 38040, "time": 2164.3995394706726, "episode/length": 160.0, "episode/score": 0.16590710539821885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16590710539821885}
{"step": 38136, "time": 2169.6278569698334, "episode/length": 148.0, "episode/score": 0.16624195310760115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16624195310760115}
{"step": 38576, "time": 2187.8469462394714, "episode/length": 204.0, "episode/score": 0.22609194513279363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22609194513279363}
{"step": 38728, "time": 2194.975930929184, "episode/length": 180.0, "episode/score": 0.2037143753386772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2037143753386772}
{"step": 38904, "time": 2203.0964648723602, "episode/length": 164.0, "episode/score": 0.1936577706837852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1936577706837852}
{"step": 39144, "time": 2213.693377971649, "episode/length": 189.0, "episode/score": 0.19233782312949188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19233782312949188}
{"step": 39416, "time": 2225.5125679969788, "episode/length": 203.0, "episode/score": 0.23685705314710503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23685705314710503}
{"step": 39704, "time": 2238.1699800491333, "episode/length": 207.0, "episode/score": 0.22290747019724222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22290747019724222}
{"step": 39744, "time": 2241.3458275794983, "episode/length": 200.0, "episode/score": 0.1954374792130693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1954374792130693}
{"step": 40040, "time": 2268.4225766658783, "eval_episode/length": 47.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8958333333333334}
{"step": 40040, "time": 2274.2362287044525, "eval_episode/length": 146.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 40040, "time": 2275.95774102211, "eval_episode/length": 150.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 40040, "time": 2277.9821515083313, "eval_episode/length": 160.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.968944099378882}
{"step": 40040, "time": 2279.580152273178, "eval_episode/length": 164.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9636363636363636}
{"step": 40040, "time": 2281.475630044937, "eval_episode/length": 171.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 40040, "time": 2286.7515530586243, "eval_episode/length": 210.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.981042654028436}
{"step": 40040, "time": 2289.765690088272, "eval_episode/length": 139.0, "eval_episode/score": 0.10000002384185791, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 40064, "time": 2290.9061238765717, "episode/length": 185.0, "episode/score": 0.18989158379008586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18989158379008586}
{"step": 40272, "time": 2300.2890639305115, "episode/length": 140.0, "episode/score": 0.1559434498194605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1559434498194605}
{"step": 40409, "time": 2307.6273517608643, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.293297744378811, "train/action_min": 0.0, "train/action_std": 4.803464560004754, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004040726871282711, "train/actor_opt_grad_steps": 1810.0, "train/actor_opt_loss": 73.69517661546304, "train/adv_mag": 0.13691794569414806, "train/adv_max": 0.017407682792442602, "train/adv_mean": 0.0030414955600588846, "train/adv_min": -0.13667780524346887, "train/adv_std": 0.009558766107339927, "train/cont_avg": 0.9942438389227642, "train/cont_loss_mean": 0.005001397240204558, "train/cont_loss_std": 0.07198669866485899, "train/cont_neg_acc": 0.7702574607560305, "train/cont_neg_loss": 0.582210111781615, "train/cont_pos_acc": 0.9996166166251268, "train/cont_pos_loss": 0.0016377975934955156, "train/cont_pred": 0.9943408680155994, "train/cont_rate": 0.9942438389227642, "train/dyn_loss_mean": 9.46477389917141, "train/dyn_loss_std": 6.803752492113811, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.18529714855963622, "train/extr_critic_critic_opt_grad_steps": 1810.0, "train/extr_critic_critic_opt_loss": 6935.22117254986, "train/extr_critic_mag": 0.14653574160444058, "train/extr_critic_max": 0.14653574160444058, "train/extr_critic_mean": 0.14507183159996823, "train/extr_critic_min": 0.12678142679416068, "train/extr_critic_std": 0.0026561193339946884, "train/extr_return_normed_mag": 0.13156393697349036, "train/extr_return_normed_max": 0.019833227786106793, "train/extr_return_normed_mean": 0.012555281215203487, "train/extr_return_normed_min": -0.13139623433836106, "train/extr_return_normed_std": 0.010890281681592265, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.15539125819516375, "train/extr_return_raw_max": 0.15539125819516375, "train/extr_return_raw_mean": 0.14811331857510698, "train/extr_return_raw_min": 0.0041617960706958924, "train/extr_return_raw_std": 0.010890281783810598, "train/extr_reward_mag": 0.0015709167573510147, "train/extr_reward_max": 0.0015709167573510147, "train/extr_reward_mean": 0.001072774634117306, "train/extr_reward_min": 0.00013639481087041096, "train/extr_reward_std": 0.00021054685563965875, "train/image_loss_mean": 29.98924025868982, "train/image_loss_std": 25.089583614008212, "train/model_loss_mean": 35.71094557909461, "train/model_loss_std": 27.27397431784529, "train/model_opt_grad_norm": 146.2766394886544, "train/model_opt_grad_steps": 1801.0, "train/model_opt_loss": 1841.1106354007877, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 52.083333333333336, "train/policy_entropy_mag": 2.801136208743584, "train/policy_entropy_max": 2.801136208743584, "train/policy_entropy_mean": 2.517350852004881, "train/policy_entropy_min": 1.2292673379425112, "train/policy_entropy_std": 0.19346716082314167, "train/policy_logprob_mag": 6.8449539673037645, "train/policy_logprob_max": -0.38572524212361353, "train/policy_logprob_mean": -2.517076441912147, "train/policy_logprob_min": -6.8449539673037645, "train/policy_logprob_std": 0.7786028552346114, "train/policy_randomness_mag": 0.9886781573295593, "train/policy_randomness_max": 0.9886781573295593, "train/policy_randomness_mean": 0.8885143869291476, "train/policy_randomness_min": 0.43387742607089563, "train/policy_randomness_std": 0.06828541793232042, "train/post_ent_mag": 47.598096087696106, "train/post_ent_max": 47.598096087696106, "train/post_ent_mean": 32.5183333885379, "train/post_ent_min": 14.11613797753807, "train/post_ent_std": 5.819079135491596, "train/prior_ent_mag": 60.025733482546926, "train/prior_ent_max": 60.025733482546926, "train/prior_ent_mean": 42.43451085904749, "train/prior_ent_min": 17.37616372302296, "train/prior_ent_std": 7.949472582437159, "train/rep_loss_mean": 9.46477389917141, "train/rep_loss_std": 6.803752492113811, "train/reward_avg": 0.0009734305956332785, "train/reward_loss_mean": 0.037839654136479384, "train/reward_loss_std": 0.013801595445994923, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001426571752966904, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03783965410619247, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0009673978126327681, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.3272726927968588, "train_stats/max_log_achievement_collect_drink": 0.35454545454545455, "train_stats/max_log_achievement_collect_sapling": 0.7181818181818181, "train_stats/max_log_achievement_collect_wood": 0.7909090909090909, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_place_plant": 0.509090909090909, "train_stats/max_log_achievement_place_table": 0.14545454545454545, "train_stats/max_log_achievement_wake_up": 0.4727272727272727, "train_stats/mean_log_entropy": 2.521025562286377, "eval_stats/sum_log_reward": 0.41249997075647116, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_wood": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.018518518518518517, "train_stats/max_log_achievement_defeat_skeleton": 0.02702702702702703, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.5, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00044069188879802823, "report/cont_loss_std": 0.005996492691338062, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.02984556369483471, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0002964089217130095, "report/cont_pred": 0.9949653148651123, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 10.478704452514648, "report/dyn_loss_std": 6.680737018585205, "report/image_loss_mean": 25.837913513183594, "report/image_loss_std": 22.328102111816406, "report/model_loss_mean": 32.1633415222168, "report/model_loss_std": 24.526243209838867, "report/post_ent_mag": 49.21120834350586, "report/post_ent_max": 49.21120834350586, "report/post_ent_mean": 34.314308166503906, "report/post_ent_min": 14.619370460510254, "report/post_ent_std": 5.468990802764893, "report/prior_ent_mag": 60.47540283203125, "report/prior_ent_max": 60.47540283203125, "report/prior_ent_mean": 44.72401428222656, "report/prior_ent_min": 17.628498077392578, "report/prior_ent_std": 7.910306453704834, "report/rep_loss_mean": 10.478704452514648, "report/rep_loss_std": 6.680737018585205, "report/reward_avg": 0.000981175689958036, "report/reward_loss_mean": 0.03776302933692932, "report/reward_loss_std": 0.013613862916827202, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013303756713867188, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03776302933692932, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.000893633347004652, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00023393277660943568, "eval/cont_loss_std": 0.0062655555084347725, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.05565153434872627, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.6608875739621e-05, "eval/cont_pred": 0.9962761998176575, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 13.764497756958008, "eval/dyn_loss_std": 7.504059314727783, "eval/image_loss_mean": 44.70933151245117, "eval/image_loss_std": 34.831138610839844, "eval/model_loss_mean": 53.59447479248047, "eval/model_loss_std": 37.860843658447266, "eval/post_ent_mag": 49.161434173583984, "eval/post_ent_max": 49.161434173583984, "eval/post_ent_mean": 35.26312255859375, "eval/post_ent_min": 17.73505210876465, "eval/post_ent_std": 6.065874099731445, "eval/prior_ent_mag": 58.79922103881836, "eval/prior_ent_max": 58.79922103881836, "eval/prior_ent_mean": 44.780860900878906, "eval/prior_ent_min": 19.614267349243164, "eval/prior_ent_std": 8.599226951599121, "eval/rep_loss_mean": 13.764497756958008, "eval/rep_loss_std": 7.504059314727783, "eval/reward_avg": 0.013476562686264515, "eval/reward_loss_mean": 0.6262111663818359, "eval/reward_loss_std": 2.8208558559417725, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013252496719360352, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.377269446849823, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 13.793919563293457, "eval/reward_pred": 0.0008756198221817613, "eval/reward_rate": 0.0185546875, "replay/size": 39905.0, "replay/inserts": 19816.0, "replay/samples": 19824.0, "replay/insert_wait_avg": 1.396353705833167e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.581121925003014e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10656.0, "eval_replay/inserts": 4048.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.227608311317655e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.7136335372924805e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2280859947205, "timer/env.step_count": 2477.0, "timer/env.step_total": 234.42663145065308, "timer/env.step_frac": 0.23437317421207712, "timer/env.step_avg": 0.09464135302811993, "timer/env.step_min": 0.022895336151123047, "timer/env.step_max": 3.9263341426849365, "timer/replay._sample_count": 19824.0, "timer/replay._sample_total": 10.35771894454956, "timer/replay._sample_frac": 0.010355357032640086, "timer/replay._sample_avg": 0.0005224838047089165, "timer/replay._sample_min": 0.0003631114959716797, "timer/replay._sample_max": 0.011039495468139648, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2983.0, "timer/agent.policy_total": 50.66138529777527, "timer/agent.policy_frac": 0.05064983278028315, "timer/agent.policy_avg": 0.016983367515177764, "timer/agent.policy_min": 0.01018524169921875, "timer/agent.policy_max": 0.1247107982635498, "timer/dataset_train_count": 1239.0, "timer/dataset_train_total": 0.1423485279083252, "timer/dataset_train_frac": 0.00014231606760648047, "timer/dataset_train_avg": 0.00011488985303335367, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.00026535987854003906, "timer/agent.train_count": 1239.0, "timer/agent.train_total": 561.1889593601227, "timer/agent.train_frac": 0.5610609892063008, "timer/agent.train_avg": 0.45293701320429597, "timer/agent.train_min": 0.4411168098449707, "timer/agent.train_max": 0.8657963275909424, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47870421409606934, "timer/agent.report_frac": 0.00047859505326727656, "timer/agent.report_avg": 0.23935210704803467, "timer/agent.report_min": 0.231520414352417, "timer/agent.report_max": 0.24718379974365234, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.313262540729346e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 19.811245626773104}
{"step": 40496, "time": 2311.0821290016174, "episode/length": 310.0, "episode/score": 0.32820800785884785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32820800785884785}
{"step": 40576, "time": 2315.6265349388123, "episode/length": 208.0, "episode/score": 0.23244822552078404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23244822552078404}
{"step": 41088, "time": 2338.092838048935, "episode/length": 172.0, "episode/score": 0.19679968878972431, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19679968878972431}
{"step": 41288, "time": 2347.0335483551025, "episode/length": 192.0, "episode/score": 0.21359841505091026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21359841505091026}
{"step": 41296, "time": 2349.0073659420013, "episode/length": 234.0, "episode/score": 0.2540115678420989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2540115678420989}
{"step": 41312, "time": 2351.2649190425873, "episode/length": 155.0, "episode/score": 0.170446688460288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.170446688460288}
{"step": 41648, "time": 2365.3021697998047, "episode/length": 171.0, "episode/score": 0.17805275705177337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17805275705177337}
{"step": 41904, "time": 2376.461615562439, "episode/length": 396.0, "episode/score": 0.41144786314544035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41144786314544035}
{"step": 42112, "time": 2385.9518642425537, "episode/length": 201.0, "episode/score": 0.21045776004029904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21045776004029904}
{"step": 42280, "time": 2393.7140367031097, "episode/length": 148.0, "episode/score": 0.15872986597241834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15872986597241834}
{"step": 42288, "time": 2395.7740983963013, "episode/length": 213.0, "episode/score": 0.23373433911183383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23373433911183383}
{"step": 42672, "time": 2411.8890137672424, "episode/length": 171.0, "episode/score": 0.1785276581740618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1785276581740618}
{"step": 42824, "time": 2419.1129388809204, "episode/length": 188.0, "episode/score": 0.18557859244356223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18557859244356223}
{"step": 42896, "time": 2424.0296494960785, "episode/length": 200.0, "episode/score": 0.2053210756403132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2053210756403132}
{"step": 42976, "time": 2428.51864027977, "episode/length": 165.0, "episode/score": 0.16997001271010959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16997001271010959}
{"step": 43008, "time": 2431.218996286392, "episode/length": 111.0, "episode/score": 0.11230904076182924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11230904076182924}
{"step": 43312, "time": 2444.3553199768066, "episode/length": 175.0, "episode/score": 0.18513501630695828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18513501630695828}
{"step": 43560, "time": 2455.0529158115387, "episode/length": 159.0, "episode/score": 0.15298209250431682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15298209250431682}
{"step": 44064, "time": 2475.8876135349274, "episode/length": 221.0, "episode/score": 0.23335741185292136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23335741185292136}
{"step": 44232, "time": 2483.541524410248, "episode/length": 175.0, "episode/score": 0.19785513431634172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19785513431634172}
{"step": 44384, "time": 2491.089349269867, "episode/length": 213.0, "episode/score": 0.2424770601292039, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2424770601292039}
{"step": 44568, "time": 2499.5811998844147, "episode/length": 194.0, "episode/score": 0.20829018000586075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20829018000586075}
{"step": 44648, "time": 2504.1870539188385, "episode/length": 208.0, "episode/score": 0.2167313377976825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2167313377976825}
{"step": 44656, "time": 2506.2031424045563, "episode/length": 167.0, "episode/score": 0.18758723023620405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18758723023620405}
{"step": 44960, "time": 2519.19948220253, "episode/length": 174.0, "episode/score": 0.19488094927510247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19488094927510247}
{"step": 44976, "time": 2521.3307950496674, "episode/length": 259.0, "episode/score": 0.2799772132502767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2799772132502767}
{"step": 45568, "time": 2545.2881996631622, "episode/length": 187.0, "episode/score": 0.19738721788598923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19738721788598923}
{"step": 45640, "time": 2549.9412972927094, "episode/length": 175.0, "episode/score": 0.1904021835362073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1904021835362073}
{"step": 46008, "time": 2565.425359725952, "episode/length": 202.0, "episode/score": 0.21927153767683194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21927153767683194}
{"step": 46040, "time": 2568.2007467746735, "episode/length": 134.0, "episode/score": 0.14624772297247546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14624772297247546}
{"step": 46040, "time": 2568.2091252803802, "episode/length": 172.0, "episode/score": 0.20048946807946777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20048946807946777}
{"step": 46048, "time": 2571.7740519046783, "episode/length": 184.0, "episode/score": 0.20615598089352716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20615598089352716}
{"step": 46208, "time": 2579.3871459960938, "episode/length": 153.0, "episode/score": 0.15158263362536673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15158263362536673}
{"step": 46352, "time": 2586.280860185623, "episode/length": 212.0, "episode/score": 0.2373611474322388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2373611474322388}
{"step": 46776, "time": 2603.6492891311646, "episode/length": 150.0, "episode/score": 0.1480568339684396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1480568339684396}
{"step": 47072, "time": 2616.612267255783, "episode/length": 178.0, "episode/score": 0.19370007284305757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19370007284305757}
{"step": 47184, "time": 2622.6966557502747, "episode/length": 142.0, "episode/score": 0.14030499062937452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14030499062937452}
{"step": 47232, "time": 2626.0827910900116, "episode/length": 147.0, "episode/score": 0.16583906303640106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16583906303640106}
{"step": 47408, "time": 2634.2280189990997, "episode/length": 174.0, "episode/score": 0.18495842702577647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18495842702577647}
{"step": 47504, "time": 2639.381212949753, "episode/length": 53.0, "episode/score": 0.042034413756482536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042034413756482536}
{"step": 47568, "time": 2643.32301402092, "episode/length": 190.0, "episode/score": 0.19665809850448568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19665809850448568}
{"step": 47760, "time": 2652.311556816101, "episode/length": 193.0, "episode/score": 0.20178826305345865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20178826305345865}
{"step": 47760, "time": 2652.3198471069336, "episode/length": 175.0, "episode/score": 0.18676259308449517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18676259308449517}
{"step": 48240, "time": 2673.675124645233, "episode/length": 182.0, "episode/score": 0.17985152400251536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17985152400251536}
{"step": 48552, "time": 2686.8646416664124, "episode/length": 164.0, "episode/score": 0.17849168227530754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17849168227530754}
{"step": 48552, "time": 2686.873102426529, "episode/length": 170.0, "episode/score": 0.16608684998209355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16608684998209355}
{"step": 48752, "time": 2697.8325176239014, "episode/length": 167.0, "episode/score": 0.17830988027526473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17830988027526473}
{"step": 48832, "time": 2702.3222382068634, "episode/length": 165.0, "episode/score": 0.1652161821275513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1652161821275513}
{"step": 48984, "time": 2709.4702389240265, "episode/length": 152.0, "episode/score": 0.16661722418666614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16661722418666614}
{"step": 49120, "time": 2716.4004895687103, "episode/length": 169.0, "episode/score": 0.15474876996086095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15474876996086095}
{"step": 49192, "time": 2721.6849744319916, "episode/length": 202.0, "episode/score": 0.2087003730594006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2087003730594006}
{"step": 49480, "time": 2733.970780611038, "episode/length": 154.0, "episode/score": 0.17668797712576634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17668797712576634}
{"step": 49776, "time": 2747.015477657318, "episode/length": 152.0, "episode/score": 0.14526877728258114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14526877728258114}
{"step": 50016, "time": 2757.522578716278, "episode/length": 182.0, "episode/score": 0.1740020976476444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1740020976476444}
{"step": 50024, "time": 2778.730036020279, "eval_episode/length": 166.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 50024, "time": 2780.380276441574, "eval_episode/length": 169.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 50024, "time": 2781.9601538181305, "eval_episode/length": 170.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9883040935672515}
{"step": 50024, "time": 2783.634651184082, "eval_episode/length": 175.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 50024, "time": 2785.4738047122955, "eval_episode/length": 183.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 50024, "time": 2790.9609837532043, "eval_episode/length": 268.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9888475836431226}
{"step": 50024, "time": 2794.070790052414, "eval_episode/length": 128.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9689922480620154}
{"step": 50024, "time": 2797.189284324646, "eval_episode/length": 147.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9662162162162162}
{"step": 50200, "time": 2803.8504440784454, "episode/length": 180.0, "episode/score": 0.2008334156980709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2008334156980709}
{"step": 50376, "time": 2812.034964799881, "episode/length": 156.0, "episode/score": 0.15244963784334686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15244963784334686}
{"step": 50488, "time": 2817.6667857170105, "episode/length": 187.0, "episode/score": 0.17890164658001595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17890164658001595}
{"step": 50544, "time": 2821.5445668697357, "episode/length": 168.0, "episode/score": 0.18570273889235978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18570273889235978}
{"step": 50672, "time": 2827.83727145195, "episode/length": 229.0, "episode/score": 0.24908563029202924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24908563029202924}
{"step": 51072, "time": 2844.342434644699, "episode/length": 198.0, "episode/score": 0.202530115452646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.202530115452646}
{"step": 51296, "time": 2854.3437316417694, "episode/length": 189.0, "episode/score": 0.22565917891506615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22565917891506615}
{"step": 51536, "time": 2864.93199467659, "episode/length": 189.0, "episode/score": 0.1952594192075594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1952594192075594}
{"step": 51608, "time": 2868.8710556030273, "episode/length": 139.0, "episode/score": 0.1465110102831204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1465110102831204}
{"step": 51704, "time": 2873.9871950149536, "episode/length": 165.0, "episode/score": 0.18692180233620093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18692180233620093}
{"step": 51944, "time": 2884.498339176178, "episode/length": 217.0, "episode/score": 0.22167982006203601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22167982006203601}
{"step": 52000, "time": 2888.5519659519196, "episode/length": 165.0, "episode/score": 0.1837137847410304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1837137847410304}
{"step": 52448, "time": 2906.847688436508, "episode/length": 237.0, "episode/score": 0.2648993624520699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2648993624520699}
{"step": 52656, "time": 2916.1349580287933, "episode/length": 197.0, "episode/score": 0.2180702498158098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2180702498158098}
{"step": 52744, "time": 2920.884748697281, "episode/length": 36.0, "episode/score": 0.041791665920754895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041791665920754895}
{"step": 52952, "time": 2930.3516285419464, "episode/length": 167.0, "episode/score": 0.16986179456307582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16986179456307582}
{"step": 53032, "time": 2934.8406212329865, "episode/length": 165.0, "episode/score": 0.16869421334649815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16869421334649815}
{"step": 53112, "time": 2939.372229576111, "episode/length": 196.0, "episode/score": 0.22089367125863646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22089367125863646}
{"step": 53168, "time": 2943.1866223812103, "episode/length": 233.0, "episode/score": 0.2572689396474743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2572689396474743}
{"step": 53168, "time": 2943.194736480713, "episode/length": 145.0, "episode/score": 0.15070695225176678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15070695225176678}
{"step": 53520, "time": 2959.5914459228516, "episode/length": 196.0, "episode/score": 0.23166021232691492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23166021232691492}
{"step": 54208, "time": 2987.2803592681885, "episode/length": 193.0, "episode/score": 0.20046074828042038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20046074828042038}
{"step": 54360, "time": 2994.374431848526, "episode/length": 201.0, "episode/score": 0.20574883417657475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20574883417657475}
{"step": 54360, "time": 2994.383304834366, "episode/length": 175.0, "episode/score": 0.17517144768453363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17517144768453363}
{"step": 54392, "time": 2998.8115360736847, "episode/length": 159.0, "episode/score": 0.15250269441048658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15250269441048658}
{"step": 54552, "time": 3006.406509876251, "episode/length": 172.0, "episode/score": 0.18662069117817737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18662069117817737}
{"step": 54648, "time": 3011.6432762145996, "episode/length": 201.0, "episode/score": 0.21054388983156969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21054388983156969}
{"step": 55032, "time": 3027.592153787613, "episode/length": 83.0, "episode/score": 0.09444047455326654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09444047455326654}
{"step": 55040, "time": 3029.551924467087, "episode/length": 233.0, "episode/score": 0.26533165707223816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26533165707223816}
{"step": 55456, "time": 3046.7135360240936, "episode/length": 155.0, "episode/score": 0.16576213577354793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16576213577354793}
{"step": 55744, "time": 3059.0653858184814, "episode/length": 168.0, "episode/score": 0.18644066763226874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18644066763226874}
{"step": 55872, "time": 3065.403369665146, "episode/length": 188.0, "episode/score": 0.20830937648861436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20830937648861436}
{"step": 56056, "time": 3073.7368171215057, "episode/length": 316.0, "episode/score": 0.35111871254366633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35111871254366633}
{"step": 56176, "time": 3080.0773503780365, "episode/length": 190.0, "episode/score": 0.2117645423131762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2117645423131762}
{"step": 56288, "time": 3085.826667547226, "episode/length": 155.0, "episode/score": 0.15472087882153573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15472087882153573}
{"step": 56472, "time": 3093.9579203128815, "episode/length": 179.0, "episode/score": 0.18087998333066935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18087998333066935}
{"step": 56712, "time": 3104.5566806793213, "episode/length": 269.0, "episode/score": 0.28720481893833494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28720481893833494}
{"step": 56920, "time": 3113.820539712906, "episode/length": 130.0, "episode/score": 0.13780420976763708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13780420976763708}
{"step": 57040, "time": 3120.5745856761932, "episode/length": 197.0, "episode/score": 0.2260884649658692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2260884649658692}
{"step": 57344, "time": 3133.8692932128906, "episode/length": 160.0, "episode/score": 0.18216297378967283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18216297378967283}
{"step": 57592, "time": 3145.983752012253, "episode/length": 176.0, "episode/score": 0.2095564323317376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2095564323317376}
{"step": 57648, "time": 3149.732496738434, "episode/length": 169.0, "episode/score": 0.1974774207919836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1974774207919836}
{"step": 57656, "time": 3151.2476799488068, "episode/length": 238.0, "episode/score": 0.25139867544930894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25139867544930894}
{"step": 57696, "time": 3154.5139739513397, "episode/length": 152.0, "episode/score": 0.16686924277018989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16686924277018989}
{"step": 57920, "time": 3164.598527431488, "episode/length": 150.0, "episode/score": 0.16545305402542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16545305402542}
{"step": 58352, "time": 3182.280492782593, "episode/length": 163.0, "episode/score": 0.15627415458948235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15627415458948235}
{"step": 58680, "time": 3195.9985876083374, "episode/length": 166.0, "episode/score": 0.1835915041883709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1835915041883709}
{"step": 58816, "time": 3202.843379020691, "episode/length": 236.0, "episode/score": 0.2744278616992233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2744278616992233}
{"step": 58832, "time": 3204.921163082123, "episode/length": 141.0, "episode/score": 0.16341595539051923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16341595539051923}
{"step": 58960, "time": 3211.109726667404, "episode/length": 162.0, "episode/score": 0.164078217379938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.164078217379938}
{"step": 59120, "time": 3218.786687850952, "episode/length": 183.0, "episode/score": 0.19026004849365563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19026004849365563}
{"step": 59240, "time": 3224.627507686615, "episode/length": 164.0, "episode/score": 0.15844085417302267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15844085417302267}
{"step": 59296, "time": 3228.5395917892456, "episode/length": 212.0, "episode/score": 0.18273410289475578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18273410289475578}
{"step": 59776, "time": 3248.1044507026672, "episode/length": 177.0, "episode/score": 0.20046772069326835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20046772069326835}
{"step": 60008, "time": 3277.511322259903, "eval_episode/length": 157.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 60008, "time": 3279.0867784023285, "eval_episode/length": 159.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.99375}
{"step": 60008, "time": 3280.692549228668, "eval_episode/length": 162.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 60008, "time": 3282.972026348114, "eval_episode/length": 181.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.978021978021978}
{"step": 60008, "time": 3284.537040948868, "eval_episode/length": 183.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 60008, "time": 3286.66032743454, "eval_episode/length": 196.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 60008, "time": 3289.7334249019623, "eval_episode/length": 234.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9872340425531915}
{"step": 60008, "time": 3291.3844027519226, "eval_episode/length": 239.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9875}
{"step": 60192, "time": 3298.514664173126, "episode/length": 133.0, "episode/score": 0.15721839420075412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15721839420075412}
{"step": 60248, "time": 3301.8257732391357, "episode/length": 160.0, "episode/score": 0.17479974012348976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17479974012348976}
{"step": 60345, "time": 3308.0383865833282, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.05102880859375, "train/action_min": 0.0, "train/action_std": 4.816657817840576, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00343829489313066, "train/actor_opt_grad_steps": 3050.0, "train/actor_opt_loss": 31.09619133090973, "train/adv_mag": 0.15911558198928832, "train/adv_max": 0.040440587759017946, "train/adv_mean": 0.001409453221480362, "train/adv_min": -0.15876787316799162, "train/adv_std": 0.009750313820317387, "train/cont_avg": 0.9943671875, "train/cont_loss_mean": 0.0007492672607004352, "train/cont_loss_std": 0.02016971162066329, "train/cont_neg_acc": 0.969082543373108, "train/cont_neg_loss": 0.0783670334557828, "train/cont_pos_acc": 0.9999056601524353, "train/cont_pos_loss": 0.0003165387556364294, "train/cont_pred": 0.9943650074005127, "train/cont_rate": 0.9943671875, "train/dyn_loss_mean": 11.706875022888184, "train/dyn_loss_std": 6.913410591125488, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16764649195969106, "train/extr_critic_critic_opt_grad_steps": 3050.0, "train/extr_critic_critic_opt_loss": 7598.895140625, "train/extr_critic_mag": 0.20975267219543456, "train/extr_critic_max": 0.20975267219543456, "train/extr_critic_mean": 0.1941428997516632, "train/extr_critic_min": 0.12189812088012696, "train/extr_critic_std": 0.01450469358637929, "train/extr_return_normed_mag": 0.15665488934516908, "train/extr_return_normed_max": 0.050122217178344725, "train/extr_return_normed_mean": 0.034010342612862586, "train/extr_return_normed_min": -0.15553995978832244, "train/extr_return_normed_std": 0.018871123172342776, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.21166422247886657, "train/extr_return_raw_max": 0.21166422247886657, "train/extr_return_raw_mean": 0.19555235719680786, "train/extr_return_raw_min": 0.006002045512199402, "train/extr_return_raw_std": 0.018871123149991037, "train/extr_reward_mag": 0.0015213708877563476, "train/extr_reward_max": 0.0015213708877563476, "train/extr_reward_mean": 0.001073472287040204, "train/extr_reward_min": 2.6445388793945313e-05, "train/extr_reward_std": 0.0002390819222200662, "train/image_loss_mean": 22.21628356933594, "train/image_loss_std": 18.311396537780762, "train/model_loss_mean": 29.27956677246094, "train/model_loss_std": 20.74250431060791, "train/model_opt_grad_norm": 116.48830603027343, "train/model_opt_grad_steps": 3041.0, "train/model_opt_loss": 3450.425162109375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 119.375, "train/policy_entropy_mag": 2.791571516036987, "train/policy_entropy_max": 2.791571516036987, "train/policy_entropy_mean": 2.4233889198303222, "train/policy_entropy_min": 0.559866808116436, "train/policy_entropy_std": 0.38946691471338274, "train/policy_logprob_mag": 7.151778152465821, "train/policy_logprob_max": -0.1417297439724207, "train/policy_logprob_mean": -2.4239364490509034, "train/policy_logprob_min": -7.151778152465821, "train/policy_logprob_std": 0.8990133910179138, "train/policy_randomness_mag": 0.9853022394180297, "train/policy_randomness_max": 0.9853022394180297, "train/policy_randomness_mean": 0.8553499407768249, "train/policy_randomness_min": 0.19760841375589372, "train/policy_randomness_std": 0.13746473047137261, "train/post_ent_mag": 47.13620565795898, "train/post_ent_max": 47.13620565795898, "train/post_ent_mean": 34.037776306152345, "train/post_ent_min": 15.573314239501952, "train/post_ent_std": 5.195227172851562, "train/prior_ent_mag": 59.07673767089844, "train/prior_ent_max": 59.07673767089844, "train/prior_ent_mean": 46.23094555664063, "train/prior_ent_min": 19.07291806793213, "train/prior_ent_std": 6.979423748016357, "train/rep_loss_mean": 11.706875022888184, "train/rep_loss_std": 6.913410591125488, "train/reward_avg": 0.0010047434056177735, "train/reward_loss_mean": 0.03840886551141739, "train/reward_loss_std": 0.01321929519623518, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0014409465789794922, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03840886548161507, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010017786100506782, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.7727272317490794, "train_stats/max_log_achievement_collect_drink": 0.4090909090909091, "train_stats/max_log_achievement_collect_sapling": 0.6181818181818182, "train_stats/max_log_achievement_collect_wood": 0.6909090909090909, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_eat_cow": 0.01818181818181818, "train_stats/max_log_achievement_make_wood_pickaxe": 0.03636363636363636, "train_stats/max_log_achievement_make_wood_sword": 0.00909090909090909, "train_stats/max_log_achievement_place_plant": 0.4090909090909091, "train_stats/max_log_achievement_place_table": 0.09090909090909091, "train_stats/max_log_achievement_wake_up": 0.15454545454545454, "train_stats/mean_log_entropy": 2.435410177707672, "train_stats/max_log_achievement_defeat_zombie": 0.009433962264150943, "eval_stats/sum_log_reward": 1.1624999577179551, "eval_stats/max_log_achievement_collect_drink": 0.125, "eval_stats/max_log_achievement_collect_sapling": 0.5625, "eval_stats/max_log_achievement_collect_wood": 1.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.3125, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.475904329912737e-05, "report/cont_loss_std": 0.0005296241142787039, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002472207706887275, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.3667473215027712e-05, "report/cont_pred": 0.9950950145721436, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.135519027709961, "report/dyn_loss_std": 6.86194372177124, "report/image_loss_mean": 16.916488647460938, "report/image_loss_std": 14.4971342086792, "report/model_loss_mean": 24.235477447509766, "report/model_loss_std": 17.2606258392334, "report/post_ent_mag": 47.589019775390625, "report/post_ent_max": 47.589019775390625, "report/post_ent_mean": 34.6824951171875, "report/post_ent_min": 14.96002197265625, "report/post_ent_std": 5.087706565856934, "report/prior_ent_mag": 57.569576263427734, "report/prior_ent_max": 57.569576263427734, "report/prior_ent_mean": 47.542137145996094, "report/prior_ent_min": 19.811174392700195, "report/prior_ent_std": 6.201755523681641, "report/rep_loss_mean": 12.135519027709961, "report/rep_loss_std": 6.86194372177124, "report/reward_avg": 0.0009833050426095724, "report/reward_loss_mean": 0.03765258938074112, "report/reward_loss_std": 0.013800918124616146, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0014603137969970703, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03765258938074112, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010321141453459859, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 4.084131887793774e-06, "eval/cont_loss_std": 7.752706733299419e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0001513352181063965, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.795968950726092e-06, "eval/cont_pred": 0.9980433583259583, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 12.989680290222168, "eval/dyn_loss_std": 7.69959020614624, "eval/image_loss_mean": 21.104469299316406, "eval/image_loss_std": 22.32789421081543, "eval/model_loss_mean": 29.35940170288086, "eval/model_loss_std": 25.759990692138672, "eval/post_ent_mag": 48.85734939575195, "eval/post_ent_max": 48.85734939575195, "eval/post_ent_mean": 33.915245056152344, "eval/post_ent_min": 14.68124771118164, "eval/post_ent_std": 6.722793102264404, "eval/prior_ent_mag": 59.010536193847656, "eval/prior_ent_max": 59.010536193847656, "eval/prior_ent_mean": 44.95093536376953, "eval/prior_ent_min": 18.14112663269043, "eval/prior_ent_std": 8.620197296142578, "eval/rep_loss_mean": 12.989680290222168, "eval/rep_loss_std": 7.69959020614624, "eval/reward_avg": 0.015625, "eval/reward_loss_mean": 0.4611221253871918, "eval/reward_loss_std": 2.530574321746826, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0014632940292358398, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.19091695547103882, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 14.75355339050293, "eval/reward_pred": 0.0009453061502426863, "eval/reward_rate": 0.0185546875, "replay/size": 59841.0, "replay/inserts": 19936.0, "replay/samples": 19936.0, "replay/insert_wait_avg": 1.3882476674993769e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.427675274746376e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 15232.0, "eval_replay/inserts": 4576.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2192901197846953e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3969519138336, "timer/env.step_count": 2492.0, "timer/env.step_total": 234.98759937286377, "timer/env.step_frac": 0.23489435760806254, "timer/env.step_avg": 0.094296789475467, "timer/env.step_min": 0.022540807723999023, "timer/env.step_max": 3.250410318374634, "timer/replay._sample_count": 19936.0, "timer/replay._sample_total": 10.360769748687744, "timer/replay._sample_frac": 0.01035665865321443, "timer/replay._sample_avg": 0.0005197015323378684, "timer/replay._sample_min": 0.0003752708435058594, "timer/replay._sample_max": 0.021993637084960938, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3064.0, "timer/agent.policy_total": 50.72353672981262, "timer/agent.policy_frac": 0.05070340991420929, "timer/agent.policy_avg": 0.016554679089364432, "timer/agent.policy_min": 0.009737730026245117, "timer/agent.policy_max": 0.11838912963867188, "timer/dataset_train_count": 1246.0, "timer/dataset_train_total": 0.1422557830810547, "timer/dataset_train_frac": 0.00014219933678217314, "timer/dataset_train_avg": 0.00011416997037002784, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.00033783912658691406, "timer/agent.train_count": 1246.0, "timer/agent.train_total": 562.0550565719604, "timer/agent.train_frac": 0.5618320362699101, "timer/agent.train_avg": 0.45108752533865204, "timer/agent.train_min": 0.4382352828979492, "timer/agent.train_max": 0.8592867851257324, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.479076623916626, "timer/agent.report_frac": 0.0004788865289924333, "timer/agent.report_avg": 0.239538311958313, "timer/agent.report_min": 0.23230648040771484, "timer/agent.report_max": 0.24677014350891113, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.029273986816406e-05, "timer/dataset_eval_frac": 4.02767519344007e-08, "timer/dataset_eval_avg": 4.029273986816406e-05, "timer/dataset_eval_min": 4.029273986816406e-05, "timer/dataset_eval_max": 4.029273986816406e-05, "fps": 19.927815653963638}
{"step": 60392, "time": 3309.6917707920074, "episode/length": 194.0, "episode/score": 0.17960768842021935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17960768842021935}
{"step": 60480, "time": 3314.7064502239227, "episode/length": 224.0, "episode/score": 0.25671352650351764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25671352650351764}
{"step": 60568, "time": 3319.296262741089, "episode/length": 218.0, "episode/score": 0.23983579409468803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23983579409468803}
{"step": 60712, "time": 3326.190945625305, "episode/length": 176.0, "episode/score": 0.21025295388972154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21025295388972154}
{"step": 60752, "time": 3329.4203181266785, "episode/length": 44.0, "episode/score": 0.048440475307870656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048440475307870656}
{"step": 60864, "time": 3335.109861135483, "episode/length": 202.0, "episode/score": 0.22126892158303235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22126892158303235}
{"step": 61128, "time": 3346.283327817917, "episode/length": 168.0, "episode/score": 0.1724011359092401, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1724011359092401}
{"step": 61496, "time": 3361.717364549637, "episode/length": 162.0, "episode/score": 0.1910973085759906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1910973085759906}
{"step": 61584, "time": 3366.787858247757, "episode/length": 166.0, "episode/score": 0.16612993913440732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16612993913440732}
{"step": 61808, "time": 3376.7600741386414, "episode/length": 165.0, "episode/score": 0.18696919614649232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18696919614649232}
{"step": 62104, "time": 3389.1436455249786, "episode/length": 173.0, "episode/score": 0.1615762615647327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1615762615647327}
{"step": 62136, "time": 3391.876205921173, "episode/length": 172.0, "episode/score": 0.17733526576103031, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17733526576103031}
{"step": 62208, "time": 3396.3558564186096, "episode/length": 204.0, "episode/score": 0.22454472001845716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22454472001845716}
{"step": 62368, "time": 3404.0177059173584, "episode/length": 154.0, "episode/score": 0.1541197682145139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1541197682145139}
{"step": 62368, "time": 3404.0260746479034, "episode/length": 187.0, "episode/score": 0.1886129414442621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1886129414442621}
{"step": 62816, "time": 3424.475482940674, "episode/length": 153.0, "episode/score": 0.18234096813739598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18234096813739598}
{"step": 62920, "time": 3429.7239892482758, "episode/length": 177.0, "episode/score": 0.18425551875498059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18425551875498059}
{"step": 63120, "time": 3438.857544183731, "episode/length": 163.0, "episode/score": 0.17277894928520254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17277894928520254}
{"step": 63712, "time": 3463.167735338211, "episode/length": 167.0, "episode/score": 0.19558438805870537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19558438805870537}
{"step": 63736, "time": 3465.40495634079, "episode/length": 190.0, "episode/score": 0.1838750542319758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1838750542319758}
{"step": 63760, "time": 3467.943817615509, "episode/length": 173.0, "episode/score": 0.16566162619528768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16566162619528768}
{"step": 63824, "time": 3471.8656272888184, "episode/length": 214.0, "episode/score": 0.2092134391041327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2092134391041327}
{"step": 63960, "time": 3478.177099466324, "episode/length": 142.0, "episode/score": 0.16149106647935696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16149106647935696}
{"step": 64072, "time": 3483.76256275177, "episode/length": 241.0, "episode/score": 0.2815877148686923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2815877148686923}
{"step": 64296, "time": 3493.748472213745, "episode/length": 58.0, "episode/score": 0.0658749989233911, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0658749989233911}
{"step": 64360, "time": 3497.559458732605, "episode/length": 179.0, "episode/score": 0.18608705213591747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18608705213591747}
{"step": 64616, "time": 3508.703659772873, "episode/length": 186.0, "episode/score": 0.2225863050261978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2225863050261978}
{"step": 65064, "time": 3527.0538272857666, "episode/length": 165.0, "episode/score": 0.18031661923487263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18031661923487263}
{"step": 65352, "time": 3539.552867412567, "episode/length": 173.0, "episode/score": 0.1669632208713665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1669632208713665}
{"step": 65384, "time": 3542.7036707401276, "episode/length": 202.0, "episode/score": 0.22210474119901846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22210474119901846}
{"step": 65584, "time": 3554.0044128894806, "episode/length": 233.0, "episode/score": 0.26987131591067737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26987131591067737}
{"step": 65600, "time": 3556.1751770973206, "episode/length": 162.0, "episode/score": 0.1307543784560039, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1307543784560039}
{"step": 65760, "time": 3563.712077140808, "episode/length": 210.0, "episode/score": 0.21430087864700909, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21430087864700909}
{"step": 65848, "time": 3568.2877440452576, "episode/length": 185.0, "episode/score": 0.19165056187875962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19165056187875962}
{"step": 65992, "time": 3575.222188949585, "episode/length": 171.0, "episode/score": 0.18573966125723018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18573966125723018}
{"step": 66536, "time": 3596.9510536193848, "episode/length": 183.0, "episode/score": 0.20037736093627245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20037736093627245}
{"step": 66688, "time": 3604.3267464637756, "episode/length": 162.0, "episode/score": 0.14811657916470722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14811657916470722}
{"step": 66728, "time": 3607.140524864197, "episode/length": 171.0, "episode/score": 0.1848861998614666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1848861998614666}
{"step": 67144, "time": 3624.1017010211945, "episode/length": 75.0, "episode/score": 0.08488078558229972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08488078558229972}
{"step": 67216, "time": 3628.4853184223175, "episode/length": 203.0, "episode/score": 0.21561349849571343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21561349849571343}
{"step": 67216, "time": 3628.4928386211395, "episode/length": 201.0, "episode/score": 0.2347713389171986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2347713389171986}
{"step": 67288, "time": 3634.231148004532, "episode/length": 161.0, "episode/score": 0.1742373562897228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1742373562897228}
{"step": 67448, "time": 3641.828648328781, "episode/length": 210.0, "episode/score": 0.2270284710220949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2270284710220949}
{"step": 67712, "time": 3653.5872750282288, "episode/length": 232.0, "episode/score": 0.25480996539863554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25480996539863554}
{"step": 68064, "time": 3668.3329010009766, "episode/length": 105.0, "episode/score": 0.1199098571983086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1199098571983086}
{"step": 68104, "time": 3671.176737308502, "episode/length": 171.0, "episode/score": 0.17876849140475315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17876849140475315}
{"step": 68120, "time": 3673.3091235160828, "episode/length": 178.0, "episode/score": 0.19793840283909958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19793840283909958}
{"step": 68184, "time": 3677.260133266449, "episode/length": 91.0, "episode/score": 0.10676084403576169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10676084403576169}
{"step": 68456, "time": 3688.7858798503876, "episode/length": 145.0, "episode/score": 0.1767499964335002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1767499964335002}
{"step": 68584, "time": 3695.062971353531, "episode/length": 170.0, "episode/score": 0.1783637695298239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1783637695298239}
{"step": 68888, "time": 3707.9521975517273, "episode/length": 146.0, "episode/score": 0.13882302846741368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13882302846741368}
{"step": 69176, "time": 3720.210774421692, "episode/length": 133.0, "episode/score": 0.15905209099719286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15905209099719286}
{"step": 69248, "time": 3724.625125169754, "episode/length": 262.0, "episode/score": 0.29500182355286597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29500182355286597}
{"step": 69568, "time": 3738.2202360630035, "episode/length": 172.0, "episode/score": 0.16905817272845525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16905817272845525}
{"step": 69600, "time": 3740.9158363342285, "episode/length": 191.0, "episode/score": 0.1908286705579485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1908286705579485}
{"step": 69768, "time": 3748.5451214313507, "episode/length": 163.0, "episode/score": 0.16323139810629073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16323139810629073}
{"step": 69784, "time": 3750.766492128372, "episode/length": 207.0, "episode/score": 0.22979144986265965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22979144986265965}
{"step": 69888, "time": 3756.3557460308075, "episode/length": 162.0, "episode/score": 0.1795980462911757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1795980462911757}
{"step": 69944, "time": 3759.8302216529846, "episode/length": 131.0, "episode/score": 0.12152168462762347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12152168462762347}
{"step": 70096, "time": 3788.104063510895, "eval_episode/length": 147.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9594594594594594}
{"step": 70096, "time": 3790.0856437683105, "eval_episode/length": 156.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 70096, "time": 3791.89142870903, "eval_episode/length": 163.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 70096, "time": 3793.8230676651, "eval_episode/length": 174.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 70096, "time": 3795.7897458076477, "eval_episode/length": 185.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9623655913978495}
{"step": 70096, "time": 3797.6415157318115, "eval_episode/length": 194.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9641025641025641}
{"step": 70096, "time": 3799.5023622512817, "eval_episode/length": 202.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 70096, "time": 3801.1578233242035, "eval_episode/length": 206.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9806763285024155}
{"step": 70744, "time": 3825.0505199432373, "episode/length": 186.0, "episode/score": 0.204566027229248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.204566027229248}
{"step": 70768, "time": 3827.796870946884, "episode/length": 198.0, "episode/score": 0.22125488938672788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22125488938672788}
{"step": 70896, "time": 3834.118463754654, "episode/length": 161.0, "episode/score": 0.18402216970343943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18402216970343943}
{"step": 70904, "time": 3835.685758113861, "episode/length": 166.0, "episode/score": 0.15579800621890172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15579800621890172}
{"step": 71216, "time": 3849.2992379665375, "episode/length": 180.0, "episode/score": 0.20175000910739982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20175000910739982}
{"step": 71256, "time": 3852.058616876602, "episode/length": 170.0, "episode/score": 0.17560704181278197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17560704181278197}
{"step": 71272, "time": 3854.1245822906494, "episode/length": 165.0, "episode/score": 0.16531399686755321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16531399686755321}
{"step": 71592, "time": 3867.496572494507, "episode/length": 225.0, "episode/score": 0.22920197146959254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22920197146959254}
{"step": 71936, "time": 3882.1389055252075, "episode/length": 148.0, "episode/score": 0.14710395889460415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14710395889460415}
{"step": 72112, "time": 3890.1368341445923, "episode/length": 150.0, "episode/score": 0.146128186444912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.146128186444912}
{"step": 72328, "time": 3899.409615755081, "episode/length": 194.0, "episode/score": 0.19626745897357978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19626745897357978}
{"step": 72480, "time": 3906.796510219574, "episode/length": 157.0, "episode/score": 0.17030026595261916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17030026595261916}
{"step": 72520, "time": 3909.6933040618896, "episode/length": 155.0, "episode/score": 0.17512140791200181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17512140791200181}
{"step": 72520, "time": 3909.7024371623993, "episode/length": 202.0, "episode/score": 0.1994144253299055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1994144253299055}
{"step": 72792, "time": 3923.020473241806, "episode/length": 191.0, "episode/score": 0.20431850066324841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20431850066324841}
{"step": 72816, "time": 3925.665781736374, "episode/length": 152.0, "episode/score": 0.15014385026165655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15014385026165655}
{"step": 73304, "time": 3945.382739305496, "episode/length": 170.0, "episode/score": 0.1866159846017581, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1866159846017581}
{"step": 73744, "time": 3964.9380555152893, "episode/length": 176.0, "episode/score": 0.18053828583242648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18053828583242648}
{"step": 73776, "time": 3967.7517817020416, "episode/length": 161.0, "episode/score": 0.18043405100047494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18043405100047494}
{"step": 73896, "time": 3973.5957446098328, "episode/length": 222.0, "episode/score": 0.23758110026392387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23758110026392387}
{"step": 74024, "time": 3979.886193037033, "episode/length": 153.0, "episode/score": 0.15244513666607418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15244513666607418}
{"step": 74120, "time": 3984.9797196388245, "episode/length": 199.0, "episode/score": 0.21574275304237744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21574275304237744}
{"step": 74176, "time": 3988.814156293869, "episode/length": 206.0, "episode/score": 0.23897683556151605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23897683556151605}
{"step": 74448, "time": 4000.4948585033417, "episode/length": 203.0, "episode/score": 0.23034478036743167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23034478036743167}
{"step": 74544, "time": 4005.8050429821014, "episode/length": 154.0, "episode/score": 0.18723213896737434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18723213896737434}
{"step": 74960, "time": 4023.300644159317, "episode/length": 151.0, "episode/score": 0.1513612089884191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1513612089884191}
{"step": 75296, "time": 4037.4270799160004, "episode/length": 189.0, "episode/score": 0.19945539203808949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19945539203808949}
{"step": 75560, "time": 4048.857298851013, "episode/length": 179.0, "episode/score": 0.1885521260933274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1885521260933274}
{"step": 75568, "time": 4050.838611841202, "episode/length": 192.0, "episode/score": 0.20105512219106458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20105512219106458}
{"step": 75640, "time": 4054.8429749011993, "episode/length": 182.0, "episode/score": 0.185942847611841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.185942847611841}
{"step": 75720, "time": 4059.4984800815582, "episode/length": 158.0, "episode/score": 0.18147668168990094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18147668168990094}
{"step": 75776, "time": 4063.318463563919, "episode/length": 234.0, "episode/score": 0.25235878120770394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25235878120770394}
{"step": 75816, "time": 4066.0632717609406, "episode/length": 158.0, "episode/score": 0.17085181123388793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17085181123388793}
{"step": 76416, "time": 4090.175484418869, "episode/length": 181.0, "episode/score": 0.1780705845378634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1780705845378634}
{"step": 76736, "time": 4103.470103740692, "episode/length": 179.0, "episode/score": 0.19843638514112172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19843638514112172}
{"step": 76888, "time": 4110.393571138382, "episode/length": 155.0, "episode/score": 0.1660983564606795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1660983564606795}
{"step": 76896, "time": 4112.501822471619, "episode/length": 166.0, "episode/score": 0.15879160313443208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15879160313443208}
{"step": 77104, "time": 4121.980922460556, "episode/length": 160.0, "episode/score": 0.16525664692926512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16525664692926512}
{"step": 77128, "time": 4124.143303394318, "episode/length": 175.0, "episode/score": 0.1843593565156425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1843593565156425}
{"step": 77176, "time": 4127.631620168686, "episode/length": 174.0, "episode/score": 0.18326975655031674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18326975655031674}
{"step": 77624, "time": 4145.810152769089, "episode/length": 256.0, "episode/score": 0.26330447642772015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26330447642772015}
{"step": 78080, "time": 4164.620434999466, "episode/length": 167.0, "episode/score": 0.16426305811705788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16426305811705788}
{"step": 78256, "time": 4172.834452390671, "episode/length": 170.0, "episode/score": 0.18695876231276998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18695876231276998}
{"step": 78344, "time": 4178.0633499622345, "episode/length": 240.0, "episode/score": 0.2609769317673454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2609769317673454}
{"step": 78392, "time": 4181.861899137497, "episode/length": 186.0, "episode/score": 0.20181825742724868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20181825742724868}
{"step": 78456, "time": 4186.305770397186, "episode/length": 168.0, "episode/score": 0.15845842941917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15845842941917}
{"step": 78792, "time": 4201.068872690201, "episode/length": 207.0, "episode/score": 0.23645501584564954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23645501584564954}
{"step": 78800, "time": 4203.195981025696, "episode/length": 202.0, "episode/score": 0.21786387039037436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21786387039037436}
{"step": 79032, "time": 4213.187953710556, "episode/length": 175.0, "episode/score": 0.18684860144912818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18684860144912818}
{"step": 79464, "time": 4231.442514657974, "episode/length": 172.0, "episode/score": 0.1845009822980046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1845009822980046}
{"step": 79504, "time": 4234.786613702774, "episode/length": 155.0, "episode/score": 0.1626816919972498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1626816919972498}
{"step": 79648, "time": 4241.74888586998, "episode/length": 162.0, "episode/score": 0.1767968221765841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1767968221765841}
{"step": 79704, "time": 4245.0751712322235, "episode/length": 163.0, "episode/score": 0.18865036921829414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18865036921829414}
{"step": 79848, "time": 4252.063415765762, "episode/length": 173.0, "episode/score": 0.16020867024667496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16020867024667496}
{"step": 80080, "time": 4282.169127464294, "eval_episode/length": 168.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 80080, "time": 4283.804698944092, "eval_episode/length": 169.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 80080, "time": 4286.110100507736, "eval_episode/length": 186.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 80080, "time": 4288.7208416461945, "eval_episode/length": 210.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.976303317535545}
{"step": 80080, "time": 4290.24107336998, "eval_episode/length": 211.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 80080, "time": 4292.145261287689, "eval_episode/length": 221.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 80080, "time": 4294.33073759079, "eval_episode/length": 236.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9789029535864979}
{"step": 80080, "time": 4298.028606891632, "eval_episode/length": 115.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 80128, "time": 4299.853087902069, "episode/length": 165.0, "episode/score": 0.18988272594287992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18988272594287992}
{"step": 80297, "time": 4308.469176054001, "train_stats/sum_log_reward": 0.41578945197295725, "train_stats/max_log_achievement_collect_drink": 0.14035087719298245, "train_stats/max_log_achievement_collect_sapling": 0.5350877192982456, "train_stats/max_log_achievement_collect_wood": 0.43859649122807015, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.40350877192982454, "train_stats/max_log_achievement_place_table": 0.07017543859649122, "train_stats/max_log_achievement_wake_up": 0.07017543859649122, "train_stats/mean_log_entropy": 2.373366619411268, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.94624169921875, "train/action_min": 0.0, "train/action_std": 4.765744857788086, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004407498562708497, "train/actor_opt_grad_steps": 4300.0, "train/actor_opt_loss": -12.667416512966156, "train/adv_mag": 0.1498136967420578, "train/adv_max": 0.06205190336704254, "train/adv_mean": -0.0003840247160187573, "train/adv_min": -0.14975337874889375, "train/adv_std": 0.011010273560881615, "train/cont_avg": 0.9943984375, "train/cont_loss_mean": 0.000636640010145129, "train/cont_loss_std": 0.016857887754838884, "train/cont_neg_acc": 0.9808539719581604, "train/cont_neg_loss": 0.062166070596442295, "train/cont_pos_acc": 0.9999371199607849, "train/cont_pos_loss": 0.00024938013248083734, "train/cont_pred": 0.9943884272575378, "train/cont_rate": 0.9943984375, "train/dyn_loss_mean": 13.191831230163574, "train/dyn_loss_std": 7.21860336303711, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.19199806609749795, "train/extr_critic_critic_opt_grad_steps": 4300.0, "train/extr_critic_critic_opt_loss": 10620.157859375, "train/extr_critic_mag": 0.24640730857849122, "train/extr_critic_max": 0.24640730857849122, "train/extr_critic_mean": 0.20547583305835723, "train/extr_critic_min": 0.060521151542663576, "train/extr_critic_std": 0.03768595360219479, "train/extr_return_normed_mag": 0.1409769621491432, "train/extr_return_normed_max": 0.12200238424539565, "train/extr_return_normed_mean": 0.08173200809955597, "train/extr_return_normed_min": -0.12223053681850433, "train/extr_return_normed_std": 0.040731148794293404, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.24536221182346343, "train/extr_return_raw_max": 0.24536221182346343, "train/extr_return_raw_mean": 0.20509184384346008, "train/extr_return_raw_min": 0.0011292905807495117, "train/extr_return_raw_std": 0.040731148734688756, "train/extr_reward_mag": 0.0014414215087890626, "train/extr_reward_max": 0.0014414215087890626, "train/extr_reward_mean": 0.0010894173681735993, "train/extr_reward_min": 4.454612731933594e-06, "train/extr_reward_std": 0.0002374712259043008, "train/image_loss_mean": 17.36601959991455, "train/image_loss_std": 15.47767209625244, "train/model_loss_mean": 25.32073846435547, "train/model_loss_std": 18.1630763092041, "train/model_opt_grad_norm": 98.62661065673828, "train/model_opt_grad_steps": 4291.0, "train/model_opt_loss": 6764.587888671875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 270.0, "train/policy_entropy_mag": 2.769682540893555, "train/policy_entropy_max": 2.769682540893555, "train/policy_entropy_mean": 2.3426581783294678, "train/policy_entropy_min": 0.18683545714616775, "train/policy_entropy_std": 0.41436149370670317, "train/policy_logprob_mag": 7.308739471435547, "train/policy_logprob_max": -0.02915046615898609, "train/policy_logprob_mean": -2.342658632278442, "train/policy_logprob_min": -7.308739471435547, "train/policy_logprob_std": 0.971183072090149, "train/policy_randomness_mag": 0.9775763931274414, "train/policy_randomness_max": 0.9775763931274414, "train/policy_randomness_mean": 0.8268555316925049, "train/policy_randomness_min": 0.06594471733272075, "train/policy_randomness_std": 0.1462514231801033, "train/post_ent_mag": 49.05662417602539, "train/post_ent_max": 49.05662417602539, "train/post_ent_mean": 34.74419836425781, "train/post_ent_min": 17.034413345336915, "train/post_ent_std": 5.19008260345459, "train/prior_ent_mag": 60.49800555419922, "train/prior_ent_max": 60.49800555419922, "train/prior_ent_mean": 48.292106658935545, "train/prior_ent_min": 20.822675674438475, "train/prior_ent_std": 6.388855503082276, "train/rep_loss_mean": 13.191831230163574, "train/rep_loss_std": 7.21860336303711, "train/reward_avg": 0.0010253981272689999, "train/reward_loss_mean": 0.038983563631772994, "train/reward_loss_std": 0.012707290589809418, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0014046344757080078, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.038983563661575314, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010247531849890948, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.6625000042840838, "eval_stats/max_log_achievement_collect_drink": 0.25, "eval_stats/max_log_achievement_collect_sapling": 0.625, "eval_stats/max_log_achievement_collect_wood": 0.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.6414393030572683e-05, "report/cont_loss_std": 0.0004033783625345677, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002719751500990242, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.5160414477577433e-05, "report/cont_pred": 0.9951035976409912, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.225116729736328, "report/dyn_loss_std": 7.195858478546143, "report/image_loss_mean": 10.665104866027832, "report/image_loss_std": 10.63518238067627, "report/model_loss_mean": 18.03777313232422, "report/model_loss_std": 13.486635208129883, "report/post_ent_mag": 50.346290588378906, "report/post_ent_max": 50.346290588378906, "report/post_ent_mean": 34.7320442199707, "report/post_ent_min": 16.57252311706543, "report/post_ent_std": 5.304812431335449, "report/prior_ent_mag": 61.37609100341797, "report/prior_ent_max": 61.37609100341797, "report/prior_ent_mean": 47.50879669189453, "report/prior_ent_min": 17.122371673583984, "report/prior_ent_std": 6.823297500610352, "report/rep_loss_mean": 12.225116729736328, "report/rep_loss_std": 7.195858478546143, "report/reward_avg": 0.000989623018540442, "report/reward_loss_mean": 0.03758122771978378, "report/reward_loss_std": 0.014759667217731476, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013308525085449219, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.037581223994493484, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.000964348204433918, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 8.37179015888978e-07, "eval/cont_loss_std": 1.2880375834356528e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00016017038433346897, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.253722861198185e-07, "eval/cont_pred": 0.9980466961860657, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 14.073970794677734, "eval/dyn_loss_std": 9.145613670349121, "eval/image_loss_mean": 14.215141296386719, "eval/image_loss_std": 14.793417930603027, "eval/model_loss_mean": 23.215354919433594, "eval/model_loss_std": 19.34990882873535, "eval/post_ent_mag": 44.33049774169922, "eval/post_ent_max": 44.33049774169922, "eval/post_ent_mean": 32.930023193359375, "eval/post_ent_min": 16.88325309753418, "eval/post_ent_std": 4.914062023162842, "eval/prior_ent_mag": 61.37609100341797, "eval/prior_ent_max": 61.37609100341797, "eval/prior_ent_mean": 44.24641418457031, "eval/prior_ent_min": 16.400514602661133, "eval/prior_ent_std": 9.688109397888184, "eval/rep_loss_mean": 14.073970794677734, "eval/rep_loss_std": 9.145613670349121, "eval/reward_avg": 0.01953125, "eval/reward_loss_mean": 0.5558295249938965, "eval/reward_loss_std": 2.869551181793213, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013386011123657227, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.21061117947101593, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 15.580330848693848, "eval/reward_pred": 0.00084633007645607, "eval/reward_rate": 0.0224609375, "replay/size": 79793.0, "replay/inserts": 19952.0, "replay/samples": 19952.0, "replay/insert_wait_avg": 1.3652188164191716e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.271939850465335e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 19176.0, "eval_replay/inserts": 3944.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2183286113622948e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2814998626708984e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4154345989227, "timer/env.step_count": 2494.0, "timer/env.step_total": 241.23908758163452, "timer/env.step_frac": 0.24113891013521782, "timer/env.step_avg": 0.09672778170875482, "timer/env.step_min": 0.02223372459411621, "timer/env.step_max": 3.298532009124756, "timer/replay._sample_count": 19952.0, "timer/replay._sample_total": 9.977990627288818, "timer/replay._sample_frac": 0.009973847146099961, "timer/replay._sample_avg": 0.0005000997708143954, "timer/replay._sample_min": 0.0003790855407714844, "timer/replay._sample_max": 0.010209798812866211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2987.0, "timer/agent.policy_total": 49.30623149871826, "timer/agent.policy_frac": 0.049285756490238135, "timer/agent.policy_avg": 0.016506940575399486, "timer/agent.policy_min": 0.009243249893188477, "timer/agent.policy_max": 0.12908625602722168, "timer/dataset_train_count": 1247.0, "timer/dataset_train_total": 0.13513970375061035, "timer/dataset_train_frac": 0.00013508358535550713, "timer/dataset_train_avg": 0.00010837185545357687, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.00026035308837890625, "timer/agent.train_count": 1247.0, "timer/agent.train_total": 561.0011584758759, "timer/agent.train_frac": 0.5607681959652964, "timer/agent.train_avg": 0.4498806403174626, "timer/agent.train_min": 0.4370076656341553, "timer/agent.train_max": 0.9134228229522705, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48147106170654297, "timer/agent.report_frac": 0.00048127112502974314, "timer/agent.report_avg": 0.24073553085327148, "timer/agent.report_min": 0.23382830619812012, "timer/agent.report_max": 0.24764275550842285, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.384137935256355e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 19.943468960220894}
{"step": 80504, "time": 4316.1395518779755, "episode/length": 213.0, "episode/score": 0.2455739173328766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2455739173328766}
{"step": 80504, "time": 4316.1478435993195, "episode/length": 183.0, "episode/score": 0.18692512361599256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18692512361599256}
{"step": 80616, "time": 4323.6918869018555, "episode/length": 120.0, "episode/score": 0.14279414409543278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14279414409543278}
{"step": 80648, "time": 4326.504745721817, "episode/length": 142.0, "episode/score": 0.14872213565627135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14872213565627135}
{"step": 81312, "time": 4353.053591012955, "episode/length": 182.0, "episode/score": 0.19957831821307082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19957831821307082}
{"step": 81616, "time": 4366.0713839530945, "episode/length": 238.0, "episode/score": 0.2570415382235751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2570415382235751}
{"step": 81632, "time": 4368.135557174683, "episode/length": 140.0, "episode/score": 0.1432587071551552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1432587071551552}
{"step": 81648, "time": 4370.344940900803, "episode/length": 189.0, "episode/score": 0.2049882559708749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2049882559708749}
{"step": 81752, "time": 4375.508029937744, "episode/length": 155.0, "episode/score": 0.17036902693939737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17036902693939737}
{"step": 82080, "time": 4391.078800916672, "episode/length": 182.0, "episode/score": 0.2021194524556904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2021194524556904}
{"step": 82168, "time": 4395.560976028442, "episode/length": 189.0, "episode/score": 0.18909580017862027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18909580017862027}
{"step": 82176, "time": 4397.682644367218, "episode/length": 338.0, "episode/score": 0.3523198554846658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3523198554846658}
{"step": 82592, "time": 4414.725872993469, "episode/length": 119.0, "episode/score": 0.1356326490401898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1356326490401898}
{"step": 82632, "time": 4417.610886096954, "episode/length": 56.0, "episode/score": 0.05845833267085254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05845833267085254}
{"step": 82840, "time": 4427.007776021957, "episode/length": 152.0, "episode/score": 0.15433602827079085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15433602827079085}
{"step": 82912, "time": 4431.415374040604, "episode/length": 103.0, "episode/score": 0.11527942207180786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11527942207180786}
{"step": 82920, "time": 4433.0109395980835, "episode/length": 158.0, "episode/score": 0.1644678376931097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1644678376931097}
{"step": 82944, "time": 4435.612859487534, "episode/length": 148.0, "episode/score": 0.17362962851098018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17362962851098018}
{"step": 83160, "time": 4444.888442277908, "episode/length": 230.0, "episode/score": 0.2311545301147362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2311545301147362}
{"step": 84040, "time": 4479.513864040375, "episode/length": 180.0, "episode/score": 0.1799751574342281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1799751574342281}
{"step": 84264, "time": 4490.124926805496, "episode/length": 164.0, "episode/score": 0.16231365934277164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16231365934277164}
{"step": 84304, "time": 4493.860435724258, "episode/length": 208.0, "episode/score": 0.20675120212308684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20675120212308684}
{"step": 84368, "time": 4497.765647649765, "episode/length": 274.0, "episode/score": 0.29299021732435904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29299021732435904}
{"step": 84520, "time": 4504.754131793976, "episode/length": 200.0, "episode/score": 0.24520832824055105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24520832824055105}
{"step": 84632, "time": 4510.5687420368195, "episode/length": 223.0, "episode/score": 0.24562204470862525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24562204470862525}
{"step": 84768, "time": 4517.352006435394, "episode/length": 200.0, "episode/score": 0.2116091906937072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2116091906937072}
{"step": 84936, "time": 4524.892367601395, "episode/length": 70.0, "episode/score": 0.06951568890031012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06951568890031012}
{"step": 85352, "time": 4541.97242474556, "episode/length": 303.0, "episode/score": 0.3271268064834203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3271268064834203}
{"step": 85432, "time": 4546.3875069618225, "episode/length": 173.0, "episode/score": 0.18679843059749146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18679843059749146}
{"step": 85640, "time": 4555.679351091385, "episode/length": 87.0, "episode/score": 0.08984572427266357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08984572427266357}
{"step": 85736, "time": 4560.766274213791, "episode/length": 183.0, "episode/score": 0.20624063567834128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20624063567834128}
{"step": 85768, "time": 4563.415538072586, "episode/length": 182.0, "episode/score": 0.18260012961741268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18260012961741268}
{"step": 85872, "time": 4569.276442289352, "episode/length": 168.0, "episode/score": 0.18804339907637768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18804339907637768}
{"step": 86008, "time": 4575.632799625397, "episode/length": 171.0, "episode/score": 0.1890037700100038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1890037700100038}
{"step": 86456, "time": 4593.782603025436, "episode/length": 210.0, "episode/score": 0.2199106491952989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2199106491952989}
{"step": 86600, "time": 4600.783889293671, "episode/length": 155.0, "episode/score": 0.15819262005379642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15819262005379642}
{"step": 86936, "time": 4614.878600597382, "episode/length": 145.0, "episode/score": 0.155203211184471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.155203211184471}
{"step": 87104, "time": 4623.036194086075, "episode/length": 153.0, "episode/score": 0.13662091352603056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13662091352603056}
{"step": 87184, "time": 4628.152111053467, "episode/length": 218.0, "episode/score": 0.24287332196013267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24287332196013267}
{"step": 87256, "time": 4632.669299840927, "episode/length": 201.0, "episode/score": 0.2291650239549199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2291650239549199}
{"step": 87288, "time": 4635.347779989243, "episode/length": 193.0, "episode/score": 0.21901207861151306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21901207861151306}
{"step": 87408, "time": 4641.5663006305695, "episode/length": 174.0, "episode/score": 0.16971715045337987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16971715045337987}
{"step": 88032, "time": 4666.53329706192, "episode/length": 196.0, "episode/score": 0.19710636855711527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19710636855711527}
{"step": 88136, "time": 4671.675515413284, "episode/length": 191.0, "episode/score": 0.1950225822909033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1950225822909033}
{"step": 88176, "time": 4674.942108392715, "episode/length": 154.0, "episode/score": 0.15963813809912608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15963813809912608}
{"step": 88408, "time": 4684.945328712463, "episode/length": 162.0, "episode/score": 0.13704895368005054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13704895368005054}
{"step": 88664, "time": 4696.229519367218, "episode/length": 184.0, "episode/score": 0.17837320424985137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17837320424985137}
{"step": 88728, "time": 4700.127843379974, "episode/length": 183.0, "episode/score": 0.15837009477661468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15837009477661468}
{"step": 88976, "time": 4711.197515487671, "episode/length": 210.0, "episode/score": 0.20876122372033024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20876122372033024}
{"step": 88984, "time": 4712.732496023178, "episode/length": 196.0, "episode/score": 0.1888701186377375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1888701186377375}
{"step": 89272, "time": 4725.227797746658, "episode/length": 136.0, "episode/score": 0.15090136623814487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15090136623814487}
{"step": 89536, "time": 4736.907178401947, "episode/length": 174.0, "episode/score": 0.18231591618189213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18231591618189213}
{"step": 89568, "time": 4739.67570066452, "episode/length": 191.0, "episode/score": 0.18528693578571165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18528693578571165}
{"step": 89760, "time": 4748.896911621094, "episode/length": 168.0, "episode/score": 0.1633660031324098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1633660031324098}
{"step": 90064, "time": 4761.765928506851, "episode/length": 166.0, "episode/score": 0.15399258685090444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15399258685090444}
{"step": 90064, "time": 4781.267560958862, "eval_episode/length": 154.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 90064, "time": 4783.213277101517, "eval_episode/length": 155.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 90064, "time": 4785.1491277217865, "eval_episode/length": 156.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9617834394904459}
{"step": 90064, "time": 4787.229939460754, "eval_episode/length": 157.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 90064, "time": 4789.592152357101, "eval_episode/length": 165.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 90064, "time": 4792.089288473129, "eval_episode/length": 181.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 90064, "time": 4794.033544778824, "eval_episode/length": 190.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 90064, "time": 4796.084713935852, "eval_episode/length": 201.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 90248, "time": 4805.53462934494, "episode/length": 158.0, "episode/score": 0.15703604460099996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15703604460099996}
{"step": 90328, "time": 4810.165714740753, "episode/length": 207.0, "episode/score": 0.2161171316081436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2161171316081436}
{"step": 90616, "time": 4822.407835483551, "episode/length": 167.0, "episode/score": 0.15276689211134453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15276689211134453}
{"step": 90656, "time": 4826.340538024902, "episode/length": 208.0, "episode/score": 0.20873401830908733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20873401830908733}
{"step": 90832, "time": 4834.893186092377, "episode/length": 161.0, "episode/score": 0.1926683373378637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1926683373378637}
{"step": 91200, "time": 4850.384425640106, "episode/length": 179.0, "episode/score": 0.19439658804424198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19439658804424198}
{"step": 91272, "time": 4854.36905670166, "episode/length": 150.0, "episode/score": 0.17280153067849824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17280153067849824}
{"step": 91784, "time": 4875.0239980220795, "episode/length": 181.0, "episode/score": 0.20284310505917347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20284310505917347}
{"step": 91840, "time": 4878.917226552963, "episode/length": 198.0, "episode/score": 0.2055389627871591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2055389627871591}
{"step": 92224, "time": 4895.163949966431, "episode/length": 195.0, "episode/score": 0.2135763345847863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2135763345847863}
{"step": 92424, "time": 4904.466676950455, "episode/length": 198.0, "episode/score": 0.20471797883953968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20471797883953968}
{"step": 92496, "time": 4908.944319725037, "episode/length": 234.0, "episode/score": 0.2591510733377618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2591510733377618}
{"step": 92584, "time": 4913.527489900589, "episode/length": 172.0, "episode/score": 0.1869016617414445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1869016617414445}
{"step": 92616, "time": 4916.266526699066, "episode/length": 48.0, "episode/score": 0.05758333223639056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05758333223639056}
{"step": 92632, "time": 4918.370406150818, "episode/length": 382.0, "episode/score": 0.34313038676361884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34313038676361884}
{"step": 92752, "time": 4924.528815507889, "episode/length": 184.0, "episode/score": 0.1854765413916084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1854765413916084}
{"step": 92992, "time": 4934.934597730637, "episode/length": 50.0, "episode/score": 0.052619758061837274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052619758061837274}
{"step": 93144, "time": 4941.89079451561, "episode/length": 169.0, "episode/score": 0.1634070455222627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1634070455222627}
{"step": 93584, "time": 4960.235068321228, "episode/length": 217.0, "episode/score": 0.24917458437118967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24917458437118967}
{"step": 93664, "time": 4964.661408901215, "episode/length": 154.0, "episode/score": 0.16864335168259004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16864335168259004}
{"step": 93864, "time": 4973.470670223236, "episode/length": 155.0, "episode/score": 0.12102336619727794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12102336619727794}
{"step": 93928, "time": 4977.384908437729, "episode/length": 161.0, "episode/score": 0.17380669452427355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17380669452427355}
{"step": 93952, "time": 4980.038134336472, "episode/length": 181.0, "episode/score": 0.196621436121859, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.196621436121859}
{"step": 93976, "time": 4982.319110393524, "episode/length": 152.0, "episode/score": 0.15835815980142343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15835815980142343}
{"step": 94312, "time": 4996.449950456619, "episode/length": 164.0, "episode/score": 0.17589447603290864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17589447603290864}
{"step": 94432, "time": 5002.714404344559, "episode/length": 160.0, "episode/score": 0.17030952678476297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17030952678476297}
{"step": 94816, "time": 5018.671811342239, "episode/length": 143.0, "episode/score": 0.14049148023491398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14049148023491398}
{"step": 94848, "time": 5021.4558362960815, "episode/length": 157.0, "episode/score": 0.1705668312687294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1705668312687294}
{"step": 95408, "time": 5043.962084054947, "episode/length": 184.0, "episode/score": 0.19723210649863177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19723210649863177}
{"step": 95408, "time": 5043.970970869064, "episode/length": 192.0, "episode/score": 0.2036724813173123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2036724813173123}
{"step": 95616, "time": 5055.1502068042755, "episode/length": 162.0, "episode/score": 0.17846346732687834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17846346732687834}
{"step": 95656, "time": 5057.868387937546, "episode/length": 104.0, "episode/score": 0.12089844161528163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12089844161528163}
{"step": 95752, "time": 5062.921340227127, "episode/length": 224.0, "episode/score": 0.22963292603947139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22963292603947139}
{"step": 95864, "time": 5068.640143632889, "episode/length": 235.0, "episode/score": 0.2397517359692074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2397517359692074}
{"step": 95984, "time": 5074.904927968979, "episode/length": 141.0, "episode/score": 0.15827315814385656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15827315814385656}
{"step": 96208, "time": 5084.848785400391, "episode/length": 221.0, "episode/score": 0.22730126717976873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22730126717976873}
{"step": 96592, "time": 5100.720023870468, "episode/length": 147.0, "episode/score": 0.16041686593234772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16041686593234772}
{"step": 96696, "time": 5105.917233943939, "episode/length": 160.0, "episode/score": 0.153604286013433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.153604286013433}
{"step": 97056, "time": 5121.2193257808685, "episode/length": 179.0, "episode/score": 0.19252386975495028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19252386975495028}
{"step": 97112, "time": 5124.620891094208, "episode/length": 140.0, "episode/score": 0.1270881177042611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1270881177042611}
{"step": 97136, "time": 5127.280399084091, "episode/length": 184.0, "episode/score": 0.17019949411042035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17019949411042035}
{"step": 97176, "time": 5130.05845284462, "episode/length": 177.0, "episode/score": 0.19784138307295507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19784138307295507}
{"step": 97360, "time": 5138.879729986191, "episode/length": 143.0, "episode/score": 0.14410438491358946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14410438491358946}
{"step": 97368, "time": 5140.573265075684, "episode/length": 187.0, "episode/score": 0.20196301229225355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20196301229225355}
{"step": 97744, "time": 5156.308178186417, "episode/length": 143.0, "episode/score": 0.1594522049126681, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1594522049126681}
{"step": 97880, "time": 5162.626378059387, "episode/length": 147.0, "episode/score": 0.1488208576465695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1488208576465695}
{"step": 98120, "time": 5172.97869515419, "episode/length": 132.0, "episode/score": 0.1502553606769652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1502553606769652}
{"step": 98392, "time": 5185.871415376663, "episode/length": 151.0, "episode/score": 0.18192360748071223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18192360748071223}
{"step": 98408, "time": 5188.05038022995, "episode/length": 161.0, "episode/score": 0.15304596166788542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15304596166788542}
{"step": 98504, "time": 5193.068448781967, "episode/length": 170.0, "episode/score": 0.17328546975477366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17328546975477366}
{"step": 98808, "time": 5206.687048912048, "episode/length": 180.0, "episode/score": 0.17793951617568382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17793951617568382}
{"step": 98984, "time": 5214.848795890808, "episode/length": 154.0, "episode/score": 0.16903990589707973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16903990589707973}
{"step": 99056, "time": 5219.26118516922, "episode/length": 146.0, "episode/score": 0.16411518628592603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16411518628592603}
{"step": 99144, "time": 5223.763947486877, "episode/length": 221.0, "episode/score": 0.2346360052761156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2346360052761156}
{"step": 99208, "time": 5227.6691019535065, "episode/length": 135.0, "episode/score": 0.15807916363155528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15807916363155528}
{"step": 99272, "time": 5231.535361051559, "episode/length": 57.0, "episode/score": 0.06186120804250095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06186120804250095}
{"step": 99528, "time": 5242.723511457443, "episode/length": 141.0, "episode/score": 0.16309500798161025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16309500798161025}
{"step": 99736, "time": 5252.091675758362, "episode/length": 153.0, "episode/score": 0.15646112821923452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15646112821923452}
{"step": 100048, "time": 5282.613499879837, "eval_episode/length": 102.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.941747572815534}
{"step": 100048, "time": 5285.585162401199, "eval_episode/length": 138.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 100048, "time": 5288.008049249649, "eval_episode/length": 159.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.96875}
{"step": 100048, "time": 5289.763427257538, "eval_episode/length": 163.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 100048, "time": 5292.0706396102905, "eval_episode/length": 182.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.994535519125683}
{"step": 100048, "time": 5293.705523014069, "eval_episode/length": 184.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9621621621621622}
{"step": 100048, "time": 5295.625422000885, "eval_episode/length": 193.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 100048, "time": 5298.346496105194, "eval_episode/length": 222.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 100192, "time": 5303.707416534424, "episode/length": 222.0, "episode/score": 0.25672039143501024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25672039143501024}
{"step": 100265, "time": 5308.780896902084, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.34766748046875, "train/action_min": 0.0, "train/action_std": 4.7026625328063965, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004985515385866165, "train/actor_opt_grad_steps": 5550.0, "train/actor_opt_loss": -18.234199233531953, "train/adv_mag": 0.12769892370700836, "train/adv_max": 0.06683910143375396, "train/adv_mean": -0.0004513403680175543, "train/adv_min": -0.1275916370153427, "train/adv_std": 0.010268319293856621, "train/cont_avg": 0.9944140625, "train/cont_loss_mean": 0.0008783578355187274, "train/cont_loss_std": 0.02372669750536443, "train/cont_neg_acc": 0.976469844341278, "train/cont_neg_loss": 0.0846609478744823, "train/cont_pos_acc": 0.9999292702674866, "train/cont_pos_loss": 0.0004290534258457228, "train/cont_pred": 0.9943840856552124, "train/cont_rate": 0.9944140625, "train/dyn_loss_mean": 13.892567085266114, "train/dyn_loss_std": 7.3624374961853025, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17378380063176155, "train/extr_critic_critic_opt_grad_steps": 5550.0, "train/extr_critic_critic_opt_loss": 9951.7254296875, "train/extr_critic_mag": 0.25267567062377927, "train/extr_critic_max": 0.25267567062377927, "train/extr_critic_mean": 0.19187783527374266, "train/extr_critic_min": 0.03200551319122315, "train/extr_critic_std": 0.048137221038341525, "train/extr_return_normed_mag": 0.16410220658779145, "train/extr_return_normed_max": 0.16410220658779145, "train/extr_return_normed_mean": 0.10571663075685502, "train/extr_return_normed_min": -0.08411905109882355, "train/extr_return_normed_std": 0.049548570603132246, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.24981209075450897, "train/extr_return_raw_max": 0.24981209075450897, "train/extr_return_raw_mean": 0.1914265195131302, "train/extr_return_raw_min": 0.001590833306312561, "train/extr_return_raw_std": 0.049548570603132246, "train/extr_reward_mag": 0.0014055700302124023, "train/extr_reward_max": 0.0014055700302124023, "train/extr_reward_mean": 0.0010733548398129643, "train/extr_reward_min": 7.532119750976562e-06, "train/extr_reward_std": 0.0002481978286523372, "train/image_loss_mean": 13.359330047607422, "train/image_loss_std": 13.895263252258301, "train/model_loss_mean": 21.735073623657225, "train/model_loss_std": 16.643441368103026, "train/model_opt_grad_norm": 88.06339868164062, "train/model_opt_grad_steps": 5540.872, "train/model_opt_loss": 13076.00934375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 602.5, "train/policy_entropy_mag": 2.797862575531006, "train/policy_entropy_max": 2.797862575531006, "train/policy_entropy_mean": 2.333012529373169, "train/policy_entropy_min": 0.17103288275003434, "train/policy_entropy_std": 0.3868702430725098, "train/policy_logprob_mag": 7.215552803039551, "train/policy_logprob_max": -0.02463166218996048, "train/policy_logprob_mean": -2.3334456424713137, "train/policy_logprob_min": -7.215552803039551, "train/policy_logprob_std": 0.9839861640930175, "train/policy_randomness_mag": 0.9875227069854736, "train/policy_randomness_max": 0.9875227069854736, "train/policy_randomness_mean": 0.8234510402679444, "train/policy_randomness_min": 0.060367101967334746, "train/policy_randomness_std": 0.13654821795225144, "train/post_ent_mag": 50.57207653808594, "train/post_ent_max": 50.57207653808594, "train/post_ent_mean": 35.090835693359374, "train/post_ent_min": 17.317358169555664, "train/post_ent_std": 5.321794937133789, "train/prior_ent_mag": 61.84292077636719, "train/prior_ent_max": 61.84292077636719, "train/prior_ent_mean": 49.28239028930664, "train/prior_ent_min": 20.716379333496093, "train/prior_ent_std": 5.997936599731445, "train/rep_loss_mean": 13.892567085266114, "train/rep_loss_std": 7.3624374961853025, "train/reward_avg": 0.001037338181398809, "train/reward_loss_mean": 0.03932516571879387, "train/reward_loss_std": 0.012403291784226894, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013670482635498046, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03932516542077064, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001038790157996118, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.8017543709199679, "train_stats/max_log_achievement_collect_drink": 0.09649122807017543, "train_stats/max_log_achievement_collect_sapling": 0.6052631578947368, "train_stats/max_log_achievement_collect_wood": 0.4824561403508772, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.017543859649122806, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02631578947368421, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.40350877192982454, "train_stats/max_log_achievement_place_table": 0.08771929824561403, "train_stats/max_log_achievement_wake_up": 0.7105263157894737, "train_stats/mean_log_entropy": 2.3710325036132547, "eval_stats/sum_log_reward": 1.2874999684281647, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.6875, "eval_stats/max_log_achievement_collect_wood": 0.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5625, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.498173878644593e-05, "report/cont_loss_std": 0.0002560661523602903, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0021261379588395357, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.5387739697180223e-06, "report/cont_pred": 0.9941505193710327, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.816728591918945, "report/dyn_loss_std": 6.939363479614258, "report/image_loss_mean": 11.237146377563477, "report/image_loss_std": 14.180840492248535, "report/model_loss_mean": 18.968334197998047, "report/model_loss_std": 16.484704971313477, "report/post_ent_mag": 50.58701705932617, "report/post_ent_max": 50.58701705932617, "report/post_ent_mean": 36.16421127319336, "report/post_ent_min": 16.69757080078125, "report/post_ent_std": 5.872605323791504, "report/prior_ent_mag": 62.08702850341797, "report/prior_ent_max": 62.08702850341797, "report/prior_ent_mean": 49.4475212097168, "report/prior_ent_min": 21.025222778320312, "report/prior_ent_std": 6.687753200531006, "report/rep_loss_mean": 12.816728591918945, "report/rep_loss_std": 6.939363479614258, "report/reward_avg": 0.001090069068595767, "report/reward_loss_mean": 0.04113546386361122, "report/reward_loss_std": 0.010766105726361275, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012508630752563477, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04113546758890152, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010072779841721058, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.7977768948185258e-05, "eval/cont_loss_std": 0.0003303546109236777, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004309382289648056, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.368352958612377e-06, "eval/cont_pred": 0.9970775842666626, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.080774307250977, "eval/dyn_loss_std": 9.72854232788086, "eval/image_loss_mean": 19.946874618530273, "eval/image_loss_std": 22.209136962890625, "eval/model_loss_mean": 30.764244079589844, "eval/model_loss_std": 26.092802047729492, "eval/post_ent_mag": 46.985538482666016, "eval/post_ent_max": 46.985538482666016, "eval/post_ent_mean": 34.43417739868164, "eval/post_ent_min": 15.764809608459473, "eval/post_ent_std": 5.59429407119751, "eval/prior_ent_mag": 62.08702850341797, "eval/prior_ent_max": 62.08702850341797, "eval/prior_ent_mean": 46.948577880859375, "eval/prior_ent_min": 18.966522216796875, "eval/prior_ent_std": 8.696791648864746, "eval/rep_loss_mean": 17.080774307250977, "eval/rep_loss_std": 9.72854232788086, "eval/reward_avg": 0.01865234412252903, "eval/reward_loss_mean": 0.5688877105712891, "eval/reward_loss_std": 2.9677348136901855, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.001282811164855957, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.22313198447227478, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 16.31648826599121, "eval/reward_pred": 0.0008121333085000515, "eval/reward_rate": 0.021484375, "replay/size": 99761.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.3421671703839913e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.768282639674651e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 22576.0, "eval_replay/inserts": 3400.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1847299688002642e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.298214673996, "timer/env.step_count": 2496.0, "timer/env.step_total": 241.9645619392395, "timer/env.step_frac": 0.24189242606825745, "timer/env.step_avg": 0.09694093026411839, "timer/env.step_min": 0.022661685943603516, "timer/env.step_max": 3.4104807376861572, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 9.844382047653198, "timer/replay._sample_frac": 0.009841447183689666, "timer/replay._sample_avg": 0.0004930079150467347, "timer/replay._sample_min": 0.00034880638122558594, "timer/replay._sample_max": 0.011320114135742188, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2921.0, "timer/agent.policy_total": 47.13116002082825, "timer/agent.policy_frac": 0.047117109007525936, "timer/agent.policy_avg": 0.016135282444651917, "timer/agent.policy_min": 0.009474992752075195, "timer/agent.policy_max": 0.12156796455383301, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.1325211524963379, "timer/dataset_train_frac": 0.00013248164452590513, "timer/dataset_train_avg": 0.00010618682091052715, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.00032448768615722656, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 560.2226359844208, "timer/agent.train_frac": 0.5600556191805273, "timer/agent.train_avg": 0.4488963429362346, "timer/agent.train_min": 0.4360642433166504, "timer/agent.train_max": 0.8354082107543945, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48168373107910156, "timer/agent.report_frac": 0.00048154012874659143, "timer/agent.report_avg": 0.24084186553955078, "timer/agent.report_min": 0.2315657138824463, "timer/agent.report_max": 0.2501180171966553, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 6.270408630371094e-05, "timer/dataset_eval_frac": 6.268539259979247e-08, "timer/dataset_eval_avg": 6.270408630371094e-05, "timer/dataset_eval_min": 6.270408630371094e-05, "timer/dataset_eval_max": 6.270408630371094e-05, "fps": 19.961787389209363}
{"step": 100344, "time": 5311.6669754981995, "episode/length": 141.0, "episode/score": 0.13506732264340826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13506732264340826}
{"step": 100448, "time": 5317.46142745018, "episode/length": 182.0, "episode/score": 0.19053879256080108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19053879256080108}
{"step": 100584, "time": 5324.215210437775, "episode/length": 190.0, "episode/score": 0.21838491669041105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21838491669041105}
{"step": 100608, "time": 5326.919979810715, "episode/length": 166.0, "episode/score": 0.1892056222723113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1892056222723113}
{"step": 100640, "time": 5329.6043176651, "episode/length": 186.0, "episode/score": 0.1765957991929099, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1765957991929099}
{"step": 100904, "time": 5340.754721879959, "episode/length": 145.0, "episode/score": 0.14242025636758626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14242025636758626}
{"step": 101072, "time": 5348.8603591918945, "episode/length": 192.0, "episode/score": 0.2051956312971015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2051956312971015}
{"step": 101320, "time": 5359.386514425278, "episode/length": 140.0, "episode/score": 0.1547133815329289, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1547133815329289}
{"step": 101688, "time": 5374.8060665130615, "episode/length": 154.0, "episode/score": 0.17150375735218404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17150375735218404}
{"step": 101824, "time": 5381.776862621307, "episode/length": 154.0, "episode/score": 0.1614922009393922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1614922009393922}
{"step": 101840, "time": 5383.94130396843, "episode/length": 149.0, "episode/score": 0.16587574854202103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16587574854202103}
{"step": 102160, "time": 5397.416756391525, "episode/length": 156.0, "episode/score": 0.17615350038249744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17615350038249744}
{"step": 102176, "time": 5399.497082710266, "episode/length": 228.0, "episode/score": 0.2618155064628809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2618155064628809}
{"step": 102336, "time": 5407.124343395233, "episode/length": 157.0, "episode/score": 0.16143443900364218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16143443900364218}
{"step": 102344, "time": 5408.728443861008, "episode/length": 216.0, "episode/score": 0.22992262601474067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22992262601474067}
{"step": 102808, "time": 5428.037504911423, "episode/length": 139.0, "episode/score": 0.13626088502860512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13626088502860512}
{"step": 102816, "time": 5429.966350078583, "episode/length": 58.0, "episode/score": 0.06178262822504621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06178262822504621}
{"step": 103000, "time": 5438.3937203884125, "episode/length": 209.0, "episode/score": 0.21784682412908296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21784682412908296}
{"step": 103232, "time": 5449.541163444519, "episode/length": 173.0, "episode/score": 0.18655549839240848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18655549839240848}
{"step": 103264, "time": 5452.6998863220215, "episode/length": 179.0, "episode/score": 0.19791246558816056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19791246558816056}
{"step": 103400, "time": 5459.807834386826, "episode/length": 152.0, "episode/score": 0.14571168787733768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14571168787733768}
{"step": 103472, "time": 5464.66085934639, "episode/length": 163.0, "episode/score": 0.1884023302263813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1884023302263813}
{"step": 103912, "time": 5482.664124488831, "episode/length": 136.0, "episode/score": 0.14655004958876816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14655004958876816}
{"step": 104008, "time": 5487.902841091156, "episode/length": 208.0, "episode/score": 0.22732757235280587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22732757235280587}
{"step": 104352, "time": 5502.605874538422, "episode/length": 192.0, "episode/score": 0.19536665984196588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19536665984196588}
{"step": 104384, "time": 5505.342288732529, "episode/length": 139.0, "episode/score": 0.16089860458305338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16089860458305338}
{"step": 104528, "time": 5512.358084201813, "episode/length": 190.0, "episode/score": 0.20744695333087293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20744695333087293}
{"step": 104544, "time": 5514.455778598785, "episode/length": 142.0, "episode/score": 0.13827647634388995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13827647634388995}
{"step": 104560, "time": 5516.502538204193, "episode/length": 135.0, "episode/score": 0.13590744014800293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13590744014800293}
{"step": 104880, "time": 5530.164363861084, "episode/length": 205.0, "episode/score": 0.23974039442146022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23974039442146022}
{"step": 105424, "time": 5551.859761238098, "episode/length": 188.0, "episode/score": 0.18987103766812652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18987103766812652}
{"step": 105784, "time": 5566.818461179733, "episode/length": 156.0, "episode/score": 0.13649428394182905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13649428394182905}
{"step": 105840, "time": 5571.069436073303, "episode/length": 185.0, "episode/score": 0.17888116375706886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17888116375706886}
{"step": 105944, "time": 5576.2027759552, "episode/length": 241.0, "episode/score": 0.25694672674580943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25694672674580943}
{"step": 106008, "time": 5580.201951980591, "episode/length": 180.0, "episode/score": 0.1682258540940893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1682258540940893}
{"step": 106040, "time": 5582.8841507434845, "episode/length": 186.0, "episode/score": 0.2094763201321257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2094763201321257}
{"step": 106048, "time": 5584.9279754161835, "episode/length": 145.0, "episode/score": 0.15413470952353236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15413470952353236}
{"step": 106656, "time": 5610.490569353104, "episode/length": 283.0, "episode/score": 0.3139478034518106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3139478034518106}
{"step": 106992, "time": 5624.766370296478, "episode/length": 143.0, "episode/score": 0.11133978669386124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11133978669386124}
{"step": 107040, "time": 5628.099524497986, "episode/length": 201.0, "episode/score": 0.22567247761344333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22567247761344333}
{"step": 107280, "time": 5638.881226539612, "episode/length": 154.0, "episode/score": 0.16629887588896963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16629887588896963}
{"step": 107584, "time": 5652.532290697098, "episode/length": 224.0, "episode/score": 0.25307896385129425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25307896385129425}
{"step": 107608, "time": 5654.730958938599, "episode/length": 118.0, "episode/score": 0.12190711723542336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12190711723542336}
{"step": 107664, "time": 5658.591926574707, "episode/length": 214.0, "episode/score": 0.22078608827450807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22078608827450807}
{"step": 107752, "time": 5663.227846860886, "episode/length": 217.0, "episode/score": 0.23285276898604934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23285276898604934}
{"step": 107760, "time": 5665.272973537445, "episode/length": 213.0, "episode/score": 0.2347377303894973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2347377303894973}
{"step": 108208, "time": 5683.838507175446, "episode/length": 145.0, "episode/score": 0.14749920918256976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14749920918256976}
{"step": 108232, "time": 5686.602225065231, "episode/length": 70.0, "episode/score": 0.06972315787879779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06972315787879779}
{"step": 108656, "time": 5704.788976430893, "episode/length": 207.0, "episode/score": 0.2251867373524874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2251867373524874}
{"step": 109088, "time": 5722.715168476105, "episode/length": 225.0, "episode/score": 0.23338845779653639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23338845779653639}
{"step": 109128, "time": 5725.963703393936, "episode/length": 171.0, "episode/score": 0.18193813713014606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18193813713014606}
{"step": 109208, "time": 5730.880612850189, "episode/length": 199.0, "episode/score": 0.2112379640338986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2112379640338986}
{"step": 109312, "time": 5736.546948194504, "episode/length": 215.0, "episode/score": 0.24082211767108674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24082211767108674}
{"step": 109320, "time": 5738.453684329987, "episode/length": 135.0, "episode/score": 0.1588645804386033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1588645804386033}
{"step": 109536, "time": 5748.470055580139, "episode/length": 221.0, "episode/score": 0.2299350733665051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2299350733665051}
{"step": 110032, "time": 5787.737254619598, "eval_episode/length": 143.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 110032, "time": 5787.744906663895, "eval_episode/length": 143.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 110032, "time": 5790.981010913849, "eval_episode/length": 144.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.993103448275862}
{"step": 110032, "time": 5792.761349439621, "eval_episode/length": 150.0, "eval_episode/score": -0.8999999985098839, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 110032, "time": 5792.768925189972, "eval_episode/length": 150.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9536423841059603}
{"step": 110032, "time": 5796.54029917717, "eval_episode/length": 161.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 110032, "time": 5798.537101268768, "eval_episode/length": 170.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 110032, "time": 5800.407689571381, "eval_episode/length": 181.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 110080, "time": 5802.210169315338, "episode/length": 233.0, "episode/score": 0.24435551588021553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24435551588021553}
{"step": 110136, "time": 5805.593413352966, "episode/length": 184.0, "episode/score": 0.1800843350752075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1800843350752075}
{"step": 110184, "time": 5808.883494377136, "episode/length": 136.0, "episode/score": 0.14339949270015495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14339949270015495}
{"step": 110224, "time": 5812.054049253464, "episode/length": 112.0, "episode/score": 0.13045025776136754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13045025776136754}
{"step": 110456, "time": 5822.086779356003, "episode/length": 142.0, "episode/score": 0.15363806590721651, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15363806590721651}
{"step": 110656, "time": 5831.327011823654, "episode/length": 64.0, "episode/score": 0.06761219397458262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06761219397458262}
{"step": 110688, "time": 5834.003510475159, "episode/length": 143.0, "episode/score": 0.14305537348900543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14305537348900543}
{"step": 110968, "time": 5845.639261722565, "episode/length": 229.0, "episode/score": 0.26388141376855856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26388141376855856}
{"step": 111216, "time": 5856.477021694183, "episode/length": 250.0, "episode/score": 0.25174747698793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25174747698793}
{"step": 111448, "time": 5866.497602462769, "episode/length": 170.0, "episode/score": 0.18096617119681468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18096617119681468}
{"step": 111800, "time": 5881.4869520664215, "episode/length": 201.0, "episode/score": 0.22403306349588092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22403306349588092}
{"step": 111968, "time": 5890.133429765701, "episode/length": 159.0, "episode/score": 0.15627208597243225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15627208597243225}
{"step": 111984, "time": 5892.227150440216, "episode/length": 190.0, "episode/score": 0.2050273334252779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2050273334252779}
{"step": 112040, "time": 5895.618501901627, "episode/length": 172.0, "episode/score": 0.16666162334286128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16666162334286128}
{"step": 112264, "time": 5905.416331768036, "episode/length": 254.0, "episode/score": 0.27786917533285305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27786917533285305}
{"step": 112272, "time": 5907.4866309165955, "episode/length": 162.0, "episode/score": 0.16889685437945445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16889685437945445}
{"step": 112664, "time": 5923.450070619583, "episode/length": 151.0, "episode/score": 0.15662584213623632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15662584213623632}
{"step": 112680, "time": 5925.636606931686, "episode/length": 182.0, "episode/score": 0.18364895141894522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18364895141894522}
{"step": 113168, "time": 5945.613921165466, "episode/length": 140.0, "episode/score": 0.14878226989139876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14878226989139876}
{"step": 113256, "time": 5950.373962163925, "episode/length": 181.0, "episode/score": 0.1833060150302117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1833060150302117}
{"step": 113344, "time": 5955.355934619904, "episode/length": 171.0, "episode/score": 0.18439657361295758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18439657361295758}
{"step": 113352, "time": 5956.902590513229, "episode/length": 170.0, "episode/score": 0.17310720044361005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17310720044361005}
{"step": 113456, "time": 5962.5801594257355, "episode/length": 148.0, "episode/score": 0.13963411653548974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13963411653548974}
{"step": 113840, "time": 5978.514656543732, "episode/length": 47.0, "episode/score": 0.044391211516085605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044391211516085605}
{"step": 114024, "time": 5986.782113313675, "episode/length": 218.0, "episode/score": 0.24114131018177432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24114131018177432}
{"step": 114208, "time": 5995.416975021362, "episode/length": 192.0, "episode/score": 0.23043662242025675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23043662242025675}
{"step": 114248, "time": 5998.2447991371155, "episode/length": 195.0, "episode/score": 0.18966042310103148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18966042310103148}
{"step": 114528, "time": 6010.647629499435, "episode/length": 169.0, "episode/score": 0.1763317683171408, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1763317683171408}
{"step": 114624, "time": 6015.723489284515, "episode/length": 159.0, "episode/score": 0.15475152768613043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15475152768613043}
{"step": 114776, "time": 6024.087473392487, "episode/length": 189.0, "episode/score": 0.19341657050927097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19341657050927097}
{"step": 114840, "time": 6027.925754785538, "episode/length": 185.0, "episode/score": 0.19908908482057086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19908908482057086}
{"step": 115016, "time": 6036.012636423111, "episode/length": 146.0, "episode/score": 0.1505117284445987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1505117284445987}
{"step": 115080, "time": 6040.059758424759, "episode/length": 37.0, "episode/score": 0.04438316899177153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04438316899177153}
{"step": 115376, "time": 6052.763853788376, "episode/length": 145.0, "episode/score": 0.13916887040522852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13916887040522852}
{"step": 115472, "time": 6057.969080924988, "episode/length": 152.0, "episode/score": 0.13890404636367748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13890404636367748}
{"step": 115560, "time": 6062.473965883255, "episode/length": 191.0, "episode/score": 0.2006001904023833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2006001904023833}
{"step": 115832, "time": 6074.3419642448425, "episode/length": 150.0, "episode/score": 0.1473215817459277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1473215817459277}
{"step": 115888, "time": 6078.247940778732, "episode/length": 169.0, "episode/score": 0.1799810232478194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1799810232478194}
{"step": 116440, "time": 6100.458596229553, "episode/length": 177.0, "episode/score": 0.198766387271462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.198766387271462}
{"step": 116600, "time": 6108.048942089081, "episode/length": 189.0, "episode/score": 0.20223313186579617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20223313186579617}
{"step": 116648, "time": 6111.350993394852, "episode/length": 146.0, "episode/score": 0.1424380153985112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1424380153985112}
{"step": 116696, "time": 6114.69322013855, "episode/length": 231.0, "episode/score": 0.2575413725935505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2575413725935505}
{"step": 116744, "time": 6117.91507267952, "episode/length": 147.0, "episode/score": 0.16315765049876063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16315765049876063}
{"step": 116824, "time": 6122.8377430438995, "episode/length": 180.0, "episode/score": 0.19365431074766093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19365431074766093}
{"step": 117008, "time": 6132.008452653885, "episode/length": 139.0, "episode/score": 0.14818015874698176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14818015874698176}
{"step": 117200, "time": 6140.732407808304, "episode/length": 170.0, "episode/score": 0.16149519302052795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16149519302052795}
{"step": 117472, "time": 6152.449666023254, "episode/length": 128.0, "episode/score": 0.11047349664113426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11047349664113426}
{"step": 117936, "time": 6171.356876850128, "episode/length": 166.0, "episode/score": 0.17931070573649777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17931070573649777}
{"step": 118176, "time": 6181.792812585831, "episode/length": 145.0, "episode/score": 0.16392365141837217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16392365141837217}
{"step": 118200, "time": 6184.05494093895, "episode/length": 181.0, "episode/score": 0.18634659131930675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18634659131930675}
{"step": 118208, "time": 6186.09260892868, "episode/length": 194.0, "episode/score": 0.22527380535029806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22527380535029806}
{"step": 118312, "time": 6191.22993016243, "episode/length": 201.0, "episode/score": 0.21831027180815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21831027180815}
{"step": 118472, "time": 6198.6542110443115, "episode/length": 205.0, "episode/score": 0.20379663345556764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20379663345556764}
{"step": 118872, "time": 6215.204082489014, "episode/length": 208.0, "episode/score": 0.2178024808272312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2178024808272312}
{"step": 119200, "time": 6229.551770687103, "episode/length": 215.0, "episode/score": 0.2390614841642673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2390614841642673}
{"step": 119312, "time": 6235.661830663681, "episode/length": 171.0, "episode/score": 0.15527356484017218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15527356484017218}
{"step": 119344, "time": 6238.327660560608, "episode/length": 142.0, "episode/score": 0.14829482417644613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14829482417644613}
{"step": 119440, "time": 6243.353226184845, "episode/length": 140.0, "episode/score": 0.13565020367241232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13565020367241232}
{"step": 119832, "time": 6259.281111717224, "episode/length": 202.0, "episode/score": 0.2103282719554045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2103282719554045}
{"step": 119864, "time": 6261.984975814819, "episode/length": 210.0, "episode/score": 0.22734180825318617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22734180825318617}
{"step": 119984, "time": 6268.210991382599, "episode/length": 138.0, "episode/score": 0.15211888140402152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15211888140402152}
{"step": 120016, "time": 6288.347017526627, "eval_episode/length": 81.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.926829268292683}
{"step": 120016, "time": 6292.788754701614, "eval_episode/length": 139.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 120016, "time": 6295.249459266663, "eval_episode/length": 161.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 120016, "time": 6297.609076023102, "eval_episode/length": 180.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.994475138121547}
{"step": 120016, "time": 6299.817773103714, "eval_episode/length": 195.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 120016, "time": 6302.448992967606, "eval_episode/length": 220.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9683257918552036}
{"step": 120016, "time": 6304.053285598755, "eval_episode/length": 225.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9823008849557522}
{"step": 120016, "time": 6305.985169887543, "eval_episode/length": 153.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 120016, "time": 6305.9933025836945, "eval_episode/length": 235.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 120073, "time": 6308.965711116791, "train_stats/sum_log_reward": 0.5655172297666813, "train_stats/max_log_achievement_collect_drink": 0.06896551724137931, "train_stats/max_log_achievement_collect_sapling": 0.45689655172413796, "train_stats/max_log_achievement_collect_wood": 0.45689655172413796, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.017241379310344827, "train_stats/max_log_achievement_make_wood_sword": 0.008620689655172414, "train_stats/max_log_achievement_place_plant": 0.35344827586206895, "train_stats/max_log_achievement_place_table": 0.06896551724137931, "train_stats/max_log_achievement_wake_up": 0.3706896551724138, "train_stats/mean_log_entropy": 2.379358012100746, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.761237912061738, "train/action_min": 0.0, "train/action_std": 4.696105588742388, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00499235104194017, "train/actor_opt_grad_steps": 6790.0, "train/actor_opt_loss": -18.529856177970647, "train/adv_mag": 0.12539059208418296, "train/adv_max": 0.0725194024361246, "train/adv_mean": -0.0005096531487681678, "train/adv_min": -0.12529548009236655, "train/adv_std": 0.010534157491917533, "train/cont_avg": 0.9944502667682927, "train/cont_loss_mean": 0.0005144204487916751, "train/cont_loss_std": 0.01480637374772887, "train/cont_neg_acc": 0.9839298943193947, "train/cont_neg_loss": 0.0656703568810782, "train/cont_pos_acc": 0.9999360975211229, "train/cont_pos_loss": 0.00015130327602413095, "train/cont_pred": 0.9944786332487091, "train/cont_rate": 0.9944502667682927, "train/dyn_loss_mean": 13.385751383091376, "train/dyn_loss_std": 7.668290471642967, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.20352499801816978, "train/extr_critic_critic_opt_grad_steps": 6790.0, "train/extr_critic_critic_opt_loss": 9051.979579522358, "train/extr_critic_mag": 0.24483309044101373, "train/extr_critic_max": 0.24483309044101373, "train/extr_critic_mean": 0.18204885163927467, "train/extr_critic_min": 0.014595830343603119, "train/extr_critic_std": 0.051097608951291416, "train/extr_return_normed_mag": 0.17827270488913466, "train/extr_return_normed_max": 0.17827270488913466, "train/extr_return_normed_mean": 0.11763001112191658, "train/extr_return_normed_min": -0.06289079970097154, "train/extr_return_normed_std": 0.05262527863184611, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.24218190467454553, "train/extr_return_raw_max": 0.24218190467454553, "train/extr_return_raw_mean": 0.18153921484462615, "train/extr_return_raw_min": 0.0010184001147262448, "train/extr_return_raw_std": 0.052625278813567586, "train/extr_reward_mag": 0.0013593251143044572, "train/extr_reward_max": 0.0013593251143044572, "train/extr_reward_mean": 0.0010719024169266345, "train/extr_reward_min": 7.775740894844862e-06, "train/extr_reward_std": 0.0002468830720820593, "train/image_loss_mean": 10.447541915304292, "train/image_loss_std": 11.888468750124055, "train/model_loss_mean": 18.518647604841526, "train/model_loss_std": 14.816735120323616, "train/model_opt_grad_norm": 80.04544495373237, "train/model_opt_grad_steps": 6779.829268292683, "train/model_opt_loss": 13221.357961763211, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 716.4634146341464, "train/policy_entropy_mag": 2.774470393250628, "train/policy_entropy_max": 2.774470393250628, "train/policy_entropy_mean": 2.3296978938870314, "train/policy_entropy_min": 0.19622932229100204, "train/policy_entropy_std": 0.3650220530789073, "train/policy_logprob_mag": 7.375438577760526, "train/policy_logprob_max": -0.02961461852509074, "train/policy_logprob_mean": -2.330161835119976, "train/policy_logprob_min": -7.375438577760526, "train/policy_logprob_std": 0.9532376455097664, "train/policy_randomness_mag": 0.9792662946189322, "train/policy_randomness_max": 0.9792662946189322, "train/policy_randomness_mean": 0.8222811348069974, "train/policy_randomness_min": 0.06926033926022247, "train/policy_randomness_std": 0.12883676509789335, "train/post_ent_mag": 52.233390404926084, "train/post_ent_max": 52.233390404926084, "train/post_ent_mean": 35.53896927252048, "train/post_ent_min": 17.52679385208502, "train/post_ent_std": 5.691890228085402, "train/prior_ent_mag": 62.93570284339471, "train/prior_ent_max": 62.93570284339471, "train/prior_ent_mean": 49.15131976740147, "train/prior_ent_min": 21.09182181009432, "train/prior_ent_std": 6.3023706839336615, "train/rep_loss_mean": 13.385751383091376, "train/rep_loss_std": 7.668290471642967, "train/reward_avg": 0.0010327681065234167, "train/reward_loss_mean": 0.03914054710327125, "train/reward_loss_std": 0.012514702642593927, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001323394659088879, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03914054740614038, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001032306949941184, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.5705882091732586, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.17647058823529413, "eval_stats/max_log_achievement_collect_wood": 1.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.058823529411764705, "eval_stats/max_log_achievement_place_table": 0.23529411764705882, "eval_stats/max_log_achievement_wake_up": 0.4117647058823529, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.0017217438435181975, "report/cont_loss_std": 0.05429546907544136, "report/cont_neg_acc": 0.875, "report/cont_neg_loss": 0.21729931235313416, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.4282666345243342e-05, "report/cont_pred": 0.9929684400558472, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 13.724124908447266, "report/dyn_loss_std": 7.241020679473877, "report/image_loss_mean": 7.264211654663086, "report/image_loss_std": 9.848979949951172, "report/model_loss_mean": 15.53958797454834, "report/model_loss_std": 12.589822769165039, "report/post_ent_mag": 52.491424560546875, "report/post_ent_max": 52.491424560546875, "report/post_ent_mean": 33.55912780761719, "report/post_ent_min": 18.625417709350586, "report/post_ent_std": 4.8239521980285645, "report/prior_ent_mag": 63.64411544799805, "report/prior_ent_max": 63.64411544799805, "report/prior_ent_mean": 47.96284866333008, "report/prior_ent_min": 19.978168487548828, "report/prior_ent_std": 6.278013229370117, "report/rep_loss_mean": 13.724124908447266, "report/rep_loss_std": 7.241020679473877, "report/reward_avg": 0.0010335496626794338, "report/reward_loss_mean": 0.03917919844388962, "report/reward_loss_std": 0.012506121769547462, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013129711151123047, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.039179202169179916, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010517907794564962, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.009087648242712021, "eval/cont_loss_std": 0.15224622189998627, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 0.46528416872024536, "eval/cont_pos_acc": 0.9970616698265076, "eval/cont_pos_loss": 0.007747206836938858, "eval/cont_pred": 0.9950761795043945, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.91336441040039, "eval/dyn_loss_std": 9.338455200195312, "eval/image_loss_mean": 18.738975524902344, "eval/image_loss_std": 20.35346794128418, "eval/model_loss_mean": 29.514524459838867, "eval/model_loss_std": 24.130905151367188, "eval/post_ent_mag": 52.29753875732422, "eval/post_ent_max": 52.29753875732422, "eval/post_ent_mean": 35.61314392089844, "eval/post_ent_min": 16.2587833404541, "eval/post_ent_std": 5.767242908477783, "eval/prior_ent_mag": 63.64411544799805, "eval/prior_ent_max": 63.64411544799805, "eval/prior_ent_mean": 49.48741912841797, "eval/prior_ent_min": 19.108932495117188, "eval/prior_ent_std": 7.958669185638428, "eval/rep_loss_mean": 16.91336441040039, "eval/rep_loss_std": 9.338455200195312, "eval/reward_avg": 0.012792968191206455, "eval/reward_loss_mean": 0.6184412240982056, "eval/reward_loss_std": 3.11989426612854, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013283491134643555, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.34223172068595886, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 16.979787826538086, "eval/reward_pred": 0.0009716093773022294, "eval/reward_rate": 0.0166015625, "replay/size": 119569.0, "replay/inserts": 19808.0, "replay/samples": 19808.0, "replay/insert_wait_avg": 1.3461237192539099e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.200934707444396e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 25920.0, "eval_replay/inserts": 3344.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2296666368913422e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1733524799347, "timer/env.step_count": 2476.0, "timer/env.step_total": 245.29163718223572, "timer/env.step_frac": 0.2452491226386245, "timer/env.step_avg": 0.09906770483935207, "timer/env.step_min": 0.02242302894592285, "timer/env.step_max": 2.093606948852539, "timer/replay._sample_count": 19808.0, "timer/replay._sample_total": 9.810752868652344, "timer/replay._sample_frac": 0.00980905244508518, "timer/replay._sample_avg": 0.0004952924509618509, "timer/replay._sample_min": 0.000354766845703125, "timer/replay._sample_max": 0.011105060577392578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2894.0, "timer/agent.policy_total": 48.8669056892395, "timer/agent.policy_frac": 0.04885843595820042, "timer/agent.policy_avg": 0.016885592843552004, "timer/agent.policy_min": 0.009671688079833984, "timer/agent.policy_max": 0.6244392395019531, "timer/dataset_train_count": 1238.0, "timer/dataset_train_total": 0.1382288932800293, "timer/dataset_train_frac": 0.00013820493511178847, "timer/dataset_train_avg": 0.00011165500264945824, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0004665851593017578, "timer/agent.train_count": 1238.0, "timer/agent.train_total": 558.2004175186157, "timer/agent.train_frac": 0.5581036688635576, "timer/agent.train_avg": 0.4508888671394311, "timer/agent.train_min": 0.4377171993255615, "timer/agent.train_max": 0.8799426555633545, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47290921211242676, "timer/agent.report_frac": 0.0004728272463366936, "timer/agent.report_avg": 0.23645460605621338, "timer/agent.report_min": 0.22459626197814941, "timer/agent.report_max": 0.24831295013427734, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.0989043255703945e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 19.804329660563617}
{"step": 120328, "time": 6318.2910368442535, "episode/length": 231.0, "episode/score": 0.23738262719052727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23738262719052727}
{"step": 120368, "time": 6321.553527355194, "episode/length": 145.0, "episode/score": 0.16502380682504736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16502380682504736}
{"step": 120448, "time": 6326.112424135208, "episode/length": 125.0, "episode/score": 0.12931146023129259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12931146023129259}
{"step": 120552, "time": 6331.217547178268, "episode/length": 70.0, "episode/score": 0.08604166482109576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08604166482109576}
{"step": 120584, "time": 6333.921748161316, "episode/length": 154.0, "episode/score": 0.15818376076003915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15818376076003915}
{"step": 120728, "time": 6340.817940235138, "episode/length": 44.0, "episode/score": 0.047298246252466924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047298246252466924}
{"step": 121184, "time": 6359.598794460297, "episode/length": 233.0, "episode/score": 0.25485121338624595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25485121338624595}
{"step": 121304, "time": 6365.337286949158, "episode/length": 179.0, "episode/score": 0.17351466297805018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17351466297805018}
{"step": 121424, "time": 6371.597712278366, "episode/length": 198.0, "episode/score": 0.20026554401465546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20026554401465546}
{"step": 121688, "time": 6382.655278921127, "episode/length": 137.0, "episode/score": 0.1381483374216259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1381483374216259}
{"step": 121784, "time": 6387.708660364151, "episode/length": 181.0, "episode/score": 0.19173378600771684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19173378600771684}
{"step": 121848, "time": 6391.671432256699, "episode/length": 174.0, "episode/score": 0.20317266125039168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20317266125039168}
{"step": 122008, "time": 6399.263630390167, "episode/length": 181.0, "episode/score": 0.18094503852626076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18094503852626076}
{"step": 122192, "time": 6407.992054700851, "episode/length": 182.0, "episode/score": 0.16749844401692826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16749844401692826}
{"step": 122280, "time": 6412.527398586273, "episode/length": 136.0, "episode/score": 0.12449655677937699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12449655677937699}
{"step": 122592, "time": 6425.9989268779755, "episode/length": 160.0, "episode/score": 0.1497258207446066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1497258207446066}
{"step": 122648, "time": 6429.998945236206, "episode/length": 152.0, "episode/score": 0.1694657917096265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1694657917096265}
{"step": 123040, "time": 6448.094084739685, "episode/length": 94.0, "episode/score": 0.1109613073640503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1109613073640503}
{"step": 123048, "time": 6449.722390413284, "episode/length": 169.0, "episode/score": 0.19636706000892445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19636706000892445}
{"step": 123080, "time": 6452.41986656189, "episode/length": 153.0, "episode/score": 0.15353419827897596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15353419827897596}
{"step": 123312, "time": 6462.895963668823, "episode/length": 190.0, "episode/score": 0.20527382234013203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20527382234013203}
{"step": 123488, "time": 6470.980493307114, "episode/length": 161.0, "episode/score": 0.1899099616566673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1899099616566673}
{"step": 124016, "time": 6492.362465620041, "episode/length": 250.0, "episode/score": 0.27731381106332265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27731381106332265}
{"step": 124176, "time": 6499.979937553406, "episode/length": 141.0, "episode/score": 0.13880114888024764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13880114888024764}
{"step": 124184, "time": 6502.002514600754, "episode/length": 191.0, "episode/score": 0.19282017176828958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19282017176828958}
{"step": 124240, "time": 6506.376400947571, "episode/length": 205.0, "episode/score": 0.21829956807596318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21829956807596318}
{"step": 124336, "time": 6511.485998630524, "episode/length": 156.0, "episode/score": 0.14851600180963942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14851600180963942}
{"step": 124352, "time": 6513.556882143021, "episode/length": 162.0, "episode/score": 0.17498832158480582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17498832158480582}
{"step": 124432, "time": 6518.079967737198, "episode/length": 139.0, "episode/score": 0.13542621229862561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13542621229862561}
{"step": 124920, "time": 6537.82719373703, "episode/length": 178.0, "episode/score": 0.20031193360273392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20031193360273392}
{"step": 125448, "time": 6559.610313415527, "episode/length": 178.0, "episode/score": 0.183697057208974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.183697057208974}
{"step": 125480, "time": 6562.694716215134, "episode/length": 154.0, "episode/score": 0.15900765750029677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15900765750029677}
{"step": 125496, "time": 6564.845683097839, "episode/length": 164.0, "episode/score": 0.14628401106165256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14628401106165256}
{"step": 125504, "time": 6566.8460965156555, "episode/length": 145.0, "episode/score": 0.16034572015269077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16034572015269077}
{"step": 125664, "time": 6574.26215004921, "episode/length": 184.0, "episode/score": 0.19915110552801707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19915110552801707}
{"step": 125920, "time": 6585.432446241379, "episode/length": 185.0, "episode/score": 0.18180692693385936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18180692693385936}
{"step": 126160, "time": 6596.00674200058, "episode/length": 225.0, "episode/score": 0.23874942449856462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23874942449856462}
{"step": 126384, "time": 6605.837367773056, "episode/length": 182.0, "episode/score": 0.2157589528310382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2157589528310382}
{"step": 126696, "time": 6618.931307792664, "episode/length": 149.0, "episode/score": 0.15728926778319874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15728926778319874}
{"step": 126792, "time": 6624.054482460022, "episode/length": 163.0, "episode/score": 0.13079322508747282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13079322508747282}
{"step": 126888, "time": 6629.239310741425, "episode/length": 172.0, "episode/score": 0.1835508870826743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1835508870826743}
{"step": 127000, "time": 6634.966455936432, "episode/length": 166.0, "episode/score": 0.16905915081360945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16905915081360945}
{"step": 127224, "time": 6644.968896389008, "episode/length": 221.0, "episode/score": 0.24530160035646986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24530160035646986}
{"step": 127352, "time": 6651.31885933876, "episode/length": 148.0, "episode/score": 0.15069801934032512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15069801934032512}
{"step": 127624, "time": 6663.024863958359, "episode/length": 154.0, "episode/score": 0.16652270600616248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16652270600616248}
{"step": 128152, "time": 6684.607784509659, "episode/length": 143.0, "episode/score": 0.15353362888617994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15353362888617994}
{"step": 128160, "time": 6686.756891965866, "episode/length": 158.0, "episode/score": 0.1781637315257285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1781637315257285}
{"step": 128312, "time": 6693.713493824005, "episode/length": 189.0, "episode/score": 0.18900649746910858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18900649746910858}
{"step": 128472, "time": 6701.383777618408, "episode/length": 139.0, "episode/score": 0.13641921875159824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13641921875159824}
{"step": 128520, "time": 6704.627712488174, "episode/length": 227.0, "episode/score": 0.2436530522772955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2436530522772955}
{"step": 128624, "time": 6710.200348854065, "episode/length": 174.0, "episode/score": 0.17097358292721765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17097358292721765}
{"step": 128720, "time": 6715.2745814323425, "episode/length": 349.0, "episode/score": 0.3586887523965743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3586887523965743}
{"step": 129440, "time": 6743.679663896561, "episode/length": 226.0, "episode/score": 0.2473702157876687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2473702157876687}
{"step": 129648, "time": 6753.141452074051, "episode/length": 146.0, "episode/score": 0.16614830266917124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16614830266917124}
{"step": 129704, "time": 6756.445250272751, "episode/length": 173.0, "episode/score": 0.1911743180025951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1911743180025951}
{"step": 129704, "time": 6756.455690860748, "episode/length": 147.0, "episode/score": 0.15478497197909746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15478497197909746}
{"step": 129704, "time": 6756.46514081955, "episode/length": 192.0, "episode/score": 0.2051175855958718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2051175855958718}
{"step": 129960, "time": 6771.907764196396, "episode/length": 154.0, "episode/score": 0.17234515316522447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17234515316522447}
{"step": 130000, "time": 6791.223667621613, "eval_episode/length": 89.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9444444444444444}
{"step": 130000, "time": 6794.842379808426, "eval_episode/length": 142.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.993006993006993}
{"step": 130000, "time": 6796.385405540466, "eval_episode/length": 143.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 130000, "time": 6797.981477737427, "eval_episode/length": 146.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 130000, "time": 6799.794418334961, "eval_episode/length": 153.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 130000, "time": 6801.649893760681, "eval_episode/length": 163.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 130000, "time": 6805.542172431946, "eval_episode/length": 220.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9773755656108597}
{"step": 130000, "time": 6808.1209716796875, "eval_episode/length": 157.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 130008, "time": 6808.20227098465, "episode/length": 231.0, "episode/score": 0.24933006030187244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24933006030187244}
{"step": 130128, "time": 6814.518368959427, "episode/length": 187.0, "episode/score": 0.16875404646634706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16875404646634706}
{"step": 130824, "time": 6842.394376993179, "episode/length": 139.0, "episode/score": 0.14427645352043328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14427645352043328}
{"step": 130824, "time": 6842.4017877578735, "episode/length": 139.0, "episode/score": 0.14730394305297523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14730394305297523}
{"step": 130920, "time": 6849.334424257278, "episode/length": 158.0, "episode/score": 0.1744489813427208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1744489813427208}
{"step": 131272, "time": 6865.234111070633, "episode/length": 228.0, "episode/score": 0.26224819008348277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26224819008348277}
{"step": 131408, "time": 6872.1864058971405, "episode/length": 212.0, "episode/score": 0.2124816424548044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2124816424548044}
{"step": 131704, "time": 6884.834273815155, "episode/length": 211.0, "episode/score": 0.21635824206350662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21635824206350662}
{"step": 131776, "time": 6889.2868502140045, "episode/length": 226.0, "episode/score": 0.24845095574346487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24845095574346487}
{"step": 132008, "time": 6899.429824829102, "episode/length": 234.0, "episode/score": 0.27535416156752035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27535416156752035}
{"step": 132144, "time": 6906.174859762192, "episode/length": 152.0, "episode/score": 0.1513488456421328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1513488456421328}
{"step": 132184, "time": 6909.070233345032, "episode/length": 169.0, "episode/score": 0.1983659351553797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1983659351553797}
{"step": 132552, "time": 6924.25081205368, "episode/length": 215.0, "episode/score": 0.2635801227406773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2635801227406773}
{"step": 132624, "time": 6928.7651517391205, "episode/length": 168.0, "episode/score": 0.18443244508307544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18443244508307544}
{"step": 132768, "time": 6935.689389228821, "episode/length": 169.0, "episode/score": 0.1971884022004815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1971884022004815}
{"step": 132912, "time": 6942.747113704681, "episode/length": 150.0, "episode/score": 0.14695568740171439, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14695568740171439}
{"step": 133016, "time": 6947.909467935562, "episode/length": 154.0, "episode/score": 0.16451626168236544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16451626168236544}
{"step": 133656, "time": 6973.544821500778, "episode/length": 183.0, "episode/score": 0.18952059692310286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18952059692310286}
{"step": 133792, "time": 6980.449152231216, "episode/length": 154.0, "episode/score": 0.16860647842077015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16860647842077015}
{"step": 133872, "time": 6984.907789230347, "episode/length": 215.0, "episode/score": 0.22620089459633164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22620089459633164}
{"step": 133888, "time": 6986.966856241226, "episode/length": 234.0, "episode/score": 0.2563302441740234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2563302441740234}
{"step": 134000, "time": 6992.738966226578, "episode/length": 171.0, "episode/score": 0.18631035883390723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18631035883390723}
{"step": 134040, "time": 6995.60617518425, "episode/length": 158.0, "episode/score": 0.17101516980801534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17101516980801534}
{"step": 134072, "time": 6998.507754802704, "episode/length": 144.0, "episode/score": 0.1543897140527406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1543897140527406}
{"step": 134136, "time": 7002.375016212463, "episode/length": 139.0, "episode/score": 0.1627013091938352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1627013091938352}
{"step": 135000, "time": 7036.244271278381, "episode/length": 138.0, "episode/score": 0.15195180174669076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15195180174669076}
{"step": 135008, "time": 7038.291194677353, "episode/length": 120.0, "episode/score": 0.14563651780281361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14563651780281361}
{"step": 135152, "time": 7045.231561422348, "episode/length": 186.0, "episode/score": 0.19687448542481434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19687448542481434}
{"step": 135152, "time": 7045.239861965179, "episode/length": 143.0, "episode/score": 0.15833479414231988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15833479414231988}
{"step": 135336, "time": 7055.169059753418, "episode/length": 157.0, "episode/score": 0.15646067572197353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15646067572197353}
{"step": 135432, "time": 7060.341584682465, "episode/length": 204.0, "episode/score": 0.21260878028078878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21260878028078878}
{"step": 135448, "time": 7062.437146663666, "episode/length": 163.0, "episode/score": 0.19751141157667007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19751141157667007}
{"step": 135480, "time": 7065.408469438553, "episode/length": 200.0, "episode/score": 0.2037936019787594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2037936019787594}
{"step": 136064, "time": 7089.337419271469, "episode/length": 72.0, "episode/score": 0.07999433256554767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07999433256554767}
{"step": 136312, "time": 7099.850766420364, "episode/length": 144.0, "episode/score": 0.14922734716492414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14922734716492414}
{"step": 136376, "time": 7103.738425016403, "episode/length": 170.0, "episode/score": 0.19581349909549317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19581349909549317}
{"step": 136488, "time": 7109.517548561096, "episode/length": 185.0, "episode/score": 0.21582529522402183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21582529522402183}
{"step": 136496, "time": 7111.578419685364, "episode/length": 132.0, "episode/score": 0.160499996796716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.160499996796716}
{"step": 136608, "time": 7117.422692775726, "episode/length": 144.0, "episode/score": 0.13526691276092606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13526691276092606}
{"step": 136744, "time": 7123.905883312225, "episode/length": 175.0, "episode/score": 0.1844430257615386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1844430257615386}
{"step": 137112, "time": 7139.147950172424, "episode/length": 244.0, "episode/score": 0.26596877322390355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26596877322390355}
{"step": 137320, "time": 7148.481285333633, "episode/length": 156.0, "episode/score": 0.15976481462075753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15976481462075753}
{"step": 137624, "time": 7161.340433835983, "episode/length": 141.0, "episode/score": 0.12066533039069327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12066533039069327}
{"step": 137704, "time": 7165.809944152832, "episode/length": 136.0, "episode/score": 0.12824804764932196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12824804764932196}
{"step": 137792, "time": 7170.930300474167, "episode/length": 184.0, "episode/score": 0.1964732390251811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1964732390251811}
{"step": 138088, "time": 7183.420067310333, "episode/length": 167.0, "episode/score": 0.16154524399553338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16154524399553338}
{"step": 138128, "time": 7186.7408452034, "episode/length": 218.0, "episode/score": 0.25654463793034665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25654463793034665}
{"step": 138192, "time": 7190.71506690979, "episode/length": 211.0, "episode/score": 0.216968330149939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.216968330149939}
{"step": 138448, "time": 7201.78489613533, "episode/length": 166.0, "episode/score": 0.15516129322986671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15516129322986671}
{"step": 138464, "time": 7204.052323102951, "episode/length": 104.0, "episode/score": 0.12833333073649555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12833333073649555}
{"step": 138800, "time": 7218.236842632294, "episode/length": 184.0, "episode/score": 0.18595892465600627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18595892465600627}
{"step": 139192, "time": 7234.302404880524, "episode/length": 137.0, "episode/score": 0.1210627367777306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1210627367777306}
{"step": 139248, "time": 7238.395836353302, "episode/length": 139.0, "episode/score": 0.13964479846345057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13964479846345057}
{"step": 139568, "time": 7253.205957651138, "episode/length": 232.0, "episode/score": 0.23187174642589525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23187174642589525}
{"step": 139592, "time": 7255.375113248825, "episode/length": 174.0, "episode/score": 0.17854632533089898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17854632533089898}
{"step": 139728, "time": 7262.112482309341, "episode/length": 241.0, "episode/score": 0.24895309749672379, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24895309749672379}
{"step": 139840, "time": 7267.848427772522, "episode/length": 171.0, "episode/score": 0.1817101044384799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1817101044384799}
{"step": 140088, "time": 7299.300353765488, "eval_episode/length": 144.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 140088, "time": 7301.51583981514, "eval_episode/length": 151.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 140088, "time": 7303.638719320297, "eval_episode/length": 152.0, "eval_episode/score": -0.8999999985098839, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 140088, "time": 7305.893659591675, "eval_episode/length": 158.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 140088, "time": 7310.044075489044, "eval_episode/length": 203.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9656862745098039}
{"step": 140088, "time": 7312.280384063721, "eval_episode/length": 208.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 140088, "time": 7314.308296203613, "eval_episode/length": 210.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.981042654028436}
{"step": 140088, "time": 7317.145063877106, "eval_episode/length": 228.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.982532751091703}
{"step": 140089, "time": 7318.227075099945, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.54564404296875, "train/action_min": 0.0, "train/action_std": 4.819157398223877, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005045544818043709, "train/actor_opt_grad_steps": 8030.0, "train/actor_opt_loss": -17.278290959715843, "train/adv_mag": 0.12049510064721107, "train/adv_max": 0.07573678141832352, "train/adv_mean": -0.0004107683147158241, "train/adv_min": -0.1196116171181202, "train/adv_std": 0.009885286170989275, "train/cont_avg": 0.9942890625, "train/cont_loss_mean": 0.0005801846824483619, "train/cont_loss_std": 0.0159567404584559, "train/cont_neg_acc": 0.9852310582514732, "train/cont_neg_loss": 0.06870582214836421, "train/cont_pos_acc": 0.9999448890686036, "train/cont_pos_loss": 0.00014279113018750422, "train/cont_pred": 0.994332022190094, "train/cont_rate": 0.9942890625, "train/dyn_loss_mean": 12.845003036499023, "train/dyn_loss_std": 7.712471534729004, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15886079144477844, "train/extr_critic_critic_opt_grad_steps": 8030.0, "train/extr_critic_critic_opt_loss": 8387.95553125, "train/extr_critic_mag": 0.24015741443634034, "train/extr_critic_max": 0.24015741443634034, "train/extr_critic_mean": 0.17314772617816926, "train/extr_critic_min": 0.007964115142822265, "train/extr_critic_std": 0.05306461727619171, "train/extr_return_normed_mag": 0.18819038546085357, "train/extr_return_normed_max": 0.18819038546085357, "train/extr_return_normed_mean": 0.12438514775037765, "train/extr_return_normed_min": -0.047371425390243534, "train/extr_return_normed_std": 0.05420508745312691, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2365421555042267, "train/extr_return_raw_max": 0.2365421555042267, "train/extr_return_raw_mean": 0.1727369202375412, "train/extr_return_raw_min": 0.000980344772338867, "train/extr_return_raw_std": 0.054205087333917615, "train/extr_reward_mag": 0.0013336439132690429, "train/extr_reward_max": 0.0013336439132690429, "train/extr_reward_mean": 0.0010716723864898085, "train/extr_reward_min": 4.384040832519532e-06, "train/extr_reward_std": 0.00024306883662939072, "train/image_loss_mean": 8.585401844024657, "train/image_loss_std": 10.688766059875489, "train/model_loss_mean": 16.332098373413086, "train/model_loss_std": 13.744919105529785, "train/model_opt_grad_norm": 71.58097207641602, "train/model_opt_grad_steps": 8018.64, "train/model_opt_loss": 10207.5614921875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 630.0, "train/policy_entropy_mag": 2.7693006381988527, "train/policy_entropy_max": 2.7693006381988527, "train/policy_entropy_mean": 2.348677186965942, "train/policy_entropy_min": 0.1464321935772896, "train/policy_entropy_std": 0.3448541166782379, "train/policy_logprob_mag": 7.399378097534179, "train/policy_logprob_max": -0.02029359146207571, "train/policy_logprob_mean": -2.3488244228363038, "train/policy_logprob_min": -7.399378097534179, "train/policy_logprob_std": 0.9382818012237549, "train/policy_randomness_mag": 0.9774415984153747, "train/policy_randomness_max": 0.9774415984153747, "train/policy_randomness_mean": 0.8289799766540528, "train/policy_randomness_min": 0.051684138268232344, "train/policy_randomness_std": 0.12171836966276169, "train/post_ent_mag": 53.07066534423828, "train/post_ent_max": 53.07066534423828, "train/post_ent_mean": 35.86077209472656, "train/post_ent_min": 18.12850198364258, "train/post_ent_std": 5.765851352691651, "train/prior_ent_mag": 63.56382275390625, "train/prior_ent_max": 63.56382275390625, "train/prior_ent_mean": 48.95101217651367, "train/prior_ent_min": 22.111420104980468, "train/prior_ent_std": 6.194708950042725, "train/rep_loss_mean": 12.845003036499023, "train/rep_loss_std": 7.712471534729004, "train/reward_avg": 0.0010321874804794789, "train/reward_loss_mean": 0.039114491164684295, "train/reward_loss_std": 0.012471641451120376, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012972898483276367, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03911449104547501, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010288265757262707, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.5956521645188332, "train_stats/max_log_achievement_collect_drink": 0.2608695652173913, "train_stats/max_log_achievement_collect_sapling": 0.43478260869565216, "train_stats/max_log_achievement_collect_wood": 0.5217391304347826, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.008695652173913044, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.3130434782608696, "train_stats/max_log_achievement_place_table": 0.09565217391304348, "train_stats/max_log_achievement_wake_up": 0.2956521739130435, "train_stats/mean_log_entropy": 2.38159847881483, "eval_stats/sum_log_reward": 0.6624999917112291, "eval_stats/max_log_achievement_collect_drink": 0.25, "eval_stats/max_log_achievement_collect_sapling": 0.625, "eval_stats/max_log_achievement_collect_wood": 0.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 7.839671161491424e-05, "report/cont_loss_std": 0.0015530007658526301, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.0875478842062876e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.853634451748803e-05, "report/cont_pred": 0.9969933032989502, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.83425521850586, "report/dyn_loss_std": 7.803151607513428, "report/image_loss_mean": 9.696887016296387, "report/image_loss_std": 13.61314868927002, "report/model_loss_mean": 18.035533905029297, "report/model_loss_std": 16.769882202148438, "report/post_ent_mag": 51.65273666381836, "report/post_ent_max": 51.65273666381836, "report/post_ent_mean": 34.89165115356445, "report/post_ent_min": 19.930952072143555, "report/post_ent_std": 4.868483066558838, "report/prior_ent_mag": 63.73313903808594, "report/prior_ent_max": 63.73313903808594, "report/prior_ent_mean": 49.14958953857422, "report/prior_ent_min": 20.953596115112305, "report/prior_ent_std": 5.30574369430542, "report/rep_loss_mean": 13.83425521850586, "report/rep_loss_std": 7.803151607513428, "report/reward_avg": 0.0010014981962740421, "report/reward_loss_mean": 0.03801668435335159, "report/reward_loss_std": 0.013361806981265545, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012778043746948242, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03801668435335159, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010213854257017374, "report/reward_rate": 0.0, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.0033560318406671286, "eval/cont_loss_std": 0.058472104370594025, "eval/cont_neg_acc": 0.7142857313156128, "eval/cont_neg_loss": 0.44902732968330383, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00028848135843873024, "eval/cont_pred": 0.9947643280029297, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 14.923576354980469, "eval/dyn_loss_std": 9.765643119812012, "eval/image_loss_mean": 10.760462760925293, "eval/image_loss_std": 12.904561042785645, "eval/model_loss_mean": 20.211864471435547, "eval/model_loss_std": 17.33193016052246, "eval/post_ent_mag": 51.998779296875, "eval/post_ent_max": 51.998779296875, "eval/post_ent_mean": 36.14507293701172, "eval/post_ent_min": 20.57427406311035, "eval/post_ent_std": 5.9715094566345215, "eval/prior_ent_mag": 63.73313903808594, "eval/prior_ent_max": 63.73313903808594, "eval/prior_ent_mean": 47.909915924072266, "eval/prior_ent_min": 21.344058990478516, "eval/prior_ent_std": 7.739924430847168, "eval/rep_loss_mean": 14.923576354980469, "eval/rep_loss_std": 9.765643119812012, "eval/reward_avg": 0.012988281436264515, "eval/reward_loss_mean": 0.49389925599098206, "eval/reward_loss_std": 2.8060760498046875, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012803077697753906, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.2087547928094864, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 17.3845157623291, "eval/reward_pred": 0.0009083180921152234, "eval/reward_rate": 0.0166015625, "replay/size": 139585.0, "replay/inserts": 20016.0, "replay/samples": 20016.0, "replay/insert_wait_avg": 1.308538740296825e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.054012112575565e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 29736.0, "eval_replay/inserts": 3816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1983407618364698e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1009.2504677772522, "timer/env.step_count": 2502.0, "timer/env.step_total": 243.42465543746948, "timer/env.step_frac": 0.2411935027125445, "timer/env.step_avg": 0.09729202855214608, "timer/env.step_min": 0.0223538875579834, "timer/env.step_max": 5.599758148193359, "timer/replay._sample_count": 20016.0, "timer/replay._sample_total": 9.970951318740845, "timer/replay._sample_frac": 0.00987956076027452, "timer/replay._sample_avg": 0.0004981490466996825, "timer/replay._sample_min": 0.0003600120544433594, "timer/replay._sample_max": 0.011008739471435547, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2979.0, "timer/agent.policy_total": 47.951921463012695, "timer/agent.policy_frac": 0.04751240945037241, "timer/agent.policy_avg": 0.01609665037361957, "timer/agent.policy_min": 0.009627103805541992, "timer/agent.policy_max": 0.11855888366699219, "timer/dataset_train_count": 1251.0, "timer/dataset_train_total": 0.13246488571166992, "timer/dataset_train_frac": 0.00013125075483334404, "timer/dataset_train_avg": 0.0001058871988102877, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.00046753883361816406, "timer/agent.train_count": 1251.0, "timer/agent.train_total": 563.4501917362213, "timer/agent.train_frac": 0.5582857870525935, "timer/agent.train_avg": 0.45039983352215934, "timer/agent.train_min": 0.43498873710632324, "timer/agent.train_max": 0.8753929138183594, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4840688705444336, "timer/agent.report_frac": 0.00047963204972352864, "timer/agent.report_avg": 0.2420344352722168, "timer/agent.report_min": 0.23620200157165527, "timer/agent.report_max": 0.24786686897277832, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 9.5367431640625e-05, "timer/dataset_eval_frac": 9.449332419003959e-08, "timer/dataset_eval_avg": 9.5367431640625e-05, "timer/dataset_eval_min": 9.5367431640625e-05, "timer/dataset_eval_max": 9.5367431640625e-05, "fps": 19.832302985307592}
{"step": 140416, "time": 7330.6190819740295, "episode/length": 201.0, "episode/score": 0.20898022339497402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20898022339497402}
{"step": 140488, "time": 7334.5408799648285, "episode/length": 254.0, "episode/score": 0.29500304851262626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29500304851262626}
{"step": 140528, "time": 7337.8151977062225, "episode/length": 166.0, "episode/score": 0.18048253047390972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18048253047390972}
{"step": 140592, "time": 7341.734604597092, "episode/length": 167.0, "episode/score": 0.18017836252602137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18017836252602137}
{"step": 140944, "time": 7356.502291202545, "episode/length": 168.0, "episode/score": 0.18702400156325893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18702400156325893}
{"step": 141008, "time": 7360.524592876434, "episode/length": 159.0, "episode/score": 0.1597910591553955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1597910591553955}
{"step": 141048, "time": 7363.3938109874725, "episode/length": 184.0, "episode/score": 0.19669596661560718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19669596661560718}
{"step": 141256, "time": 7372.753285884857, "episode/length": 176.0, "episode/score": 0.18064501305343583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18064501305343583}
{"step": 141600, "time": 7387.443801403046, "episode/length": 125.0, "episode/score": 0.14771527497214265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14771527497214265}
{"step": 141656, "time": 7390.757222890854, "episode/length": 154.0, "episode/score": 0.1730357115689003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1730357115689003}
{"step": 142200, "time": 7412.642661809921, "episode/length": 208.0, "episode/score": 0.2234227728758924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2234227728758924}
{"step": 142216, "time": 7415.361845493317, "episode/length": 158.0, "episode/score": 0.18297546085523209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18297546085523209}
{"step": 142280, "time": 7419.988438367844, "episode/length": 158.0, "episode/score": 0.14967256120144157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14967256120144157}
{"step": 142376, "time": 7425.441962480545, "episode/length": 235.0, "episode/score": 0.2488675526105908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2488675526105908}
{"step": 142448, "time": 7429.848765134811, "episode/length": 174.0, "episode/score": 0.1748583362714271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1748583362714271}
{"step": 142736, "time": 7442.1644830703735, "episode/length": 184.0, "episode/score": 0.20475144822557922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20475144822557922}
{"step": 142912, "time": 7450.369955301285, "episode/length": 156.0, "episode/score": 0.14850076807488222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14850076807488222}
{"step": 143088, "time": 7458.440978527069, "episode/length": 185.0, "episode/score": 0.19794452761561843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19794452761561843}
{"step": 143344, "time": 7469.478161811829, "episode/length": 142.0, "episode/score": 0.17303011688272818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17303011688272818}
{"step": 143648, "time": 7482.475601196289, "episode/length": 149.0, "episode/score": 0.15984371786180418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15984371786180418}
{"step": 143696, "time": 7485.783572435379, "episode/length": 184.0, "episode/score": 0.18333457449261914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18333457449261914}
{"step": 143968, "time": 7497.336293458939, "episode/length": 153.0, "episode/score": 0.16456117720008478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16456117720008478}
{"step": 144184, "time": 7506.64101600647, "episode/length": 237.0, "episode/score": 0.2455455542440177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2455455542440177}
{"step": 144288, "time": 7512.418714761734, "episode/length": 149.0, "episode/score": 0.14240297038122662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14240297038122662}
{"step": 144472, "time": 7520.536323547363, "episode/length": 140.0, "episode/score": 0.12983934339354164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12983934339354164}
{"step": 144760, "time": 7532.748849391937, "episode/length": 230.0, "episode/score": 0.2518718779028859, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2518718779028859}
{"step": 144912, "time": 7540.221551656723, "episode/length": 157.0, "episode/score": 0.1573307405487867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1573307405487867}
{"step": 144944, "time": 7542.986958265305, "episode/length": 81.0, "episode/score": 0.09400623050532886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09400623050532886}
{"step": 145248, "time": 7555.890535593033, "episode/length": 159.0, "episode/score": 0.17401166647687205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17401166647687205}
{"step": 145328, "time": 7560.593391180038, "episode/length": 142.0, "episode/score": 0.13910193617812183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13910193617812183}
{"step": 145592, "time": 7571.813111066818, "episode/length": 401.0, "episode/score": 0.42019588533003116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42019588533003116}
{"step": 145688, "time": 7576.990186452866, "episode/length": 248.0, "episode/score": 0.28549001636383764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28549001636383764}
{"step": 145720, "time": 7579.771200180054, "episode/length": 155.0, "episode/score": 0.1614158354141182, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1614158354141182}
{"step": 146072, "time": 7594.552515268326, "episode/length": 43.0, "episode/score": 0.050541665783384815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050541665783384815}
{"step": 146400, "time": 7608.583713531494, "episode/length": 185.0, "episode/score": 0.19650124906729616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19650124906729616}
{"step": 146496, "time": 7613.720933437347, "episode/length": 145.0, "episode/score": 0.15683204245760862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15683204245760862}
{"step": 146544, "time": 7617.16050863266, "episode/length": 222.0, "episode/score": 0.2436343207837126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2436343207837126}
{"step": 146584, "time": 7619.947768449783, "episode/length": 166.0, "episode/score": 0.19933332956861705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19933332956861705}
{"step": 146944, "time": 7635.181007146835, "episode/length": 156.0, "episode/score": 0.1731219092662286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1731219092662286}
{"step": 147160, "time": 7644.703547239304, "episode/length": 276.0, "episode/score": 0.3060201969292393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3060201969292393}
{"step": 147288, "time": 7651.544298171997, "episode/length": 211.0, "episode/score": 0.23559972052862577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23559972052862577}
{"step": 147344, "time": 7655.457422018051, "episode/length": 158.0, "episode/score": 0.16841909938375466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16841909938375466}
{"step": 147568, "time": 7666.878780603409, "episode/length": 133.0, "episode/score": 0.15941562822354172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15941562822354172}
{"step": 147656, "time": 7671.501329898834, "episode/length": 156.0, "episode/score": 0.16559829809739313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16559829809739313}
{"step": 147816, "time": 7679.02472114563, "episode/length": 158.0, "episode/score": 0.1730114613828846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1730114613828846}
{"step": 148080, "time": 7690.8015785217285, "episode/length": 186.0, "episode/score": 0.19546147246546752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19546147246546752}
{"step": 148616, "time": 7712.211707830429, "episode/length": 208.0, "episode/score": 0.22272836859610834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22272836859610834}
{"step": 148936, "time": 7725.909700632095, "episode/length": 198.0, "episode/score": 0.21684399101013696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21684399101013696}
{"step": 148952, "time": 7728.1376123428345, "episode/length": 141.0, "episode/score": 0.14917555386546155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14917555386546155}
{"step": 149096, "time": 7734.932373046875, "episode/length": 241.0, "episode/score": 0.25229145138109743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25229145138109743}
{"step": 149104, "time": 7736.973871946335, "episode/length": 180.0, "episode/score": 0.19564534672463196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19564534672463196}
{"step": 149128, "time": 7739.593762636185, "episode/length": 229.0, "episode/score": 0.2796763886199187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2796763886199187}
{"step": 149248, "time": 7746.411761760712, "episode/length": 145.0, "episode/score": 0.14526242377905874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14526242377905874}
{"step": 149344, "time": 7751.538637638092, "episode/length": 221.0, "episode/score": 0.25117372403019544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25117372403019544}
{"step": 149912, "time": 7773.87305188179, "episode/length": 161.0, "episode/score": 0.16465652886836324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16465652886836324}
{"step": 150064, "time": 7781.34996175766, "episode/length": 138.0, "episode/score": 0.14377807827258948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14377807827258948}
{"step": 150072, "time": 7801.792208909988, "eval_episode/length": 146.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 150072, "time": 7803.327612876892, "eval_episode/length": 148.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 150072, "time": 7805.043745040894, "eval_episode/length": 154.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 150072, "time": 7807.188703536987, "eval_episode/length": 164.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 150072, "time": 7808.689653635025, "eval_episode/length": 165.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 150072, "time": 7810.462119579315, "eval_episode/length": 169.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 150072, "time": 7812.582839727402, "eval_episode/length": 171.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 150072, "time": 7815.184721946716, "eval_episode/length": 185.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 150200, "time": 7820.106236934662, "episode/length": 157.0, "episode/score": 0.17776884609338595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17776884609338595}
{"step": 150384, "time": 7829.194217681885, "episode/length": 156.0, "episode/score": 0.1673832090673386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1673832090673386}
{"step": 150624, "time": 7839.762975215912, "episode/length": 171.0, "episode/score": 0.19540926869012765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19540926869012765}
{"step": 150648, "time": 7841.889779090881, "episode/length": 192.0, "episode/score": 0.23306943970965222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23306943970965222}
{"step": 150736, "time": 7847.021275281906, "episode/length": 173.0, "episode/score": 0.1586046262164018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1586046262164018}
{"step": 150944, "time": 7856.2301325798035, "episode/length": 230.0, "episode/score": 0.2536760797374882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2536760797374882}
{"step": 151416, "time": 7875.479971647263, "episode/length": 187.0, "episode/score": 0.19690622749112663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19690622749112663}
{"step": 151448, "time": 7878.210781335831, "episode/length": 172.0, "episode/score": 0.17702156327140983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17702156327140983}
{"step": 151584, "time": 7885.007088899612, "episode/length": 149.0, "episode/score": 0.13797322589744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13797322589744}
{"step": 151840, "time": 7896.157201051712, "episode/length": 204.0, "episode/score": 0.21491980931023136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21491980931023136}
{"step": 152024, "time": 7904.358155250549, "episode/length": 174.0, "episode/score": 0.18375334994016157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18375334994016157}
{"step": 152112, "time": 7909.397285699844, "episode/length": 145.0, "episode/score": 0.14476518027368002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14476518027368002}
{"step": 152120, "time": 7910.9588096141815, "episode/length": 172.0, "episode/score": 0.16886086140402767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16886086140402767}
{"step": 152160, "time": 7914.206015110016, "episode/length": 188.0, "episode/score": 0.1954048659918044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1954048659918044}
{"step": 152544, "time": 7930.219701051712, "episode/length": 140.0, "episode/score": 0.14486329297506018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14486329297506018}
{"step": 152640, "time": 7935.310820102692, "episode/length": 148.0, "episode/score": 0.1576816781598609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1576816781598609}
{"step": 152680, "time": 7938.123953580856, "episode/length": 70.0, "episode/score": 0.08541666495148093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08541666495148093}
{"step": 152928, "time": 7949.1348965168, "episode/length": 47.0, "episode/score": 0.045982739407918416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045982739407918416}
{"step": 153432, "time": 7969.775067329407, "episode/length": 175.0, "episode/score": 0.1978671353936079, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1978671353936079}
{"step": 153624, "time": 7978.410427808762, "episode/length": 187.0, "episode/score": 0.18978209396300372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18978209396300372}
{"step": 153624, "time": 7978.421101808548, "episode/length": 254.0, "episode/score": 0.27879683932405896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27879683932405896}
{"step": 153768, "time": 7986.982655286789, "episode/length": 200.0, "episode/score": 0.20493403442014824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20493403442014824}
{"step": 153872, "time": 7992.73067855835, "episode/length": 253.0, "episode/score": 0.28147457595332526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28147457595332526}
{"step": 154280, "time": 8009.307734012604, "episode/length": 199.0, "episode/score": 0.23252514491105103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23252514491105103}
{"step": 154320, "time": 8012.398041963577, "episode/length": 173.0, "episode/score": 0.17655031666436116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17655031666436116}
{"step": 154720, "time": 8028.866308450699, "episode/length": 259.0, "episode/score": 0.2689268479080056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2689268479080056}
{"step": 155088, "time": 8044.087101697922, "episode/length": 151.0, "episode/score": 0.14421199999378587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14421199999378587}
{"step": 155232, "time": 8051.09073638916, "episode/length": 224.0, "episode/score": 0.2438400668252143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2438400668252143}
{"step": 155304, "time": 8054.977443933487, "episode/length": 209.0, "episode/score": 0.20255112742052006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20255112742052006}
{"step": 155312, "time": 8056.9627006053925, "episode/length": 210.0, "episode/score": 0.23743504109916103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23743504109916103}
{"step": 155432, "time": 8062.734746694565, "episode/length": 138.0, "episode/score": 0.15259429049001483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15259429049001483}
{"step": 155456, "time": 8065.407560586929, "episode/length": 45.0, "episode/score": 0.03910213057679357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03910213057679357}
{"step": 155480, "time": 8067.634665250778, "episode/length": 149.0, "episode/score": 0.16211659096734365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16211659096734365}
{"step": 155840, "time": 8084.281414985657, "episode/length": 66.0, "episode/score": 0.07501785593194654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07501785593194654}
{"step": 156120, "time": 8096.063811302185, "episode/length": 293.0, "episode/score": 0.3000466471439722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3000466471439722}
{"step": 156560, "time": 8114.296918153763, "episode/length": 165.0, "episode/score": 0.17283016900000803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17283016900000803}
{"step": 156608, "time": 8117.58797287941, "episode/length": 140.0, "episode/score": 0.1491810338520736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1491810338520736}
{"step": 156608, "time": 8117.5960085392, "episode/length": 143.0, "episode/score": 0.16729070655310352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16729070655310352}
{"step": 156616, "time": 8120.763933181763, "episode/length": 236.0, "episode/score": 0.2717628919344861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2717628919344861}
{"step": 156624, "time": 8122.719645738602, "episode/length": 163.0, "episode/score": 0.17942129077709978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17942129077709978}
{"step": 156736, "time": 8128.841461896896, "episode/length": 162.0, "episode/score": 0.19000808262717328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19000808262717328}
{"step": 157552, "time": 8161.285329580307, "episode/length": 213.0, "episode/score": 0.23850550040151575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23850550040151575}
{"step": 157552, "time": 8161.292674064636, "episode/length": 178.0, "episode/score": 0.1942783427384711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1942783427384711}
{"step": 157768, "time": 8172.333931922913, "episode/length": 144.0, "episode/score": 0.14486252218648588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14486252218648588}
{"step": 157776, "time": 8174.449554681778, "episode/length": 151.0, "episode/score": 0.15332132262119558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15332132262119558}
{"step": 157936, "time": 8181.898604393005, "episode/length": 164.0, "episode/score": 0.17477660812619433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17477660812619433}
{"step": 158112, "time": 8189.963405847549, "episode/length": 187.0, "episode/score": 0.18381403439525457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18381403439525457}
{"step": 158152, "time": 8192.748863697052, "episode/length": 46.0, "episode/score": 0.04710130648891209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04710130648891209}
{"step": 158176, "time": 8195.309988737106, "episode/length": 193.0, "episode/score": 0.23037255908457155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23037255908457155}
{"step": 158208, "time": 8198.236540317535, "episode/length": 183.0, "episode/score": 0.20372004003002075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20372004003002075}
{"step": 158728, "time": 8218.904181957245, "episode/length": 146.0, "episode/score": 0.12051371406232647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12051371406232647}
{"step": 158768, "time": 8222.198213815689, "episode/length": 151.0, "episode/score": 0.1456557434021306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1456557434021306}
{"step": 159032, "time": 8233.355214357376, "episode/length": 114.0, "episode/score": 0.1397916638525203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1397916638525203}
{"step": 159224, "time": 8242.169600486755, "episode/length": 160.0, "episode/score": 0.19092829094279296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19092829094279296}
{"step": 159312, "time": 8247.186489343643, "episode/length": 137.0, "episode/score": 0.12203894523281633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12203894523281633}
{"step": 159544, "time": 8257.22018957138, "episode/length": 170.0, "episode/score": 0.1666143620850562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1666143620850562}
{"step": 159584, "time": 8260.50694322586, "episode/length": 178.0, "episode/score": 0.16316222666500835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16316222666500835}
{"step": 159664, "time": 8264.987193346024, "episode/length": 236.0, "episode/score": 0.2727069613702042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2727069613702042}
{"step": 159960, "time": 8277.341532230377, "episode/length": 148.0, "episode/score": 0.1659214768478705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1659214768478705}
{"step": 160040, "time": 8281.738132238388, "episode/length": 163.0, "episode/score": 0.1643087332331561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1643087332331561}
{"step": 160056, "time": 8299.91675043106, "eval_episode/length": 83.0, "eval_episode/score": -0.8999999761581421, "eval_episode/reward_rate": 0.9880952380952381}
{"step": 160056, "time": 8305.467325687408, "eval_episode/length": 146.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9591836734693877}
{"step": 160056, "time": 8307.01718878746, "eval_episode/length": 148.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 160056, "time": 8309.601998806, "eval_episode/length": 174.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 160056, "time": 8311.206015586853, "eval_episode/length": 177.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 160056, "time": 8313.541475057602, "eval_episode/length": 196.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 160056, "time": 8315.856808900833, "eval_episode/length": 215.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9675925925925926}
{"step": 160056, "time": 8317.898972988129, "eval_episode/length": 141.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9577464788732394}
{"step": 160057, "time": 8318.941626787186, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.42386865234375, "train/action_min": 0.0, "train/action_std": 4.712992198944092, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004848183657974005, "train/actor_opt_grad_steps": 9280.0, "train/actor_opt_loss": -13.89837673330307, "train/adv_mag": 0.11544696798920631, "train/adv_max": 0.071798933416605, "train/adv_mean": -0.0002161954907423933, "train/adv_min": -0.11504894748330116, "train/adv_std": 0.009526540901511907, "train/cont_avg": 0.9943984375, "train/cont_loss_mean": 0.0003534377564328679, "train/cont_loss_std": 0.009881372769872542, "train/cont_neg_acc": 0.9870825414657592, "train/cont_neg_loss": 0.027991388116541203, "train/cont_pos_acc": 0.9999685487747192, "train/cont_pos_loss": 0.00019226476937751614, "train/cont_pred": 0.994401047706604, "train/cont_rate": 0.9943984375, "train/dyn_loss_mean": 12.69694708251953, "train/dyn_loss_std": 7.761298400878906, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16669592851400375, "train/extr_critic_critic_opt_grad_steps": 9280.0, "train/extr_critic_critic_opt_loss": 7784.6082734375, "train/extr_critic_mag": 0.23296270751953124, "train/extr_critic_max": 0.23296270751953124, "train/extr_critic_mean": 0.16567863643169403, "train/extr_critic_min": 0.007290174484252929, "train/extr_critic_std": 0.049987972885370255, "train/extr_return_normed_mag": 0.17782999753952025, "train/extr_return_normed_max": 0.17782999753952025, "train/extr_return_normed_mean": 0.11469855642318726, "train/extr_return_normed_min": -0.04975790402293205, "train/extr_return_normed_std": 0.05087388691306114, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.22859390270709992, "train/extr_return_raw_max": 0.22859390270709992, "train/extr_return_raw_mean": 0.16546246373653412, "train/extr_return_raw_min": 0.001006000518798828, "train/extr_return_raw_std": 0.05087388697266579, "train/extr_reward_mag": 0.001337937355041504, "train/extr_reward_max": 0.001337937355041504, "train/extr_reward_mean": 0.001077711123973131, "train/extr_reward_min": 9.289741516113281e-06, "train/extr_reward_std": 0.00024849542137235405, "train/image_loss_mean": 8.412292263031006, "train/image_loss_std": 11.079074863433839, "train/model_loss_mean": 16.070055435180663, "train/model_loss_std": 14.179110572814942, "train/model_opt_grad_norm": 79.04044613647461, "train/model_opt_grad_steps": 9267.928, "train/model_opt_loss": 14952.55180859375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 930.0, "train/policy_entropy_mag": 2.7649153022766115, "train/policy_entropy_max": 2.7649153022766115, "train/policy_entropy_mean": 2.3213347454071043, "train/policy_entropy_min": 0.13159597039222717, "train/policy_entropy_std": 0.3779068796634674, "train/policy_logprob_mag": 7.418445373535156, "train/policy_logprob_max": -0.017472300715744495, "train/policy_logprob_mean": -2.321821123123169, "train/policy_logprob_min": -7.418445373535156, "train/policy_logprob_std": 0.9751301164627075, "train/policy_randomness_mag": 0.9758937664031982, "train/policy_randomness_max": 0.9758937664031982, "train/policy_randomness_mean": 0.8193292989730835, "train/policy_randomness_min": 0.04644760274887085, "train/policy_randomness_std": 0.13338454473018646, "train/post_ent_mag": 53.75671826171875, "train/post_ent_max": 53.75671826171875, "train/post_ent_mean": 36.293184204101564, "train/post_ent_min": 19.270498825073243, "train/post_ent_std": 5.801707027435302, "train/prior_ent_mag": 64.19903631591797, "train/prior_ent_max": 64.19903631591797, "train/prior_ent_mean": 49.17232489013672, "train/prior_ent_min": 23.707074600219727, "train/prior_ent_std": 5.973996692657471, "train/rep_loss_mean": 12.69694708251953, "train/rep_loss_std": 7.761298400878906, "train/reward_avg": 0.001036545543000102, "train/reward_loss_mean": 0.03924152088165283, "train/reward_loss_std": 0.012429947525262833, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013019685745239257, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03924152094125748, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001037593761458993, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.7120689609698181, "train_stats/max_log_achievement_collect_drink": 0.27586206896551724, "train_stats/max_log_achievement_collect_sapling": 0.6206896551724138, "train_stats/max_log_achievement_collect_wood": 0.5862068965517241, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.008620689655172414, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008620689655172414, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.43103448275862066, "train_stats/max_log_achievement_place_table": 0.09482758620689655, "train_stats/max_log_achievement_wake_up": 0.2413793103448276, "train_stats/mean_log_entropy": 2.36322061357827, "eval_stats/sum_log_reward": 0.6624999935738742, "eval_stats/max_log_achievement_collect_drink": 0.25, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_wood": 0.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.25, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_collect_stone": 0.3333333333333333, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00020172733638901263, "report/cont_loss_std": 0.006194703746587038, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.041105471551418304, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0220305739494506e-06, "report/cont_pred": 0.9952989816665649, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.995028495788574, "report/dyn_loss_std": 7.663848876953125, "report/image_loss_mean": 7.932682037353516, "report/image_loss_std": 10.282124519348145, "report/model_loss_mean": 15.767902374267578, "report/model_loss_std": 13.421075820922852, "report/post_ent_mag": 52.74060821533203, "report/post_ent_max": 52.74060821533203, "report/post_ent_mean": 36.0621337890625, "report/post_ent_min": 17.817489624023438, "report/post_ent_std": 5.749381065368652, "report/prior_ent_mag": 64.33908081054688, "report/prior_ent_max": 64.33908081054688, "report/prior_ent_mean": 49.47303771972656, "report/prior_ent_min": 20.40389060974121, "report/prior_ent_std": 5.372358322143555, "report/rep_loss_mean": 12.995028495788574, "report/rep_loss_std": 7.663848876953125, "report/reward_avg": 0.0010020406916737556, "report/reward_loss_mean": 0.038000911474227905, "report/reward_loss_std": 0.013733363710343838, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013206005096435547, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.038000915199518204, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001052080187946558, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0025672749616205692, "eval/cont_loss_std": 0.07808320969343185, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.02443382330238819, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.002481523435562849, "eval/cont_pred": 0.9952566623687744, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.255542755126953, "eval/dyn_loss_std": 10.305922508239746, "eval/image_loss_mean": 14.322587966918945, "eval/image_loss_std": 18.735504150390625, "eval/model_loss_mean": 25.392770767211914, "eval/model_loss_std": 22.57818031311035, "eval/post_ent_mag": 55.92920684814453, "eval/post_ent_max": 55.92920684814453, "eval/post_ent_mean": 37.73993682861328, "eval/post_ent_min": 17.787654876708984, "eval/post_ent_std": 6.917019367218018, "eval/prior_ent_mag": 64.33908081054688, "eval/prior_ent_max": 64.33908081054688, "eval/prior_ent_mean": 51.48076629638672, "eval/prior_ent_min": 21.026025772094727, "eval/prior_ent_std": 6.321025371551514, "eval/rep_loss_mean": 17.255542755126953, "eval/rep_loss_std": 10.305922508239746, "eval/reward_avg": 0.009765625, "eval/reward_loss_mean": 0.7142907381057739, "eval/reward_loss_std": 3.402005434036255, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013053417205810547, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.4605984091758728, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 17.77933120727539, "eval/reward_pred": 0.001105837756767869, "eval/reward_rate": 0.0146484375, "replay/size": 159553.0, "replay/inserts": 19968.0, "replay/samples": 19968.0, "replay/insert_wait_avg": 1.3263824467475597e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.078626333138882e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33032.0, "eval_replay/inserts": 3296.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2026539126646172e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.7032012939453, "timer/env.step_count": 2496.0, "timer/env.step_total": 243.96578788757324, "timer/env.step_frac": 0.24379435138422328, "timer/env.step_avg": 0.09774270348059826, "timer/env.step_min": 0.0224456787109375, "timer/env.step_max": 3.158111095428467, "timer/replay._sample_count": 19968.0, "timer/replay._sample_total": 10.132902383804321, "timer/replay._sample_frac": 0.010125781920855368, "timer/replay._sample_avg": 0.0005074570504709696, "timer/replay._sample_min": 0.00034999847412109375, "timer/replay._sample_max": 0.02543926239013672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2908.0, "timer/agent.policy_total": 47.69820308685303, "timer/agent.policy_frac": 0.04766468521853186, "timer/agent.policy_avg": 0.016402408214186048, "timer/agent.policy_min": 0.00962209701538086, "timer/agent.policy_max": 0.11817073822021484, "timer/dataset_train_count": 1248.0, "timer/dataset_train_total": 0.1339855194091797, "timer/dataset_train_frac": 0.000133891366826779, "timer/dataset_train_avg": 0.0001073601918342786, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.00037288665771484375, "timer/agent.train_count": 1248.0, "timer/agent.train_total": 561.492006778717, "timer/agent.train_frac": 0.5610974423312403, "timer/agent.train_avg": 0.44991346697012585, "timer/agent.train_min": 0.4366176128387451, "timer/agent.train_max": 1.1108713150024414, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47341084480285645, "timer/agent.report_frac": 0.00047307817561762487, "timer/agent.report_avg": 0.23670542240142822, "timer/agent.report_min": 0.2248847484588623, "timer/agent.report_max": 0.24852609634399414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.0031256675720214844, "timer/dataset_eval_frac": 3.123471143072075e-06, "timer/dataset_eval_avg": 0.0031256675720214844, "timer/dataset_eval_min": 0.0031256675720214844, "timer/dataset_eval_max": 0.0031256675720214844, "fps": 19.953716367713874}
{"step": 160336, "time": 8329.376118659973, "episode/length": 162.0, "episode/score": 0.1884413292609679, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1884413292609679}
{"step": 160848, "time": 8350.144688129425, "episode/length": 162.0, "episode/score": 0.17566578651440068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17566578651440068}
{"step": 160864, "time": 8352.32867527008, "episode/length": 159.0, "episode/score": 0.14688716513774125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14688716513774125}
{"step": 161024, "time": 8359.795666456223, "episode/length": 169.0, "episode/score": 0.18348326201703458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18348326201703458}
{"step": 161072, "time": 8363.095779418945, "episode/length": 230.0, "episode/score": 0.2392063465576939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2392063465576939}
{"step": 161112, "time": 8365.771819591522, "episode/length": 143.0, "episode/score": 0.15029092323584337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15029092323584337}
{"step": 161168, "time": 8369.52765417099, "episode/length": 231.0, "episode/score": 0.260278305171596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.260278305171596}
{"step": 161208, "time": 8372.419327497482, "episode/length": 145.0, "episode/score": 0.1534853870543884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1534853870543884}
{"step": 161424, "time": 8382.245432138443, "episode/length": 69.0, "episode/score": 0.08249999833060429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08249999833060429}
{"step": 161488, "time": 8386.058745145798, "episode/length": 46.0, "episode/score": 0.04211633994418662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04211633994418662}
{"step": 161992, "time": 8406.10252571106, "episode/length": 206.0, "episode/score": 0.22280789697470027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22280789697470027}
{"step": 162088, "time": 8411.327673435211, "episode/length": 154.0, "episode/score": 0.1716404999679071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1716404999679071}
{"step": 162160, "time": 8415.845916986465, "episode/length": 141.0, "episode/score": 0.1373367992528074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1373367992528074}
{"step": 162320, "time": 8423.280758857727, "episode/length": 155.0, "episode/score": 0.14877457365219016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14877457365219016}
{"step": 162344, "time": 8425.388187885284, "episode/length": 141.0, "episode/score": 0.1414847829764767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1414847829764767}
{"step": 162400, "time": 8429.291818857193, "episode/length": 153.0, "episode/score": 0.14958475593084586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14958475593084586}
{"step": 162760, "time": 8444.319412708282, "episode/length": 166.0, "episode/score": 0.17371915241892566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17371915241892566}
{"step": 163048, "time": 8456.672471046448, "episode/length": 194.0, "episode/score": 0.21116503364100936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21116503364100936}
{"step": 163216, "time": 8464.585713624954, "episode/length": 152.0, "episode/score": 0.17685001799691236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17685001799691236}
{"step": 163488, "time": 8476.211133480072, "episode/length": 174.0, "episode/score": 0.19103261353302514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19103261353302514}
{"step": 163560, "time": 8480.18019413948, "episode/length": 151.0, "episode/score": 0.1469815205946361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1469815205946361}
{"step": 163584, "time": 8482.890675544739, "episode/length": 157.0, "episode/score": 0.1618016558859381, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1618016558859381}
{"step": 163688, "time": 8488.039205551147, "episode/length": 160.0, "episode/score": 0.1803899460719549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1803899460719549}
{"step": 163760, "time": 8492.400211334229, "episode/length": 199.0, "episode/score": 0.23133504098223057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23133504098223057}
{"step": 164272, "time": 8514.421013593674, "episode/length": 152.0, "episode/score": 0.1843985811337916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1843985811337916}
{"step": 164376, "time": 8519.535810709, "episode/length": 144.0, "episode/score": 0.14727670893080358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14727670893080358}
{"step": 164560, "time": 8528.12103009224, "episode/length": 224.0, "episode/score": 0.24907971113862004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24907971113862004}
{"step": 164576, "time": 8530.180439472198, "episode/length": 135.0, "episode/score": 0.1634802597709495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1634802597709495}
{"step": 164864, "time": 8542.457790374756, "episode/length": 162.0, "episode/score": 0.19393767123256112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19393767123256112}
{"step": 165040, "time": 8550.810784339905, "episode/length": 168.0, "episode/score": 0.1871223060079501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1871223060079501}
{"step": 165088, "time": 8554.646809339523, "episode/length": 165.0, "episode/score": 0.19555944468629605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19555944468629605}
{"step": 165128, "time": 8557.946394443512, "episode/length": 192.0, "episode/score": 0.19057887158123776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19057887158123776}
{"step": 165432, "time": 8571.468401908875, "episode/length": 144.0, "episode/score": 0.14949890956268064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14949890956268064}
{"step": 165648, "time": 8581.201810359955, "episode/length": 135.0, "episode/score": 0.13626079328969354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13626079328969354}
{"step": 165784, "time": 8587.60913181305, "episode/length": 150.0, "episode/score": 0.1796732420916669, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1796732420916669}
{"step": 165896, "time": 8593.431553840637, "episode/length": 189.0, "episode/score": 0.2096963201474864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2096963201474864}
{"step": 166288, "time": 8609.815269470215, "episode/length": 149.0, "episode/score": 0.14497206314990763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14497206314990763}
{"step": 166352, "time": 8613.676671504974, "episode/length": 163.0, "episode/score": 0.16164014696187223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16164014696187223}
{"step": 166400, "time": 8617.093460559845, "episode/length": 158.0, "episode/score": 0.14958089575520717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14958089575520717}
{"step": 166880, "time": 8636.456105232239, "episode/length": 153.0, "episode/score": 0.15054576357579208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15054576357579208}
{"step": 166960, "time": 8640.991178750992, "episode/length": 146.0, "episode/score": 0.16703362464613747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16703362464613747}
{"step": 167104, "time": 8647.952748775482, "episode/length": 208.0, "episode/score": 0.23769348180212546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23769348180212546}
{"step": 167496, "time": 8663.780905246735, "episode/length": 199.0, "episode/score": 0.22078904536101618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22078904536101618}
{"step": 167512, "time": 8665.906640291214, "episode/length": 144.0, "episode/score": 0.15167821585055208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15167821585055208}
{"step": 167728, "time": 8675.682094812393, "episode/length": 165.0, "episode/score": 0.16081269722781144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16081269722781144}
{"step": 167920, "time": 8684.427788972855, "episode/length": 381.0, "episode/score": 0.41045665981982893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41045665981982893}
{"step": 167960, "time": 8687.357934474945, "episode/length": 208.0, "episode/score": 0.21862369624068378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21862369624068378}
{"step": 167976, "time": 8689.452054738998, "episode/length": 136.0, "episode/score": 0.1335622211881855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1335622211881855}
{"step": 168280, "time": 8702.311665058136, "episode/length": 164.0, "episode/score": 0.17388604177176603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17388604177176603}
{"step": 168384, "time": 8708.034274339676, "episode/length": 159.0, "episode/score": 0.1562660290474014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1562660290474014}
{"step": 168744, "time": 8722.764325857162, "episode/length": 155.0, "episode/score": 0.16267656340824033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16267656340824033}
{"step": 168976, "time": 8733.247593402863, "episode/length": 155.0, "episode/score": 0.15833724435287877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15833724435287877}
{"step": 169040, "time": 8737.189065933228, "episode/length": 134.0, "episode/score": 0.14123950237808458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14123950237808458}
{"step": 169280, "time": 8748.422089099884, "episode/length": 162.0, "episode/score": 0.17889675146216177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17889675146216177}
{"step": 169376, "time": 8753.611206054688, "episode/length": 232.0, "episode/score": 0.26665687998684007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26665687998684007}
{"step": 169608, "time": 8763.565456151962, "episode/length": 165.0, "episode/score": 0.17175207678519655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17175207678519655}
{"step": 170040, "time": 8795.82019495964, "eval_episode/length": 48.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9387755102040817}
{"step": 170040, "time": 8801.345994234085, "eval_episode/length": 146.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 170040, "time": 8803.145830631256, "eval_episode/length": 153.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 170040, "time": 8805.460510969162, "eval_episode/length": 173.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 170040, "time": 8807.371042013168, "eval_episode/length": 182.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.994535519125683}
{"step": 170040, "time": 8809.075792074203, "eval_episode/length": 186.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 170040, "time": 8813.660141706467, "eval_episode/length": 261.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9847328244274809}
{"step": 170040, "time": 8815.389587163925, "eval_episode/length": 217.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 170200, "time": 8821.309983253479, "episode/length": 152.0, "episode/score": 0.1745570164084711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1745570164084711}
{"step": 170200, "time": 8821.324528932571, "episode/length": 144.0, "episode/score": 0.16417240623923135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16417240623923135}
{"step": 170544, "time": 8837.594819068909, "episode/length": 157.0, "episode/score": 0.17288991084387817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17288991084387817}
{"step": 170640, "time": 8842.64831829071, "episode/length": 236.0, "episode/score": 0.27955339882191765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27955339882191765}
{"step": 170696, "time": 8845.990536689758, "episode/length": 288.0, "episode/score": 0.3264433463955356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3264433463955356}
{"step": 170832, "time": 8852.741214990616, "episode/length": 181.0, "episode/score": 0.192055324154353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.192055324154353}
{"step": 170936, "time": 8858.056084156036, "episode/length": 165.0, "episode/score": 0.19791666301898658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19791666301898658}
{"step": 171000, "time": 8861.968017578125, "episode/length": 37.0, "episode/score": 0.03661926918721292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03661926918721292}
{"step": 171184, "time": 8870.563171386719, "episode/length": 122.0, "episode/score": 0.1471931254163792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1471931254163792}
{"step": 171224, "time": 8873.156537771225, "episode/length": 412.0, "episode/score": 0.35990033783946274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35990033783946274}
{"step": 171536, "time": 8886.723586320877, "episode/length": 166.0, "episode/score": 0.17179598382426775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17179598382426775}
{"step": 171928, "time": 8902.706335544586, "episode/length": 172.0, "episode/score": 0.16118101700612897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16118101700612897}
{"step": 172104, "time": 8912.069158792496, "episode/length": 182.0, "episode/score": 0.20391845142694365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20391845142694365}
{"step": 172368, "time": 8923.719305753708, "episode/length": 191.0, "episode/score": 0.21330220609888784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21330220609888784}
{"step": 172424, "time": 8927.04214143753, "episode/length": 154.0, "episode/score": 0.16934315360231267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16934315360231267}
{"step": 172808, "time": 8942.978623628616, "episode/length": 225.0, "episode/score": 0.2593484973995146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2593484973995146}
{"step": 172976, "time": 8951.133937835693, "episode/length": 179.0, "episode/score": 0.1980458748748788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1980458748748788}
{"step": 173048, "time": 8955.127124071121, "episode/length": 227.0, "episode/score": 0.25129472350727156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25129472350727156}
{"step": 173176, "time": 8961.4859957695, "episode/length": 93.0, "episode/score": 0.10795016406882496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10795016406882496}
{"step": 173368, "time": 8970.130551338196, "episode/length": 124.0, "episode/score": 0.141807582628644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.141807582628644}
{"step": 173392, "time": 8972.744143247604, "episode/length": 306.0, "episode/score": 0.30109859406275064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30109859406275064}
{"step": 173456, "time": 8976.677124023438, "episode/length": 190.0, "episode/score": 0.20073976605999633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20073976605999633}
{"step": 173496, "time": 8979.549900531769, "episode/length": 173.0, "episode/score": 0.1948647655599416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1948647655599416}
{"step": 174112, "time": 9004.363386154175, "episode/length": 141.0, "episode/score": 0.16163912594493013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16163912594493013}
{"step": 174144, "time": 9007.002197027206, "episode/length": 166.0, "episode/score": 0.15533497717206046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15533497717206046}
{"step": 174384, "time": 9017.4734852314, "episode/length": 166.0, "episode/score": 0.16084805567061267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16084805567061267}
{"step": 174600, "time": 9026.769794464111, "episode/length": 177.0, "episode/score": 0.19400085173583648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19400085173583648}
{"step": 174840, "time": 9037.209349870682, "episode/length": 167.0, "episode/score": 0.17161883513381326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17161883513381326}
{"step": 174872, "time": 9039.902078151703, "episode/length": 184.0, "episode/score": 0.18174077442290582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18174077442290582}
{"step": 175240, "time": 9055.264454364777, "episode/length": 233.0, "episode/score": 0.24954190722473868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24954190722473868}
{"step": 175280, "time": 9059.192605018616, "episode/length": 145.0, "episode/score": 0.12489707255144822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12489707255144822}
{"step": 175312, "time": 9061.919821500778, "episode/length": 231.0, "episode/score": 0.25062461901870847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25062461901870847}
{"step": 175448, "time": 9068.39079618454, "episode/length": 162.0, "episode/score": 0.16286365260748425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16286365260748425}
{"step": 175512, "time": 9072.280664205551, "episode/length": 140.0, "episode/score": 0.1553213284046251, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1553213284046251}
{"step": 175928, "time": 9089.287775278091, "episode/length": 165.0, "episode/score": 0.15439609586655934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15439609586655934}
{"step": 175968, "time": 9092.464796066284, "episode/length": 140.0, "episode/score": 0.16873401041357283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16873401041357283}
{"step": 176408, "time": 9110.089076757431, "episode/length": 145.0, "episode/score": 0.16797188838108923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16797188838108923}
{"step": 176480, "time": 9114.46002483368, "episode/length": 149.0, "episode/score": 0.14550383313508064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14550383313508064}
{"step": 176576, "time": 9119.491444587708, "episode/length": 140.0, "episode/score": 0.14241892601467043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14241892601467043}
{"step": 176856, "time": 9131.227373600006, "episode/length": 167.0, "episode/score": 0.1807525276663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1807525276663}
{"step": 177056, "time": 9140.407202482224, "episode/length": 140.0, "episode/score": 0.16626162669126643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16626162669126643}
{"step": 177104, "time": 9143.673647880554, "episode/length": 141.0, "episode/score": 0.14648714027725873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14648714027725873}
{"step": 177240, "time": 9149.963149547577, "episode/length": 240.0, "episode/score": 0.26319902187060507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26319902187060507}
{"step": 177648, "time": 9166.962394714355, "episode/length": 145.0, "episode/score": 0.14429315768438755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14429315768438755}
{"step": 177944, "time": 9179.879546403885, "episode/length": 170.0, "episode/score": 0.1877055480222225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1877055480222225}
{"step": 178024, "time": 9184.360207080841, "episode/length": 393.0, "episode/score": 0.4240366571334562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4240366571334562}
{"step": 178056, "time": 9187.253220558167, "episode/length": 149.0, "episode/score": 0.14013108398785334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14013108398785334}
{"step": 178128, "time": 9191.756078004837, "episode/length": 110.0, "episode/score": 0.12604015919941958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12604015919941958}
{"step": 178440, "time": 9204.580209255219, "episode/length": 172.0, "episode/score": 0.18347174778136832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18347174778136832}
{"step": 179016, "time": 9227.559685468674, "episode/length": 238.0, "episode/score": 0.2540509898485652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2540509898485652}
{"step": 179256, "time": 9238.007426738739, "episode/length": 163.0, "episode/score": 0.16480152902613554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16480152902613554}
{"step": 179696, "time": 9256.216785430908, "episode/length": 410.0, "episode/score": 0.41167788018037754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41167788018037754}
{"step": 179744, "time": 9259.58558511734, "episode/length": 210.0, "episode/score": 0.24048369017418736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24048369017418736}
{"step": 179752, "time": 9261.261415719986, "episode/length": 202.0, "episode/score": 0.21019633974583485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21019633974583485}
{"step": 179872, "time": 9267.53167796135, "episode/length": 178.0, "episode/score": 0.19576391534883442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19576391534883442}
{"step": 180024, "time": 9290.712167263031, "eval_episode/length": 91.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9456521739130435}
{"step": 180024, "time": 9292.559691905975, "eval_episode/length": 101.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9411764705882353}
{"step": 180024, "time": 9295.521080732346, "eval_episode/length": 137.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9637681159420289}
{"step": 180024, "time": 9297.130060434341, "eval_episode/length": 141.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 180024, "time": 9298.82708621025, "eval_episode/length": 146.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 180024, "time": 9301.088233470917, "eval_episode/length": 163.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 180024, "time": 9304.250566720963, "eval_episode/length": 203.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 180024, "time": 9308.228446245193, "eval_episode/length": 140.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 180249, "time": 9319.020835638046, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.413680303664434, "train/action_min": 0.0, "train/action_std": 4.684617038757082, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004804609611349564, "train/actor_opt_grad_steps": 10535.0, "train/actor_opt_loss": -1.4985855876926393, "train/adv_mag": 0.13086211787802832, "train/adv_max": 0.07903946528122538, "train/adv_mean": 0.00033148777238004246, "train/adv_min": -0.1299528538707703, "train/adv_std": 0.010158928924254955, "train/cont_avg": 0.9943111359126984, "train/cont_loss_mean": 0.00047875315386132597, "train/cont_loss_std": 0.013286320504899805, "train/cont_neg_acc": 0.9855631159411536, "train/cont_neg_loss": 0.033125467530643014, "train/cont_pos_acc": 0.9999141281559354, "train/cont_pos_loss": 0.00030983132346465127, "train/cont_pred": 0.9942543667460245, "train/cont_rate": 0.9943111359126984, "train/dyn_loss_mean": 12.730860225738041, "train/dyn_loss_std": 7.983658680840144, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16023653142509006, "train/extr_critic_critic_opt_grad_steps": 10535.0, "train/extr_critic_critic_opt_loss": 7374.083248077877, "train/extr_critic_mag": 0.22563687960306802, "train/extr_critic_max": 0.22563687960306802, "train/extr_critic_mean": 0.17040471815400654, "train/extr_critic_min": 0.007737853224315341, "train/extr_critic_std": 0.04403852501381484, "train/extr_return_normed_mag": 0.15845731444775113, "train/extr_return_normed_max": 0.15845731444775113, "train/extr_return_normed_mean": 0.1048255025276116, "train/extr_return_normed_min": -0.06495577871562942, "train/extr_return_normed_std": 0.04539661567717317, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.22436805660762485, "train/extr_return_raw_max": 0.22436805660762485, "train/extr_return_raw_mean": 0.17073625054151292, "train/extr_return_raw_min": 0.0009549648042709108, "train/extr_return_raw_std": 0.045396615706738974, "train/extr_reward_mag": 0.0013315072135319786, "train/extr_reward_max": 0.0013315072135319786, "train/extr_reward_mean": 0.001083199124199353, "train/extr_reward_min": 1.0030610220772879e-05, "train/extr_reward_std": 0.0002451387416739534, "train/image_loss_mean": 8.414649422206576, "train/image_loss_std": 12.242130037338015, "train/model_loss_mean": 16.09320869143047, "train/model_loss_std": 15.429355174776108, "train/model_opt_grad_norm": 76.69277674054342, "train/model_opt_grad_steps": 10521.960317460318, "train/model_opt_loss": 12459.915965246775, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 773.8095238095239, "train/policy_entropy_mag": 2.76451894025954, "train/policy_entropy_max": 2.76451894025954, "train/policy_entropy_mean": 2.287693871392144, "train/policy_entropy_min": 0.1171068445084587, "train/policy_entropy_std": 0.4572757108817025, "train/policy_logprob_mag": 7.427195806351919, "train/policy_logprob_max": -0.015391464374722942, "train/policy_logprob_mean": -2.2883191212775214, "train/policy_logprob_min": -7.427195806351919, "train/policy_logprob_std": 1.0137451385694838, "train/policy_randomness_mag": 0.9757538679100218, "train/policy_randomness_max": 0.9757538679100218, "train/policy_randomness_mean": 0.8074555420686328, "train/policy_randomness_min": 0.04133357715216421, "train/policy_randomness_std": 0.16139825752803258, "train/post_ent_mag": 54.65211389935206, "train/post_ent_max": 54.65211389935206, "train/post_ent_mean": 36.5699287596203, "train/post_ent_min": 19.77283393012153, "train/post_ent_std": 6.0168586344946, "train/prior_ent_mag": 64.67341123308454, "train/prior_ent_max": 64.67341123308454, "train/prior_ent_mean": 49.40756652468727, "train/prior_ent_min": 24.34117043207562, "train/prior_ent_std": 6.0717782330891445, "train/rep_loss_mean": 12.730860225738041, "train/rep_loss_std": 7.983658680840144, "train/reward_avg": 0.001045604384714915, "train/reward_loss_mean": 0.03956438201878752, "train/reward_loss_std": 0.01200344485215961, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012961096233791774, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039564382462274464, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010454081080203492, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 0.6045044957920238, "train_stats/max_log_achievement_collect_drink": 0.6846846846846847, "train_stats/max_log_achievement_collect_sapling": 0.6576576576576577, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.4594594594594595, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.36936936936936937, "train_stats/max_log_achievement_place_table": 0.06306306306306306, "train_stats/max_log_achievement_wake_up": 0.18018018018018017, "train_stats/mean_log_entropy": 2.319097234322144, "eval_stats/sum_log_reward": 0.6625000028871, "eval_stats/max_log_achievement_collect_drink": 1.125, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.3125, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 6.081078390707262e-05, "report/cont_loss_std": 0.0007484360248781741, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.006604814436286688, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.870084972528275e-05, "report/cont_pred": 0.995120644569397, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.882792472839355, "report/dyn_loss_std": 8.048890113830566, "report/image_loss_mean": 7.732600212097168, "report/image_loss_std": 12.643525123596191, "report/model_loss_mean": 15.499786376953125, "report/model_loss_std": 15.901229858398438, "report/post_ent_mag": 54.12446975708008, "report/post_ent_max": 54.12446975708008, "report/post_ent_mean": 35.408538818359375, "report/post_ent_min": 20.02836036682129, "report/post_ent_std": 5.726324558258057, "report/prior_ent_mag": 64.66858673095703, "report/prior_ent_max": 64.66858673095703, "report/prior_ent_mean": 48.668731689453125, "report/prior_ent_min": 22.301551818847656, "report/prior_ent_std": 6.46829891204834, "report/rep_loss_mean": 12.882792472839355, "report/rep_loss_std": 8.048890113830566, "report/reward_avg": 0.0009869916830211878, "report/reward_loss_mean": 0.037450797855854034, "report/reward_loss_std": 0.014372716657817364, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013517141342163086, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.037450797855854034, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001019899151287973, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0006054326659068465, "eval/cont_loss_std": 0.018490202724933624, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.2980748116970062, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.330088864255231e-05, "eval/cont_pred": 0.9984639883041382, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.209041595458984, "eval/dyn_loss_std": 9.414416313171387, "eval/image_loss_mean": 16.698078155517578, "eval/image_loss_std": 21.619199752807617, "eval/model_loss_mean": 28.14090919494629, "eval/model_loss_std": 25.132543563842773, "eval/post_ent_mag": 52.187461853027344, "eval/post_ent_max": 52.187461853027344, "eval/post_ent_mean": 36.77669906616211, "eval/post_ent_min": 20.855682373046875, "eval/post_ent_std": 5.421377182006836, "eval/prior_ent_mag": 64.66858673095703, "eval/prior_ent_max": 64.66858673095703, "eval/prior_ent_mean": 51.58442306518555, "eval/prior_ent_min": 26.273754119873047, "eval/prior_ent_std": 5.047168254852295, "eval/rep_loss_mean": 18.209041595458984, "eval/rep_loss_std": 9.414416313171387, "eval/reward_avg": 0.0062500000931322575, "eval/reward_loss_mean": 0.5168017745018005, "eval/reward_loss_std": 2.94201397895813, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013360977172851562, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.34298187494277954, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 18.14214515686035, "eval/reward_pred": 0.0010320856235921383, "eval/reward_rate": 0.009765625, "replay/size": 179745.0, "replay/inserts": 20192.0, "replay/samples": 20192.0, "replay/insert_wait_avg": 1.319295914161791e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.218781506013946e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 37112.0, "eval_replay/inserts": 4080.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1742699380014456e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0665221214294, "timer/env.step_count": 2524.0, "timer/env.step_total": 233.64524507522583, "timer/env.step_frac": 0.23362970353171797, "timer/env.step_avg": 0.09256943148780739, "timer/env.step_min": 0.022369384765625, "timer/env.step_max": 3.1214420795440674, "timer/replay._sample_count": 20192.0, "timer/replay._sample_total": 10.085235118865967, "timer/replay._sample_frac": 0.010084564272256884, "timer/replay._sample_avg": 0.0004994668739533462, "timer/replay._sample_min": 0.0003943443298339844, "timer/replay._sample_max": 0.008724212646484375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3034.0, "timer/agent.policy_total": 48.328638315200806, "timer/agent.policy_frac": 0.04832542360550359, "timer/agent.policy_avg": 0.01592901724297983, "timer/agent.policy_min": 0.009555339813232422, "timer/agent.policy_max": 0.11431121826171875, "timer/dataset_train_count": 1262.0, "timer/dataset_train_total": 0.1358170509338379, "timer/dataset_train_frac": 0.00013580801669646012, "timer/dataset_train_avg": 0.00010762048409971306, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.000194549560546875, "timer/agent.train_count": 1262.0, "timer/agent.train_total": 568.7377269268036, "timer/agent.train_frac": 0.5686998958032781, "timer/agent.train_avg": 0.4506638089752802, "timer/agent.train_min": 0.4376945495605469, "timer/agent.train_max": 1.1555776596069336, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47234511375427246, "timer/agent.report_frac": 0.0004723136944453378, "timer/agent.report_avg": 0.23617255687713623, "timer/agent.report_min": 0.2256155014038086, "timer/agent.report_max": 0.24672961235046387, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9085131845718194e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 20.190404784803388}
{"step": 180512, "time": 9328.99745464325, "episode/length": 357.0, "episode/score": 0.3710956429063117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3710956429063117}
{"step": 180648, "time": 9335.32910823822, "episode/length": 173.0, "episode/score": 0.19310136819558466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19310136819558466}
{"step": 180896, "time": 9346.470746278763, "episode/length": 142.0, "episode/score": 0.13652894586084585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13652894586084585}
{"step": 180984, "time": 9351.037891626358, "episode/length": 160.0, "episode/score": 0.1764806753517405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1764806753517405}
{"step": 181056, "time": 9355.43938779831, "episode/length": 378.0, "episode/score": 0.36627648308285643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.36627648308285643}
{"step": 181824, "time": 9385.708364486694, "episode/length": 259.0, "episode/score": 0.278079674510991, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.278079674510991}
{"step": 181848, "time": 9387.941007375717, "episode/length": 246.0, "episode/score": 0.2713425677848136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2713425677848136}
{"step": 182000, "time": 9395.309435844421, "episode/length": 185.0, "episode/score": 0.20525127325299763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20525127325299763}
{"step": 182128, "time": 9401.770085573196, "episode/length": 388.0, "episode/score": 0.4227004164054051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4227004164054051}
{"step": 182432, "time": 9414.57585144043, "episode/length": 180.0, "episode/score": 0.17525498709937892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17525498709937892}
{"step": 182496, "time": 9418.424792528152, "episode/length": 179.0, "episode/score": 0.18263797830695694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18263797830695694}
{"step": 182664, "time": 9426.003124952316, "episode/length": 251.0, "episode/score": 0.27158670401877316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27158670401877316}
{"step": 183120, "time": 9444.851760864258, "episode/length": 158.0, "episode/score": 0.17059361694464314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17059361694464314}
{"step": 183216, "time": 9449.907252073288, "episode/length": 173.0, "episode/score": 0.1854364367359267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1854364367359267}
{"step": 183424, "time": 9459.311156749725, "episode/length": 161.0, "episode/score": 0.18624416322631987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18624416322631987}
{"step": 183496, "time": 9463.32401895523, "episode/length": 324.0, "episode/score": 0.3652443233727354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3652443233727354}
{"step": 183536, "time": 9466.503467082977, "episode/length": 191.0, "episode/score": 0.20297947599829058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20297947599829058}
{"step": 183664, "time": 9472.845981121063, "episode/length": 145.0, "episode/score": 0.14921861504376466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14921861504376466}
{"step": 183920, "time": 9483.807888746262, "episode/length": 156.0, "episode/score": 0.1605813335838775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1605813335838775}
{"step": 184184, "time": 9494.993149995804, "episode/length": 218.0, "episode/score": 0.24432736300286706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24432736300286706}
{"step": 184280, "time": 9500.076952934265, "episode/length": 144.0, "episode/score": 0.15426415603178611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15426415603178611}
{"step": 184376, "time": 9505.133729457855, "episode/length": 144.0, "episode/score": 0.14120778368874198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14120778368874198}
{"step": 184688, "time": 9518.775635242462, "episode/length": 143.0, "episode/score": 0.14433792152794922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14433792152794922}
{"step": 184824, "time": 9525.51728773117, "episode/length": 165.0, "episode/score": 0.1774667503245837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1774667503245837}
{"step": 184824, "time": 9525.524989128113, "episode/length": 174.0, "episode/score": 0.18634997069898418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18634997069898418}
{"step": 185008, "time": 9535.691653251648, "episode/length": 167.0, "episode/score": 0.17293537310820284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17293537310820284}
{"step": 185376, "time": 9550.788551568985, "episode/length": 181.0, "episode/score": 0.19642757105179953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19642757105179953}
{"step": 185384, "time": 9552.393680334091, "episode/length": 149.0, "episode/score": 0.16744151962780052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16744151962780052}
{"step": 185792, "time": 9569.275257587433, "episode/length": 176.0, "episode/score": 0.19927641061303802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19927641061303802}
{"step": 186000, "time": 9578.713362932205, "episode/length": 146.0, "episode/score": 0.14878028404154975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14878028404154975}
{"step": 186040, "time": 9581.421560764313, "episode/length": 151.0, "episode/score": 0.17774809081674903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17774809081674903}
{"step": 186352, "time": 9594.65694141388, "episode/length": 207.0, "episode/score": 0.21838097789986932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21838097789986932}
{"step": 186424, "time": 9598.649743795395, "episode/length": 176.0, "episode/score": 0.1885973927478517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1885973927478517}
{"step": 186560, "time": 9605.801137685776, "episode/length": 146.0, "episode/score": 0.15013343642317523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15013343642317523}
{"step": 186592, "time": 9608.590158224106, "episode/length": 151.0, "episode/score": 0.18396158058499168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18396158058499168}
{"step": 187144, "time": 9630.379276752472, "episode/length": 142.0, "episode/score": 0.12409025084775749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12409025084775749}
{"step": 187376, "time": 9640.948134422302, "episode/length": 386.0, "episode/score": 0.35376072003236914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35376072003236914}
{"step": 187512, "time": 9647.391808748245, "episode/length": 183.0, "episode/score": 0.2088058850897596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2088058850897596}
{"step": 187592, "time": 9651.86541891098, "episode/length": 145.0, "episode/score": 0.15673000004494497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15673000004494497}
{"step": 187712, "time": 9658.089258909225, "episode/length": 169.0, "episode/score": 0.1712404801496632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1712404801496632}
{"step": 187792, "time": 9662.515899419785, "episode/length": 249.0, "episode/score": 0.26415704302348786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26415704302348786}
{"step": 187800, "time": 9664.205956697464, "episode/length": 150.0, "episode/score": 0.16300453289113648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16300453289113648}
{"step": 188064, "time": 9675.76804971695, "episode/length": 187.0, "episode/score": 0.1822557038060495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1822557038060495}
{"step": 188304, "time": 9686.212272167206, "episode/length": 144.0, "episode/score": 0.16068341035520461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16068341035520461}
{"step": 188632, "time": 9700.944197177887, "episode/length": 156.0, "episode/score": 0.17606150489882566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17606150489882566}
{"step": 188912, "time": 9713.001460790634, "episode/length": 164.0, "episode/score": 0.15082151722594972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15082151722594972}
{"step": 188960, "time": 9716.229767560959, "episode/length": 180.0, "episode/score": 0.21404456269260663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21404456269260663}
{"step": 189072, "time": 9721.946568965912, "episode/length": 169.0, "episode/score": 0.18778098909865548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18778098909865548}
{"step": 189608, "time": 9743.40370106697, "episode/length": 192.0, "episode/score": 0.19225256911136057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19225256911136057}
{"step": 189752, "time": 9750.753276109695, "episode/length": 180.0, "episode/score": 0.19501662986681367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19501662986681367}
{"step": 189768, "time": 9752.87877035141, "episode/length": 245.0, "episode/score": 0.27350852495123945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27350852495123945}
{"step": 190008, "time": 9778.79829955101, "eval_episode/length": 71.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9305555555555556}
{"step": 190008, "time": 9783.176844596863, "eval_episode/length": 142.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.993006993006993}
{"step": 190008, "time": 9785.08689379692, "eval_episode/length": 150.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 190008, "time": 9787.157580375671, "eval_episode/length": 159.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.99375}
{"step": 190008, "time": 9788.867458105087, "eval_episode/length": 160.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 190008, "time": 9790.419005155563, "eval_episode/length": 163.0, "eval_episode/score": -0.8999999985098839, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 190008, "time": 9793.05036020279, "eval_episode/length": 191.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 190008, "time": 9798.581295967102, "eval_episode/length": 144.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.993103448275862}
{"step": 190104, "time": 9802.149524450302, "episode/length": 148.0, "episode/score": 0.13969436923002831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13969436923002831}
{"step": 190400, "time": 9814.993355989456, "episode/length": 165.0, "episode/score": 0.18825067288594255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18825067288594255}
{"step": 190632, "time": 9824.957925081253, "episode/length": 208.0, "episode/score": 0.22968294695897384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22968294695897384}
{"step": 190816, "time": 9833.41003036499, "episode/length": 150.0, "episode/score": 0.1577509616270163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1577509616270163}
{"step": 190960, "time": 9840.118578672409, "episode/length": 150.0, "episode/score": 0.14408218261564798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14408218261564798}
{"step": 191104, "time": 9846.888786315918, "episode/length": 413.0, "episode/score": 0.43015284354964933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.43015284354964933}
{"step": 191344, "time": 9857.387167930603, "episode/length": 338.0, "episode/score": 0.3536714337021749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3536714337021749}
{"step": 191536, "time": 9866.032235145569, "episode/length": 141.0, "episode/score": 0.1382085664713486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1382085664713486}
{"step": 191560, "time": 9868.247180223465, "episode/length": 223.0, "episode/score": 0.2232878365061879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2232878365061879}
{"step": 191976, "time": 9885.72737789154, "episode/length": 233.0, "episode/score": 0.27415396963397143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27415396963397143}
{"step": 192096, "time": 9892.122017383575, "episode/length": 182.0, "episode/score": 0.203810257442683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.203810257442683}
{"step": 192432, "time": 9906.710562467575, "episode/length": 183.0, "episode/score": 0.19175355224433588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19175355224433588}
{"step": 192536, "time": 9911.957638025284, "episode/length": 214.0, "episode/score": 0.2337531504188064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2337531504188064}
{"step": 192576, "time": 9915.238339662552, "episode/length": 183.0, "episode/score": 0.19222995802556397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19222995802556397}
{"step": 192632, "time": 9918.603879213333, "episode/length": 160.0, "episode/score": 0.17321834151516668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17321834151516668}
{"step": 192664, "time": 9921.195498466492, "episode/length": 137.0, "episode/score": 0.1324818803332164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1324818803332164}
{"step": 192704, "time": 9924.362421274185, "episode/length": 145.0, "episode/score": 0.15291874806280248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15291874806280248}
{"step": 193120, "time": 9941.380362510681, "episode/length": 142.0, "episode/score": 0.15446588659688132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15446588659688132}
{"step": 193224, "time": 9946.533629655838, "episode/length": 98.0, "episode/score": 0.11779166443739086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11779166443739086}
{"step": 193808, "time": 9969.92564868927, "episode/length": 153.0, "episode/score": 0.15647120327776065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15647120327776065}
{"step": 193840, "time": 9972.605071783066, "episode/length": 150.0, "episode/score": 0.15907228747892077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15907228747892077}
{"step": 194112, "time": 9984.225904464722, "episode/length": 196.0, "episode/score": 0.2094394155210466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2094394155210466}
{"step": 194128, "time": 9986.347063302994, "episode/length": 177.0, "episode/score": 0.19505047078928328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19505047078928328}
{"step": 194360, "time": 9996.222465753555, "episode/length": 211.0, "episode/score": 0.21726356511135236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21726356511135236}
{"step": 194472, "time": 10001.871913194656, "episode/length": 155.0, "episode/score": 0.1717982026457321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1717982026457321}
{"step": 194552, "time": 10006.33131980896, "episode/length": 306.0, "episode/score": 0.34741723163460847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34741723163460847}
{"step": 194568, "time": 10008.384670972824, "episode/length": 180.0, "episode/score": 0.19685805949302448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19685805949302448}
{"step": 195264, "time": 10035.954622268677, "episode/length": 181.0, "episode/score": 0.1960718868431286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1960718868431286}
{"step": 195320, "time": 10039.461018323898, "episode/length": 148.0, "episode/score": 0.16346525929111522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16346525929111522}
{"step": 195336, "time": 10041.550076723099, "episode/length": 152.0, "episode/score": 0.17365710365993436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17365710365993436}
{"step": 195504, "time": 10049.409554243088, "episode/length": 142.0, "episode/score": 0.14155380602096557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14155380602096557}
{"step": 196008, "time": 10069.523045778275, "episode/length": 270.0, "episode/score": 0.30415117568918504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30415117568918504}
{"step": 196160, "time": 10076.992282629013, "episode/length": 210.0, "episode/score": 0.21092822881109896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21092822881109896}
{"step": 196528, "time": 10092.264973640442, "episode/length": 246.0, "episode/score": 0.26245486762491055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26245486762491055}
{"step": 196552, "time": 10094.504251241684, "episode/length": 153.0, "episode/score": 0.15121702737451415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15121702737451415}
{"step": 196640, "time": 10101.001359462738, "episode/length": 141.0, "episode/score": 0.16186038411251502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16186038411251502}
{"step": 196664, "time": 10103.220320940018, "episode/length": 174.0, "episode/score": 0.18181085344440362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18181085344440362}
{"step": 196824, "time": 10110.809283018112, "episode/length": 185.0, "episode/score": 0.18685366605313902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18685366605313902}
{"step": 196848, "time": 10113.311254024506, "episode/length": 284.0, "episode/score": 0.3243428934147232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3243428934147232}
{"step": 197480, "time": 10138.304715156555, "episode/length": 183.0, "episode/score": 0.1900228149315808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1900228149315808}
{"step": 197552, "time": 10142.745612382889, "episode/length": 173.0, "episode/score": 0.1843795548847993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1843795548847993}
{"step": 198096, "time": 10164.582044839859, "episode/length": 195.0, "episode/score": 0.20250773867155658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20250773867155658}
{"step": 198104, "time": 10166.31812787056, "episode/length": 159.0, "episode/score": 0.1725544900764362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1725544900764362}
{"step": 198280, "time": 10174.462747812271, "episode/length": 201.0, "episode/score": 0.2284313968193601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2284313968193601}
{"step": 198720, "time": 10192.901469230652, "episode/length": 145.0, "episode/score": 0.14454331056549563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14454331056549563}
{"step": 198720, "time": 10192.910287618637, "episode/length": 270.0, "episode/score": 0.2926833826204529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2926833826204529}
{"step": 198752, "time": 10197.250436544418, "episode/length": 237.0, "episode/score": 0.2798600043024635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2798600043024635}
{"step": 198840, "time": 10201.873898983002, "episode/length": 274.0, "episode/score": 0.31308939278824255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31308939278824255}
{"step": 199008, "time": 10209.912721395493, "episode/length": 190.0, "episode/score": 0.20768806904015946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20768806904015946}
{"step": 199416, "time": 10226.512256860733, "episode/length": 163.0, "episode/score": 0.16784167540390627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16784167540390627}
{"step": 199664, "time": 10237.539830446243, "episode/length": 195.0, "episode/score": 0.20868199642609397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20868199642609397}
{"step": 200096, "time": 10269.034426689148, "eval_episode/length": 45.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9130434782608695}
{"step": 200096, "time": 10273.386142015457, "eval_episode/length": 115.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9482758620689655}
{"step": 200096, "time": 10276.905326128006, "eval_episode/length": 138.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 200096, "time": 10278.955647945404, "eval_episode/length": 142.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.972027972027972}
{"step": 200096, "time": 10278.964203834534, "eval_episode/length": 142.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.993006993006993}
{"step": 200096, "time": 10282.725188493729, "eval_episode/length": 154.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 200096, "time": 10284.429705142975, "eval_episode/length": 160.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 200096, "time": 10289.518667697906, "eval_episode/length": 131.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9924242424242424}
{"step": 200184, "time": 10292.567185401917, "episode/length": 167.0, "episode/score": 0.17797611408423109, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17797611408423109}
{"step": 200232, "time": 10295.917521953583, "episode/length": 188.0, "episode/score": 0.1894446616006462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1894446616006462}
{"step": 200352, "time": 10302.231563806534, "episode/length": 199.0, "episode/score": 0.2283375079077814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2283375079077814}
{"step": 200745, "time": 10319.158279657364, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.243316886960998, "train/action_min": 0.0, "train/action_std": 4.670070082642312, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005537857485631871, "train/actor_opt_grad_steps": 11810.0, "train/actor_opt_loss": 7.449051296468391, "train/adv_mag": 0.14030186242835466, "train/adv_max": 0.09463753048763719, "train/adv_mean": 0.0006650914398375415, "train/adv_min": -0.13973320102275805, "train/adv_std": 0.011230826580016187, "train/cont_avg": 0.9942693192829457, "train/cont_loss_mean": 0.00034317820756694895, "train/cont_loss_std": 0.009922063619493807, "train/cont_neg_acc": 0.9874492449353832, "train/cont_neg_loss": 0.038506456608463274, "train/cont_pos_acc": 0.9999467111373133, "train/cont_pos_loss": 0.00014913541496370687, "train/cont_pred": 0.9942682325377945, "train/cont_rate": 0.9942693192829457, "train/dyn_loss_mean": 12.876134731972865, "train/dyn_loss_std": 8.0857273885446, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17422672089680222, "train/extr_critic_critic_opt_grad_steps": 11810.0, "train/extr_critic_critic_opt_loss": 8996.716762808866, "train/extr_critic_mag": 0.23358863453532375, "train/extr_critic_max": 0.23358863453532375, "train/extr_critic_mean": 0.18689351673274077, "train/extr_critic_min": 0.006848337114319321, "train/extr_critic_std": 0.046935282445462176, "train/extr_return_normed_mag": 0.16589656576167705, "train/extr_return_normed_max": 0.16589656576167705, "train/extr_return_normed_mean": 0.11911483536394991, "train/extr_return_normed_min": -0.0674453452518282, "train/extr_return_normed_std": 0.04884217025408911, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2343402918457061, "train/extr_return_raw_max": 0.2343402918457061, "train/extr_return_raw_mean": 0.18755856572195542, "train/extr_return_raw_min": 0.0009983805722968524, "train/extr_return_raw_std": 0.04884217013857623, "train/extr_reward_mag": 0.0013557284377342046, "train/extr_reward_max": 0.0013557284377342046, "train/extr_reward_mean": 0.001076794669840687, "train/extr_reward_min": 1.2342319932094841e-05, "train/extr_reward_std": 0.0002477793306132143, "train/image_loss_mean": 8.498502394949742, "train/image_loss_std": 12.485324512156405, "train/model_loss_mean": 16.26393182148305, "train/model_loss_std": 15.81158100542172, "train/model_opt_grad_norm": 75.04555085647938, "train/model_opt_grad_steps": 11795.821705426357, "train/model_opt_loss": 10931.214737766473, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 678.2945736434109, "train/policy_entropy_mag": 2.763294027757275, "train/policy_entropy_max": 2.763294027757275, "train/policy_entropy_mean": 2.2547241366186808, "train/policy_entropy_min": 0.11407251650279807, "train/policy_entropy_std": 0.455645795709403, "train/policy_logprob_mag": 7.432887184527493, "train/policy_logprob_max": -0.01471497006569953, "train/policy_logprob_mean": -2.255087926406269, "train/policy_logprob_min": -7.432887184527493, "train/policy_logprob_std": 1.039048339969428, "train/policy_randomness_mag": 0.9753215275993643, "train/policy_randomness_max": 0.9753215275993643, "train/policy_randomness_mean": 0.7958186698514361, "train/policy_randomness_min": 0.040262592321102936, "train/policy_randomness_std": 0.16082296838131985, "train/post_ent_mag": 54.97737452780554, "train/post_ent_max": 54.97737452780554, "train/post_ent_mean": 37.098541348479515, "train/post_ent_min": 20.252812319023665, "train/post_ent_std": 6.097461216209471, "train/prior_ent_mag": 65.22310277657915, "train/prior_ent_max": 65.22310277657915, "train/prior_ent_mean": 50.10322703871616, "train/prior_ent_min": 25.49027119126431, "train/prior_ent_std": 6.064401508301728, "train/rep_loss_mean": 12.876134731972865, "train/rep_loss_std": 8.0857273885446, "train/reward_avg": 0.0010412059631379133, "train/reward_loss_mean": 0.0394055143345234, "train/reward_loss_std": 0.012185749879410101, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001319742017938185, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0394055143345234, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010429431834120967, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.1190476043593316, "train_stats/max_log_achievement_collect_drink": 2.5047619047619047, "train_stats/max_log_achievement_collect_sapling": 0.9523809523809523, "train_stats/max_log_achievement_collect_stone": 0.02857142857142857, "train_stats/max_log_achievement_collect_wood": 0.7428571428571429, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.009523809523809525, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009523809523809525, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.3333333333333333, "train_stats/max_log_achievement_place_table": 0.13333333333333333, "train_stats/max_log_achievement_wake_up": 0.20952380952380953, "train_stats/mean_log_entropy": 2.3051969176247007, "train_stats/max_log_achievement_collect_coal": 0.010309278350515464, "train_stats/max_log_achievement_place_stone": 0.010309278350515464, "eval_stats/sum_log_reward": 0.16250001173466444, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 0.75, "eval_stats/max_log_achievement_collect_sapling": 0.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.003404633840546012, "report/cont_loss_std": 0.10771038383245468, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00021887707407586277, "report/cont_pos_acc": 0.9990166425704956, "report/cont_pos_loss": 0.003426561364904046, "report/cont_pred": 0.9921848773956299, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.530813217163086, "report/dyn_loss_std": 8.390100479125977, "report/image_loss_mean": 8.53895378112793, "report/image_loss_std": 11.352359771728516, "report/model_loss_mean": 16.700716018676758, "report/model_loss_std": 14.890963554382324, "report/post_ent_mag": 56.786712646484375, "report/post_ent_max": 56.786712646484375, "report/post_ent_mean": 37.70843505859375, "report/post_ent_min": 20.45231819152832, "report/post_ent_std": 6.65803861618042, "report/prior_ent_mag": 66.04950714111328, "report/prior_ent_max": 66.04950714111328, "report/prior_ent_mean": 51.73871612548828, "report/prior_ent_min": 24.663143157958984, "report/prior_ent_std": 5.732748985290527, "report/rep_loss_mean": 13.530813217163086, "report/rep_loss_std": 8.390100479125977, "report/reward_avg": 0.0010573299368843436, "report/reward_loss_mean": 0.039869338274002075, "report/reward_loss_std": 0.012255087494850159, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012902021408081055, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.039869338274002075, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010619275271892548, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00038612671778537333, "eval/cont_loss_std": 0.012241357937455177, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.000885516288690269, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00038465936086140573, "eval/cont_pred": 0.9967554807662964, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.30413055419922, "eval/dyn_loss_std": 10.314667701721191, "eval/image_loss_mean": 15.063443183898926, "eval/image_loss_std": 18.633371353149414, "eval/model_loss_mean": 26.577587127685547, "eval/model_loss_std": 23.131120681762695, "eval/post_ent_mag": 52.128055572509766, "eval/post_ent_max": 52.128055572509766, "eval/post_ent_mean": 36.47221374511719, "eval/post_ent_min": 19.205097198486328, "eval/post_ent_std": 5.700283050537109, "eval/prior_ent_mag": 66.04950714111328, "eval/prior_ent_max": 66.04950714111328, "eval/prior_ent_mean": 51.057228088378906, "eval/prior_ent_min": 24.475940704345703, "eval/prior_ent_std": 5.736823558807373, "eval/rep_loss_mean": 18.30413055419922, "eval/rep_loss_std": 10.314667701721191, "eval/reward_avg": 0.00937500037252903, "eval/reward_loss_mean": 0.5312780141830444, "eval/reward_loss_std": 2.9942922592163086, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013104677200317383, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.3008245527744293, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 18.453460693359375, "eval/reward_pred": 0.0010353317484259605, "eval/reward_rate": 0.0126953125, "replay/size": 200241.0, "replay/inserts": 20496.0, "replay/samples": 20496.0, "replay/insert_wait_avg": 1.3293906360003838e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.113048301833761e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 41400.0, "eval_replay/inserts": 4288.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1778033491390855e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1238408088684, "timer/env.step_count": 2562.0, "timer/env.step_total": 226.55834364891052, "timer/env.step_frac": 0.22653028995456936, "timer/env.step_avg": 0.08843026684188544, "timer/env.step_min": 0.02238631248474121, "timer/env.step_max": 3.173283100128174, "timer/replay._sample_count": 20496.0, "timer/replay._sample_total": 10.017477989196777, "timer/replay._sample_frac": 0.010016237570234262, "timer/replay._sample_avg": 0.0004887528292933634, "timer/replay._sample_min": 0.0003459453582763672, "timer/replay._sample_max": 0.011141061782836914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3098.0, "timer/agent.policy_total": 49.61507987976074, "timer/agent.policy_frac": 0.04960893626896609, "timer/agent.policy_avg": 0.0160151968624147, "timer/agent.policy_min": 0.009464025497436523, "timer/agent.policy_max": 0.1171114444732666, "timer/dataset_train_count": 1281.0, "timer/dataset_train_total": 0.13717317581176758, "timer/dataset_train_frac": 0.0001371561902782222, "timer/dataset_train_avg": 0.00010708288509895985, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0004215240478515625, "timer/agent.train_count": 1281.0, "timer/agent.train_total": 573.6455066204071, "timer/agent.train_frac": 0.5735744746935147, "timer/agent.train_avg": 0.4478106999378666, "timer/agent.train_min": 0.4336392879486084, "timer/agent.train_max": 0.952822208404541, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46912455558776855, "timer/agent.report_frac": 0.00046906646601720396, "timer/agent.report_avg": 0.23456227779388428, "timer/agent.report_min": 0.22238993644714355, "timer/agent.report_max": 0.246734619140625, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9798632100992754e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 20.493204824901618}
{"step": 200760, "time": 10319.314311742783, "episode/length": 254.0, "episode/score": 0.26763063160797174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26763063160797174}
{"step": 200928, "time": 10327.985753059387, "episode/length": 239.0, "episode/score": 0.2604765310752555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2604765310752555}
{"step": 201032, "time": 10333.167727947235, "episode/length": 170.0, "episode/score": 0.1690810472209705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1690810472209705}
{"step": 201352, "time": 10346.634043693542, "episode/length": 241.0, "episode/score": 0.2554644015708618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2554644015708618}
{"step": 201408, "time": 10350.448095321655, "episode/length": 146.0, "episode/score": 0.1492410344653763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1492410344653763}
{"step": 201504, "time": 10355.485114574432, "episode/length": 402.0, "episode/score": 0.4071888061007485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4071888061007485}
{"step": 201544, "time": 10358.434329271317, "episode/length": 148.0, "episode/score": 0.15032002880616346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15032002880616346}
{"step": 201848, "time": 10371.425661802292, "episode/length": 207.0, "episode/score": 0.2293563422645093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2293563422645093}
{"step": 202064, "time": 10381.164551019669, "episode/length": 128.0, "episode/score": 0.15708333009388298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15708333009388298}
{"step": 202280, "time": 10390.578885793686, "episode/length": 189.0, "episode/score": 0.19934272819227772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19934272819227772}
{"step": 202480, "time": 10399.724418878555, "episode/length": 193.0, "episode/score": 0.2015688169230998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2015688169230998}
{"step": 202496, "time": 10401.814842700958, "episode/length": 142.0, "episode/score": 0.13061758179901517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13061758179901517}
{"step": 202648, "time": 10408.796813488007, "episode/length": 137.0, "episode/score": 0.14679794147377834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14679794147377834}
{"step": 202728, "time": 10413.35730433464, "episode/length": 152.0, "episode/score": 0.15115242043248145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15115242043248145}
{"step": 203048, "time": 10426.999149560928, "episode/length": 204.0, "episode/score": 0.23535096702471492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23535096702471492}
{"step": 203344, "time": 10439.685347557068, "episode/length": 186.0, "episode/score": 0.18517499256086012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18517499256086012}
{"step": 203584, "time": 10450.347655057907, "episode/length": 162.0, "episode/score": 0.15816967594037123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15816967594037123}
{"step": 203664, "time": 10454.807904958725, "episode/length": 199.0, "episode/score": 0.20912213496012555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20912213496012555}
{"step": 203808, "time": 10461.622631788254, "episode/length": 134.0, "episode/score": 0.13669386853507604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13669386853507604}
{"step": 203880, "time": 10465.639697313309, "episode/length": 174.0, "episode/score": 0.157065560513729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.157065560513729}
{"step": 204192, "time": 10479.16396188736, "episode/length": 142.0, "episode/score": 0.1679959690063697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1679959690063697}
{"step": 204336, "time": 10485.993802785873, "episode/length": 93.0, "episode/score": 0.09592625825189316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09592625825189316}
{"step": 204352, "time": 10488.061728715897, "episode/length": 212.0, "episode/score": 0.22224200009623019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22224200009623019}
{"step": 204400, "time": 10491.381192922592, "episode/length": 237.0, "episode/score": 0.2523814234264137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2523814234264137}
{"step": 204528, "time": 10497.703805446625, "episode/length": 147.0, "episode/score": 0.1586099841952091, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1586099841952091}
{"step": 205208, "time": 10526.035003900528, "episode/length": 165.0, "episode/score": 0.18226301816866908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18226301816866908}
{"step": 205344, "time": 10532.865115642548, "episode/length": 191.0, "episode/score": 0.17954602565896494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17954602565896494}
{"step": 205784, "time": 10550.697266817093, "episode/length": 172.0, "episode/score": 0.18398211173280288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18398211173280288}
{"step": 206040, "time": 10561.700409412384, "episode/length": 230.0, "episode/score": 0.26580066143287695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26580066143287695}
{"step": 206088, "time": 10564.981023073196, "episode/length": 302.0, "episode/score": 0.34381951789328014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34381951789328014}
{"step": 206160, "time": 10569.413703680038, "episode/length": 203.0, "episode/score": 0.23383810050745524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23383810050745524}
{"step": 206368, "time": 10578.671665430069, "episode/length": 253.0, "episode/score": 0.2530844501352476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2530844501352476}
{"step": 206624, "time": 10589.80260515213, "episode/length": 283.0, "episode/score": 0.3029594489998999, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3029594489998999}
{"step": 206664, "time": 10593.09266090393, "episode/length": 164.0, "episode/score": 0.18033422686130507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18033422686130507}
{"step": 206712, "time": 10596.97386598587, "episode/length": 187.0, "episode/score": 0.19318759307589062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19318759307589062}
{"step": 207104, "time": 10613.374651670456, "episode/length": 164.0, "episode/score": 0.1548369384390753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1548369384390753}
{"step": 207120, "time": 10615.472844362259, "episode/length": 61.0, "episode/score": 0.06380418960361567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06380418960361567}
{"step": 207208, "time": 10620.193912744522, "episode/length": 145.0, "episode/score": 0.15369350353012123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15369350353012123}
{"step": 207520, "time": 10633.54090642929, "episode/length": 143.0, "episode/score": 0.15665267308577313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15665267308577313}
{"step": 207872, "time": 10648.122677326202, "episode/length": 144.0, "episode/score": 0.1380050816142102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1380050816142102}
{"step": 207968, "time": 10653.232097864151, "episode/length": 225.0, "episode/score": 0.23533447712907218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23533447712907218}
{"step": 208104, "time": 10659.645352363586, "episode/length": 251.0, "episode/score": 0.2610479631121052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2610479631121052}
{"step": 208360, "time": 10670.73364186287, "episode/length": 143.0, "episode/score": 0.1499562967028396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1499562967028396}
{"step": 208376, "time": 10673.238013267517, "episode/length": 158.0, "episode/score": 0.14609560580629477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14609560580629477}
{"step": 208448, "time": 10678.255102157593, "episode/length": 165.0, "episode/score": 0.17281546650065138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17281546650065138}
{"step": 208984, "time": 10700.123364925385, "episode/length": 182.0, "episode/score": 0.18090214980338715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18090214980338715}
{"step": 209016, "time": 10702.74854850769, "episode/length": 142.0, "episode/score": 0.14483179549097258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14483179549097258}
{"step": 209520, "time": 10723.41565489769, "episode/length": 142.0, "episode/score": 0.1654097191726578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1654097191726578}
{"step": 209680, "time": 10730.92552447319, "episode/length": 153.0, "episode/score": 0.1592470689261063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1592470689261063}
{"step": 209960, "time": 10742.740963220596, "episode/length": 411.0, "episode/score": 0.42362048221002624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42362048221002624}
{"step": 210080, "time": 10765.442697286606, "eval_episode/length": 97.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9489795918367347}
{"step": 210080, "time": 10769.216835260391, "eval_episode/length": 153.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 210080, "time": 10771.189134836197, "eval_episode/length": 164.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 210080, "time": 10772.74256682396, "eval_episode/length": 165.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 210080, "time": 10774.34991812706, "eval_episode/length": 169.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 210080, "time": 10776.633766889572, "eval_episode/length": 188.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 210080, "time": 10778.493160247803, "eval_episode/length": 194.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 210080, "time": 10784.608806848526, "eval_episode/length": 140.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 210112, "time": 10785.794529676437, "episode/length": 73.0, "episode/score": 0.08290693979461139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08290693979461139}
{"step": 210136, "time": 10788.025527238846, "episode/length": 270.0, "episode/score": 0.31069724647750263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31069724647750263}
{"step": 210152, "time": 10790.141633033752, "episode/length": 223.0, "episode/score": 0.25717942086157564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25717942086157564}
{"step": 210184, "time": 10792.773335695267, "episode/length": 259.0, "episode/score": 0.2703881960073886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2703881960073886}
{"step": 210440, "time": 10803.785350322723, "episode/length": 177.0, "episode/score": 0.18784539952457635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18784539952457635}
{"step": 210448, "time": 10805.79778122902, "episode/length": 182.0, "episode/score": 0.17568529035725078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17568529035725078}
{"step": 210816, "time": 10821.119423151016, "episode/length": 141.0, "episode/score": 0.14632393832062007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14632393832062007}
{"step": 211272, "time": 10839.457919597626, "episode/length": 141.0, "episode/score": 0.14335760026369826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14335760026369826}
{"step": 211584, "time": 10852.897782087326, "episode/length": 95.0, "episode/score": 0.1051004548421588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1051004548421588}
{"step": 211736, "time": 10859.84464263916, "episode/length": 161.0, "episode/score": 0.1705912224574604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1705912224574604}
{"step": 212136, "time": 10876.449110507965, "episode/length": 243.0, "episode/score": 0.24005943452675638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24005943452675638}
{"step": 212264, "time": 10882.841961860657, "episode/length": 263.0, "episode/score": 0.31082932467870705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31082932467870705}
{"step": 212440, "time": 10890.871131420135, "episode/length": 309.0, "episode/score": 0.33529227932422145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33529227932422145}
{"step": 212544, "time": 10896.50286102295, "episode/length": 261.0, "episode/score": 0.2816199410644913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2816199410644913}
{"step": 212840, "time": 10908.88599061966, "episode/length": 195.0, "episode/score": 0.19770369908928842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19770369908928842}
{"step": 213336, "time": 10930.462082624435, "episode/length": 402.0, "episode/score": 0.39730169231779655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39730169231779655}
{"step": 213424, "time": 10935.48678445816, "episode/length": 229.0, "episode/score": 0.23756961840354052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23756961840354052}
{"step": 213488, "time": 10939.343396425247, "episode/length": 218.0, "episode/score": 0.22601737118020537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22601737118020537}
{"step": 213616, "time": 10945.775619983673, "episode/length": 168.0, "episode/score": 0.1776270132550053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1776270132550053}
{"step": 214232, "time": 10970.405171394348, "episode/length": 173.0, "episode/score": 0.18221049514249898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18221049514249898}
{"step": 214264, "time": 10973.069471120834, "episode/length": 227.0, "episode/score": 0.230517975708608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.230517975708608}
{"step": 214312, "time": 10976.345751285553, "episode/length": 271.0, "episode/score": 0.30373575451403667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30373575451403667}
{"step": 214480, "time": 10984.40137052536, "episode/length": 241.0, "episode/score": 0.2664283450753828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2664283450753828}
{"step": 214632, "time": 10991.370558261871, "episode/length": 126.0, "episode/score": 0.14674133930748212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14674133930748212}
{"step": 214768, "time": 10998.16450715065, "episode/length": 178.0, "episode/score": 0.17577471031836467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17577471031836467}
{"step": 214816, "time": 11001.47076678276, "episode/length": 62.0, "episode/score": 0.07084722093350138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07084722093350138}
{"step": 214992, "time": 11009.630342721939, "episode/length": 187.0, "episode/score": 0.1957432593408157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1957432593408157}
{"step": 215456, "time": 11028.493869781494, "episode/length": 102.0, "episode/score": 0.11883333121659234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11883333121659234}
{"step": 215488, "time": 11031.299072504044, "episode/length": 156.0, "episode/score": 0.17152370329858968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17152370329858968}
{"step": 215496, "time": 11032.951874017715, "episode/length": 258.0, "episode/score": 0.2896648150708643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2896648150708643}
{"step": 216056, "time": 11055.600131750107, "episode/length": 196.0, "episode/score": 0.21936308253134484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21936308253134484}
{"step": 216200, "time": 11062.504340410233, "episode/length": 241.0, "episode/score": 0.29329166072420776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29329166072420776}
{"step": 216216, "time": 11064.686720609665, "episode/length": 180.0, "episode/score": 0.1939369173742307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1939369173742307}
{"step": 216352, "time": 11071.462752342224, "episode/length": 169.0, "episode/score": 0.16700789240712766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16700789240712766}
{"step": 216616, "time": 11082.643998146057, "episode/length": 224.0, "episode/score": 0.2425813647932955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2425813647932955}
{"step": 217016, "time": 11099.226129293442, "episode/length": 189.0, "episode/score": 0.18797097815331654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18797097815331654}
{"step": 217112, "time": 11104.28288602829, "episode/length": 206.0, "episode/score": 0.22003339290313306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22003339290313306}
{"step": 217128, "time": 11106.338891744614, "episode/length": 204.0, "episode/score": 0.21816865022447018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21816865022447018}
{"step": 217424, "time": 11119.155183076859, "episode/length": 152.0, "episode/score": 0.1427561058262654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1427561058262654}
{"step": 217480, "time": 11122.627369642258, "episode/length": 140.0, "episode/score": 0.15804333820778993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15804333820778993}
{"step": 217568, "time": 11127.66368150711, "episode/length": 188.0, "episode/score": 0.19476936326282157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19476936326282157}
{"step": 217680, "time": 11133.249175071716, "episode/length": 182.0, "episode/score": 0.18226743421291758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18226743421291758}
{"step": 217816, "time": 11139.66042971611, "episode/length": 149.0, "episode/score": 0.14749283962737536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14749283962737536}
{"step": 218160, "time": 11154.178201675415, "episode/length": 42.0, "episode/score": 0.05174999899463728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05174999899463728}
{"step": 218312, "time": 11161.085318565369, "episode/length": 147.0, "episode/score": 0.15772888793435413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15772888793435413}
{"step": 218344, "time": 11163.838627815247, "episode/length": 153.0, "episode/score": 0.1756729019962222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1756729019962222}
{"step": 218424, "time": 11168.421849489212, "episode/length": 175.0, "episode/score": 0.18521267126743624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18521267126743624}
{"step": 218664, "time": 11178.809010744095, "episode/length": 154.0, "episode/score": 0.16318240686723584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16318240686723584}
{"step": 218952, "time": 11190.863149404526, "episode/length": 183.0, "episode/score": 0.2028882680233437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2028882680233437}
{"step": 219016, "time": 11194.773879528046, "episode/length": 166.0, "episode/score": 0.16560533257961652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16560533257961652}
{"step": 219144, "time": 11201.088927984238, "episode/length": 196.0, "episode/score": 0.19250706785169314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19250706785169314}
{"step": 219440, "time": 11213.745887517929, "episode/length": 140.0, "episode/score": 0.1302738517488251, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1302738517488251}
{"step": 219632, "time": 11222.400388002396, "episode/length": 150.0, "episode/score": 0.14817179867168306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14817179867168306}
{"step": 219800, "time": 11229.966875314713, "episode/length": 181.0, "episode/score": 0.18460996934391005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18460996934391005}
{"step": 219968, "time": 11237.846650362015, "episode/length": 225.0, "episode/score": 0.24708743942119327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24708743942119327}
{"step": 220064, "time": 11261.247900724411, "eval_episode/length": 94.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9473684210526315}
{"step": 220064, "time": 11264.43540430069, "eval_episode/length": 118.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.957983193277311}
{"step": 220064, "time": 11266.800558328629, "eval_episode/length": 139.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 220064, "time": 11268.304823637009, "eval_episode/length": 141.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 220064, "time": 11270.427181005478, "eval_episode/length": 150.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 220064, "time": 11272.988399028778, "eval_episode/length": 163.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 220064, "time": 11275.065861463547, "eval_episode/length": 165.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 220064, "time": 11278.336979150772, "eval_episode/length": 51.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9230769230769231}
{"step": 220080, "time": 11278.948460102081, "episode/length": 176.0, "episode/score": 0.19584252133972768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19584252133972768}
{"step": 220352, "time": 11291.328830957413, "episode/length": 47.0, "episode/score": 0.055291665717959404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055291665717959404}
{"step": 220400, "time": 11294.540858507156, "episode/length": 180.0, "episode/score": 0.1910298501888974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1910298501888974}
{"step": 220408, "time": 11296.151121139526, "episode/length": 157.0, "episode/score": 0.1721168345584374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1721168345584374}
{"step": 220768, "time": 11311.12897849083, "episode/length": 218.0, "episode/score": 0.24008193518875487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24008193518875487}
{"step": 220921, "time": 11319.227166175842, "train_stats/sum_log_reward": 1.0454545319757678, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.7818181818181817, "train_stats/max_log_achievement_collect_sapling": 0.8181818181818182, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.7090909090909091, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.07272727272727272, "train_stats/max_log_achievement_eat_cow": 0.02727272727272727, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.34545454545454546, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.08181818181818182, "train_stats/max_log_achievement_wake_up": 0.16363636363636364, "train_stats/mean_log_entropy": 2.218124620480971, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.016938224671379, "train/action_min": 0.0, "train/action_std": 4.51082968711853, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006956695074525972, "train/actor_opt_grad_steps": 13085.0, "train/actor_opt_loss": 0.06735338344578705, "train/adv_mag": 0.16109135492690027, "train/adv_max": 0.11026352765186438, "train/adv_mean": 0.0003976242956266813, "train/adv_min": -0.15982684173754283, "train/adv_std": 0.012907399300722376, "train/cont_avg": 0.9945203993055556, "train/cont_loss_mean": 0.0004960205118949929, "train/cont_loss_std": 0.013043732402100735, "train/cont_neg_acc": 0.9837870149612427, "train/cont_neg_loss": 0.032835623615563234, "train/cont_pos_acc": 0.9998985022779495, "train/cont_pos_loss": 0.0003070505794450388, "train/cont_pred": 0.9944563266776857, "train/cont_rate": 0.9945203993055556, "train/dyn_loss_mean": 12.79065584001087, "train/dyn_loss_std": 8.246672437304543, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1676315932519852, "train/extr_critic_critic_opt_grad_steps": 13085.0, "train/extr_critic_critic_opt_loss": 10864.909148685516, "train/extr_critic_mag": 0.25608634097235544, "train/extr_critic_max": 0.25608634097235544, "train/extr_critic_mean": 0.20417059544059965, "train/extr_critic_min": 0.004668420269375756, "train/extr_critic_std": 0.05396586959619844, "train/extr_return_normed_mag": 0.1929053891272772, "train/extr_return_normed_max": 0.1929053891272772, "train/extr_return_normed_mean": 0.1404407230752801, "train/extr_return_normed_min": -0.06310621823465067, "train/extr_return_normed_std": 0.055976527876087596, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2570328959633434, "train/extr_return_raw_max": 0.2570328959633434, "train/extr_return_raw_mean": 0.20456823174442565, "train/extr_return_raw_min": 0.0010212877440074132, "train/extr_return_raw_std": 0.05597652795000209, "train/extr_reward_mag": 0.001324432236807687, "train/extr_reward_max": 0.001324432236807687, "train/extr_reward_mean": 0.001081895454609323, "train/extr_reward_min": 8.243416982983785e-06, "train/extr_reward_std": 0.00024289132656237584, "train/image_loss_mean": 8.42641764595395, "train/image_loss_std": 12.792307637986683, "train/model_loss_mean": 16.140824809906974, "train/model_loss_std": 16.238210882459367, "train/model_opt_grad_norm": 65.07909394824316, "train/model_opt_grad_steps": 13070.0, "train/model_opt_loss": 14092.326605902777, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 868.0555555555555, "train/policy_entropy_mag": 2.7618964021168058, "train/policy_entropy_max": 2.7618964021168058, "train/policy_entropy_mean": 2.1629296512830827, "train/policy_entropy_min": 0.11024929316980499, "train/policy_entropy_std": 0.5177115052938461, "train/policy_logprob_mag": 7.434855203779917, "train/policy_logprob_max": -0.014122568595681399, "train/policy_logprob_mean": -2.163147611277444, "train/policy_logprob_min": -7.434855203779917, "train/policy_logprob_std": 1.1097165667821491, "train/policy_randomness_mag": 0.9748282252796112, "train/policy_randomness_max": 0.9748282252796112, "train/policy_randomness_mean": 0.7634192515933325, "train/policy_randomness_min": 0.03891316241037751, "train/policy_randomness_std": 0.182729442914327, "train/post_ent_mag": 55.83422721378387, "train/post_ent_max": 55.83422721378387, "train/post_ent_mean": 37.44775227137974, "train/post_ent_min": 20.748627617245628, "train/post_ent_std": 6.273651785320705, "train/prior_ent_mag": 65.83375325278631, "train/prior_ent_max": 65.83375325278631, "train/prior_ent_mean": 50.3773328387548, "train/prior_ent_min": 25.307767005193803, "train/prior_ent_std": 6.30136914101858, "train/rep_loss_mean": 12.79065584001087, "train/rep_loss_std": 8.246672437304543, "train/reward_avg": 0.0010447698527030528, "train/reward_loss_mean": 0.039517669894156005, "train/reward_loss_std": 0.012007070734860405, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001292990313635932, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03951766995328759, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010426854585400885, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.5374999884516001, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 0.75, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00020043847325723618, "report/cont_loss_std": 0.005019183270633221, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.560326538514346e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0002011240867432207, "report/cont_pred": 0.9959054589271545, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.894035339355469, "report/dyn_loss_std": 8.285503387451172, "report/image_loss_mean": 6.411802768707275, "report/image_loss_std": 9.022286415100098, "report/model_loss_mean": 13.589908599853516, "report/model_loss_std": 12.62702465057373, "report/post_ent_mag": 57.687255859375, "report/post_ent_max": 57.687255859375, "report/post_ent_mean": 37.69388961791992, "report/post_ent_min": 17.255281448364258, "report/post_ent_std": 6.570396423339844, "report/prior_ent_mag": 66.79685974121094, "report/prior_ent_max": 66.79685974121094, "report/prior_ent_mean": 49.93219757080078, "report/prior_ent_min": 28.996929168701172, "report/prior_ent_std": 7.2892584800720215, "report/rep_loss_mean": 11.894035339355469, "report/rep_loss_std": 8.285503387451172, "report/reward_avg": 0.0011012910399585962, "report/reward_loss_mean": 0.04148450121283531, "report/reward_loss_std": 0.009523415938019753, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012803077697753906, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04148450121283531, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010960320942103863, "report/reward_rate": 0.0, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.0013498569605872035, "eval/cont_loss_std": 0.03527538478374481, "eval/cont_neg_acc": 0.875, "eval/cont_neg_loss": 0.16802702844142914, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.743840352399275e-05, "eval/cont_pred": 0.9930119514465332, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 17.6204833984375, "eval/dyn_loss_std": 10.469383239746094, "eval/image_loss_mean": 13.710436820983887, "eval/image_loss_std": 16.903396606445312, "eval/model_loss_mean": 25.129615783691406, "eval/model_loss_std": 21.819843292236328, "eval/post_ent_mag": 56.08818817138672, "eval/post_ent_max": 56.08818817138672, "eval/post_ent_mean": 36.90644073486328, "eval/post_ent_min": 18.2128849029541, "eval/post_ent_std": 6.325118064880371, "eval/prior_ent_mag": 66.79685974121094, "eval/prior_ent_max": 66.79685974121094, "eval/prior_ent_mean": 50.96009826660156, "eval/prior_ent_min": 20.213809967041016, "eval/prior_ent_std": 7.131229877471924, "eval/rep_loss_mean": 17.6204833984375, "eval/rep_loss_std": 10.469383239746094, "eval/reward_avg": 0.00449218787252903, "eval/reward_loss_mean": 0.8455407619476318, "eval/reward_loss_std": 3.779554843902588, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012902021408081055, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.6511704325675964, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 18.74528694152832, "eval/reward_pred": 0.0010301591828465462, "eval/reward_rate": 0.0107421875, "replay/size": 220417.0, "replay/inserts": 20176.0, "replay/samples": 20176.0, "replay/insert_wait_avg": 1.3128738380631788e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.172950132038743e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 45392.0, "eval_replay/inserts": 3992.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1797300082648207e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0574491024017, "timer/env.step_count": 2522.0, "timer/env.step_total": 234.29061675071716, "timer/env.step_frac": 0.23427715773829186, "timer/env.step_avg": 0.09289873780758016, "timer/env.step_min": 0.02263331413269043, "timer/env.step_max": 2.0472917556762695, "timer/replay._sample_count": 20176.0, "timer/replay._sample_total": 9.888674259185791, "timer/replay._sample_frac": 0.009888106196360357, "timer/replay._sample_avg": 0.0004901206512284789, "timer/replay._sample_min": 0.0003662109375, "timer/replay._sample_max": 0.008453845977783203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3021.0, "timer/agent.policy_total": 47.86138606071472, "timer/agent.policy_frac": 0.047858636624998445, "timer/agent.policy_avg": 0.01584289508795588, "timer/agent.policy_min": 0.009431123733520508, "timer/agent.policy_max": 0.1026315689086914, "timer/dataset_train_count": 1261.0, "timer/dataset_train_total": 0.1355297565460205, "timer/dataset_train_frac": 0.00013552197093043484, "timer/dataset_train_avg": 0.00010747799884696314, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.00020194053649902344, "timer/agent.train_count": 1261.0, "timer/agent.train_total": 565.884388923645, "timer/agent.train_frac": 0.5658518812409754, "timer/agent.train_avg": 0.44875843689424666, "timer/agent.train_min": 0.4360640048980713, "timer/agent.train_max": 1.0244011878967285, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4801952838897705, "timer/agent.report_frac": 0.00048016769868647867, "timer/agent.report_avg": 0.24009764194488525, "timer/agent.report_min": 0.23364996910095215, "timer/agent.report_max": 0.24654531478881836, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.146944455006377e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 20.17461558488425}
{"step": 220968, "time": 11320.836909532547, "episode/length": 145.0, "episode/score": 0.14749684282469389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14749684282469389}
{"step": 221744, "time": 11352.733661413193, "episode/length": 166.0, "episode/score": 0.18076817336805107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18076817336805107}
{"step": 221744, "time": 11352.743062019348, "episode/length": 263.0, "episode/score": 0.30113716212235886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30113716212235886}
{"step": 222112, "time": 11369.48803448677, "episode/length": 142.0, "episode/score": 0.12689741405210953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12689741405210953}
{"step": 222304, "time": 11378.108681440353, "episode/length": 237.0, "episode/score": 0.26423049618733785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26423049618733785}
{"step": 222320, "time": 11380.147543430328, "episode/length": 279.0, "episode/score": 0.33836017656813056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33836017656813056}
{"step": 222488, "time": 11387.700033426285, "episode/length": 266.0, "episode/score": 0.27454501046759106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27454501046759106}
{"step": 222600, "time": 11393.372065782547, "episode/length": 34.0, "episode/score": 0.03773214222746901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03773214222746901}
{"step": 222664, "time": 11397.31559586525, "episode/length": 402.0, "episode/score": 0.4091610973373463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4091610973373463}
{"step": 222944, "time": 11409.539157867432, "episode/length": 149.0, "episode/score": 0.1562449802604533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1562449802604533}
{"step": 222968, "time": 11411.772743701935, "episode/length": 152.0, "episode/score": 0.14872017498055357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14872017498055357}
{"step": 223312, "time": 11426.297218084335, "episode/length": 149.0, "episode/score": 0.15610630241644685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15610630241644685}
{"step": 223640, "time": 11439.823069095612, "episode/length": 166.0, "episode/score": 0.1638289755801452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1638289755801452}
{"step": 223664, "time": 11442.461408615112, "episode/length": 146.0, "episode/score": 0.14692503750302421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14692503750302421}
{"step": 223720, "time": 11445.831638336182, "episode/length": 139.0, "episode/score": 0.1409424828580086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1409424828580086}
{"step": 224040, "time": 11459.567722797394, "episode/length": 408.0, "episode/score": 0.418420828712442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.418420828712442}
{"step": 224328, "time": 11471.759027004242, "episode/length": 172.0, "episode/score": 0.19462489369516334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19462489369516334}
{"step": 224688, "time": 11486.798238277435, "episode/length": 252.0, "episode/score": 0.29448482475845594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29448482475845594}
{"step": 224856, "time": 11494.218000173569, "episode/length": 148.0, "episode/score": 0.17266666365321726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17266666365321726}
{"step": 224928, "time": 11498.728751897812, "episode/length": 160.0, "episode/score": 0.16987602802828405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16987602802828405}
{"step": 225064, "time": 11505.018554925919, "episode/length": 218.0, "episode/score": 0.2447087706518687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2447087706518687}
{"step": 225256, "time": 11513.726741313934, "episode/length": 151.0, "episode/score": 0.17308308567544373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17308308567544373}
{"step": 225288, "time": 11516.900862455368, "episode/length": 195.0, "episode/score": 0.19362733930165632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19362733930165632}
{"step": 226008, "time": 11545.342940568924, "episode/length": 209.0, "episode/score": 0.2328571923835625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2328571923835625}
{"step": 226032, "time": 11547.85614490509, "episode/length": 167.0, "episode/score": 0.1800925450329487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1800925450329487}
{"step": 226224, "time": 11556.394164800644, "episode/length": 406.0, "episode/score": 0.39501987707490116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39501987707490116}
{"step": 226320, "time": 11561.664094686508, "episode/length": 156.0, "episode/score": 0.16427997375376435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16427997375376435}
{"step": 226328, "time": 11563.281077384949, "episode/length": 183.0, "episode/score": 0.2160112318360916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2160112318360916}
{"step": 226760, "time": 11580.889043807983, "episode/length": 228.0, "episode/score": 0.25401579450453937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25401579450453937}
{"step": 226880, "time": 11587.398306369781, "episode/length": 198.0, "episode/score": 0.21284583232500154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21284583232500154}
{"step": 226976, "time": 11592.485805511475, "episode/length": 214.0, "episode/score": 0.22201161560860783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22201161560860783}
{"step": 227264, "time": 11604.643517017365, "episode/length": 153.0, "episode/score": 0.1669048402836779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1669048402836779}
{"step": 227464, "time": 11613.286891698837, "episode/length": 181.0, "episode/score": 0.19726032556354767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19726032556354767}
{"step": 227520, "time": 11617.688596725464, "episode/length": 148.0, "episode/score": 0.15241535878158174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15241535878158174}
{"step": 227792, "time": 11629.368998289108, "episode/length": 183.0, "episode/score": 0.1792393545329105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1792393545329105}
{"step": 228032, "time": 11639.696510314941, "episode/length": 143.0, "episode/score": 0.1607125944829022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1607125944829022}
{"step": 228112, "time": 11644.160449504852, "episode/length": 235.0, "episode/score": 0.27144730139843887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27144730139843887}
{"step": 228176, "time": 11648.13079214096, "episode/length": 176.0, "episode/score": 0.17069711098884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17069711098884}
{"step": 228360, "time": 11656.303259134293, "episode/length": 136.0, "episode/score": 0.15850460526053212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15850460526053212}
{"step": 228768, "time": 11673.173453569412, "episode/length": 223.0, "episode/score": 0.26375433093926404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26375433093926404}
{"step": 228904, "time": 11679.763887166977, "episode/length": 172.0, "episode/score": 0.1809494550252566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1809494550252566}
{"step": 229200, "time": 11692.894666433334, "episode/length": 145.0, "episode/score": 0.1401409314948978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1401409314948978}
{"step": 229232, "time": 11695.741106271744, "episode/length": 139.0, "episode/score": 0.15431773306409013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15431773306409013}
{"step": 229384, "time": 11703.194014310837, "episode/length": 150.0, "episode/score": 0.14950319332456274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14950319332456274}
{"step": 229400, "time": 11706.37400507927, "episode/length": 200.0, "episode/score": 0.2153607325108169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2153607325108169}
{"step": 229640, "time": 11716.76331615448, "episode/length": 271.0, "episode/score": 0.29545792561475537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29545792561475537}
{"step": 229784, "time": 11723.530295610428, "episode/length": 177.0, "episode/score": 0.18394604617060395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18394604617060395}
{"step": 229888, "time": 11729.047067165375, "episode/length": 139.0, "episode/score": 0.14316402538315742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14316402538315742}
{"step": 230048, "time": 11754.810883283615, "eval_episode/length": 145.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 230048, "time": 11756.262859106064, "eval_episode/length": 146.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9727891156462585}
{"step": 230048, "time": 11757.921652555466, "eval_episode/length": 150.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 230048, "time": 11761.130214691162, "eval_episode/length": 192.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 230048, "time": 11763.22887301445, "eval_episode/length": 205.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 230048, "time": 11765.636049985886, "eval_episode/length": 226.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 230048, "time": 11767.360493659973, "eval_episode/length": 228.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 230048, "time": 11770.730679512024, "eval_episode/length": 43.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9090909090909091}
{"step": 230048, "time": 11770.73834514618, "eval_episode/length": 45.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8913043478260869}
{"step": 230328, "time": 11780.851049661636, "episode/length": 117.0, "episode/score": 0.12996130748069845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12996130748069845}
{"step": 230496, "time": 11788.684708595276, "episode/length": 157.0, "episode/score": 0.16008166721985617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16008166721985617}
{"step": 230848, "time": 11803.44149184227, "episode/length": 205.0, "episode/score": 0.2066276122659474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2066276122659474}
{"step": 230904, "time": 11806.858282327652, "episode/length": 157.0, "episode/score": 0.1716998552028599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1716998552028599}
{"step": 231224, "time": 11820.31295466423, "episode/length": 166.0, "episode/score": 0.1994729494135754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1994729494135754}
{"step": 231264, "time": 11823.657298326492, "episode/length": 184.0, "episode/score": 0.19347487135109986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19347487135109986}
{"step": 231680, "time": 11840.691352128983, "episode/length": 168.0, "episode/score": 0.17063214220797818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17063214220797818}
{"step": 231752, "time": 11844.61139011383, "episode/length": 156.0, "episode/score": 0.1587843679208163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1587843679208163}
{"step": 231984, "time": 11855.033610343933, "episode/length": 384.0, "episode/score": 0.40134787383613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.40134787383613}
{"step": 232032, "time": 11858.80452632904, "episode/length": 140.0, "episode/score": 0.13740187417715788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13740187417715788}
{"step": 232440, "time": 11875.161269903183, "episode/length": 146.0, "episode/score": 0.15415104963176418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15415104963176418}
{"step": 232536, "time": 11880.624501228333, "episode/length": 163.0, "episode/score": 0.17214476122899214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17214476122899214}
{"step": 232576, "time": 11884.307501077652, "episode/length": 215.0, "episode/score": 0.23111925533157773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23111925533157773}
{"step": 232624, "time": 11887.716197252274, "episode/length": 402.0, "episode/score": 0.4148586559240357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4148586559240357}
{"step": 232872, "time": 11898.066043138504, "episode/length": 148.0, "episode/score": 0.1669484200392617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1669484200392617}
{"step": 233160, "time": 11910.415239572525, "episode/length": 140.0, "episode/score": 0.14618050730132381, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14618050730132381}
{"step": 233168, "time": 11912.454088926315, "episode/length": 176.0, "episode/score": 0.17764798812640947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17764798812640947}
{"step": 233344, "time": 11920.528755664825, "episode/length": 169.0, "episode/score": 0.17311475964379497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17311475964379497}
{"step": 233648, "time": 11933.266711235046, "episode/length": 150.0, "episode/score": 0.12047579493992089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12047579493992089}
{"step": 233872, "time": 11943.048605442047, "episode/length": 155.0, "episode/score": 0.15692336052597966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15692336052597966}
{"step": 234176, "time": 11955.821280241013, "episode/length": 162.0, "episode/score": 0.16358891447271162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16358891447271162}
{"step": 234448, "time": 11967.32648730278, "episode/length": 233.0, "episode/score": 0.26678943082879414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26678943082879414}
{"step": 234568, "time": 11973.07138133049, "episode/length": 253.0, "episode/score": 0.274697553819351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.274697553819351}
{"step": 234584, "time": 11975.13304400444, "episode/length": 154.0, "episode/score": 0.1388992110023537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1388992110023537}
{"step": 234672, "time": 11980.78656053543, "episode/length": 188.0, "episode/score": 0.19616037022024102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19616037022024102}
{"step": 234712, "time": 11983.979707717896, "episode/length": 192.0, "episode/score": 0.19641189437243156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19641189437243156}
{"step": 235208, "time": 12004.747011423111, "episode/length": 77.0, "episode/score": 0.09022618884046096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09022618884046096}
{"step": 235448, "time": 12015.252525091171, "episode/length": 158.0, "episode/score": 0.17904795937647577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17904795937647577}
{"step": 235680, "time": 12025.560554742813, "episode/length": 253.0, "episode/score": 0.2876597406320798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2876597406320798}
{"step": 235808, "time": 12031.852741479874, "episode/length": 169.0, "episode/score": 0.16732680828863522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16732680828863522}
{"step": 235864, "time": 12035.28182554245, "episode/length": 248.0, "episode/score": 0.26349848251720687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26349848251720687}
{"step": 236112, "time": 12046.388766050339, "episode/length": 192.0, "episode/score": 0.16103590761849773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16103590761849773}
{"step": 236376, "time": 12057.50209569931, "episode/length": 145.0, "episode/score": 0.13202591997651325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13202591997651325}
{"step": 236392, "time": 12059.600405931473, "episode/length": 209.0, "episode/score": 0.24173511465778574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24173511465778574}
{"step": 236472, "time": 12064.13475561142, "episode/length": 224.0, "episode/score": 0.22190327067801263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22190327067801263}
{"step": 236920, "time": 12082.216313838959, "episode/length": 183.0, "episode/score": 0.16493252940017555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16493252940017555}
{"step": 237240, "time": 12095.62621665001, "episode/length": 178.0, "episode/score": 0.1785697088089364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1785697088089364}
{"step": 237360, "time": 12101.948479652405, "episode/length": 155.0, "episode/score": 0.164559325465234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.164559325465234}
{"step": 237784, "time": 12120.504875659943, "episode/length": 175.0, "episode/score": 0.19534925449625007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19534925449625007}
{"step": 237800, "time": 12122.54760313034, "episode/length": 264.0, "episode/score": 0.2878506820961775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2878506820961775}
{"step": 237896, "time": 12127.668253660202, "episode/length": 177.0, "episode/score": 0.19235328491049586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19235328491049586}
{"step": 238136, "time": 12138.03153681755, "episode/length": 283.0, "episode/score": 0.31152824459240946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31152824459240946}
{"step": 238208, "time": 12142.43310213089, "episode/length": 160.0, "episode/score": 0.1654732653641986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1654732653641986}
{"step": 238232, "time": 12144.579643726349, "episode/length": 41.0, "episode/score": 0.049166665761731565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049166665761731565}
{"step": 238368, "time": 12151.366778612137, "episode/length": 246.0, "episode/score": 0.2610575635662826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2610575635662826}
{"step": 238472, "time": 12156.45985031128, "episode/length": 138.0, "episode/score": 0.1452314292337178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1452314292337178}
{"step": 238960, "time": 12176.313337564468, "episode/length": 144.0, "episode/score": 0.16590398284643015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16590398284643015}
{"step": 239048, "time": 12180.832043409348, "episode/length": 113.0, "episode/score": 0.13125778143876232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13125778143876232}
{"step": 239096, "time": 12184.062391281128, "episode/length": 163.0, "episode/score": 0.16898988492539502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16898988492539502}
{"step": 239280, "time": 12192.661887645721, "episode/length": 254.0, "episode/score": 0.2791666462626381, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2791666462626381}
{"step": 239416, "time": 12199.03944349289, "episode/length": 150.0, "episode/score": 0.1633406608234509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1633406608234509}
{"step": 239496, "time": 12203.460966348648, "episode/length": 157.0, "episode/score": 0.17611881710308808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17611881710308808}
{"step": 239816, "time": 12216.71923661232, "episode/length": 180.0, "episode/score": 0.18719804476131685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18719804476131685}
{"step": 239992, "time": 12224.898846626282, "episode/length": 111.0, "episode/score": 0.12674617799711996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12674617799711996}
{"step": 240032, "time": 12248.74842619896, "eval_episode/length": 156.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 240032, "time": 12251.087512254715, "eval_episode/length": 175.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 240032, "time": 12252.823877811432, "eval_episode/length": 181.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 240032, "time": 12254.438716888428, "eval_episode/length": 183.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 240032, "time": 12255.942100286484, "eval_episode/length": 184.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 240032, "time": 12257.548437833786, "eval_episode/length": 187.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.973404255319149}
{"step": 240032, "time": 12259.460431814194, "eval_episode/length": 197.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 240032, "time": 12261.287004232407, "eval_episode/length": 203.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 240184, "time": 12266.712678432465, "episode/length": 85.0, "episode/score": 0.09938039361622941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09938039361622941}
{"step": 240408, "time": 12276.481528043747, "episode/length": 140.0, "episode/score": 0.15648596834944328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15648596834944328}
{"step": 240440, "time": 12279.370269536972, "episode/length": 245.0, "episode/score": 0.25525700437719934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25525700437719934}
{"step": 240472, "time": 12282.1056702137, "episode/length": 188.0, "episode/score": 0.1596285168780014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1596285168780014}
{"step": 240968, "time": 12302.00126838684, "episode/length": 193.0, "episode/score": 0.18032759108245955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18032759108245955}
{"step": 240976, "time": 12304.121320724487, "episode/length": 240.0, "episode/score": 0.25688449707377004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25688449707377004}
{"step": 241296, "time": 12317.506697654724, "episode/length": 162.0, "episode/score": 0.16891642349037284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16891642349037284}
{"step": 241297, "time": 12320.419707536697, "train_stats/sum_log_reward": 1.301834844804685, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.5963302752293576, "train_stats/max_log_achievement_collect_sapling": 0.7064220183486238, "train_stats/max_log_achievement_collect_stone": 0.027522935779816515, "train_stats/max_log_achievement_collect_wood": 0.8623853211009175, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.045871559633027525, "train_stats/max_log_achievement_eat_cow": 0.009174311926605505, "train_stats/max_log_achievement_make_wood_pickaxe": 0.01834862385321101, "train_stats/max_log_achievement_make_wood_sword": 0.01834862385321101, "train_stats/max_log_achievement_place_plant": 0.3394495412844037, "train_stats/max_log_achievement_place_stone": 0.01834862385321101, "train_stats/max_log_achievement_place_table": 0.13761467889908258, "train_stats/max_log_achievement_wake_up": 0.22935779816513763, "train_stats/mean_log_entropy": 2.160038895563248, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.987866018700787, "train/action_min": 0.0, "train/action_std": 4.555212572803647, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00716444218208588, "train/actor_opt_grad_steps": 14350.0, "train/actor_opt_loss": -6.84249267574605, "train/adv_mag": 0.16123739729716083, "train/adv_max": 0.107118217963872, "train/adv_mean": 0.00011845655327184561, "train/adv_min": -0.15966015614158524, "train/adv_std": 0.012974028574581456, "train/cont_avg": 0.9944405142716536, "train/cont_loss_mean": 0.00023700285728463363, "train/cont_loss_std": 0.006353457980965213, "train/cont_neg_acc": 0.9953318341510502, "train/cont_neg_loss": 0.013438634091937102, "train/cont_pos_acc": 0.9999613231561315, "train/cont_pos_loss": 0.00015496699080882567, "train/cont_pred": 0.994408284585307, "train/cont_rate": 0.9944405142716536, "train/dyn_loss_mean": 12.928614916763907, "train/dyn_loss_std": 8.40466310846524, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.19034970710127372, "train/extr_critic_critic_opt_grad_steps": 14350.0, "train/extr_critic_critic_opt_loss": 11419.436192790354, "train/extr_critic_mag": 0.26971433763428937, "train/extr_critic_max": 0.26971433763428937, "train/extr_critic_mean": 0.213833908631107, "train/extr_critic_min": 0.0036785527477114217, "train/extr_critic_std": 0.058623058589424674, "train/extr_return_normed_mag": 0.20425817476013514, "train/extr_return_normed_max": 0.20425817476013514, "train/extr_return_normed_mean": 0.14820693304219584, "train/extr_return_normed_min": -0.06469234431118477, "train/extr_return_normed_std": 0.06046027904303055, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2700036144632054, "train/extr_return_raw_max": 0.2700036144632054, "train/extr_return_raw_mean": 0.21395237825986907, "train/extr_return_raw_min": 0.0010530958025474248, "train/extr_return_raw_std": 0.06046027913102953, "train/extr_reward_mag": 0.001326761846467266, "train/extr_reward_max": 0.001326761846467266, "train/extr_reward_mean": 0.001075799301483001, "train/extr_reward_min": 8.438515850878138e-06, "train/extr_reward_std": 0.0002456573716971627, "train/image_loss_mean": 8.397958995789056, "train/image_loss_std": 13.093618381680466, "train/model_loss_mean": 16.194715342183752, "train/model_loss_std": 16.631855476559615, "train/model_opt_grad_norm": 68.42250499575157, "train/model_opt_grad_steps": 14334.417322834646, "train/model_opt_loss": 20572.432278850887, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1269.6850393700788, "train/policy_entropy_mag": 2.7584298107567733, "train/policy_entropy_max": 2.7584298107567733, "train/policy_entropy_mean": 2.0977389793696366, "train/policy_entropy_min": 0.0917850959840722, "train/policy_entropy_std": 0.5396849043725982, "train/policy_logprob_mag": 7.435916491380826, "train/policy_logprob_max": -0.011250758492277833, "train/policy_logprob_mean": -2.097772271614375, "train/policy_logprob_min": -7.435916491380826, "train/policy_logprob_std": 1.1553940773010254, "train/policy_randomness_mag": 0.973604673945059, "train/policy_randomness_max": 0.973604673945059, "train/policy_randomness_mean": 0.7404098036720996, "train/policy_randomness_min": 0.032396111021361015, "train/policy_randomness_std": 0.1904850890786629, "train/post_ent_mag": 56.1253217862347, "train/post_ent_max": 56.1253217862347, "train/post_ent_mean": 37.731533801461765, "train/post_ent_min": 20.639983515101154, "train/post_ent_std": 6.291721689419483, "train/prior_ent_mag": 66.36375481312669, "train/prior_ent_max": 66.36375481312669, "train/prior_ent_mean": 50.760333564337785, "train/prior_ent_min": 26.136949419036625, "train/prior_ent_std": 6.317743489122766, "train/rep_loss_mean": 12.928614916763907, "train/rep_loss_std": 8.40466310846524, "train/reward_avg": 0.001039903480321257, "train/reward_loss_mean": 0.03935045898547323, "train/reward_loss_std": 0.012146245585534517, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001291725579209215, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03935045880947526, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010409349590305267, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.9235293865203857, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.411764705882353, "eval_stats/max_log_achievement_collect_sapling": 0.7647058823529411, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.7058823529411765, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.058823529411764705, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.4117647058823529, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.0002328061527805403, "report/cont_loss_std": 0.005887444131076336, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.074300083331764e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.000234082224778831, "report/cont_pred": 0.9919722080230713, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 13.289507865905762, "report/dyn_loss_std": 8.68689250946045, "report/image_loss_mean": 8.160290718078613, "report/image_loss_std": 13.104194641113281, "report/model_loss_mean": 16.172901153564453, "report/model_loss_std": 16.676328659057617, "report/post_ent_mag": 54.75736999511719, "report/post_ent_max": 54.75736999511719, "report/post_ent_mean": 36.93854904174805, "report/post_ent_min": 20.639476776123047, "report/post_ent_std": 6.1764936447143555, "report/prior_ent_mag": 66.28839111328125, "report/prior_ent_max": 66.28839111328125, "report/prior_ent_mean": 50.51246643066406, "report/prior_ent_min": 23.66506576538086, "report/prior_ent_std": 7.483429431915283, "report/rep_loss_mean": 13.289507865905762, "report/rep_loss_std": 8.68689250946045, "report/reward_avg": 0.001021126052364707, "report/reward_loss_mean": 0.038672856986522675, "report/reward_loss_std": 0.013243621215224266, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012704133987426758, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.038672856986522675, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010136112105101347, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 6.892092642374337e-05, "eval/cont_loss_std": 0.0021075548138469458, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.013638563454151154, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.3377851903205737e-06, "eval/cont_pred": 0.9951792359352112, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.905489921569824, "eval/dyn_loss_std": 10.748882293701172, "eval/image_loss_mean": 14.899730682373047, "eval/image_loss_std": 20.706680297851562, "eval/model_loss_mean": 25.10700225830078, "eval/model_loss_std": 24.729082107543945, "eval/post_ent_mag": 55.77687072753906, "eval/post_ent_max": 55.77687072753906, "eval/post_ent_mean": 38.40513229370117, "eval/post_ent_min": 21.42996597290039, "eval/post_ent_std": 6.7695465087890625, "eval/prior_ent_mag": 66.28839111328125, "eval/prior_ent_max": 66.28839111328125, "eval/prior_ent_mean": 51.66680145263672, "eval/prior_ent_min": 20.93236541748047, "eval/prior_ent_std": 7.183701992034912, "eval/rep_loss_mean": 15.905489921569824, "eval/rep_loss_std": 10.748882293701172, "eval/reward_avg": 0.006542968563735485, "eval/reward_loss_mean": 0.6639083623886108, "eval/reward_loss_std": 3.393348217010498, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013003349304199219, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.4644430875778198, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 19.032846450805664, "eval/reward_pred": 0.0010088946437463164, "eval/reward_rate": 0.0107421875, "replay/size": 240793.0, "replay/inserts": 20376.0, "replay/samples": 20368.0, "replay/insert_wait_avg": 1.3114776993247168e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.633889461256628e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 49208.0, "eval_replay/inserts": 3816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1549805695155882e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3114697933197, "timer/env.step_count": 2547.0, "timer/env.step_total": 234.30437350273132, "timer/env.step_frac": 0.23423141749153625, "timer/env.step_avg": 0.09199229426883837, "timer/env.step_min": 0.022290468215942383, "timer/env.step_max": 3.119921922683716, "timer/replay._sample_count": 20368.0, "timer/replay._sample_total": 9.657167196273804, "timer/replay._sample_frac": 0.009654160216986344, "timer/replay._sample_avg": 0.0004741342888979676, "timer/replay._sample_min": 0.0003800392150878906, "timer/replay._sample_max": 0.010261774063110352, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3024.0, "timer/agent.policy_total": 48.86555314064026, "timer/agent.policy_frac": 0.04885033773604201, "timer/agent.policy_avg": 0.01615924376343924, "timer/agent.policy_min": 0.00947713851928711, "timer/agent.policy_max": 0.14767861366271973, "timer/dataset_train_count": 1273.0, "timer/dataset_train_total": 0.13459467887878418, "timer/dataset_train_frac": 0.00013455276975539787, "timer/dataset_train_avg": 0.00010573030548215568, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.00037217140197753906, "timer/agent.train_count": 1273.0, "timer/agent.train_total": 569.0406718254089, "timer/agent.train_frac": 0.5688634880323644, "timer/agent.train_avg": 0.44700759766332204, "timer/agent.train_min": 0.43411803245544434, "timer/agent.train_max": 0.9371438026428223, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4727349281311035, "timer/agent.report_frac": 0.00047258773132810133, "timer/agent.report_avg": 0.23636746406555176, "timer/agent.report_min": 0.22487163543701172, "timer/agent.report_max": 0.2478632926940918, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 3.598999564782993e-08, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05, "fps": 20.36941707087807}
{"step": 241328, "time": 12321.886873960495, "episode/length": 142.0, "episode/score": 0.1402989885664283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1402989885664283}
{"step": 241568, "time": 12332.32307267189, "episode/length": 140.0, "episode/score": 0.14001880300565972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14001880300565972}
{"step": 241632, "time": 12336.139879703522, "episode/length": 144.0, "episode/score": 0.15961011650506407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15961011650506407}
{"step": 241968, "time": 12350.23255777359, "episode/length": 268.0, "episode/score": 0.3007934618344734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3007934618344734}
{"step": 242096, "time": 12356.551191329956, "episode/length": 210.0, "episode/score": 0.20081198616207985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20081198616207985}
{"step": 242192, "time": 12361.635027170181, "episode/length": 152.0, "episode/score": 0.1821854601657833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1821854601657833}
{"step": 242512, "time": 12375.157362937927, "episode/length": 151.0, "episode/score": 0.16445579945502686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16445579945502686}
{"step": 242664, "time": 12382.18356513977, "episode/length": 166.0, "episode/score": 0.18346565421961714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18346565421961714}
{"step": 242776, "time": 12388.478811740875, "episode/length": 224.0, "episode/score": 0.24308328557526693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24308328557526693}
{"step": 242784, "time": 12390.555588960648, "episode/length": 143.0, "episode/score": 0.14754855865794525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14754855865794525}
{"step": 243264, "time": 12409.906836271286, "episode/length": 161.0, "episode/score": 0.15037433210818563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15037433210818563}
{"step": 243288, "time": 12412.122024297714, "episode/length": 136.0, "episode/score": 0.15648154340306064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15648154340306064}
{"step": 243576, "time": 12424.302959442139, "episode/length": 184.0, "episode/score": 0.18763383381883614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18763383381883614}
{"step": 243776, "time": 12433.551823854446, "episode/length": 275.0, "episode/score": 0.3090602257871069, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3090602257871069}
{"step": 244008, "time": 12443.51477265358, "episode/length": 153.0, "episode/score": 0.17668451398276375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17668451398276375}
{"step": 244608, "time": 12467.559178590775, "episode/length": 227.0, "episode/score": 0.2709666613918671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2709666613918671}
{"step": 244720, "time": 12473.145693778992, "episode/length": 178.0, "episode/score": 0.20107497667777352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20107497667777352}
{"step": 244744, "time": 12475.84587264061, "episode/length": 145.0, "episode/score": 0.14089669892564416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14089669892564416}
{"step": 244800, "time": 12480.190520763397, "episode/length": 285.0, "episode/score": 0.32851877507710014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32851877507710014}
{"step": 244832, "time": 12482.888629674911, "episode/length": 131.0, "episode/score": 0.13992830659844913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13992830659844913}
{"step": 244864, "time": 12485.475906848907, "episode/length": 274.0, "episode/score": 0.2805871090022265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2805871090022265}
{"step": 245152, "time": 12497.696119308472, "episode/length": 235.0, "episode/score": 0.264724672648299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.264724672648299}
{"step": 245184, "time": 12500.510213375092, "episode/length": 146.0, "episode/score": 0.16584282327676192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16584282327676192}
{"step": 246056, "time": 12535.509939908981, "episode/length": 163.0, "episode/score": 0.1678656051371945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1678656051371945}
{"step": 246184, "time": 12542.412451505661, "episode/length": 172.0, "episode/score": 0.1864627948598354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1864627948598354}
{"step": 246216, "time": 12545.133238554, "episode/length": 200.0, "episode/score": 0.21018926760007162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21018926760007162}
{"step": 246376, "time": 12552.65471982956, "episode/length": 148.0, "episode/score": 0.17147903112345375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17147903112345375}
{"step": 246768, "time": 12569.157192707062, "episode/length": 201.0, "episode/score": 0.2239387607842218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2239387607842218}
{"step": 246776, "time": 12570.74846982956, "episode/length": 256.0, "episode/score": 0.2610072025527188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2610072025527188}
{"step": 247208, "time": 12588.472690820694, "episode/length": 143.0, "episode/score": 0.13081307817265042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13081307817265042}
{"step": 247320, "time": 12594.857846021652, "episode/length": 141.0, "episode/score": 0.11239899915381102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11239899915381102}
{"step": 247392, "time": 12599.238868713379, "episode/length": 76.0, "episode/score": 0.09071721455802617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09071721455802617}
{"step": 247608, "time": 12608.548144578934, "episode/length": 173.0, "episode/score": 0.16720604178772192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16720604178772192}
{"step": 248008, "time": 12624.79278922081, "episode/length": 154.0, "episode/score": 0.1440038849996199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1440038849996199}
{"step": 248152, "time": 12631.745741844177, "episode/length": 414.0, "episode/score": 0.4085514288781269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4085514288781269}
{"step": 248184, "time": 12634.544971466064, "episode/length": 225.0, "episode/score": 0.2702086899189453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2702086899189453}
{"step": 248192, "time": 12636.550687074661, "episode/length": 415.0, "episode/score": 0.3982702907505882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3982702907505882}
{"step": 248656, "time": 12655.400139808655, "episode/length": 180.0, "episode/score": 0.1913468542143164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1913468542143164}
{"step": 248664, "time": 12657.003957748413, "episode/length": 158.0, "episode/score": 0.166925377865482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.166925377865482}
{"step": 248864, "time": 12666.209661483765, "episode/length": 106.0, "episode/score": 0.12883333076024428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12883333076024428}
{"step": 248968, "time": 12671.502066135406, "episode/length": 205.0, "episode/score": 0.17606559022351576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17606559022351576}
{"step": 249008, "time": 12674.73715043068, "episode/length": 174.0, "episode/score": 0.1797386091093358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1797386091093358}
{"step": 249424, "time": 12691.705131053925, "episode/length": 158.0, "episode/score": 0.180213882346834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.180213882346834}
{"step": 249504, "time": 12696.262405633926, "episode/length": 164.0, "episode/score": 0.18194305930228438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18194305930228438}
{"step": 249616, "time": 12701.993265390396, "episode/length": 177.0, "episode/score": 0.20610910339200927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20610910339200927}
{"step": 249696, "time": 12706.455772638321, "episode/length": 85.0, "episode/score": 0.09904166491469368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09904166491469368}
{"step": 249968, "time": 12718.239997625351, "episode/length": 163.0, "episode/score": 0.16653820554347476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16653820554347476}
{"step": 250016, "time": 12744.996732473373, "eval_episode/length": 141.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 250016, "time": 12746.971318721771, "eval_episode/length": 151.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.993421052631579}
{"step": 250016, "time": 12746.978140354156, "eval_episode/length": 151.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.993421052631579}
{"step": 250016, "time": 12750.546587467194, "eval_episode/length": 158.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 250016, "time": 12752.72747373581, "eval_episode/length": 172.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 250016, "time": 12754.88173365593, "eval_episode/length": 185.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 250016, "time": 12756.473826885223, "eval_episode/length": 186.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 250016, "time": 12758.455077886581, "eval_episode/length": 197.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9646464646464646}
{"step": 250080, "time": 12760.87387228012, "episode/length": 151.0, "episode/score": 0.16517696534538118, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16517696534538118}
{"step": 250192, "time": 12766.646548986435, "episode/length": 190.0, "episode/score": 0.21659348723551375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21659348723551375}
{"step": 250424, "time": 12776.511206388474, "episode/length": 181.0, "episode/score": 0.21312797223799862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21312797223799862}
{"step": 250904, "time": 12795.89533996582, "episode/length": 184.0, "episode/score": 0.1727729906760942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1727729906760942}
{"step": 251000, "time": 12800.969940662384, "episode/length": 186.0, "episode/score": 0.19257750130964268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19257750130964268}
{"step": 251136, "time": 12807.646525144577, "episode/length": 179.0, "episode/score": 0.19684308711293852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19684308711293852}
{"step": 251240, "time": 12812.856236457825, "episode/length": 158.0, "episode/score": 0.16211799422762851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16211799422762851}
{"step": 251312, "time": 12817.422289133072, "episode/length": 211.0, "episode/score": 0.20257194308032922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20257194308032922}
{"step": 251528, "time": 12826.649920463562, "episode/length": 137.0, "episode/score": 0.16573369224352064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16573369224352064}
{"step": 251672, "time": 12833.446716547012, "episode/length": 184.0, "episode/score": 0.1845138187163684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1845138187163684}
{"step": 252640, "time": 12871.210265398026, "episode/length": 204.0, "episode/score": 0.20160882979325834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20160882979325834}
{"step": 252656, "time": 12873.203626155853, "episode/length": 176.0, "episode/score": 0.1735972649598807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1735972649598807}
{"step": 252688, "time": 12875.922068357468, "episode/length": 222.0, "episode/score": 0.2224520903891971, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2224520903891971}
{"step": 252920, "time": 12885.90407705307, "episode/length": 155.0, "episode/score": 0.16600036435238508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16600036435238508}
{"step": 252968, "time": 12889.128251791, "episode/length": 179.0, "episode/score": 0.2122708293609321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2122708293609321}
{"step": 253056, "time": 12894.064519166946, "episode/length": 371.0, "episode/score": 0.36706313322338247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.36706313322338247}
{"step": 253752, "time": 12921.328283071518, "episode/length": 138.0, "episode/score": 0.14361593014655227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14361593014655227}
{"step": 254008, "time": 12933.605603933334, "episode/length": 164.0, "episode/score": 0.1594293501266293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1594293501266293}
{"step": 254040, "time": 12936.252078771591, "episode/length": 139.0, "episode/score": 0.14333388625573207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14333388625573207}
{"step": 254056, "time": 12938.381372451782, "episode/length": 174.0, "episode/score": 0.1964511490032237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1964511490032237}
{"step": 254288, "time": 12948.748367071152, "episode/length": 164.0, "episode/score": 0.166367966564394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.166367966564394}
{"step": 254296, "time": 12950.436711788177, "episode/length": 154.0, "episode/score": 0.17500219769453906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17500219769453906}
{"step": 254360, "time": 12954.308282613754, "episode/length": 402.0, "episode/score": 0.3961824697917109, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3961824697917109}
{"step": 254536, "time": 12962.322978973389, "episode/length": 402.0, "episode/score": 0.41006017501558745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41006017501558745}
{"step": 254992, "time": 12981.106889724731, "episode/length": 122.0, "episode/score": 0.13977337812002588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13977337812002588}
{"step": 255128, "time": 12987.404754638672, "episode/length": 171.0, "episode/score": 0.194702711141872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.194702711141872}
{"step": 255336, "time": 12996.61991763115, "episode/length": 159.0, "episode/score": 0.15639614249994338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15639614249994338}
{"step": 255480, "time": 13003.601529359818, "episode/length": 147.0, "episode/score": 0.15110026298907542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15110026298907542}
{"step": 255544, "time": 13007.565742492676, "episode/length": 156.0, "episode/score": 0.15219242220928209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15219242220928209}
{"step": 255608, "time": 13011.400629281998, "episode/length": 195.0, "episode/score": 0.20820899230329815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20820899230329815}
{"step": 255928, "time": 13024.799345731735, "episode/length": 173.0, "episode/score": 0.19256471435073763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19256471435073763}
{"step": 255928, "time": 13024.807901144028, "episode/length": 195.0, "episode/score": 0.19407674162994226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19407674162994226}
{"step": 256240, "time": 13039.934499502182, "episode/length": 155.0, "episode/score": 0.1524232572337496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1524232572337496}
{"step": 256264, "time": 13042.719809055328, "episode/length": 97.0, "episode/score": 0.11013333135269932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11013333135269932}
{"step": 256384, "time": 13049.456120967865, "episode/length": 156.0, "episode/score": 0.14191579804537469, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14191579804537469}
{"step": 256536, "time": 13056.474617481232, "episode/length": 149.0, "episode/score": 0.15777173488459084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15777173488459084}
{"step": 256992, "time": 13075.27548122406, "episode/length": 180.0, "episode/score": 0.17903563308573212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17903563308573212}
{"step": 257320, "time": 13088.798421382904, "episode/length": 134.0, "episode/score": 0.1555492396273621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1555492396273621}
{"step": 257408, "time": 13093.863752126694, "episode/length": 224.0, "episode/score": 0.24710806892471737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24710806892471737}
{"step": 257528, "time": 13099.513679504395, "episode/length": 199.0, "episode/score": 0.2091079514066223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2091079514066223}
{"step": 257552, "time": 13102.299933671951, "episode/length": 202.0, "episode/score": 0.20712587896741752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20712587896741752}
{"step": 257600, "time": 13106.094138145447, "episode/length": 166.0, "episode/score": 0.15654263433316373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15654263433316373}
{"step": 257712, "time": 13112.413571834564, "episode/length": 146.0, "episode/score": 0.13458011961120064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13458011961120064}
{"step": 257776, "time": 13116.299725532532, "episode/length": 56.0, "episode/score": 0.05954969242520747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05954969242520747}
{"step": 258152, "time": 13131.553404569626, "episode/length": 220.0, "episode/score": 0.22260919609652774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22260919609652774}
{"step": 258504, "time": 13146.082731246948, "episode/length": 188.0, "episode/score": 0.1813493398767605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1813493398767605}
{"step": 258768, "time": 13157.69360756874, "episode/length": 145.0, "episode/score": 0.1523209069036966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1523209069036966}
{"step": 258832, "time": 13161.704407215118, "episode/length": 162.0, "episode/score": 0.1768853092999052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1768853092999052}
{"step": 258960, "time": 13168.032996416092, "episode/length": 175.0, "episode/score": 0.1780547251491953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1780547251491953}
{"step": 259080, "time": 13173.717085123062, "episode/length": 115.0, "episode/score": 0.1367781655944782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1367781655944782}
{"step": 259080, "time": 13173.724683046341, "episode/length": 162.0, "episode/score": 0.16252967790569528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16252967790569528}
{"step": 259160, "time": 13180.003588914871, "episode/length": 180.0, "episode/score": 0.17193000087809196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17193000087809196}
{"step": 259408, "time": 13190.851434230804, "episode/length": 40.0, "episode/score": 0.0436887248797575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0436887248797575}
{"step": 259568, "time": 13198.339044570923, "episode/length": 269.0, "episode/score": 0.28776243367428833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28776243367428833}
{"step": 259904, "time": 13212.603571414948, "episode/length": 174.0, "episode/score": 0.19119651001801685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19119651001801685}
{"step": 260000, "time": 13236.05494594574, "eval_episode/length": 124.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.96}
{"step": 260000, "time": 13238.534710884094, "eval_episode/length": 145.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9657534246575342}
{"step": 260000, "time": 13240.477844238281, "eval_episode/length": 154.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 260000, "time": 13242.553461790085, "eval_episode/length": 166.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9580838323353293}
{"step": 260000, "time": 13244.487541437149, "eval_episode/length": 175.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 260000, "time": 13248.10552573204, "eval_episode/length": 224.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 260000, "time": 13249.826194286346, "eval_episode/length": 61.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9838709677419355}
{"step": 260000, "time": 13251.997952222824, "eval_episode/length": 245.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9959349593495935}
{"step": 260232, "time": 13260.396104812622, "episode/length": 182.0, "episode/score": 0.19748714654906507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19748714654906507}
{"step": 260352, "time": 13266.583372592926, "episode/length": 189.0, "episode/score": 0.1623935747120413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1623935747120413}
{"step": 260632, "time": 13278.363323450089, "episode/length": 193.0, "episode/score": 0.20178214687075524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20178214687075524}
{"step": 260664, "time": 13281.023578882217, "episode/length": 187.0, "episode/score": 0.1812202115997934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1812202115997934}
{"step": 260744, "time": 13285.433773517609, "episode/length": 166.0, "episode/score": 0.1871580877850647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1871580877850647}
{"step": 260792, "time": 13288.74592757225, "episode/length": 110.0, "episode/score": 0.12454937399706978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12454937399706978}
{"step": 260944, "time": 13296.143295288086, "episode/length": 38.0, "episode/score": 0.046874999068677425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046874999068677425}
{"step": 261456, "time": 13316.845211029053, "episode/length": 152.0, "episode/score": 0.14263604588813905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14263604588813905}
{"step": 261473, "time": 13319.600564479828, "train_stats/sum_log_reward": 0.9636363433165984, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.554545454545455, "train_stats/max_log_achievement_collect_sapling": 0.7272727272727273, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.5727272727272728, "train_stats/max_log_achievement_defeat_skeleton": 0.00909090909090909, "train_stats/max_log_achievement_defeat_zombie": 0.03636363636363636, "train_stats/max_log_achievement_eat_cow": 0.02727272727272727, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.3181818181818182, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.045454545454545456, "train_stats/max_log_achievement_wake_up": 0.11818181818181818, "train_stats/mean_log_entropy": 2.226313126087189, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.195155552455357, "train/action_min": 0.0, "train/action_std": 4.668865090324765, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0073976942729796205, "train/actor_opt_grad_steps": 15615.0, "train/actor_opt_loss": -13.277936191549378, "train/adv_mag": 0.16206507130511225, "train/adv_max": 0.10669506719661137, "train/adv_mean": -0.0002329970280871272, "train/adv_min": -0.1610371115070487, "train/adv_std": 0.013023300347701898, "train/cont_avg": 0.9942258804563492, "train/cont_loss_mean": 0.00025693381832510233, "train/cont_loss_std": 0.007428185143091183, "train/cont_neg_acc": 0.9929705229070451, "train/cont_neg_loss": 0.024334535033137258, "train/cont_pos_acc": 0.9999531810245816, "train/cont_pos_loss": 0.00011957105935992436, "train/cont_pred": 0.9942023635856689, "train/cont_rate": 0.9942258804563492, "train/dyn_loss_mean": 12.900329521724156, "train/dyn_loss_std": 8.421725492628793, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.18466156620591406, "train/extr_critic_critic_opt_grad_steps": 15615.0, "train/extr_critic_critic_opt_loss": 11403.822521391368, "train/extr_critic_mag": 0.2720425630372668, "train/extr_critic_max": 0.2720425630372668, "train/extr_critic_mean": 0.2142588006598609, "train/extr_critic_min": 0.0035846687498546784, "train/extr_critic_std": 0.06114575210663061, "train/extr_return_normed_mag": 0.20978177445275442, "train/extr_return_normed_max": 0.20978177445275442, "train/extr_return_normed_mean": 0.1517398108447355, "train/extr_return_normed_min": -0.06126085263750856, "train/extr_return_normed_std": 0.06294381222318089, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.27206783020307146, "train/extr_return_raw_max": 0.27206783020307146, "train/extr_return_raw_mean": 0.21402586961076372, "train/extr_return_raw_min": 0.0010252036745586092, "train/extr_return_raw_std": 0.06294381225274669, "train/extr_reward_mag": 0.0013404999460492814, "train/extr_reward_max": 0.0013404999460492814, "train/extr_reward_mean": 0.0010824277941581038, "train/extr_reward_min": 9.088289170038133e-06, "train/extr_reward_std": 0.0002415378868814543, "train/image_loss_mean": 8.151678444847228, "train/image_loss_std": 12.579673922251141, "train/model_loss_mean": 15.931644492679172, "train/model_loss_std": 16.14574977329799, "train/model_opt_grad_norm": 70.93356018066406, "train/model_opt_grad_steps": 15597.539682539682, "train/model_opt_loss": 13466.394632006448, "train/model_opt_model_opt_grad_overflow": 0.007936507936507936, "train/model_opt_model_opt_grad_scale": 833.3333333333334, "train/policy_entropy_mag": 2.7569459903807867, "train/policy_entropy_max": 2.7569459903807867, "train/policy_entropy_mean": 2.1027807546040367, "train/policy_entropy_min": 0.092868360912516, "train/policy_entropy_std": 0.522608208987448, "train/policy_logprob_mag": 7.436525356201899, "train/policy_logprob_max": -0.011435998899359551, "train/policy_logprob_mean": -2.1026777104725913, "train/policy_logprob_min": -7.436525356201899, "train/policy_logprob_std": 1.1487462681437295, "train/policy_randomness_mag": 0.9730809472856068, "train/policy_randomness_max": 0.9730809472856068, "train/policy_randomness_mean": 0.7421893354446168, "train/policy_randomness_min": 0.03277845584624817, "train/policy_randomness_std": 0.18445776343818696, "train/post_ent_mag": 56.92566898890904, "train/post_ent_max": 56.92566898890904, "train/post_ent_mean": 38.278453796628924, "train/post_ent_min": 20.81496265956334, "train/post_ent_std": 6.558417354311262, "train/prior_ent_mag": 66.69101012699188, "train/prior_ent_max": 66.69101012699188, "train/prior_ent_mean": 51.24900960165357, "train/prior_ent_min": 26.9031376308865, "train/prior_ent_std": 6.3312570708138605, "train/rep_loss_mean": 12.900329521724156, "train/rep_loss_std": 8.421725492628793, "train/reward_avg": 0.0010447533452875972, "train/reward_loss_mean": 0.03951148490702349, "train/reward_loss_std": 0.01202992559780204, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012958513365851508, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03951148508441827, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001045258937492257, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.0999999959021807, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 1.6875, "eval_stats/max_log_achievement_collect_sapling": 1.3125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.9375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00011332923895679414, "report/cont_loss_std": 0.003300009062513709, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.02639024518430233, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.0282498806191143e-05, "report/cont_pred": 0.9961814284324646, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.888877868652344, "report/dyn_loss_std": 8.741019248962402, "report/image_loss_mean": 7.003445625305176, "report/image_loss_std": 11.814371109008789, "report/model_loss_mean": 14.776510238647461, "report/model_loss_std": 15.755733489990234, "report/post_ent_mag": 57.38236618041992, "report/post_ent_max": 57.38236618041992, "report/post_ent_mean": 39.5224609375, "report/post_ent_min": 21.648094177246094, "report/post_ent_std": 6.950655460357666, "report/prior_ent_mag": 67.49603271484375, "report/prior_ent_max": 67.49603271484375, "report/prior_ent_mean": 52.674617767333984, "report/prior_ent_min": 28.93082618713379, "report/prior_ent_std": 5.8334784507751465, "report/rep_loss_mean": 12.888877868652344, "report/rep_loss_std": 8.741019248962402, "report/reward_avg": 0.0010470798006281257, "report/reward_loss_mean": 0.03962421417236328, "report/reward_loss_std": 0.011890910565853119, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013464689254760742, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03962421789765358, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001033907406963408, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0001663263246882707, "eval/cont_loss_std": 0.005197719670832157, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.03328675776720047, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.811981514445506e-06, "eval/cont_pred": 0.9952632188796997, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.97537612915039, "eval/dyn_loss_std": 10.977495193481445, "eval/image_loss_mean": 11.094902038574219, "eval/image_loss_std": 14.698403358459473, "eval/model_loss_mean": 21.924388885498047, "eval/model_loss_std": 20.62259864807129, "eval/post_ent_mag": 52.52235412597656, "eval/post_ent_max": 52.52235412597656, "eval/post_ent_mean": 37.65724182128906, "eval/post_ent_min": 19.099292755126953, "eval/post_ent_std": 5.842347145080566, "eval/prior_ent_mag": 67.49603271484375, "eval/prior_ent_max": 67.49603271484375, "eval/prior_ent_mean": 51.221927642822266, "eval/prior_ent_min": 23.873241424560547, "eval/prior_ent_std": 6.924350738525391, "eval/rep_loss_mean": 16.97537612915039, "eval/rep_loss_std": 10.977495193481445, "eval/reward_avg": 0.007617187220603228, "eval/reward_loss_mean": 0.6440941095352173, "eval/reward_loss_std": 3.3881537914276123, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013003349304199219, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.42425596714019775, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 19.183780670166016, "eval/reward_pred": 0.0009630392305552959, "eval/reward_rate": 0.01171875, "replay/size": 260969.0, "replay/inserts": 20176.0, "replay/samples": 20176.0, "replay/insert_wait_avg": 1.3132874309591222e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.655840842710611e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 52760.0, "eval_replay/inserts": 3552.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1957846246324145e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.035932302475, "timer/env.step_count": 2522.0, "timer/env.step_total": 236.51781368255615, "timer/env.step_frac": 0.23650931535829856, "timer/env.step_avg": 0.09378184523495486, "timer/env.step_min": 0.022460222244262695, "timer/env.step_max": 3.310452461242676, "timer/replay._sample_count": 20176.0, "timer/replay._sample_total": 9.599338054656982, "timer/replay._sample_frac": 0.009598993140731994, "timer/replay._sample_avg": 0.0004757800383949734, "timer/replay._sample_min": 0.0003821849822998047, "timer/replay._sample_max": 0.010782480239868164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2966.0, "timer/agent.policy_total": 46.82304859161377, "timer/agent.policy_frac": 0.04682136619212146, "timer/agent.policy_avg": 0.01578659763709163, "timer/agent.policy_min": 0.009558916091918945, "timer/agent.policy_max": 0.1112205982208252, "timer/dataset_train_count": 1261.0, "timer/dataset_train_total": 0.1337568759918213, "timer/dataset_train_frac": 0.0001337520699719864, "timer/dataset_train_avg": 0.00010607206660731268, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.0010921955108642578, "timer/agent.train_count": 1261.0, "timer/agent.train_total": 563.9913363456726, "timer/agent.train_frac": 0.5639710715665419, "timer/agent.train_avg": 0.4472572056666714, "timer/agent.train_min": 0.4353334903717041, "timer/agent.train_max": 0.9287896156311035, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4819817543029785, "timer/agent.report_frac": 0.0004819644362110744, "timer/agent.report_avg": 0.24099087715148926, "timer/agent.report_min": 0.2349071502685547, "timer/agent.report_max": 0.24707460403442383, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.225440979003906e-05, "timer/dataset_eval_frac": 8.225145430590393e-08, "timer/dataset_eval_avg": 8.225440979003906e-05, "timer/dataset_eval_min": 8.225440979003906e-05, "timer/dataset_eval_max": 8.225440979003906e-05, "fps": 20.17504451103407}
{"step": 261536, "time": 13322.256888389587, "episode/length": 245.0, "episode/score": 0.28788591612646997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28788591612646997}
{"step": 261904, "time": 13337.554041862488, "episode/length": 193.0, "episode/score": 0.20907391582204582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20907391582204582}
{"step": 262184, "time": 13350.524470329285, "episode/length": 402.0, "episode/score": 0.40872213044804084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.40872213044804084}
{"step": 262248, "time": 13354.46647977829, "episode/length": 181.0, "episode/score": 0.20236237696190074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20236237696190074}
{"step": 262440, "time": 13363.321035861969, "episode/length": 221.0, "episode/score": 0.20953402580835245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20953402580835245}
{"step": 262576, "time": 13370.723536014557, "episode/length": 203.0, "episode/score": 0.2055947281905901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2055947281905901}
{"step": 262624, "time": 13374.469005584717, "episode/length": 46.0, "episode/score": 0.05273214200860821, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05273214200860821}
{"step": 262848, "time": 13384.432925462723, "episode/length": 262.0, "episode/score": 0.29320687814561097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29320687814561097}
{"step": 262896, "time": 13387.849438428879, "episode/length": 179.0, "episode/score": 0.1809755257636425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1809755257636425}
{"step": 263240, "time": 13402.336061954498, "episode/length": 166.0, "episode/score": 0.17539516620581708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17539516620581708}
{"step": 263280, "time": 13406.009420633316, "episode/length": 136.0, "episode/score": 0.12000526618703589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12000526618703589}
{"step": 264144, "time": 13440.206540346146, "episode/length": 161.0, "episode/score": 0.14957836901112387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14957836901112387}
{"step": 264328, "time": 13448.437031269073, "episode/length": 178.0, "episode/score": 0.18873176277338644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18873176277338644}
{"step": 264424, "time": 13453.48770070076, "episode/length": 224.0, "episode/score": 0.21827616790824322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21827616790824322}
{"step": 264424, "time": 13453.496141195297, "episode/length": 230.0, "episode/score": 0.24813130896973234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24813130896973234}
{"step": 264528, "time": 13460.7990629673, "episode/length": 260.0, "episode/score": 0.28392360932321026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28392360932321026}
{"step": 264656, "time": 13467.139320373535, "episode/length": 171.0, "episode/score": 0.1774953270505648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1774953270505648}
{"step": 264728, "time": 13471.623841524124, "episode/length": 398.0, "episode/score": 0.42196984999463893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42196984999463893}
{"step": 265344, "time": 13496.362400531769, "episode/length": 262.0, "episode/score": 0.28444119530468015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28444119530468015}
{"step": 265456, "time": 13502.160433292389, "episode/length": 163.0, "episode/score": 0.16105803184473189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16105803184473189}
{"step": 265464, "time": 13503.655270338058, "episode/length": 141.0, "episode/score": 0.15963566210120916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15963566210120916}
{"step": 265584, "time": 13509.946307182312, "episode/length": 144.0, "episode/score": 0.16148723958031042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16148723958031042}
{"step": 265928, "time": 13523.915822505951, "episode/length": 187.0, "episode/score": 0.1852418147282151, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1852418147282151}
{"step": 265936, "time": 13525.972979784012, "episode/length": 159.0, "episode/score": 0.1552228216351068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1552228216351068}
{"step": 265992, "time": 13529.31681895256, "episode/length": 182.0, "episode/score": 0.1797425861877855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1797425861877855}
{"step": 266800, "time": 13561.534173965454, "episode/length": 167.0, "episode/score": 0.1742304350991617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1742304350991617}
{"step": 266976, "time": 13569.682284116745, "episode/length": 173.0, "episode/score": 0.17927058164787013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17927058164787013}
{"step": 267008, "time": 13572.342285871506, "episode/length": 207.0, "episode/score": 0.2037802975391969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2037802975391969}
{"step": 267048, "time": 13575.593512535095, "episode/length": 289.0, "episode/score": 0.32215107720730884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32215107720730884}
{"step": 267128, "time": 13580.494941949844, "episode/length": 149.0, "episode/score": 0.16664454248166294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16664454248166294}
{"step": 267392, "time": 13592.030669212341, "episode/length": 174.0, "episode/score": 0.1707981038998696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1707981038998696}
{"step": 267440, "time": 13595.27952837944, "episode/length": 187.0, "episode/score": 0.1963053693434631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1963053693434631}
{"step": 268040, "time": 13618.85980796814, "episode/length": 154.0, "episode/score": 0.14436947261310706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14436947261310706}
{"step": 268120, "time": 13623.354515075684, "episode/length": 142.0, "episode/score": 0.11471878524753265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11471878524753265}
{"step": 268272, "time": 13630.867159843445, "episode/length": 142.0, "episode/score": 0.16257539247726527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16257539247726527}
{"step": 268640, "time": 13646.128249645233, "episode/length": 45.0, "episode/score": 0.0533154750810354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0533154750810354}
{"step": 268704, "time": 13650.044271469116, "episode/length": 206.0, "episode/score": 0.22276593383048748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22276593383048748}
{"step": 268856, "time": 13657.140475273132, "episode/length": 182.0, "episode/score": 0.19818038944049476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19818038944049476}
{"step": 268944, "time": 13662.202021360397, "episode/length": 187.0, "episode/score": 0.19419865611598652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19419865611598652}
{"step": 269208, "time": 13673.252701759338, "episode/length": 274.0, "episode/score": 0.2808973280607461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2808973280607461}
{"step": 269728, "time": 13694.431163549423, "episode/length": 210.0, "episode/score": 0.24390240635602822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24390240635602822}
{"step": 270088, "time": 13727.849736690521, "eval_episode/length": 149.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 270088, "time": 13729.373253822327, "eval_episode/length": 150.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9735099337748344}
{"step": 270088, "time": 13730.927730321884, "eval_episode/length": 152.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 270088, "time": 13733.247558355331, "eval_episode/length": 169.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 270088, "time": 13735.51306605339, "eval_episode/length": 178.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 270088, "time": 13738.373043775558, "eval_episode/length": 210.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 270088, "time": 13740.105570077896, "eval_episode/length": 215.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 270088, "time": 13742.598904132843, "eval_episode/length": 240.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.983402489626556}
{"step": 270112, "time": 13743.719122886658, "episode/length": 156.0, "episode/score": 0.15095873451173247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15095873451173247}
{"step": 270216, "time": 13748.978756189346, "episode/length": 261.0, "episode/score": 0.28400280528967414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28400280528967414}
{"step": 270320, "time": 13754.672072649002, "episode/length": 138.0, "episode/score": 0.12695410599189927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12695410599189927}
{"step": 270552, "time": 13766.086520671844, "episode/length": 635.0, "episode/score": 0.6103890653148483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.6103890653148483}
{"step": 270608, "time": 13769.929129362106, "episode/length": 237.0, "episode/score": 0.2201403932822359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2201403932822359}
{"step": 270664, "time": 13773.331263303757, "episode/length": 214.0, "episode/score": 0.19691097574195737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19691097574195737}
{"step": 270744, "time": 13777.909796714783, "episode/length": 262.0, "episode/score": 0.2670804399149347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2670804399149347}
{"step": 271128, "time": 13793.658733606339, "episode/length": 174.0, "episode/score": 0.16967575370290433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16967575370290433}
{"step": 271352, "time": 13803.45220541954, "episode/length": 141.0, "episode/score": 0.1551861557391021, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1551861557391021}
{"step": 271728, "time": 13819.383195638657, "episode/length": 139.0, "episode/score": 0.13752844497366823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13752844497366823}
{"step": 271792, "time": 13823.349184036255, "episode/length": 82.0, "episode/score": 0.09459557164382204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09459557164382204}
{"step": 271848, "time": 13826.671439886093, "episode/length": 190.0, "episode/score": 0.16365727509128192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16365727509128192}
{"step": 272480, "time": 13852.135029792786, "episode/length": 240.0, "episode/score": 0.26527736747038944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26527736747038944}
{"step": 272520, "time": 13854.962285757065, "episode/length": 221.0, "episode/score": 0.23936886093588328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23936886093588328}
{"step": 272656, "time": 13861.777726888657, "episode/length": 248.0, "episode/score": 0.27865455418941565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27865455418941565}
{"step": 272768, "time": 13867.596254348755, "episode/length": 176.0, "episode/score": 0.20526893563510384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20526893563510384}
{"step": 272960, "time": 13876.887657165527, "episode/length": 153.0, "episode/score": 0.16489098542342617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16489098542342617}
{"step": 273000, "time": 13880.20283985138, "episode/length": 143.0, "episode/score": 0.12991549257185397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12991549257185397}
{"step": 273224, "time": 13890.579048156738, "episode/length": 178.0, "episode/score": 0.17574132859772362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17574132859772362}
{"step": 273336, "time": 13896.255510568619, "episode/length": 402.0, "episode/score": 0.4117881961265084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4117881961265084}
{"step": 273648, "time": 13909.934454202652, "episode/length": 123.0, "episode/score": 0.1382058299614073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1382058299614073}
{"step": 273840, "time": 13918.607003688812, "episode/length": 169.0, "episode/score": 0.191028626662046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.191028626662046}
{"step": 273944, "time": 13923.75365281105, "episode/length": 146.0, "episode/score": 0.16885538918722887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16885538918722887}
{"step": 274136, "time": 13932.403718948364, "episode/length": 146.0, "episode/score": 0.14602903301283732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14602903301283732}
{"step": 274152, "time": 13934.603572368622, "episode/length": 143.0, "episode/score": 0.1663181137855645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1663181137855645}
{"step": 274264, "time": 13940.186154127121, "episode/length": 217.0, "episode/score": 0.22778499968671895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22778499968671895}
{"step": 274328, "time": 13944.018251419067, "episode/length": 47.0, "episode/score": 0.05139146929332128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05139146929332128}
{"step": 274800, "time": 13963.645308732986, "episode/length": 196.0, "episode/score": 0.21323888710503525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21323888710503525}
{"step": 274864, "time": 13968.064908981323, "episode/length": 151.0, "episode/score": 0.15062449492961605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15062449492961605}
{"step": 274920, "time": 13971.924888849258, "episode/length": 197.0, "episode/score": 0.2017528220735585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2017528220735585}
{"step": 275144, "time": 13982.089403390884, "episode/length": 123.0, "episode/score": 0.12297592463755791, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12297592463755791}
{"step": 275216, "time": 13986.4844186306, "episode/length": 171.0, "episode/score": 0.17990459399425163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17990459399425163}
{"step": 275384, "time": 13994.097038030624, "episode/length": 131.0, "episode/score": 0.1381988397997702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1381988397997702}
{"step": 275736, "time": 14008.755023956299, "episode/length": 183.0, "episode/score": 0.16607048277683134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16607048277683134}
{"step": 275848, "time": 14014.375060796738, "episode/length": 122.0, "episode/score": 0.1396945243850496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1396945243850496}
{"step": 276000, "time": 14021.746532201767, "episode/length": 149.0, "episode/score": 0.15174391998380088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15174391998380088}
{"step": 276032, "time": 14024.367716789246, "episode/length": 236.0, "episode/score": 0.23433771041209184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23433771041209184}
{"step": 276328, "time": 14036.649335384369, "episode/length": 147.0, "episode/score": 0.1547958035848751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1547958035848751}
{"step": 276608, "time": 14048.748103380203, "episode/length": 210.0, "episode/score": 0.22221525629811367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22221525629811367}
{"step": 276936, "time": 14062.273045301437, "episode/length": 214.0, "episode/score": 0.21895456974743865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21895456974743865}
{"step": 277064, "time": 14069.272154092789, "episode/length": 151.0, "episode/score": 0.1261836563212455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1261836563212455}
{"step": 277424, "time": 14084.421307325363, "episode/length": 254.0, "episode/score": 0.2875823337458314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2875823337458314}
{"step": 277480, "time": 14087.749411582947, "episode/length": 184.0, "episode/score": 0.19240161365405584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19240161365405584}
{"step": 277520, "time": 14091.024009943008, "episode/length": 222.0, "episode/score": 0.2093786407135667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2093786407135667}
{"step": 277568, "time": 14094.3218729496, "episode/length": 191.0, "episode/score": 0.20735188542994365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20735188542994365}
{"step": 277888, "time": 14107.777842283249, "episode/length": 159.0, "episode/score": 0.16631808166630435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16631808166630435}
{"step": 277992, "time": 14112.948594331741, "episode/length": 70.0, "episode/score": 0.07029283025894983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07029283025894983}
{"step": 278032, "time": 14116.141038179398, "episode/length": 212.0, "episode/score": 0.24311186791373984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24311186791373984}
{"step": 278056, "time": 14118.328181028366, "episode/length": 139.0, "episode/score": 0.15373499095903753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15373499095903753}
{"step": 278344, "time": 14130.540269613266, "episode/length": 102.0, "episode/score": 0.11820121902405845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11820121902405845}
{"step": 278480, "time": 14138.10894703865, "episode/length": 176.0, "episode/score": 0.19339842074123226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19339842074123226}
{"step": 278968, "time": 14159.291668176651, "episode/length": 185.0, "episode/score": 0.1525674686452021, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1525674686452021}
{"step": 279104, "time": 14166.137812137604, "episode/length": 191.0, "episode/score": 0.1852094626822236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1852094626822236}
{"step": 279224, "time": 14171.960016012192, "episode/length": 166.0, "episode/score": 0.14674991356923783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14674991356923783}
{"step": 279464, "time": 14182.542006731033, "episode/length": 183.0, "episode/score": 0.18515863630659624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18515863630659624}
{"step": 279704, "time": 14193.034868955612, "episode/length": 205.0, "episode/score": 0.22518274376238878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22518274376238878}
{"step": 279944, "time": 14203.672688961029, "episode/length": 199.0, "episode/score": 0.21951632385525954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21951632385525954}
{"step": 280072, "time": 14225.48163819313, "eval_episode/length": 65.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9848484848484849}
{"step": 280072, "time": 14230.930618524551, "eval_episode/length": 137.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 280072, "time": 14230.938563108444, "eval_episode/length": 137.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 280072, "time": 14235.118508577347, "eval_episode/length": 144.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.993103448275862}
{"step": 280072, "time": 14237.557267189026, "eval_episode/length": 164.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 280072, "time": 14239.499317407608, "eval_episode/length": 173.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 280072, "time": 14242.557545900345, "eval_episode/length": 142.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.993006993006993}
{"step": 280072, "time": 14244.261483430862, "eval_episode/length": 213.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 280096, "time": 14245.392335176468, "episode/length": 257.0, "episode/score": 0.27122840232982526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27122840232982526}
{"step": 280104, "time": 14246.993917226791, "episode/length": 202.0, "episode/score": 0.22689612796693837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22689612796693837}
{"step": 280472, "time": 14262.349932193756, "episode/length": 187.0, "episode/score": 0.2102837862846627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2102837862846627}
{"step": 280616, "time": 14269.303044557571, "episode/length": 143.0, "episode/score": 0.15475575760137872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15475575760137872}
{"step": 280968, "time": 14284.00086426735, "episode/length": 157.0, "episode/score": 0.16399100657145027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16399100657145027}
{"step": 281120, "time": 14291.664119243622, "episode/length": 146.0, "episode/score": 0.17529457686759997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17529457686759997}
{"step": 281192, "time": 14295.789603948593, "episode/length": 245.0, "episode/score": 0.2639765856147278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2639765856147278}
{"step": 281224, "time": 14298.509691476822, "episode/length": 140.0, "episode/score": 0.14600298416917212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14600298416917212}
{"step": 281280, "time": 14302.316089630127, "episode/length": 271.0, "episode/score": 0.3279212289876341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3279212289876341}
{"step": 281424, "time": 14309.178783655167, "episode/length": 164.0, "episode/score": 0.1718102210725192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1718102210725192}
{"step": 281560, "time": 14315.536920547485, "episode/length": 34.0, "episode/score": 0.0414583325618878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0414583325618878}
{"step": 281609, "time": 14319.998289823532, "train_stats/sum_log_reward": 1.2559632660325515, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.275229357798165, "train_stats/max_log_achievement_collect_sapling": 0.963302752293578, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.5321100917431193, "train_stats/max_log_achievement_defeat_skeleton": 0.009174311926605505, "train_stats/max_log_achievement_defeat_zombie": 0.027522935779816515, "train_stats/max_log_achievement_eat_cow": 0.027522935779816515, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.5688073394495413, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.03669724770642202, "train_stats/max_log_achievement_wake_up": 0.08256880733944955, "train_stats/mean_log_entropy": 2.216884452268618, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.098109654017857, "train/action_min": 0.0, "train/action_std": 4.6833893155294755, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007635074301755854, "train/actor_opt_grad_steps": 16875.0, "train/actor_opt_loss": -15.830793191930132, "train/adv_mag": 0.16369691266426964, "train/adv_max": 0.1090940579417206, "train/adv_mean": -0.0003015979128118517, "train/adv_min": -0.1629219191178443, "train/adv_std": 0.01278218828762571, "train/cont_avg": 0.9945436507936508, "train/cont_loss_mean": 0.00043661442083926913, "train/cont_loss_std": 0.013027087599124253, "train/cont_neg_acc": 0.9891534405095237, "train/cont_neg_loss": 0.04561031638119734, "train/cont_pos_acc": 0.9999609892330472, "train/cont_pos_loss": 0.00016822307759051158, "train/cont_pred": 0.9945353302690718, "train/cont_rate": 0.9945436507936508, "train/dyn_loss_mean": 12.612043297480023, "train/dyn_loss_std": 8.362342592269655, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17567717875280078, "train/extr_critic_critic_opt_grad_steps": 16875.0, "train/extr_critic_critic_opt_loss": 10898.992900545634, "train/extr_critic_mag": 0.27012805522434297, "train/extr_critic_max": 0.27012805522434297, "train/extr_critic_mean": 0.20473322142211217, "train/extr_critic_min": 0.002697351432981945, "train/extr_critic_std": 0.06299659178133994, "train/extr_return_normed_mag": 0.21941112998932127, "train/extr_return_normed_max": 0.21941112998932127, "train/extr_return_normed_mean": 0.15463603098714163, "train/extr_return_normed_min": -0.04876562388288596, "train/extr_return_normed_std": 0.06440940153385911, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.26920666675719, "train/extr_return_raw_max": 0.26920666675719, "train/extr_return_raw_mean": 0.20443157094811637, "train/extr_return_raw_min": 0.001029912441495865, "train/extr_return_raw_std": 0.06440940197734606, "train/extr_reward_mag": 0.0013386219266861203, "train/extr_reward_max": 0.0013386219266861203, "train/extr_reward_mean": 0.001083178240584121, "train/extr_reward_min": 9.011654626755488e-06, "train/extr_reward_std": 0.00024238331573701183, "train/image_loss_mean": 7.603203470744784, "train/image_loss_std": 11.866775497557624, "train/model_loss_mean": 15.210552866496737, "train/model_loss_std": 15.396959213983445, "train/model_opt_grad_norm": 66.40457746717665, "train/model_opt_grad_steps": 16856.626984126986, "train/model_opt_loss": 14185.695068359375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 932.5396825396825, "train/policy_entropy_mag": 2.7566962185360135, "train/policy_entropy_max": 2.7566962185360135, "train/policy_entropy_mean": 2.1176554920181396, "train/policy_entropy_min": 0.08930108382824868, "train/policy_entropy_std": 0.5269691125741081, "train/policy_logprob_mag": 7.43696399718996, "train/policy_logprob_max": -0.010863952479133058, "train/policy_logprob_mean": -2.1167498732370045, "train/policy_logprob_min": -7.43696399718996, "train/policy_logprob_std": 1.1415844384639982, "train/policy_randomness_mag": 0.972992792015984, "train/policy_randomness_max": 0.972992792015984, "train/policy_randomness_mean": 0.7474394521069905, "train/policy_randomness_min": 0.031519363796900186, "train/policy_randomness_std": 0.18599697143312485, "train/post_ent_mag": 57.445503265138655, "train/post_ent_max": 57.445503265138655, "train/post_ent_mean": 38.75536110287621, "train/post_ent_min": 20.780772375682044, "train/post_ent_std": 6.721209635810246, "train/prior_ent_mag": 66.94069611080108, "train/prior_ent_max": 66.94069611080108, "train/prior_ent_mean": 51.50103889949738, "train/prior_ent_min": 26.88142136165074, "train/prior_ent_std": 6.427499449442303, "train/rep_loss_mean": 12.612043297480023, "train/rep_loss_std": 8.362342592269655, "train/reward_avg": 0.0010497302241024695, "train/reward_loss_mean": 0.039686859481864505, "train/reward_loss_std": 0.011777479186772353, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012942183585393997, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039686859570561894, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010505387520728011, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.7874999921768904, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.75, "eval_stats/max_log_achievement_collect_sapling": 0.6875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.080201738863252e-05, "report/cont_loss_std": 0.0006490920204669237, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.1159030691487715e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.083983417833224e-05, "report/cont_pred": 0.9960733652114868, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.202974319458008, "report/dyn_loss_std": 8.58918571472168, "report/image_loss_mean": 5.912903785705566, "report/image_loss_std": 11.093072891235352, "report/model_loss_mean": 12.67335319519043, "report/model_loss_std": 14.915214538574219, "report/post_ent_mag": 59.730987548828125, "report/post_ent_max": 59.730987548828125, "report/post_ent_mean": 39.17622375488281, "report/post_ent_min": 20.09415054321289, "report/post_ent_std": 7.715897560119629, "report/prior_ent_mag": 67.10762023925781, "report/prior_ent_max": 67.10762023925781, "report/prior_ent_mean": 50.788368225097656, "report/prior_ent_min": 28.476654052734375, "report/prior_ent_std": 7.4301557540893555, "report/rep_loss_mean": 11.202974319458008, "report/rep_loss_std": 8.58918571472168, "report/reward_avg": 0.0010205627186223865, "report/reward_loss_mean": 0.03864502161741257, "report/reward_loss_std": 0.01320409681648016, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012508630752563477, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03864502161741257, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0009802087442949414, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.013306383974850178, "eval/cont_loss_std": 0.423865407705307, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 2.2682952880859375, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.5684845493524335e-05, "eval/cont_pred": 0.9951395988464355, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.25311279296875, "eval/dyn_loss_std": 10.25278377532959, "eval/image_loss_mean": 12.27796745300293, "eval/image_loss_std": 15.630326271057129, "eval/model_loss_mean": 23.240903854370117, "eval/model_loss_std": 20.38375473022461, "eval/post_ent_mag": 57.910499572753906, "eval/post_ent_max": 57.910499572753906, "eval/post_ent_mean": 38.24322509765625, "eval/post_ent_min": 22.161609649658203, "eval/post_ent_std": 7.197110652923584, "eval/prior_ent_mag": 67.10762023925781, "eval/prior_ent_max": 67.10762023925781, "eval/prior_ent_mean": 52.47702407836914, "eval/prior_ent_min": 23.94683837890625, "eval/prior_ent_std": 6.5361833572387695, "eval/rep_loss_mean": 17.25311279296875, "eval/rep_loss_std": 10.25278377532959, "eval/reward_avg": 0.004785156808793545, "eval/reward_loss_mean": 0.5977625846862793, "eval/reward_loss_std": 3.255307674407959, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012460947036743164, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.4117705523967743, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 19.45735740661621, "eval/reward_pred": 0.0009991740807890892, "eval/reward_rate": 0.009765625, "replay/size": 281105.0, "replay/inserts": 20136.0, "replay/samples": 20144.0, "replay/insert_wait_avg": 1.3119060461796794e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.813581878746948e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 56400.0, "eval_replay/inserts": 3640.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2135112678611672e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3896381855011, "timer/env.step_count": 2517.0, "timer/env.step_total": 236.50645542144775, "timer/env.step_frac": 0.23641433936723028, "timer/env.step_avg": 0.0939636294880603, "timer/env.step_min": 0.022604703903198242, "timer/env.step_max": 3.210918664932251, "timer/replay._sample_count": 20144.0, "timer/replay._sample_total": 9.721587657928467, "timer/replay._sample_frac": 0.009717801231489569, "timer/replay._sample_avg": 0.00048260462956356564, "timer/replay._sample_min": 0.00034356117248535156, "timer/replay._sample_max": 0.022402524948120117, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2972.0, "timer/agent.policy_total": 47.446601152420044, "timer/agent.policy_frac": 0.047428121345277345, "timer/agent.policy_avg": 0.015964536053977133, "timer/agent.policy_min": 0.009486913681030273, "timer/agent.policy_max": 0.11341643333435059, "timer/dataset_train_count": 1259.0, "timer/dataset_train_total": 0.13408637046813965, "timer/dataset_train_frac": 0.00013403414564683462, "timer/dataset_train_avg": 0.0001065022799588083, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.00031495094299316406, "timer/agent.train_count": 1259.0, "timer/agent.train_total": 566.4025990962982, "timer/agent.train_frac": 0.5661819929718932, "timer/agent.train_avg": 0.44988292223693266, "timer/agent.train_min": 0.4358344078063965, "timer/agent.train_max": 1.091437816619873, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.481583833694458, "timer/agent.report_frac": 0.0004813962633279079, "timer/agent.report_avg": 0.240791916847229, "timer/agent.report_min": 0.23388409614562988, "timer/agent.report_max": 0.24769973754882812, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 6.604194641113281e-05, "timer/dataset_eval_frac": 6.601622396941174e-08, "timer/dataset_eval_avg": 6.604194641113281e-05, "timer/dataset_eval_min": 6.604194641113281e-05, "timer/dataset_eval_max": 6.604194641113281e-05, "fps": 20.12790824116564}
{"step": 281752, "time": 14325.22643327713, "episode/length": 141.0, "episode/score": 0.14824774191583856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14824774191583856}
{"step": 282240, "time": 14345.256205797195, "episode/length": 220.0, "episode/score": 0.24167454239432118, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24167454239432118}
{"step": 282520, "time": 14357.192795038223, "episode/length": 174.0, "episode/score": 0.17909983512799954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17909983512799954}
{"step": 282592, "time": 14361.664759635925, "episode/length": 174.0, "episode/score": 0.18588469988753786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18588469988753786}
{"step": 282864, "time": 14374.03730225563, "episode/length": 179.0, "episode/score": 0.19991170308639994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19991170308639994}
{"step": 283128, "time": 14385.264118671417, "episode/length": 269.0, "episode/score": 0.31006655281817075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31006655281817075}
{"step": 283184, "time": 14389.33179974556, "episode/length": 202.0, "episode/score": 0.21568707901315065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21568707901315065}
{"step": 283256, "time": 14393.33032298088, "episode/length": 253.0, "episode/score": 0.2944414630183019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2944414630183019}
{"step": 283408, "time": 14400.85434126854, "episode/length": 145.0, "episode/score": 0.15803905342545477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15803905342545477}
{"step": 283512, "time": 14406.00962305069, "episode/length": 219.0, "episode/score": 0.2258856638618454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2258856638618454}
{"step": 284104, "time": 14429.64594578743, "episode/length": 154.0, "episode/score": 0.16755424868824775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16755424868824775}
{"step": 284280, "time": 14437.694840192795, "episode/length": 127.0, "episode/score": 0.1515745584765682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1515745584765682}
{"step": 284368, "time": 14442.823471784592, "episode/length": 230.0, "episode/score": 0.26325110273683094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26325110273683094}
{"step": 284384, "time": 14444.993160486221, "episode/length": 156.0, "episode/score": 0.15965282070465037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15965282070465037}
{"step": 284480, "time": 14450.099088668823, "episode/length": 161.0, "episode/score": 0.1790025697700912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1790025697700912}
{"step": 284576, "time": 14455.25032901764, "episode/length": 58.0, "episode/score": 0.05654043397771602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05654043397771602}
{"step": 284760, "time": 14463.525821208954, "episode/length": 155.0, "episode/score": 0.1454675164204673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1454675164204673}
{"step": 284920, "time": 14471.687363147736, "episode/length": 290.0, "episode/score": 0.33811943253022037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33811943253022037}
{"step": 285104, "time": 14480.785222291946, "episode/length": 211.0, "episode/score": 0.23372577618283685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23372577618283685}
{"step": 285496, "time": 14496.614252090454, "episode/length": 140.0, "episode/score": 0.1629166636703303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1629166636703303}
{"step": 285600, "time": 14502.438824415207, "episode/length": 164.0, "episode/score": 0.1713996591479372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1713996591479372}
{"step": 285664, "time": 14506.392478942871, "episode/length": 159.0, "episode/score": 0.15071483419887954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15071483419887954}
{"step": 285904, "time": 14516.88434100151, "episode/length": 177.0, "episode/score": 0.18928890061579295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18928890061579295}
{"step": 285912, "time": 14518.437703371048, "episode/length": 166.0, "episode/score": 0.1889625968233304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1889625968233304}
{"step": 286144, "time": 14528.940264225006, "episode/length": 129.0, "episode/score": 0.15202105091884732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15202105091884732}
{"step": 286632, "time": 14548.411098003387, "episode/length": 213.0, "episode/score": 0.24546345746966836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24546345746966836}
{"step": 286904, "time": 14561.659649848938, "episode/length": 124.0, "episode/score": 0.13453941571424366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13453941571424366}
{"step": 287096, "time": 14570.261014938354, "episode/length": 178.0, "episode/score": 0.17338493754141382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17338493754141382}
{"step": 287144, "time": 14573.666142702103, "episode/length": 205.0, "episode/score": 0.22949269780838222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22949269780838222}
{"step": 287152, "time": 14575.684096097946, "episode/length": 154.0, "episode/score": 0.14601953490364394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14601953490364394}
{"step": 287240, "time": 14580.190114736557, "episode/length": 309.0, "episode/score": 0.34326152210087457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34326152210087457}
{"step": 287456, "time": 14590.032510519028, "episode/length": 231.0, "episode/score": 0.24833335419680225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24833335419680225}
{"step": 287616, "time": 14597.42900300026, "episode/length": 183.0, "episode/score": 0.19797230478343408, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19797230478343408}
{"step": 288008, "time": 14613.303507566452, "episode/length": 137.0, "episode/score": 0.1312498947545464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1312498947545464}
{"step": 288376, "time": 14628.765919208527, "episode/length": 141.0, "episode/score": 0.13308877842428046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13308877842428046}
{"step": 288472, "time": 14633.838522195816, "episode/length": 171.0, "episode/score": 0.1851418414098589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1851418414098589}
{"step": 288672, "time": 14643.050340175629, "episode/length": 254.0, "episode/score": 0.27496638708453247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27496638708453247}
{"step": 288720, "time": 14646.433021783829, "episode/length": 157.0, "episode/score": 0.15567947816452943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15567947816452943}
{"step": 288976, "time": 14657.709041118622, "episode/length": 227.0, "episode/score": 0.24696993640645815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24696993640645815}
{"step": 289016, "time": 14660.414120912552, "episode/length": 174.0, "episode/score": 0.19170424934054608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19170424934054608}
{"step": 289320, "time": 14673.346800327301, "episode/length": 271.0, "episode/score": 0.2879256567630364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2879256567630364}
{"step": 289416, "time": 14678.486413002014, "episode/length": 175.0, "episode/score": 0.18183375060471008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18183375060471008}
{"step": 289936, "time": 14699.681041240692, "episode/length": 182.0, "episode/score": 0.18630218856469583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18630218856469583}
{"step": 289952, "time": 14701.86839556694, "episode/length": 159.0, "episode/score": 0.16786702184163005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16786702184163005}
{"step": 290016, "time": 14705.816154956818, "episode/length": 124.0, "episode/score": 0.13434701905680413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13434701905680413}
{"step": 290056, "time": 14727.936560630798, "eval_episode/length": 77.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9358974358974359}
{"step": 290056, "time": 14731.523852348328, "eval_episode/length": 118.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9495798319327731}
{"step": 290056, "time": 14733.907667636871, "eval_episode/length": 137.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 290056, "time": 14736.789162397385, "eval_episode/length": 167.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 290056, "time": 14739.151103019714, "eval_episode/length": 185.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 290056, "time": 14739.158485651016, "eval_episode/length": 185.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 290056, "time": 14742.860578298569, "eval_episode/length": 193.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 290056, "time": 14744.429423332214, "eval_episode/length": 195.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 290216, "time": 14750.397963523865, "episode/length": 229.0, "episode/score": 0.2479578488300831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2479578488300831}
{"step": 290488, "time": 14762.080206155777, "episode/length": 145.0, "episode/score": 0.1585370863231219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1585370863231219}
{"step": 290504, "time": 14764.155644655228, "episode/length": 222.0, "episode/score": 0.24763022114348132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24763022114348132}
{"step": 290536, "time": 14766.95859503746, "episode/length": 194.0, "episode/score": 0.222764937685497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.222764937685497}
{"step": 290640, "time": 14772.492890834808, "episode/length": 152.0, "episode/score": 0.15012710329210677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15012710329210677}
{"step": 291040, "time": 14788.805070877075, "episode/length": 137.0, "episode/score": 0.15513733185252931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15513733185252931}
{"step": 291136, "time": 14794.005103111267, "episode/length": 139.0, "episode/score": 0.14638687164006114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14638687164006114}
{"step": 291480, "time": 14808.24615240097, "episode/length": 190.0, "episode/score": 0.21602634380087693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21602634380087693}
{"step": 291704, "time": 14818.152666807175, "episode/length": 185.0, "episode/score": 0.19906646293384256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19906646293384256}
{"step": 291752, "time": 14821.465340137482, "episode/length": 157.0, "episode/score": 0.1502362262845054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1502362262845054}
{"step": 291840, "time": 14826.542532205582, "episode/length": 166.0, "episode/score": 0.17374610944534652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17374610944534652}
{"step": 291896, "time": 14830.019874334335, "episode/length": 23.0, "episode/score": 0.024833333038259298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024833333038259298}
{"step": 291904, "time": 14832.04321885109, "episode/length": 157.0, "episode/score": 0.15821625956687058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15821625956687058}
{"step": 292216, "time": 14845.26884150505, "episode/length": 209.0, "episode/score": 0.2220313731177157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2220313731177157}
{"step": 292552, "time": 14859.278440475464, "episode/length": 41.0, "episode/score": 0.04677380868815817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04677380868815817}
{"step": 292928, "time": 14874.997912406921, "episode/length": 180.0, "episode/score": 0.1878297057992313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1878297057992313}
{"step": 293008, "time": 14879.48576760292, "episode/length": 233.0, "episode/score": 0.26180419366573915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26180419366573915}
{"step": 293024, "time": 14881.563444137573, "episode/length": 158.0, "episode/score": 0.16608222619106527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16608222619106527}
{"step": 293208, "time": 14889.835874080658, "episode/length": 163.0, "episode/score": 0.16302715908750542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16302715908750542}
{"step": 293280, "time": 14894.243069648743, "episode/length": 179.0, "episode/score": 0.18760091521471622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18760091521471622}
{"step": 293328, "time": 14897.531333208084, "episode/length": 285.0, "episode/score": 0.3168978604840049, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3168978604840049}
{"step": 293400, "time": 14901.510994434357, "episode/length": 186.0, "episode/score": 0.18911872905664495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18911872905664495}
{"step": 293704, "time": 14914.185889720917, "episode/length": 143.0, "episode/score": 0.15121157180328737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15121157180328737}
{"step": 294160, "time": 14932.823872804642, "episode/length": 153.0, "episode/score": 0.17275543104915414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17275543104915414}
{"step": 294504, "time": 14947.11756181717, "episode/length": 152.0, "episode/score": 0.17229453740583267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17229453740583267}
{"step": 294504, "time": 14947.133002996445, "episode/length": 161.0, "episode/score": 0.15457524629164254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15457524629164254}
{"step": 294544, "time": 14952.170056343079, "episode/length": 142.0, "episode/score": 0.15486791760486085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15486791760486085}
{"step": 294704, "time": 14959.578552007675, "episode/length": 171.0, "episode/score": 0.16164803594438126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16164803594438126}
{"step": 295288, "time": 14984.432450056076, "episode/length": 197.0, "episode/score": 0.2114963923522737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2114963923522737}
{"step": 295360, "time": 14988.881847858429, "episode/length": 106.0, "episode/score": 0.13249999715480953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13249999715480953}
{"step": 295632, "time": 15000.65821647644, "episode/length": 140.0, "episode/score": 0.1465564525060472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1465564525060472}
{"step": 295704, "time": 15004.668877124786, "episode/length": 144.0, "episode/score": 0.17046621907138615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17046621907138615}
{"step": 295992, "time": 15017.052927970886, "episode/length": 160.0, "episode/score": 0.1642931067290192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1642931067290192}
{"step": 296072, "time": 15021.628981351852, "episode/length": 238.0, "episode/score": 0.25118995559751056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25118995559751056}
{"step": 296216, "time": 15028.638710260391, "episode/length": 398.0, "episode/score": 0.46545909561245935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.46545909561245935}
{"step": 296272, "time": 15032.419228076935, "episode/length": 407.0, "episode/score": 0.4090152090211632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4090152090211632}
{"step": 296344, "time": 15036.370314121246, "episode/length": 131.0, "episode/score": 0.12109556901123142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12109556901123142}
{"step": 296872, "time": 15057.641962528229, "episode/length": 188.0, "episode/score": 0.20841970506808138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20841970506808138}
{"step": 297232, "time": 15072.946135282516, "episode/length": 199.0, "episode/score": 0.21795080187075655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21795080187075655}
{"step": 297328, "time": 15078.032466888428, "episode/length": 166.0, "episode/score": 0.1800114410580136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1800114410580136}
{"step": 297416, "time": 15082.61926317215, "episode/length": 167.0, "episode/score": 0.1947155884172389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1947155884172389}
{"step": 297672, "time": 15093.698972463608, "episode/length": 174.0, "episode/score": 0.1804304085599142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1804304085599142}
{"step": 297824, "time": 15101.101045846939, "episode/length": 184.0, "episode/score": 0.1864264418491075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1864264418491075}
{"step": 297848, "time": 15103.159573316574, "episode/length": 267.0, "episode/score": 0.2752695557373954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2752695557373954}
{"step": 298040, "time": 15111.736401081085, "episode/length": 227.0, "episode/score": 0.22833067954707076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22833067954707076}
{"step": 298376, "time": 15125.777793645859, "episode/length": 187.0, "episode/score": 0.21643935190149932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21643935190149932}
{"step": 298632, "time": 15136.9945230484, "episode/length": 174.0, "episode/score": 0.19234529347886564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19234529347886564}
{"step": 298768, "time": 15143.792553901672, "episode/length": 179.0, "episode/score": 0.184943600130282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.184943600130282}
{"step": 299160, "time": 15159.795394659042, "episode/length": 163.0, "episode/score": 0.17443448792346317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17443448792346317}
{"step": 299304, "time": 15166.639909029007, "episode/length": 157.0, "episode/score": 0.16137365435770334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16137365435770334}
{"step": 299528, "time": 15176.542790651321, "episode/length": 143.0, "episode/score": 0.15549512751749717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15549512751749717}
{"step": 300040, "time": 15212.318251371384, "eval_episode/length": 59.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 300040, "time": 15218.143099308014, "eval_episode/length": 160.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 300040, "time": 15218.150193691254, "eval_episode/length": 160.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 300040, "time": 15221.3446662426, "eval_episode/length": 162.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 300040, "time": 15223.401460409164, "eval_episode/length": 175.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 300040, "time": 15224.92903637886, "eval_episode/length": 177.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 300040, "time": 15227.1863925457, "eval_episode/length": 195.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 300040, "time": 15230.006521224976, "eval_episode/length": 224.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9822222222222222}
{"step": 300088, "time": 15231.798692703247, "episode/length": 282.0, "episode/score": 0.3105803885846399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3105803885846399}
{"step": 300208, "time": 15237.984745025635, "episode/length": 179.0, "episode/score": 0.1940479158438393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1940479158438393}
{"step": 300288, "time": 15242.510651350021, "episode/length": 140.0, "episode/score": 0.14008505154197337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14008505154197337}
{"step": 300312, "time": 15244.680418014526, "episode/length": 361.0, "episode/score": 0.3779713485155298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3779713485155298}
{"step": 300432, "time": 15251.05164527893, "episode/length": 140.0, "episode/score": 0.15131694505907944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15131694505907944}
{"step": 300688, "time": 15262.1457092762, "episode/length": 256.0, "episode/score": 0.28923748971283203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28923748971283203}
{"step": 300992, "time": 15274.895279407501, "episode/length": 414.0, "episode/score": 0.44919643040520896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44919643040520896}
{"step": 301000, "time": 15276.573719501495, "episode/length": 183.0, "episode/score": 0.19115376206173096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19115376206173096}
{"step": 301152, "time": 15284.190173864365, "episode/length": 89.0, "episode/score": 0.10668960037219222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10668960037219222}
{"step": 301312, "time": 15291.733469724655, "episode/length": 38.0, "episode/score": 0.04458333260845393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04458333260845393}
{"step": 301528, "time": 15301.146518230438, "episode/length": 151.0, "episode/score": 0.12392662908314378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12392662908314378}
{"step": 301672, "time": 15308.150788545609, "episode/length": 197.0, "episode/score": 0.19988554895280686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19988554895280686}
{"step": 301928, "time": 15319.2269821167, "episode/length": 154.0, "episode/score": 0.174920246910915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.174920246910915}
{"step": 301929, "time": 15321.753690242767, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.0935673751230315, "train/action_min": 0.0, "train/action_std": 4.615570030813142, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007346927774996739, "train/actor_opt_grad_steps": 18140.0, "train/actor_opt_loss": -10.185524180003508, "train/adv_mag": 0.1677581892590823, "train/adv_max": 0.11423531450389877, "train/adv_mean": -1.3100562121365563e-05, "train/adv_min": -0.16554936144764967, "train/adv_std": 0.01244216114575938, "train/cont_avg": 0.9946173720472441, "train/cont_loss_mean": 0.00021165531944151961, "train/cont_loss_std": 0.006058275663742358, "train/cont_neg_acc": 0.9911104877164044, "train/cont_neg_loss": 0.01977297608110477, "train/cont_pos_acc": 0.9999767828175402, "train/cont_pos_loss": 9.447776423576573e-05, "train/cont_pred": 0.9946117316644023, "train/cont_rate": 0.9946173720472441, "train/dyn_loss_mean": 12.595080668532004, "train/dyn_loss_std": 8.439438095242958, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17780560868110243, "train/extr_critic_critic_opt_grad_steps": 18140.0, "train/extr_critic_critic_opt_loss": 10674.07395730807, "train/extr_critic_mag": 0.2678690435379509, "train/extr_critic_max": 0.2678690435379509, "train/extr_critic_mean": 0.20465666712738398, "train/extr_critic_min": 0.0019806905055609276, "train/extr_critic_std": 0.061067219119607, "train/extr_return_normed_mag": 0.22061559945110262, "train/extr_return_normed_max": 0.22061559945110262, "train/extr_return_normed_mean": 0.15734602323197944, "train/extr_return_normed_min": -0.04629874619559979, "train/extr_return_normed_std": 0.06255290795146949, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2679131148368355, "train/extr_return_raw_max": 0.2679131148368355, "train/extr_return_raw_mean": 0.20464354026036, "train/extr_return_raw_min": 0.0009987692194660819, "train/extr_return_raw_std": 0.0625529079221365, "train/extr_reward_mag": 0.00134315359310841, "train/extr_reward_max": 0.00134315359310841, "train/extr_reward_mean": 0.0010805707415712513, "train/extr_reward_min": 1.0437852754367618e-05, "train/extr_reward_std": 0.00024554486900722007, "train/image_loss_mean": 7.242230272668553, "train/image_loss_std": 11.437792774260513, "train/model_loss_mean": 14.839025820334127, "train/model_loss_std": 15.034191935081182, "train/model_opt_grad_norm": 67.51613399175208, "train/model_opt_grad_steps": 18120.75590551181, "train/model_opt_loss": 12354.043437807579, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 836.6141732283464, "train/policy_entropy_mag": 2.7586390390170843, "train/policy_entropy_max": 2.7586390390170843, "train/policy_entropy_mean": 2.1284675372867135, "train/policy_entropy_min": 0.09056872827565576, "train/policy_entropy_std": 0.5040103380135664, "train/policy_logprob_mag": 7.432354754350317, "train/policy_logprob_max": -0.01106569182685041, "train/policy_logprob_mean": -2.1294237440965307, "train/policy_logprob_min": -7.432354754350317, "train/policy_logprob_std": 1.134617726633868, "train/policy_randomness_mag": 0.9736785212839683, "train/policy_randomness_max": 0.9736785212839683, "train/policy_randomness_mean": 0.7512556352014617, "train/policy_randomness_min": 0.03196678664095289, "train/policy_randomness_std": 0.17789353359871962, "train/post_ent_mag": 57.35122365275706, "train/post_ent_max": 57.35122365275706, "train/post_ent_mean": 38.97374223724125, "train/post_ent_min": 20.83823924177275, "train/post_ent_std": 6.744989417669341, "train/prior_ent_mag": 67.26118277001568, "train/prior_ent_max": 67.26118277001568, "train/prior_ent_mean": 51.70277582003376, "train/prior_ent_min": 27.719807467122717, "train/prior_ent_std": 6.296883669425183, "train/rep_loss_mean": 12.595080668532004, "train/rep_loss_std": 8.439438095242958, "train/reward_avg": 0.0010452840704558873, "train/reward_loss_mean": 0.039535518618315224, "train/reward_loss_std": 0.011907463717296368, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012989738794762318, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0395355187356472, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010443086530573255, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.2009174140221481, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.128440366972477, "train_stats/max_log_achievement_collect_sapling": 0.7522935779816514, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.6605504587155964, "train_stats/max_log_achievement_defeat_skeleton": 0.009174311926605505, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009174311926605505, "train_stats/max_log_achievement_make_wood_sword": 0.009174311926605505, "train_stats/max_log_achievement_place_plant": 0.41284403669724773, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.11009174311926606, "train_stats/max_log_achievement_wake_up": 0.29357798165137616, "train_stats/mean_log_entropy": 2.201578811767998, "eval_stats/sum_log_reward": 0.47499999636784196, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 1.8125, "eval_stats/max_log_achievement_collect_sapling": 0.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.0943615052383393e-05, "report/cont_loss_std": 7.186461152741686e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003754021890927106, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 8.43505040393211e-06, "report/cont_pred": 0.993158221244812, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 14.468406677246094, "report/dyn_loss_std": 8.08802318572998, "report/image_loss_mean": 6.95985221862793, "report/image_loss_std": 8.690205574035645, "report/model_loss_mean": 15.682012557983398, "report/model_loss_std": 11.88154411315918, "report/post_ent_mag": 54.659339904785156, "report/post_ent_max": 54.659339904785156, "report/post_ent_mean": 38.53852462768555, "report/post_ent_min": 21.508352279663086, "report/post_ent_std": 6.27887487411499, "report/prior_ent_mag": 67.47126770019531, "report/prior_ent_max": 67.47126770019531, "report/prior_ent_mean": 52.5527458190918, "report/prior_ent_min": 25.982234954833984, "report/prior_ent_std": 5.815062046051025, "report/rep_loss_mean": 14.468406677246094, "report/rep_loss_std": 8.08802318572998, "report/reward_avg": 0.001092488644644618, "report/reward_loss_mean": 0.04110464081168175, "report/reward_loss_std": 0.01076561026275158, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012460947036743164, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.041104644536972046, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001048255362547934, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.9609545638086274e-05, "eval/cont_loss_std": 0.0005903715500608087, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00025909446412697434, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.853258385788649e-05, "eval/cont_pred": 0.995080292224884, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.96540069580078, "eval/dyn_loss_std": 10.802913665771484, "eval/image_loss_mean": 10.557662010192871, "eval/image_loss_std": 15.238580703735352, "eval/model_loss_mean": 21.97405242919922, "eval/model_loss_std": 19.80531883239746, "eval/post_ent_mag": 58.08738708496094, "eval/post_ent_max": 58.08738708496094, "eval/post_ent_mean": 38.89299011230469, "eval/post_ent_min": 21.758068084716797, "eval/post_ent_std": 7.097352981567383, "eval/prior_ent_mag": 67.47126770019531, "eval/prior_ent_max": 67.47126770019531, "eval/prior_ent_mean": 52.75642395019531, "eval/prior_ent_min": 22.844661712646484, "eval/prior_ent_std": 6.565001487731934, "eval/rep_loss_mean": 17.96540069580078, "eval/rep_loss_std": 10.802913665771484, "eval/reward_avg": 0.0022460937034338713, "eval/reward_loss_mean": 0.6371102333068848, "eval/reward_loss_std": 3.318006753921509, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012460947036743164, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.5070360898971558, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 19.535022735595703, "eval/reward_pred": 0.0010707357432693243, "eval/reward_rate": 0.0068359375, "replay/size": 301425.0, "replay/inserts": 20320.0, "replay/samples": 20320.0, "replay/insert_wait_avg": 1.3116659141900972e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.929881726662944e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 59768.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.35887263789596e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.7448117733002, "timer/env.step_count": 2540.0, "timer/env.step_total": 232.23583269119263, "timer/env.step_frac": 0.2318313306560441, "timer/env.step_avg": 0.09143143019338293, "timer/env.step_min": 0.02241826057434082, "timer/env.step_max": 3.3114864826202393, "timer/replay._sample_count": 20320.0, "timer/replay._sample_total": 9.77043628692627, "timer/replay._sample_frac": 0.009753418407658664, "timer/replay._sample_avg": 0.0004808285574274739, "timer/replay._sample_min": 0.00037288665771484375, "timer/replay._sample_max": 0.01059722900390625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2961.0, "timer/agent.policy_total": 48.28742790222168, "timer/agent.policy_frac": 0.048203322178173025, "timer/agent.policy_avg": 0.01630781084168243, "timer/agent.policy_min": 0.009445905685424805, "timer/agent.policy_max": 0.12529993057250977, "timer/dataset_train_count": 1270.0, "timer/dataset_train_total": 0.13566851615905762, "timer/dataset_train_frac": 0.00013543221244030767, "timer/dataset_train_avg": 0.00010682560327484851, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0004050731658935547, "timer/agent.train_count": 1270.0, "timer/agent.train_total": 570.4070844650269, "timer/agent.train_frac": 0.5694135649729851, "timer/agent.train_avg": 0.4491394365866353, "timer/agent.train_min": 0.4354071617126465, "timer/agent.train_max": 1.044996976852417, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48351049423217773, "timer/agent.report_frac": 0.0004826683288494022, "timer/agent.report_avg": 0.24175524711608887, "timer/agent.report_min": 0.2358400821685791, "timer/agent.report_max": 0.24767041206359863, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8560396975294878e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 20.284374321799508}
{"step": 301968, "time": 15323.306278467178, "episode/length": 209.0, "episode/score": 0.21678247797353833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21678247797353833}
{"step": 302016, "time": 15326.661537885666, "episode/length": 225.0, "episode/score": 0.22975080171818263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22975080171818263}
{"step": 302112, "time": 15331.808841705322, "episode/length": 119.0, "episode/score": 0.12036149937193841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12036149937193841}
{"step": 302640, "time": 15353.022391080856, "episode/length": 165.0, "episode/score": 0.17120479333607364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17120479333607364}
{"step": 302768, "time": 15359.24354481697, "episode/length": 221.0, "episode/score": 0.25216148539766436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25216148539766436}
{"step": 302912, "time": 15365.981753587723, "episode/length": 111.0, "episode/score": 0.13552782984334044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13552782984334044}
{"step": 303312, "time": 15383.95439171791, "episode/length": 222.0, "episode/score": 0.2027202793979086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2027202793979086}
{"step": 303400, "time": 15388.571787595749, "episode/length": 183.0, "episode/score": 0.1974994309239264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1974994309239264}
{"step": 303400, "time": 15388.579853534698, "episode/length": 178.0, "episode/score": 0.19884516820093268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19884516820093268}
{"step": 303440, "time": 15393.365728855133, "episode/length": 165.0, "episode/score": 0.20058332930784672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20058332930784672}
{"step": 303464, "time": 15395.49376821518, "episode/length": 223.0, "episode/score": 0.22127568991709268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22127568991709268}
{"step": 304136, "time": 15422.146081924438, "episode/length": 186.0, "episode/score": 0.1992988121273811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1992988121273811}
{"step": 304408, "time": 15433.923236608505, "episode/length": 186.0, "episode/score": 0.19408161107639899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19408161107639899}
{"step": 304528, "time": 15440.17505121231, "episode/length": 151.0, "episode/score": 0.16693629922519904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16693629922519904}
{"step": 304568, "time": 15443.022473096848, "episode/length": 145.0, "episode/score": 0.13857688732059614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13857688732059614}
{"step": 304880, "time": 15456.299012422562, "episode/length": 263.0, "episode/score": 0.2882155599836551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2882155599836551}
{"step": 305096, "time": 15465.814489603043, "episode/length": 206.0, "episode/score": 0.24132254159485456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24132254159485456}
{"step": 305176, "time": 15470.342926979065, "episode/length": 129.0, "episode/score": 0.14669254775799345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14669254775799345}
{"step": 305192, "time": 15472.37756729126, "episode/length": 215.0, "episode/score": 0.24069350512945675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24069350512945675}
{"step": 305392, "time": 15481.523775815964, "episode/length": 248.0, "episode/score": 0.2824231943795894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2824231943795894}
{"step": 305704, "time": 15494.519171714783, "episode/length": 161.0, "episode/score": 0.1884232422162313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1884232422162313}
{"step": 306184, "time": 15514.129158496857, "episode/length": 98.0, "episode/score": 0.11263560844236054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11263560844236054}
{"step": 306264, "time": 15518.776354551315, "episode/length": 211.0, "episode/score": 0.23296884591400158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23296884591400158}
{"step": 306400, "time": 15525.560454130173, "episode/length": 162.0, "episode/score": 0.1564015425319667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1564015425319667}
{"step": 306600, "time": 15534.237221717834, "episode/length": 177.0, "episode/score": 0.1823498517696862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1823498517696862}
{"step": 306712, "time": 15539.922125339508, "episode/length": 228.0, "episode/score": 0.2626561985089211, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2626561985089211}
{"step": 306800, "time": 15544.859063863754, "episode/length": 136.0, "episode/score": 0.16039393637038302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16039393637038302}
{"step": 306920, "time": 15550.856762170792, "episode/length": 298.0, "episode/score": 0.29408337995846523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29408337995846523}
{"step": 307096, "time": 15559.001006126404, "episode/length": 237.0, "episode/score": 0.2618154684387264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2618154684387264}
{"step": 307608, "time": 15579.601926326752, "episode/length": 177.0, "episode/score": 0.1944243816033122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1944243816033122}
{"step": 307624, "time": 15581.624442338943, "episode/length": 152.0, "episode/score": 0.17924300376398605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17924300376398605}
{"step": 307904, "time": 15593.772361516953, "episode/length": 162.0, "episode/score": 0.18760442717393744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18760442717393744}
{"step": 308072, "time": 15601.231470823288, "episode/length": 225.0, "episode/score": 0.26833267055553733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26833267055553733}
{"step": 308392, "time": 15614.773425340652, "episode/length": 198.0, "episode/score": 0.19964507715849322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19964507715849322}
{"step": 308608, "time": 15624.745453834534, "episode/length": 236.0, "episode/score": 0.2556622914271429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2556622914271429}
{"step": 308728, "time": 15630.419647216797, "episode/length": 139.0, "episode/score": 0.1690416632918641, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1690416632918641}
{"step": 308744, "time": 15632.441582679749, "episode/length": 205.0, "episode/score": 0.2111506244618795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2111506244618795}
{"step": 308984, "time": 15642.932652950287, "episode/length": 257.0, "episode/score": 0.2662010851854575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2662010851854575}
{"step": 309112, "time": 15649.277859210968, "episode/length": 185.0, "episode/score": 0.21305692447640467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21305692447640467}
{"step": 309840, "time": 15678.193105220795, "episode/length": 153.0, "episode/score": 0.17968155274138553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17968155274138553}
{"step": 310024, "time": 15703.924783706665, "eval_episode/length": 128.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9612403100775194}
{"step": 310024, "time": 15706.081897974014, "eval_episode/length": 142.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.993006993006993}
{"step": 310024, "time": 15707.801030874252, "eval_episode/length": 150.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 310024, "time": 15709.564042806625, "eval_episode/length": 155.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 310024, "time": 15711.237889051437, "eval_episode/length": 161.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 310024, "time": 15714.279751777649, "eval_episode/length": 198.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 310024, "time": 15717.474815130234, "eval_episode/length": 236.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9831223628691983}
{"step": 310024, "time": 15719.22829413414, "eval_episode/length": 242.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9711934156378601}
{"step": 310088, "time": 15721.620591878891, "episode/length": 167.0, "episode/score": 0.18078425966450595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18078425966450595}
{"step": 310240, "time": 15728.987548828125, "episode/length": 291.0, "episode/score": 0.3254899523781205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3254899523781205}
{"step": 310248, "time": 15730.58818435669, "episode/length": 271.0, "episode/score": 0.2910083033821138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2910083033821138}
{"step": 310248, "time": 15730.596723556519, "episode/length": 231.0, "episode/score": 0.2599342942412477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2599342942412477}
{"step": 310504, "time": 15743.395840406418, "episode/length": 189.0, "episode/score": 0.2086491165246116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2086491165246116}
{"step": 310544, "time": 15746.662950277328, "episode/length": 226.0, "episode/score": 0.27300841206670157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27300841206670157}
{"step": 310608, "time": 15750.450175523758, "episode/length": 186.0, "episode/score": 0.19605950802724692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19605950802724692}
{"step": 311224, "time": 15774.771381855011, "episode/length": 141.0, "episode/score": 0.15058363468597236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15058363468597236}
{"step": 311608, "time": 15792.076569795609, "episode/length": 220.0, "episode/score": 0.23506163084311993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23506163084311993}
{"step": 311784, "time": 15800.254737377167, "episode/length": 192.0, "episode/score": 0.20447588346542034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20447588346542034}
{"step": 311840, "time": 15803.996017694473, "episode/length": 153.0, "episode/score": 0.15999844215366466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15999844215366466}
{"step": 312000, "time": 15811.427485466003, "episode/length": 218.0, "episode/score": 0.24214766441036772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24214766441036772}
{"step": 312216, "time": 15820.820125341415, "episode/length": 245.0, "episode/score": 0.26127445613747113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26127445613747113}
{"step": 312376, "time": 15828.17629480362, "episode/length": 143.0, "episode/score": 0.15890178314293735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15890178314293735}
{"step": 312704, "time": 15842.14912891388, "episode/length": 274.0, "episode/score": 0.3176253151268611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3176253151268611}
{"step": 312832, "time": 15848.658302307129, "episode/length": 285.0, "episode/score": 0.32442313603860384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32442313603860384}
{"step": 313064, "time": 15859.086225509644, "episode/length": 44.0, "episode/score": 0.054166665533557534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054166665533557534}
{"step": 313152, "time": 15864.66506576538, "episode/length": 192.0, "episode/score": 0.19585062928672414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19585062928672414}
{"step": 313232, "time": 15869.68072271347, "episode/length": 153.0, "episode/score": 0.16716181273659458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16716181273659458}
{"step": 313272, "time": 15873.178000926971, "episode/length": 54.0, "episode/score": 0.0647916654124856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0647916654124856}
{"step": 313400, "time": 15879.508825063705, "episode/length": 201.0, "episode/score": 0.21130799242382636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21130799242382636}
{"step": 313504, "time": 15884.996591567993, "episode/length": 207.0, "episode/score": 0.2402336914165062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2402336914165062}
{"step": 313720, "time": 15894.330127000809, "episode/length": 167.0, "episode/score": 0.1735816554100893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1735816554100893}
{"step": 314072, "time": 15910.035442352295, "episode/length": 231.0, "episode/score": 0.23464927403983893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23464927403983893}
{"step": 314368, "time": 15922.763624429703, "episode/length": 162.0, "episode/score": 0.18493643378678826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18493643378678826}
{"step": 314696, "time": 15936.453548192978, "episode/length": 161.0, "episode/score": 0.1736620234005386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1736620234005386}
{"step": 314800, "time": 15942.302871465683, "episode/length": 190.0, "episode/score": 0.20005620883603115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20005620883603115}
{"step": 314872, "time": 15946.348291635513, "episode/length": 143.0, "episode/score": 0.15875617842357315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15875617842357315}
{"step": 314888, "time": 15948.36897945404, "episode/length": 172.0, "episode/score": 0.17619922464655247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17619922464655247}
{"step": 315272, "time": 15964.259541511536, "episode/length": 149.0, "episode/score": 0.14721179624757497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14721179624757497}
{"step": 315376, "time": 15970.008623123169, "episode/length": 267.0, "episode/score": 0.28393806465828675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28393806465828675}
{"step": 315392, "time": 15972.037166833878, "episode/length": 279.0, "episode/score": 0.30933651724262745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30933651724262745}
{"step": 315936, "time": 15993.73761177063, "episode/length": 154.0, "episode/score": 0.16053791582635313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16053791582635313}
{"step": 315976, "time": 15996.554116010666, "episode/length": 200.0, "episode/score": 0.24106547140399925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24106547140399925}
{"step": 316040, "time": 16000.654112100601, "episode/length": 145.0, "episode/score": 0.12909824984853913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12909824984853913}
{"step": 316120, "time": 16005.767323493958, "episode/length": 164.0, "episode/score": 0.16663814563617052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16663814563617052}
{"step": 316448, "time": 16019.732402086258, "episode/length": 146.0, "episode/score": 0.14694061153750226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14694061153750226}
{"step": 316448, "time": 16019.739471435547, "episode/length": 194.0, "episode/score": 0.20212313114279823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20212313114279823}
{"step": 316632, "time": 16029.506154060364, "episode/length": 154.0, "episode/score": 0.1608289895029884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1608289895029884}
{"step": 316776, "time": 16036.32299208641, "episode/length": 174.0, "episode/score": 0.1839354683233978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1839354683233978}
{"step": 317128, "time": 16051.064351558685, "episode/length": 143.0, "episode/score": 0.14969654864034965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14969654864034965}
{"step": 317344, "time": 16061.600987672806, "episode/length": 175.0, "episode/score": 0.157809413841278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.157809413841278}
{"step": 317552, "time": 16070.950137376785, "episode/length": 188.0, "episode/score": 0.18955949373867043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18955949373867043}
{"step": 317584, "time": 16073.584163427353, "episode/length": 118.0, "episode/score": 0.1360416642128257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1360416642128257}
{"step": 317640, "time": 16076.9503698349, "episode/length": 148.0, "episode/score": 0.16475142209401383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16475142209401383}
{"step": 317856, "time": 16086.756093502045, "episode/length": 175.0, "episode/score": 0.1898139838795032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1898139838795032}
{"step": 318040, "time": 16095.027890205383, "episode/length": 157.0, "episode/score": 0.16889587528294214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16889587528294214}
{"step": 318608, "time": 16118.024926662445, "episode/length": 184.0, "episode/score": 0.19684249698548228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19684249698548228}
{"step": 318752, "time": 16124.980429410934, "episode/length": 149.0, "episode/score": 0.16529477208496246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16529477208496246}
{"step": 318752, "time": 16124.988590478897, "episode/length": 175.0, "episode/score": 0.17745319083496724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17745319083496724}
{"step": 319520, "time": 16158.2564702034, "episode/length": 207.0, "episode/score": 0.2340786090499023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2340786090499023}
{"step": 319632, "time": 16163.99602818489, "episode/length": 255.0, "episode/score": 0.2763294646947543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2763294646947543}
{"step": 319752, "time": 16169.591186761856, "episode/length": 453.0, "episode/score": 0.47938068118128285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.47938068118128285}
{"step": 319872, "time": 16175.868631124496, "episode/length": 139.0, "episode/score": 0.15667350617877673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15667350617877673}
{"step": 319872, "time": 16175.877469539642, "episode/length": 228.0, "episode/score": 0.2322659279088839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2322659279088839}
{"step": 320008, "time": 16199.911490917206, "eval_episode/length": 78.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9367088607594937}
{"step": 320008, "time": 16204.863744020462, "eval_episode/length": 144.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.993103448275862}
{"step": 320008, "time": 16208.51534819603, "eval_episode/length": 179.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 320008, "time": 16210.290299654007, "eval_episode/length": 186.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9679144385026738}
{"step": 320008, "time": 16213.100482463837, "eval_episode/length": 217.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.981651376146789}
{"step": 320008, "time": 16215.108698368073, "eval_episode/length": 229.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 320008, "time": 16216.815781593323, "eval_episode/length": 232.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9828326180257511}
{"step": 320008, "time": 16219.41440153122, "eval_episode/length": 179.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 320168, "time": 16225.417062997818, "episode/length": 194.0, "episode/score": 0.2355076912936056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2355076912936056}
{"step": 320176, "time": 16227.455989599228, "episode/length": 177.0, "episode/score": 0.20750310103176162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20750310103176162}
{"step": 320744, "time": 16249.848109722137, "episode/length": 138.0, "episode/score": 0.13813783653677092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13813783653677092}
{"step": 320872, "time": 16256.095765829086, "episode/length": 168.0, "episode/score": 0.18640314683580073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18640314683580073}
{"step": 321200, "time": 16270.179632663727, "episode/length": 444.0, "episode/score": 0.418516096429812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.418516096429812}
{"step": 321360, "time": 16277.66080069542, "episode/length": 185.0, "episode/score": 0.17069884334159724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17069884334159724}
{"step": 321400, "time": 16280.38278055191, "episode/length": 152.0, "episode/score": 0.1753988064301666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1753988064301666}
{"step": 321528, "time": 16286.59785747528, "episode/length": 221.0, "episode/score": 0.23871537407649157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23871537407649157}
{"step": 321552, "time": 16289.213691234589, "episode/length": 172.0, "episode/score": 0.18044369632480084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18044369632480084}
{"step": 321680, "time": 16295.531940937042, "episode/length": 225.0, "episode/score": 0.22447703268335317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22447703268335317}
{"step": 322120, "time": 16313.702662467957, "episode/length": 171.0, "episode/score": 0.17993135221331613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17993135221331613}
{"step": 322265, "time": 16321.828938245773, "train_stats/sum_log_reward": 1.3547169445961151, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.669811320754717, "train_stats/max_log_achievement_collect_sapling": 0.7924528301886793, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.44339622641509435, "train_stats/max_log_achievement_defeat_skeleton": 0.009433962264150943, "train_stats/max_log_achievement_defeat_zombie": 0.009433962264150943, "train_stats/max_log_achievement_eat_cow": 0.018867924528301886, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009433962264150943, "train_stats/max_log_achievement_make_wood_sword": 0.009433962264150943, "train_stats/max_log_achievement_place_plant": 0.5188679245283019, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.07547169811320754, "train_stats/max_log_achievement_wake_up": 0.3113207547169811, "train_stats/mean_log_entropy": 2.1429530325925574, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.767842450479823, "train/action_min": 0.0, "train/action_std": 4.517468092009777, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007642046849089344, "train/actor_opt_grad_steps": 19410.0, "train/actor_opt_loss": -9.630343606270204, "train/adv_mag": 0.1715647885062563, "train/adv_max": 0.11240418237729335, "train/adv_mean": 4.998251017337952e-05, "train/adv_min": -0.16957917715620807, "train/adv_std": 0.012841671096586337, "train/cont_avg": 0.994625061515748, "train/cont_loss_mean": 0.00027656129761245804, "train/cont_loss_std": 0.008189182228765218, "train/cont_neg_acc": 0.987688965740658, "train/cont_neg_loss": 0.024826531928926077, "train/cont_pos_acc": 0.9999768288116756, "train/cont_pos_loss": 0.00014406716497858735, "train/cont_pred": 0.9946345330223324, "train/cont_rate": 0.994625061515748, "train/dyn_loss_mean": 12.737000044875257, "train/dyn_loss_std": 8.482218663523517, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16282774704530484, "train/extr_critic_critic_opt_grad_steps": 19410.0, "train/extr_critic_critic_opt_loss": 10793.275475209153, "train/extr_critic_mag": 0.27428012476192687, "train/extr_critic_max": 0.27428012476192687, "train/extr_critic_mean": 0.20747593010035087, "train/extr_critic_min": 0.001758555727680837, "train/extr_critic_std": 0.06502809759786748, "train/extr_return_normed_mag": 0.22834823274706292, "train/extr_return_normed_max": 0.22834823274706292, "train/extr_return_normed_mean": 0.16154200753827733, "train/extr_return_normed_min": -0.0449987477732925, "train/extr_return_normed_std": 0.06650720950304054, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.27433215633152036, "train/extr_return_raw_max": 0.27433215633152036, "train/extr_return_raw_mean": 0.2075259331173784, "train/extr_return_raw_min": 0.0009851756058339997, "train/extr_return_raw_std": 0.06650720964970551, "train/extr_reward_mag": 0.0013686052457554134, "train/extr_reward_max": 0.0013686052457554134, "train/extr_reward_mean": 0.0010964058680591855, "train/extr_reward_min": 1.0738222617802657e-05, "train/extr_reward_std": 0.00022856488708850349, "train/image_loss_mean": 7.32425996825451, "train/image_loss_std": 11.545349511574573, "train/model_loss_mean": 15.00625338516836, "train/model_loss_std": 15.153484119205025, "train/model_opt_grad_norm": 67.49489679111271, "train/model_opt_grad_steps": 19390.0, "train/model_opt_loss": 13541.689218596212, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 910.4330708661417, "train/policy_entropy_mag": 2.7540271394834743, "train/policy_entropy_max": 2.7540271394834743, "train/policy_entropy_mean": 2.039154116562971, "train/policy_entropy_min": 0.08674245298378111, "train/policy_entropy_std": 0.5325173177118376, "train/policy_logprob_mag": 7.435201633633591, "train/policy_logprob_max": -0.010501345010899653, "train/policy_logprob_mean": -2.0388112650142878, "train/policy_logprob_min": -7.435201633633591, "train/policy_logprob_std": 1.1822776259399774, "train/policy_randomness_mag": 0.9720507221897756, "train/policy_randomness_max": 0.9720507221897756, "train/policy_randomness_mean": 0.7197319180007995, "train/policy_randomness_min": 0.030616279354128313, "train/policy_randomness_std": 0.18795524549296522, "train/post_ent_mag": 57.68808049479807, "train/post_ent_max": 57.68808049479807, "train/post_ent_mean": 39.15432423869456, "train/post_ent_min": 20.67646048388143, "train/post_ent_std": 6.772864041365977, "train/prior_ent_mag": 67.57155170590859, "train/prior_ent_max": 67.57155170590859, "train/prior_ent_mean": 51.9812018326887, "train/prior_ent_min": 28.049259426086905, "train/prior_ent_std": 6.195450910433071, "train/rep_loss_mean": 12.737000044875257, "train/rep_loss_std": 8.482218663523517, "train/reward_avg": 0.0010450632447985507, "train/reward_loss_mean": 0.03951691598521443, "train/reward_loss_std": 0.012007891523145785, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001298598417146938, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039516916073213414, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010436914501873059, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.9749999637715518, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.5625, "eval_stats/max_log_achievement_collect_sapling": 0.6875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.005411928053945303, "report/cont_loss_std": 0.16818104684352875, "report/cont_neg_acc": 0.800000011920929, "report/cont_neg_loss": 1.090807318687439, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.614012767793611e-05, "report/cont_pred": 0.9960740804672241, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.517248153686523, "report/dyn_loss_std": 8.465956687927246, "report/image_loss_mean": 7.0113043785095215, "report/image_loss_std": 10.074172019958496, "report/model_loss_mean": 14.568069458007812, "report/model_loss_std": 13.622121810913086, "report/post_ent_mag": 59.82231521606445, "report/post_ent_max": 59.82231521606445, "report/post_ent_mean": 39.531497955322266, "report/post_ent_min": 22.670169830322266, "report/post_ent_std": 7.7597737312316895, "report/prior_ent_mag": 68.7791748046875, "report/prior_ent_max": 68.7791748046875, "report/prior_ent_mean": 52.25068664550781, "report/prior_ent_min": 27.619342803955078, "report/prior_ent_std": 7.157753944396973, "report/rep_loss_mean": 12.517248153686523, "report/rep_loss_std": 8.465956687927246, "report/reward_avg": 0.001088250195607543, "report/reward_loss_mean": 0.041003596037626266, "report/reward_loss_std": 0.01061976607888937, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012557506561279297, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.041003599762916565, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010601081885397434, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.1801874279626645e-05, "eval/cont_loss_std": 0.00018330191960558295, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0007840862381272018, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.012450962269213e-06, "eval/cont_pred": 0.9951130151748657, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.515371322631836, "eval/dyn_loss_std": 10.676163673400879, "eval/image_loss_mean": 10.375944137573242, "eval/image_loss_std": 17.30072021484375, "eval/model_loss_mean": 20.980789184570312, "eval/model_loss_std": 22.32798194885254, "eval/post_ent_mag": 59.60538864135742, "eval/post_ent_max": 59.60538864135742, "eval/post_ent_mean": 38.84925842285156, "eval/post_ent_min": 22.35821533203125, "eval/post_ent_std": 7.232891082763672, "eval/prior_ent_mag": 68.7791748046875, "eval/prior_ent_max": 68.7791748046875, "eval/prior_ent_mean": 52.55927276611328, "eval/prior_ent_min": 27.080883026123047, "eval/prior_ent_std": 5.743149280548096, "eval/rep_loss_mean": 16.515371322631836, "eval/rep_loss_std": 10.676163673400879, "eval/reward_avg": 0.004882812965661287, "eval/reward_loss_mean": 0.6956076622009277, "eval/reward_loss_std": 3.5385243892669678, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012269020080566406, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.5086864829063416, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 19.649417877197266, "eval/reward_pred": 0.0010348442010581493, "eval/reward_rate": 0.009765625, "replay/size": 321761.0, "replay/inserts": 20336.0, "replay/samples": 20336.0, "replay/insert_wait_avg": 1.2997423542661989e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.917311696158348e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 63784.0, "eval_replay/inserts": 4016.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2094874780966466e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0605442523956, "timer/env.step_count": 2542.0, "timer/env.step_total": 227.68965768814087, "timer/env.step_frac": 0.22767587322260807, "timer/env.step_avg": 0.08957106911413881, "timer/env.step_min": 0.02236032485961914, "timer/env.step_max": 3.3005974292755127, "timer/replay._sample_count": 20336.0, "timer/replay._sample_total": 9.906009435653687, "timer/replay._sample_frac": 0.009905409720027515, "timer/replay._sample_avg": 0.0004871169077327737, "timer/replay._sample_min": 0.0003647804260253906, "timer/replay._sample_max": 0.021544694900512695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3044.0, "timer/agent.policy_total": 48.663931369781494, "timer/agent.policy_frac": 0.0486609852268101, "timer/agent.policy_avg": 0.015986836849468295, "timer/agent.policy_min": 0.009445905685424805, "timer/agent.policy_max": 0.10369062423706055, "timer/dataset_train_count": 1271.0, "timer/dataset_train_total": 0.13734936714172363, "timer/dataset_train_frac": 0.00013734105193041128, "timer/dataset_train_avg": 0.00010806401820749302, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0003256797790527344, "timer/agent.train_count": 1271.0, "timer/agent.train_total": 572.626490354538, "timer/agent.train_frac": 0.5725918232106738, "timer/agent.train_avg": 0.4505322504756396, "timer/agent.train_min": 0.4375927448272705, "timer/agent.train_max": 1.4836483001708984, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4788076877593994, "timer/agent.report_frac": 0.00047877870046091704, "timer/agent.report_avg": 0.2394038438796997, "timer/agent.report_min": 0.23304510116577148, "timer/agent.report_max": 0.24576258659362793, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7654880831696205e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 20.334505158588037}
{"step": 322280, "time": 16321.989928483963, "episode/length": 175.0, "episode/score": 0.16414366230128508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16414366230128508}
{"step": 322760, "time": 16342.215972661972, "episode/length": 194.0, "episode/score": 0.18911475877393968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18911475877393968}
{"step": 322904, "time": 16349.142441034317, "episode/length": 152.0, "episode/score": 0.1832215571166671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1832215571166671}
{"step": 323200, "time": 16361.996588468552, "episode/length": 229.0, "episode/score": 0.2301701662117921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2301701662117921}
{"step": 323296, "time": 16367.116138219833, "episode/length": 236.0, "episode/score": 0.2742959926981712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2742959926981712}
{"step": 323640, "time": 16381.19263958931, "episode/length": 263.0, "episode/score": 0.2517122156032201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2517122156032201}
{"step": 323720, "time": 16385.716725587845, "episode/length": 199.0, "episode/score": 0.2332619003864238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2332619003864238}
{"step": 323760, "time": 16389.011427640915, "episode/length": 275.0, "episode/score": 0.30278659322993917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30278659322993917}
{"step": 323872, "time": 16394.72069334984, "episode/length": 198.0, "episode/score": 0.1888777410131297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1888777410131297}
{"step": 323872, "time": 16394.72772026062, "episode/length": 138.0, "episode/score": 0.1320513478203793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1320513478203793}
{"step": 324272, "time": 16412.776777505875, "episode/length": 170.0, "episode/score": 0.1694854088818829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1694854088818829}
{"step": 324416, "time": 16419.781213521957, "episode/length": 151.0, "episode/score": 0.1674642256111838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1674642256111838}
{"step": 324688, "time": 16431.469629764557, "episode/length": 130.0, "episode/score": 0.15241531985157053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15241531985157053}
{"step": 324824, "time": 16437.927484750748, "episode/length": 190.0, "episode/score": 0.1785759613121627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1785759613121627}
{"step": 324968, "time": 16444.738904714584, "episode/length": 155.0, "episode/score": 0.1525451950110437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1525451950110437}
{"step": 325016, "time": 16448.09196472168, "episode/length": 74.0, "episode/score": 0.08118939266205416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08118939266205416}
{"step": 325024, "time": 16450.111152648926, "episode/length": 143.0, "episode/score": 0.1431852807818359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1431852807818359}
{"step": 325488, "time": 16468.848264694214, "episode/length": 215.0, "episode/score": 0.24482044678006787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24482044678006787}
{"step": 325512, "time": 16471.043680906296, "episode/length": 67.0, "episode/score": 0.08249999827239662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08249999827239662}
{"step": 325536, "time": 16473.601613521576, "episode/length": 207.0, "episode/score": 0.2166252762726799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2166252762726799}
{"step": 325568, "time": 16476.417421102524, "episode/length": 161.0, "episode/score": 0.1738309258926165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1738309258926165}
{"step": 325824, "time": 16487.758684635162, "episode/length": 141.0, "episode/score": 0.13742999548958323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13742999548958323}
{"step": 325840, "time": 16489.950330734253, "episode/length": 126.0, "episode/score": 0.14529851532097382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14529851532097382}
{"step": 326200, "time": 16504.52816271782, "episode/length": 147.0, "episode/score": 0.16769376963384275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16769376963384275}
{"step": 326320, "time": 16510.778920173645, "episode/length": 161.0, "episode/score": 0.17127116175106494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17127116175106494}
{"step": 326752, "time": 16528.33334517479, "episode/length": 157.0, "episode/score": 0.1749706370246713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1749706370246713}
{"step": 327048, "time": 16540.683577537537, "episode/length": 188.0, "episode/score": 0.2146167441187572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2146167441187572}
{"step": 327072, "time": 16543.309571266174, "episode/length": 194.0, "episode/score": 0.20365198216677527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20365198216677527}
{"step": 327272, "time": 16552.07428598404, "episode/length": 180.0, "episode/score": 0.18972027808922576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18972027808922576}
{"step": 327280, "time": 16554.122505426407, "episode/length": 179.0, "episode/score": 0.17911180305236485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17911180305236485}
{"step": 327392, "time": 16559.925675868988, "episode/length": 227.0, "episode/score": 0.21733790070720715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21733790070720715}
{"step": 327544, "time": 16566.993819475174, "episode/length": 167.0, "episode/score": 0.16918923498360527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16918923498360527}
{"step": 327560, "time": 16569.094581842422, "episode/length": 154.0, "episode/score": 0.15917268059911294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15917268059911294}
{"step": 327976, "time": 16587.548857688904, "episode/length": 152.0, "episode/score": 0.15440884261624888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15440884261624888}
{"step": 328000, "time": 16590.30433511734, "episode/length": 118.0, "episode/score": 0.13302799936445808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13302799936445808}
{"step": 328312, "time": 16603.284408807755, "episode/length": 41.0, "episode/score": 0.04244230716722086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04244230716722086}
{"step": 328440, "time": 16609.559616804123, "episode/length": 130.0, "episode/score": 0.15150606875613448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15150606875613448}
{"step": 328472, "time": 16612.341635465622, "episode/length": 149.0, "episode/score": 0.16878780062779697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16878780062779697}
{"step": 328808, "time": 16626.348595142365, "episode/length": 155.0, "episode/score": 0.16129004871254438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16129004871254438}
{"step": 329016, "time": 16635.760258436203, "episode/length": 242.0, "episode/score": 0.2656629962821171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2656629962821171}
{"step": 329024, "time": 16637.81065940857, "episode/length": 217.0, "episode/score": 0.2223428131219407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2223428131219407}
{"step": 329336, "time": 16650.770315885544, "episode/length": 223.0, "episode/score": 0.2300131642496126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2300131642496126}
{"step": 329640, "time": 16663.9729115963, "episode/length": 165.0, "episode/score": 0.1858963647928249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1858963647928249}
{"step": 329712, "time": 16668.929136514664, "episode/length": 213.0, "episode/score": 0.2483889525410632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2483889525410632}
{"step": 329824, "time": 16675.01504611969, "episode/length": 172.0, "episode/score": 0.17729456668439525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17729456668439525}
{"step": 330096, "time": 16704.798621177673, "eval_episode/length": 131.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 330096, "time": 16706.574689865112, "eval_episode/length": 138.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 330096, "time": 16708.47227525711, "eval_episode/length": 147.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 330096, "time": 16710.033141613007, "eval_episode/length": 148.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 330096, "time": 16711.585318803787, "eval_episode/length": 149.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9533333333333334}
{"step": 330096, "time": 16715.62931585312, "eval_episode/length": 174.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 330096, "time": 16717.560423851013, "eval_episode/length": 180.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.994475138121547}
{"step": 330096, "time": 16720.289922714233, "eval_episode/length": 209.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 330168, "time": 16722.739282608032, "episode/length": 169.0, "episode/score": 0.18356734335429792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18356734335429792}
{"step": 330208, "time": 16726.020765542984, "episode/length": 216.0, "episode/score": 0.21397035539484932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21397035539484932}
{"step": 330424, "time": 16735.297501325607, "episode/length": 174.0, "episode/score": 0.1927099669810559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1927099669810559}
{"step": 330480, "time": 16739.0835211277, "episode/length": 142.0, "episode/score": 0.13806190930154116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13806190930154116}
{"step": 330792, "time": 16752.0399889946, "episode/length": 221.0, "episode/score": 0.2470863577846103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2470863577846103}
{"step": 330888, "time": 16757.078801870346, "episode/length": 146.0, "episode/score": 0.1313978226189647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1313978226189647}
{"step": 331264, "time": 16772.675266742706, "episode/length": 202.0, "episode/score": 0.2141580581837843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2141580581837843}
{"step": 331288, "time": 16774.861249685287, "episode/length": 107.0, "episode/score": 0.12130766485552158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12130766485552158}
{"step": 331456, "time": 16783.129766464233, "episode/length": 155.0, "episode/score": 0.17384859006506304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17384859006506304}
{"step": 331848, "time": 16798.989315509796, "episode/length": 209.0, "episode/score": 0.24709157940196746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24709157940196746}
{"step": 331872, "time": 16801.67596912384, "episode/length": 173.0, "episode/score": 0.18099874863401055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18099874863401055}
{"step": 332224, "time": 16816.390255212784, "episode/length": 178.0, "episode/score": 0.16251166388474303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16251166388474303}
{"step": 332224, "time": 16816.39812898636, "episode/length": 166.0, "episode/score": 0.1793782463973912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1793782463973912}
{"step": 332432, "time": 16827.372550964355, "episode/length": 142.0, "episode/score": 0.1440116359426611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1440116359426611}
{"step": 332600, "time": 16835.250881671906, "episode/length": 142.0, "episode/score": 0.1389562292079063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1389562292079063}
{"step": 332928, "time": 16849.442817926407, "episode/length": 207.0, "episode/score": 0.20135119471160579, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20135119471160579}
{"step": 333280, "time": 16864.821779489517, "episode/length": 178.0, "episode/score": 0.20251985595041333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20251985595041333}
{"step": 333296, "time": 16866.85305404663, "episode/length": 86.0, "episode/score": 0.09731580611423851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09731580611423851}
{"step": 333336, "time": 16869.72413110733, "episode/length": 182.0, "episode/score": 0.17513567384230555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17513567384230555}
{"step": 333384, "time": 16872.91878271103, "episode/length": 444.0, "episode/score": 0.42295799534804246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42295799534804246}
{"step": 333832, "time": 16891.140810251236, "episode/length": 200.0, "episode/score": 0.20487561849267877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20487561849267877}
{"step": 333904, "time": 16895.591431617737, "episode/length": 183.0, "episode/score": 0.17164336413634373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17164336413634373}
{"step": 333912, "time": 16897.301738977432, "episode/length": 210.0, "episode/score": 0.23033461545537648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23033461545537648}
{"step": 334344, "time": 16914.775866508484, "episode/length": 125.0, "episode/score": 0.12609243529050218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12609243529050218}
{"step": 334384, "time": 16918.02459335327, "episode/length": 181.0, "episode/score": 0.18153611405705306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18153611405705306}
{"step": 334672, "time": 16930.280364513397, "episode/length": 160.0, "episode/score": 0.1578479959393917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1578479959393917}
{"step": 335064, "time": 16946.23870563507, "episode/length": 222.0, "episode/score": 0.2431372912601546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2431372912601546}
{"step": 335144, "time": 16950.678159713745, "episode/length": 154.0, "episode/score": 0.16704948534606956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16704948534606956}
{"step": 335368, "time": 16960.579003810883, "episode/length": 258.0, "episode/score": 0.28059277330839905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28059277330839905}
{"step": 335520, "time": 16968.01897072792, "episode/length": 141.0, "episode/score": 0.12573115361510645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12573115361510645}
{"step": 335600, "time": 16972.526980638504, "episode/length": 210.0, "episode/score": 0.22211461703454916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22211461703454916}
{"step": 335768, "time": 16980.02293419838, "episode/length": 241.0, "episode/score": 0.273569343143663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.273569343143663}
{"step": 335832, "time": 16983.91448378563, "episode/length": 95.0, "episode/score": 0.1109214815469386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1109214815469386}
{"step": 336136, "time": 16998.119418382645, "episode/length": 182.0, "episode/score": 0.17205692585048382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17205692585048382}
{"step": 336280, "time": 17004.970794677734, "episode/length": 241.0, "episode/score": 0.23885063146826724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23885063146826724}
{"step": 336512, "time": 17015.268806934357, "episode/length": 142.0, "episode/score": 0.14685518645228512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14685518645228512}
{"step": 336912, "time": 17031.698259353638, "episode/length": 142.0, "episode/score": 0.1575877330151343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1575877330151343}
{"step": 337064, "time": 17038.589735507965, "episode/length": 182.0, "episode/score": 0.18641310477732986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18641310477732986}
{"step": 337408, "time": 17053.20321893692, "episode/length": 235.0, "episode/score": 0.2697563563983749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2697563563983749}
{"step": 337504, "time": 17058.340425014496, "episode/length": 170.0, "episode/score": 0.15435913865667317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15435913865667317}
{"step": 337632, "time": 17064.74863219261, "episode/length": 168.0, "episode/score": 0.17981748387910557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17981748387910557}
{"step": 337656, "time": 17066.838511943817, "episode/length": 227.0, "episode/score": 0.23524990693204018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23524990693204018}
{"step": 337992, "time": 17080.8005964756, "episode/length": 184.0, "episode/score": 0.20728560083671255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20728560083671255}
{"step": 338280, "time": 17093.06489300728, "episode/length": 391.0, "episode/score": 0.4304387332886108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4304387332886108}
{"step": 338744, "time": 17111.8826751709, "episode/length": 166.0, "episode/score": 0.173442658807744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.173442658807744}
{"step": 338856, "time": 17117.60847592354, "episode/length": 242.0, "episode/score": 0.2762305609312534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2762305609312534}
{"step": 338872, "time": 17119.70482301712, "episode/length": 225.0, "episode/score": 0.22397074585842347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22397074585842347}
{"step": 338952, "time": 17124.130804538727, "episode/length": 164.0, "episode/score": 0.15884796679893043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15884796679893043}
{"step": 339120, "time": 17132.19383740425, "episode/length": 46.0, "episode/score": 0.054374999017454684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054374999017454684}
{"step": 339216, "time": 17137.532900094986, "episode/length": 194.0, "episode/score": 0.210740093260938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.210740093260938}
{"step": 339264, "time": 17140.76347541809, "episode/length": 219.0, "episode/score": 0.24098355880278177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24098355880278177}
{"step": 339416, "time": 17147.73556494713, "episode/length": 141.0, "episode/score": 0.1577785173049051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1577785173049051}
{"step": 339416, "time": 17147.743425369263, "episode/length": 177.0, "episode/score": 0.16592454338297102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16592454338297102}
{"step": 339688, "time": 17160.912657260895, "episode/length": 91.0, "episode/score": 0.09501849089019743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09501849089019743}
{"step": 340080, "time": 17193.4562022686, "eval_episode/length": 91.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9565217391304348}
{"step": 340080, "time": 17196.840458393097, "eval_episode/length": 135.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 340080, "time": 17198.920432329178, "eval_episode/length": 148.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.959731543624161}
{"step": 340080, "time": 17200.50412750244, "eval_episode/length": 150.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 340080, "time": 17202.621731758118, "eval_episode/length": 159.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9625}
{"step": 340080, "time": 17204.339407444, "eval_episode/length": 167.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 340080, "time": 17205.987230062485, "eval_episode/length": 172.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 340080, "time": 17210.706783533096, "eval_episode/length": 250.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9960159362549801}
{"step": 340168, "time": 17213.785020828247, "episode/length": 93.0, "episode/score": 0.11124999786261469, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11124999786261469}
{"step": 340336, "time": 17221.788818120956, "episode/length": 184.0, "episode/score": 0.18970252027929746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18970252027929746}
{"step": 340600, "time": 17233.08843064308, "episode/length": 184.0, "episode/score": 0.21226851723986329, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21226851723986329}
{"step": 340856, "time": 17244.277693748474, "episode/length": 198.0, "episode/score": 0.1989446779800801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1989446779800801}
{"step": 340880, "time": 17246.999937295914, "episode/length": 148.0, "episode/score": 0.1514343068265589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1514343068265589}
{"step": 341040, "time": 17254.448957443237, "episode/length": 227.0, "episode/score": 0.219701145806539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.219701145806539}
{"step": 341112, "time": 17258.484886169434, "episode/length": 211.0, "episode/score": 0.21519524646009813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21519524646009813}
{"step": 341416, "time": 17271.294647693634, "episode/length": 155.0, "episode/score": 0.1308666814074968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1308666814074968}
{"step": 341624, "time": 17280.65252828598, "episode/length": 160.0, "episode/score": 0.17022097029257566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17022097029257566}
{"step": 342120, "time": 17300.852888822556, "episode/length": 157.0, "episode/score": 0.1921666627167724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1921666627167724}
{"step": 342208, "time": 17305.883428812027, "episode/length": 145.0, "episode/score": 0.16010084640220157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16010084640220157}
{"step": 342296, "time": 17310.40083217621, "episode/length": 427.0, "episode/score": 0.39863422328176057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39863422328176057}
{"step": 342520, "time": 17320.325955867767, "episode/length": 239.0, "episode/score": 0.26957183323975187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26957183323975187}
{"step": 342521, "time": 17322.949895620346, "train_stats/sum_log_reward": 1.3499999829301876, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.4732142857142856, "train_stats/max_log_achievement_collect_sapling": 0.5535714285714286, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.7410714285714286, "train_stats/max_log_achievement_defeat_skeleton": 0.008928571428571428, "train_stats/max_log_achievement_defeat_zombie": 0.0, "train_stats/max_log_achievement_eat_cow": 0.026785714285714284, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008928571428571428, "train_stats/max_log_achievement_make_wood_sword": 0.008928571428571428, "train_stats/max_log_achievement_place_plant": 0.375, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.08035714285714286, "train_stats/max_log_achievement_wake_up": 0.4107142857142857, "train_stats/mean_log_entropy": 2.1753738799265454, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.881516824557087, "train/action_min": 0.0, "train/action_std": 4.59554231072974, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007953077136707587, "train/actor_opt_grad_steps": 20680.0, "train/actor_opt_loss": -8.704453382787742, "train/adv_mag": 0.1765723466051845, "train/adv_max": 0.11819168778620368, "train/adv_mean": 0.00012223720970838244, "train/adv_min": -0.17487911856549931, "train/adv_std": 0.013065541859745509, "train/cont_avg": 0.9946404404527559, "train/cont_loss_mean": 0.00032277892763104106, "train/cont_loss_std": 0.00941067984742375, "train/cont_neg_acc": 0.9871734803117166, "train/cont_neg_loss": 0.039733847780675076, "train/cont_pos_acc": 0.9999612757540125, "train/cont_pos_loss": 0.00013818066414377584, "train/cont_pred": 0.9946495745125719, "train/cont_rate": 0.9946404404527559, "train/dyn_loss_mean": 12.285973083315872, "train/dyn_loss_std": 8.44564547501211, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1789898986187507, "train/extr_critic_critic_opt_grad_steps": 20680.0, "train/extr_critic_critic_opt_loss": 10954.871962659941, "train/extr_critic_mag": 0.27609470134645, "train/extr_critic_max": 0.27609470134645, "train/extr_critic_mean": 0.20886597870372411, "train/extr_critic_min": 0.0018048239505197119, "train/extr_critic_std": 0.06577266770319676, "train/extr_return_normed_mag": 0.23173246374280435, "train/extr_return_normed_max": 0.23173246374280435, "train/extr_return_normed_mean": 0.16453976166529918, "train/extr_return_normed_min": -0.04344084518631612, "train/extr_return_normed_std": 0.06714413106793493, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2761810466529816, "train/extr_return_raw_max": 0.2761810466529816, "train/extr_return_raw_mean": 0.2089883479781038, "train/extr_return_raw_min": 0.0010077380758570873, "train/extr_return_raw_std": 0.06714413092126996, "train/extr_reward_mag": 0.0013460296345508005, "train/extr_reward_max": 0.0013460296345508005, "train/extr_reward_mean": 0.00109543952555579, "train/extr_reward_min": 1.0110261872058778e-05, "train/extr_reward_std": 0.0002331072438231442, "train/image_loss_mean": 6.742250994434507, "train/image_loss_std": 11.026321392359696, "train/model_loss_mean": 14.153972460528998, "train/model_loss_std": 14.583022365419884, "train/model_opt_grad_norm": 65.53783002237635, "train/model_opt_grad_steps": 20659.354330708662, "train/model_opt_loss": 18097.61004398376, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1279.5275590551182, "train/policy_entropy_mag": 2.754798635723084, "train/policy_entropy_max": 2.754798635723084, "train/policy_entropy_mean": 2.043290769959998, "train/policy_entropy_min": 0.08444941648113446, "train/policy_entropy_std": 0.5598140499723239, "train/policy_logprob_mag": 7.435322303471603, "train/policy_logprob_max": -0.01017705399513714, "train/policy_logprob_mean": -2.044414398238415, "train/policy_logprob_min": -7.435322303471603, "train/policy_logprob_std": 1.183865752745801, "train/policy_randomness_mag": 0.9723230290600634, "train/policy_randomness_max": 0.9723230290600634, "train/policy_randomness_mean": 0.7211919764834126, "train/policy_randomness_min": 0.0298069380517081, "train/policy_randomness_std": 0.19758979143120173, "train/post_ent_mag": 57.89113340603085, "train/post_ent_max": 57.89113340603085, "train/post_ent_mean": 39.61119127649022, "train/post_ent_min": 20.839853256706178, "train/post_ent_std": 6.906886220916989, "train/prior_ent_mag": 67.82925481120432, "train/prior_ent_max": 67.82925481120432, "train/prior_ent_mean": 52.034869216558505, "train/prior_ent_min": 28.15455550847091, "train/prior_ent_std": 6.2239189636050245, "train/rep_loss_mean": 12.285973083315872, "train/rep_loss_std": 8.44564547501211, "train/reward_avg": 0.0010536071903064965, "train/reward_loss_mean": 0.039814771659026936, "train/reward_loss_std": 0.011665330363774862, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00130212494707483, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03981477162969394, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010543119732481171, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.7250000117346644, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.0625, "eval_stats/max_log_achievement_collect_sapling": 0.3125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.25, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 9.169070108328015e-05, "report/cont_loss_std": 0.002154991962015629, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.9929571863031015e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.18311343411915e-05, "report/cont_pred": 0.9979575276374817, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 12.829416275024414, "report/dyn_loss_std": 7.887284755706787, "report/image_loss_mean": 6.292726516723633, "report/image_loss_std": 11.244731903076172, "report/model_loss_mean": 14.031241416931152, "report/model_loss_std": 14.701621055603027, "report/post_ent_mag": 58.28348159790039, "report/post_ent_max": 58.28348159790039, "report/post_ent_mean": 39.59989929199219, "report/post_ent_min": 22.042322158813477, "report/post_ent_std": 6.903799533843994, "report/prior_ent_mag": 67.92711639404297, "report/prior_ent_max": 67.92711639404297, "report/prior_ent_mean": 52.952613830566406, "report/prior_ent_min": 28.372961044311523, "report/prior_ent_std": 5.398597240447998, "report/rep_loss_mean": 12.829416275024414, "report/rep_loss_std": 7.887284755706787, "report/reward_avg": 0.0010817635338753462, "report/reward_loss_mean": 0.04077339917421341, "report/reward_loss_std": 0.010614539496600628, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012753009796142578, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04077339917421341, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010572111932560802, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.008857297711074352, "eval/cont_loss_std": 0.2830682098865509, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 1.8126434087753296, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.531488907057792e-06, "eval/cont_pred": 0.9960876703262329, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.775657653808594, "eval/dyn_loss_std": 10.513651847839355, "eval/image_loss_mean": 13.460434913635254, "eval/image_loss_std": 27.614694595336914, "eval/model_loss_mean": 25.287065505981445, "eval/model_loss_std": 31.406909942626953, "eval/post_ent_mag": 58.35777282714844, "eval/post_ent_max": 58.35777282714844, "eval/post_ent_mean": 38.08673095703125, "eval/post_ent_min": 19.546255111694336, "eval/post_ent_std": 6.606021404266357, "eval/prior_ent_mag": 67.92711639404297, "eval/prior_ent_max": 67.92711639404297, "eval/prior_ent_mean": 52.7847900390625, "eval/prior_ent_min": 26.560626983642578, "eval/prior_ent_std": 5.451357364654541, "eval/rep_loss_mean": 18.775657653808594, "eval/rep_loss_std": 10.513651847839355, "eval/reward_avg": 0.00830078125, "eval/reward_loss_mean": 0.5523778200149536, "eval/reward_loss_std": 3.1837916374206543, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012557506561279297, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.32436084747314453, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 19.781816482543945, "eval/reward_pred": 0.0010204801801592112, "eval/reward_rate": 0.01171875, "replay/size": 342017.0, "replay/inserts": 20256.0, "replay/samples": 20256.0, "replay/insert_wait_avg": 1.293352524062845e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.987657994455636e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 67472.0, "eval_replay/inserts": 3688.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1907999531048756e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.1094408035278, "timer/env.step_count": 2532.0, "timer/env.step_total": 234.6145691871643, "timer/env.step_frac": 0.2343545666684093, "timer/env.step_avg": 0.09265978245938558, "timer/env.step_min": 0.02229619026184082, "timer/env.step_max": 3.162595510482788, "timer/replay._sample_count": 20256.0, "timer/replay._sample_total": 9.875944137573242, "timer/replay._sample_frac": 0.009864999504596062, "timer/replay._sample_avg": 0.00048755648388493493, "timer/replay._sample_min": 0.0003609657287597656, "timer/replay._sample_max": 0.010818004608154297, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2993.0, "timer/agent.policy_total": 48.594813108444214, "timer/agent.policy_frac": 0.048540959787014094, "timer/agent.policy_avg": 0.016236155398745143, "timer/agent.policy_min": 0.009584188461303711, "timer/agent.policy_max": 0.1327674388885498, "timer/dataset_train_count": 1266.0, "timer/dataset_train_total": 0.13641881942749023, "timer/dataset_train_frac": 0.0001362676385490835, "timer/dataset_train_avg": 0.00010775578153830192, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.0010786056518554688, "timer/agent.train_count": 1266.0, "timer/agent.train_total": 569.6997509002686, "timer/agent.train_frac": 0.569068403193767, "timer/agent.train_avg": 0.4499998032387587, "timer/agent.train_min": 0.4390602111816406, "timer/agent.train_max": 0.9646966457366943, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47902846336364746, "timer/agent.report_frac": 0.0004784975986033668, "timer/agent.report_avg": 0.23951423168182373, "timer/agent.report_min": 0.23355841636657715, "timer/agent.report_max": 0.2454700469970703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.677078247070312e-05, "timer/dataset_eval_frac": 7.668570422139264e-08, "timer/dataset_eval_avg": 7.677078247070312e-05, "timer/dataset_eval_min": 7.677078247070312e-05, "timer/dataset_eval_max": 7.677078247070312e-05, "fps": 20.233311717398404}
{"step": 342800, "time": 17333.37516093254, "episode/length": 210.0, "episode/score": 0.22122764060259215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22122764060259215}
{"step": 343112, "time": 17346.328298568726, "episode/length": 185.0, "episode/score": 0.19124555971939117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19124555971939117}
{"step": 343440, "time": 17360.45948433876, "episode/length": 164.0, "episode/score": 0.19103124656248838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19103124656248838}
{"step": 343656, "time": 17369.86180305481, "episode/length": 279.0, "episode/score": 0.30687666982885276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30687666982885276}
{"step": 344088, "time": 17389.232147455215, "episode/length": 234.0, "episode/score": 0.26625743573822547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26625743573822547}
{"step": 344248, "time": 17396.658722877502, "episode/length": 420.0, "episode/score": 0.41800479788071243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41800479788071243}
{"step": 344368, "time": 17402.981350183487, "episode/length": 258.0, "episode/score": 0.29643691131059313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29643691131059313}
{"step": 344504, "time": 17409.427594423294, "episode/length": 173.0, "episode/score": 0.17892468846184784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17892468846184784}
{"step": 344552, "time": 17412.716836452484, "episode/length": 218.0, "episode/score": 0.24877139611635357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24877139611635357}
{"step": 344920, "time": 17427.998512744904, "episode/length": 184.0, "episode/score": 0.22337301126754028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22337301126754028}
{"step": 344984, "time": 17431.932309389114, "episode/length": 165.0, "episode/score": 0.14796084841145785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14796084841145785}
{"step": 345416, "time": 17449.600265979767, "episode/length": 145.0, "episode/score": 0.15848030522465706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15848030522465706}
{"step": 345616, "time": 17458.77681660652, "episode/length": 190.0, "episode/score": 0.2013642021738633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2013642021738633}
{"step": 345688, "time": 17462.727227926254, "episode/length": 147.0, "episode/score": 0.15753329679682793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15753329679682793}
{"step": 345816, "time": 17469.111434459686, "episode/length": 157.0, "episode/score": 0.17155027497938136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17155027497938136}
{"step": 345992, "time": 17477.207401275635, "episode/length": 202.0, "episode/score": 0.20662199917751423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20662199917751423}
{"step": 346016, "time": 17479.717664718628, "episode/length": 436.0, "episode/score": 0.42568615619893535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42568615619893535}
{"step": 346040, "time": 17481.921564102173, "episode/length": 139.0, "episode/score": 0.15637353010424704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15637353010424704}
{"step": 346432, "time": 17498.637506961823, "episode/length": 180.0, "episode/score": 0.1960300662631198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1960300662631198}
{"step": 346888, "time": 17516.935901403427, "episode/length": 149.0, "episode/score": 0.16217208905618463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16217208905618463}
{"step": 347032, "time": 17523.817183732986, "episode/length": 123.0, "episode/score": 0.13862934152439266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13862934152439266}
{"step": 347120, "time": 17528.983597517014, "episode/length": 140.0, "episode/score": 0.11728200725883653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11728200725883653}
{"step": 347304, "time": 17537.1664788723, "episode/length": 185.0, "episode/score": 0.20130218516442255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20130218516442255}
{"step": 347360, "time": 17541.463135242462, "episode/length": 242.0, "episode/score": 0.26839880116313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26839880116313}
{"step": 347528, "time": 17549.012644529343, "episode/length": 136.0, "episode/score": 0.15367955352485296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15367955352485296}
{"step": 347536, "time": 17551.054219961166, "episode/length": 189.0, "episode/score": 0.19368497711457167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19368497711457167}
{"step": 348216, "time": 17577.896158456802, "episode/length": 84.0, "episode/score": 0.09463205261272378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09463205261272378}
{"step": 348400, "time": 17586.40849518776, "episode/length": 188.0, "episode/score": 0.20127413312911813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20127413312911813}
{"step": 348512, "time": 17592.270087003708, "episode/length": 173.0, "episode/score": 0.18935723011964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18935723011964}
{"step": 348552, "time": 17594.956753492355, "episode/length": 148.0, "episode/score": 0.17279824253637344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17279824253637344}
{"step": 348712, "time": 17602.48259472847, "episode/length": 147.0, "episode/score": 0.16462403273908421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16462403273908421}
{"step": 348816, "time": 17608.075870275497, "episode/length": 188.0, "episode/score": 0.2053552361758193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2053552361758193}
{"step": 348944, "time": 17614.297008275986, "episode/length": 238.0, "episode/score": 0.262320522670052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.262320522670052}
{"step": 349072, "time": 17620.80831670761, "episode/length": 431.0, "episode/score": 0.41870528020990605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41870528020990605}
{"step": 349560, "time": 17640.36826324463, "episode/length": 144.0, "episode/score": 0.1544824646989582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1544824646989582}
{"step": 349688, "time": 17646.65369796753, "episode/length": 141.0, "episode/score": 0.14133432597736828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14133432597736828}
{"step": 349728, "time": 17650.02459001541, "episode/length": 188.0, "episode/score": 0.19119882649829378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19119882649829378}
{"step": 349816, "time": 17654.671142339706, "episode/length": 137.0, "episode/score": 0.14003852813402773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14003852813402773}
{"step": 350064, "time": 17684.156177043915, "eval_episode/length": 135.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9558823529411765}
{"step": 350064, "time": 17686.308639526367, "eval_episode/length": 141.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 350064, "time": 17688.555481672287, "eval_episode/length": 149.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 350064, "time": 17690.64093518257, "eval_episode/length": 150.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 350064, "time": 17693.088979959488, "eval_episode/length": 158.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 350064, "time": 17694.835906744003, "eval_episode/length": 163.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 350064, "time": 17696.81836104393, "eval_episode/length": 175.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 350064, "time": 17702.301332712173, "eval_episode/length": 270.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.996309963099631}
{"step": 350320, "time": 17711.9344997406, "episode/length": 225.0, "episode/score": 0.21901293903283658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21901293903283658}
{"step": 350336, "time": 17714.085646629333, "episode/length": 173.0, "episode/score": 0.19153742914204486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19153742914204486}
{"step": 350504, "time": 17721.788974285126, "episode/length": 210.0, "episode/score": 0.2191105537895055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2191105537895055}
{"step": 350616, "time": 17727.451828718185, "episode/length": 192.0, "episode/score": 0.20997592485218775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20997592485218775}
{"step": 350816, "time": 17736.58932042122, "episode/length": 156.0, "episode/score": 0.16546734045550693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16546734045550693}
{"step": 350968, "time": 17744.302867650986, "episode/length": 154.0, "episode/score": 0.16959303360636113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16959303360636113}
{"step": 351056, "time": 17749.367931365967, "episode/length": 154.0, "episode/score": 0.17877598558698082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17877598558698082}
{"step": 351224, "time": 17756.91615343094, "episode/length": 110.0, "episode/score": 0.12979973276378587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12979973276378587}
{"step": 351400, "time": 17765.093390226364, "episode/length": 111.0, "episode/score": 0.12708361911791144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12708361911791144}
{"step": 351400, "time": 17765.102910995483, "episode/length": 213.0, "episode/score": 0.2438641733606346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2438641733606346}
{"step": 351792, "time": 17782.98819375038, "episode/length": 183.0, "episode/score": 0.2069564545963658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2069564545963658}
{"step": 352080, "time": 17795.139155864716, "episode/length": 182.0, "episode/score": 0.17827558910357766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17827558910357766}
{"step": 352224, "time": 17802.056883096695, "episode/length": 145.0, "episode/score": 0.14057031210541027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14057031210541027}
{"step": 352232, "time": 17803.62105679512, "episode/length": 176.0, "episode/score": 0.17350807863476803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17350807863476803}
{"step": 352480, "time": 17816.07364463806, "episode/length": 188.0, "episode/score": 0.19335349166794913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19335349166794913}
{"step": 352512, "time": 17818.78245663643, "episode/length": 160.0, "episode/score": 0.18370668681018287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18370668681018287}
{"step": 352672, "time": 17826.29619693756, "episode/length": 158.0, "episode/score": 0.1763100840671541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1763100840671541}
{"step": 353248, "time": 17849.34414792061, "episode/length": 145.0, "episode/score": 0.1652865576907061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1652865576907061}
{"step": 353312, "time": 17853.2813000679, "episode/length": 238.0, "episode/score": 0.2566419220675016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2566419220675016}
{"step": 353664, "time": 17867.92031979561, "episode/length": 179.0, "episode/score": 0.19599314199695073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19599314199695073}
{"step": 353664, "time": 17867.92746090889, "episode/length": 147.0, "episode/score": 0.16524768540693913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16524768540693913}
{"step": 353688, "time": 17871.87458562851, "episode/length": 181.0, "episode/score": 0.18158766272608773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18158766272608773}
{"step": 353896, "time": 17881.285672187805, "episode/length": 152.0, "episode/score": 0.14823603300646937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14823603300646937}
{"step": 354360, "time": 17900.21609544754, "episode/length": 138.0, "episode/score": 0.12820579559411271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12820579559411271}
{"step": 354584, "time": 17910.065356492996, "episode/length": 114.0, "episode/score": 0.1209018412637306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1209018412637306}
{"step": 354608, "time": 17912.57384967804, "episode/length": 161.0, "episode/score": 0.15484422609188186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15484422609188186}
{"step": 354688, "time": 17917.110092639923, "episode/length": 361.0, "episode/score": 0.38805509039593744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.38805509039593744}
{"step": 355032, "time": 17931.267770051956, "episode/length": 167.0, "episode/score": 0.17795306535936106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17795306535936106}
{"step": 355176, "time": 17938.251566886902, "episode/length": 159.0, "episode/score": 0.19060690951482684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19060690951482684}
{"step": 355304, "time": 17945.013805627823, "episode/length": 348.0, "episode/score": 0.36901357442275184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.36901357442275184}
{"step": 355416, "time": 17951.547736883163, "episode/length": 218.0, "episode/score": 0.25102736084772914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25102736084772914}
{"step": 355736, "time": 17965.012220144272, "episode/length": 171.0, "episode/score": 0.1830889711591226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1830889711591226}
{"step": 356128, "time": 17981.381327867508, "episode/length": 102.0, "episode/score": 0.11327385089953168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11327385089953168}
{"step": 356176, "time": 17984.60656929016, "episode/length": 185.0, "episode/score": 0.1639618435401644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1639618435401644}
{"step": 356312, "time": 17990.958610773087, "episode/length": 141.0, "episode/score": 0.13370951079832594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13370951079832594}
{"step": 356336, "time": 17993.56108045578, "episode/length": 162.0, "episode/score": 0.16615091851053876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16615091851053876}
{"step": 356424, "time": 17998.065556049347, "episode/length": 229.0, "episode/score": 0.23860612726093677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23860612726093677}
{"step": 356464, "time": 18001.33620405197, "episode/length": 231.0, "episode/score": 0.22842765034238255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22842765034238255}
{"step": 356992, "time": 18022.394768238068, "episode/length": 196.0, "episode/score": 0.22047261667557905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22047261667557905}
{"step": 357424, "time": 18040.284364700317, "episode/length": 155.0, "episode/score": 0.14264810115673754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14264810115673754}
{"step": 357496, "time": 18044.23010277748, "episode/length": 147.0, "episode/score": 0.15359432476907386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15359432476907386}
{"step": 357744, "time": 18055.139767885208, "episode/length": 250.0, "episode/score": 0.254960570365256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.254960570365256}
{"step": 357752, "time": 18056.737268924713, "episode/length": 160.0, "episode/score": 0.1704863352515531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1704863352515531}
{"step": 358024, "time": 18068.436707258224, "episode/length": 210.0, "episode/score": 0.2141259687978163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2141259687978163}
{"step": 358184, "time": 18075.850006341934, "episode/length": 148.0, "episode/score": 0.16383016404324735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16383016404324735}
{"step": 358560, "time": 18091.59431385994, "episode/length": 100.0, "episode/score": 0.12276315526105464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12276315526105464}
{"step": 358680, "time": 18097.325381040573, "episode/length": 147.0, "episode/score": 0.14429270229629765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14429270229629765}
{"step": 358712, "time": 18099.982813358307, "episode/length": 160.0, "episode/score": 0.15671228630708356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15671228630708356}
{"step": 358904, "time": 18108.569523096085, "episode/length": 42.0, "episode/score": 0.049999999115243554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049999999115243554}
{"step": 359320, "time": 18125.547787427902, "episode/length": 196.0, "episode/score": 0.2022975501149631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2022975501149631}
{"step": 359344, "time": 18128.22451043129, "episode/length": 164.0, "episode/score": 0.15984874172227137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15984874172227137}
{"step": 359448, "time": 18133.429277420044, "episode/length": 157.0, "episode/score": 0.16319601884879376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16319601884879376}
{"step": 359448, "time": 18133.44291138649, "episode/length": 414.0, "episode/score": 0.3915495050118807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3915495050118807}
{"step": 359656, "time": 18144.4281873703, "episode/length": 403.0, "episode/score": 0.44447085031470124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44447085031470124}
{"step": 359968, "time": 18157.8038687706, "episode/length": 160.0, "episode/score": 0.15578428182743664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15578428182743664}
{"step": 360048, "time": 18178.389746427536, "eval_episode/length": 88.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9325842696629213}
{"step": 360048, "time": 18182.1352622509, "eval_episode/length": 141.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 360048, "time": 18183.599231004715, "eval_episode/length": 142.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.993006993006993}
{"step": 360048, "time": 18185.47712278366, "eval_episode/length": 152.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 360048, "time": 18187.11919260025, "eval_episode/length": 153.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 360048, "time": 18188.88690137863, "eval_episode/length": 158.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 360048, "time": 18190.732920646667, "eval_episode/length": 166.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 360048, "time": 18197.397085905075, "eval_episode/length": 200.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 360112, "time": 18199.818296194077, "episode/length": 150.0, "episode/score": 0.1593022032038789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1593022032038789}
{"step": 360552, "time": 18219.001270771027, "episode/length": 137.0, "episode/score": 0.13359818376738986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13359818376738986}
{"step": 360640, "time": 18224.09640431404, "episode/length": 164.0, "episode/score": 0.16170936008393255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16170936008393255}
{"step": 360816, "time": 18232.14801454544, "episode/length": 183.0, "episode/score": 0.2047163910483505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2047163910483505}
{"step": 360976, "time": 18239.64321565628, "episode/length": 164.0, "episode/score": 0.17013417373937045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17013417373937045}
{"step": 361120, "time": 18246.508303642273, "episode/length": 208.0, "episode/score": 0.2356495450148941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2356495450148941}
{"step": 361144, "time": 18248.87748003006, "episode/length": 146.0, "episode/score": 0.15093148932783151, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15093148932783151}
{"step": 361328, "time": 18257.458292007446, "episode/length": 326.0, "episode/score": 0.34267457832675063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34267457832675063}
{"step": 361520, "time": 18266.18835067749, "episode/length": 175.0, "episode/score": 0.1907928994323811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1907928994323811}
{"step": 361904, "time": 18282.25000500679, "episode/length": 168.0, "episode/score": 0.1756895092976265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1756895092976265}
{"step": 362008, "time": 18287.787286281586, "episode/length": 128.0, "episode/score": 0.15479708651082547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15479708651082547}
{"step": 362224, "time": 18298.34487247467, "episode/length": 137.0, "episode/score": 0.13275071107545955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13275071107545955}
{"step": 362336, "time": 18304.55731678009, "episode/length": 148.0, "episode/score": 0.1680311613667982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1680311613667982}
{"step": 362664, "time": 18318.246576547623, "episode/length": 252.0, "episode/score": 0.2518750858457679, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2518750858457679}
{"step": 362729, "time": 18323.134930849075, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.723533024863591, "train/action_min": 0.0, "train/action_std": 4.545117018714784, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008279420365209855, "train/actor_opt_grad_steps": 21945.0, "train/actor_opt_loss": -5.474599648326162, "train/adv_mag": 0.18383425338164208, "train/adv_max": 0.12315728805131382, "train/adv_mean": 0.0002786901166072788, "train/adv_min": -0.18217147573355644, "train/adv_std": 0.01346703776941886, "train/cont_avg": 0.9945048983134921, "train/cont_loss_mean": 0.0003284579098617325, "train/cont_loss_std": 0.009593227724612989, "train/cont_neg_acc": 0.9887251205860622, "train/cont_neg_loss": 0.04684222509240499, "train/cont_pos_acc": 0.999976591931449, "train/cont_pos_loss": 0.00010696614400431927, "train/cont_pred": 0.994527165378843, "train/cont_rate": 0.9945048983134921, "train/dyn_loss_mean": 12.286964847928001, "train/dyn_loss_std": 8.42557874936906, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.17244392045078769, "train/extr_critic_critic_opt_grad_steps": 21945.0, "train/extr_critic_critic_opt_loss": 11471.0437515501, "train/extr_critic_mag": 0.2797397914386931, "train/extr_critic_max": 0.2797397914386931, "train/extr_critic_mean": 0.219188430716121, "train/extr_critic_min": 0.00196993350982666, "train/extr_critic_std": 0.06405235087824246, "train/extr_return_normed_mag": 0.2259635967867715, "train/extr_return_normed_max": 0.2259635967867715, "train/extr_return_normed_mean": 0.1654900945131741, "train/extr_return_normed_min": -0.052974442315716595, "train/extr_return_normed_std": 0.06554606488891064, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.27994059925041503, "train/extr_return_raw_max": 0.27994059925041503, "train/extr_return_raw_mean": 0.21946709946034446, "train/extr_return_raw_min": 0.0010025605322822693, "train/extr_return_raw_std": 0.06554606497760802, "train/extr_reward_mag": 0.0013253253603738452, "train/extr_reward_max": 0.0013253253603738452, "train/extr_reward_mean": 0.0010965059553864338, "train/extr_reward_min": 9.710826571025545e-06, "train/extr_reward_std": 0.0002344980755532604, "train/image_loss_mean": 6.488743835025364, "train/image_loss_std": 10.88620252457876, "train/model_loss_mean": 13.900926491570852, "train/model_loss_std": 14.424433465987917, "train/model_opt_grad_norm": 62.270527839660645, "train/model_opt_grad_steps": 21923.222222222223, "train/model_opt_loss": 18781.108754960318, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1349.2063492063492, "train/policy_entropy_mag": 2.7565357590478565, "train/policy_entropy_max": 2.7565357590478565, "train/policy_entropy_mean": 2.015374869581253, "train/policy_entropy_min": 0.08222765440032595, "train/policy_entropy_std": 0.5727855350290026, "train/policy_logprob_mag": 7.4367692394862095, "train/policy_logprob_max": -0.00985132067626904, "train/policy_logprob_mean": -2.015675992246658, "train/policy_logprob_min": -7.4367692394862095, "train/policy_logprob_std": 1.2000837344971915, "train/policy_randomness_mag": 0.9729361534118652, "train/policy_randomness_max": 0.9729361534118652, "train/policy_randomness_mean": 0.711338883827603, "train/policy_randomness_min": 0.02902275353433594, "train/policy_randomness_std": 0.20216815835899776, "train/post_ent_mag": 57.97760866558741, "train/post_ent_max": 57.97760866558741, "train/post_ent_mean": 39.780368411351766, "train/post_ent_min": 20.919850500803147, "train/post_ent_std": 6.876927746666802, "train/prior_ent_mag": 67.9357053363134, "train/prior_ent_max": 67.9357053363134, "train/prior_ent_mean": 52.227400764586434, "train/prior_ent_min": 28.824199176969984, "train/prior_ent_std": 6.022711401893979, "train/rep_loss_mean": 12.286964847928001, "train/rep_loss_std": 8.42557874936906, "train/reward_avg": 0.0010495750688105112, "train/reward_loss_mean": 0.039675378669348976, "train/reward_loss_std": 0.011803586752937427, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012939174969991047, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039675378817177955, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010507734481333976, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.0626167969725957, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.485981308411215, "train_stats/max_log_achievement_collect_sapling": 0.48598130841121495, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.5420560747663551, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.009345794392523364, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.2803738317757009, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.056074766355140186, "train_stats/max_log_achievement_wake_up": 0.4392523364485981, "train_stats/mean_log_entropy": 2.1428551584760718, "eval_stats/sum_log_reward": 1.0374999875202775, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 1.3125, "eval_stats/max_log_achievement_collect_sapling": 0.9375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.2050980987842195e-06, "report/cont_loss_std": 3.60789053956978e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.19398628664203e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.8924126834463095e-06, "report/cont_pred": 0.9960922598838806, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.280725479125977, "report/dyn_loss_std": 8.7940092086792, "report/image_loss_mean": 6.399847030639648, "report/image_loss_std": 13.195239067077637, "report/model_loss_mean": 13.207042694091797, "report/model_loss_std": 16.975061416625977, "report/post_ent_mag": 61.468379974365234, "report/post_ent_max": 61.468379974365234, "report/post_ent_mean": 40.64983367919922, "report/post_ent_min": 21.078731536865234, "report/post_ent_std": 7.147274017333984, "report/prior_ent_mag": 67.89378356933594, "report/prior_ent_max": 67.89378356933594, "report/prior_ent_mean": 51.863460540771484, "report/prior_ent_min": 28.464794158935547, "report/prior_ent_std": 6.168514251708984, "report/rep_loss_mean": 11.280725479125977, "report/rep_loss_std": 8.7940092086792, "report/reward_avg": 0.0010250513441860676, "report/reward_loss_mean": 0.03875826299190521, "report/reward_loss_std": 0.01302218809723854, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012803077697753906, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03875826299190521, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010158427758142352, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 8.84627879713662e-05, "eval/cont_loss_std": 0.002667087595909834, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 9.998409950640053e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.844023977871984e-05, "eval/cont_pred": 0.9979623556137085, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.14047622680664, "eval/dyn_loss_std": 10.92179012298584, "eval/image_loss_mean": 18.461488723754883, "eval/image_loss_std": 24.596208572387695, "eval/model_loss_mean": 29.178165435791016, "eval/model_loss_std": 28.95275115966797, "eval/post_ent_mag": 54.607696533203125, "eval/post_ent_max": 54.607696533203125, "eval/post_ent_mean": 38.06428527832031, "eval/post_ent_min": 20.401987075805664, "eval/post_ent_std": 6.049953460693359, "eval/prior_ent_mag": 67.89378356933594, "eval/prior_ent_max": 67.89378356933594, "eval/prior_ent_mean": 51.447784423828125, "eval/prior_ent_min": 22.952537536621094, "eval/prior_ent_std": 7.191040515899658, "eval/rep_loss_mean": 17.14047622680664, "eval/rep_loss_std": 10.92179012298584, "eval/reward_avg": 0.01162109337747097, "eval/reward_loss_mean": 0.43230366706848145, "eval/reward_loss_std": 2.8321096897125244, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012606382369995117, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.18117143213748932, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 19.962665557861328, "eval/reward_pred": 0.0009653186425566673, "eval/reward_rate": 0.0126953125, "replay/size": 362225.0, "replay/inserts": 20208.0, "replay/samples": 20208.0, "replay/insert_wait_avg": 1.3076329363402354e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.91708250793312e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 71960.0, "eval_replay/inserts": 4488.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1984146002567175e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1714198589325, "timer/env.step_count": 2526.0, "timer/env.step_total": 229.52988696098328, "timer/env.step_frac": 0.22949054772366614, "timer/env.step_avg": 0.09086693862271705, "timer/env.step_min": 0.02237224578857422, "timer/env.step_max": 3.2864460945129395, "timer/replay._sample_count": 20208.0, "timer/replay._sample_total": 9.868775367736816, "timer/replay._sample_frac": 0.009867083953597415, "timer/replay._sample_avg": 0.0004883598261944188, "timer/replay._sample_min": 0.0003566741943359375, "timer/replay._sample_max": 0.020225048065185547, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3087.0, "timer/agent.policy_total": 49.010406255722046, "timer/agent.policy_frac": 0.049002006338708055, "timer/agent.policy_avg": 0.01587638686612311, "timer/agent.policy_min": 0.009564876556396484, "timer/agent.policy_max": 0.09801363945007324, "timer/dataset_train_count": 1263.0, "timer/dataset_train_total": 0.13556766510009766, "timer/dataset_train_frac": 0.00013554443009301202, "timer/dataset_train_avg": 0.00010733781876492293, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.00023365020751953125, "timer/agent.train_count": 1263.0, "timer/agent.train_total": 569.0815556049347, "timer/agent.train_frac": 0.5689840204444153, "timer/agent.train_avg": 0.4505792205898137, "timer/agent.train_min": 0.4370872974395752, "timer/agent.train_max": 1.0752613544464111, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47316527366638184, "timer/agent.report_frac": 0.000473084177643387, "timer/agent.report_avg": 0.23658263683319092, "timer/agent.report_min": 0.22393250465393066, "timer/agent.report_max": 0.24923276901245117, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7175059672682553e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 20.204274527627792}
{"step": 362808, "time": 18325.94512963295, "episode/length": 184.0, "episode/score": 0.18978892058339625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18978892058339625}
{"step": 362944, "time": 18332.618767499924, "episode/length": 265.0, "episode/score": 0.2629726207269414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2629726207269414}
{"step": 363016, "time": 18336.660978078842, "episode/length": 138.0, "episode/score": 0.1236477282091073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1236477282091073}
{"step": 363208, "time": 18345.426624536514, "episode/length": 210.0, "episode/score": 0.21376686743815299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21376686743815299}
{"step": 363336, "time": 18351.734979391098, "episode/length": 165.0, "episode/score": 0.17309057684724394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17309057684724394}
{"step": 364008, "time": 18378.284288167953, "episode/length": 149.0, "episode/score": 0.15865739888522512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15865739888522512}
{"step": 364024, "time": 18380.379085302353, "episode/length": 224.0, "episode/score": 0.2185152049523822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2185152049523822}
{"step": 364136, "time": 18386.17715549469, "episode/length": 183.0, "episode/score": 0.18305695042317893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18305695042317893}
{"step": 364144, "time": 18388.182321071625, "episode/length": 225.0, "episode/score": 0.234244867110192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.234244867110192}
{"step": 364400, "time": 18399.281193733215, "episode/length": 181.0, "episode/score": 0.15847759895495983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15847759895495983}
{"step": 364480, "time": 18403.877358436584, "episode/length": 158.0, "episode/score": 0.17914979832130484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17914979832130484}
{"step": 364776, "time": 18416.21036028862, "episode/length": 219.0, "episode/score": 0.24766206998083362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24766206998083362}
{"step": 365000, "time": 18426.142538785934, "episode/length": 207.0, "episode/score": 0.21676094831491355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21676094831491355}
{"step": 365280, "time": 18438.484359264374, "episode/length": 156.0, "episode/score": 0.1716924347274471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1716924347274471}
{"step": 365304, "time": 18441.233083724976, "episode/length": 144.0, "episode/score": 0.14314898212978733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14314898212978733}
{"step": 365528, "time": 18451.673310518265, "episode/length": 173.0, "episode/score": 0.16485937301331433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16485937301331433}
{"step": 365968, "time": 18470.01498889923, "episode/length": 185.0, "episode/score": 0.18682748668652494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18682748668652494}
{"step": 365992, "time": 18472.218044757843, "episode/length": 247.0, "episode/score": 0.28950567475840217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28950567475840217}
{"step": 366008, "time": 18474.32051730156, "episode/length": 200.0, "episode/score": 0.20767901791987242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20767901791987242}
{"step": 366264, "time": 18486.074817419052, "episode/length": 185.0, "episode/score": 0.2186588690165081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2186588690165081}
{"step": 366408, "time": 18493.18236875534, "episode/length": 140.0, "episode/score": 0.15438180486671627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15438180486671627}
{"step": 366680, "time": 18504.892567634583, "episode/length": 209.0, "episode/score": 0.23722556559732766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23722556559732766}
{"step": 366752, "time": 18509.300871133804, "episode/length": 152.0, "episode/score": 0.17230371362529695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17230371362529695}
{"step": 366768, "time": 18511.45062661171, "episode/length": 182.0, "episode/score": 0.1817441268976836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1817441268976836}
{"step": 367208, "time": 18529.089173078537, "episode/length": 149.0, "episode/score": 0.15623704105382785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15623704105382785}
{"step": 367368, "time": 18536.42272925377, "episode/length": 171.0, "episode/score": 0.16093820827882155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16093820827882155}
{"step": 367704, "time": 18550.545418024063, "episode/length": 216.0, "episode/score": 0.2297339006072434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2297339006072434}
{"step": 367768, "time": 18554.444729804993, "episode/length": 187.0, "episode/score": 0.1819795561623323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1819795561623323}
{"step": 367840, "time": 18558.91491293907, "episode/length": 178.0, "episode/score": 0.20766832417757541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20766832417757541}
{"step": 367872, "time": 18561.731776714325, "episode/length": 148.0, "episode/score": 0.15154867850833398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15154867850833398}
{"step": 367936, "time": 18565.587412834167, "episode/length": 147.0, "episode/score": 0.15381435510425945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15381435510425945}
{"step": 368424, "time": 18585.229013442993, "episode/length": 151.0, "episode/score": 0.1387675909727477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1387675909727477}
{"step": 368600, "time": 18593.94642186165, "episode/length": 153.0, "episode/score": 0.15344846362768294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15344846362768294}
{"step": 368880, "time": 18607.535701036453, "episode/length": 263.0, "episode/score": 0.28552177131859935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28552177131859935}
{"step": 368896, "time": 18609.54227256775, "episode/length": 140.0, "episode/score": 0.1347375172563261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1347375172563261}
{"step": 368912, "time": 18611.717445373535, "episode/length": 38.0, "episode/score": 0.04280833264783723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04280833264783723}
{"step": 368960, "time": 18615.025029182434, "episode/length": 156.0, "episode/score": 0.16741641082626302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16741641082626302}
{"step": 369048, "time": 18619.5612988472, "episode/length": 146.0, "episode/score": 0.14466448482107808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14466448482107808}
{"step": 369392, "time": 18634.263377666473, "episode/length": 181.0, "episode/score": 0.19831871413771296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19831871413771296}
{"step": 369464, "time": 18638.232704162598, "episode/length": 129.0, "episode/score": 0.1426242079542135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1426242079542135}
{"step": 369544, "time": 18642.712198972702, "episode/length": 212.0, "episode/score": 0.2299931972174818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2299931972174818}
{"step": 370032, "time": 18680.91873526573, "eval_episode/length": 140.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9574468085106383}
{"step": 370032, "time": 18682.486478567123, "eval_episode/length": 143.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 370032, "time": 18684.424424409866, "eval_episode/length": 153.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 370032, "time": 18689.91010117531, "eval_episode/length": 217.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.981651376146789}
{"step": 370032, "time": 18691.533770799637, "eval_episode/length": 220.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9728506787330317}
{"step": 370032, "time": 18693.271022319794, "eval_episode/length": 226.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9823788546255506}
{"step": 370032, "time": 18695.2528693676, "eval_episode/length": 236.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 370032, "time": 18697.326584339142, "eval_episode/length": 245.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.983739837398374}
{"step": 370280, "time": 18706.616031885147, "episode/length": 170.0, "episode/score": 0.19125186555447726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19125186555447726}
{"step": 370328, "time": 18710.449679851532, "episode/length": 178.0, "episode/score": 0.1637797977309674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1637797977309674}
{"step": 370448, "time": 18717.242309570312, "episode/length": 195.0, "episode/score": 0.2051556120022724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2051556120022724}
{"step": 370456, "time": 18718.869286060333, "episode/length": 175.0, "episode/score": 0.18803326169017964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18803326169017964}
{"step": 370592, "time": 18725.641376256943, "episode/length": 203.0, "episode/score": 0.20325884424983087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20325884424983087}
{"step": 370632, "time": 18728.449590444565, "episode/length": 43.0, "episode/score": 0.04924999922513962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04924999922513962}
{"step": 371272, "time": 18753.879400014877, "episode/length": 215.0, "episode/score": 0.2277814768240205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2277814768240205}
{"step": 371352, "time": 18758.507578849792, "episode/length": 244.0, "episode/score": 0.26450251675942127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26450251675942127}
{"step": 371424, "time": 18763.000765800476, "episode/length": 244.0, "episode/score": 0.26256280348570726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26256280348570726}
{"step": 371720, "time": 18775.30644583702, "episode/length": 140.0, "episode/score": 0.15515780397618073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15515780397618073}
{"step": 371808, "time": 18780.46023273468, "episode/length": 146.0, "episode/score": 0.14754175803318503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14754175803318503}
{"step": 372096, "time": 18792.763419389725, "episode/length": 205.0, "episode/score": 0.191646325455622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.191646325455622}
{"step": 372280, "time": 18800.867023706436, "episode/length": 243.0, "episode/score": 0.2838065408077455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2838065408077455}
{"step": 372672, "time": 18817.255814552307, "episode/length": 174.0, "episode/score": 0.16248148345221125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16248148345221125}
{"step": 372696, "time": 18819.374079942703, "episode/length": 158.0, "episode/score": 0.17725080167474516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17725080167474516}
{"step": 372960, "time": 18830.87712788582, "episode/length": 154.0, "episode/score": 0.1634193737691021, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1634193737691021}
{"step": 372968, "time": 18832.401907444, "episode/length": 201.0, "episode/score": 0.2275651356058006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2275651356058006}
{"step": 373520, "time": 18854.61695623398, "episode/length": 177.0, "episode/score": 0.1780855785800668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1780855785800668}
{"step": 373824, "time": 18867.292361021042, "episode/length": 143.0, "episode/score": 0.14998611377450288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14998611377450288}
{"step": 373848, "time": 18869.46726179123, "episode/length": 254.0, "episode/score": 0.2863953225178193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2863953225178193}
{"step": 373936, "time": 18874.55349469185, "episode/length": 206.0, "episode/score": 0.20217208750682403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20217208750682403}
{"step": 374024, "time": 18879.293484210968, "episode/length": 445.0, "episode/score": 0.43856301172263557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.43856301172263557}
{"step": 374360, "time": 18893.302600622177, "episode/length": 66.0, "episode/score": 0.07260772298695883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07260772298695883}
{"step": 374368, "time": 18895.326984405518, "episode/length": 174.0, "episode/score": 0.17671015515952604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17671015515952604}
{"step": 374456, "time": 18899.930527210236, "episode/length": 186.0, "episode/score": 0.16815944779546044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16815944779546044}
{"step": 374536, "time": 18904.91736650467, "episode/length": 229.0, "episode/score": 0.22377231424434285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22377231424434285}
{"step": 374704, "time": 18913.053617954254, "episode/length": 147.0, "episode/score": 0.15721487061546213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15721487061546213}
{"step": 375016, "time": 18925.980160951614, "episode/length": 123.0, "episode/score": 0.13959241662723798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13959241662723798}
{"step": 375016, "time": 18925.988362312317, "episode/length": 145.0, "episode/score": 0.1616015079839599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1616015079839599}
{"step": 375624, "time": 18952.14028954506, "episode/length": 210.0, "episode/score": 0.2355180831968937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2355180831968937}
{"step": 375696, "time": 18957.13035273552, "episode/length": 154.0, "episode/score": 0.18067223129264676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18067223129264676}
{"step": 375744, "time": 18960.41771364212, "episode/length": 172.0, "episode/score": 0.17255846485250004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17255846485250004}
{"step": 375776, "time": 18963.12859416008, "episode/length": 175.0, "episode/score": 0.179336960953151, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.179336960953151}
{"step": 375784, "time": 18964.61838531494, "episode/length": 155.0, "episode/score": 0.15097785885427584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15097785885427584}
{"step": 375816, "time": 18967.48606991768, "episode/length": 99.0, "episode/score": 0.12154166417894885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12154166417894885}
{"step": 376088, "time": 18979.17116713524, "episode/length": 172.0, "episode/score": 0.20282705012959923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20282705012959923}
{"step": 376376, "time": 18991.422684907913, "episode/length": 169.0, "episode/score": 0.18339708182838876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18339708182838876}
{"step": 377000, "time": 19017.57976937294, "episode/length": 162.0, "episode/score": 0.17383617959194453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17383617959194453}
{"step": 377016, "time": 19019.714511871338, "episode/length": 173.0, "episode/score": 0.18007245950502693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18007245950502693}
{"step": 377056, "time": 19022.920350313187, "episode/length": 159.0, "episode/score": 0.1448340860169992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1448340860169992}
{"step": 377080, "time": 19025.18341255188, "episode/length": 166.0, "episode/score": 0.1452259975967536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1452259975967536}
{"step": 377216, "time": 19032.031386852264, "episode/length": 178.0, "episode/score": 0.18573551055033022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18573551055033022}
{"step": 377336, "time": 19037.82528567314, "episode/length": 155.0, "episode/score": 0.16591355305990874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16591355305990874}
{"step": 377472, "time": 19044.611586093903, "episode/length": 206.0, "episode/score": 0.22937230640172857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22937230640172857}
{"step": 377984, "time": 19065.13835167885, "episode/length": 200.0, "episode/score": 0.18614717909122191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18614717909122191}
{"step": 378400, "time": 19082.118632793427, "episode/length": 174.0, "episode/score": 0.20009707459303172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20009707459303172}
{"step": 378440, "time": 19085.204429149628, "episode/length": 177.0, "episode/score": 0.1952131837952038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1952131837952038}
{"step": 378568, "time": 19091.663281440735, "episode/length": 185.0, "episode/score": 0.179386691511354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.179386691511354}
{"step": 378592, "time": 19094.82906961441, "episode/length": 171.0, "episode/score": 0.18707031635676685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18707031635676685}
{"step": 378656, "time": 19099.213971853256, "episode/length": 164.0, "episode/score": 0.1833240319479046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1833240319479046}
{"step": 378752, "time": 19104.18147969246, "episode/length": 159.0, "episode/score": 0.1780689386459926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1780689386459926}
{"step": 378784, "time": 19106.783630609512, "episode/length": 215.0, "episode/score": 0.2315822995083181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2315822995083181}
{"step": 379120, "time": 19121.033057451248, "episode/length": 141.0, "episode/score": 0.1306443297721671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1306443297721671}
{"step": 379696, "time": 19144.52540898323, "episode/length": 156.0, "episode/score": 0.15576632107467958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15576632107467958}
{"step": 379784, "time": 19149.282361745834, "episode/length": 172.0, "episode/score": 0.20523842184775276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20523842184775276}
{"step": 379808, "time": 19151.996191978455, "episode/length": 143.0, "episode/score": 0.13419470724102212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13419470724102212}
{"step": 379896, "time": 19156.51182460785, "episode/length": 165.0, "episode/score": 0.1768064061975565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1768064061975565}
{"step": 380016, "time": 19180.525839805603, "eval_episode/length": 133.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9925373134328358}
{"step": 380016, "time": 19182.914288520813, "eval_episode/length": 153.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 380016, "time": 19184.613042354584, "eval_episode/length": 157.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 380016, "time": 19186.906678676605, "eval_episode/length": 174.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 380016, "time": 19189.057878017426, "eval_episode/length": 189.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 380016, "time": 19190.942821264267, "eval_episode/length": 198.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9698492462311558}
{"step": 380016, "time": 19193.906802892685, "eval_episode/length": 235.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 380016, "time": 19195.5439517498, "eval_episode/length": 239.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9958333333333333}
{"step": 380064, "time": 19197.329698562622, "episode/length": 183.0, "episode/score": 0.18780128852131384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18780128852131384}
{"step": 380288, "time": 19207.206630945206, "episode/length": 191.0, "episode/score": 0.22204755851407754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22204755851407754}
{"step": 380568, "time": 19219.02436900139, "episode/length": 180.0, "episode/score": 0.18937085176594337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18937085176594337}
{"step": 380648, "time": 19224.056617975235, "episode/length": 232.0, "episode/score": 0.2597896668485191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2597896668485191}
{"step": 380968, "time": 19237.858230113983, "episode/length": 147.0, "episode/score": 0.16187596880104138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16187596880104138}
{"step": 380984, "time": 19239.83644270897, "episode/length": 146.0, "episode/score": 0.15490168975725283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15490168975725283}
{"step": 381272, "time": 19252.06186556816, "episode/length": 171.0, "episode/score": 0.1793567751806222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1793567751806222}
{"step": 381688, "time": 19269.391003370285, "episode/length": 174.0, "episode/score": 0.16619612901558867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16619612901558867}
{"step": 381744, "time": 19273.213218450546, "episode/length": 136.0, "episode/score": 0.15760226976999547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15760226976999547}
{"step": 381920, "time": 19281.27203798294, "episode/length": 231.0, "episode/score": 0.2320659718996012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2320659718996012}
{"step": 382104, "time": 19289.42488527298, "episode/length": 191.0, "episode/score": 0.21468673527988358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21468673527988358}
{"step": 382200, "time": 19294.493146657944, "episode/length": 153.0, "episode/score": 0.15140147165038798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15140147165038798}
{"step": 382408, "time": 19303.80171728134, "episode/length": 177.0, "episode/score": 0.18261103972145065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18261103972145065}
{"step": 382592, "time": 19312.359393835068, "episode/length": 164.0, "episode/score": 0.18192828974611075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18192828974611075}
{"step": 382624, "time": 19315.016697883606, "episode/length": 116.0, "episode/score": 0.12449526692330437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12449526692330437}
{"step": 382793, "time": 19323.629620552063, "train_stats/sum_log_reward": 1.471681386232376, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.0, "train_stats/max_log_achievement_collect_sapling": 0.6814159292035398, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.9203539823008849, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.008849557522123894, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.008849557522123894, "train_stats/max_log_achievement_place_plant": 0.4778761061946903, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.1504424778761062, "train_stats/max_log_achievement_wake_up": 0.37168141592920356, "train_stats/mean_log_entropy": 2.1669082789294487, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.0382099609375, "train/action_min": 0.0, "train/action_std": 4.6212286987304685, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008054721977561713, "train/actor_opt_grad_steps": 23200.0, "train/actor_opt_loss": -7.277736265696586, "train/adv_mag": 0.1828424096107483, "train/adv_max": 0.12360602992773057, "train/adv_mean": 0.00016540165641345083, "train/adv_min": -0.18261418783664704, "train/adv_std": 0.013637723695486784, "train/cont_avg": 0.9945703125, "train/cont_loss_mean": 0.0002535783319424354, "train/cont_loss_std": 0.007251978609167054, "train/cont_neg_acc": 0.9946222224235535, "train/cont_neg_loss": 0.021208697463240243, "train/cont_pos_acc": 0.9999527845382691, "train/cont_pos_loss": 0.00011566291315637046, "train/cont_pred": 0.9945614981651306, "train/cont_rate": 0.9945703125, "train/dyn_loss_mean": 12.024815742492676, "train/dyn_loss_std": 8.447697895050048, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16450278553366662, "train/extr_critic_critic_opt_grad_steps": 23200.0, "train/extr_critic_critic_opt_loss": 11676.9845234375, "train/extr_critic_mag": 0.28128222274780273, "train/extr_critic_max": 0.28128222274780273, "train/extr_critic_mean": 0.22346560299396515, "train/extr_critic_min": 0.0014171037673950196, "train/extr_critic_std": 0.06124781686067581, "train/extr_return_normed_mag": 0.21670831727981568, "train/extr_return_normed_max": 0.21670831727981568, "train/extr_return_normed_mean": 0.1591974231004715, "train/extr_return_normed_min": -0.06345476552844048, "train/extr_return_normed_std": 0.06279910343885421, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2811417362689972, "train/extr_return_raw_max": 0.2811417362689972, "train/extr_return_raw_mean": 0.22363084626197816, "train/extr_return_raw_min": 0.0009786539077758789, "train/extr_return_raw_std": 0.0627991032898426, "train/extr_reward_mag": 0.0013330192565917968, "train/extr_reward_max": 0.0013330192565917968, "train/extr_reward_mean": 0.0010869145421311258, "train/extr_reward_min": 1.0141372680664063e-05, "train/extr_reward_std": 0.00024332880787551403, "train/image_loss_mean": 6.110881546020508, "train/image_loss_std": 10.48246481704712, "train/model_loss_mean": 13.365710762023927, "train/model_loss_std": 14.05504189300537, "train/model_opt_grad_norm": 60.326122802734375, "train/model_opt_grad_steps": 23176.408, "train/model_opt_loss": 11607.8457734375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 875.0, "train/policy_entropy_mag": 2.760274341583252, "train/policy_entropy_max": 2.760274341583252, "train/policy_entropy_mean": 2.0860481824874877, "train/policy_entropy_min": 0.08216723406314849, "train/policy_entropy_std": 0.5650637559890747, "train/policy_logprob_mag": 7.4371406364440915, "train/policy_logprob_max": -0.00984447829425335, "train/policy_logprob_mean": -2.086050004005432, "train/policy_logprob_min": -7.4371406364440915, "train/policy_logprob_std": 1.1646692638397216, "train/policy_randomness_mag": 0.9742557129859925, "train/policy_randomness_max": 0.9742557129859925, "train/policy_randomness_mean": 0.7362834630012512, "train/policy_randomness_min": 0.02900142775475979, "train/policy_randomness_std": 0.19944270837306977, "train/post_ent_mag": 58.49109997558594, "train/post_ent_max": 58.49109997558594, "train/post_ent_mean": 40.22123596191406, "train/post_ent_min": 20.888296798706055, "train/post_ent_std": 7.056476402282715, "train/prior_ent_mag": 68.02628295898438, "train/prior_ent_max": 68.02628295898438, "train/prior_ent_mean": 52.37066436767578, "train/prior_ent_min": 29.032999618530273, "train/prior_ent_std": 5.985813709259033, "train/rep_loss_mean": 12.024815742492676, "train/rep_loss_std": 8.447697895050048, "train/reward_avg": 0.0010500105596147479, "train/reward_loss_mean": 0.03968615865707398, "train/reward_loss_std": 0.011771540828049184, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012956619262695312, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039686158299446106, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010500276768580078, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.9749999581836164, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.75, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00013902851787861437, "report/cont_loss_std": 0.0039686886593699455, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.796809298568405e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00013965526886750013, "report/cont_pred": 0.9930332899093628, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.46604061126709, "report/dyn_loss_std": 8.966527938842773, "report/image_loss_mean": 6.5794572830200195, "report/image_loss_std": 8.4686861038208, "report/model_loss_mean": 14.7009859085083, "report/model_loss_std": 12.229683876037598, "report/post_ent_mag": 57.493934631347656, "report/post_ent_max": 57.493934631347656, "report/post_ent_mean": 39.14372253417969, "report/post_ent_min": 20.794960021972656, "report/post_ent_std": 6.8177924156188965, "report/prior_ent_mag": 67.67062377929688, "report/prior_ent_max": 67.67062377929688, "report/prior_ent_mean": 52.600929260253906, "report/prior_ent_min": 28.589630126953125, "report/prior_ent_std": 6.677145957946777, "report/rep_loss_mean": 13.46604061126709, "report/rep_loss_std": 8.966527938842773, "report/reward_avg": 0.0011122663272544742, "report/reward_loss_mean": 0.04176439344882965, "report/reward_loss_std": 0.010407110676169395, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013622045516967773, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04176439717411995, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0011004480766132474, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.5784967217769008e-06, "eval/cont_loss_std": 3.3340966183459386e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.000378358963644132, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.7140432002379384e-07, "eval/cont_pred": 0.9970710277557373, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.29341697692871, "eval/dyn_loss_std": 10.74758243560791, "eval/image_loss_mean": 13.947578430175781, "eval/image_loss_std": 20.774208068847656, "eval/model_loss_mean": 24.779090881347656, "eval/model_loss_std": 25.261215209960938, "eval/post_ent_mag": 56.40763854980469, "eval/post_ent_max": 56.40763854980469, "eval/post_ent_mean": 38.93633270263672, "eval/post_ent_min": 20.51129913330078, "eval/post_ent_std": 6.362826824188232, "eval/prior_ent_mag": 67.67062377929688, "eval/prior_ent_max": 67.67062377929688, "eval/prior_ent_mean": 52.708431243896484, "eval/prior_ent_min": 28.126873016357422, "eval/prior_ent_std": 5.755616188049316, "eval/rep_loss_mean": 17.29341697692871, "eval/rep_loss_std": 10.74758243560791, "eval/reward_avg": 0.00830078125, "eval/reward_loss_mean": 0.45546191930770874, "eval/reward_loss_std": 2.921114921569824, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012753009796142578, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.24286538362503052, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.033676147460938, "eval/reward_pred": 0.0009586709784343839, "eval/reward_rate": 0.0107421875, "replay/size": 382289.0, "replay/inserts": 20064.0, "replay/samples": 20064.0, "replay/insert_wait_avg": 1.338395205411044e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.018226904922315e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 75848.0, "eval_replay/inserts": 3888.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1768851260589473e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4808576107025, "timer/env.step_count": 2508.0, "timer/env.step_total": 242.3924810886383, "timer/env.step_frac": 0.24227598083936128, "timer/env.step_avg": 0.09664771973231193, "timer/env.step_min": 0.022090435028076172, "timer/env.step_max": 3.279284954071045, "timer/replay._sample_count": 20064.0, "timer/replay._sample_total": 9.763198852539062, "timer/replay._sample_frac": 0.009758506400467309, "timer/replay._sample_avg": 0.0004866028136233584, "timer/replay._sample_min": 0.0003809928894042969, "timer/replay._sample_max": 0.009685993194580078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2994.0, "timer/agent.policy_total": 48.71610426902771, "timer/agent.policy_frac": 0.04869269001844676, "timer/agent.policy_avg": 0.016271243910830898, "timer/agent.policy_min": 0.009649515151977539, "timer/agent.policy_max": 0.11654138565063477, "timer/dataset_train_count": 1254.0, "timer/dataset_train_total": 0.13811111450195312, "timer/dataset_train_frac": 0.00013804473464068374, "timer/dataset_train_avg": 0.00011013645494573614, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0006740093231201172, "timer/agent.train_count": 1254.0, "timer/agent.train_total": 561.0085003376007, "timer/agent.train_frac": 0.5607388647868513, "timer/agent.train_avg": 0.44737519963126055, "timer/agent.train_min": 0.43492722511291504, "timer/agent.train_max": 0.9756224155426025, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47931408882141113, "timer/agent.report_frac": 0.000479083717769558, "timer/agent.report_avg": 0.23965704441070557, "timer/agent.report_min": 0.23390603065490723, "timer/agent.report_max": 0.2454080581665039, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.740495871371121e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 20.054083104472582}
{"step": 382936, "time": 19328.8507335186, "episode/length": 148.0, "episode/score": 0.16976934317813175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16976934317813175}
{"step": 383280, "time": 19343.33460855484, "episode/length": 169.0, "episode/score": 0.18771980526389598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18771980526389598}
{"step": 383280, "time": 19343.347539663315, "episode/length": 447.0, "episode/score": 0.4259472032026679, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4259472032026679}
{"step": 383288, "time": 19346.62731051445, "episode/length": 147.0, "episode/score": 0.16079042342494176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16079042342494176}
{"step": 383728, "time": 19364.60830760002, "episode/length": 164.0, "episode/score": 0.17917268626842997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17917268626842997}
{"step": 383792, "time": 19368.54729127884, "episode/length": 149.0, "episode/score": 0.1458080194120157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1458080194120157}
{"step": 383888, "time": 19373.613752365112, "episode/length": 210.0, "episode/score": 0.21106737673312637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21106737673312637}
{"step": 383928, "time": 19376.37922525406, "episode/length": 162.0, "episode/score": 0.15365750165824466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15365750165824466}
{"step": 384064, "time": 19383.01114487648, "episode/length": 140.0, "episode/score": 0.14240401092865795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14240401092865795}
{"step": 384464, "time": 19399.45189833641, "episode/length": 49.0, "episode/score": 0.05723214187310077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05723214187310077}
{"step": 384536, "time": 19403.390123844147, "episode/length": 156.0, "episode/score": 0.17514441125945268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17514441125945268}
{"step": 385072, "time": 19426.451856851578, "episode/length": 223.0, "episode/score": 0.22621765689268614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22621765689268614}
{"step": 385104, "time": 19429.185863256454, "episode/length": 226.0, "episode/score": 0.25295635412317097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25295635412317097}
{"step": 385152, "time": 19432.458436012268, "episode/length": 177.0, "episode/score": 0.1891732132337438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1891732132337438}
{"step": 385344, "time": 19441.057943344116, "episode/length": 176.0, "episode/score": 0.18646177081336646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18646177081336646}
{"step": 385504, "time": 19448.693789482117, "episode/length": 213.0, "episode/score": 0.24399145116944965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24399145116944965}
{"step": 385592, "time": 19453.277549028397, "episode/length": 140.0, "episode/score": 0.14818761575384087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14818761575384087}
{"step": 385592, "time": 19453.2864818573, "episode/length": 212.0, "episode/score": 0.21386598473895901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21386598473895901}
{"step": 385856, "time": 19466.367125988007, "episode/length": 164.0, "episode/score": 0.1583335927857661, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1583335927857661}
{"step": 386264, "time": 19483.00696372986, "episode/length": 148.0, "episode/score": 0.14010626889512423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14010626889512423}
{"step": 386272, "time": 19484.99134850502, "episode/length": 145.0, "episode/score": 0.16512461626211916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16512461626211916}
{"step": 386896, "time": 19509.884674310684, "episode/length": 217.0, "episode/score": 0.23614883670552445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23614883670552445}
{"step": 386920, "time": 19512.03316783905, "episode/length": 165.0, "episode/score": 0.18226463354312727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18226463354312727}
{"step": 387048, "time": 19518.40342092514, "episode/length": 212.0, "episode/score": 0.2299328786323258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2299328786323258}
{"step": 387184, "time": 19525.22181224823, "episode/length": 165.0, "episode/score": 0.1735965668863173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1735965668863173}
{"step": 387416, "time": 19535.15421462059, "episode/length": 227.0, "episode/score": 0.2692088079822952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2692088079822952}
{"step": 387568, "time": 19542.567004680634, "episode/length": 161.0, "episode/score": 0.1780566461561648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1780566461561648}
{"step": 387616, "time": 19545.860861063004, "episode/length": 168.0, "episode/score": 0.16085488056569375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16085488056569375}
{"step": 387904, "time": 19558.07057929039, "episode/length": 106.0, "episode/score": 0.1251578257943038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1251578257943038}
{"step": 387960, "time": 19561.471779346466, "episode/length": 129.0, "episode/score": 0.1286824003284437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1286824003284437}
{"step": 388696, "time": 19590.523564338684, "episode/length": 188.0, "episode/score": 0.2096986606181872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2096986606181872}
{"step": 388760, "time": 19594.9215092659, "episode/length": 167.0, "episode/score": 0.15281536771772153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15281536771772153}
{"step": 388768, "time": 19597.50109052658, "episode/length": 233.0, "episode/score": 0.25819526826444417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25819526826444417}
{"step": 389016, "time": 19608.497373580933, "episode/length": 180.0, "episode/score": 0.1797994576140809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1797994576140809}
{"step": 389064, "time": 19611.797100543976, "episode/length": 444.0, "episode/score": 0.44505169835588276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44505169835588276}
{"step": 389280, "time": 19621.60158085823, "episode/length": 171.0, "episode/score": 0.17582089304755755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17582089304755755}
{"step": 389320, "time": 19624.262051343918, "episode/length": 169.0, "episode/score": 0.17136963875418587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17136963875418587}
{"step": 390000, "time": 19665.770471811295, "eval_episode/length": 37.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 390000, "time": 19671.888787031174, "eval_episode/length": 149.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 390000, "time": 19673.642724514008, "eval_episode/length": 156.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 390000, "time": 19675.224433898926, "eval_episode/length": 158.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 390000, "time": 19676.892477989197, "eval_episode/length": 162.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 390000, "time": 19678.51788663864, "eval_episode/length": 165.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 390000, "time": 19680.53426384926, "eval_episode/length": 140.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9716312056737588}
{"step": 390000, "time": 19682.640511989594, "eval_episode/length": 191.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 390160, "time": 19688.71143245697, "episode/length": 182.0, "episode/score": 0.1956183815739223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1956183815739223}
{"step": 390168, "time": 19690.24338078499, "episode/length": 174.0, "episode/score": 0.18804205033961807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18804205033961807}
{"step": 390536, "time": 19705.39968252182, "episode/length": 156.0, "episode/score": 0.17600107927864883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17600107927864883}
{"step": 390544, "time": 19707.356259822845, "episode/length": 190.0, "episode/score": 0.19426301633120602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19426301633120602}
{"step": 390544, "time": 19707.364156007767, "episode/length": 222.0, "episode/score": 0.24490257524416847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24490257524416847}
{"step": 390736, "time": 19717.550805091858, "episode/length": 176.0, "episode/score": 0.19440063810907304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19440063810907304}
{"step": 390952, "time": 19726.769509792328, "episode/length": 50.0, "episode/score": 0.05425007726444164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05425007726444164}
{"step": 390952, "time": 19726.7775015831, "episode/length": 235.0, "episode/score": 0.25059834909779966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25059834909779966}
{"step": 391328, "time": 19744.4435839653, "episode/length": 145.0, "episode/score": 0.1593140837358078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1593140837358078}
{"step": 391696, "time": 19759.62591791153, "episode/length": 509.0, "episode/score": 0.5532682681559891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.5532682681559891}
{"step": 391728, "time": 19762.39058613777, "episode/length": 49.0, "episode/score": 0.0541115991800325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0541115991800325}
{"step": 391776, "time": 19765.63468027115, "episode/length": 102.0, "episode/score": 0.11396499642796698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11396499642796698}
{"step": 391864, "time": 19770.131416082382, "episode/length": 165.0, "episode/score": 0.15980589812534163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15980589812534163}
{"step": 391952, "time": 19775.5261991024, "episode/length": 222.0, "episode/score": 0.2347960927290842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2347960927290842}
{"step": 392200, "time": 19786.07497692108, "episode/length": 155.0, "episode/score": 0.17720574701888836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17720574701888836}
{"step": 392288, "time": 19791.15000295639, "episode/length": 217.0, "episode/score": 0.2300039202636981, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2300039202636981}
{"step": 392584, "time": 19803.438997745514, "episode/length": 230.0, "episode/score": 0.2544233742119104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2544233742119104}
{"step": 392992, "time": 19820.484005451202, "episode/length": 161.0, "episode/score": 0.1753876607872371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1753876607872371}
{"step": 393016, "time": 19822.660860061646, "episode/length": 154.0, "episode/score": 0.1573619660739496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1573619660739496}
{"step": 393152, "time": 19829.463359594345, "episode/length": 160.0, "episode/score": 0.1648458999225113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1648458999225113}
{"step": 393240, "time": 19835.667038440704, "episode/length": 188.0, "episode/score": 0.1983531413025048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1983531413025048}
{"step": 393392, "time": 19843.107649087906, "episode/length": 49.0, "episode/score": 0.05243567381876346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05243567381876346}
{"step": 393744, "time": 19857.736355543137, "episode/length": 181.0, "episode/score": 0.17969667715078685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17969667715078685}
{"step": 394360, "time": 19882.686268806458, "episode/length": 300.0, "episode/score": 0.33076308155250445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33076308155250445}
{"step": 394632, "time": 19894.34313941002, "episode/length": 154.0, "episode/score": 0.1691314091312961, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1691314091312961}
{"step": 394696, "time": 19898.234443187714, "episode/length": 181.0, "episode/score": 0.1822175756242359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1822175756242359}
{"step": 394880, "time": 19906.88412952423, "episode/length": 286.0, "episode/score": 0.31008392517469474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31008392517469474}
{"step": 394960, "time": 19911.316467523575, "episode/length": 242.0, "episode/score": 0.255074505788798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.255074505788798}
{"step": 395016, "time": 19914.648112535477, "episode/length": 158.0, "episode/score": 0.16061260056994797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16061260056994797}
{"step": 395480, "time": 19934.723799943924, "episode/length": 290.0, "episode/score": 0.33767929058922164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33767929058922164}
{"step": 395560, "time": 19939.12979078293, "episode/length": 149.0, "episode/score": 0.1733962417110888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1733962417110888}
{"step": 395720, "time": 19946.572980880737, "episode/length": 439.0, "episode/score": 0.4671274748961878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4671274748961878}
{"step": 395960, "time": 19957.045625686646, "episode/length": 117.0, "episode/score": 0.12479605245698622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12479605245698622}
{"step": 396376, "time": 19974.01495909691, "episode/length": 186.0, "episode/score": 0.19769527795142494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19769527795142494}
{"step": 396456, "time": 19979.09726333618, "episode/length": 121.0, "episode/score": 0.12024828487756167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12024828487756167}
{"step": 396472, "time": 19981.70178771019, "episode/length": 229.0, "episode/score": 0.24266210926180065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24266210926180065}
{"step": 396504, "time": 19984.946525096893, "episode/length": 225.0, "episode/score": 0.24887168451732578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24887168451732578}
{"step": 396744, "time": 19995.340893268585, "episode/length": 222.0, "episode/score": 0.21755534784369956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21755534784369956}
{"step": 397008, "time": 20006.958066225052, "episode/length": 160.0, "episode/score": 0.159552166353933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.159552166353933}
{"step": 397160, "time": 20013.9788274765, "episode/length": 199.0, "episode/score": 0.2177566256150385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2177566256150385}
{"step": 397608, "time": 20032.211477041245, "episode/length": 205.0, "episode/score": 0.22383028441981878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22383028441981878}
{"step": 397680, "time": 20036.514055490494, "episode/length": 83.0, "episode/score": 0.09505092421659356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09505092421659356}
{"step": 397816, "time": 20042.88398528099, "episode/length": 167.0, "episode/score": 0.1680911123930855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1680911123930855}
{"step": 397824, "time": 20044.99384045601, "episode/length": 164.0, "episode/score": 0.17739196227284992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17739196227284992}
{"step": 397904, "time": 20049.577971696854, "episode/length": 190.0, "episode/score": 0.18592639842245262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18592639842245262}
{"step": 397976, "time": 20053.47391819954, "episode/length": 153.0, "episode/score": 0.1775602855013858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1775602855013858}
{"step": 398224, "time": 20064.41131043434, "episode/length": 220.0, "episode/score": 0.23359442203945946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23359442203945946}
{"step": 398384, "time": 20071.977413654327, "episode/length": 152.0, "episode/score": 0.1519935303585953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1519935303585953}
{"step": 399104, "time": 20100.92672085762, "episode/length": 159.0, "episode/score": 0.1589779393543722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1589779393543722}
{"step": 399208, "time": 20105.9577794075, "episode/length": 173.0, "episode/score": 0.18797255741083063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18797255741083063}
{"step": 399408, "time": 20115.271870613098, "episode/length": 187.0, "episode/score": 0.2129537299479125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2129537299479125}
{"step": 399504, "time": 20120.3234705925, "episode/length": 190.0, "episode/score": 0.21178015282202978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21178015282202978}
{"step": 399504, "time": 20120.3319272995, "episode/length": 227.0, "episode/score": 0.23259414895437658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23259414895437658}
{"step": 399696, "time": 20130.636784791946, "episode/length": 183.0, "episode/score": 0.21585893564406433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21585893564406433}
{"step": 400048, "time": 20145.207280158997, "episode/length": 304.0, "episode/score": 0.34917715990013676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34917715990013676}
{"step": 400088, "time": 20161.660709142685, "eval_episode/length": 34.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8571428571428571}
{"step": 400088, "time": 20164.975329637527, "eval_episode/length": 66.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9253731343283582}
{"step": 400088, "time": 20167.66650390625, "eval_episode/length": 80.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9259259259259259}
{"step": 400088, "time": 20172.455206155777, "eval_episode/length": 142.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.993006993006993}
{"step": 400088, "time": 20174.452795267105, "eval_episode/length": 143.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 400088, "time": 20176.62278985977, "eval_episode/length": 148.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 400088, "time": 20178.998106718063, "eval_episode/length": 159.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.99375}
{"step": 400088, "time": 20182.320488214493, "eval_episode/length": 187.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 400392, "time": 20193.601922512054, "episode/length": 147.0, "episode/score": 0.16396881379114348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16396881379114348}
{"step": 400424, "time": 20196.378566741943, "episode/length": 254.0, "episode/score": 0.2900417248129088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2900417248129088}
{"step": 400496, "time": 20200.903126478195, "episode/length": 173.0, "episode/score": 0.1686677243487793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1686677243487793}
{"step": 400672, "time": 20208.92997431755, "episode/length": 145.0, "episode/score": 0.16953313719386642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16953313719386642}
{"step": 400688, "time": 20211.112646102905, "episode/length": 147.0, "episode/score": 0.15512051033329044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15512051033329044}
{"step": 400880, "time": 20219.681956768036, "episode/length": 183.0, "episode/score": 0.18550878988753539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18550878988753539}
{"step": 401304, "time": 20236.65470814705, "episode/length": 156.0, "episode/score": 0.16947414122114424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16947414122114424}
{"step": 401440, "time": 20244.957008361816, "episode/length": 126.0, "episode/score": 0.13349002765971818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13349002765971818}
{"step": 401784, "time": 20259.396368980408, "episode/length": 173.0, "episode/score": 0.1832905229748576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1832905229748576}
{"step": 401808, "time": 20262.087398052216, "episode/length": 139.0, "episode/score": 0.15009037704294315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15009037704294315}
{"step": 401960, "time": 20269.113684415817, "episode/length": 182.0, "episode/score": 0.1881671746596112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1881671746596112}
{"step": 402200, "time": 20279.451627969742, "episode/length": 190.0, "episode/score": 0.20198255296054413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20198255296054413}
{"step": 402200, "time": 20279.4595849514, "episode/length": 164.0, "episode/score": 0.1666074974637013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1666074974637013}
{"step": 402712, "time": 20301.65663075447, "episode/length": 175.0, "episode/score": 0.1573479410035361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1573479410035361}
{"step": 402840, "time": 20307.87531375885, "episode/length": 392.0, "episode/score": 0.42528522764223453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42528522764223453}
{"step": 403008, "time": 20315.805735111237, "episode/length": 152.0, "episode/score": 0.16613355930167018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16613355930167018}
{"step": 403032, "time": 20318.058908700943, "episode/length": 198.0, "episode/score": 0.20628125388975604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20628125388975604}
{"step": 403129, "time": 20324.0444355011, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.935382032018947, "train/action_min": 0.0, "train/action_std": 4.604006635861134, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00774234297179331, "train/actor_opt_grad_steps": 24460.0, "train/actor_opt_loss": -5.434890756222207, "train/adv_mag": 0.1855400184712072, "train/adv_max": 0.12843022284310635, "train/adv_mean": 0.00018377963517811772, "train/adv_min": -0.18505693185986496, "train/adv_std": 0.013804783707293938, "train/cont_avg": 0.9945712352362205, "train/cont_loss_mean": 0.00031536557889832306, "train/cont_loss_std": 0.008726279934845071, "train/cont_neg_acc": 0.9856111754582623, "train/cont_neg_loss": 0.025654752094694023, "train/cont_pos_acc": 0.9999613175241966, "train/cont_pos_loss": 0.00016733571094865545, "train/cont_pred": 0.9945760233195748, "train/cont_rate": 0.9945712352362205, "train/dyn_loss_mean": 12.111565019202045, "train/dyn_loss_std": 8.514643883141945, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14981943011049212, "train/extr_critic_critic_opt_grad_steps": 24460.0, "train/extr_critic_critic_opt_loss": 12079.606460691437, "train/extr_critic_mag": 0.2827070942075234, "train/extr_critic_max": 0.2827070942075234, "train/extr_critic_mean": 0.23099890609425822, "train/extr_critic_min": 0.0018726230606319397, "train/extr_critic_std": 0.05798167618006233, "train/extr_return_normed_mag": 0.20224110289352146, "train/extr_return_normed_max": 0.20224110289352146, "train/extr_return_normed_mean": 0.14995025790582492, "train/extr_return_normed_min": -0.0802354617850987, "train/extr_return_normed_std": 0.05982920703456158, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28347353179623763, "train/extr_return_raw_max": 0.28347353179623763, "train/extr_return_raw_mean": 0.23118269161915217, "train/extr_return_raw_min": 0.0009969660616296484, "train/extr_return_raw_std": 0.05982920750388949, "train/extr_reward_mag": 0.0013680045060285432, "train/extr_reward_max": 0.0013680045060285432, "train/extr_reward_mean": 0.0010902330776177875, "train/extr_reward_min": 9.182869918703095e-06, "train/extr_reward_std": 0.00024072497917658201, "train/image_loss_mean": 6.047098493951512, "train/image_loss_std": 10.675579397697149, "train/model_loss_mean": 13.354007322957196, "train/model_loss_std": 14.238563695291834, "train/model_opt_grad_norm": 61.50293333699384, "train/model_opt_grad_steps": 24435.976377952757, "train/model_opt_loss": 15357.407907080462, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1146.6535433070867, "train/policy_entropy_mag": 2.761612114943857, "train/policy_entropy_max": 2.761612114943857, "train/policy_entropy_mean": 2.0650748746601617, "train/policy_entropy_min": 0.08075422248033089, "train/policy_entropy_std": 0.6125007780987447, "train/policy_logprob_mag": 7.437873224573811, "train/policy_logprob_max": -0.009645876599343742, "train/policy_logprob_mean": -2.064926298584525, "train/policy_logprob_min": -7.437873224573811, "train/policy_logprob_std": 1.1882574135862936, "train/policy_randomness_mag": 0.9747278863989463, "train/policy_randomness_max": 0.9747278863989463, "train/policy_randomness_mean": 0.728880805293406, "train/policy_randomness_min": 0.028502696729081824, "train/policy_randomness_std": 0.21618589676740602, "train/post_ent_mag": 58.4261654831293, "train/post_ent_max": 58.4261654831293, "train/post_ent_mean": 40.152831760917124, "train/post_ent_min": 20.812885329479307, "train/post_ent_std": 6.924896893538828, "train/prior_ent_mag": 68.16098971629705, "train/prior_ent_max": 68.16098971629705, "train/prior_ent_mean": 52.34579257514533, "train/prior_ent_min": 30.205710223340613, "train/prior_ent_std": 5.913193101958027, "train/rep_loss_mean": 12.111565019202045, "train/rep_loss_std": 8.514643883141945, "train/reward_avg": 0.001048826529574764, "train/reward_loss_mean": 0.03965447030550852, "train/reward_loss_std": 0.011729236780189153, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001302248849643497, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03965447001217857, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010496933741025686, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.4211008943138865, "train_stats/max_log_achievement_collect_coal": 0.01834862385321101, "train_stats/max_log_achievement_collect_drink": 4.110091743119266, "train_stats/max_log_achievement_collect_sapling": 0.7431192660550459, "train_stats/max_log_achievement_collect_stone": 0.12844036697247707, "train_stats/max_log_achievement_collect_wood": 0.7339449541284404, "train_stats/max_log_achievement_defeat_skeleton": 0.009174311926605505, "train_stats/max_log_achievement_defeat_zombie": 0.009174311926605505, "train_stats/max_log_achievement_eat_cow": 0.01834862385321101, "train_stats/max_log_achievement_make_wood_pickaxe": 0.03669724770642202, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 0.46788990825688076, "train_stats/max_log_achievement_place_stone": 0.01834862385321101, "train_stats/max_log_achievement_place_table": 0.11009174311926606, "train_stats/max_log_achievement_wake_up": 0.3853211009174312, "train_stats/mean_log_entropy": 2.1676004742263655, "eval_stats/sum_log_reward": 0.662499981932342, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.125, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_furnace": 0.3333333333333333, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 2.4133201804943383e-05, "report/cont_loss_std": 0.0003831155481748283, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0019597229547798634, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.89233524503652e-06, "report/cont_pred": 0.9921940565109253, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 13.022411346435547, "report/dyn_loss_std": 8.327001571655273, "report/image_loss_mean": 6.251312255859375, "report/image_loss_std": 11.829996109008789, "report/model_loss_mean": 14.104862213134766, "report/model_loss_std": 15.058958053588867, "report/post_ent_mag": 58.29460144042969, "report/post_ent_max": 58.29460144042969, "report/post_ent_mean": 40.20307159423828, "report/post_ent_min": 21.58917999267578, "report/post_ent_std": 7.238191604614258, "report/prior_ent_mag": 68.7121810913086, "report/prior_ent_max": 68.7121810913086, "report/prior_ent_mean": 53.715213775634766, "report/prior_ent_min": 33.801368713378906, "report/prior_ent_std": 5.829254627227783, "report/rep_loss_mean": 13.022411346435547, "report/rep_loss_std": 8.327001571655273, "report/reward_avg": 0.0010637873783707619, "report/reward_loss_mean": 0.040078721940517426, "report/reward_loss_std": 0.012122999876737595, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012753009796142578, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.040078721940517426, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00106206932105124, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00018044799799099565, "eval/cont_loss_std": 0.004882094915956259, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.007564531173557043, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0001514908071840182, "eval/cont_pred": 0.9959831833839417, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.256771087646484, "eval/dyn_loss_std": 10.730347633361816, "eval/image_loss_mean": 17.575176239013672, "eval/image_loss_std": 24.333677291870117, "eval/model_loss_mean": 29.92173194885254, "eval/model_loss_std": 28.859657287597656, "eval/post_ent_mag": 57.69117736816406, "eval/post_ent_max": 57.69117736816406, "eval/post_ent_mean": 38.605995178222656, "eval/post_ent_min": 21.02659034729004, "eval/post_ent_std": 6.782713890075684, "eval/prior_ent_mag": 68.7121810913086, "eval/prior_ent_max": 68.7121810913086, "eval/prior_ent_mean": 53.9118766784668, "eval/prior_ent_min": 41.04673767089844, "eval/prior_ent_std": 4.860218048095703, "eval/rep_loss_mean": 19.256771087646484, "eval/rep_loss_std": 10.730347633361816, "eval/reward_avg": 0.009863280691206455, "eval/reward_loss_mean": 0.7923113703727722, "eval/reward_loss_std": 3.783275842666626, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 0.0013360977172851562, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.5239576101303101, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.152122497558594, "eval/reward_pred": 0.0010560727678239346, "eval/reward_rate": 0.013671875, "replay/size": 402625.0, "replay/inserts": 20336.0, "replay/samples": 20336.0, "replay/insert_wait_avg": 1.3137055981543756e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.748955539790408e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 78888.0, "eval_replay/inserts": 3040.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.236090534611752e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4034850597382, "timer/env.step_count": 2542.0, "timer/env.step_total": 233.9589285850525, "timer/env.step_frac": 0.23386456772597294, "timer/env.step_avg": 0.09203734405391523, "timer/env.step_min": 0.022600173950195312, "timer/env.step_max": 3.3653743267059326, "timer/replay._sample_count": 20336.0, "timer/replay._sample_total": 9.815743684768677, "timer/replay._sample_frac": 0.009811784776202113, "timer/replay._sample_avg": 0.00048267819063575317, "timer/replay._sample_min": 0.00034880638122558594, "timer/replay._sample_max": 0.009360074996948242, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2922.0, "timer/agent.policy_total": 46.24219989776611, "timer/agent.policy_frac": 0.04622354938618072, "timer/agent.policy_avg": 0.015825530423602366, "timer/agent.policy_min": 0.009472846984863281, "timer/agent.policy_max": 0.11695361137390137, "timer/dataset_train_count": 1271.0, "timer/dataset_train_total": 0.13854312896728516, "timer/dataset_train_frac": 0.0001384872514303688, "timer/dataset_train_avg": 0.00010900324859739194, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0007047653198242188, "timer/agent.train_count": 1271.0, "timer/agent.train_total": 570.2259449958801, "timer/agent.train_frac": 0.5699959601418518, "timer/agent.train_avg": 0.44864354444994503, "timer/agent.train_min": 0.43425869941711426, "timer/agent.train_max": 1.6557517051696777, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4730367660522461, "timer/agent.report_frac": 0.00047284597976385414, "timer/agent.report_avg": 0.23651838302612305, "timer/agent.report_min": 0.2248225212097168, "timer/agent.report_max": 0.2482142448425293, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8122045508772308e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 20.32755612162547}
{"step": 403408, "time": 20334.573195934296, "episode/length": 180.0, "episode/score": 0.2000455710094684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2000455710094684}
{"step": 403752, "time": 20348.756910324097, "episode/length": 193.0, "episode/score": 0.21350239576713648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21350239576713648}
{"step": 403832, "time": 20353.30008506775, "episode/length": 252.0, "episode/score": 0.2840796329292061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2840796329292061}
{"step": 403928, "time": 20358.26351094246, "episode/length": 64.0, "episode/score": 0.0777251102754235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0777251102754235}
{"step": 403984, "time": 20362.047437667847, "episode/length": 158.0, "episode/score": 0.1684151764075068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1684151764075068}
{"step": 404384, "time": 20379.00954270363, "episode/length": 171.0, "episode/score": 0.17499023897653387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17499023897653387}
{"step": 404392, "time": 20380.67918920517, "episode/length": 169.0, "episode/score": 0.17404120339597284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17404120339597284}
{"step": 404416, "time": 20383.352949380875, "episode/length": 276.0, "episode/score": 0.29693602869701863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29693602869701863}
{"step": 404608, "time": 20392.094618797302, "episode/length": 220.0, "episode/score": 0.24264896043678164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24264896043678164}
{"step": 405144, "time": 20413.310100078583, "episode/length": 173.0, "episode/score": 0.1976491291043203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1976491291043203}
{"step": 405376, "time": 20423.697736501694, "episode/length": 180.0, "episode/score": 0.2082236670794373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2082236670794373}
{"step": 405432, "time": 20427.630457401276, "episode/length": 199.0, "episode/score": 0.19344826523683878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19344826523683878}
{"step": 405536, "time": 20433.68223309517, "episode/length": 143.0, "episode/score": 0.16739583018352278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16739583018352278}
{"step": 405656, "time": 20439.584321975708, "episode/length": 157.0, "episode/score": 0.162618218654643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.162618218654643}
{"step": 405696, "time": 20442.761813163757, "episode/length": 213.0, "episode/score": 0.21656788371001312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21656788371001312}
{"step": 405704, "time": 20444.294618844986, "episode/length": 160.0, "episode/score": 0.15455106172430533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15455106172430533}
{"step": 406072, "time": 20459.496341228485, "episode/length": 182.0, "episode/score": 0.1882951024117574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1882951024117574}
{"step": 406536, "time": 20478.24839568138, "episode/length": 173.0, "episode/score": 0.181925889312879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.181925889312879}
{"step": 406768, "time": 20488.49627304077, "episode/length": 138.0, "episode/score": 0.1596160512717688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1596160512717688}
{"step": 406944, "time": 20496.44264316559, "episode/length": 175.0, "episode/score": 0.1719858201167881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1719858201167881}
{"step": 406960, "time": 20498.685086488724, "episode/length": 197.0, "episode/score": 0.22837499593151733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22837499593151733}
{"step": 407072, "time": 20504.344284057617, "episode/length": 171.0, "episode/score": 0.18496258921823028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18496258921823028}
{"step": 407256, "time": 20512.556503534317, "episode/length": 147.0, "episode/score": 0.14445760280250397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14445760280250397}
{"step": 407576, "time": 20525.984109401703, "episode/length": 39.0, "episode/score": 0.047270832350477576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047270832350477576}
{"step": 407816, "time": 20536.390876293182, "episode/length": 263.0, "episode/score": 0.28061723708833597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28061723708833597}
{"step": 407872, "time": 20540.22610974312, "episode/length": 304.0, "episode/score": 0.34457950749765587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34457950749765587}
{"step": 407968, "time": 20545.27955722809, "episode/length": 149.0, "episode/score": 0.15622311280822032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15622311280822032}
{"step": 408248, "time": 20556.962401628494, "episode/length": 146.0, "episode/score": 0.1550964720954653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1550964720954653}
{"step": 408576, "time": 20571.15361213684, "episode/length": 203.0, "episode/score": 0.22319657866410125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22319657866410125}
{"step": 408712, "time": 20577.438680887222, "episode/length": 141.0, "episode/score": 0.15037778445093863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15037778445093863}
{"step": 408792, "time": 20581.915489435196, "episode/length": 228.0, "episode/score": 0.2335082936560866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2335082936560866}
{"step": 408808, "time": 20584.043977737427, "episode/length": 123.0, "episode/score": 0.14070917008211836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14070917008211836}
{"step": 409224, "time": 20601.20884823799, "episode/length": 156.0, "episode/score": 0.16303760908340337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16303760908340337}
{"step": 409448, "time": 20610.974653482437, "episode/length": 149.0, "episode/score": 0.17336518585216254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17336518585216254}
{"step": 409480, "time": 20613.679783582687, "episode/length": 200.0, "episode/score": 0.21003976046631578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21003976046631578}
{"step": 409608, "time": 20620.73550772667, "episode/length": 383.0, "episode/score": 0.38057718940126506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.38057718940126506}
{"step": 409624, "time": 20623.854209184647, "episode/length": 49.0, "episode/score": 0.058541665552183986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058541665552183986}
{"step": 409872, "time": 20634.854075193405, "episode/length": 132.0, "episode/score": 0.13763483068760252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13763483068760252}
{"step": 409984, "time": 20640.598388910294, "episode/length": 148.0, "episode/score": 0.16034341043268796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16034341043268796}
{"step": 410072, "time": 20663.26679611206, "eval_episode/length": 141.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9647887323943662}
{"step": 410072, "time": 20665.237748146057, "eval_episode/length": 151.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9605263157894737}
{"step": 410072, "time": 20666.741548776627, "eval_episode/length": 152.0, "eval_episode/score": -0.9000000208616257, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 410072, "time": 20668.530452013016, "eval_episode/length": 159.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.99375}
{"step": 410072, "time": 20670.29090642929, "eval_episode/length": 167.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 410072, "time": 20671.974019289017, "eval_episode/length": 173.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 410072, "time": 20675.397589683533, "eval_episode/length": 222.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 410072, "time": 20678.5903775692, "eval_episode/length": 259.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 410568, "time": 20696.94812130928, "episode/length": 248.0, "episode/score": 0.28997313862782903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28997313862782903}
{"step": 410576, "time": 20699.00288915634, "episode/length": 232.0, "episode/score": 0.24359216271477635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24359216271477635}
{"step": 410720, "time": 20705.780647993088, "episode/length": 154.0, "episode/score": 0.1614239538939728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1614239538939728}
{"step": 410800, "time": 20710.643625736237, "episode/length": 146.0, "episode/score": 0.17351378513558302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17351378513558302}
{"step": 410904, "time": 20716.229525327682, "episode/length": 181.0, "episode/score": 0.20927551936983946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20927551936983946}
{"step": 410944, "time": 20719.36647462845, "episode/length": 133.0, "episode/score": 0.15132927663216833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15132927663216833}
{"step": 410960, "time": 20721.544870853424, "episode/length": 168.0, "episode/score": 0.20760416222037748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20760416222037748}
{"step": 411512, "time": 20743.398272037506, "episode/length": 190.0, "episode/score": 0.1922116789046413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1922116789046413}
{"step": 411760, "time": 20754.388290405273, "episode/length": 148.0, "episode/score": 0.17392261582426727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17392261582426727}
{"step": 411880, "time": 20760.201667785645, "episode/length": 116.0, "episode/score": 0.13588888620142825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13588888620142825}
{"step": 412048, "time": 20768.297471284866, "episode/length": 165.0, "episode/score": 0.16713396394698066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16713396394698066}
{"step": 412176, "time": 20774.666073083878, "episode/length": 171.0, "episode/score": 0.17179517198019312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17179517198019312}
{"step": 412232, "time": 20778.025485515594, "episode/length": 158.0, "episode/score": 0.17959300837901537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17959300837901537}
{"step": 412592, "time": 20793.457118034363, "episode/length": 210.0, "episode/score": 0.22473547686786333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22473547686786333}
{"step": 412944, "time": 20808.21241211891, "episode/length": 295.0, "episode/score": 0.31911357383251016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31911357383251016}
{"step": 412944, "time": 20808.220675230026, "episode/length": 178.0, "episode/score": 0.1873483665040112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1873483665040112}
{"step": 413040, "time": 20814.84012246132, "episode/length": 144.0, "episode/score": 0.1657997585607518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1657997585607518}
{"step": 413216, "time": 20822.912301063538, "episode/length": 181.0, "episode/score": 0.21503458584811597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21503458584811597}
{"step": 413272, "time": 20826.364357948303, "episode/length": 40.0, "episode/score": 0.04674999922281131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04674999922281131}
{"step": 413368, "time": 20831.542939901352, "episode/length": 164.0, "episode/score": 0.18813748403954378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18813748403954378}
{"step": 413448, "time": 20836.051034927368, "episode/length": 158.0, "episode/score": 0.17189214534118946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17189214534118946}
{"step": 413744, "time": 20848.73110485077, "episode/length": 143.0, "episode/score": 0.12840825517923804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12840825517923804}
{"step": 413888, "time": 20855.654223442078, "episode/length": 206.0, "episode/score": 0.22155737212233362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22155737212233362}
{"step": 414352, "time": 20874.396154165268, "episode/length": 163.0, "episode/score": 0.1940564558362894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1940564558362894}
{"step": 414464, "time": 20880.048090219498, "episode/length": 155.0, "episode/score": 0.17383636881913844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17383636881913844}
{"step": 414552, "time": 20884.50878429413, "episode/length": 147.0, "episode/score": 0.1574202483661793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1574202483661793}
{"step": 414696, "time": 20891.276235818863, "episode/length": 155.0, "episode/score": 0.16554260842440272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16554260842440272}
{"step": 414784, "time": 20896.31699872017, "episode/length": 188.0, "episode/score": 0.20972424325009342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20972424325009342}
{"step": 414944, "time": 20903.72495150566, "episode/length": 249.0, "episode/score": 0.2833944372669066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2833944372669066}
{"step": 415008, "time": 20907.70922088623, "episode/length": 157.0, "episode/score": 0.1808495337872955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1808495337872955}
{"step": 415208, "time": 20916.6393969059, "episode/length": 164.0, "episode/score": 0.19129306398826884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19129306398826884}
{"step": 415448, "time": 20927.193260908127, "episode/length": 122.0, "episode/score": 0.14895833024638705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14895833024638705}
{"step": 415456, "time": 20929.18439602852, "episode/length": 137.0, "episode/score": 0.14336050901147246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14336050901147246}
{"step": 415640, "time": 20937.377452135086, "episode/length": 78.0, "episode/score": 0.08885605957129883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08885605957129883}
{"step": 415864, "time": 20947.323952436447, "episode/length": 163.0, "episode/score": 0.17706342166366085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17706342166366085}
{"step": 416120, "time": 20958.29121041298, "episode/length": 146.0, "episode/score": 0.1627561040349974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1627561040349974}
{"step": 416240, "time": 20964.40645956993, "episode/length": 181.0, "episode/score": 0.1698169914079699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1698169914079699}
{"step": 416424, "time": 20972.558510541916, "episode/length": 151.0, "episode/score": 0.16606934710853238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16606934710853238}
{"step": 416704, "time": 20984.781887292862, "episode/length": 155.0, "episode/score": 0.15867622646419477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15867622646419477}
{"step": 416768, "time": 20988.818083763123, "episode/length": 164.0, "episode/score": 0.18708348981272138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18708348981272138}
{"step": 417456, "time": 21016.09763121605, "episode/length": 344.0, "episode/score": 0.3716200067929094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3716200067929094}
{"step": 417640, "time": 21024.25934290886, "episode/length": 174.0, "episode/score": 0.18916013723537617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18916013723537617}
{"step": 417720, "time": 21028.76488494873, "episode/length": 259.0, "episode/score": 0.2977840085095522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2977840085095522}
{"step": 417728, "time": 21030.762813091278, "episode/length": 232.0, "episode/score": 0.2612282101608798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2612282101608798}
{"step": 417992, "time": 21043.30568909645, "episode/length": 160.0, "episode/score": 0.1872272766486276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1872272766486276}
{"step": 418144, "time": 21051.01166534424, "episode/length": 171.0, "episode/score": 0.1983654803580066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1983654803580066}
{"step": 418376, "time": 21061.06070446968, "episode/length": 243.0, "episode/score": 0.25576853349593875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25576853349593875}
{"step": 418584, "time": 21070.453468084335, "episode/length": 307.0, "episode/score": 0.3260112469552041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3260112469552041}
{"step": 418904, "time": 21083.91128206253, "episode/length": 147.0, "episode/score": 0.14990401260001818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14990401260001818}
{"step": 418928, "time": 21086.466409921646, "episode/length": 183.0, "episode/score": 0.19687498633265932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19687498633265932}
{"step": 419168, "time": 21097.150054216385, "episode/length": 179.0, "episode/score": 0.1950707961259468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1950707961259468}
{"step": 419272, "time": 21102.407319307327, "episode/length": 159.0, "episode/score": 0.16986463699413434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16986463699413434}
{"step": 419344, "time": 21106.78915643692, "episode/length": 212.0, "episode/score": 0.2174922373114896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2174922373114896}
{"step": 419360, "time": 21108.869507551193, "episode/length": 151.0, "episode/score": 0.1785953365624664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1785953365624664}
{"step": 419736, "time": 21124.19611644745, "episode/length": 169.0, "episode/score": 0.1903610750205189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1903610750205189}
{"step": 420056, "time": 21158.26684331894, "eval_episode/length": 144.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.993103448275862}
{"step": 420056, "time": 21159.984697818756, "eval_episode/length": 149.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 420056, "time": 21161.87571835518, "eval_episode/length": 159.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.99375}
{"step": 420056, "time": 21164.647076129913, "eval_episode/length": 185.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 420056, "time": 21166.986560106277, "eval_episode/length": 206.0, "eval_episode/score": 3.099999964237213, "eval_episode/reward_rate": 0.9806763285024155}
{"step": 420056, "time": 21169.073084115982, "eval_episode/length": 221.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.972972972972973}
{"step": 420056, "time": 21169.081062555313, "eval_episode/length": 221.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 420056, "time": 21172.298946380615, "eval_episode/length": 223.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 420176, "time": 21177.01477789879, "episode/length": 155.0, "episode/score": 0.18468161071723443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18468161071723443}
{"step": 420288, "time": 21182.685002088547, "episode/length": 139.0, "episode/score": 0.16847221870557405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16847221870557405}
{"step": 420576, "time": 21194.935250759125, "episode/length": 162.0, "episode/score": 0.1588338598462542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1588338598462542}
{"step": 420592, "time": 21197.090614318848, "episode/length": 153.0, "episode/score": 0.14637972690252354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14637972690252354}
{"step": 420696, "time": 21202.245470523834, "episode/length": 263.0, "episode/score": 0.2931987786978425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2931987786978425}
{"step": 420824, "time": 21208.524617671967, "episode/length": 184.0, "episode/score": 0.2191116301664806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2191116301664806}
{"step": 421032, "time": 21217.74656176567, "episode/length": 265.0, "episode/score": 0.2885426835441649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2885426835441649}
{"step": 421552, "time": 21238.855830669403, "episode/length": 171.0, "episode/score": 0.1703576735462775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1703576735462775}
{"step": 421696, "time": 21245.630625724792, "episode/length": 137.0, "episode/score": 0.14052200519881808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14052200519881808}
{"step": 421720, "time": 21247.89606976509, "episode/length": 178.0, "episode/score": 0.178398284416744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.178398284416744}
{"step": 421952, "time": 21258.353837013245, "episode/length": 140.0, "episode/score": 0.12854258116703932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12854258116703932}
{"step": 422352, "time": 21274.85872244835, "episode/length": 221.0, "episode/score": 0.23724594737450388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23724594737450388}
{"step": 422424, "time": 21278.906709194183, "episode/length": 173.0, "episode/score": 0.18646712354848205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18646712354848205}
{"step": 422512, "time": 21284.31006550789, "episode/length": 226.0, "episode/score": 0.257895240605194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.257895240605194}
{"step": 422680, "time": 21291.80850982666, "episode/length": 140.0, "episode/score": 0.14291921427093257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14291921427093257}
{"step": 422688, "time": 21293.802356004715, "episode/length": 368.0, "episode/score": 0.4087052423219575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4087052423219575}
{"step": 422928, "time": 21304.09193778038, "episode/length": 153.0, "episode/score": 0.1623352333845105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1623352333845105}
{"step": 423120, "time": 21312.98140835762, "episode/length": 174.0, "episode/score": 0.19154783550629872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19154783550629872}
{"step": 423144, "time": 21315.62694478035, "episode/length": 148.0, "episode/score": 0.14968103058890847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14968103058890847}
{"step": 423305, "time": 21324.575815677643, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.7030783825971945, "train/action_min": 0.0, "train/action_std": 4.480189171363049, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00794049548571856, "train/actor_opt_grad_steps": 25730.0, "train/actor_opt_loss": -12.207460116213701, "train/adv_mag": 0.18309553929670588, "train/adv_max": 0.12285043985590222, "train/adv_mean": -0.00011896892638607079, "train/adv_min": -0.18208133787151395, "train/adv_std": 0.013726377082387293, "train/cont_avg": 0.9943713090551181, "train/cont_loss_mean": 0.00017662799885375698, "train/cont_loss_std": 0.005206106881535482, "train/cont_neg_acc": 0.994006999364988, "train/cont_neg_loss": 0.017735550011713612, "train/cont_pos_acc": 0.9999844966910956, "train/cont_pos_loss": 8.726219446583672e-05, "train/cont_pred": 0.9943733069840379, "train/cont_rate": 0.9943713090551181, "train/dyn_loss_mean": 11.861606770613061, "train/dyn_loss_std": 8.407575986516758, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.158292022746379, "train/extr_critic_critic_opt_grad_steps": 25730.0, "train/extr_critic_critic_opt_loss": 12034.984290415847, "train/extr_critic_mag": 0.28692501924169345, "train/extr_critic_max": 0.28692501924169345, "train/extr_critic_mean": 0.23252137216526692, "train/extr_critic_min": 0.001877235615347314, "train/extr_critic_std": 0.06076553733799401, "train/extr_return_normed_mag": 0.21198307892938298, "train/extr_return_normed_max": 0.21198307892938298, "train/extr_return_normed_mean": 0.157029002670228, "train/extr_return_normed_min": -0.07439453418799273, "train/extr_return_normed_std": 0.062476374472924104, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2873564496284395, "train/extr_return_raw_max": 0.2873564496284395, "train/extr_return_raw_mean": 0.2324023780625636, "train/extr_return_raw_min": 0.000978835924403874, "train/extr_return_raw_std": 0.06247637470758806, "train/extr_reward_mag": 0.001350494820301927, "train/extr_reward_max": 0.001350494820301927, "train/extr_reward_mean": 0.0010976887878221204, "train/extr_reward_min": 9.471037256436085e-06, "train/extr_reward_std": 0.00023771222398018713, "train/image_loss_mean": 5.863552850062453, "train/image_loss_std": 10.379513413887324, "train/model_loss_mean": 13.020433133042703, "train/model_loss_std": 13.89542111073892, "train/model_opt_grad_norm": 59.06194942204032, "train/model_opt_grad_steps": 25704.771653543306, "train/model_opt_loss": 16390.242272084153, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1259.8425196850394, "train/policy_entropy_mag": 2.761382908333005, "train/policy_entropy_max": 2.761382908333005, "train/policy_entropy_mean": 2.0238056417525283, "train/policy_entropy_min": 0.08121274335412529, "train/policy_entropy_std": 0.6321657935934742, "train/policy_logprob_mag": 7.436445975866843, "train/policy_logprob_max": -0.009710855070706896, "train/policy_logprob_mean": -2.0240393417088067, "train/policy_logprob_min": -7.436445975866843, "train/policy_logprob_std": 1.2086596808095618, "train/policy_randomness_mag": 0.9746469878774928, "train/policy_randomness_max": 0.9746469878774928, "train/policy_randomness_mean": 0.7143145771477166, "train/policy_randomness_min": 0.028664534500851407, "train/policy_randomness_std": 0.22312678455367801, "train/post_ent_mag": 58.84292965986597, "train/post_ent_max": 58.84292965986597, "train/post_ent_mean": 40.58512484933448, "train/post_ent_min": 20.828813988392746, "train/post_ent_std": 7.075502068977657, "train/prior_ent_mag": 68.3588055588129, "train/prior_ent_max": 68.3588055588129, "train/prior_ent_mean": 52.57894074447512, "train/prior_ent_min": 30.414467698945774, "train/prior_ent_std": 5.828935349081445, "train/rep_loss_mean": 11.861606770613061, "train/rep_loss_std": 8.407575986516758, "train/reward_avg": 0.0010516720454531215, "train/reward_loss_mean": 0.03973966508399783, "train/reward_loss_std": 0.011704470419625598, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012936695354191336, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03973966517199681, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010516949183138923, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.3300884753070046, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.584070796460177, "train_stats/max_log_achievement_collect_sapling": 0.7522123893805309, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.7699115044247787, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.061946902654867256, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008849557522123894, "train_stats/max_log_achievement_make_wood_sword": 0.008849557522123894, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.3893805309734513, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.07079646017699115, "train_stats/max_log_achievement_wake_up": 0.26548672566371684, "train_stats/mean_log_entropy": 2.112911384717553, "eval_stats/sum_log_reward": 1.5374999847263098, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.4375, "eval_stats/max_log_achievement_collect_sapling": 0.25, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 0.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.000492298393510282, "report/cont_loss_std": 0.015598074533045292, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.09997627139091492, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.153269856033148e-06, "report/cont_pred": 0.9954975247383118, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.962069511413574, "report/dyn_loss_std": 8.901080131530762, "report/image_loss_mean": 7.172219276428223, "report/image_loss_std": 14.42125415802002, "report/model_loss_mean": 14.990435600280762, "report/model_loss_std": 17.711265563964844, "report/post_ent_mag": 56.937957763671875, "report/post_ent_max": 56.937957763671875, "report/post_ent_mean": 41.56591796875, "report/post_ent_min": 20.814855575561523, "report/post_ent_std": 7.315260410308838, "report/prior_ent_mag": 68.6480712890625, "report/prior_ent_max": 68.6480712890625, "report/prior_ent_mean": 54.481807708740234, "report/prior_ent_min": 36.43333435058594, "report/prior_ent_std": 5.068737030029297, "report/rep_loss_mean": 12.962069511413574, "report/rep_loss_std": 8.901080131530762, "report/reward_avg": 0.0010747016640380025, "report/reward_loss_mean": 0.04048208147287369, "report/reward_loss_std": 0.011319944635033607, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012557506561279297, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04048208147287369, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010571061866357923, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 6.160318298498169e-05, "eval/cont_loss_std": 0.0014154118252918124, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.011969134211540222, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.175654683218454e-06, "eval/cont_pred": 0.9951715469360352, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 20.507305145263672, "eval/dyn_loss_std": 9.499812126159668, "eval/image_loss_mean": 18.0114803314209, "eval/image_loss_std": 25.291393280029297, "eval/model_loss_mean": 30.93172836303711, "eval/model_loss_std": 28.689796447753906, "eval/post_ent_mag": 55.8925666809082, "eval/post_ent_max": 55.8925666809082, "eval/post_ent_mean": 38.06830978393555, "eval/post_ent_min": 18.618850708007812, "eval/post_ent_std": 5.9980854988098145, "eval/prior_ent_mag": 68.6480712890625, "eval/prior_ent_max": 68.6480712890625, "eval/prior_ent_mean": 53.80923843383789, "eval/prior_ent_min": 31.15894317626953, "eval/prior_ent_std": 4.523009300231934, "eval/rep_loss_mean": 20.507305145263672, "eval/rep_loss_std": 9.499812126159668, "eval/reward_avg": 0.00576171837747097, "eval/reward_loss_mean": 0.6158044338226318, "eval/reward_loss_std": 3.334423542022705, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 0.0013053417205810547, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.4230324625968933, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.162885665893555, "eval/reward_pred": 0.0010520732030272484, "eval/reward_rate": 0.009765625, "replay/size": 422801.0, "replay/inserts": 20176.0, "replay/samples": 20176.0, "replay/insert_wait_avg": 1.292761406380444e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.563432372816965e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 82760.0, "eval_replay/inserts": 3872.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1892604433800562e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.5214693546295, "timer/env.step_count": 2522.0, "timer/env.step_total": 239.22310757637024, "timer/env.step_frac": 0.23909842507495346, "timer/env.step_avg": 0.09485452322615791, "timer/env.step_min": 0.022025346755981445, "timer/env.step_max": 3.074129343032837, "timer/replay._sample_count": 20176.0, "timer/replay._sample_total": 9.551744937896729, "timer/replay._sample_frac": 0.009546766591683365, "timer/replay._sample_avg": 0.0004734211408553097, "timer/replay._sample_min": 0.0003883838653564453, "timer/replay._sample_max": 0.009299039840698242, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3006.0, "timer/agent.policy_total": 48.85835862159729, "timer/agent.policy_frac": 0.04883289376400148, "timer/agent.policy_avg": 0.01625361231590063, "timer/agent.policy_min": 0.009562253952026367, "timer/agent.policy_max": 0.12738871574401855, "timer/dataset_train_count": 1261.0, "timer/dataset_train_total": 0.13547277450561523, "timer/dataset_train_frac": 0.000135402166425274, "timer/dataset_train_avg": 0.00010743281086884634, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0004239082336425781, "timer/agent.train_count": 1261.0, "timer/agent.train_total": 564.707967042923, "timer/agent.train_frac": 0.5644136426249592, "timer/agent.train_avg": 0.44782550915378505, "timer/agent.train_min": 0.435699462890625, "timer/agent.train_max": 0.8638482093811035, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48049306869506836, "timer/agent.report_frac": 0.00048024263687715044, "timer/agent.report_avg": 0.24024653434753418, "timer/agent.report_min": 0.23597311973571777, "timer/agent.report_max": 0.24451994895935059, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.288818359375e-05, "timer/dataset_eval_frac": 2.287625432816915e-08, "timer/dataset_eval_avg": 2.288818359375e-05, "timer/dataset_eval_min": 2.288818359375e-05, "timer/dataset_eval_max": 2.288818359375e-05, "fps": 20.16526734561442}
{"step": 423528, "time": 21332.72526574135, "episode/length": 146.0, "episode/score": 0.14352909950139292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14352909950139292}
{"step": 423760, "time": 21343.209149122238, "episode/length": 134.0, "episode/score": 0.14803203998917525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14803203998917525}
{"step": 423824, "time": 21347.108684301376, "episode/length": 87.0, "episode/score": 0.103624997951556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.103624997951556}
{"step": 423976, "time": 21354.058656454086, "episode/length": 182.0, "episode/score": 0.19084068034862867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19084068034862867}
{"step": 424096, "time": 21360.330461740494, "episode/length": 145.0, "episode/score": 0.14915925536570285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14915925536570285}
{"step": 424312, "time": 21369.819926261902, "episode/length": 145.0, "episode/score": 0.15541145655288346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15541145655288346}
{"step": 424320, "time": 21371.85104393959, "episode/length": 236.0, "episode/score": 0.24539923663678564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24539923663678564}
{"step": 424584, "time": 21383.037108421326, "episode/length": 236.0, "episode/score": 0.26306563752905276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26306563752905276}
{"step": 424760, "time": 21391.020132780075, "episode/length": 153.0, "episode/score": 0.1655444502825958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1655444502825958}
{"step": 424864, "time": 21396.811963558197, "episode/length": 110.0, "episode/score": 0.13216666410153266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13216666410153266}
{"step": 425056, "time": 21405.56091117859, "episode/length": 153.0, "episode/score": 0.17346733967133332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17346733967133332}
{"step": 425368, "time": 21418.615377664566, "episode/length": 158.0, "episode/score": 0.17049909522756934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17049909522756934}
{"step": 425520, "time": 21426.002076148987, "episode/length": 150.0, "episode/score": 0.17792927524715196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17792927524715196}
{"step": 425584, "time": 21430.016864538193, "episode/length": 157.0, "episode/score": 0.15651656710542738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15651656710542738}
{"step": 425648, "time": 21433.81162595749, "episode/length": 235.0, "episode/score": 0.26705574591323966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26705574591323966}
{"step": 425712, "time": 21437.774577379227, "episode/length": 140.0, "episode/score": 0.16570237794076093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16570237794076093}
{"step": 425808, "time": 21442.816031217575, "episode/length": 130.0, "episode/score": 0.15486363332456676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15486363332456676}
{"step": 426192, "time": 21459.89616894722, "episode/length": 141.0, "episode/score": 0.15764560671232175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15764560671232175}
{"step": 426680, "time": 21479.369647979736, "episode/length": 226.0, "episode/score": 0.27497499435412465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27497499435412465}
{"step": 426776, "time": 21484.48902487755, "episode/length": 148.0, "episode/score": 0.1621782294132572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1621782294132572}
{"step": 426848, "time": 21488.996070623398, "episode/length": 141.0, "episode/score": 0.14679547883861233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14679547883861233}
{"step": 426872, "time": 21491.217284202576, "episode/length": 168.0, "episode/score": 0.17227162236667937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17227162236667937}
{"step": 426968, "time": 21496.305000782013, "episode/length": 164.0, "episode/score": 0.17476434607669944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17476434607669944}
{"step": 427096, "time": 21502.630032777786, "episode/length": 215.0, "episode/score": 0.23756695361225866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23756695361225866}
{"step": 427256, "time": 21510.032361268997, "episode/length": 180.0, "episode/score": 0.19005468179602758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19005468179602758}
{"step": 427680, "time": 21527.907047748566, "episode/length": 103.0, "episode/score": 0.12194615150656318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12194615150656318}
{"step": 427832, "time": 21534.793661355972, "episode/length": 204.0, "episode/score": 0.2419842321323813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2419842321323813}
{"step": 427848, "time": 21536.947712421417, "episode/length": 145.0, "episode/score": 0.15887408556227456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15887408556227456}
{"step": 428040, "time": 21545.66374707222, "episode/length": 145.0, "episode/score": 0.15127040292645688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15127040292645688}
{"step": 428168, "time": 21552.085399627686, "episode/length": 149.0, "episode/score": 0.15392605304077733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15392605304077733}
{"step": 428408, "time": 21562.434606075287, "episode/length": 143.0, "episode/score": 0.1637856555480539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1637856555480539}
{"step": 428584, "time": 21570.516251564026, "episode/length": 225.0, "episode/score": 0.2316624489831156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2316624489831156}
{"step": 429024, "time": 21588.547061681747, "episode/length": 148.0, "episode/score": 0.16145106077601667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16145106077601667}
{"step": 429200, "time": 21596.525419950485, "episode/length": 262.0, "episode/score": 0.2901047441209812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2901047441209812}
{"step": 429272, "time": 21600.520678043365, "episode/length": 153.0, "episode/score": 0.16762499741162173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16762499741162173}
{"step": 429328, "time": 21604.414746761322, "episode/length": 205.0, "episode/score": 0.24386287528977846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24386287528977846}
{"step": 429384, "time": 21607.864315986633, "episode/length": 191.0, "episode/score": 0.20537515664909733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20537515664909733}
{"step": 429648, "time": 21619.49659895897, "episode/length": 154.0, "episode/score": 0.16612126318796072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16612126318796072}
{"step": 429664, "time": 21621.654074192047, "episode/length": 186.0, "episode/score": 0.20521710607863497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20521710607863497}
{"step": 429888, "time": 21632.197399377823, "episode/length": 162.0, "episode/score": 0.17556405014329357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17556405014329357}
{"step": 430040, "time": 21656.63805413246, "eval_episode/length": 114.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9565217391304348}
{"step": 430040, "time": 21659.509165287018, "eval_episode/length": 148.0, "eval_episode/score": -0.9000000208616257, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 430040, "time": 21659.516205072403, "eval_episode/length": 148.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 430040, "time": 21663.418026447296, "eval_episode/length": 167.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 430040, "time": 21665.21796154976, "eval_episode/length": 172.0, "eval_episode/score": -0.9000000059604645, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 430040, "time": 21666.86043739319, "eval_episode/length": 175.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 430040, "time": 21669.847598791122, "eval_episode/length": 207.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9663461538461539}
{"step": 430040, "time": 21671.823732614517, "eval_episode/length": 220.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.995475113122172}
{"step": 430440, "time": 21686.701770544052, "episode/length": 145.0, "episode/score": 0.15851860539987683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15851860539987683}
{"step": 430800, "time": 21702.801707029343, "episode/length": 199.0, "episode/score": 0.1998549975687638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1998549975687638}
{"step": 430840, "time": 21706.160819768906, "episode/length": 226.0, "episode/score": 0.2479159172726213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2479159172726213}
{"step": 430976, "time": 21713.550367593765, "episode/length": 198.0, "episode/score": 0.22237250710531953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22237250710531953}
{"step": 431032, "time": 21717.379650115967, "episode/length": 142.0, "episode/score": 0.14906357540166937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14906357540166937}
{"step": 431048, "time": 21719.458365917206, "episode/length": 172.0, "episode/score": 0.1993346060771728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1993346060771728}
{"step": 431096, "time": 21722.67835688591, "episode/length": 180.0, "episode/score": 0.18967117958891322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18967117958891322}
{"step": 431512, "time": 21739.65841960907, "episode/length": 272.0, "episode/score": 0.30804731759781134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30804731759781134}
{"step": 432256, "time": 21769.070796728134, "episode/length": 159.0, "episode/score": 0.162174483310082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.162174483310082}
{"step": 432344, "time": 21773.702382087708, "episode/length": 187.0, "episode/score": 0.20273142198493588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20273142198493588}
{"step": 432352, "time": 21775.63437986374, "episode/length": 162.0, "episode/score": 0.17836169248948863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17836169248948863}
{"step": 432360, "time": 21777.198765277863, "episode/length": 165.0, "episode/score": 0.18935713966493495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18935713966493495}
{"step": 432368, "time": 21779.131903886795, "episode/length": 195.0, "episode/score": 0.21008341846209078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21008341846209078}
{"step": 432944, "time": 21802.34946012497, "episode/length": 85.0, "episode/score": 0.09124498748678889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09124498748678889}
{"step": 432984, "time": 21805.145530462265, "episode/length": 235.0, "episode/score": 0.2684252526869386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2684252526869386}
{"step": 433176, "time": 21813.79761815071, "episode/length": 207.0, "episode/score": 0.23237776173664315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23237776173664315}
{"step": 433624, "time": 21832.20178747177, "episode/length": 156.0, "episode/score": 0.16918315416842233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16918315416842233}
{"step": 433944, "time": 21845.779940605164, "episode/length": 437.0, "episode/score": 0.42750753350537707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42750753350537707}
{"step": 434208, "time": 21859.183487653732, "episode/length": 232.0, "episode/score": 0.24793715412124584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24793715412124584}
{"step": 434248, "time": 21861.924560785294, "episode/length": 162.0, "episode/score": 0.17072532853489975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17072532853489975}
{"step": 434496, "time": 21873.010308265686, "episode/length": 266.0, "episode/score": 0.29352525461399637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29352525461399637}
{"step": 434568, "time": 21877.025755167007, "episode/length": 197.0, "episode/score": 0.2109828855836895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2109828855836895}
{"step": 434584, "time": 21879.10851573944, "episode/length": 278.0, "episode/score": 0.30607535889794235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30607535889794235}
{"step": 434864, "time": 21891.232203245163, "episode/length": 154.0, "episode/score": 0.15239116458360513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15239116458360513}
{"step": 435392, "time": 21912.45050263405, "episode/length": 147.0, "episode/score": 0.17018524217110098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17018524217110098}
{"step": 435760, "time": 21928.07469010353, "episode/length": 157.0, "episode/score": 0.179775229174993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.179775229174993}
{"step": 435824, "time": 21932.02938556671, "episode/length": 156.0, "episode/score": 0.16435869364795508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16435869364795508}
{"step": 435840, "time": 21934.17822790146, "episode/length": 236.0, "episode/score": 0.23877996618648467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23877996618648467}
{"step": 435856, "time": 21936.244419813156, "episode/length": 158.0, "episode/score": 0.17289849169537774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17289849169537774}
{"step": 436264, "time": 21952.712856531143, "episode/length": 174.0, "episode/score": 0.1916442796427873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1916442796427873}
{"step": 436384, "time": 21959.04478573799, "episode/length": 266.0, "episode/score": 0.31019047027803026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31019047027803026}
{"step": 436464, "time": 21964.139382839203, "episode/length": 410.0, "episode/score": 0.4386214284140806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4386214284140806}
{"step": 436688, "time": 21974.75966310501, "episode/length": 161.0, "episode/score": 0.1661891307521728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1661891307521728}
{"step": 436840, "time": 21981.751089572906, "episode/length": 134.0, "episode/score": 0.14864305377705023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14864305377705023}
{"step": 436984, "time": 21988.55914926529, "episode/length": 144.0, "episode/score": 0.14902001070731785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14902001070731785}
{"step": 437120, "time": 21995.392769813538, "episode/length": 157.0, "episode/score": 0.1740491093005403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1740491093005403}
{"step": 437704, "time": 22018.53776407242, "episode/length": 232.0, "episode/score": 0.2476482502206636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2476482502206636}
{"step": 437872, "time": 22026.585666894913, "episode/length": 185.0, "episode/score": 0.2117347886924108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2117347886924108}
{"step": 438056, "time": 22034.810519695282, "episode/length": 223.0, "episode/score": 0.2505391589438659, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2505391589438659}
{"step": 438144, "time": 22039.91071343422, "episode/length": 181.0, "episode/score": 0.1758821994990285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1758821994990285}
{"step": 438272, "time": 22046.260914325714, "episode/length": 143.0, "episode/score": 0.14929898706213862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14929898706213862}
{"step": 438368, "time": 22051.362753629684, "episode/length": 237.0, "episode/score": 0.2550432894968253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2550432894968253}
{"step": 438992, "time": 22076.217003822327, "episode/length": 160.0, "episode/score": 0.17829004251689184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17829004251689184}
{"step": 439112, "time": 22081.99433016777, "episode/length": 283.0, "episode/score": 0.30171823033015244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30171823033015244}
{"step": 439168, "time": 22085.842769622803, "episode/length": 127.0, "episode/score": 0.14765277502010576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14765277502010576}
{"step": 439216, "time": 22089.26090502739, "episode/length": 144.0, "episode/score": 0.13440883550174476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13440883550174476}
{"step": 439264, "time": 22092.63329768181, "episode/length": 284.0, "episode/score": 0.30068111082619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30068111082619}
{"step": 439408, "time": 22099.704915761948, "episode/length": 191.0, "episode/score": 0.2161312939515483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2161312939515483}
{"step": 439504, "time": 22104.809706687927, "episode/length": 141.0, "episode/score": 0.140897802730251, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.140897802730251}
{"step": 439680, "time": 22112.824412822723, "episode/length": 70.0, "episode/score": 0.07746589940143167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07746589940143167}
{"step": 439760, "time": 22117.989582538605, "episode/length": 185.0, "episode/score": 0.19509299198580266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19509299198580266}
{"step": 440024, "time": 22148.667097091675, "eval_episode/length": 127.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9921875}
{"step": 440024, "time": 22151.12288236618, "eval_episode/length": 146.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 440024, "time": 22152.702311754227, "eval_episode/length": 147.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 440024, "time": 22152.709142684937, "eval_episode/length": 147.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 440024, "time": 22156.13164830208, "eval_episode/length": 154.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 440024, "time": 22158.08894920349, "eval_episode/length": 165.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 440024, "time": 22160.89197254181, "eval_episode/length": 195.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 440024, "time": 22164.20728993416, "eval_episode/length": 240.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.995850622406639}
{"step": 440192, "time": 22170.64308166504, "episode/length": 149.0, "episode/score": 0.15417304600850912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15417304600850912}
{"step": 440424, "time": 22180.67144227028, "episode/length": 144.0, "episode/score": 0.14862836294105364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14862836294105364}
{"step": 440640, "time": 22190.630696296692, "episode/length": 141.0, "episode/score": 0.14478152237006725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14478152237006725}
{"step": 440688, "time": 22193.989566087723, "episode/length": 183.0, "episode/score": 0.18809150235483685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18809150235483685}
{"step": 440744, "time": 22197.49839067459, "episode/length": 166.0, "episode/score": 0.17868384599751153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17868384599751153}
{"step": 440896, "time": 22204.965961933136, "episode/length": 215.0, "episode/score": 0.24085298694171797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24085298694171797}
{"step": 441040, "time": 22211.93822145462, "episode/length": 159.0, "episode/score": 0.16453980428832438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16453980428832438}
{"step": 441456, "time": 22228.942432641983, "episode/length": 221.0, "episode/score": 0.24742049310134462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24742049310134462}
{"step": 441560, "time": 22234.08486533165, "episode/length": 114.0, "episode/score": 0.12316724806623824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12316724806623824}
{"step": 441576, "time": 22236.304674386978, "episode/length": 143.0, "episode/score": 0.15703403388943116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15703403388943116}
{"step": 441984, "time": 22253.406777620316, "episode/length": 223.0, "episode/score": 0.2426590889426734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2426590889426734}
{"step": 442384, "time": 22271.243567466736, "episode/length": 185.0, "episode/score": 0.18923173517850955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18923173517850955}
{"step": 442504, "time": 22276.99576973915, "episode/length": 219.0, "episode/score": 0.23820872277156013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23820872277156013}
{"step": 442616, "time": 22282.748913764954, "episode/length": 240.0, "episode/score": 0.2706425757451143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2706425757451143}
{"step": 442752, "time": 22289.612639188766, "episode/length": 213.0, "episode/score": 0.21684023721536505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21684023721536505}
{"step": 442848, "time": 22294.896361351013, "episode/length": 158.0, "episode/score": 0.15831489787160535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15831489787160535}
{"step": 442944, "time": 22300.22167468071, "episode/length": 40.0, "episode/score": 0.045858629993745126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045858629993745126}
{"step": 442992, "time": 22303.686499357224, "episode/length": 178.0, "episode/score": 0.175676143234341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.175676143234341}
{"step": 443464, "time": 22322.497529745102, "episode/length": 184.0, "episode/score": 0.18646195445398916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18646195445398916}
{"step": 443465, "time": 22325.065624713898, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.636644151475695, "train/action_min": 0.0, "train/action_std": 4.464234613236927, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007976650278867474, "train/actor_opt_grad_steps": 26995.0, "train/actor_opt_loss": -4.523633941446269, "train/adv_mag": 0.1923710440122892, "train/adv_max": 0.13860250293972, "train/adv_mean": 0.00028462949686239346, "train/adv_min": -0.1910300346475745, "train/adv_std": 0.014365904957115178, "train/cont_avg": 0.9945281498015873, "train/cont_loss_mean": 0.0002031851753681987, "train/cont_loss_std": 0.005920424243786978, "train/cont_neg_acc": 0.9942932743874807, "train/cont_neg_loss": 0.012009517919126203, "train/cont_pos_acc": 0.9999531654138414, "train/cont_pos_loss": 0.00012324774991782981, "train/cont_pred": 0.9945130253595019, "train/cont_rate": 0.9945281498015873, "train/dyn_loss_mean": 11.888570906623961, "train/dyn_loss_std": 8.508626824333554, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15947229950319206, "train/extr_critic_critic_opt_grad_steps": 26995.0, "train/extr_critic_critic_opt_loss": 12261.963394407243, "train/extr_critic_mag": 0.2896141741010878, "train/extr_critic_max": 0.2896141741010878, "train/extr_critic_mean": 0.2377565104573492, "train/extr_critic_min": 0.0019009548520284986, "train/extr_critic_std": 0.057081409271747346, "train/extr_return_normed_mag": 0.19706216773816518, "train/extr_return_normed_max": 0.19706216773816518, "train/extr_return_normed_mean": 0.14514950485456557, "train/extr_return_normed_min": -0.09189945080923656, "train/extr_return_normed_std": 0.059095842054202444, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28995374862163786, "train/extr_return_raw_max": 0.28995374862163786, "train/extr_return_raw_mean": 0.2380410942529875, "train/extr_return_raw_min": 0.000992129719446576, "train/extr_return_raw_std": 0.05909584208376824, "train/extr_reward_mag": 0.0013124034518287296, "train/extr_reward_max": 0.0013124034518287296, "train/extr_reward_mean": 0.0010961606315085812, "train/extr_reward_min": 9.907616509331598e-06, "train/extr_reward_std": 0.0002407150117621299, "train/image_loss_mean": 5.895725452710712, "train/image_loss_std": 10.662707767789326, "train/model_loss_mean": 13.0686755028982, "train/model_loss_std": 14.208924013470847, "train/model_opt_grad_norm": 57.23401301247733, "train/model_opt_grad_steps": 26968.61111111111, "train/model_opt_loss": 17071.380851624504, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1309.5238095238096, "train/policy_entropy_mag": 2.7625032985021196, "train/policy_entropy_max": 2.7625032985021196, "train/policy_entropy_mean": 2.008420527927459, "train/policy_entropy_min": 0.08092827308509085, "train/policy_entropy_std": 0.6566931614800106, "train/policy_logprob_mag": 7.43792012002733, "train/policy_logprob_max": -0.009672967968360773, "train/policy_logprob_mean": -2.0074910606656755, "train/policy_logprob_min": -7.43792012002733, "train/policy_logprob_std": 1.2224735333805992, "train/policy_randomness_mag": 0.9750424358579848, "train/policy_randomness_max": 0.9750424358579848, "train/policy_randomness_mean": 0.7088843040050022, "train/policy_randomness_min": 0.028564128847349258, "train/policy_randomness_std": 0.23178386747364013, "train/post_ent_mag": 58.788547122289266, "train/post_ent_max": 58.788547122289266, "train/post_ent_mean": 40.70542081197103, "train/post_ent_min": 20.796666765969896, "train/post_ent_std": 7.042300110771542, "train/prior_ent_mag": 68.38744360303122, "train/prior_ent_max": 68.38744360303122, "train/prior_ent_mean": 52.66352877541194, "train/prior_ent_min": 31.163731786939834, "train/prior_ent_std": 5.741423224645947, "train/rep_loss_mean": 11.888570906623961, "train/rep_loss_std": 8.508626824333554, "train/reward_avg": 0.0010477236822240114, "train/reward_loss_mean": 0.03960437853894536, "train/reward_loss_std": 0.011844767878452936, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012915049280439103, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03960437868677434, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001047912307844926, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.4272726875814525, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.627272727272727, "train_stats/max_log_achievement_collect_sapling": 0.7090909090909091, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.8, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.045454545454545456, "train_stats/max_log_achievement_eat_cow": 0.01818181818181818, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.00909090909090909, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.4818181818181818, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.1, "train_stats/max_log_achievement_wake_up": 0.3090909090909091, "train_stats/mean_log_entropy": 2.1296585126356646, "eval_stats/sum_log_reward": 1.2249999707564712, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.1875, "eval_stats/max_log_achievement_collect_sapling": 0.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 9.285591659136117e-06, "report/cont_loss_std": 0.0002709329128265381, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001446799375116825, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.130154469654371e-07, "report/cont_pred": 0.994148313999176, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.38062572479248, "report/dyn_loss_std": 8.411046028137207, "report/image_loss_mean": 5.563035488128662, "report/image_loss_std": 8.169122695922852, "report/model_loss_mean": 13.63003921508789, "report/model_loss_std": 11.67677116394043, "report/post_ent_mag": 56.58625793457031, "report/post_ent_max": 56.58625793457031, "report/post_ent_mean": 39.55284118652344, "report/post_ent_min": 19.93599510192871, "report/post_ent_std": 6.819039821624756, "report/prior_ent_mag": 68.56343841552734, "report/prior_ent_max": 68.56343841552734, "report/prior_ent_mean": 53.17255401611328, "report/prior_ent_min": 31.941627502441406, "report/prior_ent_std": 5.103720188140869, "report/rep_loss_mean": 13.38062572479248, "report/rep_loss_std": 8.411046028137207, "report/reward_avg": 0.0010212506167590618, "report/reward_loss_mean": 0.0386195033788681, "report/reward_loss_std": 0.013078774325549603, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013155937194824219, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0386195033788681, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010553398169577122, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.504260348563548e-07, "eval/cont_loss_std": 4.4913695091963746e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 8.028777301660739e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.278647682236624e-07, "eval/cont_pred": 0.9970700740814209, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.97635269165039, "eval/dyn_loss_std": 10.097530364990234, "eval/image_loss_mean": 16.116796493530273, "eval/image_loss_std": 23.870141983032227, "eval/model_loss_mean": 27.551292419433594, "eval/model_loss_std": 28.056489944458008, "eval/post_ent_mag": 55.80372619628906, "eval/post_ent_max": 55.80372619628906, "eval/post_ent_mean": 39.44416809082031, "eval/post_ent_min": 20.34424591064453, "eval/post_ent_std": 6.967636585235596, "eval/prior_ent_mag": 68.56343841552734, "eval/prior_ent_max": 68.56343841552734, "eval/prior_ent_mean": 54.4494743347168, "eval/prior_ent_min": 35.4608039855957, "eval/prior_ent_std": 4.705201625823975, "eval/rep_loss_mean": 17.97635269165039, "eval/rep_loss_std": 10.097530364990234, "eval/reward_avg": 0.00644531287252903, "eval/reward_loss_mean": 0.6486837863922119, "eval/reward_loss_std": 3.4912383556365967, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013412237167358398, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.4347347915172577, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.3514404296875, "eval/reward_pred": 0.0010601598769426346, "eval/reward_rate": 0.0107421875, "replay/size": 442961.0, "replay/inserts": 20160.0, "replay/samples": 20160.0, "replay/insert_wait_avg": 1.3275988518245637e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.590604206872364e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 86456.0, "eval_replay/inserts": 3696.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1848680900804924e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4781472682953, "timer/env.step_count": 2520.0, "timer/env.step_total": 236.79728937149048, "timer/env.step_frac": 0.23668411950629967, "timer/env.step_avg": 0.09396717832202003, "timer/env.step_min": 0.022626399993896484, "timer/env.step_max": 2.153315305709839, "timer/replay._sample_count": 20160.0, "timer/replay._sample_total": 9.559938669204712, "timer/replay._sample_frac": 0.009555369795239566, "timer/replay._sample_avg": 0.000474203307004202, "timer/replay._sample_min": 0.00035858154296875, "timer/replay._sample_max": 0.010593891143798828, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2982.0, "timer/agent.policy_total": 47.56413149833679, "timer/agent.policy_frac": 0.04754139970793551, "timer/agent.policy_avg": 0.015950412977309453, "timer/agent.policy_min": 0.0095062255859375, "timer/agent.policy_max": 0.1104896068572998, "timer/dataset_train_count": 1260.0, "timer/dataset_train_total": 0.13263773918151855, "timer/dataset_train_frac": 0.00013257434911864146, "timer/dataset_train_avg": 0.00010526804696945917, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.000461578369140625, "timer/agent.train_count": 1260.0, "timer/agent.train_total": 567.3525338172913, "timer/agent.train_frac": 0.5670813854019602, "timer/agent.train_avg": 0.45027978874388197, "timer/agent.train_min": 0.4357583522796631, "timer/agent.train_max": 1.043630599975586, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47127342224121094, "timer/agent.report_frac": 0.0004710481918350496, "timer/agent.report_avg": 0.23563671112060547, "timer/agent.report_min": 0.22345900535583496, "timer/agent.report_max": 0.24781441688537598, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.431586735239127e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 20.15012995758182}
{"step": 443784, "time": 22336.891510009766, "episode/length": 174.0, "episode/score": 0.190364202652745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.190364202652745}
{"step": 443808, "time": 22339.512324810028, "episode/length": 162.0, "episode/score": 0.17233587489772617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17233587489772617}
{"step": 443928, "time": 22345.238600730896, "episode/length": 308.0, "episode/score": 0.3160549900003389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3160549900003389}
{"step": 444008, "time": 22349.71200656891, "episode/length": 144.0, "episode/score": 0.17396689147699362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17396689147699362}
{"step": 444256, "time": 22360.92334342003, "episode/length": 163.0, "episode/score": 0.1767841502878582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1767841502878582}
{"step": 444264, "time": 22362.572401046753, "episode/length": 158.0, "episode/score": 0.15658999826428044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15658999826428044}
{"step": 444344, "time": 22367.13198709488, "episode/length": 198.0, "episode/score": 0.19848852547420393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19848852547420393}
{"step": 444688, "time": 22381.751077890396, "episode/length": 42.0, "episode/score": 0.04396588704548776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04396588704548776}
{"step": 444720, "time": 22385.08474445343, "episode/length": 156.0, "episode/score": 0.16776612721878337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16776612721878337}
{"step": 445024, "time": 22398.07771205902, "episode/length": 151.0, "episode/score": 0.14895959809564374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14895959809564374}
{"step": 445224, "time": 22406.883100748062, "episode/length": 161.0, "episode/score": 0.16948425324926575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16948425324926575}
{"step": 445320, "time": 22411.96875667572, "episode/length": 163.0, "episode/score": 0.19025661248724646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19025661248724646}
{"step": 445592, "time": 22423.80152606964, "episode/length": 225.0, "episode/score": 0.23234510662950925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23234510662950925}
{"step": 445864, "time": 22435.444034337997, "episode/length": 200.0, "episode/score": 0.20112517755205772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20112517755205772}
{"step": 446192, "time": 22449.412279605865, "episode/length": 187.0, "episode/score": 0.20373289556800955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20373289556800955}
{"step": 446336, "time": 22456.253266334534, "episode/length": 163.0, "episode/score": 0.15308773780179763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15308773780179763}
{"step": 446384, "time": 22459.599435329437, "episode/length": 132.0, "episode/score": 0.1418332012267456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1418332012267456}
{"step": 446600, "time": 22469.21813774109, "episode/length": 291.0, "episode/score": 0.3121288136894691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3121288136894691}
{"step": 446712, "time": 22474.950225114822, "episode/length": 248.0, "episode/score": 0.2651448364126736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2651448364126736}
{"step": 446856, "time": 22481.91374850273, "episode/length": 157.0, "episode/score": 0.17372988563647596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17372988563647596}
{"step": 447112, "time": 22492.977545261383, "episode/length": 235.0, "episode/score": 0.2466895783641121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2466895783641121}
{"step": 447160, "time": 22496.191420078278, "episode/length": 161.0, "episode/score": 0.1758915165178223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1758915165178223}
{"step": 447520, "time": 22511.758440732956, "episode/length": 165.0, "episode/score": 0.18854160449200208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18854160449200208}
{"step": 447904, "time": 22527.40245461464, "episode/length": 162.0, "episode/score": 0.18007352280164923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18007352280164923}
{"step": 448072, "time": 22534.960979938507, "episode/length": 151.0, "episode/score": 0.14895562983519994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14895562983519994}
{"step": 448080, "time": 22537.03899717331, "episode/length": 211.0, "episode/score": 0.23514715971032274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23514715971032274}
{"step": 448088, "time": 22538.61775612831, "episode/length": 218.0, "episode/score": 0.23856471651424727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23856471651424727}
{"step": 448440, "time": 22553.16529560089, "episode/length": 165.0, "episode/score": 0.1802634906680396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1802634906680396}
{"step": 448808, "time": 22568.474977970123, "episode/length": 205.0, "episode/score": 0.2162187927051491, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2162187927051491}
{"step": 448832, "time": 22571.114680051804, "episode/length": 264.0, "episode/score": 0.3019362671880117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3019362671880117}
{"step": 449248, "time": 22588.028023958206, "episode/length": 145.0, "episode/score": 0.16111026957332797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16111026957332797}
{"step": 449248, "time": 22588.035954236984, "episode/length": 167.0, "episode/score": 0.18060522883115482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18060522883115482}
{"step": 449480, "time": 22599.60788679123, "episode/length": 175.0, "episode/score": 0.15806255362713273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15806255362713273}
{"step": 449568, "time": 22604.580766916275, "episode/length": 140.0, "episode/score": 0.13926108390296577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13926108390296577}
{"step": 449696, "time": 22610.809108018875, "episode/length": 26.0, "episode/score": 0.02911977161784307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02911977161784307}
{"step": 449736, "time": 22613.59691810608, "episode/length": 205.0, "episode/score": 0.20755748533247242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20755748533247242}
{"step": 449976, "time": 22624.68397808075, "episode/length": 142.0, "episode/score": 0.15076424444714576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15076424444714576}
{"step": 450008, "time": 22641.70244884491, "eval_episode/length": 46.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8936170212765957}
{"step": 450008, "time": 22648.16704106331, "eval_episode/length": 163.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9573170731707317}
{"step": 450008, "time": 22649.741622924805, "eval_episode/length": 165.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 450008, "time": 22652.016749858856, "eval_episode/length": 184.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 450008, "time": 22653.96956896782, "eval_episode/length": 197.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 450008, "time": 22656.472495794296, "eval_episode/length": 220.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.995475113122172}
{"step": 450008, "time": 22658.29078388214, "eval_episode/length": 224.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 450008, "time": 22660.14682817459, "eval_episode/length": 232.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9699570815450643}
{"step": 450472, "time": 22677.321887493134, "episode/length": 152.0, "episode/score": 0.17569528994044958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17569528994044958}
{"step": 450576, "time": 22684.506828308105, "episode/length": 381.0, "episode/score": 0.358222157236014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.358222157236014}
{"step": 450608, "time": 22687.206922531128, "episode/length": 169.0, "episode/score": 0.18692726171957474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18692726171957474}
{"step": 450856, "time": 22697.627100229263, "episode/length": 144.0, "episode/score": 0.13584532152390238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13584532152390238}
{"step": 451168, "time": 22710.886297225952, "episode/length": 199.0, "episode/score": 0.23912978446287525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23912978446287525}
{"step": 451224, "time": 22714.175208330154, "episode/length": 155.0, "episode/score": 0.18084985040468382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18084985040468382}
{"step": 451440, "time": 22724.029694080353, "episode/length": 212.0, "episode/score": 0.2385663983404811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2385663983404811}
{"step": 451896, "time": 22742.280177354813, "episode/length": 164.0, "episode/score": 0.19255356794747058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19255356794747058}
{"step": 451928, "time": 22744.998755931854, "episode/length": 181.0, "episode/score": 0.21191821544925915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21191821544925915}
{"step": 451984, "time": 22749.00432896614, "episode/length": 171.0, "episode/score": 0.17165065920562483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17165065920562483}
{"step": 452008, "time": 22751.170236587524, "episode/length": 143.0, "episode/score": 0.14966367881424958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14966367881424958}
{"step": 452096, "time": 22756.057096481323, "episode/length": 410.0, "episode/score": 0.44846348155851956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44846348155851956}
{"step": 452352, "time": 22767.00478744507, "episode/length": 147.0, "episode/score": 0.15126647275610594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15126647275610594}
{"step": 452416, "time": 22770.87606239319, "episode/length": 148.0, "episode/score": 0.1449516806023894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1449516806023894}
{"step": 452672, "time": 22782.111312627792, "episode/length": 153.0, "episode/score": 0.1541047212522244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1541047212522244}
{"step": 453120, "time": 22800.811411380768, "episode/length": 148.0, "episode/score": 0.17452798941303627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17452798941303627}
{"step": 453168, "time": 22804.284935951233, "episode/length": 158.0, "episode/score": 0.180191538111103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.180191538111103}
{"step": 453440, "time": 22816.520173072815, "episode/length": 181.0, "episode/score": 0.18512934737373143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18512934737373143}
{"step": 453616, "time": 22824.645990133286, "episode/length": 149.0, "episode/score": 0.16190009335514333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16190009335514333}
{"step": 453648, "time": 22827.40034508705, "episode/length": 161.0, "episode/score": 0.1779149376325222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1779149376325222}
{"step": 453656, "time": 22829.066843271255, "episode/length": 205.0, "episode/score": 0.2316568052774528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2316568052774528}
{"step": 453792, "time": 22835.890662431717, "episode/length": 211.0, "episode/score": 0.22828028613548668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22828028613548668}
{"step": 454136, "time": 22850.27257847786, "episode/length": 182.0, "episode/score": 0.20153646062681219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20153646062681219}
{"step": 454320, "time": 22858.76281762123, "episode/length": 143.0, "episode/score": 0.1608802227092383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1608802227092383}
{"step": 454728, "time": 22875.32940340042, "episode/length": 200.0, "episode/score": 0.2287006190563261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2287006190563261}
{"step": 454752, "time": 22877.999542474747, "episode/length": 163.0, "episode/score": 0.17173094350982865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17173094350982865}
{"step": 454816, "time": 22882.3233833313, "episode/length": 145.0, "episode/score": 0.15917658494436182, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15917658494436182}
{"step": 454928, "time": 22888.482758283615, "episode/length": 163.0, "episode/score": 0.1738665649027098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1738665649027098}
{"step": 455160, "time": 22898.30177283287, "episode/length": 187.0, "episode/score": 0.21773213855340146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21773213855340146}
{"step": 455384, "time": 22908.08696436882, "episode/length": 155.0, "episode/score": 0.16474921443295898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16474921443295898}
{"step": 455432, "time": 22911.350053548813, "episode/length": 138.0, "episode/score": 0.15254712739260867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15254712739260867}
{"step": 455544, "time": 22916.93664622307, "episode/length": 218.0, "episode/score": 0.2503070392558584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2503070392558584}
{"step": 455864, "time": 22930.459208726883, "episode/length": 141.0, "episode/score": 0.14490189903517603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14490189903517603}
{"step": 455976, "time": 22936.1654920578, "episode/length": 152.0, "episode/score": 0.16171898051470635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16171898051470635}
{"step": 456304, "time": 22950.145236730576, "episode/length": 185.0, "episode/score": 0.1933304769518145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1933304769518145}
{"step": 456352, "time": 22953.50276017189, "episode/length": 148.0, "episode/score": 0.1562304730323376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1562304730323376}
{"step": 456608, "time": 22964.629271268845, "episode/length": 209.0, "episode/score": 0.21989747498810175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21989747498810175}
{"step": 456632, "time": 22966.755677223206, "episode/length": 155.0, "episode/score": 0.15935333631568938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15935333631568938}
{"step": 456720, "time": 22971.90850186348, "episode/length": 146.0, "episode/score": 0.14991240271410788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14991240271410788}
{"step": 457040, "time": 22985.302050352097, "episode/length": 200.0, "episode/score": 0.21525771413143957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21525771413143957}
{"step": 457080, "time": 22988.204867601395, "episode/length": 151.0, "episode/score": 0.17362357606907608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17362357606907608}
{"step": 457144, "time": 22992.124257802963, "episode/length": 145.0, "episode/score": 0.1409330263522861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1409330263522861}
{"step": 457856, "time": 23020.29301404953, "episode/length": 193.0, "episode/score": 0.20446047371660825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20446047371660825}
{"step": 457856, "time": 23020.30209517479, "episode/length": 155.0, "episode/score": 0.1533156799596327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1533156799596327}
{"step": 458048, "time": 23030.751016139984, "episode/length": 165.0, "episode/score": 0.16853313456158503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16853313456158503}
{"step": 458144, "time": 23036.1897149086, "episode/length": 223.0, "episode/score": 0.25683806355300476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25683806355300476}
{"step": 458208, "time": 23040.084696769714, "episode/length": 196.0, "episode/score": 0.21605388456009678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21605388456009678}
{"step": 458328, "time": 23045.8061273098, "episode/length": 155.0, "episode/score": 0.1792499034672801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1792499034672801}
{"step": 458552, "time": 23055.84336090088, "episode/length": 188.0, "episode/score": 0.19902471684508782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19902471684508782}
{"step": 458664, "time": 23061.5990858078, "episode/length": 189.0, "episode/score": 0.2025405653348571, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2025405653348571}
{"step": 459136, "time": 23082.081336021423, "episode/length": 159.0, "episode/score": 0.17716659325014916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17716659325014916}
{"step": 459304, "time": 23089.527142047882, "episode/length": 156.0, "episode/score": 0.16401793098521011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16401793098521011}
{"step": 459608, "time": 23102.540328502655, "episode/length": 159.0, "episode/score": 0.15386911448331375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15386911448331375}
{"step": 459680, "time": 23107.182594776154, "episode/length": 191.0, "episode/score": 0.21709342134454346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21709342134454346}
{"step": 459680, "time": 23107.190890550613, "episode/length": 183.0, "episode/score": 0.20070700228279748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20070700228279748}
{"step": 459720, "time": 23111.57469677925, "episode/length": 145.0, "episode/score": 0.1672916637326125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1672916637326125}
{"step": 460096, "time": 23147.851897001266, "eval_episode/length": 169.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9588235294117647}
{"step": 460096, "time": 23150.539030313492, "eval_episode/length": 176.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 460096, "time": 23153.064006090164, "eval_episode/length": 186.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 460096, "time": 23155.18241071701, "eval_episode/length": 189.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 460096, "time": 23157.453845739365, "eval_episode/length": 197.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 460096, "time": 23160.24605035782, "eval_episode/length": 219.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 460096, "time": 23162.063423395157, "eval_episode/length": 227.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 460096, "time": 23163.99494075775, "eval_episode/length": 234.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9659574468085106}
{"step": 460344, "time": 23173.05792450905, "episode/length": 150.0, "episode/score": 0.17247269816016342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17247269816016342}
{"step": 460464, "time": 23179.241651773453, "episode/length": 224.0, "episode/score": 0.26222068289735034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26222068289735034}
{"step": 460848, "time": 23194.99428319931, "episode/length": 145.0, "episode/score": 0.1661835155564404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1661835155564404}
{"step": 460864, "time": 23197.262423992157, "episode/length": 147.0, "episode/score": 0.16171944169309427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16171944169309427}
{"step": 461024, "time": 23204.581419229507, "episode/length": 176.0, "episode/score": 0.1706230065701675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1706230065701675}
{"step": 461256, "time": 23214.54081749916, "episode/length": 243.0, "episode/score": 0.2591118903419556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2591118903419556}
{"step": 461488, "time": 23225.074067115784, "episode/length": 453.0, "episode/score": 0.47112539791851304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.47112539791851304}
{"step": 461728, "time": 23235.483563661575, "episode/length": 157.0, "episode/score": 0.15295242403590237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15295242403590237}
{"step": 461872, "time": 23242.367758750916, "episode/length": 190.0, "episode/score": 0.2055285734759309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2055285734759309}
{"step": 462152, "time": 23254.07167840004, "episode/length": 303.0, "episode/score": 0.328367584179432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.328367584179432}
{"step": 462528, "time": 23269.948579072952, "episode/length": 209.0, "episode/score": 0.23334285721011838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23334285721011838}
{"step": 462584, "time": 23273.304911613464, "episode/length": 165.0, "episode/score": 0.18847920752341452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18847920752341452}
{"step": 462744, "time": 23280.896479845047, "episode/length": 156.0, "episode/score": 0.1620862707895867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1620862707895867}
{"step": 462816, "time": 23285.27925801277, "episode/length": 243.0, "episode/score": 0.26874136256537895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26874136256537895}
{"step": 463016, "time": 23294.161021232605, "episode/length": 248.0, "episode/score": 0.26789564695445733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26789564695445733}
{"step": 463320, "time": 23307.11499118805, "episode/length": 145.0, "episode/score": 0.154557803647549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.154557803647549}
{"step": 463336, "time": 23309.244363069534, "episode/length": 182.0, "episode/score": 0.18982731436699396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18982731436699396}
{"step": 463705, "time": 23325.583695173264, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.849805559430804, "train/action_min": 0.0, "train/action_std": 4.563707767970978, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007899701125949385, "train/actor_opt_grad_steps": 28255.0, "train/actor_opt_loss": -13.956745443481301, "train/adv_mag": 0.19021541057598024, "train/adv_max": 0.13699671312693565, "train/adv_mean": -0.00022486718518617666, "train/adv_min": -0.18887228867600833, "train/adv_std": 0.014369235632734166, "train/cont_avg": 0.994566902281746, "train/cont_loss_mean": 0.00017172106671212295, "train/cont_loss_std": 0.005133715086466444, "train/cont_neg_acc": 0.9938888893127441, "train/cont_neg_loss": 0.01447187305441912, "train/cont_pos_acc": 0.9999688059564621, "train/cont_pos_loss": 7.691056630092825e-05, "train/cont_pred": 0.9945673171489958, "train/cont_rate": 0.994566902281746, "train/dyn_loss_mean": 11.71286960632082, "train/dyn_loss_std": 8.492281376369416, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1558783854402247, "train/extr_critic_critic_opt_grad_steps": 28255.0, "train/extr_critic_critic_opt_loss": 12236.732429625496, "train/extr_critic_mag": 0.2935735687376961, "train/extr_critic_max": 0.2935735687376961, "train/extr_critic_mean": 0.24115965952948917, "train/extr_critic_min": 0.0020387484913780576, "train/extr_critic_std": 0.05929957652494075, "train/extr_return_normed_mag": 0.20046828639885736, "train/extr_return_normed_max": 0.20046828639885736, "train/extr_return_normed_mean": 0.14733458014707718, "train/extr_return_normed_min": -0.09259475134904423, "train/extr_return_normed_std": 0.061425752612569974, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2940684604266333, "train/extr_return_raw_max": 0.2940684604266333, "train/extr_return_raw_mean": 0.24093475902364367, "train/extr_return_raw_min": 0.0010054225013369606, "train/extr_return_raw_std": 0.06142575299692533, "train/extr_reward_mag": 0.0013071487820337689, "train/extr_reward_max": 0.0013071487820337689, "train/extr_reward_mean": 0.0010942708255560507, "train/extr_reward_min": 9.402396186949715e-06, "train/extr_reward_std": 0.00023593730408705713, "train/image_loss_mean": 5.608222588660225, "train/image_loss_std": 10.198700965396942, "train/model_loss_mean": 12.67581540062314, "train/model_loss_std": 13.764297228010873, "train/model_opt_grad_norm": 57.325886272248766, "train/model_opt_grad_steps": 28227.539682539682, "train/model_opt_loss": 17878.581535218254, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1418.6507936507937, "train/policy_entropy_mag": 2.7616769775511725, "train/policy_entropy_max": 2.7616769775511725, "train/policy_entropy_mean": 2.0404478330460805, "train/policy_entropy_min": 0.08123309082455105, "train/policy_entropy_std": 0.6470902214447657, "train/policy_logprob_mag": 7.438055723432511, "train/policy_logprob_max": -0.00971378366802893, "train/policy_logprob_mean": -2.0388998029724, "train/policy_logprob_min": -7.438055723432511, "train/policy_logprob_std": 1.2013328288282668, "train/policy_randomness_mag": 0.9747507780317276, "train/policy_randomness_max": 0.9747507780317276, "train/policy_randomness_mean": 0.720188542017861, "train/policy_randomness_min": 0.0286717162511888, "train/policy_randomness_std": 0.22839445076764575, "train/post_ent_mag": 58.86891428629557, "train/post_ent_max": 58.86891428629557, "train/post_ent_mean": 40.977578571864534, "train/post_ent_min": 20.577133890182253, "train/post_ent_std": 7.045803554474362, "train/prior_ent_mag": 68.59160583738297, "train/prior_ent_max": 68.59160583738297, "train/prior_ent_mean": 52.779322911822604, "train/prior_ent_min": 31.81126494634719, "train/prior_ent_std": 5.6593386521415106, "train/rep_loss_mean": 11.71286960632082, "train/rep_loss_std": 8.492281376369416, "train/reward_avg": 0.0010503584349025336, "train/reward_loss_mean": 0.039699366759686244, "train/reward_loss_std": 0.011672062607156851, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012824346148778522, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03969936673012045, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010497986305771129, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.5363636056130583, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.4818181818181815, "train_stats/max_log_achievement_collect_sapling": 0.8363636363636363, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.7909090909090909, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.05454545454545454, "train_stats/max_log_achievement_eat_cow": 0.01818181818181818, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02727272727272727, "train_stats/max_log_achievement_make_wood_sword": 0.00909090909090909, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.38181818181818183, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.09090909090909091, "train_stats/max_log_achievement_wake_up": 0.3, "train_stats/mean_log_entropy": 2.1062745560299265, "eval_stats/sum_log_reward": 1.2874999763444066, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.5625, "eval_stats/max_log_achievement_collect_sapling": 0.8125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 1.6132886457853601e-06, "report/cont_loss_std": 2.0013354514958337e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.9029201212106273e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.4761557167730643e-06, "report/cont_pred": 0.9921862483024597, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 11.47973918914795, "report/dyn_loss_std": 8.621421813964844, "report/image_loss_mean": 6.002689838409424, "report/image_loss_std": 13.050146102905273, "report/model_loss_mean": 12.930225372314453, "report/model_loss_std": 16.698810577392578, "report/post_ent_mag": 57.45933151245117, "report/post_ent_max": 57.45933151245117, "report/post_ent_mean": 40.78260803222656, "report/post_ent_min": 19.886959075927734, "report/post_ent_std": 6.954412937164307, "report/prior_ent_mag": 68.8026351928711, "report/prior_ent_max": 68.8026351928711, "report/prior_ent_mean": 52.194480895996094, "report/prior_ent_min": 30.88860511779785, "report/prior_ent_std": 5.840873718261719, "report/rep_loss_mean": 11.47973918914795, "report/rep_loss_std": 8.621421813964844, "report/reward_avg": 0.0010482862126082182, "report/reward_loss_mean": 0.0396910086274147, "report/reward_loss_std": 0.011156543157994747, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013003349304199219, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0396910086274147, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010868777753785253, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.7706621469624224e-07, "eval/cont_loss_std": 1.369551569041505e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.457637881685514e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.492789062420343e-07, "eval/cont_pred": 0.9980466365814209, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 19.747406005859375, "eval/dyn_loss_std": 9.551517486572266, "eval/image_loss_mean": 19.632625579833984, "eval/image_loss_std": 23.27027130126953, "eval/model_loss_mean": 31.82642936706543, "eval/model_loss_std": 26.555374145507812, "eval/post_ent_mag": 54.00343322753906, "eval/post_ent_max": 54.00343322753906, "eval/post_ent_mean": 38.396385192871094, "eval/post_ent_min": 21.279619216918945, "eval/post_ent_std": 6.279414653778076, "eval/prior_ent_mag": 68.8026351928711, "eval/prior_ent_max": 68.8026351928711, "eval/prior_ent_mean": 54.471275329589844, "eval/prior_ent_min": 41.793701171875, "eval/prior_ent_std": 4.271590232849121, "eval/rep_loss_mean": 19.747406005859375, "eval/rep_loss_std": 9.551517486572266, "eval/reward_avg": 0.0040039061568677425, "eval/reward_loss_mean": 0.3453609347343445, "eval/reward_loss_std": 2.523178815841675, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013412237167358398, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.2267940789461136, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.462203979492188, "eval/reward_pred": 0.0010641487315297127, "eval/reward_rate": 0.005859375, "replay/size": 463201.0, "replay/inserts": 20240.0, "replay/samples": 20240.0, "replay/insert_wait_avg": 1.3015486977317116e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.757085114128505e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 90200.0, "eval_replay/inserts": 3744.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1903735307546763e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.5065848827362, "timer/env.step_count": 2530.0, "timer/env.step_total": 234.97128105163574, "timer/env.step_frac": 0.2348523084225132, "timer/env.step_avg": 0.09287402413108133, "timer/env.step_min": 0.02245044708251953, "timer/env.step_max": 3.126115560531616, "timer/replay._sample_count": 20240.0, "timer/replay._sample_total": 9.656137466430664, "timer/replay._sample_frac": 0.009651248289947442, "timer/replay._sample_avg": 0.0004770818906339261, "timer/replay._sample_min": 0.0003795623779296875, "timer/replay._sample_max": 0.020394325256347656, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2998.0, "timer/agent.policy_total": 48.34425497055054, "timer/agent.policy_frac": 0.04831977690203478, "timer/agent.policy_avg": 0.016125501991511186, "timer/agent.policy_min": 0.0094451904296875, "timer/agent.policy_max": 0.12290453910827637, "timer/dataset_train_count": 1265.0, "timer/dataset_train_total": 0.13360977172851562, "timer/dataset_train_frac": 0.00013354212130865215, "timer/dataset_train_avg": 0.00010562037290791749, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0008115768432617188, "timer/agent.train_count": 1265.0, "timer/agent.train_total": 567.1517798900604, "timer/agent.train_frac": 0.5668646148456216, "timer/agent.train_avg": 0.44834132797633236, "timer/agent.train_min": 0.43515443801879883, "timer/agent.train_max": 0.9538447856903076, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48245763778686523, "timer/agent.report_frac": 0.00048221335579056823, "timer/agent.report_avg": 0.24122881889343262, "timer/agent.report_min": 0.2329728603363037, "timer/agent.report_max": 0.24948477745056152, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.3361700541062275e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 20.229512857483314}
{"step": 463752, "time": 23327.230855941772, "episode/length": 116.0, "episode/score": 0.12156757592219947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12156757592219947}
{"step": 463792, "time": 23330.50959444046, "episode/length": 257.0, "episode/score": 0.3114996170706945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3114996170706945}
{"step": 463880, "time": 23335.03255224228, "episode/length": 168.0, "episode/score": 0.19120450962782343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19120450962782343}
{"step": 463928, "time": 23338.38723731041, "episode/length": 167.0, "episode/score": 0.19701405812702433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19701405812702433}
{"step": 464336, "time": 23355.322472333908, "episode/length": 164.0, "episode/score": 0.15780540163086698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15780540163086698}
{"step": 464376, "time": 23358.10640645027, "episode/length": 203.0, "episode/score": 0.2407306158393112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2407306158393112}
{"step": 464568, "time": 23366.711403608322, "episode/length": 155.0, "episode/score": 0.1643324317628867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1643324317628867}
{"step": 464760, "time": 23375.41806268692, "episode/length": 177.0, "episode/score": 0.17829571132460842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17829571132460842}
{"step": 465032, "time": 23387.143957853317, "episode/length": 154.0, "episode/score": 0.1631290142204307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1631290142204307}
{"step": 465424, "time": 23403.408824682236, "episode/length": 208.0, "episode/score": 0.2199520138765365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2199520138765365}
{"step": 465480, "time": 23406.983550310135, "episode/length": 193.0, "episode/score": 0.22838690048956778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22838690048956778}
{"step": 465504, "time": 23409.654423713684, "episode/length": 202.0, "episode/score": 0.2168862597336556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2168862597336556}
{"step": 465672, "time": 23417.17058134079, "episode/length": 166.0, "episode/score": 0.1769781408693234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1769781408693234}
{"step": 466400, "time": 23446.54220700264, "episode/length": 170.0, "episode/score": 0.18904554319306044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18904554319306044}
{"step": 466464, "time": 23450.45929503441, "episode/length": 212.0, "episode/score": 0.22842974614104605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22842974614104605}
{"step": 466600, "time": 23456.870443820953, "episode/length": 146.0, "episode/score": 0.16183770997304237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16183770997304237}
{"step": 466680, "time": 23461.23358774185, "episode/length": 263.0, "episode/score": 0.29921527253463864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29921527253463864}
{"step": 466760, "time": 23465.75919675827, "episode/length": 135.0, "episode/score": 0.16611110759549774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16611110759549774}
{"step": 466864, "time": 23471.557423830032, "episode/length": 172.0, "episode/score": 0.19867447785873082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19867447785873082}
{"step": 467224, "time": 23487.918718338013, "episode/length": 102.0, "episode/score": 0.12062102926938678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12062102926938678}
{"step": 467360, "time": 23494.70162463188, "episode/length": 372.0, "episode/score": 0.41669846140757727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41669846140757727}
{"step": 467624, "time": 23506.66922545433, "episode/length": 264.0, "episode/score": 0.2805475663917605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2805475663917605}
{"step": 467936, "time": 23520.574993610382, "episode/length": 166.0, "episode/score": 0.1867971545434557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1867971545434557}
{"step": 468312, "time": 23535.987483501434, "episode/length": 180.0, "episode/score": 0.2093690439214697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2093690439214697}
{"step": 468328, "time": 23538.15715932846, "episode/length": 137.0, "episode/score": 0.15808333066524938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15808333066524938}
{"step": 468576, "time": 23549.22392964363, "episode/length": 236.0, "episode/score": 0.2448283880512463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2448283880512463}
{"step": 469144, "time": 23572.653010606766, "episode/length": 222.0, "episode/score": 0.2510035578889074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2510035578889074}
{"step": 469312, "time": 23580.663867473602, "episode/length": 210.0, "episode/score": 0.23751798352168407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23751798352168407}
{"step": 469608, "time": 23593.17295026779, "episode/length": 355.0, "episode/score": 0.4033994302189967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4033994302189967}
{"step": 469728, "time": 23599.352126598358, "episode/length": 174.0, "episode/score": 0.1959701459563803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1959701459563803}
{"step": 469736, "time": 23600.919535160065, "episode/length": 408.0, "episode/score": 0.4640163723161095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4640163723161095}
{"step": 469896, "time": 23608.38143968582, "episode/length": 164.0, "episode/score": 0.18333705002442002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18333705002442002}
{"step": 470056, "time": 23615.863721609116, "episode/length": 264.0, "episode/score": 0.31282232613739325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31282232613739325}
{"step": 470080, "time": 23635.053317070007, "eval_episode/length": 88.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9438202247191011}
{"step": 470080, "time": 23639.012413740158, "eval_episode/length": 145.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9657534246575342}
{"step": 470080, "time": 23640.887997865677, "eval_episode/length": 153.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 470080, "time": 23642.690977334976, "eval_episode/length": 158.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 470080, "time": 23644.932181596756, "eval_episode/length": 176.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 470080, "time": 23646.93514895439, "eval_episode/length": 185.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 470080, "time": 23648.537200689316, "eval_episode/length": 188.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 470080, "time": 23651.8416326046, "eval_episode/length": 230.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 470424, "time": 23664.505071163177, "episode/length": 86.0, "episode/score": 0.09411837344123342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09411837344123342}
{"step": 470472, "time": 23668.176874637604, "episode/length": 165.0, "episode/score": 0.17009198146115523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17009198146115523}
{"step": 470632, "time": 23676.164945840836, "episode/length": 164.0, "episode/score": 0.16933961596078007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16933961596078007}
{"step": 470704, "time": 23680.69296336174, "episode/length": 298.0, "episode/score": 0.3511400365823647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3511400365823647}
{"step": 470952, "time": 23691.306322574615, "episode/length": 167.0, "episode/score": 0.18261733877807274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18261733877807274}
{"step": 471216, "time": 23702.999796390533, "episode/length": 164.0, "episode/score": 0.18969764876055706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18969764876055706}
{"step": 471320, "time": 23708.232596874237, "episode/length": 157.0, "episode/score": 0.1688676422345452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1688676422345452}
{"step": 471640, "time": 23721.733333587646, "episode/length": 237.0, "episode/score": 0.27522898966344655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27522898966344655}
{"step": 471808, "time": 23729.807705163956, "episode/length": 137.0, "episode/score": 0.13395469087117817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13395469087117817}
{"step": 471928, "time": 23735.63197827339, "episode/length": 181.0, "episode/score": 0.20491598510125186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20491598510125186}
{"step": 471952, "time": 23738.38196015358, "episode/length": 164.0, "episode/score": 0.18001333997563052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18001333997563052}
{"step": 472632, "time": 23765.118760585785, "episode/length": 163.0, "episode/score": 0.18225291087583173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18225291087583173}
{"step": 472632, "time": 23765.129333019257, "episode/length": 275.0, "episode/score": 0.3196105782462837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3196105782462837}
{"step": 472720, "time": 23771.725561618805, "episode/length": 187.0, "episode/score": 0.20399839731908287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20399839731908287}
{"step": 472960, "time": 23782.213990688324, "episode/length": 250.0, "episode/score": 0.2824557264721079, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2824557264721079}
{"step": 473024, "time": 23786.253057956696, "episode/length": 136.0, "episode/score": 0.1489074349810835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1489074349810835}
{"step": 473344, "time": 23799.86386537552, "episode/length": 173.0, "episode/score": 0.191629237455345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.191629237455345}
{"step": 473376, "time": 23802.572008132935, "episode/length": 216.0, "episode/score": 0.2415857860178221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2415857860178221}
{"step": 473440, "time": 23806.481321811676, "episode/length": 203.0, "episode/score": 0.20825082529336214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20825082529336214}
{"step": 473448, "time": 23808.088025331497, "episode/length": 52.0, "episode/score": 0.062291665468364954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062291665468364954}
{"step": 473928, "time": 23827.58887195587, "episode/length": 150.0, "episode/score": 0.17070894720382057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17070894720382057}
{"step": 474568, "time": 23853.11725783348, "episode/length": 241.0, "episode/score": 0.2698825520055834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2698825520055834}
{"step": 474608, "time": 23856.32511973381, "episode/length": 157.0, "episode/score": 0.1577883279933303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1577883279933303}
{"step": 474656, "time": 23859.861624717712, "episode/length": 151.0, "episode/score": 0.1718691695787129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1718691695787129}
{"step": 474768, "time": 23865.73935174942, "episode/length": 164.0, "episode/score": 0.19217381754424423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19217381754424423}
{"step": 474816, "time": 23869.00334095955, "episode/length": 231.0, "episode/score": 0.2576193520799279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2576193520799279}
{"step": 474856, "time": 23871.792712926865, "episode/length": 184.0, "episode/score": 0.20295335586706642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20295335586706642}
{"step": 474896, "time": 23875.00072336197, "episode/length": 282.0, "episode/score": 0.3206278056750307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3206278056750307}
{"step": 475288, "time": 23892.449647903442, "episode/length": 169.0, "episode/score": 0.20250694049173035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20250694049173035}
{"step": 475792, "time": 23913.042835712433, "episode/length": 147.0, "episode/score": 0.16140338282639277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16140338282639277}
{"step": 475832, "time": 23915.912180900574, "episode/length": 67.0, "episode/score": 0.07284806043026038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07284806043026038}
{"step": 475840, "time": 23918.07097196579, "episode/length": 147.0, "episode/score": 0.17005494882323546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17005494882323546}
{"step": 475904, "time": 23922.08592414856, "episode/length": 166.0, "episode/score": 0.18298750805661257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18298750805661257}
{"step": 476184, "time": 23933.9338452816, "episode/length": 160.0, "episode/score": 0.16853117124082928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16853117124082928}
{"step": 476712, "time": 23955.367268800735, "episode/length": 242.0, "episode/score": 0.28258165141050995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28258165141050995}
{"step": 477040, "time": 23969.35139799118, "episode/length": 150.0, "episode/score": 0.15161714109308377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15161714109308377}
{"step": 477040, "time": 23969.359228134155, "episode/length": 155.0, "episode/score": 0.171646804888951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.171646804888951}
{"step": 477056, "time": 23973.073981523514, "episode/length": 279.0, "episode/score": 0.3023802990337572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3023802990337572}
{"step": 477240, "time": 23981.609830141068, "episode/length": 297.0, "episode/score": 0.3356042334362428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3356042334362428}
{"step": 477528, "time": 23994.412750005722, "episode/length": 210.0, "episode/score": 0.22319754332602315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22319754332602315}
{"step": 477704, "time": 24002.59979248047, "episode/length": 224.0, "episode/score": 0.25106479960959405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25106479960959405}
{"step": 477744, "time": 24005.731428861618, "episode/length": 194.0, "episode/score": 0.2060100790549768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2060100790549768}
{"step": 477912, "time": 24013.34683227539, "episode/length": 149.0, "episode/score": 0.16168597736395895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16168597736395895}
{"step": 478272, "time": 24028.533291578293, "episode/length": 153.0, "episode/score": 0.15730322345189052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15730322345189052}
{"step": 478536, "time": 24039.726485967636, "episode/length": 186.0, "episode/score": 0.20699921624327544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20699921624327544}
{"step": 478968, "time": 24057.51333117485, "episode/length": 157.0, "episode/score": 0.17334436616147286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17334436616147286}
{"step": 479152, "time": 24066.092754602432, "episode/length": 202.0, "episode/score": 0.21592502186103957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21592502186103957}
{"step": 479224, "time": 24070.290706157684, "episode/length": 163.0, "episode/score": 0.17904912615267676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17904912615267676}
{"step": 479224, "time": 24070.298674345016, "episode/length": 184.0, "episode/score": 0.21163428733780165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21163428733780165}
{"step": 479272, "time": 24075.26533961296, "episode/length": 253.0, "episode/score": 0.30119380708492827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30119380708492827}
{"step": 479560, "time": 24087.541862249374, "episode/length": 160.0, "episode/score": 0.168320405526174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.168320405526174}
{"step": 479656, "time": 24092.757656812668, "episode/length": 324.0, "episode/score": 0.35939692189276684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35939692189276684}
{"step": 480064, "time": 24128.089319705963, "eval_episode/length": 112.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9557522123893806}
{"step": 480064, "time": 24131.782183885574, "eval_episode/length": 149.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 480064, "time": 24133.9973590374, "eval_episode/length": 155.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 480064, "time": 24136.13689160347, "eval_episode/length": 161.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 480064, "time": 24138.21657562256, "eval_episode/length": 165.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 480064, "time": 24140.65634036064, "eval_episode/length": 172.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 480064, "time": 24142.795167207718, "eval_episode/length": 175.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 480064, "time": 24147.86315345764, "eval_episode/length": 252.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9960474308300395}
{"step": 480352, "time": 24158.7436003685, "episode/length": 226.0, "episode/score": 0.2615502486805781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2615502486805781}
{"step": 480440, "time": 24163.378467321396, "episode/length": 151.0, "episode/score": 0.1758634507386887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1758634507386887}
{"step": 480616, "time": 24171.490294218063, "episode/length": 167.0, "episode/score": 0.19698881762451492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19698881762451492}
{"step": 480760, "time": 24178.36826491356, "episode/length": 191.0, "episode/score": 0.21136220632070035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21136220632070035}
{"step": 480784, "time": 24180.90903711319, "episode/length": 203.0, "episode/score": 0.23401012127214926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23401012127214926}
{"step": 480904, "time": 24186.893543481827, "episode/length": 241.0, "episode/score": 0.2642320113518508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2642320113518508}
{"step": 480992, "time": 24191.90314435959, "episode/length": 166.0, "episode/score": 0.1863961270209984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1863961270209984}
{"step": 481032, "time": 24194.70678281784, "episode/length": 183.0, "episode/score": 0.20699622887696023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20699622887696023}
{"step": 481640, "time": 24218.896870613098, "episode/length": 75.0, "episode/score": 0.08091057485580677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08091057485580677}
{"step": 481856, "time": 24229.507020950317, "episode/length": 154.0, "episode/score": 0.18833332957001403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18833332957001403}
{"step": 481880, "time": 24231.620581626892, "episode/length": 190.0, "episode/score": 0.21749999618623406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21749999618623406}
{"step": 481904, "time": 24234.273579597473, "episode/length": 142.0, "episode/score": 0.15608554826758336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15608554826758336}
{"step": 482240, "time": 24248.468326807022, "episode/length": 224.0, "episode/score": 0.26399999525165185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26399999525165185}
{"step": 482304, "time": 24252.34773373604, "episode/length": 189.0, "episode/score": 0.2225168607546948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2225168607546948}
{"step": 482600, "time": 24264.85594344139, "episode/length": 200.0, "episode/score": 0.22957521243370138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22957521243370138}
{"step": 482672, "time": 24269.36102247238, "episode/length": 220.0, "episode/score": 0.23669606093608309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23669606093608309}
{"step": 483064, "time": 24285.392800569534, "episode/length": 177.0, "episode/score": 0.19068410056934226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19068410056934226}
{"step": 483360, "time": 24299.5619661808, "episode/length": 139.0, "episode/score": 0.1555299763494986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1555299763494986}
{"step": 483520, "time": 24307.040848731995, "episode/length": 151.0, "episode/score": 0.15507525425346103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15507525425346103}
{"step": 483720, "time": 24315.80013179779, "episode/length": 232.0, "episode/score": 0.25577842172424425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25577842172424425}
{"step": 483784, "time": 24319.656386613846, "episode/length": 237.0, "episode/score": 0.2511999208982161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2511999208982161}
{"step": 483808, "time": 24322.26305127144, "episode/length": 237.0, "episode/score": 0.2642434583794966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2642434583794966}
{"step": 483833, "time": 24325.599623203278, "train_stats/sum_log_reward": 1.7355140066731756, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.037383177570093, "train_stats/max_log_achievement_collect_sapling": 1.0373831775700935, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.9158878504672897, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.1588785046728972, "train_stats/max_log_achievement_eat_cow": 0.028037383177570093, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009345794392523364, "train_stats/max_log_achievement_make_wood_sword": 0.018691588785046728, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.3644859813084112, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.1308411214953271, "train_stats/max_log_achievement_wake_up": 0.2897196261682243, "train_stats/mean_log_entropy": 2.0146055433237664, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.7412521120101685, "train/action_min": 0.0, "train/action_std": 4.483597967359755, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008080932470629848, "train/actor_opt_grad_steps": 29515.0, "train/actor_opt_loss": -18.326099904993224, "train/adv_mag": 0.18160819138089815, "train/adv_max": 0.12850909266206953, "train/adv_mean": -0.00038351650095246026, "train/adv_min": -0.18048554729847682, "train/adv_std": 0.01415042176340071, "train/cont_avg": 0.994597904265873, "train/cont_loss_mean": 0.0001209748885584203, "train/cont_loss_std": 0.003353706360593649, "train/cont_neg_acc": 0.9986772489926171, "train/cont_neg_loss": 0.004684182357958355, "train/cont_pos_acc": 0.9999765961889236, "train/cont_pos_loss": 9.902179743272022e-05, "train/cont_pred": 0.9945652432857998, "train/cont_rate": 0.994597904265873, "train/dyn_loss_mean": 11.749192714691162, "train/dyn_loss_std": 8.520259051095872, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1661546840258534, "train/extr_critic_critic_opt_grad_steps": 29515.0, "train/extr_critic_critic_opt_loss": 11855.99169921875, "train/extr_critic_mag": 0.29408941855506293, "train/extr_critic_max": 0.29408941855506293, "train/extr_critic_mean": 0.23214656977899492, "train/extr_critic_min": 0.001456146202390156, "train/extr_critic_std": 0.0627924692003973, "train/extr_return_normed_mag": 0.22037581212463833, "train/extr_return_normed_max": 0.22037581212463833, "train/extr_return_normed_mean": 0.1580018007329532, "train/extr_return_normed_min": -0.07279548344631044, "train/extr_return_normed_std": 0.064431740503226, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2941370604057161, "train/extr_return_raw_max": 0.2941370604057161, "train/extr_return_raw_mean": 0.23176305208887374, "train/extr_return_raw_min": 0.0009657645982409281, "train/extr_return_raw_std": 0.06443174020756805, "train/extr_reward_mag": 0.0013183308026147268, "train/extr_reward_max": 0.0013183308026147268, "train/extr_reward_mean": 0.0011001090705764318, "train/extr_reward_min": 9.833820282466828e-06, "train/extr_reward_std": 0.0002357531398985653, "train/image_loss_mean": 5.524901331417144, "train/image_loss_std": 10.215175102627466, "train/model_loss_mean": 12.614085341256763, "train/model_loss_std": 13.786711488451276, "train/model_opt_grad_norm": 59.74701984344967, "train/model_opt_grad_steps": 29486.095238095237, "train/model_opt_loss": 9600.438732328868, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 753.968253968254, "train/policy_entropy_mag": 2.7599634253789507, "train/policy_entropy_max": 2.7599634253789507, "train/policy_entropy_mean": 1.969848991386474, "train/policy_entropy_min": 0.08089149211134229, "train/policy_entropy_std": 0.6413380584073445, "train/policy_logprob_mag": 7.4382030547611295, "train/policy_logprob_max": -0.009665784884303336, "train/policy_logprob_mean": -1.9696400799448528, "train/policy_logprob_min": -7.4382030547611295, "train/policy_logprob_std": 1.2349325522543892, "train/policy_randomness_mag": 0.9741459720664554, "train/policy_randomness_max": 0.9741459720664554, "train/policy_randomness_mean": 0.695270247875698, "train/policy_randomness_min": 0.028551146905455325, "train/policy_randomness_std": 0.2263641921537263, "train/post_ent_mag": 58.67646480741955, "train/post_ent_max": 58.67646480741955, "train/post_ent_mean": 40.831577603779145, "train/post_ent_min": 20.610226827954488, "train/post_ent_std": 6.987696344890292, "train/prior_ent_mag": 68.53499106755332, "train/prior_ent_max": 68.53499106755332, "train/prior_ent_mean": 52.68738704257541, "train/prior_ent_min": 32.30870664687384, "train/prior_ent_std": 5.653243590915014, "train/rep_loss_mean": 11.749192714691162, "train/rep_loss_std": 8.520259051095872, "train/reward_avg": 0.0010461595047095288, "train/reward_loss_mean": 0.03954743735847019, "train/reward_loss_std": 0.01186577095428393, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012846731004260835, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03954743735847019, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010468256881549245, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.5374999977648258, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.25, "eval_stats/max_log_achievement_collect_sapling": 0.6875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.25, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.00023962189152371138, "report/cont_loss_std": 0.007634310517460108, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002623303444124758, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0002395551564404741, "report/cont_pred": 0.9968591928482056, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.985766410827637, "report/dyn_loss_std": 8.418424606323242, "report/image_loss_mean": 5.861645221710205, "report/image_loss_std": 12.3228759765625, "report/model_loss_mean": 13.691268920898438, "report/model_loss_std": 15.880584716796875, "report/post_ent_mag": 55.31056213378906, "report/post_ent_max": 55.31056213378906, "report/post_ent_mean": 39.338645935058594, "report/post_ent_min": 19.74407196044922, "report/post_ent_std": 6.740976333618164, "report/prior_ent_mag": 68.65685272216797, "report/prior_ent_max": 68.65685272216797, "report/prior_ent_mean": 52.874568939208984, "report/prior_ent_min": 37.152557373046875, "report/prior_ent_std": 4.7408576011657715, "report/rep_loss_mean": 12.985766410827637, "report/rep_loss_std": 8.418424606323242, "report/reward_avg": 0.0009993702406063676, "report/reward_loss_mean": 0.037923384457826614, "report/reward_loss_std": 0.013467971235513687, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012606382369995117, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03792338818311691, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0009891703957691789, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.283201658632606e-05, "eval/cont_loss_std": 0.001032909844070673, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0001261199067812413, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.255790579714812e-05, "eval/cont_pred": 0.9970388412475586, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.272180557250977, "eval/dyn_loss_std": 10.760818481445312, "eval/image_loss_mean": 18.76810646057129, "eval/image_loss_std": 21.658170700073242, "eval/model_loss_mean": 30.994958877563477, "eval/model_loss_std": 26.363218307495117, "eval/post_ent_mag": 55.78105163574219, "eval/post_ent_max": 55.78105163574219, "eval/post_ent_mean": 39.21522521972656, "eval/post_ent_min": 19.786907196044922, "eval/post_ent_std": 6.330104827880859, "eval/prior_ent_mag": 68.65685272216797, "eval/prior_ent_max": 68.65685272216797, "eval/prior_ent_mean": 54.45423126220703, "eval/prior_ent_min": 30.846221923828125, "eval/prior_ent_std": 4.549637317657471, "eval/rep_loss_mean": 19.272180557250977, "eval/rep_loss_std": 10.760818481445312, "eval/reward_avg": 0.0072265625931322575, "eval/reward_loss_mean": 0.6635111570358276, "eval/reward_loss_std": 3.513404607772827, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012557506561279297, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.447856605052948, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.523338317871094, "eval/reward_pred": 0.0009916686685755849, "eval/reward_rate": 0.0107421875, "replay/size": 483329.0, "replay/inserts": 20128.0, "replay/samples": 20128.0, "replay/insert_wait_avg": 1.326677151059877e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.808895482546953e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 94072.0, "eval_replay/inserts": 3872.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.218878040628985e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0022163391113, "timer/env.step_count": 2516.0, "timer/env.step_total": 231.33697247505188, "timer/env.step_frac": 0.23133645975500824, "timer/env.step_avg": 0.09194633246226228, "timer/env.step_min": 0.022485017776489258, "timer/env.step_max": 3.1653642654418945, "timer/replay._sample_count": 20128.0, "timer/replay._sample_total": 9.703543186187744, "timer/replay._sample_frac": 0.009703521679893128, "timer/replay._sample_avg": 0.000482091771968787, "timer/replay._sample_min": 0.0004019737243652344, "timer/replay._sample_max": 0.010875940322875977, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3000.0, "timer/agent.policy_total": 48.541768074035645, "timer/agent.policy_frac": 0.04854166048925497, "timer/agent.policy_avg": 0.016180589358011883, "timer/agent.policy_min": 0.009753942489624023, "timer/agent.policy_max": 0.10628914833068848, "timer/dataset_train_count": 1258.0, "timer/dataset_train_total": 0.138596773147583, "timer/dataset_train_frac": 0.00013859646597081478, "timer/dataset_train_avg": 0.00011017231569760176, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0010862350463867188, "timer/agent.train_count": 1258.0, "timer/agent.train_total": 567.7114086151123, "timer/agent.train_frac": 0.5677101503769021, "timer/agent.train_avg": 0.45128092894683014, "timer/agent.train_min": 0.43790102005004883, "timer/agent.train_max": 1.0826094150543213, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48075270652770996, "timer/agent.report_frac": 0.00048075164101904516, "timer/agent.report_avg": 0.24037635326385498, "timer/agent.report_min": 0.2342991828918457, "timer/agent.report_max": 0.24645352363586426, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.457061734951523e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 20.127700371419003}
{"step": 484080, "time": 24335.099497556686, "episode/length": 184.0, "episode/score": 0.20181310151019716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20181310151019716}
{"step": 484136, "time": 24338.621942043304, "episode/length": 182.0, "episode/score": 0.2116092917349306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2116092917349306}
{"step": 484168, "time": 24341.374477624893, "episode/length": 137.0, "episode/score": 0.1312909747066442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1312909747066442}
{"step": 484744, "time": 24364.186344623566, "episode/length": 119.0, "episode/score": 0.133285179399536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.133285179399536}
{"step": 484928, "time": 24372.861170768738, "episode/length": 175.0, "episode/score": 0.1911424887366593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1911424887366593}
{"step": 484968, "time": 24375.623819351196, "episode/length": 144.0, "episode/score": 0.16760836887988262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16760836887988262}
{"step": 485032, "time": 24379.536962032318, "episode/length": 163.0, "episode/score": 0.16728115385194542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16728115385194542}
{"step": 485456, "time": 24397.254903316498, "episode/length": 171.0, "episode/score": 0.1743644172565837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1743644172565837}
{"step": 485640, "time": 24405.40930581093, "episode/length": 187.0, "episode/score": 0.19093530942336656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19093530942336656}
{"step": 485752, "time": 24411.119944810867, "episode/length": 197.0, "episode/score": 0.21382446821735357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21382446821735357}
{"step": 486120, "time": 24426.376709222794, "episode/length": 148.0, "episode/score": 0.1600883418104786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1600883418104786}
{"step": 486152, "time": 24429.31533241272, "episode/length": 175.0, "episode/score": 0.203782491338643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.203782491338643}
{"step": 486384, "time": 24440.087265253067, "episode/length": 168.0, "episode/score": 0.19629509365040576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19629509365040576}
{"step": 486800, "time": 24457.16620373726, "episode/length": 429.0, "episode/score": 0.4717879911131604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4717879911131604}
{"step": 486832, "time": 24459.869844675064, "episode/length": 232.0, "episode/score": 0.24560660140559776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24560660140559776}
{"step": 486952, "time": 24465.69700360298, "episode/length": 163.0, "episode/score": 0.17437517925827706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17437517925827706}
{"step": 487032, "time": 24470.14200568199, "episode/length": 196.0, "episode/score": 0.2235328671777097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2235328671777097}
{"step": 487072, "time": 24473.40417098999, "episode/length": 164.0, "episode/score": 0.15901487766677747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15901487766677747}
{"step": 487816, "time": 24502.505118608475, "episode/length": 211.0, "episode/score": 0.22879079003541847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22879079003541847}
{"step": 487936, "time": 24510.060452461243, "episode/length": 222.0, "episode/score": 0.25635552687526797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25635552687526797}
{"step": 488008, "time": 24513.999699115753, "episode/length": 150.0, "episode/score": 0.15959451197340968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15959451197340968}
{"step": 488256, "time": 24525.10057401657, "episode/length": 162.0, "episode/score": 0.1556434483572957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1556434483572957}
{"step": 488288, "time": 24527.897696733475, "episode/length": 237.0, "episode/score": 0.27141917355584155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27141917355584155}
{"step": 488368, "time": 24532.387431383133, "episode/length": 166.0, "episode/score": 0.16424662849749438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16424662849749438}
{"step": 488536, "time": 24539.973163366318, "episode/length": 212.0, "episode/score": 0.23566144429787528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23566144429787528}
{"step": 489320, "time": 24570.830251693726, "episode/length": 187.0, "episode/score": 0.19144730374409846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19144730374409846}
{"step": 489448, "time": 24577.264763116837, "episode/length": 148.0, "episode/score": 0.15869460512476508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15869460512476508}
{"step": 489448, "time": 24577.272959947586, "episode/length": 179.0, "episode/score": 0.19109515815125633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19109515815125633}
{"step": 490048, "time": 24617.708773374557, "eval_episode/length": 51.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9038461538461539}
{"step": 490048, "time": 24623.2372238636, "eval_episode/length": 149.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.96}
{"step": 490048, "time": 24625.42130422592, "eval_episode/length": 163.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 490048, "time": 24627.77178621292, "eval_episode/length": 184.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 490048, "time": 24629.811280965805, "eval_episode/length": 193.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9896907216494846}
{"step": 490048, "time": 24632.097586631775, "eval_episode/length": 211.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 490048, "time": 24633.95286846161, "eval_episode/length": 220.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.995475113122172}
{"step": 490048, "time": 24637.905482053757, "eval_episode/length": 222.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 490160, "time": 24642.071748018265, "episode/length": 277.0, "episode/score": 0.30610597874874657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30610597874874657}
{"step": 490264, "time": 24647.18751502037, "episode/length": 246.0, "episode/score": 0.2960654702910688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2960654702910688}
{"step": 490360, "time": 24652.870931625366, "episode/length": 248.0, "episode/score": 0.2620427650072088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2620427650072088}
{"step": 490552, "time": 24661.570976495743, "episode/length": 251.0, "episode/score": 0.2767848556804893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2767848556804893}
{"step": 490648, "time": 24666.59130859375, "episode/length": 446.0, "episode/score": 0.47186288984721614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.47186288984721614}
{"step": 490680, "time": 24669.3815202713, "episode/length": 153.0, "episode/score": 0.17370833054883406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17370833054883406}
{"step": 490824, "time": 24676.245141983032, "episode/length": 187.0, "episode/score": 0.20499888883023232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20499888883023232}
{"step": 491016, "time": 24685.56925201416, "episode/length": 45.0, "episode/score": 0.05258127187698847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05258127187698847}
{"step": 491144, "time": 24691.763764619827, "episode/length": 211.0, "episode/score": 0.2446811040654211, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2446811040654211}
{"step": 491984, "time": 24726.309497833252, "episode/length": 162.0, "episode/score": 0.16616192326546297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16616192326546297}
{"step": 492016, "time": 24729.176218032837, "episode/length": 182.0, "episode/score": 0.1821373000202584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1821373000202584}
{"step": 492120, "time": 24734.265793561935, "episode/length": 231.0, "episode/score": 0.26929493588613695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26929493588613695}
{"step": 492168, "time": 24737.590396404266, "episode/length": 143.0, "episode/score": 0.17092238252280367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17092238252280367}
{"step": 492336, "time": 24745.59108877182, "episode/length": 246.0, "episode/score": 0.2787928069874397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2787928069874397}
{"step": 492352, "time": 24747.738198041916, "episode/length": 190.0, "episode/score": 0.2187795318868666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2187795318868666}
{"step": 492648, "time": 24760.057647705078, "episode/length": 310.0, "episode/score": 0.36691711877392663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.36691711877392663}
{"step": 492656, "time": 24762.02519917488, "episode/length": 188.0, "episode/score": 0.1997100179978588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1997100179978588}
{"step": 492848, "time": 24770.621034145355, "episode/length": 107.0, "episode/score": 0.1331249971408397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1331249971408397}
{"step": 493480, "time": 24795.59560084343, "episode/length": 182.0, "episode/score": 0.16908519073331263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16908519073331263}
{"step": 493696, "time": 24805.33828687668, "episode/length": 196.0, "episode/score": 0.23805555066792294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23805555066792294}
{"step": 493832, "time": 24811.70731472969, "episode/length": 184.0, "episode/score": 0.2123454624597798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2123454624597798}
{"step": 493864, "time": 24814.52519440651, "episode/length": 150.0, "episode/score": 0.1667977887118468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1667977887118468}
{"step": 494464, "time": 24838.7794649601, "episode/length": 286.0, "episode/score": 0.302863421238726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.302863421238726}
{"step": 494600, "time": 24845.124798297882, "episode/length": 218.0, "episode/score": 0.2493073378718691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2493073378718691}
{"step": 494712, "time": 24850.833574533463, "episode/length": 257.0, "episode/score": 0.29241047311370494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29241047311370494}
{"step": 494808, "time": 24855.794966220856, "episode/length": 165.0, "episode/score": 0.19383332994766533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19383332994766533}
{"step": 494904, "time": 24860.899625062943, "episode/length": 150.0, "episode/score": 0.160415802791249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.160415802791249}
{"step": 495368, "time": 24879.675357580185, "episode/length": 187.0, "episode/score": 0.18826575332786888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18826575332786888}
{"step": 495624, "time": 24890.675196170807, "episode/length": 223.0, "episode/score": 0.2391919852452702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2391919852452702}
{"step": 495856, "time": 24901.135855436325, "episode/length": 439.0, "episode/score": 0.44307495773682604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44307495773682604}
{"step": 495920, "time": 24905.159568309784, "episode/length": 181.0, "episode/score": 0.20606313791358843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20606313791358843}
{"step": 496000, "time": 24909.785870552063, "episode/length": 174.0, "episode/score": 0.1790134321890946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1790134321890946}
{"step": 496088, "time": 24914.30263733864, "episode/length": 159.0, "episode/score": 0.16496455266678822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16496455266678822}
{"step": 496088, "time": 24914.310569763184, "episode/length": 171.0, "episode/score": 0.1775119101293967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1775119101293967}
{"step": 496560, "time": 24935.417827129364, "episode/length": 148.0, "episode/score": 0.16111301575801917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16111301575801917}
{"step": 496608, "time": 24938.896642446518, "episode/length": 212.0, "episode/score": 0.24903712689047097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24903712689047097}
{"step": 496856, "time": 24949.93346476555, "episode/length": 153.0, "episode/score": 0.1638046102016233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1638046102016233}
{"step": 497280, "time": 24967.75315761566, "episode/length": 159.0, "episode/score": 0.16444608823076123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16444608823076123}
{"step": 497320, "time": 24970.490000009537, "episode/length": 182.0, "episode/score": 0.20250202152237762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20250202152237762}
{"step": 497408, "time": 24975.510010242462, "episode/length": 164.0, "episode/score": 0.17819467082881602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17819467082881602}
{"step": 497584, "time": 24983.677265644073, "episode/length": 37.0, "episode/score": 0.04031163780018687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04031163780018687}
{"step": 497616, "time": 24986.45208644867, "episode/length": 190.0, "episode/score": 0.21698939567977504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21698939567977504}
{"step": 497792, "time": 24994.487645626068, "episode/length": 233.0, "episode/score": 0.27806767343645333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27806767343645333}
{"step": 497856, "time": 24998.582083940506, "episode/length": 155.0, "episode/score": 0.18257856808304496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18257856808304496}
{"step": 498112, "time": 25009.612273931503, "episode/length": 193.0, "episode/score": 0.2018714031928539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2018714031928539}
{"step": 498136, "time": 25011.75158882141, "episode/length": 159.0, "episode/score": 0.18282832074510225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18282832074510225}
{"step": 498592, "time": 25030.87552213669, "episode/length": 158.0, "episode/score": 0.16446616356552113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16446616356552113}
{"step": 498792, "time": 25039.8855843544, "episode/length": 172.0, "episode/score": 0.18471132120066613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18471132120066613}
{"step": 499080, "time": 25052.14053916931, "episode/length": 186.0, "episode/score": 0.19984776177625463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19984776177625463}
{"step": 499256, "time": 25060.339027404785, "episode/length": 142.0, "episode/score": 0.15118862030794844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15118862030794844}
{"step": 499328, "time": 25064.87369132042, "episode/length": 148.0, "episode/score": 0.17267735876521328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17267735876521328}
{"step": 499336, "time": 25066.38579940796, "episode/length": 192.0, "episode/score": 0.22323024478100706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22323024478100706}
{"step": 499616, "time": 25078.52604985237, "episode/length": 249.0, "episode/score": 0.30021147754450794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30021147754450794}
{"step": 499664, "time": 25081.86871290207, "episode/length": 225.0, "episode/score": 0.2481982938697911, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2481982938697911}
{"step": 500032, "time": 25115.61749601364, "eval_episode/length": 115.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9482758620689655}
{"step": 500032, "time": 25119.004093170166, "eval_episode/length": 159.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.99375}
{"step": 500032, "time": 25120.582681894302, "eval_episode/length": 161.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 500032, "time": 25122.2722697258, "eval_episode/length": 167.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 500032, "time": 25125.28827524185, "eval_episode/length": 193.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 500032, "time": 25128.145731925964, "eval_episode/length": 195.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 500032, "time": 25129.760919570923, "eval_episode/length": 200.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 500032, "time": 25131.779934167862, "eval_episode/length": 214.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9813953488372092}
{"step": 500264, "time": 25140.215158462524, "episode/length": 208.0, "episode/score": 0.24842119076492963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24842119076492963}
{"step": 500448, "time": 25149.00643515587, "episode/length": 206.0, "episode/score": 0.21602602260827553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21602602260827553}
{"step": 500472, "time": 25151.108978271484, "episode/length": 173.0, "episode/score": 0.18891702525434084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18891702525434084}
{"step": 500744, "time": 25162.700756788254, "episode/length": 175.0, "episode/score": 0.19122424483066425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19122424483066425}
{"step": 500928, "time": 25171.31409239769, "episode/length": 208.0, "episode/score": 0.23436914406556753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23436914406556753}
{"step": 500944, "time": 25173.38106942177, "episode/length": 159.0, "episode/score": 0.17457367041060934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17457367041060934}
{"step": 501040, "time": 25178.608709812164, "episode/length": 213.0, "episode/score": 0.22049557771606487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22049557771606487}
{"step": 501432, "time": 25194.66861486435, "episode/length": 226.0, "episode/score": 0.25325307470484404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25325307470484404}
{"step": 501696, "time": 25206.358040332794, "episode/length": 152.0, "episode/score": 0.15922697588757728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15922697588757728}
{"step": 501856, "time": 25214.536692142487, "episode/length": 52.0, "episode/score": 0.05242979624745203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05242979624745203}
{"step": 501856, "time": 25214.545362234116, "episode/length": 175.0, "episode/score": 0.2043525696717552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2043525696717552}
{"step": 502192, "time": 25230.331216812134, "episode/length": 240.0, "episode/score": 0.24531006309189252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24531006309189252}
{"step": 502336, "time": 25237.45112633705, "episode/length": 161.0, "episode/score": 0.16983845106551598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16983845106551598}
{"step": 502368, "time": 25240.258444070816, "episode/length": 179.0, "episode/score": 0.18557170861095074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18557170861095074}
{"step": 502448, "time": 25244.70037007332, "episode/length": 212.0, "episode/score": 0.23969977791239216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23969977791239216}
{"step": 502600, "time": 25251.54559612274, "episode/length": 50.0, "episode/score": 0.05841666570631787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05841666570631787}
{"step": 502928, "time": 25265.922390699387, "episode/length": 153.0, "episode/score": 0.17494437608547742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17494437608547742}
{"step": 503056, "time": 25272.32626414299, "episode/length": 263.0, "episode/score": 0.2926001997293497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2926001997293497}
{"step": 503128, "time": 25276.330187559128, "episode/length": 158.0, "episode/score": 0.17460073118490982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17460073118490982}
{"step": 503160, "time": 25278.96578669548, "episode/length": 162.0, "episode/score": 0.1916157224932249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1916157224932249}
{"step": 503888, "time": 25307.608731746674, "episode/length": 193.0, "episode/score": 0.21820757098612376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21820757098612376}
{"step": 503904, "time": 25310.136080026627, "episode/length": 181.0, "episode/score": 0.19610386781278066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19610386781278066}
{"step": 504200, "time": 25322.455032348633, "episode/length": 228.0, "episode/score": 0.2617946383106755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2617946383106755}
{"step": 504217, "time": 25325.709705114365, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.82965087890625, "train/action_min": 0.0, "train/action_std": 4.541632603472612, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007624691781243236, "train/actor_opt_grad_steps": 30780.0, "train/actor_opt_loss": -9.84856339397393, "train/adv_mag": 0.17823758627486042, "train/adv_max": 0.1283538366748592, "train/adv_mean": 6.246840357217537e-05, "train/adv_min": -0.17637730935427148, "train/adv_std": 0.013819197288120356, "train/cont_avg": 0.9945789247047244, "train/cont_loss_mean": 0.0002571192309590033, "train/cont_loss_std": 0.007129763315687141, "train/cont_neg_acc": 0.9877202862829674, "train/cont_neg_loss": 0.032599791648598206, "train/cont_pos_acc": 0.9999767659217353, "train/cont_pos_loss": 7.345492224106427e-05, "train/cont_pred": 0.9946024572755409, "train/cont_rate": 0.9945789247047244, "train/dyn_loss_mean": 11.589291722755732, "train/dyn_loss_std": 8.484670117145448, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15609834310928666, "train/extr_critic_critic_opt_grad_steps": 30780.0, "train/extr_critic_critic_opt_loss": 11931.948626660926, "train/extr_critic_mag": 0.28903030035063976, "train/extr_critic_max": 0.28903030035063976, "train/extr_critic_mean": 0.230273691336001, "train/extr_critic_min": 0.0020133820105725387, "train/extr_critic_std": 0.05860686475249726, "train/extr_return_normed_mag": 0.20559318739128865, "train/extr_return_normed_max": 0.20559318739128865, "train/extr_return_normed_mean": 0.1467457615484403, "train/extr_return_normed_min": -0.08257469212211023, "train/extr_return_normed_std": 0.06030839036299488, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28918360467032184, "train/extr_return_raw_max": 0.28918360467032184, "train/extr_return_raw_mean": 0.23033618375541656, "train/extr_return_raw_min": 0.0010157250982569897, "train/extr_return_raw_std": 0.06030839012833092, "train/extr_reward_mag": 0.001312911979795441, "train/extr_reward_max": 0.001312911979795441, "train/extr_reward_mean": 0.0011082984686748485, "train/extr_reward_min": 1.0510129252756675e-05, "train/extr_reward_std": 0.0002314046380022086, "train/image_loss_mean": 5.49005466746533, "train/image_loss_std": 10.40470669964167, "train/model_loss_mean": 12.483737938047394, "train/model_loss_std": 13.93570488456666, "train/model_opt_grad_norm": 55.57191709082896, "train/model_opt_grad_steps": 30750.67716535433, "train/model_opt_loss": 15604.672428641732, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.7583465313348245, "train/policy_entropy_max": 2.7583465313348245, "train/policy_entropy_mean": 1.9515024301573987, "train/policy_entropy_min": 0.08133785502882454, "train/policy_entropy_std": 0.6547986423875404, "train/policy_logprob_mag": 7.437000462389368, "train/policy_logprob_max": -0.00972894320308458, "train/policy_logprob_mean": -1.9511960585286299, "train/policy_logprob_min": -7.437000462389368, "train/policy_logprob_std": 1.2435818272312795, "train/policy_randomness_mag": 0.9735752761833311, "train/policy_randomness_max": 0.9735752761833311, "train/policy_randomness_mean": 0.6887947231765807, "train/policy_randomness_min": 0.028708693490722987, "train/policy_randomness_std": 0.23111518396167305, "train/post_ent_mag": 58.85386147086076, "train/post_ent_max": 58.85386147086076, "train/post_ent_mean": 41.21187411330816, "train/post_ent_min": 20.460122371283102, "train/post_ent_std": 7.058347401656504, "train/prior_ent_mag": 68.75030427467166, "train/prior_ent_max": 68.75030427467166, "train/prior_ent_mean": 52.90435751967543, "train/prior_ent_min": 32.566583993866686, "train/prior_ent_std": 5.616896997286579, "train/rep_loss_mean": 11.589291722755732, "train/rep_loss_std": 8.484670117145448, "train/reward_avg": 0.001054954292494657, "train/reward_loss_mean": 0.039851163990619616, "train/reward_loss_std": 0.011545935029706618, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012836568937526914, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03985116416661758, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001055994585310439, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.7761904329771088, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.79047619047619, "train_stats/max_log_achievement_collect_sapling": 1.2190476190476192, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.9428571428571428, "train_stats/max_log_achievement_defeat_skeleton": 0.01904761904761905, "train_stats/max_log_achievement_defeat_zombie": 0.06666666666666667, "train_stats/max_log_achievement_eat_cow": 0.01904761904761905, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.047619047619047616, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.5714285714285714, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.14285714285714285, "train_stats/max_log_achievement_wake_up": 0.23809523809523808, "train_stats/mean_log_entropy": 2.0413314932868594, "eval_stats/sum_log_reward": 0.9749999796040356, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 10.5625, "eval_stats/max_log_achievement_collect_sapling": 0.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.25, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.1975261410698295e-05, "report/cont_loss_std": 0.0012305137934163213, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004955343902111053, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.930202728952281e-05, "report/cont_pred": 0.9941052198410034, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.050027847290039, "report/dyn_loss_std": 8.978474617004395, "report/image_loss_mean": 6.2478766441345215, "report/image_loss_std": 10.688125610351562, "report/model_loss_mean": 12.91810417175293, "report/model_loss_std": 14.462564468383789, "report/post_ent_mag": 60.68461608886719, "report/post_ent_max": 60.68461608886719, "report/post_ent_mean": 43.13490295410156, "report/post_ent_min": 18.74620246887207, "report/post_ent_std": 7.363617897033691, "report/prior_ent_mag": 68.86048126220703, "report/prior_ent_max": 68.86048126220703, "report/prior_ent_mean": 54.077537536621094, "report/prior_ent_min": 32.129539489746094, "report/prior_ent_std": 5.456964015960693, "report/rep_loss_mean": 11.050027847290039, "report/rep_loss_std": 8.978474617004395, "report/reward_avg": 0.0010631642071530223, "report/reward_loss_mean": 0.04016859829425812, "report/reward_loss_std": 0.011054277420043945, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012269020080566406, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.040168602019548416, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010519898496568203, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 4.611396070686169e-05, "eval/cont_loss_std": 0.001374695566482842, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.007683729287236929, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0985500011884142e-06, "eval/cont_pred": 0.9941836595535278, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.458782196044922, "eval/dyn_loss_std": 9.89318561553955, "eval/image_loss_mean": 6.451488494873047, "eval/image_loss_std": 8.815032958984375, "eval/model_loss_mean": 17.215295791625977, "eval/model_loss_std": 13.776616096496582, "eval/post_ent_mag": 58.254913330078125, "eval/post_ent_max": 58.254913330078125, "eval/post_ent_mean": 41.13938903808594, "eval/post_ent_min": 20.959970474243164, "eval/post_ent_std": 7.173801898956299, "eval/prior_ent_mag": 68.86048126220703, "eval/prior_ent_max": 68.86048126220703, "eval/prior_ent_mean": 54.26604461669922, "eval/prior_ent_min": 32.56463623046875, "eval/prior_ent_std": 5.345932483673096, "eval/rep_loss_mean": 16.458782196044922, "eval/rep_loss_std": 9.89318561553955, "eval/reward_avg": 0.005078124813735485, "eval/reward_loss_mean": 0.8884925842285156, "eval/reward_loss_std": 4.092860221862793, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 0.001231551170349121, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.6758740544319153, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.46872901916504, "eval/reward_pred": 0.001017412287183106, "eval/reward_rate": 0.0107421875, "replay/size": 503713.0, "replay/inserts": 20384.0, "replay/samples": 20384.0, "replay/insert_wait_avg": 1.357631462522354e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.867672754045184e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 97992.0, "eval_replay/inserts": 3920.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1832738409236987e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0993988513947, "timer/env.step_count": 2548.0, "timer/env.step_total": 227.60577273368835, "timer/env.step_frac": 0.22758315122985934, "timer/env.step_avg": 0.0893272263476014, "timer/env.step_min": 0.02234053611755371, "timer/env.step_max": 3.1781184673309326, "timer/replay._sample_count": 20384.0, "timer/replay._sample_total": 9.857693433761597, "timer/replay._sample_frac": 0.009856713687742508, "timer/replay._sample_avg": 0.0004835995601335163, "timer/replay._sample_min": 0.00038361549377441406, "timer/replay._sample_max": 0.008314847946166992, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3038.0, "timer/agent.policy_total": 49.054163694381714, "timer/agent.policy_frac": 0.049049288251467794, "timer/agent.policy_avg": 0.016146860992225714, "timer/agent.policy_min": 0.009589433670043945, "timer/agent.policy_max": 0.11849641799926758, "timer/dataset_train_count": 1274.0, "timer/dataset_train_total": 0.13915467262268066, "timer/dataset_train_frac": 0.0001391408421827856, "timer/dataset_train_avg": 0.00010922658761591888, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.00036835670471191406, "timer/agent.train_count": 1274.0, "timer/agent.train_total": 573.2152512073517, "timer/agent.train_frac": 0.573158279932659, "timer/agent.train_avg": 0.44993347818473445, "timer/agent.train_min": 0.4352376461029053, "timer/agent.train_max": 1.8724985122680664, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48711228370666504, "timer/agent.report_frac": 0.00048706387011741956, "timer/agent.report_avg": 0.24355614185333252, "timer/agent.report_min": 0.23816990852355957, "timer/agent.report_max": 0.24894237518310547, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.3365020751953125e-05, "timer/dataset_eval_frac": 2.3362698526554106e-08, "timer/dataset_eval_avg": 2.3365020751953125e-05, "timer/dataset_eval_min": 2.3365020751953125e-05, "timer/dataset_eval_max": 2.3365020751953125e-05, "fps": 20.381728792502066}
{"step": 504288, "time": 25328.65830183029, "episode/length": 210.0, "episode/score": 0.24142777040106012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24142777040106012}
{"step": 504384, "time": 25334.360886096954, "episode/length": 181.0, "episode/score": 0.1942242203222122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1942242203222122}
{"step": 504624, "time": 25344.707419633865, "episode/length": 182.0, "episode/score": 0.22015685824590037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22015685824590037}
{"step": 504912, "time": 25356.90637588501, "episode/length": 222.0, "episode/score": 0.24730198852194007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24730198852194007}
{"step": 504984, "time": 25360.861060619354, "episode/length": 240.0, "episode/score": 0.2663720194759662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2663720194759662}
{"step": 505456, "time": 25380.03586292267, "episode/length": 193.0, "episode/score": 0.2193273166412837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2193273166412837}
{"step": 505536, "time": 25385.092039823532, "episode/length": 166.0, "episode/score": 0.1826095878277556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1826095878277556}
{"step": 505992, "time": 25404.4469268322, "episode/length": 200.0, "episode/score": 0.23933332867454737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23933332867454737}
{"step": 506080, "time": 25410.130759954453, "episode/length": 145.0, "episode/score": 0.14260335518338252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14260335518338252}
{"step": 506184, "time": 25415.31535434723, "episode/length": 149.0, "episode/score": 0.17226262921394664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17226262921394664}
{"step": 506448, "time": 25426.922885894775, "episode/length": 269.0, "episode/score": 0.3130855350245838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3130855350245838}
{"step": 506816, "time": 25442.23016643524, "episode/length": 273.0, "episode/score": 0.3144648836023407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3144648836023407}
{"step": 506936, "time": 25448.16250038147, "episode/length": 184.0, "episode/score": 0.18452911011627293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18452911011627293}
{"step": 507168, "time": 25458.513929367065, "episode/length": 146.0, "episode/score": 0.17229694607704005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17229694607704005}
{"step": 507416, "time": 25469.039283275604, "episode/length": 440.0, "episode/score": 0.4636176981312019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4636176981312019}
{"step": 507472, "time": 25472.952498674393, "episode/length": 160.0, "episode/score": 0.17031727497305837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17031727497305837}
{"step": 507624, "time": 25479.92717909813, "episode/length": 192.0, "episode/score": 0.2201548800458113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2201548800458113}
{"step": 507976, "time": 25495.937073469162, "episode/length": 304.0, "episode/score": 0.29871918465869385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29871918465869385}
{"step": 508104, "time": 25502.1564514637, "episode/length": 206.0, "episode/score": 0.22361686787007784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22361686787007784}
{"step": 508456, "time": 25516.807670116425, "episode/length": 160.0, "episode/score": 0.17233886120084208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17233886120084208}
{"step": 508496, "time": 25520.02644944191, "episode/length": 194.0, "episode/score": 0.22187650140222104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22187650140222104}
{"step": 508528, "time": 25522.696668624878, "episode/length": 213.0, "episode/score": 0.23804218046279857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23804218046279857}
{"step": 508744, "time": 25531.966391563416, "episode/length": 158.0, "episode/score": 0.16234463042019343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16234463042019343}
{"step": 508824, "time": 25536.380219221115, "episode/length": 105.0, "episode/score": 0.11146929915594228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11146929915594228}
{"step": 508888, "time": 25540.414267778397, "episode/length": 157.0, "episode/score": 0.1844041515769277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1844041515769277}
{"step": 509224, "time": 25554.3924100399, "episode/length": 59.0, "episode/score": 0.06684523692820221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06684523692820221}
{"step": 509376, "time": 25561.790199279785, "episode/length": 244.0, "episode/score": 0.2597302238227712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2597302238227712}
{"step": 509744, "time": 25577.029197454453, "episode/length": 151.0, "episode/score": 0.1618609768265742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1618609768265742}
{"step": 509912, "time": 25584.719115018845, "episode/length": 181.0, "episode/score": 0.18076774767541792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18076774767541792}
{"step": 509936, "time": 25587.286698818207, "episode/length": 179.0, "episode/score": 0.206059520249255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.206059520249255}
{"step": 510000, "time": 25591.203273534775, "episode/length": 236.0, "episode/score": 0.26572310473875405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26572310473875405}
{"step": 510016, "time": 25616.480474472046, "eval_episode/length": 156.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 510016, "time": 25618.082313537598, "eval_episode/length": 159.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.99375}
{"step": 510016, "time": 25619.8812520504, "eval_episode/length": 166.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 510016, "time": 25621.821814775467, "eval_episode/length": 174.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 510016, "time": 25623.39245414734, "eval_episode/length": 175.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 510016, "time": 25625.16687822342, "eval_episode/length": 182.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.994535519125683}
{"step": 510016, "time": 25625.17449259758, "eval_episode/length": 182.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.994535519125683}
{"step": 510016, "time": 25635.130306482315, "eval_episode/length": 162.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 510248, "time": 25643.519630908966, "episode/length": 169.0, "episode/score": 0.1671748665321502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1671748665321502}
{"step": 510600, "time": 25658.189074754715, "episode/length": 221.0, "episode/score": 0.24118634335536626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24118634335536626}
{"step": 510864, "time": 25669.808280706406, "episode/length": 204.0, "episode/score": 0.22485310850606766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22485310850606766}
{"step": 510912, "time": 25673.092624425888, "episode/length": 191.0, "episode/score": 0.1956038690332207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1956038690332207}
{"step": 510960, "time": 25676.595375299454, "episode/length": 151.0, "episode/score": 0.17417148101958446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17417148101958446}
{"step": 511176, "time": 25685.85554432869, "episode/length": 154.0, "episode/score": 0.1619539946113946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1619539946113946}
{"step": 511208, "time": 25688.6301176548, "episode/length": 161.0, "episode/score": 0.17653040037839673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17653040037839673}
{"step": 511400, "time": 25697.360604047775, "episode/length": 174.0, "episode/score": 0.1876393992897647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1876393992897647}
{"step": 511544, "time": 25704.248252630234, "episode/length": 72.0, "episode/score": 0.08677083166548982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08677083166548982}
{"step": 511600, "time": 25708.045013189316, "episode/length": 168.0, "episode/score": 0.1898683602375968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1898683602375968}
{"step": 512368, "time": 25737.989486694336, "episode/length": 187.0, "episode/score": 0.21149030101150856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21149030101150856}
{"step": 512496, "time": 25744.279119491577, "episode/length": 160.0, "episode/score": 0.1703372821684752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1703372821684752}
{"step": 512504, "time": 25745.82883119583, "episode/length": 165.0, "episode/score": 0.18813098976170295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18813098976170295}
{"step": 512608, "time": 25751.462433815002, "episode/length": 211.0, "episode/score": 0.2356403137309826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2356403137309826}
{"step": 512888, "time": 25763.351941347122, "episode/length": 185.0, "episode/score": 0.18606457357964246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18606457357964246}
{"step": 512896, "time": 25765.358669519424, "episode/length": 286.0, "episode/score": 0.3269847345909511, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3269847345909511}
{"step": 512944, "time": 25768.698043107986, "episode/length": 71.0, "episode/score": 0.0796914179391024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0796914179391024}
{"step": 513296, "time": 25783.324994802475, "episode/length": 211.0, "episode/score": 0.2296074629521172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2296074629521172}
{"step": 513784, "time": 25802.829894542694, "episode/length": 146.0, "episode/score": 0.16363697186898207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16363697186898207}
{"step": 513832, "time": 25806.240075349808, "episode/length": 165.0, "episode/score": 0.17388822760767653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17388822760767653}
{"step": 513888, "time": 25810.242941617966, "episode/length": 173.0, "episode/score": 0.19773290142074984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19773290142074984}
{"step": 514128, "time": 25820.67180800438, "episode/length": 153.0, "episode/score": 0.159356591058895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.159356591058895}
{"step": 514144, "time": 25822.79362630844, "episode/length": 156.0, "episode/score": 0.14925527067498479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14925527067498479}
{"step": 514400, "time": 25833.886562347412, "episode/length": 181.0, "episode/score": 0.18619353894609958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18619353894609958}
{"step": 514696, "time": 25846.226739645004, "episode/length": 36.0, "episode/score": 0.034145660836657044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034145660836657044}
{"step": 514824, "time": 25852.404898643494, "episode/length": 409.0, "episode/score": 0.4247514912567567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4247514912567567}
{"step": 514840, "time": 25854.587341070175, "episode/length": 192.0, "episode/score": 0.2065864213691384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2065864213691384}
{"step": 515200, "time": 25869.723891735077, "episode/length": 176.0, "episode/score": 0.18968008647698298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18968008647698298}
{"step": 515504, "time": 25882.603962421417, "episode/length": 171.0, "episode/score": 0.1794424241879824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1794424241879824}
{"step": 515528, "time": 25884.784821510315, "episode/length": 211.0, "episode/score": 0.2417708630227935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2417708630227935}
{"step": 515528, "time": 25884.793930768967, "episode/length": 204.0, "episode/score": 0.2393123183392163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2393123183392163}
{"step": 516184, "time": 25913.935997724533, "episode/length": 254.0, "episode/score": 0.2863714913091826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2863714913091826}
{"step": 516360, "time": 25922.14978003502, "episode/length": 189.0, "episode/score": 0.20764674406746053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20764674406746053}
{"step": 516584, "time": 25932.414626598358, "episode/length": 219.0, "episode/score": 0.2344033640647467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2344033640647467}
{"step": 516624, "time": 25935.63803076744, "episode/length": 240.0, "episode/score": 0.25666560352510714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25666560352510714}
{"step": 516888, "time": 25946.786939144135, "episode/length": 169.0, "episode/score": 0.16322370001489617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16322370001489617}
{"step": 517032, "time": 25953.69871354103, "episode/length": 228.0, "episode/score": 0.2416324728710606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2416324728710606}
{"step": 517304, "time": 25965.383801221848, "episode/length": 221.0, "episode/score": 0.23874048552534077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23874048552534077}
{"step": 517624, "time": 25978.889586687088, "episode/length": 264.0, "episode/score": 0.29417213958731736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29417213958731736}
{"step": 517736, "time": 25984.62051486969, "episode/length": 171.0, "episode/score": 0.19819741684477776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19819741684477776}
{"step": 518000, "time": 25996.372887134552, "episode/length": 171.0, "episode/score": 0.1868771117151482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1868771117151482}
{"step": 518008, "time": 25997.957854509354, "episode/length": 139.0, "episode/score": 0.15641770901129348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15641770901129348}
{"step": 518064, "time": 26001.82394051552, "episode/length": 234.0, "episode/score": 0.2529623390892084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2529623390892084}
{"step": 518160, "time": 26006.89885354042, "episode/length": 196.0, "episode/score": 0.22127503114461433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22127503114461433}
{"step": 518408, "time": 26017.496459007263, "episode/length": 171.0, "episode/score": 0.178804991322977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.178804991322977}
{"step": 518464, "time": 26021.343021154404, "episode/length": 144.0, "episode/score": 0.16111690295656445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16111690295656445}
{"step": 518912, "time": 26039.42873954773, "episode/length": 146.0, "episode/score": 0.16670774659360177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16670774659360177}
{"step": 519192, "time": 26051.186338186264, "episode/length": 195.0, "episode/score": 0.19775801390278502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19775801390278502}
{"step": 519344, "time": 26058.555448293686, "episode/length": 167.0, "episode/score": 0.1939255430479534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1939255430479534}
{"step": 519456, "time": 26064.25395655632, "episode/length": 173.0, "episode/score": 0.1991656886166311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1991656886166311}
{"step": 519760, "time": 26077.42722582817, "episode/length": 218.0, "episode/score": 0.21954853921124595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21954853921124595}
{"step": 520000, "time": 26102.44117665291, "eval_episode/length": 47.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8958333333333334}
{"step": 520000, "time": 26107.88702607155, "eval_episode/length": 139.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 520000, "time": 26111.47244501114, "eval_episode/length": 188.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 520000, "time": 26112.986832618713, "eval_episode/length": 141.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 520000, "time": 26115.719522237778, "eval_episode/length": 219.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9727272727272728}
{"step": 520000, "time": 26117.435905456543, "eval_episode/length": 221.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 520000, "time": 26119.662986516953, "eval_episode/length": 237.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 520000, "time": 26122.24606704712, "eval_episode/length": 261.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9961832061068703}
{"step": 520056, "time": 26124.12042951584, "episode/length": 236.0, "episode/score": 0.2683115319487115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2683115319487115}
{"step": 520328, "time": 26135.633580207825, "episode/length": 239.0, "episode/score": 0.2397452391396655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2397452391396655}
{"step": 520384, "time": 26139.58341741562, "episode/length": 239.0, "episode/score": 0.26674059207653045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26674059207653045}
{"step": 520608, "time": 26149.366858243942, "episode/length": 176.0, "episode/score": 0.1876614419688849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1876614419688849}
{"step": 520648, "time": 26152.1881878376, "episode/length": 216.0, "episode/score": 0.24049702243610227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24049702243610227}
{"step": 520664, "time": 26154.287323236465, "episode/length": 164.0, "episode/score": 0.16570018329002778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16570018329002778}
{"step": 521248, "time": 26177.71707201004, "episode/length": 148.0, "episode/score": 0.1496779965436872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1496779965436872}
{"step": 521376, "time": 26183.96388578415, "episode/length": 201.0, "episode/score": 0.22207307012649835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22207307012649835}
{"step": 521544, "time": 26191.634389400482, "episode/length": 116.0, "episode/score": 0.13053745304205222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13053745304205222}
{"step": 521880, "time": 26205.837607622147, "episode/length": 153.0, "episode/score": 0.1733699703527236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1733699703527236}
{"step": 521888, "time": 26207.910902023315, "episode/length": 194.0, "episode/score": 0.2112480983905698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2112480983905698}
{"step": 521920, "time": 26210.782876968384, "episode/length": 191.0, "episode/score": 0.18733101030011312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18733101030011312}
{"step": 521984, "time": 26214.669846057892, "episode/length": 164.0, "episode/score": 0.17843866730072477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17843866730072477}
{"step": 522680, "time": 26241.90913295746, "episode/length": 94.0, "episode/score": 0.10438470152712398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10438470152712398}
{"step": 522696, "time": 26243.944650650024, "episode/length": 180.0, "episode/score": 0.21885453712638991, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21885453712638991}
{"step": 522856, "time": 26251.452647924423, "episode/length": 424.0, "episode/score": 0.44939668527968024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44939668527968024}
{"step": 522944, "time": 26256.525206804276, "episode/length": 195.0, "episode/score": 0.21260699511913117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21260699511913117}
{"step": 523424, "time": 26276.033433675766, "episode/length": 234.0, "episode/score": 0.259516889893348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.259516889893348}
{"step": 523432, "time": 26277.578318834305, "episode/length": 192.0, "episode/score": 0.21035154606215656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21035154606215656}
{"step": 523536, "time": 26283.240341186523, "episode/length": 193.0, "episode/score": 0.22080054546131578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22080054546131578}
{"step": 523800, "time": 26294.51619696617, "episode/length": 239.0, "episode/score": 0.2743027011620143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2743027011620143}
{"step": 523888, "time": 26299.46037173271, "episode/length": 148.0, "episode/score": 0.1534527222684119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1534527222684119}
{"step": 524392, "time": 26321.363553762436, "episode/length": 191.0, "episode/score": 0.21206795426405733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21206795426405733}
{"step": 524441, "time": 26325.778210878372, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.16691817636565, "train/action_min": 0.0, "train/action_std": 4.770069959595448, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007386777317151427, "train/actor_opt_grad_steps": 32050.0, "train/actor_opt_loss": -10.47650918581589, "train/adv_mag": 0.17351071290143832, "train/adv_max": 0.12443216978095648, "train/adv_mean": -6.351612695088693e-06, "train/adv_min": -0.17234964363687622, "train/adv_std": 0.013406979081433588, "train/cont_avg": 0.994509719488189, "train/cont_loss_mean": 0.00017739596462371175, "train/cont_loss_std": 0.005375622609937106, "train/cont_neg_acc": 0.9992125987067936, "train/cont_neg_loss": 0.007725162649933729, "train/cont_pos_acc": 0.9999535797149177, "train/cont_pos_loss": 0.00012202110468510632, "train/cont_pred": 0.994466202934896, "train/cont_rate": 0.994509719488189, "train/dyn_loss_mean": 11.658315185486801, "train/dyn_loss_std": 8.502490133751095, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14885512375690807, "train/extr_critic_critic_opt_grad_steps": 32050.0, "train/extr_critic_critic_opt_loss": 11974.955547182579, "train/extr_critic_mag": 0.2849539875045536, "train/extr_critic_max": 0.2849539875045536, "train/extr_critic_mean": 0.2300485952163306, "train/extr_critic_min": 0.0018910404265396238, "train/extr_critic_std": 0.05752947275328824, "train/extr_return_normed_mag": 0.19572130678676244, "train/extr_return_normed_max": 0.19572130678676244, "train/extr_return_normed_mean": 0.14071756665866206, "train/extr_return_normed_min": -0.08830377547525045, "train/extr_return_normed_std": 0.05902608102700842, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2850459666233363, "train/extr_return_raw_max": 0.2850459666233363, "train/extr_return_raw_mean": 0.23004223007386124, "train/extr_return_raw_min": 0.0010208848893173098, "train/extr_return_raw_std": 0.059026080733678474, "train/extr_reward_mag": 0.0013180558137067659, "train/extr_reward_max": 0.0013180558137067659, "train/extr_reward_mean": 0.0010934239968393496, "train/extr_reward_min": 1.0167519877276083e-05, "train/extr_reward_std": 0.00024531636990727786, "train/image_loss_mean": 5.577974358881552, "train/image_loss_std": 10.363450493399553, "train/model_loss_mean": 12.612929967444712, "train/model_loss_std": 13.868060337276908, "train/model_opt_grad_norm": 53.90204833623931, "train/model_opt_grad_steps": 32019.472440944883, "train/model_opt_loss": 15895.916054072342, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1259.8425196850394, "train/policy_entropy_mag": 2.7635339263855943, "train/policy_entropy_max": 2.7635339263855943, "train/policy_entropy_mean": 2.087184201075336, "train/policy_entropy_min": 0.08147835314977826, "train/policy_entropy_std": 0.6309319474096373, "train/policy_logprob_mag": 7.438232181579109, "train/policy_logprob_max": -0.009748252849351234, "train/policy_logprob_mean": -2.0884119018794984, "train/policy_logprob_min": -7.438232181579109, "train/policy_logprob_std": 1.1727104187011719, "train/policy_randomness_mag": 0.9754062008669996, "train/policy_randomness_max": 0.9754062008669996, "train/policy_randomness_mean": 0.736684437811844, "train/policy_randomness_min": 0.028758283029860398, "train/policy_randomness_std": 0.22269129049120925, "train/post_ent_mag": 58.994424564631906, "train/post_ent_max": 58.994424564631906, "train/post_ent_mean": 41.19471803800327, "train/post_ent_min": 20.695317861602064, "train/post_ent_std": 7.101962198422649, "train/prior_ent_mag": 68.77983597883089, "train/prior_ent_max": 68.77983597883089, "train/prior_ent_mean": 52.93604020246371, "train/prior_ent_min": 32.795871028749964, "train/prior_ent_std": 5.556498073217437, "train/rep_loss_mean": 11.658315185486801, "train/rep_loss_std": 8.502490133751095, "train/reward_avg": 0.001053340128516617, "train/reward_loss_mean": 0.03978920607702938, "train/reward_loss_std": 0.011621761377754175, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012840332947378083, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039789205959697406, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010555857438667435, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.5476190214355787, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.219047619047619, "train_stats/max_log_achievement_collect_sapling": 1.0952380952380953, "train_stats/max_log_achievement_collect_stone": 0.009523809523809525, "train_stats/max_log_achievement_collect_wood": 0.8476190476190476, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.06666666666666667, "train_stats/max_log_achievement_eat_cow": 0.02857142857142857, "train_stats/max_log_achievement_make_wood_pickaxe": 0.01904761904761905, "train_stats/max_log_achievement_make_wood_sword": 0.02857142857142857, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.6, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.11428571428571428, "train_stats/max_log_achievement_wake_up": 0.1523809523809524, "train_stats/mean_log_entropy": 2.121884489059448, "eval_stats/sum_log_reward": 1.912499925121665, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 5.8125, "eval_stats/max_log_achievement_collect_sapling": 1.1875, "eval_stats/max_log_achievement_collect_stone": 0.3125, "eval_stats/max_log_achievement_collect_wood": 1.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.625, "eval_stats/max_log_achievement_place_stone": 0.125, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 0.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 4.135513154324144e-05, "report/cont_loss_std": 0.0009336392395198345, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.003590554930269718, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.884399332804605e-06, "report/cont_pred": 0.9912322759628296, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 10.485614776611328, "report/dyn_loss_std": 8.0028715133667, "report/image_loss_mean": 5.574192523956299, "report/image_loss_std": 8.634122848510742, "report/model_loss_mean": 11.905102729797363, "report/model_loss_std": 11.859987258911133, "report/post_ent_mag": 58.98299026489258, "report/post_ent_max": 58.98299026489258, "report/post_ent_mean": 42.31492614746094, "report/post_ent_min": 21.542560577392578, "report/post_ent_std": 6.688168525695801, "report/prior_ent_mag": 68.85176086425781, "report/prior_ent_max": 68.85176086425781, "report/prior_ent_mean": 53.06767654418945, "report/prior_ent_min": 30.19451141357422, "report/prior_ent_std": 5.299666404724121, "report/rep_loss_mean": 10.485614776611328, "report/rep_loss_std": 8.0028715133667, "report/reward_avg": 0.001047356752678752, "report/reward_loss_mean": 0.039499953389167786, "report/reward_loss_std": 0.01257201749831438, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012363195419311523, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.039499953389167786, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010234161745756865, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00011055673530790955, "eval/cont_loss_std": 0.0033359192311763763, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.026844345033168793, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.718336069548968e-06, "eval/cont_pred": 0.9961875677108765, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.27787971496582, "eval/dyn_loss_std": 10.428232192993164, "eval/image_loss_mean": 14.339390754699707, "eval/image_loss_std": 19.871662139892578, "eval/model_loss_mean": 25.836040496826172, "eval/model_loss_std": 23.482620239257812, "eval/post_ent_mag": 61.88832473754883, "eval/post_ent_max": 61.88832473754883, "eval/post_ent_mean": 39.230255126953125, "eval/post_ent_min": 20.53128433227539, "eval/post_ent_std": 7.000468730926514, "eval/prior_ent_mag": 68.85176086425781, "eval/prior_ent_max": 68.85176086425781, "eval/prior_ent_mean": 53.96525573730469, "eval/prior_ent_min": 28.23092269897461, "eval/prior_ent_std": 5.17091703414917, "eval/rep_loss_mean": 18.27787971496582, "eval/rep_loss_std": 10.428232192993164, "eval/reward_avg": 0.007324218284338713, "eval/reward_loss_mean": 0.5298133492469788, "eval/reward_loss_std": 3.184241533279419, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 0.0012508630752563477, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.3122834265232086, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.562345504760742, "eval/reward_pred": 0.0010174510534852743, "eval/reward_rate": 0.0107421875, "replay/size": 523937.0, "replay/inserts": 20224.0, "replay/samples": 20224.0, "replay/insert_wait_avg": 1.3103001291238808e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.901034211810631e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4864.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.150624532448618e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0543901920319, "timer/env.step_count": 2528.0, "timer/env.step_total": 226.55981636047363, "timer/env.step_frac": 0.22654749439874894, "timer/env.step_avg": 0.08962018052233925, "timer/env.step_min": 0.02249908447265625, "timer/env.step_max": 3.201554775238037, "timer/replay._sample_count": 20224.0, "timer/replay._sample_total": 9.826767444610596, "timer/replay._sample_frac": 0.009826232993911107, "timer/replay._sample_avg": 0.0004858963332975967, "timer/replay._sample_min": 0.0004062652587890625, "timer/replay._sample_max": 0.011025428771972656, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3136.0, "timer/agent.policy_total": 50.54897952079773, "timer/agent.policy_frac": 0.05054623030162514, "timer/agent.policy_avg": 0.016118934796172744, "timer/agent.policy_min": 0.009680747985839844, "timer/agent.policy_max": 0.10833215713500977, "timer/dataset_train_count": 1264.0, "timer/dataset_train_total": 0.13794326782226562, "timer/dataset_train_frac": 0.00013793576546949367, "timer/dataset_train_avg": 0.00010913233213786837, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0007395744323730469, "timer/agent.train_count": 1264.0, "timer/agent.train_total": 567.1799449920654, "timer/agent.train_frac": 0.5671490976437339, "timer/agent.train_avg": 0.44871831091144415, "timer/agent.train_min": 0.4368870258331299, "timer/agent.train_max": 1.0753111839294434, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4802992343902588, "timer/agent.report_frac": 0.00048027311224345615, "timer/agent.report_avg": 0.2401496171951294, "timer/agent.report_min": 0.23451995849609375, "timer/agent.report_max": 0.24577927589416504, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.1707946419213134e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 20.222647962769422}
{"step": 524592, "time": 26331.515496969223, "episode/length": 145.0, "episode/score": 0.1594367941870587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1594367941870587}
{"step": 524824, "time": 26341.574206113815, "episode/length": 267.0, "episode/score": 0.3014732092706254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3014732092706254}
{"step": 524976, "time": 26349.018030166626, "episode/length": 192.0, "episode/score": 0.22108202490926487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22108202490926487}
{"step": 524984, "time": 26350.603669643402, "episode/length": 180.0, "episode/score": 0.2123154722212348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2123154722212348}
{"step": 525248, "time": 26362.174681186676, "episode/length": 287.0, "episode/score": 0.31633563569630496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31633563569630496}
{"step": 525328, "time": 26366.612222909927, "episode/length": 179.0, "episode/score": 0.18558626477170037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18558626477170037}
{"step": 525464, "time": 26373.060841560364, "episode/length": 207.0, "episode/score": 0.2131411930458853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2131411930458853}
{"step": 525688, "time": 26382.920588731766, "episode/length": 161.0, "episode/score": 0.16578029441370745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16578029441370745}
{"step": 526200, "time": 26403.683928012848, "episode/length": 171.0, "episode/score": 0.2082083291024901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2082083291024901}
{"step": 526208, "time": 26405.833349704742, "episode/length": 119.0, "episode/score": 0.1407083308440633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1407083308440633}
{"step": 526448, "time": 26416.50663113594, "episode/length": 183.0, "episode/score": 0.2021698477328755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2021698477328755}
{"step": 526504, "time": 26419.83053135872, "episode/length": 146.0, "episode/score": 0.14458501487570175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14458501487570175}
{"step": 526536, "time": 26422.5509057045, "episode/length": 242.0, "episode/score": 0.2759310751207522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2759310751207522}
{"step": 526912, "time": 26438.28677034378, "episode/length": 152.0, "episode/score": 0.1616191354842158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1616191354842158}
{"step": 527072, "time": 26445.835032224655, "episode/length": 200.0, "episode/score": 0.23265739118869533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23265739118869533}
{"step": 527512, "time": 26463.493181467056, "episode/length": 315.0, "episode/score": 0.34506857111045974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34506857111045974}
{"step": 527864, "time": 26478.282967567444, "episode/length": 207.0, "episode/score": 0.23197387723485008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23197387723485008}
{"step": 528104, "time": 26488.794756412506, "episode/length": 236.0, "episode/score": 0.27442304749274626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27442304749274626}
{"step": 528192, "time": 26493.864944458008, "episode/length": 210.0, "episode/score": 0.2283497090174933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2283497090174933}
{"step": 528240, "time": 26497.18577861786, "episode/length": 223.0, "episode/score": 0.24616853429324692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24616853429324692}
{"step": 528248, "time": 26498.825016736984, "episode/length": 166.0, "episode/score": 0.2041666624136269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2041666624136269}
{"step": 528360, "time": 26504.604760169983, "episode/length": 227.0, "episode/score": 0.2475992673098517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2475992673098517}
{"step": 528408, "time": 26507.841000795364, "episode/length": 166.0, "episode/score": 0.187364322355279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.187364322355279}
{"step": 528480, "time": 26512.28820681572, "episode/length": 35.0, "episode/score": 0.040083332743961364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040083332743961364}
{"step": 529208, "time": 26540.72499847412, "episode/length": 167.0, "episode/score": 0.1787473889053217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1787473889053217}
{"step": 529224, "time": 26542.790692090988, "episode/length": 213.0, "episode/score": 0.24106115159156616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24106115159156616}
{"step": 529512, "time": 26555.1139023304, "episode/length": 175.0, "episode/score": 0.19078071050535073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19078071050535073}
{"step": 529720, "time": 26564.6742310524, "episode/length": 183.0, "episode/score": 0.20492399940121686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20492399940121686}
{"step": 529784, "time": 26569.023166179657, "episode/length": 171.0, "episode/score": 0.17206771484779892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17206771484779892}
{"step": 529944, "time": 26577.328642129898, "episode/length": 212.0, "episode/score": 0.2236728096359002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2236728096359002}
{"step": 530088, "time": 26601.64750289917, "eval_episode/length": 99.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.94}
{"step": 530088, "time": 26605.01562833786, "eval_episode/length": 142.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.993006993006993}
{"step": 530088, "time": 26606.470890522003, "eval_episode/length": 143.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 530088, "time": 26608.189481973648, "eval_episode/length": 149.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 530088, "time": 26610.3438975811, "eval_episode/length": 164.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 530088, "time": 26612.08692574501, "eval_episode/length": 172.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9653179190751445}
{"step": 530088, "time": 26614.63600039482, "eval_episode/length": 197.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 530088, "time": 26616.351563453674, "eval_episode/length": 103.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9519230769230769}
{"step": 530280, "time": 26623.65926527977, "episode/length": 224.0, "episode/score": 0.23948343132724403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23948343132724403}
{"step": 530616, "time": 26638.379805088043, "episode/length": 137.0, "episode/score": 0.16775378804231877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16775378804231877}
{"step": 530736, "time": 26644.620203495026, "episode/length": 188.0, "episode/score": 0.19461162262268772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19461162262268772}
{"step": 530936, "time": 26653.36970806122, "episode/length": 321.0, "episode/score": 0.3502870067350159, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3502870067350159}
{"step": 531376, "time": 26671.497925043106, "episode/length": 206.0, "episode/score": 0.2104132901349658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2104132901349658}
{"step": 531632, "time": 26682.795758247375, "episode/length": 210.0, "episode/score": 0.24414059122864273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24414059122864273}
{"step": 531816, "time": 26691.07243847847, "episode/length": 191.0, "episode/score": 0.19190754955343436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19190754955343436}
{"step": 531912, "time": 26696.08523631096, "episode/length": 265.0, "episode/score": 0.28874147988790355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28874147988790355}
{"step": 532280, "time": 26711.25892519951, "episode/length": 192.0, "episode/score": 0.20031222000943671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20031222000943671}
{"step": 532440, "time": 26718.657219171524, "episode/length": 187.0, "episode/score": 0.21708486532224924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21708486532224924}
{"step": 532608, "time": 26728.215806484222, "episode/length": 248.0, "episode/score": 0.28102258169747074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28102258169747074}
{"step": 532712, "time": 26733.269607782364, "episode/length": 166.0, "episode/score": 0.16447261167922989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16447261167922989}
{"step": 532760, "time": 26736.655654907227, "episode/length": 443.0, "episode/score": 0.46890090195665834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.46890090195665834}
{"step": 533008, "time": 26747.76392889023, "episode/length": 171.0, "episode/score": 0.19100521694053896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19100521694053896}
{"step": 533632, "time": 26772.764568567276, "episode/length": 226.0, "episode/score": 0.2365265771295526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2365265771295526}
{"step": 533632, "time": 26772.771591424942, "episode/length": 127.0, "episode/score": 0.14145859626296442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14145859626296442}
{"step": 533664, "time": 26776.97318124771, "episode/length": 218.0, "episode/score": 0.2664999944099691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2664999944099691}
{"step": 533920, "time": 26788.05179142952, "episode/length": 184.0, "episode/score": 0.217176016241865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.217176016241865}
{"step": 534128, "time": 26797.469180822372, "episode/length": 176.0, "episode/score": 0.19106804545299383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19106804545299383}
{"step": 534320, "time": 26806.186382055283, "episode/length": 254.0, "episode/score": 0.28792486876045587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28792486876045587}
{"step": 534368, "time": 26809.479344844818, "episode/length": 169.0, "episode/score": 0.17326632277763565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17326632277763565}
{"step": 534512, "time": 26816.471004009247, "episode/length": 218.0, "episode/score": 0.23474847014585976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23474847014585976}
{"step": 535056, "time": 26838.238196372986, "episode/length": 177.0, "episode/score": 0.19646042542080977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19646042542080977}
{"step": 535128, "time": 26842.20137476921, "episode/length": 182.0, "episode/score": 0.18512593826744705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18512593826744705}
{"step": 535616, "time": 26862.24373269081, "episode/length": 161.0, "episode/score": 0.18138489905868482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18138489905868482}
{"step": 535648, "time": 26864.916203022003, "episode/length": 159.0, "episode/score": 0.17251637803929043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17251637803929043}
{"step": 535680, "time": 26867.58295726776, "episode/length": 219.0, "episode/score": 0.22984862526936922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22984862526936922}
{"step": 535824, "time": 26874.49705886841, "episode/length": 163.0, "episode/score": 0.18301207443073508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18301207443073508}
{"step": 535888, "time": 26878.38538169861, "episode/length": 281.0, "episode/score": 0.3104977609436901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3104977609436901}
{"step": 535904, "time": 26880.459411382675, "episode/length": 221.0, "episode/score": 0.23903627953404794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23903627953404794}
{"step": 536264, "time": 26895.31164097786, "episode/length": 150.0, "episode/score": 0.16316721025577863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16316721025577863}
{"step": 536288, "time": 26897.96933412552, "episode/length": 144.0, "episode/score": 0.15045529872077168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15045529872077168}
{"step": 536864, "time": 26921.12683081627, "episode/length": 155.0, "episode/score": 0.17765654951654142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17765654951654142}
{"step": 537056, "time": 26929.79109120369, "episode/length": 175.0, "episode/score": 0.18860731922541163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18860731922541163}
{"step": 537336, "time": 26941.84069776535, "episode/length": 180.0, "episode/score": 0.20225738838598772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20225738838598772}
{"step": 537440, "time": 26948.08829808235, "episode/length": 219.0, "episode/score": 0.2612844305476756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2612844305476756}
{"step": 537720, "time": 26959.812786102295, "episode/length": 181.0, "episode/score": 0.2074078750983972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2074078750983972}
{"step": 537784, "time": 26963.718372106552, "episode/length": 186.0, "episode/score": 0.16840768893871427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16840768893871427}
{"step": 538008, "time": 26973.624829769135, "episode/length": 272.0, "episode/score": 0.2937652494892973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2937652494892973}
{"step": 538264, "time": 26984.760498523712, "episode/length": 174.0, "episode/score": 0.19720247937038948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19720247937038948}
{"step": 538312, "time": 26988.015070199966, "episode/length": 300.0, "episode/score": 0.3277256419805781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3277256419805781}
{"step": 538560, "time": 26998.942936897278, "episode/length": 187.0, "episode/score": 0.20369537400074478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20369537400074478}
{"step": 538680, "time": 27004.60808134079, "episode/length": 167.0, "episode/score": 0.19403532951946545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19403532951946545}
{"step": 538832, "time": 27012.154015302658, "episode/length": 64.0, "episode/score": 0.07381478092793259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07381478092793259}
{"step": 538928, "time": 27017.16798019409, "episode/length": 150.0, "episode/score": 0.15123428909646464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15123428909646464}
{"step": 539032, "time": 27022.31163406372, "episode/length": 43.0, "episode/score": 0.051113094290485606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051113094290485606}
{"step": 539064, "time": 27025.027993917465, "episode/length": 202.0, "episode/score": 0.2255886725279197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2255886725279197}
{"step": 539240, "time": 27033.012627124786, "episode/length": 181.0, "episode/score": 0.1967187045247556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1967187045247556}
{"step": 539368, "time": 27039.37867331505, "episode/length": 169.0, "episode/score": 0.17554246647068794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17554246647068794}
{"step": 539752, "time": 27055.186580896378, "episode/length": 148.0, "episode/score": 0.1429485788603415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1429485788603415}
{"step": 539808, "time": 27058.967672348022, "episode/length": 192.0, "episode/score": 0.2161688786554805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2161688786554805}
{"step": 540072, "time": 27087.778732061386, "eval_episode/length": 128.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9922480620155039}
{"step": 540072, "time": 27089.899166107178, "eval_episode/length": 145.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9657534246575342}
{"step": 540072, "time": 27091.422335147858, "eval_episode/length": 146.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 540072, "time": 27093.277024507523, "eval_episode/length": 153.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 540072, "time": 27095.219617128372, "eval_episode/length": 163.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 540072, "time": 27096.709715604782, "eval_episode/length": 165.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 540072, "time": 27098.605826616287, "eval_episode/length": 173.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 540072, "time": 27106.543538093567, "eval_episode/length": 162.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 540136, "time": 27108.93429160118, "episode/length": 162.0, "episode/score": 0.15579313113266835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15579313113266835}
{"step": 540208, "time": 27113.409621477127, "episode/length": 49.0, "episode/score": 0.05854166566859931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05854166566859931}
{"step": 540304, "time": 27118.51204586029, "episode/length": 154.0, "episode/score": 0.16145201033032208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16145201033032208}
{"step": 540432, "time": 27124.940601587296, "episode/length": 174.0, "episode/score": 0.19317260982461448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19317260982461448}
{"step": 540448, "time": 27127.167471170425, "episode/length": 189.0, "episode/score": 0.20786184532789775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20786184532789775}
{"step": 540496, "time": 27130.4514169693, "episode/length": 156.0, "episode/score": 0.18117468980199192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18117468980199192}
{"step": 540536, "time": 27133.221066236496, "episode/length": 145.0, "episode/score": 0.15399888112369808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15399888112369808}
{"step": 541256, "time": 27163.154547452927, "episode/length": 187.0, "episode/score": 0.20095192918779503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20095192918779503}
{"step": 541456, "time": 27172.451483488083, "episode/length": 143.0, "episode/score": 0.16766804839335236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16766804839335236}
{"step": 541848, "time": 27188.38900756836, "episode/length": 176.0, "episode/score": 0.1953671570372535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1953671570372535}
{"step": 541864, "time": 27190.472138404846, "episode/length": 170.0, "episode/score": 0.16387069335360138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16387069335360138}
{"step": 542352, "time": 27210.37062382698, "episode/length": 276.0, "episode/score": 0.29431727141854935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29431727141854935}
{"step": 542360, "time": 27212.05036830902, "episode/length": 227.0, "episode/score": 0.24283186343473062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24283186343473062}
{"step": 542592, "time": 27222.60947561264, "episode/length": 141.0, "episode/score": 0.14759620710447052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14759620710447052}
{"step": 542880, "time": 27234.906633138657, "episode/length": 202.0, "episode/score": 0.21171298882291012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21171298882291012}
{"step": 542912, "time": 27237.632580280304, "episode/length": 337.0, "episode/score": 0.3954355122932611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3954355122932611}
{"step": 543056, "time": 27244.46055984497, "episode/length": 150.0, "episode/score": 0.16734901239851752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16734901239851752}
{"step": 543160, "time": 27249.661630153656, "episode/length": 338.0, "episode/score": 0.39236904053541366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39236904053541366}
{"step": 543288, "time": 27256.326759576797, "episode/length": 177.0, "episode/score": 0.18726655848331575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18726655848331575}
{"step": 543848, "time": 27279.06061244011, "episode/length": 185.0, "episode/score": 0.18324875337793856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18324875337793856}
{"step": 544112, "time": 27290.494438409805, "episode/length": 219.0, "episode/score": 0.25433290678529374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25433290678529374}
{"step": 544144, "time": 27293.179735660553, "episode/length": 153.0, "episode/score": 0.1847646162973433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1847646162973433}
{"step": 544392, "time": 27303.681171894073, "episode/length": 153.0, "episode/score": 0.17121130670420825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17121130670420825}
{"step": 544616, "time": 27313.570314645767, "episode/length": 194.0, "episode/score": 0.22026024003298517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22026024003298517}
{"step": 544664, "time": 27317.104806900024, "episode/length": 171.0, "episode/score": 0.16833376472641248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16833376472641248}
{"step": 544712, "time": 27320.44395017624, "episode/length": 264.0, "episode/score": 0.31593147520561615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31593147520561615}
{"step": 544793, "time": 27325.967843055725, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.213017981822096, "train/action_min": 0.0, "train/action_std": 4.904292958927906, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007842871243148808, "train/actor_opt_grad_steps": 33320.0, "train/actor_opt_loss": -7.752136117793385, "train/adv_mag": 0.17817428180082576, "train/adv_max": 0.1273046995359143, "train/adv_mean": 4.7214661587825355e-05, "train/adv_min": -0.17682288000433463, "train/adv_std": 0.013672741401324592, "train/cont_avg": 0.9947634719488189, "train/cont_loss_mean": 0.0001513045238365795, "train/cont_loss_std": 0.004462631944348028, "train/cont_neg_acc": 0.9913635817099744, "train/cont_neg_loss": 0.015954039024302435, "train/cont_pos_acc": 0.9999845027923584, "train/cont_pos_loss": 5.443412369575483e-05, "train/cont_pred": 0.9947803893427211, "train/cont_rate": 0.9947634719488189, "train/dyn_loss_mean": 11.501685037387638, "train/dyn_loss_std": 8.536674202896478, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1427633375457422, "train/extr_critic_critic_opt_grad_steps": 33320.0, "train/extr_critic_critic_opt_loss": 12180.610828309547, "train/extr_critic_mag": 0.2825988822095976, "train/extr_critic_max": 0.2825988822095976, "train/extr_critic_mean": 0.23161435796050575, "train/extr_critic_min": 0.001989581453518605, "train/extr_critic_std": 0.05562652398164817, "train/extr_return_normed_mag": 0.19007938337607647, "train/extr_return_normed_max": 0.19007938337607647, "train/extr_return_normed_mean": 0.13890588975797488, "train/extr_return_normed_min": -0.09177124928536377, "train/extr_return_normed_std": 0.05757178820845649, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28283502595631155, "train/extr_return_raw_max": 0.28283502595631155, "train/extr_return_raw_mean": 0.23166153632749723, "train/extr_return_raw_min": 0.0009843937055332454, "train/extr_return_raw_std": 0.0575717881497905, "train/extr_reward_mag": 0.00130760106514758, "train/extr_reward_max": 0.00130760106514758, "train/extr_reward_mean": 0.0010969118429641203, "train/extr_reward_min": 1.072414278045414e-05, "train/extr_reward_std": 0.0002409366753977159, "train/image_loss_mean": 5.469506896386935, "train/image_loss_std": 10.35805891817949, "train/model_loss_mean": 12.4106580554031, "train/model_loss_std": 13.906849448136457, "train/model_opt_grad_norm": 53.73989597831186, "train/model_opt_grad_steps": 33288.259842519685, "train/model_opt_loss": 15513.322519377462, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.7623773259440747, "train/policy_entropy_max": 2.7623773259440747, "train/policy_entropy_mean": 2.088449158067778, "train/policy_entropy_min": 0.08070830361345621, "train/policy_entropy_std": 0.6201760740730706, "train/policy_logprob_mag": 7.438193963268611, "train/policy_logprob_max": -0.009639731960327138, "train/policy_logprob_mean": -2.0882805219785436, "train/policy_logprob_min": -7.438193963268611, "train/policy_logprob_std": 1.1634443256798692, "train/policy_randomness_mag": 0.9749979724095562, "train/policy_randomness_max": 0.9749979724095562, "train/policy_randomness_mean": 0.737130896312984, "train/policy_randomness_min": 0.028486489369643955, "train/policy_randomness_std": 0.2188949390189854, "train/post_ent_mag": 59.48581905815545, "train/post_ent_max": 59.48581905815545, "train/post_ent_mean": 41.55312806978, "train/post_ent_min": 20.591644332164854, "train/post_ent_std": 7.127928594904621, "train/prior_ent_mag": 68.8153353112889, "train/prior_ent_max": 68.8153353112889, "train/prior_ent_mean": 53.1090457345557, "train/prior_ent_min": 33.13533131156381, "train/prior_ent_std": 5.5185060388459934, "train/rep_loss_mean": 11.501685037387638, "train/rep_loss_std": 8.536674202896478, "train/reward_avg": 0.0010591947517585097, "train/reward_loss_mean": 0.03998886653053479, "train/reward_loss_std": 0.011463064509700603, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001277663576321339, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039988866442535805, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010601294558773946, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.6794392259042954, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.719626168224299, "train_stats/max_log_achievement_collect_sapling": 1.0934579439252337, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.02803738317757, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.12149532710280374, "train_stats/max_log_achievement_eat_cow": 0.018691588785046728, "train_stats/max_log_achievement_make_wood_pickaxe": 0.028037383177570093, "train_stats/max_log_achievement_make_wood_sword": 0.028037383177570093, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.514018691588785, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.21495327102803738, "train_stats/max_log_achievement_wake_up": 0.19626168224299065, "train_stats/mean_log_entropy": 2.1150312925053534, "eval_stats/sum_log_reward": 1.4750000243075192, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 1.5625, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.25, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.112533911713399e-05, "report/cont_loss_std": 0.00020095513900741935, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.6434248108416796e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.0952085833414458e-05, "report/cont_pred": 0.9950966238975525, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.196327209472656, "report/dyn_loss_std": 8.04340648651123, "report/image_loss_mean": 5.216805458068848, "report/image_loss_std": 9.070920944213867, "report/model_loss_mean": 11.975634574890137, "report/model_loss_std": 12.232115745544434, "report/post_ent_mag": 59.264678955078125, "report/post_ent_max": 59.264678955078125, "report/post_ent_mean": 41.46129608154297, "report/post_ent_min": 19.01366424560547, "report/post_ent_std": 7.319164752960205, "report/prior_ent_mag": 68.95458221435547, "report/prior_ent_max": 68.95458221435547, "report/prior_ent_mean": 53.35228729248047, "report/prior_ent_min": 35.403892517089844, "report/prior_ent_std": 5.564468860626221, "report/rep_loss_mean": 11.196327209472656, "report/rep_loss_std": 8.04340648651123, "report/reward_avg": 0.001090110745280981, "report/reward_loss_mean": 0.04101185500621796, "report/reward_loss_std": 0.010518800467252731, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013257265090942383, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04101185500621796, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00108561001252383, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 8.430542038695421e-06, "eval/cont_loss_std": 0.00011586580512812361, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0012497247662395239, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.783251824846957e-06, "eval/cont_pred": 0.997069239616394, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.887889862060547, "eval/dyn_loss_std": 9.812422752380371, "eval/image_loss_mean": 7.163461685180664, "eval/image_loss_std": 10.263415336608887, "eval/model_loss_mean": 16.995800018310547, "eval/model_loss_std": 14.286691665649414, "eval/post_ent_mag": 56.19962692260742, "eval/post_ent_max": 56.19962692260742, "eval/post_ent_mean": 40.66865158081055, "eval/post_ent_min": 21.384395599365234, "eval/post_ent_std": 7.034067630767822, "eval/prior_ent_mag": 68.95458221435547, "eval/prior_ent_max": 68.95458221435547, "eval/prior_ent_mean": 53.999568939208984, "eval/prior_ent_min": 32.20103454589844, "eval/prior_ent_std": 5.228241443634033, "eval/rep_loss_mean": 15.887889862060547, "eval/rep_loss_std": 9.812422752380371, "eval/reward_avg": 0.004101562313735485, "eval/reward_loss_mean": 0.29959461092948914, "eval/reward_loss_std": 2.346092700958252, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012655258178710938, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.15934871137142181, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.675321578979492, "eval/reward_pred": 0.0010350068332627416, "eval/reward_rate": 0.0068359375, "replay/size": 544289.0, "replay/inserts": 20352.0, "replay/samples": 20352.0, "replay/insert_wait_avg": 1.3096621201473212e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.815260744694644e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3968.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1492520570755005e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1767275333405, "timer/env.step_count": 2544.0, "timer/env.step_total": 229.8862853050232, "timer/env.step_frac": 0.229845665247555, "timer/env.step_avg": 0.09036410585889276, "timer/env.step_min": 0.022524118423461914, "timer/env.step_max": 3.025810956954956, "timer/replay._sample_count": 20352.0, "timer/replay._sample_total": 9.926864624023438, "timer/replay._sample_frac": 0.009925110583711847, "timer/replay._sample_avg": 0.0004877586784602711, "timer/replay._sample_min": 0.00040340423583984375, "timer/replay._sample_max": 0.010943174362182617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3040.0, "timer/agent.policy_total": 49.78453826904297, "timer/agent.policy_frac": 0.04977574152502306, "timer/agent.policy_avg": 0.01637649285165887, "timer/agent.policy_min": 0.009711265563964844, "timer/agent.policy_max": 0.1389460563659668, "timer/dataset_train_count": 1272.0, "timer/dataset_train_total": 0.13766956329345703, "timer/dataset_train_frac": 0.00013764523759014167, "timer/dataset_train_avg": 0.00010823078875271779, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.0003285408020019531, "timer/agent.train_count": 1272.0, "timer/agent.train_total": 571.112779378891, "timer/agent.train_frac": 0.5710118658603294, "timer/agent.train_avg": 0.4489880341029017, "timer/agent.train_min": 0.43729424476623535, "timer/agent.train_max": 1.0571238994598389, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48024606704711914, "timer/agent.report_frac": 0.00048016120934098655, "timer/agent.report_avg": 0.24012303352355957, "timer/agent.report_min": 0.23342561721801758, "timer/agent.report_max": 0.24682044982910156, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.9558679975992794e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 20.34814696418258}
{"step": 545000, "time": 27333.55603003502, "episode/length": 264.0, "episode/score": 0.29561314953662077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29561314953662077}
{"step": 545024, "time": 27336.235983371735, "episode/length": 38.0, "episode/score": 0.04499999922700226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04499999922700226}
{"step": 545032, "time": 27337.851063489914, "episode/length": 147.0, "episode/score": 0.16992054321599426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16992054321599426}
{"step": 545504, "time": 27357.115406513214, "episode/length": 169.0, "episode/score": 0.19213616374327103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19213616374327103}
{"step": 545688, "time": 27365.272913455963, "episode/length": 161.0, "episode/score": 0.183592156136001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.183592156136001}
{"step": 545752, "time": 27369.27610564232, "episode/length": 204.0, "episode/score": 0.2431666620541364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2431666620541364}
{"step": 546112, "time": 27384.445202827454, "episode/length": 186.0, "episode/score": 0.19097004425930209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19097004425930209}
{"step": 546336, "time": 27394.264166355133, "episode/length": 162.0, "episode/score": 0.1912960426452628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1912960426452628}
{"step": 546656, "time": 27407.799641609192, "episode/length": 248.0, "episode/score": 0.2809052513403003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2809052513403003}
{"step": 546680, "time": 27410.083369493484, "episode/length": 146.0, "episode/score": 0.15414024757228617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15414024757228617}
{"step": 546952, "time": 27421.621529340744, "episode/length": 243.0, "episode/score": 0.2816433876287192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2816433876287192}
{"step": 547136, "time": 27430.29164791107, "episode/length": 172.0, "episode/score": 0.17828102645944455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17828102645944455}
{"step": 547176, "time": 27433.11551308632, "episode/length": 185.0, "episode/score": 0.2137546780431876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2137546780431876}
{"step": 547208, "time": 27435.9224960804, "episode/length": 272.0, "episode/score": 0.3020085142343305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3020085142343305}
{"step": 547664, "time": 27454.680146932602, "episode/length": 165.0, "episode/score": 0.1599421086957591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1599421086957591}
{"step": 547952, "time": 27466.916803121567, "episode/length": 161.0, "episode/score": 0.1809808179441461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1809808179441461}
{"step": 548072, "time": 27472.67842721939, "episode/length": 173.0, "episode/score": 0.18399629236228066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18399629236228066}
{"step": 548376, "time": 27485.459939718246, "episode/length": 282.0, "episode/score": 0.32262239528427017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32262239528427017}
{"step": 548408, "time": 27488.226440429688, "episode/length": 153.0, "episode/score": 0.16968030448333593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16968030448333593}
{"step": 548688, "time": 27500.561680316925, "episode/length": 184.0, "episode/score": 0.18952121577058278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18952121577058278}
{"step": 548688, "time": 27500.57078933716, "episode/length": 216.0, "episode/score": 0.22530021026614122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22530021026614122}
{"step": 549008, "time": 27517.21131181717, "episode/length": 233.0, "episode/score": 0.2405065191032918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2405065191032918}
{"step": 549048, "time": 27520.070454120636, "episode/length": 136.0, "episode/score": 0.14551687843322725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14551687843322725}
{"step": 549288, "time": 27530.5734436512, "episode/length": 202.0, "episode/score": 0.2075622070233294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2075622070233294}
{"step": 549600, "time": 27544.407923698425, "episode/length": 190.0, "episode/score": 0.20685519338894665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20685519338894665}
{"step": 549776, "time": 27553.090902090073, "episode/length": 170.0, "episode/score": 0.19220710844001587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19220710844001587}
{"step": 549848, "time": 27557.023512601852, "episode/length": 183.0, "episode/score": 0.20255887515031645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20255887515031645}
{"step": 550056, "time": 27583.88337826729, "eval_episode/length": 110.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9459459459459459}
{"step": 550056, "time": 27585.95295071602, "eval_episode/length": 125.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9523809523809523}
{"step": 550056, "time": 27590.035121440887, "eval_episode/length": 187.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9680851063829787}
{"step": 550056, "time": 27591.927540779114, "eval_episode/length": 197.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 550056, "time": 27594.37069129944, "eval_episode/length": 217.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 550056, "time": 27596.626524686813, "eval_episode/length": 225.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 550056, "time": 27602.371824026108, "eval_episode/length": 306.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9869706840390879}
{"step": 550056, "time": 27605.19346022606, "eval_episode/length": 202.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 550248, "time": 27612.382072210312, "episode/length": 58.0, "episode/score": 0.06261547497160791, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06261547497160791}
{"step": 550304, "time": 27616.282701730728, "episode/length": 201.0, "episode/score": 0.228065561319454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.228065561319454}
{"step": 550416, "time": 27622.088183403015, "episode/length": 175.0, "episode/score": 0.19761141159142426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19761141159142426}
{"step": 550624, "time": 27631.474569559097, "episode/length": 241.0, "episode/score": 0.28068846851329, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28068846851329}
{"step": 550624, "time": 27631.482658147812, "episode/length": 166.0, "episode/score": 0.17775423741841223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17775423741841223}
{"step": 551016, "time": 27649.24975347519, "episode/length": 245.0, "episode/score": 0.2827198859467899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2827198859467899}
{"step": 551312, "time": 27662.134247779846, "episode/length": 213.0, "episode/score": 0.23786886689595121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23786886689595121}
{"step": 551608, "time": 27674.574359178543, "episode/length": 169.0, "episode/score": 0.18730831685115845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18730831685115845}
{"step": 551688, "time": 27679.14780831337, "episode/length": 158.0, "episode/score": 0.15933691530335636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15933691530335636}
{"step": 551888, "time": 27688.374865293503, "episode/length": 157.0, "episode/score": 0.18605248567837407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18605248567837407}
{"step": 551992, "time": 27694.175213336945, "episode/length": 210.0, "episode/score": 0.2433153651381872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2433153651381872}
{"step": 552384, "time": 27710.583785057068, "episode/length": 219.0, "episode/score": 0.24859482487772766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24859482487772766}
{"step": 552416, "time": 27713.1644384861, "episode/length": 320.0, "episode/score": 0.3644645272388516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3644645272388516}
{"step": 552816, "time": 27729.72379875183, "episode/length": 115.0, "episode/score": 0.13111142791240127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13111142791240127}
{"step": 552928, "time": 27735.416829109192, "episode/length": 201.0, "episode/score": 0.2011401119771108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2011401119771108}
{"step": 553144, "time": 27744.814155817032, "episode/length": 191.0, "episode/score": 0.1948404384602327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1948404384602327}
{"step": 553280, "time": 27751.590487003326, "episode/length": 160.0, "episode/score": 0.17858333070762455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17858333070762455}
{"step": 553352, "time": 27755.59513449669, "episode/length": 207.0, "episode/score": 0.23668616083614324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23668616083614324}
{"step": 553688, "time": 27769.62311911583, "episode/length": 158.0, "episode/score": 0.16615879596793093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16615879596793093}
{"step": 553792, "time": 27775.236171007156, "episode/length": 80.0, "episode/score": 0.09191776433726773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09191776433726773}
{"step": 553872, "time": 27779.81747817993, "episode/length": 185.0, "episode/score": 0.19775446139101405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19775446139101405}
{"step": 554000, "time": 27786.007266044617, "episode/length": 147.0, "episode/score": 0.1751719662861433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1751719662861433}
{"step": 554336, "time": 27800.02819252014, "episode/length": 414.0, "episode/score": 0.3932806018510746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3932806018510746}
{"step": 554488, "time": 27806.89601135254, "episode/length": 194.0, "episode/score": 0.19980974475038238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19980974475038238}
{"step": 554576, "time": 27811.93842101097, "episode/length": 97.0, "episode/score": 0.11756173541289172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11756173541289172}
{"step": 554904, "time": 27825.580565452576, "episode/length": 202.0, "episode/score": 0.22012794059992302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22012794059992302}
{"step": 554992, "time": 27830.734658241272, "episode/length": 162.0, "episode/score": 0.16460445568009163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16460445568009163}
{"step": 555080, "time": 27835.254296541214, "episode/length": 215.0, "episode/score": 0.22468098458557506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22468098458557506}
{"step": 555184, "time": 27840.94073200226, "episode/length": 147.0, "episode/score": 0.17255158408624993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17255158408624993}
{"step": 555504, "time": 27854.394676685333, "episode/length": 203.0, "episode/score": 0.21666252615432313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21666252615432313}
{"step": 555712, "time": 27863.654032707214, "episode/length": 141.0, "episode/score": 0.1459758137807512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1459758137807512}
{"step": 555864, "time": 27870.70616722107, "episode/length": 190.0, "episode/score": 0.21282606296153972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21282606296153972}
{"step": 556224, "time": 27886.526577949524, "episode/length": 216.0, "episode/score": 0.2379391784670588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2379391784670588}
{"step": 556312, "time": 27891.136518716812, "episode/length": 140.0, "episode/score": 0.16387814819609048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16387814819609048}
{"step": 556376, "time": 27895.120779514313, "episode/length": 183.0, "episode/score": 0.21431672477228858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21431672477228858}
{"step": 556472, "time": 27900.28172636032, "episode/length": 184.0, "episode/score": 0.1840431894397625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1840431894397625}
{"step": 556728, "time": 27911.246588230133, "episode/length": 205.0, "episode/score": 0.24208332880516537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24208332880516537}
{"step": 557288, "time": 27935.34000825882, "episode/length": 177.0, "episode/score": 0.17855356626932917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17855356626932917}
{"step": 557432, "time": 27942.311579942703, "episode/length": 150.0, "episode/score": 0.13930270211676543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13930270211676543}
{"step": 557520, "time": 27947.372587442398, "episode/length": 142.0, "episode/score": 0.1651319001266529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1651319001266529}
{"step": 557824, "time": 27960.312824964523, "episode/length": 168.0, "episode/score": 0.18871316234435653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18871316234435653}
{"step": 557880, "time": 27963.654521226883, "episode/length": 143.0, "episode/score": 0.13894148803774442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13894148803774442}
{"step": 557920, "time": 27966.93327355385, "episode/length": 301.0, "episode/score": 0.3214438776994939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3214438776994939}
{"step": 557968, "time": 27970.24178671837, "episode/length": 206.0, "episode/score": 0.2234612751753957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2234612751753957}
{"step": 558024, "time": 27973.516348838806, "episode/length": 288.0, "episode/score": 0.2994138243066118, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2994138243066118}
{"step": 558664, "time": 27998.720365285873, "episode/length": 153.0, "episode/score": 0.12874796511277964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12874796511277964}
{"step": 558736, "time": 28003.1576693058, "episode/length": 151.0, "episode/score": 0.1690860494491062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1690860494491062}
{"step": 558856, "time": 28008.99792408943, "episode/length": 195.0, "episode/score": 0.21056493038213375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21056493038213375}
{"step": 559112, "time": 28019.941410303116, "episode/length": 135.0, "episode/score": 0.132473604407096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.132473604407096}
{"step": 559160, "time": 28023.338091611862, "episode/length": 154.0, "episode/score": 0.16803438931310666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16803438931310666}
{"step": 559256, "time": 28028.53646326065, "episode/length": 171.0, "episode/score": 0.18605562697575806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18605562697575806}
{"step": 559328, "time": 28033.069632530212, "episode/length": 169.0, "episode/score": 0.19688527136167977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19688527136167977}
{"step": 560040, "time": 28077.762075662613, "eval_episode/length": 102.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9514563106796117}
{"step": 560040, "time": 28080.75087404251, "eval_episode/length": 140.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 560040, "time": 28082.634493112564, "eval_episode/length": 149.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 560040, "time": 28084.827506542206, "eval_episode/length": 165.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 560040, "time": 28087.393444299698, "eval_episode/length": 186.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 560040, "time": 28090.62759566307, "eval_episode/length": 228.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 560040, "time": 28093.77528166771, "eval_episode/length": 269.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9962962962962963}
{"step": 560040, "time": 28098.203774690628, "eval_episode/length": 189.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 560128, "time": 28101.708360671997, "episode/length": 173.0, "episode/score": 0.18783569498828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18783569498828}
{"step": 560192, "time": 28105.534482717514, "episode/length": 166.0, "episode/score": 0.18256635705620283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18256635705620283}
{"step": 560224, "time": 28108.16956090927, "episode/length": 194.0, "episode/score": 0.2125023327926101, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2125023327926101}
{"step": 560280, "time": 28111.58568739891, "episode/length": 145.0, "episode/score": 0.1744166632706765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1744166632706765}
{"step": 560392, "time": 28117.34278512001, "episode/length": 153.0, "episode/score": 0.15690302225993946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15690302225993946}
{"step": 560608, "time": 28126.966175079346, "episode/length": 159.0, "episode/score": 0.15391006327263312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15391006327263312}
{"step": 560984, "time": 28142.261122465134, "episode/length": 215.0, "episode/score": 0.22867330861481605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22867330861481605}
{"step": 561184, "time": 28151.629765033722, "episode/length": 419.0, "episode/score": 0.4453088210257192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4453088210257192}
{"step": 561312, "time": 28157.872965335846, "episode/length": 139.0, "episode/score": 0.14856042323299334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14856042323299334}
{"step": 561376, "time": 28161.692007780075, "episode/length": 143.0, "episode/score": 0.14732623875534046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14732623875534046}
{"step": 561416, "time": 28164.407308340073, "episode/length": 141.0, "episode/score": 0.1475074933914584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1475074933914584}
{"step": 561608, "time": 28173.015962839127, "episode/length": 151.0, "episode/score": 0.15827592169080162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15827592169080162}
{"step": 561824, "time": 28182.877861261368, "episode/length": 211.0, "episode/score": 0.2219821541766578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2219821541766578}
{"step": 562528, "time": 28210.53542280197, "episode/length": 151.0, "episode/score": 0.15225702358475246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15225702358475246}
{"step": 562584, "time": 28213.910930633545, "episode/length": 150.0, "episode/score": 0.1584995866396639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1584995866396639}
{"step": 562640, "time": 28217.775032520294, "episode/length": 206.0, "episode/score": 0.2313956445796066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2313956445796066}
{"step": 562800, "time": 28225.326773405075, "episode/length": 172.0, "episode/score": 0.19399832472663547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19399832472663547}
{"step": 562856, "time": 28228.650129795074, "episode/length": 155.0, "episode/score": 0.1567316636446776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1567316636446776}
{"step": 563056, "time": 28237.87481069565, "episode/length": 233.0, "episode/score": 0.2699777513225854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2699777513225854}
{"step": 563080, "time": 28240.058340787888, "episode/length": 54.0, "episode/score": 0.055660386744420975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055660386744420975}
{"step": 563232, "time": 28247.703301906586, "episode/length": 175.0, "episode/score": 0.19016379761706048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19016379761706048}
{"step": 563368, "time": 28254.027020454407, "episode/length": 344.0, "episode/score": 0.38711198788223555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.38711198788223555}
{"step": 564184, "time": 28286.365165233612, "episode/length": 206.0, "episode/score": 0.22929951287551376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22929951287551376}
{"step": 564256, "time": 28290.78521680832, "episode/length": 208.0, "episode/score": 0.2239779129940871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2239779129940871}
{"step": 564424, "time": 28298.478574991226, "episode/length": 170.0, "episode/score": 0.17261136755951156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17261136755951156}
{"step": 564464, "time": 28301.653185367584, "episode/length": 207.0, "episode/score": 0.21745341546920827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21745341546920827}
{"step": 564512, "time": 28305.084645032883, "episode/length": 206.0, "episode/score": 0.2384380300190969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2384380300190969}
{"step": 564576, "time": 28309.086696863174, "episode/length": 167.0, "episode/score": 0.1792311864282965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1792311864282965}
{"step": 564688, "time": 28314.902312755585, "episode/length": 164.0, "episode/score": 0.16770553980495606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16770553980495606}
{"step": 564904, "time": 28324.40989470482, "episode/length": 227.0, "episode/score": 0.25666335455389344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25666335455389344}
{"step": 564905, "time": 28327.174286603928, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.989168197389633, "train/action_min": 0.0, "train/action_std": 4.743856324089898, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007511711962121938, "train/actor_opt_grad_steps": 34585.0, "train/actor_opt_loss": -10.528557441300816, "train/adv_mag": 0.1751800108523596, "train/adv_max": 0.12935199003134454, "train/adv_mean": -5.840658373955872e-05, "train/adv_min": -0.17346290983850993, "train/adv_std": 0.013488616838696458, "train/cont_avg": 0.9947684151785714, "train/cont_loss_mean": 0.0002039877284142714, "train/cont_loss_std": 0.0062693611692134525, "train/cont_neg_acc": 0.9923280434949058, "train/cont_neg_loss": 0.030681302502382587, "train/cont_pos_acc": 0.99999219794122, "train/cont_pos_loss": 4.3227962249223164e-05, "train/cont_pred": 0.9947864384878249, "train/cont_rate": 0.9947684151785714, "train/dyn_loss_mean": 11.398434964437334, "train/dyn_loss_std": 8.502487492939782, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14219144699237649, "train/extr_critic_critic_opt_grad_steps": 34585.0, "train/extr_critic_critic_opt_loss": 12254.024011036707, "train/extr_critic_mag": 0.28330411797478083, "train/extr_critic_max": 0.28330411797478083, "train/extr_critic_mean": 0.2333137627158846, "train/extr_critic_min": 0.001773657306792244, "train/extr_critic_std": 0.05614005593908212, "train/extr_return_normed_mag": 0.19295904832699942, "train/extr_return_normed_max": 0.19295904832699942, "train/extr_return_normed_mean": 0.14259788600934875, "train/extr_return_normed_min": -0.08964674795667331, "train/extr_return_normed_std": 0.05796705848640866, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2836164529361422, "train/extr_return_raw_max": 0.2836164529361422, "train/extr_return_raw_mean": 0.23325529599946643, "train/extr_return_raw_min": 0.001010657302916996, "train/extr_return_raw_std": 0.05796705801335592, "train/extr_reward_mag": 0.0013105576000516377, "train/extr_reward_max": 0.0013105576000516377, "train/extr_reward_mean": 0.0010942400789760527, "train/extr_reward_min": 1.0339040604848711e-05, "train/extr_reward_std": 0.00024406609540280429, "train/image_loss_mean": 5.325424648466564, "train/image_loss_std": 10.152977667157613, "train/model_loss_mean": 12.204513125949436, "train/model_loss_std": 13.69130175454276, "train/model_opt_grad_norm": 54.81690639919705, "train/model_opt_grad_steps": 34552.142857142855, "train/model_opt_loss": 17758.447722904264, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1448.4126984126983, "train/policy_entropy_mag": 2.7623726413363503, "train/policy_entropy_max": 2.7623726413363503, "train/policy_entropy_mean": 2.0773739521465604, "train/policy_entropy_min": 0.08080184737604762, "train/policy_entropy_std": 0.6332627210825209, "train/policy_logprob_mag": 7.438187951133365, "train/policy_logprob_max": -0.009652357541083817, "train/policy_logprob_mean": -2.0781322906887723, "train/policy_logprob_min": -7.438187951133365, "train/policy_logprob_std": 1.171256907402523, "train/policy_randomness_mag": 0.9749963188928271, "train/policy_randomness_max": 0.9749963188928271, "train/policy_randomness_mean": 0.7332218341411106, "train/policy_randomness_min": 0.028519506241002725, "train/policy_randomness_std": 0.2235139487754731, "train/post_ent_mag": 59.07038546365405, "train/post_ent_max": 59.07038546365405, "train/post_ent_mean": 41.610536484491256, "train/post_ent_min": 20.37515381404332, "train/post_ent_std": 7.125972498030889, "train/prior_ent_mag": 68.87589506119016, "train/prior_ent_max": 68.87589506119016, "train/prior_ent_mean": 53.101701040116566, "train/prior_ent_min": 33.21560175456698, "train/prior_ent_std": 5.375636717629811, "train/rep_loss_mean": 11.398434964437334, "train/rep_loss_std": 8.502487492939782, "train/reward_avg": 0.0010544808760714081, "train/reward_loss_mean": 0.039823600992796915, "train/reward_loss_std": 0.011637999033111902, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012757409186590287, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.03982360093366532, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001054274391323801, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.43944951215195, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.128440366972477, "train_stats/max_log_achievement_collect_sapling": 1.0825688073394495, "train_stats/max_log_achievement_collect_stone": 0.009174311926605505, "train_stats/max_log_achievement_collect_wood": 0.8715596330275229, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.11009174311926606, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.01834862385321101, "train_stats/max_log_achievement_make_wood_sword": 0.01834862385321101, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.29357798165137616, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.13761467889908258, "train_stats/max_log_achievement_wake_up": 0.1559633027522936, "train_stats/mean_log_entropy": 2.096843068752814, "eval_stats/sum_log_reward": 1.0999999772757292, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 9.375, "eval_stats/max_log_achievement_collect_sapling": 1.1875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 1.1231972166569903e-05, "report/cont_loss_std": 7.254602678585798e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00018767068104352802, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.491944183537271e-06, "report/cont_pred": 0.9902268052101135, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 12.985535621643066, "report/dyn_loss_std": 9.355228424072266, "report/image_loss_mean": 5.441246509552002, "report/image_loss_std": 11.141510963439941, "report/model_loss_mean": 13.272806167602539, "report/model_loss_std": 14.862679481506348, "report/post_ent_mag": 55.29428482055664, "report/post_ent_max": 55.29428482055664, "report/post_ent_mean": 39.37492370605469, "report/post_ent_min": 21.584495544433594, "report/post_ent_std": 6.825181484222412, "report/prior_ent_mag": 68.894775390625, "report/prior_ent_max": 68.894775390625, "report/prior_ent_mean": 52.10588836669922, "report/prior_ent_min": 33.22974395751953, "report/prior_ent_std": 5.044930934906006, "report/rep_loss_mean": 12.985535621643066, "report/rep_loss_std": 9.355228424072266, "report/reward_avg": 0.0010681363055482507, "report/reward_loss_mean": 0.04022727906703949, "report/reward_loss_std": 0.011667173355817795, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012655258178710938, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04022727906703949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001081615686416626, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.5821087749354774e-06, "eval/cont_loss_std": 6.8628269218606874e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.2653297744691372e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.537598558978061e-06, "eval/cont_pred": 0.995113730430603, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.989343643188477, "eval/dyn_loss_std": 10.033931732177734, "eval/image_loss_mean": 8.237638473510742, "eval/image_loss_std": 13.707659721374512, "eval/model_loss_mean": 18.395614624023438, "eval/model_loss_std": 18.173158645629883, "eval/post_ent_mag": 56.176292419433594, "eval/post_ent_max": 56.176292419433594, "eval/post_ent_mean": 40.11402893066406, "eval/post_ent_min": 22.718555450439453, "eval/post_ent_std": 6.563066482543945, "eval/prior_ent_mag": 68.894775390625, "eval/prior_ent_max": 68.894775390625, "eval/prior_ent_mean": 53.26469421386719, "eval/prior_ent_min": 39.34520721435547, "eval/prior_ent_std": 4.828610897064209, "eval/rep_loss_mean": 15.989343643188477, "eval/rep_loss_std": 10.033931732177734, "eval/reward_avg": 0.004492186941206455, "eval/reward_loss_mean": 0.5643675923347473, "eval/reward_loss_std": 3.3200571537017822, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012704133987426758, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.36669379472732544, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.608489990234375, "eval/reward_pred": 0.0010331720113754272, "eval/reward_rate": 0.009765625, "replay/size": 564401.0, "replay/inserts": 20112.0, "replay/samples": 20112.0, "replay/insert_wait_avg": 1.3335057450554726e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.908995794510215e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5352.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.150396372705297e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.191743850708, "timer/env.step_count": 2514.0, "timer/env.step_total": 232.65799260139465, "timer/env.step_frac": 0.2323810539093771, "timer/env.step_avg": 0.09254494534661681, "timer/env.step_min": 0.02227020263671875, "timer/env.step_max": 3.2044758796691895, "timer/replay._sample_count": 20112.0, "timer/replay._sample_total": 9.805575847625732, "timer/replay._sample_frac": 0.009793904022732216, "timer/replay._sample_avg": 0.00048754852066555947, "timer/replay._sample_min": 0.0003285408020019531, "timer/replay._sample_max": 0.028754711151123047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3183.0, "timer/agent.policy_total": 50.87726712226868, "timer/agent.policy_frac": 0.050816706624635534, "timer/agent.policy_avg": 0.015984061301372504, "timer/agent.policy_min": 0.009776830673217773, "timer/agent.policy_max": 0.11505007743835449, "timer/dataset_train_count": 1257.0, "timer/dataset_train_total": 0.13571834564208984, "timer/dataset_train_frac": 0.00013555679666324473, "timer/dataset_train_avg": 0.00010797004426578349, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.0004763603210449219, "timer/agent.train_count": 1257.0, "timer/agent.train_total": 563.6227004528046, "timer/agent.train_frac": 0.5629518060996404, "timer/agent.train_avg": 0.4483871920865589, "timer/agent.train_min": 0.4352295398712158, "timer/agent.train_max": 1.0780348777770996, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5388853549957275, "timer/agent.report_frac": 0.0005382439061304156, "timer/agent.report_avg": 0.26944267749786377, "timer/agent.report_min": 0.25634074211120605, "timer/agent.report_max": 0.2825446128845215, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.6432960961591456e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 20.087817845005056}
{"step": 565504, "time": 28351.011937856674, "episode/length": 155.0, "episode/score": 0.16919514404889924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16919514404889924}
{"step": 565536, "time": 28353.772588014603, "episode/length": 119.0, "episode/score": 0.13475555605236877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13475555605236877}
{"step": 565744, "time": 28363.164883613586, "episode/length": 194.0, "episode/score": 0.18173902368926065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18173902368926065}
{"step": 565816, "time": 28367.07347011566, "episode/length": 168.0, "episode/score": 0.19916726712108357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19916726712108357}
{"step": 566008, "time": 28375.7468149662, "episode/length": 186.0, "episode/score": 0.19223352165863616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19223352165863616}
{"step": 566096, "time": 28380.67054128647, "episode/length": 208.0, "episode/score": 0.22911609205402783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22911609205402783}
{"step": 566128, "time": 28383.403609752655, "episode/length": 179.0, "episode/score": 0.1960726640190842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1960726640190842}
{"step": 566224, "time": 28388.628121376038, "episode/length": 164.0, "episode/score": 0.20292928858816595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20292928858816595}
{"step": 567024, "time": 28420.20973443985, "episode/length": 159.0, "episode/score": 0.17772730638898793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17772730638898793}
{"step": 567024, "time": 28420.218087911606, "episode/length": 185.0, "episode/score": 0.21471569352706865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21471569352706865}
{"step": 567104, "time": 28426.50523495674, "episode/length": 199.0, "episode/score": 0.23439938825868012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23439938825868012}
{"step": 567528, "time": 28443.70684528351, "episode/length": 178.0, "episode/score": 0.1862246148948543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1862246148948543}
{"step": 567528, "time": 28443.71497440338, "episode/length": 174.0, "episode/score": 0.18955088371876627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18955088371876627}
{"step": 567712, "time": 28454.0773396492, "episode/length": 212.0, "episode/score": 0.24382424631039612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24382424631039612}
{"step": 568456, "time": 28483.026912212372, "episode/length": 178.0, "episode/score": 0.18565257917362032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18565257917362032}
{"step": 568592, "time": 28489.8576939106, "episode/length": 295.0, "episode/score": 0.3151647626500562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3151647626500562}
{"step": 568704, "time": 28495.579026460648, "episode/length": 146.0, "episode/score": 0.14415335190096812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14415335190096812}
{"step": 568704, "time": 28495.587938070297, "episode/length": 209.0, "episode/score": 0.20733791559359815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20733791559359815}
{"step": 568968, "time": 28508.232717990875, "episode/length": 179.0, "episode/score": 0.2163423217843956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2163423217843956}
{"step": 568976, "time": 28510.18503022194, "episode/length": 233.0, "episode/score": 0.25493566627210384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25493566627210384}
{"step": 569192, "time": 28519.419330358505, "episode/length": 421.0, "episode/score": 0.4586860599238207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4586860599238207}
{"step": 569200, "time": 28521.401769161224, "episode/length": 185.0, "episode/score": 0.21512108616661862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21512108616661862}
{"step": 569480, "time": 28533.038264751434, "episode/length": 96.0, "episode/score": 0.10236065855860943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10236065855860943}
{"step": 569616, "time": 28539.95271229744, "episode/length": 144.0, "episode/score": 0.16876388585660607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16876388585660607}
{"step": 569960, "time": 28554.002838611603, "episode/length": 94.0, "episode/score": 0.11360923200845718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11360923200845718}
{"step": 570024, "time": 28576.56764292717, "eval_episode/length": 151.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.993421052631579}
{"step": 570024, "time": 28578.164725780487, "eval_episode/length": 154.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 570024, "time": 28580.426085948944, "eval_episode/length": 171.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 570024, "time": 28582.360395669937, "eval_episode/length": 180.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 570024, "time": 28583.934620141983, "eval_episode/length": 183.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 570024, "time": 28585.798877477646, "eval_episode/length": 190.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 570024, "time": 28587.63435935974, "eval_episode/length": 198.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9698492462311558}
{"step": 570024, "time": 28591.669903039932, "eval_episode/length": 99.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.95}
{"step": 570256, "time": 28601.85722541809, "episode/length": 160.0, "episode/score": 0.17450879452371737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17450879452371737}
{"step": 570288, "time": 28604.50701189041, "episode/length": 163.0, "episode/score": 0.1860291714547202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1860291714547202}
{"step": 570304, "time": 28606.547458410263, "episode/length": 199.0, "episode/score": 0.20969316961418372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20969316961418372}
{"step": 570384, "time": 28611.17486357689, "episode/length": 52.0, "episode/score": 0.05930319054823485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05930319054823485}
{"step": 570536, "time": 28618.0398042202, "episode/length": 167.0, "episode/score": 0.17482440252206288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17482440252206288}
{"step": 570776, "time": 28628.69027709961, "episode/length": 161.0, "episode/score": 0.18191100773401558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18191100773401558}
{"step": 570936, "time": 28636.08441066742, "episode/length": 49.0, "episode/score": 0.05370077409679652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05370077409679652}
{"step": 571032, "time": 28641.13854122162, "episode/length": 176.0, "episode/score": 0.20059032911012764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20059032911012764}
{"step": 571152, "time": 28647.343591928482, "episode/length": 319.0, "episode/score": 0.3812565717380494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3812565717380494}
{"step": 571480, "time": 28661.04640007019, "episode/length": 148.0, "episode/score": 0.15526532769217738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15526532769217738}
{"step": 571528, "time": 28664.31006193161, "episode/length": 142.0, "episode/score": 0.15689405550438096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15689405550438096}
{"step": 571584, "time": 28668.151487588882, "episode/length": 159.0, "episode/score": 0.18566915050178068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18566915050178068}
{"step": 571904, "time": 28681.759453058243, "episode/length": 205.0, "episode/score": 0.21689824066197616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21689824066197616}
{"step": 572360, "time": 28700.10164785385, "episode/length": 197.0, "episode/score": 0.21075432087673107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21075432087673107}
{"step": 572648, "time": 28712.590924978256, "episode/length": 201.0, "episode/score": 0.21666845149957226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21666845149957226}
{"step": 572656, "time": 28715.10451745987, "episode/length": 214.0, "episode/score": 0.25150726880019647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25150726880019647}
{"step": 572688, "time": 28717.809893131256, "episode/length": 191.0, "episode/score": 0.21654922598645499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21654922598645499}
{"step": 573152, "time": 28736.63386774063, "episode/length": 202.0, "episode/score": 0.21524682970812137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21524682970812137}
{"step": 573232, "time": 28741.119402885437, "episode/length": 218.0, "episode/score": 0.2307149620319251, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2307149620319251}
{"step": 573376, "time": 28748.110325574875, "episode/length": 223.0, "episode/score": 0.25369879258141736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25369879258141736}
{"step": 573424, "time": 28751.541326761246, "episode/length": 189.0, "episode/score": 0.2048146578217711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2048146578217711}
{"step": 573808, "time": 28768.72828745842, "episode/length": 180.0, "episode/score": 0.17992416389279242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17992416389279242}
{"step": 573872, "time": 28772.558627843857, "episode/length": 152.0, "episode/score": 0.14447837690386223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14447837690386223}
{"step": 574040, "time": 28780.103685617447, "episode/length": 168.0, "episode/score": 0.1688745760693564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1688745760693564}
{"step": 574104, "time": 28784.076446533203, "episode/length": 180.0, "episode/score": 0.19175563179123856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19175563179123856}
{"step": 574304, "time": 28793.239765644073, "episode/length": 143.0, "episode/score": 0.17086677509360015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17086677509360015}
{"step": 574384, "time": 28797.80096721649, "episode/length": 143.0, "episode/score": 0.15974815803565434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15974815803565434}
{"step": 574544, "time": 28805.265921354294, "episode/length": 145.0, "episode/score": 0.1702499968232587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1702499968232587}
{"step": 574888, "time": 28819.4201567173, "episode/length": 182.0, "episode/score": 0.18860789509562892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18860789509562892}
{"step": 575320, "time": 28837.182212352753, "episode/length": 159.0, "episode/score": 0.18070781700680527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18070781700680527}
{"step": 575368, "time": 28840.764103889465, "episode/length": 194.0, "episode/score": 0.20759893927879602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20759893927879602}
{"step": 575424, "time": 28844.677951812744, "episode/length": 193.0, "episode/score": 0.20531781255886017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20531781255886017}
{"step": 575480, "time": 28848.10468506813, "episode/length": 146.0, "episode/score": 0.16954166372306645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16954166372306645}
{"step": 575824, "time": 28862.645553827286, "episode/length": 159.0, "episode/score": 0.1745088746311012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1745088746311012}
{"step": 575920, "time": 28867.81637072563, "episode/length": 191.0, "episode/score": 0.19510272471234202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19510272471234202}
{"step": 576000, "time": 28872.242372751236, "episode/length": 236.0, "episode/score": 0.23667512090105447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23667512090105447}
{"step": 576520, "time": 28892.9694545269, "episode/length": 203.0, "episode/score": 0.22153300767695328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22153300767695328}
{"step": 576744, "time": 28902.963237524033, "episode/length": 164.0, "episode/score": 0.1836497995773243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1836497995773243}
{"step": 576744, "time": 28902.971206903458, "episode/length": 177.0, "episode/score": 0.18795636013146577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18795636013146577}
{"step": 576784, "time": 28907.95573735237, "episode/length": 162.0, "episode/score": 0.18906570215312968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18906570215312968}
{"step": 576792, "time": 28909.555888175964, "episode/length": 177.0, "episode/score": 0.18355785119638313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18355785119638313}
{"step": 577264, "time": 28929.005265712738, "episode/length": 179.0, "episode/score": 0.21384469296208408, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21384469296208408}
{"step": 577288, "time": 28931.223720788956, "episode/length": 160.0, "episode/score": 0.18358681113022612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18358681113022612}
{"step": 577936, "time": 28957.19362282753, "episode/length": 176.0, "episode/score": 0.19380287673993735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19380287673993735}
{"step": 577992, "time": 28960.590348243713, "episode/length": 258.0, "episode/score": 0.29068336718410137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29068336718410137}
{"step": 578008, "time": 28962.7961935997, "episode/length": 157.0, "episode/score": 0.1473468715630588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1473468715630588}
{"step": 578072, "time": 28966.82532596588, "episode/length": 160.0, "episode/score": 0.15674653607675282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15674653607675282}
{"step": 578304, "time": 28977.29577755928, "episode/length": 194.0, "episode/score": 0.211126971745216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.211126971745216}
{"step": 578768, "time": 28996.174349069595, "episode/length": 187.0, "episode/score": 0.2100491213695932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2100491213695932}
{"step": 579096, "time": 29009.7557117939, "episode/length": 144.0, "episode/score": 0.16022148859337904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16022148859337904}
{"step": 579104, "time": 29011.743985652924, "episode/length": 226.0, "episode/score": 0.2654693898948608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2654693898948608}
{"step": 579256, "time": 29018.733154773712, "episode/length": 155.0, "episode/score": 0.17330329791730037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17330329791730037}
{"step": 579280, "time": 29021.452454805374, "episode/length": 160.0, "episode/score": 0.17935921445314307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17935921445314307}
{"step": 579792, "time": 29041.897302865982, "episode/length": 185.0, "episode/score": 0.2017494458486908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2017494458486908}
{"step": 579952, "time": 29049.3251516819, "episode/length": 234.0, "episode/score": 0.25792916858335957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25792916858335957}
{"step": 580008, "time": 29066.930441379547, "eval_episode/length": 43.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8863636363636364}
{"step": 580008, "time": 29068.75108218193, "eval_episode/length": 54.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9090909090909091}
{"step": 580008, "time": 29072.091486930847, "eval_episode/length": 99.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 580008, "time": 29075.1419672966, "eval_episode/length": 138.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 580008, "time": 29078.146219730377, "eval_episode/length": 172.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 580008, "time": 29081.160429239273, "eval_episode/length": 207.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9855769230769231}
{"step": 580008, "time": 29083.350570440292, "eval_episode/length": 223.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 580008, "time": 29086.136721134186, "eval_episode/length": 154.0, "eval_episode/score": -0.9000000208616257, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 580040, "time": 29087.33139514923, "episode/length": 158.0, "episode/score": 0.15873753706546267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15873753706546267}
{"step": 580376, "time": 29101.395353078842, "episode/length": 447.0, "episode/score": 0.42103783118727733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42103783118727733}
{"step": 580416, "time": 29104.61171603203, "episode/length": 144.0, "episode/score": 0.1680833303835243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1680833303835243}
{"step": 580760, "time": 29118.931942224503, "episode/length": 184.0, "episode/score": 0.19618032868311275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19618032868311275}
{"step": 581032, "time": 29130.44988465309, "episode/length": 241.0, "episode/score": 0.2689712642750237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2689712642750237}
{"step": 581096, "time": 29134.378348827362, "episode/length": 248.0, "episode/score": 0.27683435464132344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27683435464132344}
{"step": 581160, "time": 29138.218321561813, "episode/length": 150.0, "episode/score": 0.1601082200068049, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1601082200068049}
{"step": 581304, "time": 29145.01257610321, "episode/length": 157.0, "episode/score": 0.17941115389112383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17941115389112383}
{"step": 581480, "time": 29153.01864337921, "episode/length": 210.0, "episode/score": 0.22787202049221378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22787202049221378}
{"step": 581640, "time": 29161.046049833298, "episode/length": 152.0, "episode/score": 0.16393847546714824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16393847546714824}
{"step": 581680, "time": 29165.2103164196, "episode/length": 162.0, "episode/score": 0.17299192865903024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17299192865903024}
{"step": 582200, "time": 29185.98615050316, "episode/length": 137.0, "episode/score": 0.1583201856337837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1583201856337837}
{"step": 582496, "time": 29198.916734695435, "episode/length": 166.0, "episode/score": 0.17147755893529393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17147755893529393}
{"step": 582512, "time": 29201.09889316559, "episode/length": 184.0, "episode/score": 0.1912538976976066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1912538976976066}
{"step": 582760, "time": 29211.71738934517, "episode/length": 181.0, "episode/score": 0.19936560752466903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19936560752466903}
{"step": 582864, "time": 29217.33690881729, "episode/length": 172.0, "episode/score": 0.20612499612616375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20612499612616375}
{"step": 583048, "time": 29225.507935523987, "episode/length": 170.0, "episode/score": 0.19893193232564954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19893193232564954}
{"step": 583320, "time": 29237.723499774933, "episode/length": 102.0, "episode/score": 0.1116513396591472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1116513396591472}
{"step": 583408, "time": 29242.68896150589, "episode/length": 220.0, "episode/score": 0.24163065046377596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24163065046377596}
{"step": 583888, "time": 29262.215428590775, "episode/length": 210.0, "episode/score": 0.23059185833335505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23059185833335505}
{"step": 583920, "time": 29265.212421417236, "episode/length": 144.0, "episode/score": 0.16461995556892361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16461995556892361}
{"step": 584096, "time": 29274.058906555176, "episode/length": 153.0, "episode/score": 0.17497080715475022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17497080715475022}
{"step": 584304, "time": 29283.30168223381, "episode/length": 442.0, "episode/score": 0.4443402868328121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4443402868328121}
{"step": 584424, "time": 29289.052894592285, "episode/length": 171.0, "episode/score": 0.2027976733425021, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2027976733425021}
{"step": 584456, "time": 29291.80779194832, "episode/length": 141.0, "episode/score": 0.15391416755483078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15391416755483078}
{"step": 584792, "time": 29305.80240035057, "episode/length": 172.0, "episode/score": 0.20766666252166033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20766666252166033}
{"step": 585305, "time": 29327.5005941391, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.018376868540846, "train/action_min": 0.0, "train/action_std": 4.74500907312228, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007805579253949049, "train/actor_opt_grad_steps": 35850.0, "train/actor_opt_loss": -11.41572853383117, "train/adv_mag": 0.17823733606441752, "train/adv_max": 0.12931087701104757, "train/adv_mean": -0.00011642501707626259, "train/adv_min": -0.1765927770358371, "train/adv_std": 0.013628003018812871, "train/cont_avg": 0.9943713090551181, "train/cont_loss_mean": 0.00019796607860458128, "train/cont_loss_std": 0.005987176241116299, "train/cont_neg_acc": 0.9928602684201218, "train/cont_neg_loss": 0.022464678839120227, "train/cont_pos_acc": 0.9999767710843425, "train/cont_pos_loss": 6.041862019132827e-05, "train/cont_pred": 0.9943831295479001, "train/cont_rate": 0.9943713090551181, "train/dyn_loss_mean": 11.440670081010953, "train/dyn_loss_std": 8.574851625547634, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1479840040734903, "train/extr_critic_critic_opt_grad_steps": 35850.0, "train/extr_critic_critic_opt_loss": 12046.598440575788, "train/extr_critic_mag": 0.28489880862198474, "train/extr_critic_max": 0.28489880862198474, "train/extr_critic_mean": 0.23127695249290917, "train/extr_critic_min": 0.0016933538782314991, "train/extr_critic_std": 0.05923370513918362, "train/extr_return_normed_mag": 0.20074438720237553, "train/extr_return_normed_max": 0.20074438720237553, "train/extr_return_normed_mean": 0.14698508804238689, "train/extr_return_normed_min": -0.08322448594363656, "train/extr_return_normed_std": 0.06115657541402212, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2849197730304688, "train/extr_return_raw_max": 0.2849197730304688, "train/extr_return_raw_mean": 0.23116047821176333, "train/extr_return_raw_min": 0.000950900588448592, "train/extr_return_raw_std": 0.06115657515002517, "train/extr_reward_mag": 0.0012952905940258597, "train/extr_reward_max": 0.0012952905940258597, "train/extr_reward_mean": 0.0010987521794543962, "train/extr_reward_min": 1.0583344406968965e-05, "train/extr_reward_std": 0.0002385107026935929, "train/image_loss_mean": 5.496792093036682, "train/image_loss_std": 10.623327161383441, "train/model_loss_mean": 12.401345328083188, "train/model_loss_std": 14.168622865451603, "train/model_opt_grad_norm": 55.37501117375892, "train/model_opt_grad_steps": 35815.913385826774, "train/model_opt_loss": 17541.764263964076, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1407.4803149606298, "train/policy_entropy_mag": 2.761251211166382, "train/policy_entropy_max": 2.761251211166382, "train/policy_entropy_mean": 2.0679088615057037, "train/policy_entropy_min": 0.0803055959189032, "train/policy_entropy_std": 0.6198162640642932, "train/policy_logprob_mag": 7.438249073629304, "train/policy_logprob_max": -0.00958392502901357, "train/policy_logprob_mean": -2.067343744705981, "train/policy_logprob_min": -7.438249073629304, "train/policy_logprob_std": 1.1695804126619354, "train/policy_randomness_mag": 0.9746005032944867, "train/policy_randomness_max": 0.9746005032944867, "train/policy_randomness_mean": 0.7298810740155498, "train/policy_randomness_min": 0.02834435124096908, "train/policy_randomness_std": 0.21876794228872914, "train/post_ent_mag": 59.41191806943398, "train/post_ent_max": 59.41191806943398, "train/post_ent_mean": 41.54767563587099, "train/post_ent_min": 20.200250640628845, "train/post_ent_std": 7.126876602022667, "train/prior_ent_mag": 68.81040834441899, "train/prior_ent_max": 68.81040834441899, "train/prior_ent_mean": 53.048929920346716, "train/prior_ent_min": 33.33845491484394, "train/prior_ent_std": 5.479760245075376, "train/rep_loss_mean": 11.440670081010953, "train/rep_loss_std": 8.574851625547634, "train/reward_avg": 0.0010582004911192935, "train/reward_loss_mean": 0.03995317871880343, "train/reward_loss_std": 0.011484470079088305, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012807282875841996, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.039953178542805466, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010569544333055264, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.1754716739480227, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.943396226415094, "train_stats/max_log_achievement_collect_sapling": 0.7169811320754716, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.7830188679245284, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.02830188679245283, "train_stats/max_log_achievement_eat_cow": 0.009433962264150943, "train_stats/max_log_achievement_make_wood_pickaxe": 0.018867924528301886, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.3113207547169811, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.10377358490566038, "train_stats/max_log_achievement_wake_up": 0.1792452830188679, "train_stats/mean_log_entropy": 2.0910633521259956, "eval_stats/sum_log_reward": 1.0374999595806003, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.875, "eval_stats/max_log_achievement_collect_sapling": 0.9375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0009011269430629909, "report/cont_loss_std": 0.020396003499627113, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.12300099432468414, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00042230397230014205, "report/cont_pred": 0.9961312413215637, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.988319396972656, "report/dyn_loss_std": 7.943490028381348, "report/image_loss_mean": 4.503986358642578, "report/image_loss_std": 7.654446601867676, "report/model_loss_mean": 11.735820770263672, "report/model_loss_std": 11.092475891113281, "report/post_ent_mag": 53.18171691894531, "report/post_ent_max": 53.18171691894531, "report/post_ent_mean": 39.478111267089844, "report/post_ent_min": 20.027786254882812, "report/post_ent_std": 6.098098278045654, "report/prior_ent_mag": 68.33724975585938, "report/prior_ent_max": 68.33724975585938, "report/prior_ent_mean": 51.499534606933594, "report/prior_ent_min": 32.54871368408203, "report/prior_ent_std": 5.083554744720459, "report/rep_loss_mean": 11.988319396972656, "report/rep_loss_std": 7.943490028381348, "report/reward_avg": 0.0010047650430351496, "report/reward_loss_mean": 0.03794223442673683, "report/reward_loss_std": 0.014462928287684917, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012853145599365234, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03794223442673683, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010058796033263206, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 3.6079377423448022e-06, "eval/cont_loss_std": 9.783389396034181e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00011242836626479402, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.181190777468146e-06, "eval/cont_pred": 0.9960910677909851, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.01300048828125, "eval/dyn_loss_std": 10.640838623046875, "eval/image_loss_mean": 8.109800338745117, "eval/image_loss_std": 10.543364524841309, "eval/model_loss_mean": 18.97186279296875, "eval/model_loss_std": 15.371779441833496, "eval/post_ent_mag": 56.874908447265625, "eval/post_ent_max": 56.874908447265625, "eval/post_ent_mean": 39.48131561279297, "eval/post_ent_min": 21.404342651367188, "eval/post_ent_std": 6.701693534851074, "eval/prior_ent_mag": 68.33724975585938, "eval/prior_ent_max": 68.33724975585938, "eval/prior_ent_mean": 52.80449676513672, "eval/prior_ent_min": 30.8096866607666, "eval/prior_ent_std": 5.512935638427734, "eval/rep_loss_mean": 17.01300048828125, "eval/rep_loss_std": 10.640838623046875, "eval/reward_avg": 0.013769530691206455, "eval/reward_loss_mean": 0.6542582511901855, "eval/reward_loss_std": 3.49410343170166, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012803077697753906, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.31573471426963806, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.70680046081543, "eval/reward_pred": 0.0010439578909426928, "eval/reward_rate": 0.0166015625, "replay/size": 584801.0, "replay/inserts": 20400.0, "replay/samples": 20400.0, "replay/insert_wait_avg": 1.3383346445420209e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.848762998393938e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4056.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.177162343463484e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3168435096741, "timer/env.step_count": 2550.0, "timer/env.step_total": 228.57528805732727, "timer/env.step_frac": 0.2285028884001959, "timer/env.step_avg": 0.08963736786561853, "timer/env.step_min": 0.022403717041015625, "timer/env.step_max": 3.3537352085113525, "timer/replay._sample_count": 20400.0, "timer/replay._sample_total": 9.967423677444458, "timer/replay._sample_frac": 0.009964266564254911, "timer/replay._sample_avg": 0.0004885991998747284, "timer/replay._sample_min": 0.000400543212890625, "timer/replay._sample_max": 0.010355472564697266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3057.0, "timer/agent.policy_total": 49.086910247802734, "timer/agent.policy_frac": 0.049071362305145486, "timer/agent.policy_avg": 0.016057216306118, "timer/agent.policy_min": 0.009717464447021484, "timer/agent.policy_max": 0.14101791381835938, "timer/dataset_train_count": 1275.0, "timer/dataset_train_total": 0.13732075691223145, "timer/dataset_train_frac": 0.00013727726150289843, "timer/dataset_train_avg": 0.00010770255444096584, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.00048470497131347656, "timer/agent.train_count": 1275.0, "timer/agent.train_total": 572.9488275051117, "timer/agent.train_frac": 0.5727673498877466, "timer/agent.train_avg": 0.44937162941577385, "timer/agent.train_min": 0.4378361701965332, "timer/agent.train_max": 1.2589356899261475, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4806489944458008, "timer/agent.report_frac": 0.0004804967521684567, "timer/agent.report_avg": 0.2403244972229004, "timer/agent.report_min": 0.23478078842163086, "timer/agent.report_max": 0.24586820602416992, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.316734313964844e-05, "timer/dataset_eval_frac": 5.315050274781688e-08, "timer/dataset_eval_avg": 5.316734313964844e-05, "timer/dataset_eval_min": 5.316734313964844e-05, "timer/dataset_eval_max": 5.316734313964844e-05, "fps": 20.393276604261086}
{"step": 585344, "time": 29329.0539624691, "episode/length": 181.0, "episode/score": 0.1911111374884058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1911111374884058}
{"step": 585392, "time": 29332.448833465576, "episode/length": 183.0, "episode/score": 0.19782883776861127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19782883776861127}
{"step": 585416, "time": 29334.672191381454, "episode/length": 164.0, "episode/score": 0.17645274011374568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17645274011374568}
{"step": 585432, "time": 29336.732646226883, "episode/length": 140.0, "episode/score": 0.16068604362590122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16068604362590122}
{"step": 585712, "time": 29349.031685113907, "episode/length": 156.0, "episode/score": 0.1803943418635754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1803943418635754}
{"step": 585768, "time": 29352.477885961533, "episode/length": 167.0, "episode/score": 0.201979162695352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.201979162695352}
{"step": 586016, "time": 29363.378329992294, "episode/length": 437.0, "episode/score": 0.3989927801230806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3989927801230806}
{"step": 586152, "time": 29369.913966178894, "episode/length": 169.0, "episode/score": 0.17145648124278523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17145648124278523}
{"step": 586592, "time": 29389.15433359146, "episode/length": 155.0, "episode/score": 0.16656349728873465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16656349728873465}
{"step": 586736, "time": 29396.477806568146, "episode/length": 162.0, "episode/score": 0.17396274631391861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17396274631391861}
{"step": 586920, "time": 29404.68080854416, "episode/length": 187.0, "episode/score": 0.20910458947037114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20910458947037114}
{"step": 587368, "time": 29422.89490056038, "episode/length": 246.0, "episode/score": 0.2772836021176772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2772836021176772}
{"step": 587488, "time": 29429.054134607315, "episode/length": 214.0, "episode/score": 0.2380285651070153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2380285651070153}
{"step": 587608, "time": 29434.741884946823, "episode/length": 198.0, "episode/score": 0.22683064570446732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22683064570446732}
{"step": 587640, "time": 29437.562707185745, "episode/length": 240.0, "episode/score": 0.25318375787173864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25318375787173864}
{"step": 587848, "time": 29446.87476348877, "episode/length": 156.0, "episode/score": 0.18155852833297104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18155852833297104}
{"step": 588152, "time": 29459.658399820328, "episode/length": 249.0, "episode/score": 0.2917916613514535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2917916613514535}
{"step": 588272, "time": 29465.834436178207, "episode/length": 191.0, "episode/score": 0.21550291024323087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21550291024323087}
{"step": 588440, "time": 29473.542891025543, "episode/length": 189.0, "episode/score": 0.20685055904323235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20685055904323235}
{"step": 588536, "time": 29478.53855085373, "episode/length": 145.0, "episode/score": 0.16514527871186147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16514527871186147}
{"step": 588880, "time": 29493.154512643814, "episode/length": 173.0, "episode/score": 0.19466695570736192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19466695570736192}
{"step": 589008, "time": 29499.573996305466, "episode/length": 58.0, "episode/score": 0.06979166541714221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06979166541714221}
{"step": 589120, "time": 29505.28327178955, "episode/length": 158.0, "episode/score": 0.15738303787293262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15738303787293262}
{"step": 589128, "time": 29506.852336883545, "episode/length": 185.0, "episode/score": 0.17014141917752568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17014141917752568}
{"step": 589152, "time": 29509.457995653152, "episode/length": 192.0, "episode/score": 0.200995129027433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.200995129027433}
{"step": 589624, "time": 29528.38461136818, "episode/length": 168.0, "episode/score": 0.18596029989930685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18596029989930685}
{"step": 589648, "time": 29531.046795368195, "episode/length": 186.0, "episode/score": 0.21345039305379032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21345039305379032}
{"step": 590016, "time": 29547.55244064331, "episode/length": 141.0, "episode/score": 0.1661344418207591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1661344418207591}
{"step": 590096, "time": 29571.6220433712, "eval_episode/length": 139.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 590096, "time": 29574.559104681015, "eval_episode/length": 174.0, "eval_episode/score": 2.099999964237213, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 590096, "time": 29576.48312973976, "eval_episode/length": 185.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 590096, "time": 29578.542715787888, "eval_episode/length": 196.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 590096, "time": 29580.58823823929, "eval_episode/length": 208.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 590096, "time": 29583.18516778946, "eval_episode/length": 233.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9700854700854701}
{"step": 590096, "time": 29585.492077827454, "eval_episode/length": 253.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9960629921259843}
{"step": 590096, "time": 29587.824806451797, "eval_episode/length": 270.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.996309963099631}
{"step": 590256, "time": 29593.75431704521, "episode/length": 226.0, "episode/score": 0.24766207538777962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24766207538777962}
{"step": 590296, "time": 29596.551376342773, "episode/length": 146.0, "episode/score": 0.14026115400520212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14026115400520212}
{"step": 590360, "time": 29600.543709754944, "episode/length": 153.0, "episode/score": 0.16099331749865087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16099331749865087}
{"step": 591144, "time": 29632.754257440567, "episode/length": 140.0, "episode/score": 0.16749936341511784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16749936341511784}
{"step": 591472, "time": 29646.66271162033, "episode/length": 227.0, "episode/score": 0.27449110455199843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27449110455199843}
{"step": 591480, "time": 29648.373806476593, "episode/length": 290.0, "episode/score": 0.3249084272138134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3249084272138134}
{"step": 591504, "time": 29651.048095464706, "episode/length": 311.0, "episode/score": 0.3613335497066146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3613335497066146}
{"step": 591528, "time": 29653.31346511841, "episode/length": 145.0, "episode/score": 0.1593223349282198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1593223349282198}
{"step": 591648, "time": 29659.56759786606, "episode/length": 252.0, "episode/score": 0.28257136573847674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28257136573847674}
{"step": 592528, "time": 29694.253769874573, "episode/length": 172.0, "episode/score": 0.19592407011441537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19592407011441537}
{"step": 592712, "time": 29702.881795167923, "episode/length": 154.0, "episode/score": 0.16790874587240978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16790874587240978}
{"step": 592744, "time": 29706.096432685852, "episode/length": 154.0, "episode/score": 0.15773215711305966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15773215711305966}
{"step": 592872, "time": 29712.98370242119, "episode/length": 173.0, "episode/score": 0.18999644623545464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18999644623545464}
{"step": 592936, "time": 29716.78755426407, "episode/length": 160.0, "episode/score": 0.1685655722831143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1685655722831143}
{"step": 593160, "time": 29726.571073293686, "episode/length": 203.0, "episode/score": 0.2213757679983246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2213757679983246}
{"step": 593264, "time": 29732.220532894135, "episode/length": 370.0, "episode/score": 0.38212233794001804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.38212233794001804}
{"step": 593632, "time": 29747.58429980278, "episode/length": 114.0, "episode/score": 0.11751595831719897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11751595831719897}
{"step": 593800, "time": 29755.072927713394, "episode/length": 442.0, "episode/score": 0.48171779620497546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.48171779620497546}
{"step": 594216, "time": 29772.065664291382, "episode/length": 183.0, "episode/score": 0.20384817530066357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20384817530066357}
{"step": 594248, "time": 29774.88751578331, "episode/length": 171.0, "episode/score": 0.19585592495695892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19585592495695892}
{"step": 594264, "time": 29777.023403406143, "episode/length": 165.0, "episode/score": 0.19508434038016276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19508434038016276}
{"step": 594480, "time": 29786.809876203537, "episode/length": 151.0, "episode/score": 0.17168654207580403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17168654207580403}
{"step": 595120, "time": 29812.319271087646, "episode/length": 244.0, "episode/score": 0.2630984237148368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2630984237148368}
{"step": 595160, "time": 29815.186332464218, "episode/length": 328.0, "episode/score": 0.3549837042401123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3549837042401123}
{"step": 595568, "time": 29832.419613599777, "episode/length": 241.0, "episode/score": 0.2588414040455973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2588414040455973}
{"step": 595648, "time": 29837.538933992386, "episode/length": 174.0, "episode/score": 0.1596300120709202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1596300120709202}
{"step": 595688, "time": 29840.853915929794, "episode/length": 177.0, "episode/score": 0.18861842738169798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18861842738169798}
{"step": 595760, "time": 29845.743425130844, "episode/length": 192.0, "episode/score": 0.2289695900399238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2289695900399238}
{"step": 595936, "time": 29854.566844940186, "episode/length": 266.0, "episode/score": 0.2859330245591991, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2859330245591991}
{"step": 596520, "time": 29878.802960395813, "episode/length": 174.0, "episode/score": 0.18392397044772224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18392397044772224}
{"step": 596928, "time": 29895.711953401566, "episode/length": 154.0, "episode/score": 0.18125657550990582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18125657550990582}
{"step": 597000, "time": 29899.63329386711, "episode/length": 314.0, "episode/score": 0.3535369148958125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3535369148958125}
{"step": 597008, "time": 29901.72922563553, "episode/length": 179.0, "episode/score": 0.1819075829553185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1819075829553185}
{"step": 597064, "time": 29905.21020269394, "episode/length": 162.0, "episode/score": 0.1745049926903448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1745049926903448}
{"step": 597208, "time": 29912.107676267624, "episode/length": 255.0, "episode/score": 0.29384909476902976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29384909476902976}
{"step": 597296, "time": 29917.17085623741, "episode/length": 169.0, "episode/score": 0.1858324480126612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1858324480126612}
{"step": 597664, "time": 29932.425032138824, "episode/length": 74.0, "episode/score": 0.08265376618874143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08265376618874143}
{"step": 597784, "time": 29938.212077617645, "episode/length": 157.0, "episode/score": 0.1658185058258823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1658185058258823}
{"step": 597808, "time": 29940.856912612915, "episode/length": 269.0, "episode/score": 0.33145832642912865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33145832642912865}
{"step": 598192, "time": 29958.32275748253, "episode/length": 148.0, "episode/score": 0.17307137036550557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17307137036550557}
{"step": 598240, "time": 29961.589878559113, "episode/length": 153.0, "episode/score": 0.17833393135515507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17833393135515507}
{"step": 598272, "time": 29964.2654132843, "episode/length": 132.0, "episode/score": 0.1501894214125059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1501894214125059}
{"step": 598280, "time": 29965.943957328796, "episode/length": 168.0, "episode/score": 0.19297606357577024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19297606357577024}
{"step": 598456, "time": 29973.975552797318, "episode/length": 144.0, "episode/score": 0.14751857534065493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14751857534065493}
{"step": 599072, "time": 29999.088479042053, "episode/length": 160.0, "episode/score": 0.1848049889158574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1848049889158574}
{"step": 599240, "time": 30007.249144792557, "episode/length": 178.0, "episode/score": 0.1926600612459879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1926600612459879}
{"step": 599448, "time": 30016.497050523758, "episode/length": 222.0, "episode/score": 0.24939423982141307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24939423982141307}
{"step": 599576, "time": 30022.855870485306, "episode/length": 162.0, "episode/score": 0.1774472477591189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1774472477591189}
{"step": 599824, "time": 30033.90468096733, "episode/length": 192.0, "episode/score": 0.20835971417545807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20835971417545807}
{"step": 599984, "time": 30041.411528110504, "episode/length": 190.0, "episode/score": 0.21387065084491041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21387065084491041}
{"step": 600048, "time": 30045.292489290237, "episode/length": 225.0, "episode/score": 0.2714479112146364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2714479112146364}
{"step": 600080, "time": 30067.23600745201, "eval_episode/length": 142.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.993006993006993}
{"step": 600080, "time": 30069.60666513443, "eval_episode/length": 163.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 600080, "time": 30071.287689208984, "eval_episode/length": 167.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 600080, "time": 30073.65016889572, "eval_episode/length": 183.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 600080, "time": 30076.760715723038, "eval_episode/length": 222.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 600080, "time": 30078.44109082222, "eval_episode/length": 224.0, "eval_episode/score": 1.1000000461935997, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 600080, "time": 30080.080675125122, "eval_episode/length": 225.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 600080, "time": 30081.643706083298, "eval_episode/length": 226.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 600528, "time": 30098.331575632095, "episode/length": 181.0, "episode/score": 0.1730891285060352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1730891285060352}
{"step": 600872, "time": 30112.59514284134, "episode/length": 334.0, "episode/score": 0.3701463565466838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3701463565466838}
{"step": 601048, "time": 30120.76690196991, "episode/length": 183.0, "episode/score": 0.19722422503218695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19722422503218695}
{"step": 601352, "time": 30133.61135649681, "episode/length": 237.0, "episode/score": 0.24384724037736305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24384724037736305}
{"step": 601448, "time": 30138.65343785286, "episode/length": 275.0, "episode/score": 0.31030610898233135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31030610898233135}
{"step": 601472, "time": 30141.365533590317, "episode/length": 185.0, "episode/score": 0.21764298161360784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21764298161360784}
{"step": 601704, "time": 30151.416353940964, "episode/length": 234.0, "episode/score": 0.2286380598307005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2286380598307005}
{"step": 601744, "time": 30154.62622976303, "episode/length": 151.0, "episode/score": 0.16754994071925466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16754994071925466}
{"step": 601776, "time": 30157.458988428116, "episode/length": 215.0, "episode/score": 0.23917249536498275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23917249536498275}
{"step": 602456, "time": 30184.09561061859, "episode/length": 197.0, "episode/score": 0.21764729356436874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21764729356436874}
{"step": 602568, "time": 30189.95554637909, "episode/length": 189.0, "episode/score": 0.22082198828320543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22082198828320543}
{"step": 602576, "time": 30191.901868104935, "episode/length": 140.0, "episode/score": 0.15938762909991055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15938762909991055}
{"step": 602680, "time": 30197.05507349968, "episode/length": 150.0, "episode/score": 0.1726980645707954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1726980645707954}
{"step": 602680, "time": 30197.062973976135, "episode/length": 165.0, "episode/score": 0.17030357621479197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17030357621479197}
{"step": 602912, "time": 30209.189152240753, "episode/length": 145.0, "episode/score": 0.17133143603859935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17133143603859935}
{"step": 603440, "time": 30230.349160671234, "episode/length": 122.0, "episode/score": 0.14225612944755994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14225612944755994}
{"step": 603656, "time": 30239.711298704147, "episode/length": 134.0, "episode/score": 0.16480555206635472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16480555206635472}
{"step": 603696, "time": 30242.916501522064, "episode/length": 248.0, "episode/score": 0.28182174955509254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28182174955509254}
{"step": 603744, "time": 30246.171296596527, "episode/length": 245.0, "episode/score": 0.2886367466999218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2886367466999218}
{"step": 603832, "time": 30250.87180161476, "episode/length": 143.0, "episode/score": 0.15860775112832926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15860775112832926}
{"step": 603976, "time": 30257.66294527054, "episode/length": 175.0, "episode/score": 0.16800085741579096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16800085741579096}
{"step": 604256, "time": 30269.795185804367, "episode/length": 196.0, "episode/score": 0.22174780605291744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22174780605291744}
{"step": 604696, "time": 30287.436824798584, "episode/length": 222.0, "episode/score": 0.21035093119280646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21035093119280646}
{"step": 604904, "time": 30296.642187595367, "episode/length": 155.0, "episode/score": 0.15802730247833097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15802730247833097}
{"step": 605136, "time": 30307.060537576675, "episode/length": 162.0, "episode/score": 0.17088439079816453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17088439079816453}
{"step": 605400, "time": 30318.294615745544, "episode/length": 177.0, "episode/score": 0.20285465173492412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20285465173492412}
{"step": 605512, "time": 30323.956754922867, "episode/length": 220.0, "episode/score": 0.2513251666587166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2513251666587166}
{"step": 605545, "time": 30327.839578151703, "train_stats/sum_log_reward": 1.4301886491758644, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.6415094339622645, "train_stats/max_log_achievement_collect_sapling": 0.6226415094339622, "train_stats/max_log_achievement_collect_stone": 0.009433962264150943, "train_stats/max_log_achievement_collect_wood": 0.9056603773584906, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0660377358490566, "train_stats/max_log_achievement_eat_cow": 0.02830188679245283, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009433962264150943, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.24528301886792453, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.10377358490566038, "train_stats/max_log_achievement_wake_up": 0.33962264150943394, "train_stats/mean_log_entropy": 2.0664692003771945, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.862628125768947, "train/action_min": 0.0, "train/action_std": 4.701457263916496, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008190667685707958, "train/actor_opt_grad_steps": 37120.0, "train/actor_opt_loss": -9.444617133440934, "train/adv_mag": 0.17865330209647576, "train/adv_max": 0.13257555217724146, "train/adv_mean": 4.136507288249981e-05, "train/adv_min": -0.1762843434148886, "train/adv_std": 0.013659390041560639, "train/cont_avg": 0.994625061515748, "train/cont_loss_mean": 0.00019982023056829077, "train/cont_loss_std": 0.006094450577762029, "train/cont_neg_acc": 0.9893294605683154, "train/cont_neg_loss": 0.02713132450793365, "train/cont_pos_acc": 0.9999999854508348, "train/cont_pos_loss": 3.159301772130204e-05, "train/cont_pred": 0.9946662117177107, "train/cont_rate": 0.994625061515748, "train/dyn_loss_mean": 11.334393291022835, "train/dyn_loss_std": 8.52682559696708, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13899649301265168, "train/extr_critic_critic_opt_grad_steps": 37120.0, "train/extr_critic_critic_opt_loss": 12045.48663570374, "train/extr_critic_mag": 0.2878105856302216, "train/extr_critic_max": 0.2878105856302216, "train/extr_critic_mean": 0.2334647452033411, "train/extr_critic_min": 0.0014204209245096042, "train/extr_critic_std": 0.060203906705999, "train/extr_return_normed_mag": 0.21032623641603576, "train/extr_return_normed_max": 0.21032623641603576, "train/extr_return_normed_mean": 0.1558771105263177, "train/extr_return_normed_min": -0.07663924868885927, "train/extr_return_normed_std": 0.06193045212879894, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28795521935140056, "train/extr_return_raw_max": 0.28795521935140056, "train/extr_return_raw_mean": 0.23350609768563368, "train/extr_return_raw_min": 0.0009897346571674497, "train/extr_return_raw_std": 0.061930451806136, "train/extr_reward_mag": 0.0013096670466145194, "train/extr_reward_max": 0.0013096670466145194, "train/extr_reward_mean": 0.0011059086830318562, "train/extr_reward_min": 1.1062997532641794e-05, "train/extr_reward_std": 0.00023537310890809406, "train/image_loss_mean": 5.345504004185594, "train/image_loss_std": 10.440234961472159, "train/model_loss_mean": 12.186391079519677, "train/model_loss_std": 13.986722262825554, "train/model_opt_grad_norm": 53.28008995656892, "train/model_opt_grad_steps": 37084.74803149606, "train/model_opt_loss": 15937.14422367126, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1309.0551181102362, "train/policy_entropy_mag": 2.758533398936114, "train/policy_entropy_max": 2.758533398936114, "train/policy_entropy_mean": 2.0113139039888157, "train/policy_entropy_min": 0.08011681475038604, "train/policy_entropy_std": 0.6303184628486633, "train/policy_logprob_mag": 7.438238181467131, "train/policy_logprob_max": -0.00955795078707023, "train/policy_logprob_mean": -2.0098586129391287, "train/policy_logprob_min": -7.438238181467131, "train/policy_logprob_std": 1.204081999973988, "train/policy_randomness_mag": 0.9736412331813903, "train/policy_randomness_max": 0.9736412331813903, "train/policy_randomness_mean": 0.7099055408492801, "train/policy_randomness_min": 0.028277719760034965, "train/policy_randomness_std": 0.22247475538197464, "train/post_ent_mag": 59.51609318650613, "train/post_ent_max": 59.51609318650613, "train/post_ent_mean": 41.756894719882276, "train/post_ent_min": 20.373586083960344, "train/post_ent_std": 7.201487462351642, "train/prior_ent_mag": 68.92487827811654, "train/prior_ent_max": 68.92487827811654, "train/prior_ent_mean": 53.14067708413432, "train/prior_ent_min": 33.47514373298705, "train/prior_ent_std": 5.4869735109524465, "train/rep_loss_mean": 11.334393291022835, "train/rep_loss_std": 8.52682559696708, "train/reward_avg": 0.0010611050877734785, "train/reward_loss_mean": 0.040051325598335644, "train/reward_loss_std": 0.011369764350178673, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012798046502541368, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04005132556900265, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010622794277907357, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.787499938160181, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.0625, "eval_stats/max_log_achievement_collect_sapling": 1.1875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.2147448842370068e-06, "report/cont_loss_std": 2.5321329303551465e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.6799680098483805e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.1771276149374899e-06, "report/cont_pred": 0.993162989616394, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 9.578426361083984, "report/dyn_loss_std": 8.302966117858887, "report/image_loss_mean": 4.470444202423096, "report/image_loss_std": 7.487562656402588, "report/model_loss_mean": 10.258369445800781, "report/model_loss_std": 10.455292701721191, "report/post_ent_mag": 62.2542839050293, "report/post_ent_max": 62.2542839050293, "report/post_ent_mean": 43.70387268066406, "report/post_ent_min": 20.921329498291016, "report/post_ent_std": 7.530857563018799, "report/prior_ent_mag": 68.88525390625, "report/prior_ent_max": 68.88525390625, "report/prior_ent_mean": 53.287208557128906, "report/prior_ent_min": 39.611854553222656, "report/prior_ent_std": 5.0852131843566895, "report/rep_loss_mean": 9.578426361083984, "report/rep_loss_std": 8.302966117858887, "report/reward_avg": 0.0010842605261132121, "report/reward_loss_mean": 0.04086799547076225, "report/reward_loss_std": 0.010453183203935623, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012704133987426758, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04086799547076225, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010845701908692718, "report/reward_rate": 0.0, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 1.4822222510701977e-05, "eval/cont_loss_std": 0.00038347337977029383, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001610542880371213, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2574954527954105e-06, "eval/cont_pred": 0.9921978116035461, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 16.06764030456543, "eval/dyn_loss_std": 10.40030288696289, "eval/image_loss_mean": 12.754071235656738, "eval/image_loss_std": 19.91059684753418, "eval/model_loss_mean": 23.2109375, "eval/model_loss_std": 24.6068172454834, "eval/post_ent_mag": 58.34418869018555, "eval/post_ent_max": 58.34418869018555, "eval/post_ent_mean": 39.84722137451172, "eval/post_ent_min": 21.612606048583984, "eval/post_ent_std": 6.824167251586914, "eval/prior_ent_mag": 68.88525390625, "eval/prior_ent_max": 68.88525390625, "eval/prior_ent_mean": 52.97978973388672, "eval/prior_ent_min": 31.868667602539062, "eval/prior_ent_std": 5.762097358703613, "eval/rep_loss_mean": 16.06764030456543, "eval/rep_loss_std": 10.40030288696289, "eval/reward_avg": -0.0010742186568677425, "eval/reward_loss_mean": 0.8162678480148315, "eval/reward_loss_std": 3.9020252227783203, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012803077697753906, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.6984942555427551, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.798513412475586, "eval/reward_pred": 0.001017970498651266, "eval/reward_rate": 0.005859375, "replay/size": 605041.0, "replay/inserts": 20240.0, "replay/samples": 20240.0, "replay/insert_wait_avg": 1.3230817591248765e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.695595737502509e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3984.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1711474882072234e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3278625011444, "timer/env.step_count": 2530.0, "timer/env.step_total": 231.62865042686462, "timer/env.step_frac": 0.2315527329686867, "timer/env.step_avg": 0.09155282625567772, "timer/env.step_min": 0.0228421688079834, "timer/env.step_max": 3.3418502807617188, "timer/replay._sample_count": 20240.0, "timer/replay._sample_total": 9.776872396469116, "timer/replay._sample_frac": 0.009773667977240743, "timer/replay._sample_avg": 0.0004830470551615176, "timer/replay._sample_min": 0.0003712177276611328, "timer/replay._sample_max": 0.010636329650878906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3028.0, "timer/agent.policy_total": 48.571091175079346, "timer/agent.policy_frac": 0.048555171755024246, "timer/agent.policy_avg": 0.0160406509825229, "timer/agent.policy_min": 0.009641647338867188, "timer/agent.policy_max": 0.09464001655578613, "timer/dataset_train_count": 1265.0, "timer/dataset_train_total": 0.13814020156860352, "timer/dataset_train_frac": 0.00013809492542095965, "timer/dataset_train_avg": 0.00010920174037043757, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.0003650188446044922, "timer/agent.train_count": 1265.0, "timer/agent.train_total": 569.2330641746521, "timer/agent.train_frac": 0.5690464951674791, "timer/agent.train_avg": 0.4499866119957724, "timer/agent.train_min": 0.4351685047149658, "timer/agent.train_max": 2.087724208831787, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48373913764953613, "timer/agent.report_frac": 0.0004835805897078896, "timer/agent.report_avg": 0.24186956882476807, "timer/agent.report_min": 0.23593592643737793, "timer/agent.report_max": 0.2478032112121582, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.57763671875e-05, "timer/dataset_eval_frac": 4.576136375232438e-08, "timer/dataset_eval_avg": 4.57763671875e-05, "timer/dataset_eval_min": 4.57763671875e-05, "timer/dataset_eval_max": 4.57763671875e-05, "fps": 20.23313966827832}
{"step": 605552, "time": 30327.869807720184, "episode/length": 231.0, "episode/score": 0.2308639246966777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2308639246966777}
{"step": 605624, "time": 30332.284852981567, "episode/length": 272.0, "episode/score": 0.30057753678556764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30057753678556764}
{"step": 605864, "time": 30342.63811993599, "episode/length": 200.0, "episode/score": 0.19737286523832154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19737286523832154}
{"step": 606208, "time": 30357.23126268387, "episode/length": 42.0, "episode/score": 0.04966666578548029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04966666578548029}
{"step": 606472, "time": 30369.96276283264, "episode/length": 166.0, "episode/score": 0.1509822789739701, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1509822789739701}
{"step": 606520, "time": 30373.24871635437, "episode/length": 201.0, "episode/score": 0.2158902136316101, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2158902136316101}
{"step": 606552, "time": 30375.934423208237, "episode/length": 42.0, "episode/score": 0.050624999101273715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050624999101273715}
{"step": 606680, "time": 30382.19851231575, "episode/length": 159.0, "episode/score": 0.1741947916616482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1741947916616482}
{"step": 606856, "time": 30390.244482040405, "episode/length": 153.0, "episode/score": 0.15667404548639752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15667404548639752}
{"step": 606920, "time": 30394.097623825073, "episode/length": 170.0, "episode/score": 0.16414929825532454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16414929825532454}
{"step": 606920, "time": 30394.107491254807, "episode/length": 277.0, "episode/score": 0.29883404946849623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29883404946849623}
{"step": 606936, "time": 30397.944407463074, "episode/length": 47.0, "episode/score": 0.04997499946784956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04997499946784956}
{"step": 607928, "time": 30435.993762016296, "episode/length": 155.0, "episode/score": 0.1776743741120299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1776743741120299}
{"step": 608008, "time": 30440.47362971306, "episode/length": 185.0, "episode/score": 0.2074639798829594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2074639798829594}
{"step": 608088, "time": 30444.937342643738, "episode/length": 145.0, "episode/score": 0.14202347007767457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14202347007767457}
{"step": 608096, "time": 30447.04174041748, "episode/length": 154.0, "episode/score": 0.1692099204601618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1692099204601618}
{"step": 608312, "time": 30456.349902629852, "episode/length": 349.0, "episode/score": 0.37423370625356256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.37423370625356256}
{"step": 608392, "time": 30460.915342092514, "episode/length": 239.0, "episode/score": 0.2315401005289459, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2315401005289459}
{"step": 608552, "time": 30468.415296792984, "episode/length": 201.0, "episode/score": 0.194547601216982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.194547601216982}
{"step": 608696, "time": 30475.21096754074, "episode/length": 221.0, "episode/score": 0.23452390037800797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23452390037800797}
{"step": 609240, "time": 30496.85878419876, "episode/length": 163.0, "episode/score": 0.1759162946318611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1759162946318611}
{"step": 609624, "time": 30512.70632839203, "episode/length": 191.0, "episode/score": 0.2157214948128967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2157214948128967}
{"step": 609648, "time": 30515.33554124832, "episode/length": 193.0, "episode/score": 0.1807038329129682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1807038329129682}
{"step": 609752, "time": 30521.23664355278, "episode/length": 149.0, "episode/score": 0.15181827608421372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15181827608421372}
{"step": 610024, "time": 30533.197069644928, "episode/length": 165.0, "episode/score": 0.19476930968630768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19476930968630768}
{"step": 610064, "time": 30553.42695260048, "eval_episode/length": 107.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9444444444444444}
{"step": 610064, "time": 30556.145154476166, "eval_episode/length": 139.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 610064, "time": 30558.17783355713, "eval_episode/length": 152.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9607843137254902}
{"step": 610064, "time": 30560.739017486572, "eval_episode/length": 176.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 610064, "time": 30562.78729081154, "eval_episode/length": 188.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 610064, "time": 30565.06465125084, "eval_episode/length": 207.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 610064, "time": 30573.342091560364, "eval_episode/length": 178.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 610064, "time": 30575.385355949402, "eval_episode/length": 142.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.993006993006993}
{"step": 610072, "time": 30575.467086315155, "episode/length": 257.0, "episode/score": 0.2834246675738541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2834246675738541}
{"step": 610232, "time": 30582.97967338562, "episode/length": 229.0, "episode/score": 0.26196293975272056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26196293975272056}
{"step": 610512, "time": 30595.101390123367, "episode/length": 158.0, "episode/score": 0.17812269700380057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17812269700380057}
{"step": 610648, "time": 30601.416349887848, "episode/length": 291.0, "episode/score": 0.327461123719786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.327461123719786}
{"step": 610952, "time": 30614.318847179413, "episode/length": 162.0, "episode/score": 0.17038643557634714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17038643557634714}
{"step": 611144, "time": 30622.972833156586, "episode/length": 189.0, "episode/score": 0.19377788072733892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19377788072733892}
{"step": 611464, "time": 30637.00006532669, "episode/length": 153.0, "episode/score": 0.17350765407127255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17350765407127255}
{"step": 611504, "time": 30640.67851114273, "episode/length": 178.0, "episode/score": 0.2005924021359533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2005924021359533}
{"step": 611720, "time": 30650.61128139496, "episode/length": 211.0, "episode/score": 0.2427857813945593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2427857813945593}
{"step": 611752, "time": 30653.77496123314, "episode/length": 249.0, "episode/score": 0.2783938752531867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2783938752531867}
{"step": 611904, "time": 30661.743519067764, "episode/length": 173.0, "episode/score": 0.17164409416454873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17164409416454873}
{"step": 611944, "time": 30664.9189991951, "episode/length": 161.0, "episode/score": 0.15780367638308235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15780367638308235}
{"step": 612440, "time": 30685.529119729996, "episode/length": 185.0, "episode/score": 0.16938659980814919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16938659980814919}
{"step": 612768, "time": 30699.655658006668, "episode/length": 162.0, "episode/score": 0.15664332950882454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15664332950882454}
{"step": 612784, "time": 30702.208350419998, "episode/length": 204.0, "episode/score": 0.23013457947718052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23013457947718052}
{"step": 613008, "time": 30712.344472169876, "episode/length": 156.0, "episode/score": 0.17597346484535592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17597346484535592}
{"step": 613120, "time": 30718.02829194069, "episode/length": 174.0, "episode/score": 0.20419892189329403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20419892189329403}
{"step": 613264, "time": 30724.86205816269, "episode/length": 219.0, "episode/score": 0.24660310191302415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24660310191302415}
{"step": 613568, "time": 30737.810732364655, "episode/length": 202.0, "episode/score": 0.21488008424557847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21488008424557847}
{"step": 613736, "time": 30745.5276491642, "episode/length": 161.0, "episode/score": 0.18041877631003445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18041877631003445}
{"step": 613864, "time": 30751.707406520844, "episode/length": 244.0, "episode/score": 0.27830979954751456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27830979954751456}
{"step": 614008, "time": 30758.63909316063, "episode/length": 152.0, "episode/score": 0.167588656172029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.167588656172029}
{"step": 614080, "time": 30763.111379384995, "episode/length": 163.0, "episode/score": 0.17408016339231835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17408016339231835}
{"step": 614400, "time": 30776.757546663284, "episode/length": 173.0, "episode/score": 0.17898961038554262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17898961038554262}
{"step": 614528, "time": 30784.528200387955, "episode/length": 175.0, "episode/score": 0.19312426343731204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19312426343731204}
{"step": 614840, "time": 30797.80431485176, "episode/length": 196.0, "episode/score": 0.21237761707288882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21237761707288882}
{"step": 615056, "time": 30807.553220510483, "episode/length": 185.0, "episode/score": 0.21247234817428762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21247234817428762}
{"step": 615256, "time": 30816.368035316467, "episode/length": 155.0, "episode/score": 0.17077091195096727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17077091195096727}
{"step": 615592, "time": 30830.788238286972, "episode/length": 41.0, "episode/score": 0.04254948516609147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04254948516609147}
{"step": 615616, "time": 30833.40306711197, "episode/length": 191.0, "episode/score": 0.19046940893758801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19046940893758801}
{"step": 615664, "time": 30836.76215839386, "episode/length": 141.0, "episode/score": 0.15557814401518044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15557814401518044}
{"step": 615832, "time": 30844.339789628983, "episode/length": 245.0, "episode/score": 0.29571758679958293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29571758679958293}
{"step": 615856, "time": 30846.906979084015, "episode/length": 181.0, "episode/score": 0.19964831016841345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19964831016841345}
{"step": 615992, "time": 30853.165113925934, "episode/length": 281.0, "episode/score": 0.3109681470045871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3109681470045871}
{"step": 616512, "time": 30873.99263238907, "episode/length": 111.0, "episode/score": 0.11421296022081151, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11421296022081151}
{"step": 616712, "time": 30882.910176753998, "episode/length": 233.0, "episode/score": 0.2710496546196737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2710496546196737}
{"step": 616936, "time": 30892.690335035324, "episode/length": 167.0, "episode/score": 0.17572803121584002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17572803121584002}
{"step": 616992, "time": 30896.595037937164, "episode/length": 124.0, "episode/score": 0.14404581007875095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14404581007875095}
{"step": 617200, "time": 30906.40579366684, "episode/length": 267.0, "episode/score": 0.2932835968294967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2932835968294967}
{"step": 617216, "time": 30909.16040444374, "episode/length": 169.0, "episode/score": 0.1704798214668699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1704798214668699}
{"step": 617272, "time": 30913.152898788452, "episode/length": 179.0, "episode/score": 0.19446468747582912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19446468747582912}
{"step": 617872, "time": 30937.620344161987, "episode/length": 169.0, "episode/score": 0.1813862403278108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1813862403278108}
{"step": 617944, "time": 30942.0953540802, "episode/length": 153.0, "episode/score": 0.16802012631524121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16802012631524121}
{"step": 618384, "time": 30960.51811695099, "episode/length": 173.0, "episode/score": 0.17655986765339549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17655986765339549}
{"step": 618408, "time": 30962.784437179565, "episode/length": 183.0, "episode/score": 0.20013353105423448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20013353105423448}
{"step": 618672, "time": 30974.305824041367, "episode/length": 174.0, "episode/score": 0.2039572298690473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2039572298690473}
{"step": 618904, "time": 30984.266798734665, "episode/length": 64.0, "episode/score": 0.07596322394238086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07596322394238086}
{"step": 618984, "time": 30988.691894054413, "episode/length": 138.0, "episode/score": 0.15660272083914606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15660272083914606}
{"step": 619032, "time": 30991.993500232697, "episode/length": 420.0, "episode/score": 0.3923714916077188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3923714916077188}
{"step": 619056, "time": 30994.61603808403, "episode/length": 229.0, "episode/score": 0.24760956526233713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24760956526233713}
{"step": 619312, "time": 31005.709099531174, "episode/length": 170.0, "episode/score": 0.19162179181876127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19162179181876127}
{"step": 619728, "time": 31022.605408668518, "episode/length": 164.0, "episode/score": 0.1432405838604609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1432405838604609}
{"step": 620000, "time": 31034.268648386, "episode/length": 165.0, "episode/score": 0.18616235128138214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18616235128138214}
{"step": 620048, "time": 31051.714171409607, "eval_episode/length": 45.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8913043478260869}
{"step": 620048, "time": 31053.817944288254, "eval_episode/length": 60.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9180327868852459}
{"step": 620048, "time": 31057.96521782875, "eval_episode/length": 122.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.991869918699187}
{"step": 620048, "time": 31060.647993803024, "eval_episode/length": 149.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 620048, "time": 31063.796262979507, "eval_episode/length": 173.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 620048, "time": 31065.833939552307, "eval_episode/length": 187.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 620048, "time": 31068.643689632416, "eval_episode/length": 217.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 620048, "time": 31070.29633283615, "eval_episode/length": 172.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 620280, "time": 31078.792041778564, "episode/length": 384.0, "episode/score": 0.39129933440062814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39129933440062814}
{"step": 620520, "time": 31089.355401039124, "episode/length": 201.0, "episode/score": 0.18460664933263615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18460664933263615}
{"step": 620600, "time": 31093.893192768097, "episode/length": 195.0, "episode/score": 0.20197569488664158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20197569488664158}
{"step": 620688, "time": 31098.911022901535, "episode/length": 171.0, "episode/score": 0.1832794672664022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1832794672664022}
{"step": 620760, "time": 31102.978293418884, "episode/length": 221.0, "episode/score": 0.2476772424270166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2476772424270166}
{"step": 621288, "time": 31124.124596118927, "episode/length": 194.0, "episode/score": 0.21046555433895264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21046555433895264}
{"step": 621576, "time": 31136.408938884735, "episode/length": 196.0, "episode/score": 0.16875055220953072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16875055220953072}
{"step": 621840, "time": 31147.883021116257, "episode/length": 194.0, "episode/score": 0.19517069992798497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19517069992798497}
{"step": 621864, "time": 31150.09255695343, "episode/length": 350.0, "episode/score": 0.378690455283504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.378690455283504}
{"step": 621968, "time": 31155.642543315887, "episode/length": 170.0, "episode/score": 0.181398575025014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.181398575025014}
{"step": 622088, "time": 31161.362035036087, "episode/length": 165.0, "episode/score": 0.18238971354912792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18238971354912792}
{"step": 622128, "time": 31164.67415523529, "episode/length": 179.0, "episode/score": 0.18485676022828557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18485676022828557}
{"step": 622792, "time": 31192.183349132538, "episode/length": 283.0, "episode/score": 0.31455745403218316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31455745403218316}
{"step": 622872, "time": 31196.68929195404, "episode/length": 197.0, "episode/score": 0.2003165046689901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2003165046689901}
{"step": 623032, "time": 31204.123300552368, "episode/length": 181.0, "episode/score": 0.17495658271764114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17495658271764114}
{"step": 623056, "time": 31206.675384759903, "episode/length": 148.0, "episode/score": 0.16457016755430232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16457016755430232}
{"step": 623312, "time": 31217.729850292206, "episode/length": 152.0, "episode/score": 0.16520602567470632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16520602567470632}
{"step": 623552, "time": 31228.12051153183, "episode/length": 177.0, "episode/score": 0.20698007159808185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20698007159808185}
{"step": 623840, "time": 31240.291285037994, "episode/length": 249.0, "episode/score": 0.2767048642908776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2767048642908776}
{"step": 624232, "time": 31256.14081645012, "episode/length": 149.0, "episode/score": 0.15384991000428272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15384991000428272}
{"step": 624320, "time": 31261.152848005295, "episode/length": 180.0, "episode/score": 0.18383260281007097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18383260281007097}
{"step": 624592, "time": 31272.84418773651, "episode/length": 224.0, "episode/score": 0.2431257947919221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2431257947919221}
{"step": 624632, "time": 31275.60331249237, "episode/length": 196.0, "episode/score": 0.21796927647392295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21796927647392295}
{"step": 624880, "time": 31286.68438577652, "episode/length": 129.0, "episode/score": 0.1264280375571616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1264280375571616}
{"step": 625328, "time": 31305.26544737816, "episode/length": 419.0, "episode/score": 0.4157385017733759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4157385017733759}
{"step": 625344, "time": 31307.337557554245, "episode/length": 223.0, "episode/score": 0.20879894656991382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20879894656991382}
{"step": 625504, "time": 31314.685456991196, "episode/length": 158.0, "episode/score": 0.15603055907467933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15603055907467933}
{"step": 625512, "time": 31316.230647563934, "episode/length": 148.0, "episode/score": 0.1639533975321683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1639533975321683}
{"step": 625744, "time": 31326.49736070633, "episode/length": 143.0, "episode/score": 0.17271669118144928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17271669118144928}
{"step": 625745, "time": 31328.724934101105, "train_stats/sum_log_reward": 1.5953270678765306, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.224299065420561, "train_stats/max_log_achievement_collect_sapling": 0.7009345794392523, "train_stats/max_log_achievement_collect_stone": 0.009345794392523364, "train_stats/max_log_achievement_collect_wood": 0.9439252336448598, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.06542056074766354, "train_stats/max_log_achievement_eat_cow": 0.009345794392523364, "train_stats/max_log_achievement_make_wood_pickaxe": 0.018691588785046728, "train_stats/max_log_achievement_make_wood_sword": 0.018691588785046728, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.19626168224299065, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.19626168224299065, "train_stats/max_log_achievement_wake_up": 0.308411214953271, "train_stats/mean_log_entropy": 2.104360362079656, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.029038202194941, "train/action_min": 0.0, "train/action_std": 4.682465821977646, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008045388234128792, "train/actor_opt_grad_steps": 38385.0, "train/actor_opt_loss": -11.496213144430566, "train/adv_mag": 0.18121428113608135, "train/adv_max": 0.13118147879602418, "train/adv_mean": -0.00011680501707257376, "train/adv_min": -0.18044777545664045, "train/adv_std": 0.01356875810713049, "train/cont_avg": 0.9944506448412699, "train/cont_loss_mean": 0.00028117072132238444, "train/cont_loss_std": 0.007857920862631675, "train/cont_neg_acc": 0.9939531381168063, "train/cont_neg_loss": 0.024266831158218424, "train/cont_pos_acc": 0.999968780884667, "train/cont_pos_loss": 0.00013071059860684787, "train/cont_pred": 0.9944669112326607, "train/cont_rate": 0.9944506448412699, "train/dyn_loss_mean": 11.317335802411277, "train/dyn_loss_std": 8.542046505307395, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14450885136685673, "train/extr_critic_critic_opt_grad_steps": 38385.0, "train/extr_critic_critic_opt_loss": 12087.42417689732, "train/extr_critic_mag": 0.2887062401998611, "train/extr_critic_max": 0.2887062401998611, "train/extr_critic_mean": 0.23307773080610095, "train/extr_critic_min": 0.0021351632617768786, "train/extr_critic_std": 0.0628839252694022, "train/extr_return_normed_mag": 0.21448591930998695, "train/extr_return_normed_max": 0.21448591930998695, "train/extr_return_normed_mean": 0.1586810832931882, "train/extr_return_normed_min": -0.07269379821798158, "train/extr_return_normed_std": 0.06466362566228896, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2887658512308484, "train/extr_return_raw_max": 0.2887658512308484, "train/extr_return_raw_mean": 0.23296101710626058, "train/extr_return_raw_min": 0.0015861345898537408, "train/extr_return_raw_std": 0.06466362551445999, "train/extr_reward_mag": 0.0013029036067780993, "train/extr_reward_max": 0.0013029036067780993, "train/extr_reward_mean": 0.0010940342760896163, "train/extr_reward_min": 1.0443112206837488e-05, "train/extr_reward_std": 0.00024331040150995942, "train/image_loss_mean": 5.260693362780979, "train/image_loss_std": 10.214187955099439, "train/model_loss_mean": 12.091499434577095, "train/model_loss_std": 13.77068901818896, "train/model_opt_grad_norm": 51.50448202708411, "train/model_opt_grad_steps": 38348.62698412698, "train/model_opt_loss": 16402.91904606895, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1359.126984126984, "train/policy_entropy_mag": 2.76124049746801, "train/policy_entropy_max": 2.76124049746801, "train/policy_entropy_mean": 2.03559600739252, "train/policy_entropy_min": 0.08003646164895996, "train/policy_entropy_std": 0.6435549377448975, "train/policy_logprob_mag": 7.438221568153018, "train/policy_logprob_max": -0.009546632242817727, "train/policy_logprob_mean": -2.0366922030373225, "train/policy_logprob_min": -7.438221568153018, "train/policy_logprob_std": 1.1954768782570249, "train/policy_randomness_mag": 0.9745967227315145, "train/policy_randomness_max": 0.9745967227315145, "train/policy_randomness_mean": 0.7184760598909288, "train/policy_randomness_min": 0.02824935871398165, "train/policy_randomness_std": 0.22714665177322568, "train/post_ent_mag": 59.176024754842125, "train/post_ent_max": 59.176024754842125, "train/post_ent_mean": 41.85642293899778, "train/post_ent_min": 20.420472447834317, "train/post_ent_std": 7.136394073092748, "train/prior_ent_mag": 69.01381525917658, "train/prior_ent_max": 69.01381525917658, "train/prior_ent_mean": 53.22807920546759, "train/prior_ent_min": 33.40614161415706, "train/prior_ent_std": 5.37923983165196, "train/rep_loss_mean": 11.317335802411277, "train/rep_loss_std": 8.542046505307395, "train/reward_avg": 0.0010630808704133546, "train/reward_loss_mean": 0.040123484437427824, "train/reward_loss_std": 0.011289637779728287, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001276820425003294, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040123484260033045, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010622456440672514, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 0.9749999726191163, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.0625, "eval_stats/max_log_achievement_collect_sapling": 0.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.25, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.345465185906505e-06, "report/cont_loss_std": 0.00010580413800198585, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.800110324751586e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.325103873270564e-06, "report/cont_pred": 0.9941364526748657, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 10.932334899902344, "report/dyn_loss_std": 8.38073444366455, "report/image_loss_mean": 5.699220657348633, "report/image_loss_std": 8.837926864624023, "report/model_loss_mean": 12.299829483032227, "report/model_loss_std": 12.026477813720703, "report/post_ent_mag": 58.187618255615234, "report/post_ent_max": 58.187618255615234, "report/post_ent_mean": 41.97584915161133, "report/post_ent_min": 21.671358108520508, "report/post_ent_std": 7.2408647537231445, "report/prior_ent_mag": 69.37628173828125, "report/prior_ent_max": 69.37628173828125, "report/prior_ent_mean": 53.01021194458008, "report/prior_ent_min": 32.22782897949219, "report/prior_ent_std": 5.329262733459473, "report/rep_loss_mean": 10.932334899902344, "report/rep_loss_std": 8.38073444366455, "report/reward_avg": 0.0010973296593874693, "report/reward_loss_mean": 0.04120326787233353, "report/reward_loss_std": 0.011072592809796333, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012753009796142578, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04120326787233353, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0011016560019925237, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 1.8385873090664973e-07, "eval/cont_loss_std": 8.258427328655671e-07, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.644263102207333e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.679654957342791e-07, "eval/cont_pred": 0.9990233182907104, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 16.903902053833008, "eval/dyn_loss_std": 10.474644660949707, "eval/image_loss_mean": 10.279291152954102, "eval/image_loss_std": 14.383415222167969, "eval/model_loss_mean": 21.043285369873047, "eval/model_loss_std": 18.658294677734375, "eval/post_ent_mag": 61.893577575683594, "eval/post_ent_max": 61.893577575683594, "eval/post_ent_mean": 39.97914123535156, "eval/post_ent_min": 19.11417007446289, "eval/post_ent_std": 7.165087699890137, "eval/prior_ent_mag": 69.37628173828125, "eval/prior_ent_max": 69.37628173828125, "eval/prior_ent_mean": 53.44126892089844, "eval/prior_ent_min": 36.21009063720703, "eval/prior_ent_std": 4.862364292144775, "eval/rep_loss_mean": 16.903902053833008, "eval/rep_loss_std": 10.474644660949707, "eval/reward_avg": 0.010351561941206455, "eval/reward_loss_mean": 0.6216514706611633, "eval/reward_loss_std": 3.442573070526123, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.001295328140258789, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.36201417446136475, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.813440322875977, "eval/reward_pred": 0.0010324479080736637, "eval/reward_rate": 0.0126953125, "replay/size": 625241.0, "replay/inserts": 20200.0, "replay/samples": 20192.0, "replay/insert_wait_avg": 1.3090124224672224e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.711055728410579e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4408.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.177921918256313e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.8730225563049, "timer/env.step_count": 2525.0, "timer/env.step_total": 237.7433340549469, "timer/env.step_frac": 0.23753595980410439, "timer/env.step_avg": 0.09415577586334531, "timer/env.step_min": 0.022203683853149414, "timer/env.step_max": 3.26605486869812, "timer/replay._sample_count": 20192.0, "timer/replay._sample_total": 9.64291262626648, "timer/replay._sample_frac": 0.0096345014891477, "timer/replay._sample_avg": 0.00047756104527864893, "timer/replay._sample_min": 0.0003876686096191406, "timer/replay._sample_max": 0.01065683364868164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3076.0, "timer/agent.policy_total": 50.4933397769928, "timer/agent.policy_frac": 0.050449296403283016, "timer/agent.policy_avg": 0.016415260005524318, "timer/agent.policy_min": 0.009770870208740234, "timer/agent.policy_max": 0.1358661651611328, "timer/dataset_train_count": 1262.0, "timer/dataset_train_total": 0.1381847858428955, "timer/dataset_train_frac": 0.0001380642526361248, "timer/dataset_train_avg": 0.00010949666073129597, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.00028586387634277344, "timer/agent.train_count": 1262.0, "timer/agent.train_total": 562.1486146450043, "timer/agent.train_frac": 0.5616582743026028, "timer/agent.train_avg": 0.4454426423494487, "timer/agent.train_min": 0.43254876136779785, "timer/agent.train_max": 1.0630948543548584, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48276185989379883, "timer/agent.report_frac": 0.00048234076552566954, "timer/agent.report_avg": 0.24138092994689941, "timer/agent.report_min": 0.23345589637756348, "timer/agent.report_max": 0.24930596351623535, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1443801293620947e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 20.1821564029677}
{"step": 626160, "time": 31344.336076259613, "episode/length": 190.0, "episode/score": 0.2031226371855155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2031226371855155}
{"step": 626272, "time": 31349.932411670685, "episode/length": 173.0, "episode/score": 0.18324682384172775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18324682384172775}
{"step": 626560, "time": 31362.24632191658, "episode/length": 153.0, "episode/score": 0.1549784326880399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1549784326880399}
{"step": 626784, "time": 31371.9763879776, "episode/length": 433.0, "episode/score": 0.4262561944533445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4262561944533445}
{"step": 626872, "time": 31376.602069854736, "episode/length": 170.0, "episode/score": 0.17473246127792663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17473246127792663}
{"step": 627184, "time": 31389.86614894867, "episode/length": 208.0, "episode/score": 0.23375154043696966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23375154043696966}
{"step": 627440, "time": 31400.829430818558, "episode/length": 211.0, "episode/score": 0.24382128201114028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24382128201114028}
{"step": 627640, "time": 31409.553326129913, "episode/length": 106.0, "episode/score": 0.12501276896819036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12501276896819036}
{"step": 627712, "time": 31413.95542407036, "episode/length": 295.0, "episode/score": 0.3260784174631226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3260784174631226}
{"step": 627904, "time": 31422.663049459457, "episode/length": 203.0, "episode/score": 0.21860863906977102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21860863906977102}
{"step": 628328, "time": 31439.679855823517, "episode/length": 181.0, "episode/score": 0.202320892654825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.202320892654825}
{"step": 628424, "time": 31444.710581064224, "episode/length": 282.0, "episode/score": 0.3224775218122886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3224775218122886}
{"step": 628584, "time": 31452.240152835846, "episode/length": 252.0, "episode/score": 0.25468019848858603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25468019848858603}
{"step": 628960, "time": 31467.823836803436, "episode/length": 164.0, "episode/score": 0.18600809721829137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18600809721829137}
{"step": 628992, "time": 31470.62513756752, "episode/length": 225.0, "episode/score": 0.2340139428783914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2340139428783914}
{"step": 629192, "time": 31479.3849234581, "episode/length": 160.0, "episode/score": 0.1801527606980926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1801527606980926}
{"step": 629552, "time": 31494.607978343964, "episode/length": 263.0, "episode/score": 0.2817520584517297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2817520584517297}
{"step": 629616, "time": 31498.42317867279, "episode/length": 237.0, "episode/score": 0.27273259512912773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27273259512912773}
{"step": 629760, "time": 31505.243049144745, "episode/length": 178.0, "episode/score": 0.20287876995598708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20287876995598708}
{"step": 629824, "time": 31509.154719114304, "episode/length": 107.0, "episode/score": 0.13374999712686986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13374999712686986}
{"step": 630032, "time": 31536.071499586105, "eval_episode/length": 112.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9557522123893806}
{"step": 630032, "time": 31539.551830291748, "eval_episode/length": 141.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 630032, "time": 31543.066621780396, "eval_episode/length": 177.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 630032, "time": 31544.847088336945, "eval_episode/length": 183.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 630032, "time": 31546.37055873871, "eval_episode/length": 184.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 630032, "time": 31548.755603790283, "eval_episode/length": 202.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 630032, "time": 31553.14866256714, "eval_episode/length": 157.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 630032, "time": 31554.881700992584, "eval_episode/length": 277.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9820143884892086}
{"step": 630320, "time": 31565.492305755615, "episode/length": 165.0, "episode/score": 0.1721339600567262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1721339600567262}
{"step": 630328, "time": 31567.230070590973, "episode/length": 217.0, "episode/score": 0.21768422121704134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21768422121704134}
{"step": 630376, "time": 31570.53586244583, "episode/length": 243.0, "episode/score": 0.28220033554816837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28220033554816837}
{"step": 630672, "time": 31583.072254896164, "episode/length": 184.0, "episode/score": 0.2093083671156819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2093083671156819}
{"step": 630976, "time": 31597.498880386353, "episode/length": 151.0, "episode/score": 0.1530594157725318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1530594157725318}
{"step": 631056, "time": 31601.972126483917, "episode/length": 179.0, "episode/score": 0.1767004004559567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1767004004559567}
{"step": 631120, "time": 31605.85933971405, "episode/length": 99.0, "episode/score": 0.12004166416591033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12004166416591033}
{"step": 631168, "time": 31609.176109552383, "episode/length": 167.0, "episode/score": 0.16533218894937818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16533218894937818}
{"step": 631976, "time": 31640.61768770218, "episode/length": 162.0, "episode/score": 0.1748068111774046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1748068111774046}
{"step": 632088, "time": 31646.245170354843, "episode/length": 316.0, "episode/score": 0.3432138336988828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3432138336988828}
{"step": 632128, "time": 31649.561898708344, "episode/length": 224.0, "episode/score": 0.2588414987694705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2588414987694705}
{"step": 632304, "time": 31657.759961366653, "episode/length": 165.0, "episode/score": 0.1879505084689299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1879505084689299}
{"step": 632560, "time": 31668.78029036522, "episode/length": 187.0, "episode/score": 0.19416179543623002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19416179543623002}
{"step": 632608, "time": 31672.05594778061, "episode/length": 185.0, "episode/score": 0.16324353598974994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16324353598974994}
{"step": 632984, "time": 31687.28191614151, "episode/length": 226.0, "episode/score": 0.2429298832976201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2429298832976201}
{"step": 633272, "time": 31699.442045927048, "episode/length": 147.0, "episode/score": 0.1720651615760289, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1720651615760289}
{"step": 633336, "time": 31703.23638033867, "episode/length": 150.0, "episode/score": 0.16189912626941805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16189912626941805}
{"step": 633344, "time": 31705.24125933647, "episode/length": 370.0, "episode/score": 0.38374914063024335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.38374914063024335}
{"step": 633736, "time": 31721.08277487755, "episode/length": 219.0, "episode/score": 0.2535238050913904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2535238050913904}
{"step": 633752, "time": 31723.15403008461, "episode/length": 148.0, "episode/score": 0.1662445097863383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1662445097863383}
{"step": 633824, "time": 31727.541039705276, "episode/length": 60.0, "episode/score": 0.07083333202172071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07083333202172071}
{"step": 634016, "time": 31736.254945755005, "episode/length": 175.0, "episode/score": 0.1822482971510908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1822482971510908}
{"step": 634424, "time": 31752.76367211342, "episode/length": 179.0, "episode/score": 0.197600229344971, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.197600229344971}
{"step": 634504, "time": 31757.22377896309, "episode/length": 144.0, "episode/score": 0.16443145073390042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16443145073390042}
{"step": 634768, "time": 31768.73980474472, "episode/length": 186.0, "episode/score": 0.22158332908293232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22158332908293232}
{"step": 635080, "time": 31781.708536863327, "episode/length": 167.0, "episode/score": 0.19003435596459894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19003435596459894}
{"step": 635168, "time": 31786.77170562744, "episode/length": 167.0, "episode/score": 0.18267772861327103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18267772861327103}
{"step": 635264, "time": 31791.81478524208, "episode/length": 188.0, "episode/score": 0.18971320269884018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18971320269884018}
{"step": 635576, "time": 31804.60608124733, "episode/length": 143.0, "episode/score": 0.16212522613932379, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16212522613932379}
{"step": 635840, "time": 31816.221192121506, "episode/length": 166.0, "episode/score": 0.1757853131293814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1757853131293814}
{"step": 635864, "time": 31818.39128422737, "episode/length": 230.0, "episode/score": 0.257844331805245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.257844331805245}
{"step": 635960, "time": 31823.718962192535, "episode/length": 456.0, "episode/score": 0.4478664129601384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4478664129601384}
{"step": 636232, "time": 31835.707844257355, "episode/length": 182.0, "episode/score": 0.20269829634344205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20269829634344205}
{"step": 636432, "time": 31844.988551855087, "episode/length": 168.0, "episode/score": 0.1738995550895197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1738995550895197}
{"step": 636768, "time": 31859.043824911118, "episode/length": 199.0, "episode/score": 0.17974463941663998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17974463941663998}
{"step": 637032, "time": 31870.19119477272, "episode/length": 181.0, "episode/score": 0.18849780395339621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18849780395339621}
{"step": 637040, "time": 31872.291167974472, "episode/length": 149.0, "episode/score": 0.1562061289587291, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1562061289587291}
{"step": 637048, "time": 31873.796798944473, "episode/length": 222.0, "episode/score": 0.26246175797678006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26246175797678006}
{"step": 637344, "time": 31886.514798641205, "episode/length": 172.0, "episode/score": 0.17757282863567525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17757282863567525}
{"step": 637384, "time": 31889.15663957596, "episode/length": 189.0, "episode/score": 0.21456747855881986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21456747855881986}
{"step": 638064, "time": 31916.364000320435, "episode/length": 203.0, "episode/score": 0.21170820979205018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21170820979205018}
{"step": 638160, "time": 31921.38407254219, "episode/length": 139.0, "episode/score": 0.14804782302053354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14804782302053354}
{"step": 638200, "time": 31924.141304016113, "episode/length": 178.0, "episode/score": 0.1793204577143115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1793204577143115}
{"step": 638208, "time": 31926.10357785225, "episode/length": 246.0, "episode/score": 0.2742850581607854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2742850581607854}
{"step": 638568, "time": 31940.914865255356, "episode/length": 189.0, "episode/score": 0.18795442432110576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18795442432110576}
{"step": 638752, "time": 31949.560210704803, "episode/length": 214.0, "episode/score": 0.23438807211005042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23438807211005042}
{"step": 638800, "time": 31952.857916116714, "episode/length": 181.0, "episode/score": 0.18256361168550939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18256361168550939}
{"step": 639408, "time": 31978.579411506653, "episode/length": 155.0, "episode/score": 0.13518981733068358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13518981733068358}
{"step": 639472, "time": 31982.513234853745, "episode/length": 260.0, "episode/score": 0.28000909960337594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28000909960337594}
{"step": 639472, "time": 31982.52110505104, "episode/length": 175.0, "episode/score": 0.17725378517934587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17725378517934587}
{"step": 639600, "time": 31990.450337171555, "episode/length": 174.0, "episode/score": 0.16932568374249968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16932568374249968}
{"step": 639656, "time": 31993.758166074753, "episode/length": 180.0, "episode/score": 0.18382589075918077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18382589075918077}
{"step": 639832, "time": 32001.66733598709, "episode/length": 157.0, "episode/score": 0.18654764409802738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18654764409802738}
{"step": 640016, "time": 32030.701758384705, "eval_episode/length": 134.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 640016, "time": 32033.63456773758, "eval_episode/length": 168.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 640016, "time": 32035.841873645782, "eval_episode/length": 180.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.994475138121547}
{"step": 640016, "time": 32039.22718667984, "eval_episode/length": 222.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 640016, "time": 32040.922622919083, "eval_episode/length": 227.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 640016, "time": 32042.43868994713, "eval_episode/length": 228.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 640016, "time": 32044.97665476799, "eval_episode/length": 253.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9803149606299213}
{"step": 640016, "time": 32047.24951863289, "eval_episode/length": 47.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 640496, "time": 32065.01652431488, "episode/length": 217.0, "episode/score": 0.23004318330640672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23004318330640672}
{"step": 640512, "time": 32067.095371484756, "episode/length": 213.0, "episode/score": 0.2151407011806441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2151407011806441}
{"step": 640648, "time": 32073.332597494125, "episode/length": 154.0, "episode/score": 0.16515937486656185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16515937486656185}
{"step": 640840, "time": 32082.010639429092, "episode/length": 147.0, "episode/score": 0.16960939757700544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16960939757700544}
{"step": 640896, "time": 32085.760724544525, "episode/length": 177.0, "episode/score": 0.19524847258981026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19524847258981026}
{"step": 641024, "time": 32092.088745355606, "episode/length": 177.0, "episode/score": 0.18658403203335183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18658403203335183}
{"step": 641128, "time": 32097.15484046936, "episode/length": 206.0, "episode/score": 0.22516285137862724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22516285137862724}
{"step": 641584, "time": 32115.817762613297, "episode/length": 218.0, "episode/score": 0.24308782099978998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24308782099978998}
{"step": 641960, "time": 32130.96659708023, "episode/length": 182.0, "episode/score": 0.1848261891373113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1848261891373113}
{"step": 642008, "time": 32134.249650001526, "episode/length": 169.0, "episode/score": 0.18460768853037735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18460768853037735}
{"step": 642120, "time": 32140.02205967903, "episode/length": 152.0, "episode/score": 0.1761983693759248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1761983693759248}
{"step": 642136, "time": 32142.078300476074, "episode/length": 138.0, "episode/score": 0.16014369505501236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16014369505501236}
{"step": 642224, "time": 32147.11737036705, "episode/length": 172.0, "episode/score": 0.1849959280280018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1849959280280018}
{"step": 642432, "time": 32156.37869668007, "episode/length": 162.0, "episode/score": 0.16563713385949086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16563713385949086}
{"step": 643016, "time": 32179.95471405983, "episode/length": 178.0, "episode/score": 0.19641746568777307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19641746568777307}
{"step": 643232, "time": 32189.706475496292, "episode/length": 136.0, "episode/score": 0.13730499187477108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13730499187477108}
{"step": 643248, "time": 32191.849195718765, "episode/length": 160.0, "episode/score": 0.18445747873374785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18445747873374785}
{"step": 643296, "time": 32195.167501449585, "episode/length": 146.0, "episode/score": 0.1501453285172829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1501453285172829}
{"step": 643360, "time": 32199.195286512375, "episode/length": 168.0, "episode/score": 0.1670797348033375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1670797348033375}
{"step": 643600, "time": 32209.439665555954, "episode/length": 145.0, "episode/score": 0.16205541140607238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16205541140607238}
{"step": 643984, "time": 32225.146620750427, "episode/length": 433.0, "episode/score": 0.4672055433557034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4672055433557034}
{"step": 644096, "time": 32230.915630102158, "episode/length": 233.0, "episode/score": 0.26691396912247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26691396912247}
{"step": 644480, "time": 32246.592952013016, "episode/length": 155.0, "episode/score": 0.1640098635089089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1640098635089089}
{"step": 644720, "time": 32257.06714630127, "episode/length": 183.0, "episode/score": 0.19878352873092808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19878352873092808}
{"step": 644824, "time": 32262.2279214859, "episode/length": 225.0, "episode/score": 0.25670149732741265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25670149732741265}
{"step": 645096, "time": 32274.151362895966, "episode/length": 216.0, "episode/score": 0.24571335546079354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24571335546079354}
{"step": 645144, "time": 32277.973603725433, "episode/length": 39.0, "episode/score": 0.04549999925075099, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04549999925075099}
{"step": 645224, "time": 32282.653807878494, "episode/length": 240.0, "episode/score": 0.2810109848360298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2810109848360298}
{"step": 645496, "time": 32294.088203668594, "episode/length": 236.0, "episode/score": 0.2771812022256199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2771812022256199}
{"step": 645624, "time": 32300.28374004364, "episode/length": 59.0, "episode/score": 0.056523594974351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056523594974351}
{"step": 645992, "time": 32315.189448595047, "episode/length": 236.0, "episode/score": 0.27172217431962054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27172217431962054}
{"step": 646128, "time": 32321.87167572975, "episode/length": 175.0, "episode/score": 0.17418381109928305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17418381109928305}
{"step": 646152, "time": 32324.156867980957, "episode/length": 208.0, "episode/score": 0.246071423873218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.246071423873218}
{"step": 646217, "time": 32329.111062526703, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.1565704345703125, "train/action_min": 0.0, "train/action_std": 4.733853477984667, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008536403494872502, "train/actor_opt_grad_steps": 39655.0, "train/actor_opt_loss": -12.49183928174898, "train/adv_mag": 0.18425942404428497, "train/adv_max": 0.13591145630925894, "train/adv_mean": -0.00011533178811262701, "train/adv_min": -0.18255212635267526, "train/adv_std": 0.014200213925505523, "train/cont_avg": 0.9944915771484375, "train/cont_loss_mean": 0.00022842437076120437, "train/cont_loss_std": 0.0070631147497732805, "train/cont_neg_acc": 0.9960193461738527, "train/cont_neg_loss": 0.026769409931723942, "train/cont_pos_acc": 0.9999462892301381, "train/cont_pos_loss": 7.778612294850884e-05, "train/cont_pred": 0.9944811896421015, "train/cont_rate": 0.9944915771484375, "train/dyn_loss_mean": 11.253258526325226, "train/dyn_loss_std": 8.569605860859156, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1473664164368529, "train/extr_critic_critic_opt_grad_steps": 39655.0, "train/extr_critic_critic_opt_loss": 12097.411582946777, "train/extr_critic_mag": 0.288946483284235, "train/extr_critic_max": 0.288946483284235, "train/extr_critic_mean": 0.23313579673413187, "train/extr_critic_min": 0.001586301252245903, "train/extr_critic_std": 0.06226086203241721, "train/extr_return_normed_mag": 0.2187278465135023, "train/extr_return_normed_max": 0.2187278465135023, "train/extr_return_normed_mean": 0.16261936933733523, "train/extr_return_normed_min": -0.06940387492068112, "train/extr_return_normed_std": 0.06404975624172948, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2891289354301989, "train/extr_return_raw_max": 0.2891289354301989, "train/extr_return_raw_mean": 0.23302046372555196, "train/extr_return_raw_min": 0.0009972136467695236, "train/extr_return_raw_std": 0.06404975615441799, "train/extr_reward_mag": 0.001301380805671215, "train/extr_reward_max": 0.001301380805671215, "train/extr_reward_mean": 0.0010944688538074843, "train/extr_reward_min": 1.0658055543899536e-05, "train/extr_reward_std": 0.00024212520020228112, "train/image_loss_mean": 5.133796660229564, "train/image_loss_std": 9.841816551983356, "train/model_loss_mean": 11.926050178706646, "train/model_loss_std": 13.448270872235298, "train/model_opt_grad_norm": 54.8766577988863, "train/model_opt_grad_steps": 39617.5078125, "train/model_opt_loss": 16260.762153625488, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1367.1875, "train/policy_entropy_mag": 2.7608559485524893, "train/policy_entropy_max": 2.7608559485524893, "train/policy_entropy_mean": 2.06700237095356, "train/policy_entropy_min": 0.07993671426083893, "train/policy_entropy_std": 0.6071670046076179, "train/policy_logprob_mag": 7.4382542707026005, "train/policy_logprob_max": -0.00953346001188038, "train/policy_logprob_mean": -2.0661804527044296, "train/policy_logprob_min": -7.4382542707026005, "train/policy_logprob_std": 1.175521801225841, "train/policy_randomness_mag": 0.9744609915651381, "train/policy_randomness_max": 0.9744609915651381, "train/policy_randomness_mean": 0.7295611351728439, "train/policy_randomness_min": 0.02821415226208046, "train/policy_randomness_std": 0.2143033086322248, "train/post_ent_mag": 59.50646764039993, "train/post_ent_max": 59.50646764039993, "train/post_ent_mean": 41.99109551310539, "train/post_ent_min": 20.339990988373756, "train/post_ent_std": 7.233410131186247, "train/prior_ent_mag": 69.0810626745224, "train/prior_ent_max": 69.0810626745224, "train/prior_ent_mean": 53.31335669755936, "train/prior_ent_min": 33.70467871427536, "train/prior_ent_std": 5.427792754024267, "train/rep_loss_mean": 11.253258526325226, "train/rep_loss_std": 8.569605860859156, "train/reward_avg": 0.0010616169493005145, "train/reward_loss_mean": 0.04007004312006757, "train/reward_loss_std": 0.011330285153235309, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001271951012313366, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04007004326558672, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001059859107954253, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.581132052149975, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.226415094339623, "train_stats/max_log_achievement_collect_sapling": 0.7641509433962265, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.8207547169811321, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0660377358490566, "train_stats/max_log_achievement_eat_cow": 0.009433962264150943, "train_stats/max_log_achievement_make_wood_pickaxe": 0.018867924528301886, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.3018867924528302, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.1320754716981132, "train_stats/max_log_achievement_wake_up": 0.39622641509433965, "train_stats/mean_log_entropy": 2.1674450422233007, "eval_stats/sum_log_reward": 1.9124999679625034, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.75, "eval_stats/max_log_achievement_collect_sapling": 0.8125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 0.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 6.487919017672539e-05, "report/cont_loss_std": 0.0018666601972654462, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.0325660443631932e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.51417940389365e-05, "report/cont_pred": 0.9940778017044067, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 10.91739559173584, "report/dyn_loss_std": 9.039841651916504, "report/image_loss_mean": 5.4725847244262695, "report/image_loss_std": 10.63266658782959, "report/model_loss_mean": 12.063345909118652, "report/model_loss_std": 14.715252876281738, "report/post_ent_mag": 57.88365936279297, "report/post_ent_max": 57.88365936279297, "report/post_ent_mean": 40.84894561767578, "report/post_ent_min": 19.648799896240234, "report/post_ent_std": 6.675511360168457, "report/prior_ent_mag": 68.98855590820312, "report/prior_ent_max": 68.98855590820312, "report/prior_ent_mean": 51.82362747192383, "report/prior_ent_min": 32.341552734375, "report/prior_ent_std": 5.55406379699707, "report/rep_loss_mean": 10.91739559173584, "report/rep_loss_std": 9.039841651916504, "report/reward_avg": 0.0010649911127984524, "report/reward_loss_mean": 0.0402585007250309, "report/reward_loss_std": 0.011225946247577667, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001295328140258789, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0402585007250309, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010612055193632841, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 7.137661668821238e-06, "eval/cont_loss_std": 0.0002164200705010444, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.589743523159996e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.04224157743738e-06, "eval/cont_pred": 0.9980400204658508, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.232410430908203, "eval/dyn_loss_std": 10.310869216918945, "eval/image_loss_mean": 8.470651626586914, "eval/image_loss_std": 12.2240571975708, "eval/model_loss_mean": 19.424942016601562, "eval/model_loss_std": 16.53536033630371, "eval/post_ent_mag": 62.1585693359375, "eval/post_ent_max": 62.1585693359375, "eval/post_ent_mean": 39.45920181274414, "eval/post_ent_min": 21.031097412109375, "eval/post_ent_std": 6.918894290924072, "eval/prior_ent_mag": 68.98855590820312, "eval/prior_ent_max": 68.98855590820312, "eval/prior_ent_mean": 53.79362487792969, "eval/prior_ent_min": 38.116180419921875, "eval/prior_ent_std": 4.913297653198242, "eval/rep_loss_mean": 17.232410430908203, "eval/rep_loss_std": 10.310869216918945, "eval/reward_avg": 0.01093750074505806, "eval/reward_loss_mean": 0.6148358583450317, "eval/reward_loss_std": 3.407407760620117, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012853145599365234, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.33529937267303467, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.78139877319336, "eval/reward_pred": 0.0011027029249817133, "eval/reward_rate": 0.013671875, "replay/size": 645713.0, "replay/inserts": 20472.0, "replay/samples": 20480.0, "replay/insert_wait_avg": 1.3293885495244362e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.72811472415924e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4392.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1664162133777945e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3765408992767, "timer/env.step_count": 2559.0, "timer/env.step_total": 226.5721514225006, "timer/env.step_frac": 0.22648686985285185, "timer/env.step_avg": 0.08853933232610418, "timer/env.step_min": 0.022044658660888672, "timer/env.step_max": 3.1194777488708496, "timer/replay._sample_count": 20480.0, "timer/replay._sample_total": 9.740614175796509, "timer/replay._sample_frac": 0.009736947816709394, "timer/replay._sample_avg": 0.00047561592655256393, "timer/replay._sample_min": 0.00034928321838378906, "timer/replay._sample_max": 0.009303092956542969, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3108.0, "timer/agent.policy_total": 49.93014574050903, "timer/agent.policy_frac": 0.04991135207511455, "timer/agent.policy_avg": 0.016065040457049238, "timer/agent.policy_min": 0.009805440902709961, "timer/agent.policy_max": 0.1162872314453125, "timer/dataset_train_count": 1280.0, "timer/dataset_train_total": 0.13784265518188477, "timer/dataset_train_frac": 0.00013779077132093954, "timer/dataset_train_avg": 0.00010768957436084748, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.0010998249053955078, "timer/agent.train_count": 1280.0, "timer/agent.train_total": 570.2805268764496, "timer/agent.train_frac": 0.5700658737596971, "timer/agent.train_avg": 0.44553166162222624, "timer/agent.train_min": 0.43373608589172363, "timer/agent.train_max": 1.0767536163330078, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4812958240509033, "timer/agent.report_frac": 0.0004811146647024011, "timer/agent.report_avg": 0.24064791202545166, "timer/agent.report_min": 0.23352861404418945, "timer/agent.report_max": 0.24776721000671387, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.0742416381835938e-05, "timer/dataset_eval_frac": 2.073460895353442e-08, "timer/dataset_eval_avg": 2.0742416381835938e-05, "timer/dataset_eval_min": 2.0742416381835938e-05, "timer/dataset_eval_max": 2.0742416381835938e-05, "fps": 20.464043971952552}
{"step": 646472, "time": 32338.231538057327, "episode/length": 310.0, "episode/score": 0.34185957777208387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34185957777208387}
{"step": 646696, "time": 32348.1431119442, "episode/length": 183.0, "episode/score": 0.19396366413275246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19396366413275246}
{"step": 646864, "time": 32356.110123872757, "episode/length": 220.0, "episode/score": 0.2277277093853627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2277277093853627}
{"step": 647048, "time": 32364.079186439514, "episode/length": 111.0, "episode/score": 0.11844252617447637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11844252617447637}
{"step": 647080, "time": 32366.74173307419, "episode/length": 181.0, "episode/score": 0.1924990953411907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1924990953411907}
{"step": 647216, "time": 32374.871170282364, "episode/length": 214.0, "episode/score": 0.2430474201855759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2430474201855759}
{"step": 647264, "time": 32378.169228315353, "episode/length": 158.0, "episode/score": 0.16572767465549987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16572767465549987}
{"step": 647568, "time": 32390.74133205414, "episode/length": 179.0, "episode/score": 0.21210713891196065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21210713891196065}
{"step": 647768, "time": 32399.39357638359, "episode/length": 62.0, "episode/score": 0.06816333769529592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06816333769529592}
{"step": 648288, "time": 32420.38132572174, "episode/length": 150.0, "episode/score": 0.17341666363063268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17341666363063268}
{"step": 648400, "time": 32425.892055511475, "episode/length": 147.0, "episode/score": 0.16105448468442773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16105448468442773}
{"step": 648464, "time": 32429.90605020523, "episode/length": 199.0, "episode/score": 0.22786440920026507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22786440920026507}
{"step": 648736, "time": 32441.26858139038, "episode/length": 145.0, "episode/score": 0.16647186841146322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16647186841146322}
{"step": 648760, "time": 32443.40043067932, "episode/length": 213.0, "episode/score": 0.22409855423029512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22409855423029512}
{"step": 648784, "time": 32446.097724199295, "episode/length": 288.0, "episode/score": 0.31137826837584726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31137826837584726}
{"step": 648896, "time": 32451.644108057022, "episode/length": 274.0, "episode/score": 0.3153885799329146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3153885799329146}
{"step": 649168, "time": 32462.92671442032, "episode/length": 174.0, "episode/score": 0.178424204201292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.178424204201292}
{"step": 649584, "time": 32479.92087006569, "episode/length": 161.0, "episode/score": 0.15667613513505785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15667613513505785}
{"step": 649976, "time": 32495.600130796432, "episode/length": 148.0, "episode/score": 0.16810353871187544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16810353871187544}
{"step": 650000, "time": 32514.690278291702, "eval_episode/length": 111.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9553571428571429}
{"step": 650000, "time": 32516.814386606216, "eval_episode/length": 125.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9603174603174603}
{"step": 650000, "time": 32518.700670957565, "eval_episode/length": 136.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 650000, "time": 32520.384807109833, "eval_episode/length": 141.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9647887323943662}
{"step": 650000, "time": 32522.42989063263, "eval_episode/length": 154.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.967741935483871}
{"step": 650000, "time": 32526.749209165573, "eval_episode/length": 201.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 650000, "time": 32531.072481632233, "eval_episode/length": 249.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.996}
{"step": 650000, "time": 32533.05821466446, "eval_episode/length": 149.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 650024, "time": 32533.715598344803, "episode/length": 157.0, "episode/score": 0.16767146752317785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16767146752317785}
{"step": 650040, "time": 32535.85374522209, "episode/length": 162.0, "episode/score": 0.1767075188763556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1767075188763556}
{"step": 650320, "time": 32547.74826359749, "episode/length": 231.0, "episode/score": 0.26015306114641135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26015306114641135}
{"step": 650800, "time": 32566.799384832382, "episode/length": 237.0, "episode/score": 0.2641512993031938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2641512993031938}
{"step": 650920, "time": 32573.071135759354, "episode/length": 166.0, "episode/score": 0.18547514518104435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18547514518104435}
{"step": 650960, "time": 32576.617668628693, "episode/length": 223.0, "episode/score": 0.2631524792450364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2631524792450364}
{"step": 651040, "time": 32581.02654147148, "episode/length": 132.0, "episode/score": 0.14934124684805283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14934124684805283}
{"step": 651368, "time": 32594.299534082413, "episode/length": 167.0, "episode/score": 0.18402917811181396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18402917811181396}
{"step": 651384, "time": 32596.448380231857, "episode/length": 167.0, "episode/score": 0.19313322387461085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19313322387461085}
{"step": 651416, "time": 32599.151125907898, "episode/length": 376.0, "episode/score": 0.39784743648124277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39784743648124277}
{"step": 651664, "time": 32610.081506729126, "episode/length": 30.0, "episode/score": 0.03506944380933419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03506944380933419}
{"step": 652112, "time": 32628.80536341667, "episode/length": 223.0, "episode/score": 0.24038287124130875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24038287124130875}
{"step": 652312, "time": 32637.344014167786, "episode/length": 188.0, "episode/score": 0.18903444905299693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18903444905299693}
{"step": 652312, "time": 32637.355830669403, "episode/length": 173.0, "episode/score": 0.19240645532408962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19240645532408962}
{"step": 652384, "time": 32643.44330716133, "episode/length": 167.0, "episode/score": 0.1704117893750663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1704117893750663}
{"step": 652472, "time": 32648.132526636124, "episode/length": 188.0, "episode/score": 0.21520878715091385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21520878715091385}
{"step": 652808, "time": 32662.096291303635, "episode/length": 177.0, "episode/score": 0.1993586626376782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1993586626376782}
{"step": 652912, "time": 32667.748515605927, "episode/length": 155.0, "episode/score": 0.18517171351413708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18517171351413708}
{"step": 653144, "time": 32677.81682562828, "episode/length": 221.0, "episode/score": 0.25146652980401996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25146652980401996}
{"step": 653208, "time": 32681.550327539444, "episode/length": 102.0, "episode/score": 0.11443557741768018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11443557741768018}
{"step": 653248, "time": 32684.75599002838, "episode/length": 41.0, "episode/score": 0.0502083323081024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0502083323081024}
{"step": 653360, "time": 32690.914442777634, "episode/length": 155.0, "episode/score": 0.169821918298112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.169821918298112}
{"step": 653656, "time": 32703.411877393723, "episode/length": 167.0, "episode/score": 0.18539791410694306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18539791410694306}
{"step": 653720, "time": 32707.41186285019, "episode/length": 175.0, "episode/score": 0.17329397069079278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17329397069079278}
{"step": 654352, "time": 32732.03431248665, "episode/length": 192.0, "episode/score": 0.21255472634038597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21255472634038597}
{"step": 654528, "time": 32740.263644456863, "episode/length": 256.0, "episode/score": 0.27693628842826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27693628842826}
{"step": 654576, "time": 32743.507853746414, "episode/length": 170.0, "episode/score": 0.17512218003503222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17512218003503222}
{"step": 654696, "time": 32749.33138871193, "episode/length": 193.0, "episode/score": 0.20402362968889065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20402362968889065}
{"step": 654752, "time": 32753.11392736435, "episode/length": 187.0, "episode/score": 0.20860418146912707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20860418146912707}
{"step": 654944, "time": 32761.73857474327, "episode/length": 197.0, "episode/score": 0.22886285648928606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22886285648928606}
{"step": 655776, "time": 32795.806413412094, "episode/length": 149.0, "episode/score": 0.16460714014829136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16460714014829136}
{"step": 655832, "time": 32799.35205101967, "episode/length": 184.0, "episode/score": 0.1926623535091494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1926623535091494}
{"step": 655936, "time": 32805.42187023163, "episode/length": 154.0, "episode/score": 0.1620056598840165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1620056598840165}
{"step": 656120, "time": 32813.700056791306, "episode/length": 170.0, "episode/score": 0.17984414991769881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17984414991769881}
{"step": 656640, "time": 32835.06267809868, "episode/length": 211.0, "episode/score": 0.21108741748503235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21108741748503235}
{"step": 656768, "time": 32841.36662840843, "episode/length": 279.0, "episode/score": 0.3141479237410749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3141479237410749}
{"step": 656944, "time": 32849.938972473145, "episode/length": 402.0, "episode/score": 0.44342987863547023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44342987863547023}
{"step": 656992, "time": 32853.21636366844, "episode/length": 416.0, "episode/score": 0.40132269865807757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.40132269865807757}
{"step": 657024, "time": 32855.95973443985, "episode/length": 155.0, "episode/score": 0.17132312417015783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17132312417015783}
{"step": 657488, "time": 32874.90864491463, "episode/length": 206.0, "episode/score": 0.22700894909849012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22700894909849012}
{"step": 657968, "time": 32894.55606651306, "episode/length": 165.0, "episode/score": 0.18644446411781246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18644446411781246}
{"step": 657984, "time": 32896.64182686806, "episode/length": 255.0, "episode/score": 0.28115323680412985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28115323680412985}
{"step": 658376, "time": 32912.57174348831, "episode/length": 172.0, "episode/score": 0.1838990634678339, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1838990634678339}
{"step": 658392, "time": 32914.69877052307, "episode/length": 283.0, "episode/score": 0.3055790704966057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3055790704966057}
{"step": 658480, "time": 32919.888386011124, "episode/length": 213.0, "episode/score": 0.2378110649297014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2378110649297014}
{"step": 658608, "time": 32926.2235956192, "episode/length": 197.0, "episode/score": 0.2125360146710591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2125360146710591}
{"step": 658672, "time": 32930.13151597977, "episode/length": 215.0, "episode/score": 0.23949961913240259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23949961913240259}
{"step": 658792, "time": 32935.977236032486, "episode/length": 162.0, "episode/score": 0.18027607583644567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18027607583644567}
{"step": 659408, "time": 32961.30981898308, "episode/length": 179.0, "episode/score": 0.18135476153474883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18135476153474883}
{"step": 659456, "time": 32964.635937452316, "episode/length": 132.0, "episode/score": 0.13187847109293216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13187847109293216}
{"step": 659592, "time": 32970.99896860123, "episode/length": 138.0, "episode/score": 0.16700297271017917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16700297271017917}
{"step": 659664, "time": 32975.452090501785, "episode/length": 160.0, "episode/score": 0.1803827283983992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1803827283983992}
{"step": 659824, "time": 32983.0384824276, "episode/length": 229.0, "episode/score": 0.257232231368107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.257232231368107}
{"step": 659832, "time": 32984.64469122887, "episode/length": 144.0, "episode/score": 0.16172271611867473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16172271611867473}
{"step": 660056, "time": 32994.429746866226, "episode/length": 48.0, "episode/score": 0.059999998775310814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059999998775310814}
{"step": 660056, "time": 32994.43762922287, "episode/length": 180.0, "episode/score": 0.20246714441964286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20246714441964286}
{"step": 660088, "time": 33012.779660224915, "eval_episode/length": 42.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9069767441860465}
{"step": 660088, "time": 33018.07045841217, "eval_episode/length": 133.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9552238805970149}
{"step": 660088, "time": 33019.90669250488, "eval_episode/length": 138.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9640287769784173}
{"step": 660088, "time": 33022.45041847229, "eval_episode/length": 153.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 660088, "time": 33025.01768350601, "eval_episode/length": 166.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 660088, "time": 33029.662229537964, "eval_episode/length": 223.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 660088, "time": 33033.42609858513, "eval_episode/length": 235.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 660088, "time": 33035.7637591362, "eval_episode/length": 166.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 660240, "time": 33041.60133934021, "episode/length": 180.0, "episode/score": 0.18384639243231504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18384639243231504}
{"step": 660776, "time": 33062.60444355011, "episode/length": 147.0, "episode/score": 0.16410678491956787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16410678491956787}
{"step": 661024, "time": 33073.41527032852, "episode/length": 149.0, "episode/score": 0.15087110361309897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15087110361309897}
{"step": 661104, "time": 33077.91286993027, "episode/length": 211.0, "episode/score": 0.24737877211555315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24737877211555315}
{"step": 661240, "time": 33084.18616890907, "episode/length": 222.0, "episode/score": 0.21942357160332904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21942357160332904}
{"step": 661392, "time": 33091.56302165985, "episode/length": 194.0, "episode/score": 0.19932830629295495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19932830629295495}
{"step": 661696, "time": 33104.25021934509, "episode/length": 204.0, "episode/score": 0.21461606559387292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21461606559387292}
{"step": 661952, "time": 33115.43763279915, "episode/length": 213.0, "episode/score": 0.22761000066020642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22761000066020642}
{"step": 662032, "time": 33119.98681473732, "episode/length": 246.0, "episode/score": 0.27814867806409893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27814867806409893}
{"step": 662280, "time": 33130.5319647789, "episode/length": 146.0, "episode/score": 0.17683191999822157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17683191999822157}
{"step": 662416, "time": 33137.30098295212, "episode/length": 146.0, "episode/score": 0.16565626988813165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16565626988813165}
{"step": 662600, "time": 33145.58375167847, "episode/length": 227.0, "episode/score": 0.2603420073974121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2603420073974121}
{"step": 662672, "time": 33150.0293507576, "episode/length": 205.0, "episode/score": 0.2214796813295834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2214796813295834}
{"step": 662952, "time": 33161.744804382324, "episode/length": 124.0, "episode/score": 0.1357637470273403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1357637470273403}
{"step": 663248, "time": 33174.46750283241, "episode/length": 193.0, "episode/score": 0.21265170864080574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21265170864080574}
{"step": 663776, "time": 33197.65004968643, "episode/length": 186.0, "episode/score": 0.21745832945453003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21745832945453003}
{"step": 663896, "time": 33203.98886060715, "episode/length": 312.0, "episode/score": 0.32121779604676703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32121779604676703}
{"step": 663896, "time": 33203.99730563164, "episode/length": 152.0, "episode/score": 0.1775549802050591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1775549802050591}
{"step": 664416, "time": 33227.6496090889, "episode/length": 182.0, "episode/score": 0.2049662321269352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2049662321269352}
{"step": 664584, "time": 33235.23480939865, "episode/length": 247.0, "episode/score": 0.2774804826667605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2774804826667605}
{"step": 664784, "time": 33244.43488693237, "episode/length": 295.0, "episode/score": 0.3230831596429198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3230831596429198}
{"step": 664904, "time": 33250.246737957, "episode/length": 125.0, "episode/score": 0.1381857604956167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1381857604956167}
{"step": 665080, "time": 33258.292781353, "episode/length": 147.0, "episode/score": 0.16490951110790775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16490951110790775}
{"step": 665096, "time": 33260.31740260124, "episode/length": 230.0, "episode/score": 0.24382655170757062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24382655170757062}
{"step": 665112, "time": 33262.2905960083, "episode/length": 166.0, "episode/score": 0.17322837835308746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17322837835308746}
{"step": 665296, "time": 33270.977404356, "episode/length": 407.0, "episode/score": 0.41502359331843763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41502359331843763}
{"step": 665816, "time": 33291.67918634415, "episode/length": 153.0, "episode/score": 0.16352915212064545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16352915212064545}
{"step": 666040, "time": 33301.552439689636, "episode/length": 156.0, "episode/score": 0.14340060739868932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14340060739868932}
{"step": 666064, "time": 33304.22967219353, "episode/length": 144.0, "episode/score": 0.16695833049016073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16695833049016073}
{"step": 666248, "time": 33312.41534900665, "episode/length": 228.0, "episode/score": 0.25576266891857813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25576266891857813}
{"step": 666496, "time": 33323.40607523918, "episode/length": 176.0, "episode/score": 0.18757557080698462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18757557080698462}
{"step": 666593, "time": 33329.125816106796, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.975538839505413, "train/action_min": 0.0, "train/action_std": 4.67325872886838, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007876765129603738, "train/actor_opt_grad_steps": 40930.0, "train/actor_opt_loss": -14.984570434478325, "train/adv_mag": 0.1775730512156261, "train/adv_max": 0.11966784609349694, "train/adv_mean": -0.00021932226695171481, "train/adv_min": -0.1764934012505013, "train/adv_std": 0.013226665637096551, "train/cont_avg": 0.9947250246062992, "train/cont_loss_mean": 0.00015038591233406792, "train/cont_loss_std": 0.004585090668671201, "train/cont_neg_acc": 0.9955161861547335, "train/cont_neg_loss": 0.013273882055638364, "train/cont_pos_acc": 0.9999845117095887, "train/cont_pos_loss": 5.833059552151457e-05, "train/cont_pred": 0.9947217975075789, "train/cont_rate": 0.9947250246062992, "train/dyn_loss_mean": 11.16997239721103, "train/dyn_loss_std": 8.617886779815192, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14371233239887268, "train/extr_critic_critic_opt_grad_steps": 40930.0, "train/extr_critic_critic_opt_loss": 12006.79615987943, "train/extr_critic_mag": 0.287431107731316, "train/extr_critic_max": 0.287431107731316, "train/extr_critic_mean": 0.23035664926833055, "train/extr_critic_min": 0.0014328778259397493, "train/extr_critic_std": 0.06324445479732799, "train/extr_return_normed_mag": 0.22175991793317118, "train/extr_return_normed_max": 0.22175991793317118, "train/extr_return_normed_mean": 0.16468289711578624, "train/extr_return_normed_min": -0.06437560326353771, "train/extr_return_normed_std": 0.06486732371914106, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28721436130718925, "train/extr_return_raw_max": 0.28721436130718925, "train/extr_return_raw_mean": 0.23013734453775753, "train/extr_return_raw_min": 0.0010788400738140729, "train/extr_return_raw_std": 0.06486732345514411, "train/extr_reward_mag": 0.0013300415099136472, "train/extr_reward_max": 0.0013300415099136472, "train/extr_reward_mean": 0.0010994125247426976, "train/extr_reward_min": 1.074291589691883e-05, "train/extr_reward_std": 0.00024016970272659963, "train/image_loss_mean": 5.036074653385192, "train/image_loss_std": 10.063162518298531, "train/model_loss_mean": 11.778251129811204, "train/model_loss_std": 13.676838664557991, "train/model_opt_grad_norm": 50.04343168003353, "train/model_opt_grad_steps": 40891.299212598424, "train/model_opt_loss": 14845.39365465059, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1259.8425196850394, "train/policy_entropy_mag": 2.7602357244867037, "train/policy_entropy_max": 2.7602357244867037, "train/policy_entropy_mean": 2.0374495307291585, "train/policy_entropy_min": 0.08104870656109232, "train/policy_entropy_std": 0.5971954284221168, "train/policy_logprob_mag": 7.438310442947027, "train/policy_logprob_max": -0.009690744384360595, "train/policy_logprob_mean": -2.0381675695809793, "train/policy_logprob_min": -7.438310442947027, "train/policy_logprob_std": 1.193005562767269, "train/policy_randomness_mag": 0.9742420827309917, "train/policy_randomness_max": 0.9742420827309917, "train/policy_randomness_mean": 0.7191302752870274, "train/policy_randomness_min": 0.028606636655025594, "train/policy_randomness_std": 0.21078378138110393, "train/post_ent_mag": 59.61580904262272, "train/post_ent_max": 59.61580904262272, "train/post_ent_mean": 41.98793140922006, "train/post_ent_min": 20.000809376634013, "train/post_ent_std": 7.236200362678588, "train/prior_ent_mag": 69.18190134604146, "train/prior_ent_max": 69.18190134604146, "train/prior_ent_mean": 53.239358105997404, "train/prior_ent_min": 34.25837503268024, "train/prior_ent_std": 5.3915915188826915, "train/rep_loss_mean": 11.16997239721103, "train/rep_loss_std": 8.617886779815192, "train/reward_avg": 0.0010607678999603675, "train/reward_loss_mean": 0.040042671807638305, "train/reward_loss_std": 0.011376860008875686, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012753413418146568, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04004267177830531, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001061528548964952, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.609433936412042, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.4245283018867925, "train_stats/max_log_achievement_collect_sapling": 1.009433962264151, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.8207547169811321, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.09433962264150944, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.018867924528301886, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.41509433962264153, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.20754716981132076, "train_stats/max_log_achievement_wake_up": 0.22641509433962265, "train_stats/mean_log_entropy": 2.0794654735979043, "eval_stats/sum_log_reward": 1.3499999814666808, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.2686693935393123e-06, "report/cont_loss_std": 4.678826371673495e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.59233103558654e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.2517137975009973e-06, "report/cont_pred": 0.9960925579071045, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.273733139038086, "report/dyn_loss_std": 8.770130157470703, "report/image_loss_mean": 5.952353477478027, "report/image_loss_std": 15.750176429748535, "report/model_loss_mean": 12.755241394042969, "report/model_loss_std": 19.01582908630371, "report/post_ent_mag": 58.71784973144531, "report/post_ent_max": 58.71784973144531, "report/post_ent_mean": 41.185054779052734, "report/post_ent_min": 21.999523162841797, "report/post_ent_std": 6.80206298828125, "report/prior_ent_mag": 69.26834869384766, "report/prior_ent_max": 69.26834869384766, "report/prior_ent_mean": 53.15454864501953, "report/prior_ent_min": 36.261566162109375, "report/prior_ent_std": 5.733422756195068, "report/rep_loss_mean": 11.273733139038086, "report/rep_loss_std": 8.770130157470703, "report/reward_avg": 0.0010236701928079128, "report/reward_loss_mean": 0.03864753991365433, "report/reward_loss_std": 0.013316490687429905, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012606382369995117, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03864753991365433, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001013464410789311, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 3.6026802263222635e-05, "eval/cont_loss_std": 0.001107068033888936, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0008075565565377474, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.527261651470326e-05, "eval/cont_pred": 0.9989896416664124, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 17.256072998046875, "eval/dyn_loss_std": 9.620221138000488, "eval/image_loss_mean": 11.194194793701172, "eval/image_loss_std": 16.873546600341797, "eval/model_loss_mean": 21.987319946289062, "eval/model_loss_std": 20.716171264648438, "eval/post_ent_mag": 56.2105827331543, "eval/post_ent_max": 56.2105827331543, "eval/post_ent_mean": 39.71076583862305, "eval/post_ent_min": 21.11387825012207, "eval/post_ent_std": 6.593027114868164, "eval/prior_ent_mag": 69.26834869384766, "eval/prior_ent_max": 69.26834869384766, "eval/prior_ent_mean": 54.07373046875, "eval/prior_ent_min": 40.17100524902344, "eval/prior_ent_std": 4.676055431365967, "eval/rep_loss_mean": 17.256072998046875, "eval/rep_loss_std": 9.620221138000488, "eval/reward_avg": 0.00937500037252903, "eval/reward_loss_mean": 0.439445823431015, "eval/reward_loss_std": 2.9093191623687744, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013003349304199219, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.21778354048728943, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.85253143310547, "eval/reward_pred": 0.0010235700756311417, "eval/reward_rate": 0.0107421875, "replay/size": 666089.0, "replay/inserts": 20376.0, "replay/samples": 20368.0, "replay/insert_wait_avg": 1.3376527268792022e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.683286869141967e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4504.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1445044624233753e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0010945796967, "timer/env.step_count": 2547.0, "timer/env.step_total": 230.12850284576416, "timer/env.step_frac": 0.23012825095205305, "timer/env.step_avg": 0.09035276907960901, "timer/env.step_min": 0.022292137145996094, "timer/env.step_max": 4.079062223434448, "timer/replay._sample_count": 20368.0, "timer/replay._sample_total": 9.69465184211731, "timer/replay._sample_frac": 0.009694641230559853, "timer/replay._sample_avg": 0.00047597465839146254, "timer/replay._sample_min": 0.00034999847412109375, "timer/replay._sample_max": 0.03344917297363281, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3110.0, "timer/agent.policy_total": 49.97314238548279, "timer/agent.policy_frac": 0.049973087685955625, "timer/agent.policy_avg": 0.016068534529094142, "timer/agent.policy_min": 0.009552240371704102, "timer/agent.policy_max": 0.11138391494750977, "timer/dataset_train_count": 1273.0, "timer/dataset_train_total": 0.1331489086151123, "timer/dataset_train_frac": 0.00013314876287317984, "timer/dataset_train_avg": 0.00010459458650048099, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.00026345252990722656, "timer/agent.train_count": 1273.0, "timer/agent.train_total": 570.6367311477661, "timer/agent.train_frac": 0.5706361065410697, "timer/agent.train_avg": 0.44826137560704327, "timer/agent.train_min": 0.43233728408813477, "timer/agent.train_max": 1.0547916889190674, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48105883598327637, "timer/agent.report_frac": 0.000481058309426618, "timer/agent.report_avg": 0.24052941799163818, "timer/agent.report_min": 0.2328932285308838, "timer/agent.report_max": 0.24816560745239258, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7894943221644323e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 20.37573997310214}
{"step": 666632, "time": 33330.65701723099, "episode/length": 191.0, "episode/score": 0.21741923406716523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21741923406716523}
{"step": 666680, "time": 33334.01803898811, "episode/length": 172.0, "episode/score": 0.1931288250043508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1931288250043508}
{"step": 667112, "time": 33351.69757127762, "episode/length": 249.0, "episode/score": 0.2906673427505666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2906673427505666}
{"step": 667144, "time": 33354.305706977844, "episode/length": 165.0, "episode/score": 0.1846101480323341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1846101480323341}
{"step": 667384, "time": 33364.701996803284, "episode/length": 164.0, "episode/score": 0.1897011567671143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1897011567671143}
{"step": 667680, "time": 33377.49533987045, "episode/length": 204.0, "episode/score": 0.21234737608938303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21234737608938303}
{"step": 667720, "time": 33380.2135925293, "episode/length": 71.0, "episode/score": 0.07986969334797323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07986969334797323}
{"step": 667816, "time": 33385.23612475395, "episode/length": 164.0, "episode/score": 0.1742884239056366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1742884239056366}
{"step": 668120, "time": 33398.183096170425, "episode/length": 185.0, "episode/score": 0.19431891400199675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19431891400199675}
{"step": 668232, "time": 33403.83888435364, "episode/length": 247.0, "episode/score": 0.2849818728018363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2849818728018363}
{"step": 668368, "time": 33410.547117471695, "episode/length": 210.0, "episode/score": 0.23482169504586636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23482169504586636}
{"step": 668632, "time": 33421.47614979744, "episode/length": 155.0, "episode/score": 0.18799999629845843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18799999629845843}
{"step": 669248, "time": 33445.65097403526, "episode/length": 195.0, "episode/score": 0.19908414159317545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19908414159317545}
{"step": 669360, "time": 33451.31437277794, "episode/length": 154.0, "episode/score": 0.15116118878449925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15116118878449925}
{"step": 669408, "time": 33454.61601448059, "episode/length": 286.0, "episode/score": 0.2951957893465078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2951957893465078}
{"step": 669552, "time": 33461.559210300446, "episode/length": 164.0, "episode/score": 0.15033754118985598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15033754118985598}
{"step": 669888, "time": 33475.647572517395, "episode/length": 189.0, "episode/score": 0.18844967910763444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18844967910763444}
{"step": 669968, "time": 33480.069873809814, "episode/length": 166.0, "episode/score": 0.1752779025982818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1752779025982818}
{"step": 670072, "time": 33501.44287085533, "eval_episode/length": 85.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9883720930232558}
{"step": 670072, "time": 33506.05888938904, "eval_episode/length": 153.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 670072, "time": 33508.2959754467, "eval_episode/length": 170.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 670072, "time": 33510.078182697296, "eval_episode/length": 176.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 670072, "time": 33511.60612154007, "eval_episode/length": 177.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 670072, "time": 33513.34845280647, "eval_episode/length": 183.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 670072, "time": 33515.55559825897, "eval_episode/length": 201.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.995049504950495}
{"step": 670072, "time": 33518.66030097008, "eval_episode/length": 84.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9529411764705882}
{"step": 670760, "time": 33544.19320631027, "episode/length": 150.0, "episode/score": 0.1634281648821343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1634281648821343}
{"step": 670792, "time": 33547.13259649277, "episode/length": 178.0, "episode/score": 0.17565651227960188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17565651227960188}
{"step": 670888, "time": 33552.32508635521, "episode/length": 204.0, "episode/score": 0.22703991068374307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22703991068374307}
{"step": 670984, "time": 33557.463405132294, "episode/length": 395.0, "episode/score": 0.4194641914805288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4194641914805288}
{"step": 671200, "time": 33567.207077264786, "episode/length": 434.0, "episode/score": 0.4510227053838207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4510227053838207}
{"step": 671416, "time": 33576.50311875343, "episode/length": 190.0, "episode/score": 0.22176703274908505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22176703274908505}
{"step": 671432, "time": 33578.713937044144, "episode/length": 252.0, "episode/score": 0.26308637648753574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26308637648753574}
{"step": 671488, "time": 33582.48195362091, "episode/length": 189.0, "episode/score": 0.207241809640891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.207241809640891}
{"step": 672008, "time": 33604.6231136322, "episode/length": 127.0, "episode/score": 0.13376255790171854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13376255790171854}
{"step": 672264, "time": 33615.760993003845, "episode/length": 31.0, "episode/score": 0.03916666586883366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03916666586883366}
{"step": 672552, "time": 33627.90345263481, "episode/length": 168.0, "episode/score": 0.18798562317169853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18798562317169853}
{"step": 672560, "time": 33629.91366839409, "episode/length": 224.0, "episode/score": 0.22889116660189757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22889116660189757}
{"step": 672624, "time": 33633.82682132721, "episode/length": 216.0, "episode/score": 0.2415175150572395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2415175150572395}
{"step": 673248, "time": 33658.556117773056, "episode/length": 226.0, "episode/score": 0.23699239376355763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23699239376355763}
{"step": 673808, "time": 33681.00489783287, "episode/length": 147.0, "episode/score": 0.1606005666362762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1606005666362762}
{"step": 673872, "time": 33684.909165382385, "episode/length": 163.0, "episode/score": 0.1907393672308899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1907393672308899}
{"step": 674096, "time": 33694.76203775406, "episode/length": 192.0, "episode/score": 0.17448233730419815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17448233730419815}
{"step": 674144, "time": 33698.12257313728, "episode/length": 418.0, "episode/score": 0.449798511325298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.449798511325298}
{"step": 674480, "time": 33712.48073387146, "episode/length": 276.0, "episode/score": 0.3041003016801369, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3041003016801369}
{"step": 674664, "time": 33721.14485168457, "episode/length": 176.0, "episode/score": 0.19905141967547024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19905141967547024}
{"step": 674904, "time": 33732.160572052, "episode/length": 435.0, "episode/score": 0.4028906047237797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4028906047237797}
{"step": 674936, "time": 33734.87179541588, "episode/length": 430.0, "episode/score": 0.4645954718912435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4645954718912435}
{"step": 675120, "time": 33743.305424928665, "episode/length": 79.0, "episode/score": 0.06880462304161483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06880462304161483}
{"step": 675240, "time": 33749.17796111107, "episode/length": 142.0, "episode/score": 0.1590791193871155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1590791193871155}
{"step": 675712, "time": 33768.55574941635, "episode/length": 229.0, "episode/score": 0.24410769095538853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24410769095538853}
{"step": 675808, "time": 33773.66957497597, "episode/length": 249.0, "episode/score": 0.2913703982271727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2913703982271727}
{"step": 675888, "time": 33778.10078334808, "episode/length": 217.0, "episode/score": 0.2415424065698062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2415424065698062}
{"step": 676224, "time": 33792.18198657036, "episode/length": 137.0, "episode/score": 0.15440348112906577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15440348112906577}
{"step": 676344, "time": 33797.88638615608, "episode/length": 175.0, "episode/score": 0.1831772459054264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1831772459054264}
{"step": 676584, "time": 33808.40963768959, "episode/length": 29.0, "episode/score": 0.03708333254326135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03708333254326135}
{"step": 676592, "time": 33810.505137205124, "episode/length": 45.0, "episode/score": 0.049662474302749615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049662474302749615}
{"step": 676624, "time": 33813.25730919838, "episode/length": 244.0, "episode/score": 0.2598548077344276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2598548077344276}
{"step": 676944, "time": 33826.93929004669, "episode/length": 212.0, "episode/score": 0.24776209230276436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24776209230276436}
{"step": 677040, "time": 33832.08406209946, "episode/length": 143.0, "episode/score": 0.14150546853670676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14150546853670676}
{"step": 677240, "time": 33840.7711520195, "episode/length": 178.0, "episode/score": 0.2131289641888543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2131289641888543}
{"step": 677464, "time": 33850.68099117279, "episode/length": 218.0, "episode/score": 0.24168147874979695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24168147874979695}
{"step": 677776, "time": 33864.067482471466, "episode/length": 147.0, "episode/score": 0.14404940590156912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14404940590156912}
{"step": 677936, "time": 33871.442996263504, "episode/length": 123.0, "episode/score": 0.12400301245588707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12400301245588707}
{"step": 678176, "time": 33881.90805578232, "episode/length": 198.0, "episode/score": 0.20628267492975283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20628267492975283}
{"step": 678472, "time": 33894.21786212921, "episode/length": 445.0, "episode/score": 0.43385446341721945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.43385446341721945}
{"step": 678536, "time": 33898.57067155838, "episode/length": 186.0, "episode/score": 0.2109892709227097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2109892709227097}
{"step": 678752, "time": 33908.42122721672, "episode/length": 34.0, "episode/score": 0.03599999955622479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03599999955622479}
{"step": 678768, "time": 33910.59336948395, "episode/length": 162.0, "episode/score": 0.18386832825490274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18386832825490274}
{"step": 678784, "time": 33912.80120110512, "episode/length": 192.0, "episode/score": 0.21314317638257307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21314317638257307}
{"step": 678816, "time": 33915.54312944412, "episode/length": 273.0, "episode/score": 0.3130752773972745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3130752773972745}
{"step": 678976, "time": 33922.95776605606, "episode/length": 149.0, "episode/score": 0.15586511637161493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15586511637161493}
{"step": 679152, "time": 33930.990151405334, "episode/length": 151.0, "episode/score": 0.13904456955151545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13904456955151545}
{"step": 679744, "time": 33954.72536897659, "episode/length": 195.0, "episode/score": 0.19468495896489912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19468495896489912}
{"step": 679896, "time": 33961.67586302757, "episode/length": 134.0, "episode/score": 0.13647496311773466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13647496311773466}
{"step": 680024, "time": 33969.643366098404, "episode/length": 156.0, "episode/score": 0.1671812050981316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1671812050981316}
{"step": 680056, "time": 33991.187873125076, "eval_episode/length": 150.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9602649006622517}
{"step": 680056, "time": 33993.46214938164, "eval_episode/length": 168.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 680056, "time": 33995.28031849861, "eval_episode/length": 175.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 680056, "time": 33997.64876937866, "eval_episode/length": 184.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9675675675675676}
{"step": 680056, "time": 33999.5474319458, "eval_episode/length": 193.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 680056, "time": 34001.50816202164, "eval_episode/length": 204.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 680056, "time": 34003.78040981293, "eval_episode/length": 223.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 680056, "time": 34009.500386953354, "eval_episode/length": 175.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 680136, "time": 34012.515640974045, "episode/length": 144.0, "episode/score": 0.14511392827148484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14511392827148484}
{"step": 680240, "time": 34018.11783409119, "episode/length": 185.0, "episode/score": 0.20209154534450136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20209154534450136}
{"step": 680536, "time": 34030.62340641022, "episode/length": 249.0, "episode/score": 0.28889008849955644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28889008849955644}
{"step": 680920, "time": 34046.57776236534, "episode/length": 220.0, "episode/score": 0.24456173513544854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24456173513544854}
{"step": 680928, "time": 34048.6047744751, "episode/length": 267.0, "episode/score": 0.28273912622466923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28273912622466923}
{"step": 680992, "time": 34052.51620912552, "episode/length": 155.0, "episode/score": 0.155355619282318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.155355619282318}
{"step": 681384, "time": 34068.57031369209, "episode/length": 185.0, "episode/score": 0.21275333852668155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21275333852668155}
{"step": 681680, "time": 34081.42434692383, "episode/length": 192.0, "episode/score": 0.21563972477451898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21563972477451898}
{"step": 681968, "time": 34093.76133608818, "episode/length": 178.0, "episode/score": 0.17776001708989497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17776001708989497}
{"step": 682112, "time": 34100.58740615845, "episode/length": 260.0, "episode/score": 0.3051977631942009, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3051977631942009}
{"step": 682512, "time": 34117.807985305786, "episode/length": 283.0, "episode/score": 0.3335362022771733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3335362022771733}
{"step": 682568, "time": 34121.179983854294, "episode/length": 204.0, "episode/score": 0.22124267039907863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22124267039907863}
{"step": 682720, "time": 34128.71308493614, "episode/length": 224.0, "episode/score": 0.21123428802820854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21123428802820854}
{"step": 682728, "time": 34130.368730545044, "episode/length": 216.0, "episode/score": 0.2529597805405501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2529597805405501}
{"step": 683096, "time": 34145.5998339653, "episode/length": 176.0, "episode/score": 0.19877306373382453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19877306373382453}
{"step": 683304, "time": 34154.981092453, "episode/length": 148.0, "episode/score": 0.15349509251245763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15349509251245763}
{"step": 683344, "time": 34158.379339933395, "episode/length": 171.0, "episode/score": 0.17548342227746616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17548342227746616}
{"step": 683760, "time": 34175.345807790756, "episode/length": 296.0, "episode/score": 0.3287240446006763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3287240446006763}
{"step": 684000, "time": 34186.00868535042, "episode/length": 158.0, "episode/score": 0.16262691940937657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16262691940937657}
{"step": 684072, "time": 34189.997995853424, "episode/length": 168.0, "episode/score": 0.18160450732102618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18160450732102618}
{"step": 684288, "time": 34199.723489522934, "episode/length": 221.0, "episode/score": 0.2578189640153141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2578189640153141}
{"step": 684304, "time": 34201.85993599892, "episode/length": 216.0, "episode/score": 0.24280659700161777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24280659700161777}
{"step": 684344, "time": 34204.638011455536, "episode/length": 155.0, "episode/score": 0.17650085683271755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17650085683271755}
{"step": 684640, "time": 34217.40167808533, "episode/length": 161.0, "episode/score": 0.1637587297882419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1637587297882419}
{"step": 684696, "time": 34220.71407151222, "episode/length": 43.0, "episode/score": 0.04826893862627912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04826893862627912}
{"step": 684912, "time": 34230.506180524826, "episode/length": 200.0, "episode/score": 0.2267360310506774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2267360310506774}
{"step": 685088, "time": 34238.726309776306, "episode/length": 165.0, "episode/score": 0.19071194745629327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19071194745629327}
{"step": 685160, "time": 34242.68082118034, "episode/length": 144.0, "episode/score": 0.16654539586306782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16654539586306782}
{"step": 685560, "time": 34259.0080242157, "episode/length": 156.0, "episode/score": 0.17784001300606178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17784001300606178}
{"step": 685968, "time": 34276.09742331505, "episode/length": 209.0, "episode/score": 0.2507083285599947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2507083285599947}
{"step": 686056, "time": 34280.74675607681, "episode/length": 176.0, "episode/score": 0.20100634529808303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20100634529808303}
{"step": 686064, "time": 34282.80678868294, "episode/length": 170.0, "episode/score": 0.18663115738308989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18663115738308989}
{"step": 686136, "time": 34286.811811208725, "episode/length": 257.0, "episode/score": 0.2892398901785782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2892398901785782}
{"step": 686416, "time": 34299.032084703445, "episode/length": 156.0, "episode/score": 0.1683027655017213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1683027655017213}
{"step": 686544, "time": 34305.32790064812, "episode/length": 181.0, "episode/score": 0.20638238548417576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20638238548417576}
{"step": 686712, "time": 34312.88578605652, "episode/length": 143.0, "episode/score": 0.13948017172515392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13948017172515392}
{"step": 686720, "time": 34315.04140782356, "episode/length": 225.0, "episode/score": 0.23713792092894437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23713792092894437}
{"step": 686792, "time": 34319.00168347359, "episode/length": 90.0, "episode/score": 0.10226556710222212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10226556710222212}
{"step": 687001, "time": 34329.46773862839, "train_stats/sum_log_reward": 1.7226414753580994, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.028301886792453, "train_stats/max_log_achievement_collect_sapling": 0.8113207547169812, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.8301886792452831, "train_stats/max_log_achievement_defeat_skeleton": 0.009433962264150943, "train_stats/max_log_achievement_defeat_zombie": 0.05660377358490566, "train_stats/max_log_achievement_eat_cow": 0.02830188679245283, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.37735849056603776, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.11320754716981132, "train_stats/max_log_achievement_wake_up": 0.3018867924528302, "train_stats/mean_log_entropy": 2.0238394309889594, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.834350109100342, "train/action_min": 0.0, "train/action_std": 4.71766035631299, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008630676771645085, "train/actor_opt_grad_steps": 42205.0, "train/actor_opt_loss": -7.015641940086425, "train/adv_mag": 0.18032408878207207, "train/adv_max": 0.12627229106146842, "train/adv_mean": 0.00022225015550780824, "train/adv_min": -0.17967453366145492, "train/adv_std": 0.013941100514784921, "train/cont_avg": 0.994598388671875, "train/cont_loss_mean": 0.00016052713956593578, "train/cont_loss_std": 0.004695115172648645, "train/cont_neg_acc": 0.9971566054764696, "train/cont_neg_loss": 0.016647418774230066, "train/cont_pos_acc": 0.9999692947603762, "train/cont_pos_loss": 5.9820851598946234e-05, "train/cont_pred": 0.9946039509959519, "train/cont_rate": 0.994598388671875, "train/dyn_loss_mean": 11.213834717869759, "train/dyn_loss_std": 8.584726110100746, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1473648552200757, "train/extr_critic_critic_opt_grad_steps": 42205.0, "train/extr_critic_critic_opt_loss": 11952.364601135254, "train/extr_critic_mag": 0.2873761896044016, "train/extr_critic_max": 0.2873761896044016, "train/extr_critic_mean": 0.23038470675237477, "train/extr_critic_min": 0.0013873903080821037, "train/extr_critic_std": 0.0632227367896121, "train/extr_return_normed_mag": 0.2198488007998094, "train/extr_return_normed_max": 0.2198488007998094, "train/extr_return_normed_mean": 0.1628768101800233, "train/extr_return_normed_min": -0.06670547908288427, "train/extr_return_normed_std": 0.06477176825865172, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2875789334066212, "train/extr_return_raw_max": 0.2875789334066212, "train/extr_return_raw_mean": 0.2306069437181577, "train/extr_return_raw_min": 0.0010246532037854195, "train/extr_return_raw_std": 0.06477176860789768, "train/extr_reward_mag": 0.001298755407333374, "train/extr_reward_max": 0.001298755407333374, "train/extr_reward_mean": 0.001107935507207003, "train/extr_reward_min": 1.0133720934391022e-05, "train/extr_reward_std": 0.00023489050101943576, "train/image_loss_mean": 5.1883904207497835, "train/image_loss_std": 10.246439512819052, "train/model_loss_mean": 11.956935428082943, "train/model_loss_std": 13.8325784355402, "train/model_opt_grad_norm": 52.92450129985809, "train/model_opt_grad_steps": 42165.15625, "train/model_opt_loss": 16668.18849182129, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1396.484375, "train/policy_entropy_mag": 2.7584714014083147, "train/policy_entropy_max": 2.7584714014083147, "train/policy_entropy_mean": 1.9425182435661554, "train/policy_entropy_min": 0.0800888238591142, "train/policy_entropy_std": 0.6366163496859372, "train/policy_logprob_mag": 7.438317961990833, "train/policy_logprob_max": -0.00955572645762004, "train/policy_logprob_mean": -1.9430874390527606, "train/policy_logprob_min": -7.438317961990833, "train/policy_logprob_std": 1.2448435500264168, "train/policy_randomness_mag": 0.9736193502321839, "train/policy_randomness_max": 0.9736193502321839, "train/policy_randomness_mean": 0.68562369979918, "train/policy_randomness_min": 0.02826784021453932, "train/policy_randomness_std": 0.22469763457775116, "train/post_ent_mag": 59.440294325351715, "train/post_ent_max": 59.440294325351715, "train/post_ent_mean": 42.016225308179855, "train/post_ent_min": 20.09868337213993, "train/post_ent_std": 7.18686942383647, "train/prior_ent_mag": 69.24073332548141, "train/prior_ent_max": 69.24073332548141, "train/prior_ent_mean": 53.28352677822113, "train/prior_ent_min": 34.797448471188545, "train/prior_ent_std": 5.343346860259771, "train/rep_loss_mean": 11.213834717869759, "train/rep_loss_std": 8.584726110100746, "train/reward_avg": 0.0010623046809996595, "train/reward_loss_mean": 0.04008366758353077, "train/reward_loss_std": 0.011411608633352444, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001274600625038147, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04008366778725758, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010611008192427107, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.0999999549239874, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.375, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 0.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0002909589384216815, "report/cont_loss_std": 0.008444413542747498, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0036409697495400906, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00026790081756189466, "report/cont_pred": 0.9929550290107727, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 11.328278541564941, "report/dyn_loss_std": 8.954837799072266, "report/image_loss_mean": 5.249938011169434, "report/image_loss_std": 8.226225852966309, "report/model_loss_mean": 12.087501525878906, "report/model_loss_std": 11.922022819519043, "report/post_ent_mag": 60.147743225097656, "report/post_ent_max": 60.147743225097656, "report/post_ent_mean": 42.07254409790039, "report/post_ent_min": 19.945514678955078, "report/post_ent_std": 7.548899173736572, "report/prior_ent_mag": 68.88634490966797, "report/prior_ent_max": 68.88634490966797, "report/prior_ent_mean": 53.15766143798828, "report/prior_ent_min": 32.703800201416016, "report/prior_ent_std": 5.511856555938721, "report/rep_loss_mean": 11.328278541564941, "report/rep_loss_std": 8.954837799072266, "report/reward_avg": 0.0010676381643861532, "report/reward_loss_mean": 0.04030565917491913, "report/reward_loss_std": 0.011171763762831688, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012508630752563477, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04030565917491913, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001043651718646288, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.8721447961288504e-05, "eval/cont_loss_std": 0.0005868569714948535, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0027182158082723618, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.5524714399361983e-05, "eval/cont_pred": 0.9951150417327881, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.62984275817871, "eval/dyn_loss_std": 10.954243659973145, "eval/image_loss_mean": 13.371719360351562, "eval/image_loss_std": 17.624479293823242, "eval/model_loss_mean": 24.631202697753906, "eval/model_loss_std": 22.394672393798828, "eval/post_ent_mag": 55.89524841308594, "eval/post_ent_max": 55.89524841308594, "eval/post_ent_mean": 39.50239562988281, "eval/post_ent_min": 19.791343688964844, "eval/post_ent_std": 6.837901592254639, "eval/prior_ent_mag": 68.88634490966797, "eval/prior_ent_max": 68.88634490966797, "eval/prior_ent_mean": 54.110816955566406, "eval/prior_ent_min": 34.070220947265625, "eval/prior_ent_std": 5.177292823791504, "eval/rep_loss_mean": 17.62984275817871, "eval/rep_loss_std": 10.954243659973145, "eval/reward_avg": 0.007519531529396772, "eval/reward_loss_mean": 0.6815493106842041, "eval/reward_loss_std": 3.5852718353271484, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012508630752563477, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.4622325599193573, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.87862777709961, "eval/reward_pred": 0.0010623902780935168, "eval/reward_rate": 0.0107421875, "replay/size": 686497.0, "replay/inserts": 20408.0, "replay/samples": 20416.0, "replay/insert_wait_avg": 1.3109049765281423e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.606131903430138e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4528.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1441248465763806e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3277585506439, "timer/env.step_count": 2551.0, "timer/env.step_total": 227.42635893821716, "timer/env.step_frac": 0.22735184242785678, "timer/env.step_avg": 0.08915184591854848, "timer/env.step_min": 0.022284746170043945, "timer/env.step_max": 2.0176353454589844, "timer/replay._sample_count": 20416.0, "timer/replay._sample_total": 9.768128395080566, "timer/replay._sample_frac": 0.009764927856479184, "timer/replay._sample_avg": 0.00047845456480606223, "timer/replay._sample_min": 0.00036907196044921875, "timer/replay._sample_max": 0.02839374542236328, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3117.0, "timer/agent.policy_total": 49.399179458618164, "timer/agent.policy_frac": 0.049382993760156875, "timer/agent.policy_avg": 0.015848309098048817, "timer/agent.policy_min": 0.00943899154663086, "timer/agent.policy_max": 0.09848761558532715, "timer/dataset_train_count": 1276.0, "timer/dataset_train_total": 0.13446664810180664, "timer/dataset_train_frac": 0.0001344225899485513, "timer/dataset_train_avg": 0.00010538138565972307, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0003266334533691406, "timer/agent.train_count": 1276.0, "timer/agent.train_total": 573.507890701294, "timer/agent.train_frac": 0.5733199801755364, "timer/agent.train_avg": 0.44945759459349055, "timer/agent.train_min": 0.4340529441833496, "timer/agent.train_max": 1.1818320751190186, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48330140113830566, "timer/agent.report_frac": 0.0004831430468735087, "timer/agent.report_avg": 0.24165070056915283, "timer/agent.report_min": 0.2354271411895752, "timer/agent.report_max": 0.24787425994873047, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2890983614896756e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 20.401049651172507}
{"step": 687128, "time": 34334.265642642975, "episode/length": 51.0, "episode/score": 0.050986801070393994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050986801070393994}
{"step": 687240, "time": 34339.9598069191, "episode/length": 158.0, "episode/score": 0.1789914016644616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1789914016644616}
{"step": 687656, "time": 34357.225779533386, "episode/length": 199.0, "episode/score": 0.20611554677634558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20611554677634558}
{"step": 687784, "time": 34363.548060655594, "episode/length": 123.0, "episode/score": 0.13110293959653063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13110293959653063}
{"step": 688280, "time": 34385.197645902634, "episode/length": 216.0, "episode/score": 0.24173230593623884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24173230593623884}
{"step": 688312, "time": 34387.93144893646, "episode/length": 198.0, "episode/score": 0.21538705578132067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21538705578132067}
{"step": 688344, "time": 34390.6384100914, "episode/length": 240.0, "episode/score": 0.28437797076185234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28437797076185234}
{"step": 688344, "time": 34390.6535885334, "episode/length": 275.0, "episode/score": 0.30999674015947676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30999674015947676}
{"step": 688400, "time": 34396.067490816116, "episode/length": 144.0, "episode/score": 0.17110897108796053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17110897108796053}
{"step": 688424, "time": 34398.35433459282, "episode/length": 161.0, "episode/score": 0.1815725078631658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1815725078631658}
{"step": 689144, "time": 34427.170073747635, "episode/length": 169.0, "episode/score": 0.18495487837935798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18495487837935798}
{"step": 689656, "time": 34447.79059767723, "episode/length": 153.0, "episode/score": 0.1558209378781612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1558209378781612}
{"step": 689904, "time": 34458.86151814461, "episode/length": 198.0, "episode/score": 0.2100672677916009, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2100672677916009}
{"step": 690008, "time": 34464.12228536606, "episode/length": 207.0, "episode/score": 0.2414352635241812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2414352635241812}
{"step": 690040, "time": 34481.7175757885, "eval_episode/length": 47.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 690040, "time": 34489.493559360504, "eval_episode/length": 158.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 690040, "time": 34491.279445409775, "eval_episode/length": 164.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 690040, "time": 34492.81797122955, "eval_episode/length": 166.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 690040, "time": 34495.09336924553, "eval_episode/length": 184.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 690040, "time": 34496.989297151566, "eval_episode/length": 195.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 690040, "time": 34496.99678349495, "eval_episode/length": 195.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 690040, "time": 34501.91991305351, "eval_episode/length": 189.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 690336, "time": 34513.38990068436, "episode/length": 256.0, "episode/score": 0.3003858211959596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3003858211959596}
{"step": 690368, "time": 34516.05739068985, "episode/length": 245.0, "episode/score": 0.27778120897710323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27778120897710323}
{"step": 690656, "time": 34528.23980474472, "episode/length": 288.0, "episode/score": 0.32378451065233094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32378451065233094}
{"step": 690864, "time": 34537.513501405716, "episode/length": 214.0, "episode/score": 0.2498856058518868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2498856058518868}
{"step": 691000, "time": 34543.86357522011, "episode/length": 167.0, "episode/score": 0.19462738206493668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19462738206493668}
{"step": 691184, "time": 34552.51075053215, "episode/length": 39.0, "episode/score": 0.045959820490679704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045959820490679704}
{"step": 691320, "time": 34558.9448325634, "episode/length": 457.0, "episode/score": 0.4871590625953104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4871590625953104}
{"step": 691624, "time": 34571.86757731438, "episode/length": 120.0, "episode/score": 0.13805874610989122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13805874610989122}
{"step": 691664, "time": 34575.112132787704, "episode/length": 206.0, "episode/score": 0.22097175618182519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22097175618182519}
{"step": 692072, "time": 34591.79761457443, "episode/length": 133.0, "episode/score": 0.15074363094572618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15074363094572618}
{"step": 692312, "time": 34602.48581767082, "episode/length": 242.0, "episode/score": 0.28254764747907757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28254764747907757}
{"step": 692496, "time": 34611.17684555054, "episode/length": 146.0, "episode/score": 0.16700739265615994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16700739265615994}
{"step": 692632, "time": 34617.54896736145, "episode/length": 69.0, "episode/score": 0.07750085864972789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07750085864972789}
{"step": 692696, "time": 34621.47001385689, "episode/length": 188.0, "episode/score": 0.2097669372415112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2097669372415112}
{"step": 693168, "time": 34640.96010875702, "episode/length": 353.0, "episode/score": 0.4052902340517903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4052902340517903}
{"step": 693192, "time": 34643.109277009964, "episode/length": 195.0, "episode/score": 0.20324223168427125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20324223168427125}
{"step": 693528, "time": 34657.33740782738, "episode/length": 452.0, "episode/score": 0.47145061688206624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.47145061688206624}
{"step": 693632, "time": 34663.53606438637, "episode/length": 245.0, "episode/score": 0.2813670583709609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2813670583709609}
{"step": 694008, "time": 34679.61561989784, "episode/length": 188.0, "episode/score": 0.20746640819925233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20746640819925233}
{"step": 694120, "time": 34685.282106399536, "episode/length": 225.0, "episode/score": 0.24286176046007313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24286176046007313}
{"step": 694560, "time": 34703.754490852356, "episode/length": 240.0, "episode/score": 0.2581577410455793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2581577410455793}
{"step": 694648, "time": 34708.43027591705, "episode/length": 184.0, "episode/score": 0.20478122374697705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20478122374697705}
{"step": 694728, "time": 34713.035168647766, "episode/length": 136.0, "episode/score": 0.151518511112954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.151518511112954}
{"step": 694832, "time": 34718.820987701416, "episode/length": 266.0, "episode/score": 0.2927707523413119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2927707523413119}
{"step": 695064, "time": 34728.91811990738, "episode/length": 191.0, "episode/score": 0.19823787875066046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19823787875066046}
{"step": 695400, "time": 34743.29522275925, "episode/length": 173.0, "episode/score": 0.20231547256116755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20231547256116755}
{"step": 695456, "time": 34747.19023656845, "episode/length": 166.0, "episode/score": 0.18594097325694747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18594097325694747}
{"step": 695704, "time": 34757.838680028915, "episode/length": 313.0, "episode/score": 0.3521265789604513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3521265789604513}
{"step": 695832, "time": 34764.91022491455, "episode/length": 124.0, "episode/score": 0.13874559685064014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13874559685064014}
{"step": 695944, "time": 34771.054480314255, "episode/length": 172.0, "episode/score": 0.180605717087019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.180605717087019}
{"step": 696000, "time": 34774.93982076645, "episode/length": 168.0, "episode/score": 0.1948085869753413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1948085869753413}
{"step": 696088, "time": 34779.664254665375, "episode/length": 169.0, "episode/score": 0.17821319072754704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17821319072754704}
{"step": 696360, "time": 34793.161319732666, "episode/length": 161.0, "episode/score": 0.16279009066784056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16279009066784056}
{"step": 696536, "time": 34801.49237322807, "episode/length": 141.0, "episode/score": 0.14874868685365072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14874868685365072}
{"step": 696584, "time": 34804.73206162453, "episode/length": 79.0, "episode/score": 0.08150145849685941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08150145849685941}
{"step": 696608, "time": 34807.56957292557, "episode/length": 143.0, "episode/score": 0.16539565840321302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16539565840321302}
{"step": 697008, "time": 34824.597551345825, "episode/length": 162.0, "episode/score": 0.16915393723684247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16915393723684247}
{"step": 697224, "time": 34833.989577293396, "episode/length": 173.0, "episode/score": 0.18979264946210606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18979264946210606}
{"step": 697264, "time": 34837.19266486168, "episode/length": 157.0, "episode/score": 0.17285484439707943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17285484439707943}
{"step": 697264, "time": 34837.200389146805, "episode/length": 146.0, "episode/score": 0.17383333010366186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17383333010366186}
{"step": 697960, "time": 34866.417657613754, "episode/length": 199.0, "episode/score": 0.2273285216306249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2273285216306249}
{"step": 698056, "time": 34871.6627676487, "episode/length": 189.0, "episode/score": 0.20779528628554544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20779528628554544}
{"step": 698184, "time": 34878.00527191162, "episode/length": 196.0, "episode/score": 0.20655934855221858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20655934855221858}
{"step": 698408, "time": 34887.84454655647, "episode/length": 227.0, "episode/score": 0.25619064144029835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25619064144029835}
{"step": 698472, "time": 34891.80912041664, "episode/length": 150.0, "episode/score": 0.16280818202358205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16280818202358205}
{"step": 698648, "time": 34900.094703912735, "episode/length": 177.0, "episode/score": 0.1834385799447773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1834385799447773}
{"step": 698648, "time": 34900.1031627655, "episode/length": 204.0, "episode/score": 0.22672719632464577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22672719632464577}
{"step": 699048, "time": 34918.22341012955, "episode/length": 49.0, "episode/score": 0.05923245500889607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05923245500889607}
{"step": 699264, "time": 34928.07428956032, "episode/length": 150.0, "episode/score": 0.16411509073805064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16411509073805064}
{"step": 699544, "time": 34939.876190662384, "episode/length": 197.0, "episode/score": 0.23313157464144751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23313157464144751}
{"step": 699608, "time": 34943.83060526848, "episode/length": 177.0, "episode/score": 0.19210287258465542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19210287258465542}
{"step": 699728, "time": 34950.02179956436, "episode/length": 164.0, "episode/score": 0.17659697136696195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17659697136696195}
{"step": 700024, "time": 34980.73080801964, "eval_episode/length": 132.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9473684210526315}
{"step": 700024, "time": 34984.250030994415, "eval_episode/length": 178.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.994413407821229}
{"step": 700024, "time": 34986.01476597786, "eval_episode/length": 184.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 700024, "time": 34988.1297724247, "eval_episode/length": 197.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 700024, "time": 34990.17147254944, "eval_episode/length": 211.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 700024, "time": 34991.982676029205, "eval_episode/length": 219.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 700024, "time": 34993.748498916626, "eval_episode/length": 224.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9822222222222222}
{"step": 700024, "time": 34998.40820932388, "eval_episode/length": 83.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9404761904761905}
{"step": 700224, "time": 35006.01193666458, "episode/length": 196.0, "episode/score": 0.20667349661016488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20667349661016488}
{"step": 700456, "time": 35015.93520784378, "episode/length": 175.0, "episode/score": 0.183889043990348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.183889043990348}
{"step": 700480, "time": 35018.74359178543, "episode/length": 151.0, "episode/score": 0.1632107398691005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1632107398691005}
{"step": 700512, "time": 35021.510514974594, "episode/length": 254.0, "episode/score": 0.2734061332521378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2734061332521378}
{"step": 700616, "time": 35026.620052814484, "episode/length": 418.0, "episode/score": 0.46111723427748075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.46111723427748075}
{"step": 700912, "time": 35039.728796482086, "episode/length": 162.0, "episode/score": 0.16486580003402196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16486580003402196}
{"step": 701120, "time": 35049.923377752304, "episode/length": 196.0, "episode/score": 0.2178095761955774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2178095761955774}
{"step": 701280, "time": 35057.47932243347, "episode/length": 193.0, "episode/score": 0.21576236803048232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21576236803048232}
{"step": 701696, "time": 35074.72102546692, "episode/length": 183.0, "episode/score": 0.2050565009121783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2050565009121783}
{"step": 701928, "time": 35084.682223796844, "episode/length": 176.0, "episode/score": 0.18379262533926521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18379262533926521}
{"step": 702008, "time": 35089.145478248596, "episode/length": 193.0, "episode/score": 0.20472781669013784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20472781669013784}
{"step": 702096, "time": 35094.057641744614, "episode/length": 201.0, "episode/score": 0.21330375143770652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21330375143770652}
{"step": 702192, "time": 35099.135326862335, "episode/length": 196.0, "episode/score": 0.21423084471280163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21423084471280163}
{"step": 702320, "time": 35105.423461675644, "episode/length": 149.0, "episode/score": 0.17370833025779575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17370833025779575}
{"step": 702704, "time": 35121.49112248421, "episode/length": 177.0, "episode/score": 0.19215824192178843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19215824192178843}
{"step": 702768, "time": 35125.41167092323, "episode/length": 231.0, "episode/score": 0.25298797182404087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25298797182404087}
{"step": 703280, "time": 35146.026880025864, "episode/length": 71.0, "episode/score": 0.08874999813269824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08874999813269824}
{"step": 703336, "time": 35149.56181097031, "episode/length": 175.0, "episode/score": 0.1871257998773217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1871257998773217}
{"step": 703336, "time": 35149.56984496117, "episode/length": 204.0, "episode/score": 0.22098577467659197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22098577467659197}
{"step": 703504, "time": 35159.13968658447, "episode/length": 186.0, "episode/score": 0.211600571326926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.211600571326926}
{"step": 703536, "time": 35161.83701300621, "episode/length": 151.0, "episode/score": 0.15786918656522175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15786918656522175}
{"step": 703720, "time": 35170.104583740234, "episode/length": 202.0, "episode/score": 0.2319994728823076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2319994728823076}
{"step": 703792, "time": 35174.48150396347, "episode/length": 31.0, "episode/score": 0.03708333265967667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03708333265967667}
{"step": 704032, "time": 35184.95383524895, "episode/length": 229.0, "episode/score": 0.2348528046222782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2348528046222782}
{"step": 704600, "time": 35209.06944131851, "episode/length": 228.0, "episode/score": 0.25132344649773586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25132344649773586}
{"step": 704856, "time": 35220.20452785492, "episode/length": 196.0, "episode/score": 0.2214338516787393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2214338516787393}
{"step": 704912, "time": 35224.05888390541, "episode/length": 196.0, "episode/score": 0.21605059184366837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21605059184366837}
{"step": 704952, "time": 35226.9972987175, "episode/length": 180.0, "episode/score": 0.19525250789592974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19525250789592974}
{"step": 704960, "time": 35228.978167295456, "episode/length": 44.0, "episode/score": 0.05348214172408916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05348214172408916}
{"step": 705008, "time": 35232.29212784767, "episode/length": 208.0, "episode/score": 0.23318033405666938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23318033405666938}
{"step": 705248, "time": 35242.76575279236, "episode/length": 181.0, "episode/score": 0.20186548082710942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20186548082710942}
{"step": 705256, "time": 35244.406663417816, "episode/length": 191.0, "episode/score": 0.2017317292120424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2017317292120424}
{"step": 705448, "time": 35253.05587077141, "episode/length": 60.0, "episode/score": 0.06400869433855405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06400869433855405}
{"step": 706032, "time": 35276.474875211716, "episode/length": 146.0, "episode/score": 0.14456978124508169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14456978124508169}
{"step": 706056, "time": 35278.71777033806, "episode/length": 252.0, "episode/score": 0.2867646535814856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2867646535814856}
{"step": 706312, "time": 35289.876609802246, "episode/length": 169.0, "episode/score": 0.17813912868587067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17813912868587067}
{"step": 706608, "time": 35302.63247323036, "episode/length": 211.0, "episode/score": 0.2286428959487239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2286428959487239}
{"step": 706672, "time": 35306.583077669144, "episode/length": 177.0, "episode/score": 0.191078466226827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.191078466226827}
{"step": 706776, "time": 35311.78035187721, "episode/length": 165.0, "episode/score": 0.18634172454767395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18634172454767395}
{"step": 706880, "time": 35317.491596221924, "episode/length": 202.0, "episode/score": 0.202872105908682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.202872105908682}
{"step": 707145, "time": 35331.61666893959, "train_stats/sum_log_reward": 1.449056586707538, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.839622641509434, "train_stats/max_log_achievement_collect_sapling": 0.8490566037735849, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 0.9811320754716981, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.09433962264150944, "train_stats/max_log_achievement_eat_cow": 0.009433962264150943, "train_stats/max_log_achievement_make_wood_pickaxe": 0.018867924528301886, "train_stats/max_log_achievement_make_wood_sword": 0.018867924528301886, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.33962264150943394, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.14150943396226415, "train_stats/max_log_achievement_wake_up": 0.14150943396226415, "train_stats/mean_log_entropy": 2.0596296539846457, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.887355743892609, "train/action_min": 0.0, "train/action_std": 4.683511961074102, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008528795429608889, "train/actor_opt_grad_steps": 43475.0, "train/actor_opt_loss": -12.241771500380267, "train/adv_mag": 0.18100444304328117, "train/adv_max": 0.12790154890408592, "train/adv_mean": -9.223845906836643e-05, "train/adv_min": -0.18033027087175657, "train/adv_std": 0.013995397207696759, "train/cont_avg": 0.9948846726190477, "train/cont_loss_mean": 0.00020973615416322456, "train/cont_loss_std": 0.006488990859633785, "train/cont_neg_acc": 0.9892195775395348, "train/cont_neg_loss": 0.025724261178775954, "train/cont_pos_acc": 0.9999688603575267, "train/cont_pos_loss": 7.604737745847866e-05, "train/cont_pred": 0.9949079401909359, "train/cont_rate": 0.9948846726190477, "train/dyn_loss_mean": 11.232629276457287, "train/dyn_loss_std": 8.589829789267647, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1427611277867404, "train/extr_critic_critic_opt_grad_steps": 43475.0, "train/extr_critic_critic_opt_loss": 12116.146174355159, "train/extr_critic_mag": 0.2875871497487265, "train/extr_critic_max": 0.2875871497487265, "train/extr_critic_mean": 0.23438457565175164, "train/extr_critic_min": 0.001613450428796193, "train/extr_critic_std": 0.06142534995599398, "train/extr_return_normed_mag": 0.2143903271782966, "train/extr_return_normed_max": 0.2143903271782966, "train/extr_return_normed_mean": 0.1609065987997585, "train/extr_return_normed_min": -0.07238220423460007, "train/extr_return_normed_std": 0.06319783583638214, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2877760198381212, "train/extr_return_raw_max": 0.2877760198381212, "train/extr_return_raw_mean": 0.23429229559879455, "train/extr_return_raw_min": 0.001003487715645442, "train/extr_return_raw_std": 0.0631978361320401, "train/extr_reward_mag": 0.0012924746861533514, "train/extr_reward_max": 0.0012924746861533514, "train/extr_reward_mean": 0.0011008967569703975, "train/extr_reward_min": 1.1275685022747705e-05, "train/extr_reward_std": 0.00023987345660330786, "train/image_loss_mean": 5.0816458444746715, "train/image_loss_std": 10.214124214081536, "train/model_loss_mean": 11.861534519801063, "train/model_loss_std": 13.824790621560718, "train/model_opt_grad_norm": 52.53156634739467, "train/model_opt_grad_steps": 43433.84920634921, "train/model_opt_loss": 15875.770941840277, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1339.2857142857142, "train/policy_entropy_mag": 2.7624046745754423, "train/policy_entropy_max": 2.7624046745754423, "train/policy_entropy_mean": 2.005140507978106, "train/policy_entropy_min": 0.08025573152634832, "train/policy_entropy_std": 0.6323228544659085, "train/policy_logprob_mag": 7.438271053253659, "train/policy_logprob_max": -0.009578723948271502, "train/policy_logprob_mean": -2.004588736428155, "train/policy_logprob_min": -7.438271053253659, "train/policy_logprob_std": 1.2125985272346982, "train/policy_randomness_mag": 0.975007626745436, "train/policy_randomness_max": 0.975007626745436, "train/policy_randomness_mean": 0.7077265968398442, "train/policy_randomness_min": 0.028326751265142645, "train/policy_randomness_std": 0.22318221853365974, "train/post_ent_mag": 59.50912490723625, "train/post_ent_max": 59.50912490723625, "train/post_ent_mean": 42.032315087696865, "train/post_ent_min": 20.101956503731863, "train/post_ent_std": 7.226540482233441, "train/prior_ent_mag": 69.25680166577536, "train/prior_ent_max": 69.25680166577536, "train/prior_ent_mean": 53.35831960042318, "train/prior_ent_min": 34.26517080882239, "train/prior_ent_std": 5.288436083566575, "train/rep_loss_mean": 11.232629276457287, "train/rep_loss_std": 8.589829789267647, "train/reward_avg": 0.0010623787964014189, "train/reward_loss_mean": 0.040101493871401224, "train/reward_loss_std": 0.011300937516526097, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012724456332978747, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04010149357574327, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010633108996978356, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.537499980069697, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.125, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.1875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 0.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.7878027291735634e-05, "report/cont_loss_std": 0.0008439464145340025, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.451306838542223e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.814508404000662e-05, "report/cont_pred": 0.9950597286224365, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 10.969367027282715, "report/dyn_loss_std": 8.269862174987793, "report/image_loss_mean": 4.39235782623291, "report/image_loss_std": 9.241781234741211, "report/model_loss_mean": 11.014142990112305, "report/model_loss_std": 12.988646507263184, "report/post_ent_mag": 62.90697479248047, "report/post_ent_max": 62.90697479248047, "report/post_ent_mean": 42.163597106933594, "report/post_ent_min": 20.88955307006836, "report/post_ent_std": 7.284104824066162, "report/prior_ent_mag": 69.06587219238281, "report/prior_ent_max": 69.06587219238281, "report/prior_ent_mean": 53.42461395263672, "report/prior_ent_min": 37.04314422607422, "report/prior_ent_std": 5.322911262512207, "report/rep_loss_mean": 10.969367027282715, "report/rep_loss_std": 8.269862174987793, "report/reward_avg": 0.001062865136191249, "report/reward_loss_mean": 0.040107451379299164, "report/reward_loss_std": 0.011530108749866486, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013104677200317383, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.040107451379299164, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010737390257418156, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.7159326262117247e-06, "eval/cont_loss_std": 2.3120795958675444e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.151180979126366e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.7150808844235144e-06, "eval/cont_pred": 0.9980452060699463, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 14.571440696716309, "eval/dyn_loss_std": 9.97457504272461, "eval/image_loss_mean": 9.665823936462402, "eval/image_loss_std": 13.285765647888184, "eval/model_loss_mean": 18.73756980895996, "eval/model_loss_std": 17.55637550354004, "eval/post_ent_mag": 58.42970275878906, "eval/post_ent_max": 58.42970275878906, "eval/post_ent_mean": 41.67536926269531, "eval/post_ent_min": 20.915874481201172, "eval/post_ent_std": 6.9506402015686035, "eval/prior_ent_mag": 69.06587219238281, "eval/prior_ent_max": 69.06587219238281, "eval/prior_ent_mean": 53.89562225341797, "eval/prior_ent_min": 35.910255432128906, "eval/prior_ent_std": 5.095134258270264, "eval/rep_loss_mean": 14.571440696716309, "eval/rep_loss_std": 9.97457504272461, "eval/reward_avg": 0.004101562313735485, "eval/reward_loss_mean": 0.32887881994247437, "eval/reward_loss_std": 2.508033514022827, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013104677200317383, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.2083175778388977, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.784101486206055, "eval/reward_pred": 0.0010716135147958994, "eval/reward_rate": 0.005859375, "replay/size": 706641.0, "replay/inserts": 20144.0, "replay/samples": 20144.0, "replay/insert_wait_avg": 1.3409861503279901e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.76955303073971e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4336.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1453549360437146e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2619783878326, "timer/env.step_count": 2518.0, "timer/env.step_total": 228.71790838241577, "timer/env.step_frac": 0.22865800492691998, "timer/env.step_avg": 0.09083316456807616, "timer/env.step_min": 0.02226996421813965, "timer/env.step_max": 3.2755508422851562, "timer/replay._sample_count": 20144.0, "timer/replay._sample_total": 9.720321655273438, "timer/replay._sample_frac": 0.00971777580803393, "timer/replay._sample_avg": 0.0004825417819337489, "timer/replay._sample_min": 0.0003962516784667969, "timer/replay._sample_max": 0.010582685470581055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3060.0, "timer/agent.policy_total": 50.30418109893799, "timer/agent.policy_frac": 0.05029100594227875, "timer/agent.policy_avg": 0.016439274868933984, "timer/agent.policy_min": 0.009628772735595703, "timer/agent.policy_max": 0.12504792213439941, "timer/dataset_train_count": 1259.0, "timer/dataset_train_total": 0.13616228103637695, "timer/dataset_train_frac": 0.00013612661880424152, "timer/dataset_train_avg": 0.00010815113664525573, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0008902549743652344, "timer/agent.train_count": 1259.0, "timer/agent.train_total": 569.4182512760162, "timer/agent.train_frac": 0.569269115071007, "timer/agent.train_avg": 0.4522781979952472, "timer/agent.train_min": 0.4385099411010742, "timer/agent.train_max": 1.1500296592712402, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4809277057647705, "timer/agent.report_frac": 0.0004808017460984605, "timer/agent.report_avg": 0.24046385288238525, "timer/agent.report_min": 0.23345661163330078, "timer/agent.report_max": 0.24747109413146973, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.193450927734375e-05, "timer/dataset_eval_frac": 2.192876441499515e-08, "timer/dataset_eval_avg": 2.193450927734375e-05, "timer/dataset_eval_min": 2.193450927734375e-05, "timer/dataset_eval_max": 2.193450927734375e-05, "fps": 20.138483977366906}
{"step": 707504, "time": 35345.06350564957, "episode/length": 148.0, "episode/score": 0.1645449700736208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1645449700736208}
{"step": 707544, "time": 35347.90769505501, "episode/length": 108.0, "episode/score": 0.1300459036610846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1300459036610846}
{"step": 707672, "time": 35354.23253059387, "episode/length": 204.0, "episode/score": 0.23113461275897862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23113461275897862}
{"step": 708016, "time": 35368.787890672684, "episode/length": 175.0, "episode/score": 0.18975576595767052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18975576595767052}
{"step": 708072, "time": 35372.10461807251, "episode/length": 161.0, "episode/score": 0.17136199567175936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17136199567175936}
{"step": 708208, "time": 35379.0986123085, "episode/length": 165.0, "episode/score": 0.17690114246033772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17690114246033772}
{"step": 708320, "time": 35385.12178897858, "episode/length": 282.0, "episode/score": 0.3191431401337468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3191431401337468}
{"step": 708392, "time": 35388.991015672684, "episode/length": 422.0, "episode/score": 0.41865067307662684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41865067307662684}
{"step": 708784, "time": 35405.211361169815, "episode/length": 154.0, "episode/score": 0.16353567792066315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16353567792066315}
{"step": 708872, "time": 35409.92882633209, "episode/length": 170.0, "episode/score": 0.19567261551856063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19567261551856063}
{"step": 708952, "time": 35414.39005804062, "episode/length": 159.0, "episode/score": 0.17174715154396836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17174715154396836}
{"step": 709632, "time": 35441.60968732834, "episode/length": 154.0, "episode/score": 0.18077560615347466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18077560615347466}
{"step": 709880, "time": 35452.10199213028, "episode/length": 208.0, "episode/score": 0.2459820355870761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2459820355870761}
{"step": 709928, "time": 35455.373339653015, "episode/length": 231.0, "episode/score": 0.2577323608129518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2577323608129518}
{"step": 709928, "time": 35455.381138563156, "episode/length": 142.0, "episode/score": 0.166520830229274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.166520830229274}
{"step": 710008, "time": 35480.30833029747, "eval_episode/length": 131.0, "eval_episode/score": 1.100000023841858, "eval_episode/reward_rate": 0.9924242424242424}
{"step": 710008, "time": 35482.13454413414, "eval_episode/length": 140.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9645390070921985}
{"step": 710008, "time": 35484.93895983696, "eval_episode/length": 169.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 710008, "time": 35486.70781373978, "eval_episode/length": 174.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 710008, "time": 35488.279970645905, "eval_episode/length": 178.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 710008, "time": 35489.96939587593, "eval_episode/length": 183.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 710008, "time": 35492.667734622955, "eval_episode/length": 211.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 710008, "time": 35496.95475816727, "eval_episode/length": 276.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9963898916967509}
{"step": 710104, "time": 35500.578384399414, "episode/length": 222.0, "episode/score": 0.2239420674231951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2239420674231951}
{"step": 710120, "time": 35502.760848522186, "episode/length": 262.0, "episode/score": 0.28732610867882613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28732610867882613}
{"step": 710192, "time": 35507.38176560402, "episode/length": 164.0, "episode/score": 0.16552442517058807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16552442517058807}
{"step": 710464, "time": 35518.98688673973, "episode/length": 188.0, "episode/score": 0.20557706497129402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20557706497129402}
{"step": 710920, "time": 35538.43793272972, "episode/length": 160.0, "episode/score": 0.1762642089597648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1762642089597648}
{"step": 711120, "time": 35548.245008945465, "episode/length": 148.0, "episode/score": 0.1510734325311205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1510734325311205}
{"step": 711328, "time": 35558.18097567558, "episode/length": 150.0, "episode/score": 0.16561884712791652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16561884712791652}
{"step": 711336, "time": 35559.76119852066, "episode/length": 175.0, "episode/score": 0.19754618375736754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19754618375736754}
{"step": 711376, "time": 35562.957288980484, "episode/length": 147.0, "episode/score": 0.1652337073446688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1652337073446688}
{"step": 711520, "time": 35569.779795885086, "episode/length": 176.0, "episode/score": 0.2068630913636298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2068630913636298}
{"step": 711600, "time": 35574.19256567955, "episode/length": 214.0, "episode/score": 0.23517949929009774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23517949929009774}
{"step": 711672, "time": 35578.158066511154, "episode/length": 150.0, "episode/score": 0.16300038527333527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16300038527333527}
{"step": 712464, "time": 35609.71230983734, "episode/length": 140.0, "episode/score": 0.15500665017862048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15500665017862048}
{"step": 712648, "time": 35617.83453273773, "episode/length": 190.0, "episode/score": 0.20490738265834807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20490738265834807}
{"step": 712720, "time": 35623.77143788338, "episode/length": 149.0, "episode/score": 0.16954748265561648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16954748265561648}
{"step": 712808, "time": 35628.31463313103, "episode/length": 42.0, "episode/score": 0.048541665892116725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048541665892116725}
{"step": 712880, "time": 35632.6509706974, "episode/length": 187.0, "episode/score": 0.20405885528452927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20405885528452927}
{"step": 712896, "time": 35634.73731970787, "episode/length": 152.0, "episode/score": 0.17412648514255125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17412648514255125}
{"step": 712912, "time": 35636.92052102089, "episode/length": 163.0, "episode/score": 0.17246716827321507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17246716827321507}
{"step": 713296, "time": 35652.7761592865, "episode/length": 245.0, "episode/score": 0.2984166606911458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2984166606911458}
{"step": 713912, "time": 35676.99968910217, "episode/length": 148.0, "episode/score": 0.16520666158612585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16520666158612585}
{"step": 714104, "time": 35685.70275235176, "episode/length": 181.0, "episode/score": 0.1910462111391098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1910462111391098}
{"step": 714128, "time": 35688.25519609451, "episode/length": 155.0, "episode/score": 0.17000394355272874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17000394355272874}
{"step": 714144, "time": 35690.291465997696, "episode/length": 402.0, "episode/score": 0.3871903507333627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3871903507333627}
{"step": 714200, "time": 35693.71298742294, "episode/length": 162.0, "episode/score": 0.17580651934986236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17580651934986236}
{"step": 714472, "time": 35705.337535619736, "episode/length": 207.0, "episode/score": 0.2306024125446129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2306024125446129}
{"step": 714512, "time": 35708.705887556076, "episode/length": 199.0, "episode/score": 0.2215727850325493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2215727850325493}
{"step": 714760, "time": 35719.19866275787, "episode/length": 182.0, "episode/score": 0.21053119758653338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21053119758653338}
{"step": 714856, "time": 35724.21044874191, "episode/length": 90.0, "episode/score": 0.09770765808207216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09770765808207216}
{"step": 715384, "time": 35745.648413181305, "episode/length": 159.0, "episode/score": 0.1603765682593803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1603765682593803}
{"step": 715536, "time": 35753.076816082, "episode/length": 166.0, "episode/score": 0.1729444144766603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1729444144766603}
{"step": 715544, "time": 35754.66593718529, "episode/length": 174.0, "episode/score": 0.17961984173962264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17961984173962264}
{"step": 715552, "time": 35756.62851715088, "episode/length": 129.0, "episode/score": 0.1449963516661228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1449963516661228}
{"step": 715584, "time": 35759.2904753685, "episode/length": 208.0, "episode/score": 0.24006519557588035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24006519557588035}
{"step": 715864, "time": 35771.10651922226, "episode/length": 173.0, "episode/score": 0.17925530642969534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17925530642969534}
{"step": 716008, "time": 35777.97800731659, "episode/length": 155.0, "episode/score": 0.16138417202819255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16138417202819255}
{"step": 716048, "time": 35781.173696517944, "episode/length": 57.0, "episode/score": 0.06462850932257425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06462850932257425}
{"step": 716704, "time": 35807.27944636345, "episode/length": 164.0, "episode/score": 0.17931051734012726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17931051734012726}
{"step": 716776, "time": 35811.43687391281, "episode/length": 152.0, "episode/score": 0.1875446530229965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1875446530229965}
{"step": 716856, "time": 35815.87035822868, "episode/length": 249.0, "episode/score": 0.2983888491653488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2983888491653488}
{"step": 717016, "time": 35823.43280696869, "episode/length": 183.0, "episode/score": 0.20086208487009571, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20086208487009571}
{"step": 717056, "time": 35826.70334506035, "episode/length": 189.0, "episode/score": 0.21602356626863184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21602356626863184}
{"step": 717136, "time": 35831.449701309204, "episode/length": 158.0, "episode/score": 0.18016432875992905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18016432875992905}
{"step": 717376, "time": 35842.026415109634, "episode/length": 165.0, "episode/score": 0.1745452400555223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1745452400555223}
{"step": 717416, "time": 35844.92588353157, "episode/length": 175.0, "episode/score": 0.19765261891370756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19765261891370756}
{"step": 717872, "time": 35863.7601621151, "episode/length": 145.0, "episode/score": 0.17310416320106015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17310416320106015}
{"step": 718056, "time": 35872.01109623909, "episode/length": 159.0, "episode/score": 0.18212128677078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18212128677078}
{"step": 718200, "time": 35879.37301135063, "episode/length": 167.0, "episode/score": 0.18290816883381922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18290816883381922}
{"step": 718376, "time": 35887.584741830826, "episode/length": 154.0, "episode/score": 0.166342006996274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.166342006996274}
{"step": 718424, "time": 35890.801931619644, "episode/length": 175.0, "episode/score": 0.18345332083117682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18345332083117682}
{"step": 718536, "time": 35896.56478905678, "episode/length": 184.0, "episode/score": 0.20928890731011052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20928890731011052}
{"step": 718672, "time": 35903.977900505066, "episode/length": 156.0, "episode/score": 0.15760765918821562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15760765918821562}
{"step": 718904, "time": 35913.9266500473, "episode/length": 45.0, "episode/score": 0.05092196886835154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05092196886835154}
{"step": 719024, "time": 35920.2926697731, "episode/length": 205.0, "episode/score": 0.23187588555447292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23187588555447292}
{"step": 719120, "time": 35925.33799958229, "episode/length": 155.0, "episode/score": 0.17905688777682371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17905688777682371}
{"step": 719736, "time": 35949.91890192032, "episode/length": 163.0, "episode/score": 0.1712628876994131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1712628876994131}
{"step": 720096, "time": 35984.08425092697, "eval_episode/length": 159.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.99375}
{"step": 720096, "time": 35985.76402926445, "eval_episode/length": 163.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 720096, "time": 35987.529554605484, "eval_episode/length": 170.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 720096, "time": 35989.17132854462, "eval_episode/length": 173.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 720096, "time": 35990.74002242088, "eval_episode/length": 174.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 720096, "time": 35994.583802461624, "eval_episode/length": 230.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 720096, "time": 35996.43021059036, "eval_episode/length": 237.0, "eval_episode/score": 1.1000000163912773, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 720096, "time": 35998.85092544556, "eval_episode/length": 259.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9961538461538462}
{"step": 720272, "time": 36005.43209052086, "episode/length": 258.0, "episode/score": 0.30945832724682987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30945832724682987}
{"step": 720296, "time": 36007.79243397713, "episode/length": 279.0, "episode/score": 0.3165189340506913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3165189340506913}
{"step": 720352, "time": 36011.6062142849, "episode/length": 180.0, "episode/score": 0.1780687693390064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1780687693390064}
{"step": 720416, "time": 36015.45666718483, "episode/length": 217.0, "episode/score": 0.22581449839344714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22581449839344714}
{"step": 720904, "time": 36035.60747265816, "episode/length": 68.0, "episode/score": 0.0793153831109521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0793153831109521}
{"step": 720928, "time": 36039.414310216904, "episode/length": 237.0, "episode/score": 0.2637115006618842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2637115006618842}
{"step": 721024, "time": 36044.54103112221, "episode/length": 237.0, "episode/score": 0.2801816604223859, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2801816604223859}
{"step": 721248, "time": 36054.53629231453, "episode/length": 188.0, "episode/score": 0.19937302498146892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19937302498146892}
{"step": 721608, "time": 36069.217832803726, "episode/length": 163.0, "episode/score": 0.1762939315958647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1762939315958647}
{"step": 721656, "time": 36072.57559275627, "episode/length": 154.0, "episode/score": 0.16400211131076503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16400211131076503}
{"step": 721848, "time": 36081.665714263916, "episode/length": 433.0, "episode/score": 0.47788108714121336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.47788108714121336}
{"step": 722184, "time": 36096.024030685425, "episode/length": 159.0, "episode/score": 0.16029133010306396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16029133010306396}
{"step": 722280, "time": 36101.36622428894, "episode/length": 156.0, "episode/score": 0.17776441411660926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17776441411660926}
{"step": 722424, "time": 36108.34415411949, "episode/length": 186.0, "episode/score": 0.2091762727650348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2091762727650348}
{"step": 722720, "time": 36121.09186053276, "episode/length": 183.0, "episode/score": 0.2046292254835862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2046292254835862}
{"step": 723056, "time": 36135.130113363266, "episode/length": 174.0, "episode/score": 0.1817960456937726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1817960456937726}
{"step": 723184, "time": 36141.45454096794, "episode/length": 196.0, "episode/score": 0.20502294164543855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20502294164543855}
{"step": 723344, "time": 36148.91423177719, "episode/length": 186.0, "episode/score": 0.19802416706079384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19802416706079384}
{"step": 723432, "time": 36153.38756632805, "episode/length": 394.0, "episode/score": 0.4339503765004338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4339503765004338}
{"step": 723448, "time": 36155.51373767853, "episode/length": 157.0, "episode/score": 0.1814924527934636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1814924527934636}
{"step": 723840, "time": 36172.0604429245, "episode/length": 139.0, "episode/score": 0.16735292857629247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16735292857629247}
{"step": 723872, "time": 36174.73283743858, "episode/length": 198.0, "episode/score": 0.22957737537944922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22957737537944922}
{"step": 724056, "time": 36182.89104056358, "episode/length": 203.0, "episode/score": 0.21542922759908834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21542922759908834}
{"step": 724384, "time": 36196.695397138596, "episode/length": 165.0, "episode/score": 0.18401860491030675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18401860491030675}
{"step": 724688, "time": 36209.567368745804, "episode/length": 167.0, "episode/score": 0.1765702354887253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1765702354887253}
{"step": 724872, "time": 36217.82697200775, "episode/length": 179.0, "episode/score": 0.19963737032685458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19963737032685458}
{"step": 724936, "time": 36221.6528878212, "episode/length": 185.0, "episode/score": 0.1865034508100507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1865034508100507}
{"step": 724984, "time": 36224.936438560486, "episode/length": 224.0, "episode/score": 0.2567613049186548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2567613049186548}
{"step": 725440, "time": 36243.766533613205, "episode/length": 195.0, "episode/score": 0.21869798305579025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21869798305579025}
{"step": 725608, "time": 36251.426709890366, "episode/length": 193.0, "episode/score": 0.19181291250151844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19181291250151844}
{"step": 725896, "time": 36263.689709186554, "episode/length": 119.0, "episode/score": 0.1480654729239177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1480654729239177}
{"step": 725896, "time": 36263.697284936905, "episode/length": 150.0, "episode/score": 0.1657441142378957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1657441142378957}
{"step": 726248, "time": 36281.21534538269, "episode/length": 232.0, "episode/score": 0.2720839659059493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2720839659059493}
{"step": 726256, "time": 36283.148965120316, "episode/length": 301.0, "episode/score": 0.35287076528402395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35287076528402395}
{"step": 726320, "time": 36287.05026626587, "episode/length": 166.0, "episode/score": 0.16835532240384055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16835532240384055}
{"step": 726528, "time": 36296.4518225193, "episode/length": 206.0, "episode/score": 0.22331025754556322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22331025754556322}
{"step": 726824, "time": 36308.79592418671, "episode/length": 151.0, "episode/score": 0.17117011661594006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17117011661594006}
{"step": 727321, "time": 36329.763019800186, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.035049196273562, "train/action_min": 0.0, "train/action_std": 4.79282974439954, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008144080154745588, "train/actor_opt_grad_steps": 44735.0, "train/actor_opt_loss": -12.320972220096294, "train/adv_mag": 0.17466751551107754, "train/adv_max": 0.12408509194141343, "train/adv_mean": -0.00010669000075794762, "train/adv_min": -0.17400191056113395, "train/adv_std": 0.013646691002779536, "train/cont_avg": 0.9949466765873016, "train/cont_loss_mean": 0.00012011031314683253, "train/cont_loss_std": 0.0036497244358974245, "train/cont_neg_acc": 0.993584656526172, "train/cont_neg_loss": 0.021678962620383695, "train/cont_pos_acc": 0.9999999791856796, "train/cont_pos_loss": 2.5324651488463115e-05, "train/cont_pred": 0.9949656710738227, "train/cont_rate": 0.9949466765873016, "train/dyn_loss_mean": 11.137946181827122, "train/dyn_loss_std": 8.62304821468535, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13373223035818055, "train/extr_critic_critic_opt_grad_steps": 44735.0, "train/extr_critic_critic_opt_loss": 12089.791961185516, "train/extr_critic_mag": 0.28652340173721313, "train/extr_critic_max": 0.28652340173721313, "train/extr_critic_mean": 0.2318879138855707, "train/extr_critic_min": 0.0014182679236881316, "train/extr_critic_std": 0.06315868785457006, "train/extr_return_normed_mag": 0.21322243696167356, "train/extr_return_normed_max": 0.21322243696167356, "train/extr_return_normed_mean": 0.15870446108636402, "train/extr_return_normed_min": -0.07202423792628068, "train/extr_return_normed_std": 0.06478564701383076, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2862991447013522, "train/extr_return_raw_max": 0.2862991447013522, "train/extr_return_raw_mean": 0.23178117095477999, "train/extr_return_raw_min": 0.0010524694881741963, "train/extr_return_raw_std": 0.06478564713209395, "train/extr_reward_mag": 0.0013141187410505991, "train/extr_reward_max": 0.0013141187410505991, "train/extr_reward_mean": 0.001098955469575548, "train/extr_reward_min": 1.1419493054586744e-05, "train/extr_reward_std": 0.00024249386016948386, "train/image_loss_mean": 5.005611904083737, "train/image_loss_std": 10.158399998195588, "train/model_loss_mean": 11.728636332920619, "train/model_loss_std": 13.757945212106856, "train/model_opt_grad_norm": 52.897996145581445, "train/model_opt_grad_steps": 44692.69841269841, "train/model_opt_loss": 15483.470757378473, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1319.4444444444443, "train/policy_entropy_mag": 2.761150590957157, "train/policy_entropy_max": 2.761150590957157, "train/policy_entropy_mean": 2.0360487614359175, "train/policy_entropy_min": 0.0798542888036796, "train/policy_entropy_std": 0.6221294012807664, "train/policy_logprob_mag": 7.4383284364427835, "train/policy_logprob_max": -0.009522475494397066, "train/policy_logprob_mean": -2.0350078268656655, "train/policy_logprob_min": -7.4383284364427835, "train/policy_logprob_std": 1.1889545671523563, "train/policy_randomness_mag": 0.9745649889348045, "train/policy_randomness_max": 0.9745649889348045, "train/policy_randomness_mean": 0.7186358670393626, "train/policy_randomness_min": 0.028185059612114278, "train/policy_randomness_std": 0.21958437822167837, "train/post_ent_mag": 59.65671932886517, "train/post_ent_max": 59.65671932886517, "train/post_ent_mean": 42.20275140187097, "train/post_ent_min": 20.017287133231996, "train/post_ent_std": 7.265374225283426, "train/prior_ent_mag": 69.33569511534675, "train/prior_ent_max": 69.33569511534675, "train/prior_ent_mean": 53.39836172073606, "train/prior_ent_min": 34.584537702893456, "train/prior_ent_std": 5.330848073202466, "train/rep_loss_mean": 11.137946181827122, "train/rep_loss_std": 8.62304821468535, "train/reward_avg": 0.0010633735690221545, "train/reward_loss_mean": 0.04013670708925005, "train/reward_loss_std": 0.011239005400547905, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012754372188023158, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04013670714838164, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010635425809711692, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.4148147873994377, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.611111111111111, "train_stats/max_log_achievement_collect_sapling": 0.7777777777777778, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.0648148148148149, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.09259259259259259, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.018518518518518517, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.37037037037037035, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.10185185185185185, "train_stats/max_log_achievement_wake_up": 0.08333333333333333, "train_stats/mean_log_entropy": 2.0485065711869135, "eval_stats/sum_log_reward": 1.724999972153455, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 8.25, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.7359081539325416e-05, "report/cont_loss_std": 0.0004076975164934993, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.3790463476179866e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.744147994031664e-05, "report/cont_pred": 0.9941234588623047, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 10.153667449951172, "report/dyn_loss_std": 8.514613151550293, "report/image_loss_mean": 3.9877846240997314, "report/image_loss_std": 7.460662841796875, "report/model_loss_mean": 10.119356155395508, "report/model_loss_std": 10.9998197555542, "report/post_ent_mag": 62.575828552246094, "report/post_ent_max": 62.575828552246094, "report/post_ent_mean": 42.45924377441406, "report/post_ent_min": 20.746883392333984, "report/post_ent_std": 7.237211227416992, "report/prior_ent_mag": 69.0775375366211, "report/prior_ent_max": 69.0775375366211, "report/prior_ent_mean": 52.49231719970703, "report/prior_ent_min": 34.75867462158203, "report/prior_ent_std": 5.653627395629883, "report/rep_loss_mean": 10.153667449951172, "report/rep_loss_std": 8.514613151550293, "report/reward_avg": 0.001042307703755796, "report/reward_loss_mean": 0.03935341164469719, "report/reward_loss_std": 0.012644460424780846, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012853145599365234, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03935341164469719, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010593649931252003, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.097175860806601e-07, "eval/cont_loss_std": 5.574092028837185e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.999431333388202e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.050465349791921e-07, "eval/cont_pred": 0.9970699548721313, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.519594192504883, "eval/dyn_loss_std": 9.820907592773438, "eval/image_loss_mean": 11.840620040893555, "eval/image_loss_std": 15.909748077392578, "eval/model_loss_mean": 22.301204681396484, "eval/model_loss_std": 20.00211524963379, "eval/post_ent_mag": 57.63827896118164, "eval/post_ent_max": 57.63827896118164, "eval/post_ent_mean": 40.938751220703125, "eval/post_ent_min": 20.927597045898438, "eval/post_ent_std": 6.637160778045654, "eval/prior_ent_mag": 69.0775375366211, "eval/prior_ent_max": 69.0775375366211, "eval/prior_ent_mean": 54.62752151489258, "eval/prior_ent_min": 39.26625061035156, "eval/prior_ent_std": 4.803822040557861, "eval/rep_loss_mean": 16.519594192504883, "eval/rep_loss_std": 9.820907592773438, "eval/reward_avg": 0.00390625, "eval/reward_loss_mean": 0.5488281846046448, "eval/reward_loss_std": 3.2493903636932373, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012803077697753906, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.3883618414402008, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.928056716918945, "eval/reward_pred": 0.0010765891056507826, "eval/reward_rate": 0.0078125, "replay/size": 726817.0, "replay/inserts": 20176.0, "replay/samples": 20176.0, "replay/insert_wait_avg": 1.3299611331355847e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.789608602198602e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4296.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1409794152115977e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0111863613129, "timer/env.step_count": 2522.0, "timer/env.step_total": 234.1211359500885, "timer/env.step_frac": 0.23411851701576714, "timer/env.step_avg": 0.0928315368557052, "timer/env.step_min": 0.022316932678222656, "timer/env.step_max": 4.195162296295166, "timer/replay._sample_count": 20176.0, "timer/replay._sample_total": 9.743282079696655, "timer/replay._sample_frac": 0.009743173089042148, "timer/replay._sample_avg": 0.00048291445676529814, "timer/replay._sample_min": 0.0003705024719238281, "timer/replay._sample_max": 0.017856597900390625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3059.0, "timer/agent.policy_total": 48.88288640975952, "timer/agent.policy_frac": 0.048882339594247, "timer/agent.policy_avg": 0.01598002170963044, "timer/agent.policy_min": 0.009815216064453125, "timer/agent.policy_max": 0.09383082389831543, "timer/dataset_train_count": 1261.0, "timer/dataset_train_total": 0.1372363567352295, "timer/dataset_train_frac": 0.00013723482157693061, "timer/dataset_train_avg": 0.00010883136933800911, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0010933876037597656, "timer/agent.train_count": 1261.0, "timer/agent.train_total": 566.0318355560303, "timer/agent.train_frac": 0.5660255037902325, "timer/agent.train_avg": 0.44887536523079324, "timer/agent.train_min": 0.4362177848815918, "timer/agent.train_max": 0.9530959129333496, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48256349563598633, "timer/agent.report_frac": 0.0004825580975667525, "timer/agent.report_avg": 0.24128174781799316, "timer/agent.report_min": 0.23427414894104004, "timer/agent.report_max": 0.2482893466949463, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.678436279296875e-05, "timer/dataset_eval_frac": 8.678339200258985e-08, "timer/dataset_eval_avg": 8.678436279296875e-05, "timer/dataset_eval_min": 8.678436279296875e-05, "timer/dataset_eval_max": 8.678436279296875e-05, "fps": 20.175517857389117}
{"step": 727336, "time": 36329.92517161369, "episode/length": 236.0, "episode/score": 0.25135403945478174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25135403945478174}
{"step": 727488, "time": 36337.83842897415, "episode/length": 198.0, "episode/score": 0.23962270149604592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23962270149604592}
{"step": 727848, "time": 36352.536715745926, "episode/length": 190.0, "episode/score": 0.2130367086192564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2130367086192564}
{"step": 727856, "time": 36354.5415661335, "episode/length": 165.0, "episode/score": 0.17954600193206716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17954600193206716}
{"step": 727880, "time": 36356.6589679718, "episode/length": 203.0, "episode/score": 0.20488084800945217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20488084800945217}
{"step": 727896, "time": 36358.714755535126, "episode/length": 204.0, "episode/score": 0.22586277315713232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22586277315713232}
{"step": 728112, "time": 36368.63274860382, "episode/length": 276.0, "episode/score": 0.31886978109650954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31886978109650954}
{"step": 728296, "time": 36376.77454805374, "episode/length": 183.0, "episode/score": 0.20097708761477406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20097708761477406}
{"step": 728848, "time": 36399.07720708847, "episode/length": 188.0, "episode/score": 0.20255629655457597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20255629655457597}
{"step": 729328, "time": 36420.340965270996, "episode/length": 229.0, "episode/score": 0.2538273121317616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2538273121317616}
{"step": 729360, "time": 36422.93527126312, "episode/length": 182.0, "episode/score": 0.1781202449274133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1781202449274133}
{"step": 729432, "time": 36426.99731707573, "episode/length": 196.0, "episode/score": 0.20979407676077244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20979407676077244}
{"step": 729680, "time": 36437.84563732147, "episode/length": 172.0, "episode/score": 0.191125924734024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.191125924734024}
{"step": 729712, "time": 36440.542224407196, "episode/length": 228.0, "episode/score": 0.24005186364911424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24005186364911424}
{"step": 729856, "time": 36447.34429979324, "episode/length": 250.0, "episode/score": 0.28452847236940215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28452847236940215}
{"step": 730008, "time": 36454.32346367836, "episode/length": 144.0, "episode/score": 0.1540622439310937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1540622439310937}
{"step": 730080, "time": 36479.5023560524, "eval_episode/length": 156.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 730080, "time": 36481.447922706604, "eval_episode/length": 167.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 730080, "time": 36483.263072013855, "eval_episode/length": 176.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 730080, "time": 36484.8975212574, "eval_episode/length": 178.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.994413407821229}
{"step": 730080, "time": 36486.663361787796, "eval_episode/length": 183.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 730080, "time": 36488.89352059364, "eval_episode/length": 189.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 730080, "time": 36491.91459655762, "eval_episode/length": 211.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 730080, "time": 36494.8162791729, "eval_episode/length": 230.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 730248, "time": 36501.06559085846, "episode/length": 266.0, "episode/score": 0.3014539407063239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3014539407063239}
{"step": 730608, "time": 36516.697635650635, "episode/length": 159.0, "episode/score": 0.173791137677199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.173791137677199}
{"step": 730952, "time": 36531.18360209465, "episode/length": 198.0, "episode/score": 0.20910274558673336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20910274558673336}
{"step": 731168, "time": 36540.914011240005, "episode/length": 144.0, "episode/score": 0.16233615404053126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16233615404053126}
{"step": 731240, "time": 36545.027055978775, "episode/length": 225.0, "episode/score": 0.2473793111539635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2473793111539635}
{"step": 731272, "time": 36547.839524030685, "episode/length": 194.0, "episode/score": 0.2156755296018673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2156755296018673}
{"step": 731464, "time": 36556.44867491722, "episode/length": 151.0, "episode/score": 0.1610847391129937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1610847391129937}
{"step": 731560, "time": 36561.5581099987, "episode/length": 234.0, "episode/score": 0.2717179181913707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2717179181913707}
{"step": 731608, "time": 36564.89476323128, "episode/length": 218.0, "episode/score": 0.2561944398912601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2561944398912601}
{"step": 732184, "time": 36587.944870471954, "episode/length": 153.0, "episode/score": 0.17314939118659822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17314939118659822}
{"step": 732240, "time": 36591.78535747528, "episode/length": 203.0, "episode/score": 0.21760806906968355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21760806906968355}
{"step": 732480, "time": 36602.187685251236, "episode/length": 150.0, "episode/score": 0.1644763649564993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1644763649564993}
{"step": 732552, "time": 36606.18163752556, "episode/length": 163.0, "episode/score": 0.17765252808021614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17765252808021614}
{"step": 732696, "time": 36613.13892388344, "episode/length": 153.0, "episode/score": 0.17044117964906036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17044117964906036}
{"step": 732904, "time": 36622.44512343407, "episode/length": 167.0, "episode/score": 0.159579757211759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.159579757211759}
{"step": 733464, "time": 36645.010798215866, "episode/length": 152.0, "episode/score": 0.16838672059384407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16838672059384407}
{"step": 733632, "time": 36653.02519583702, "episode/length": 180.0, "episode/score": 0.201560803448956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.201560803448956}
{"step": 733784, "time": 36660.05503940582, "episode/length": 162.0, "episode/score": 0.17368112013900827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17368112013900827}
{"step": 733944, "time": 36667.5829846859, "episode/length": 173.0, "episode/score": 0.20309627319329593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20309627319329593}
{"step": 734024, "time": 36672.12222790718, "episode/length": 139.0, "episode/score": 0.1677513076501782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1677513076501782}
{"step": 734184, "time": 36679.61418390274, "episode/length": 185.0, "episode/score": 0.2164959156725672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2164959156725672}
{"step": 734448, "time": 36691.35346317291, "episode/length": 409.0, "episode/score": 0.42340084274292167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42340084274292167}
{"step": 734808, "time": 36706.1551527977, "episode/length": 167.0, "episode/score": 0.18680287492497882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18680287492497882}
{"step": 734928, "time": 36712.34339284897, "episode/length": 414.0, "episode/score": 0.46095183789475414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.46095183789475414}
{"step": 735248, "time": 36725.74643969536, "episode/length": 162.0, "episode/score": 0.1779216490995168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1779216490995168}
{"step": 735304, "time": 36729.18139219284, "episode/length": 189.0, "episode/score": 0.1977918605934974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1977918605934974}
{"step": 735512, "time": 36738.42393517494, "episode/length": 165.0, "episode/score": 0.18130923830722168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18130923830722168}
{"step": 735584, "time": 36742.85322642326, "episode/length": 243.0, "episode/score": 0.27018796736956574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27018796736956574}
{"step": 735664, "time": 36747.35448431969, "episode/length": 204.0, "episode/score": 0.2318958427222242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2318958427222242}
{"step": 736048, "time": 36763.1581325531, "episode/length": 199.0, "episode/score": 0.22407676026705303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22407676026705303}
{"step": 736216, "time": 36770.74076247215, "episode/length": 160.0, "episode/score": 0.18248006265275762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18248006265275762}
{"step": 736520, "time": 36783.54723381996, "episode/length": 158.0, "episode/score": 0.1716689936683906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1716689936683906}
{"step": 736672, "time": 36791.092015028, "episode/length": 144.0, "episode/score": 0.15016962825939117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15016962825939117}
{"step": 736696, "time": 36793.352766275406, "episode/length": 235.0, "episode/score": 0.2636591119990044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2636591119990044}
{"step": 736968, "time": 36804.87659573555, "episode/length": 172.0, "episode/score": 0.16854342994247418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16854342994247418}
{"step": 736968, "time": 36804.88445997238, "episode/length": 162.0, "episode/score": 0.16398748529536533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16398748529536533}
{"step": 737328, "time": 36823.181280612946, "episode/length": 159.0, "episode/score": 0.18613690145139117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18613690145139117}
{"step": 737504, "time": 36831.33037567139, "episode/length": 274.0, "episode/score": 0.313858430219625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.313858430219625}
{"step": 737744, "time": 36842.58523631096, "episode/length": 190.0, "episode/score": 0.20861242557293735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20861242557293735}
{"step": 737968, "time": 36852.58052635193, "episode/length": 180.0, "episode/score": 0.207055233846404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.207055233846404}
{"step": 737992, "time": 36854.85346579552, "episode/length": 164.0, "episode/score": 0.17078537696488638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17078537696488638}
{"step": 738512, "time": 36876.03098368645, "episode/length": 192.0, "episode/score": 0.22840448361239396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22840448361239396}
{"step": 738536, "time": 36878.410653591156, "episode/length": 195.0, "episode/score": 0.2294272555527641, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2294272555527641}
{"step": 738608, "time": 36882.8277759552, "episode/length": 159.0, "episode/score": 0.17639236077593523, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17639236077593523}
{"step": 738632, "time": 36885.03361392021, "episode/length": 241.0, "episode/score": 0.27059169396943616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27059169396943616}
{"step": 738704, "time": 36889.396069049835, "episode/length": 149.0, "episode/score": 0.15471376882942423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15471376882942423}
{"step": 738928, "time": 36899.332473516464, "episode/length": 147.0, "episode/score": 0.16412052789928566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16412052789928566}
{"step": 739288, "time": 36914.15032887459, "episode/length": 164.0, "episode/score": 0.1816263709915802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1816263709915802}
{"step": 739544, "time": 36925.22528219223, "episode/length": 193.0, "episode/score": 0.2282276343112244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2282276343112244}
{"step": 739792, "time": 36936.15983748436, "episode/length": 159.0, "episode/score": 0.16729548712373798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16729548712373798}
{"step": 740064, "time": 36966.32552957535, "eval_episode/length": 111.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9464285714285714}
{"step": 740064, "time": 36969.36438012123, "eval_episode/length": 145.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 740064, "time": 36971.188517808914, "eval_episode/length": 152.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 740064, "time": 36975.72964644432, "eval_episode/length": 222.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 740064, "time": 36975.73743605614, "eval_episode/length": 222.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 740064, "time": 36979.23404574394, "eval_episode/length": 225.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 740064, "time": 36981.583631038666, "eval_episode/length": 244.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 740064, "time": 36984.339565992355, "eval_episode/length": 160.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 740144, "time": 36987.31486940384, "episode/length": 191.0, "episode/score": 0.21785158929742465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21785158929742465}
{"step": 740176, "time": 36990.023062467575, "episode/length": 192.0, "episode/score": 0.20110571200257255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20110571200257255}
{"step": 740216, "time": 36992.75178551674, "episode/length": 160.0, "episode/score": 0.1715172009462549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1715172009462549}
{"step": 740264, "time": 36996.04476809502, "episode/length": 194.0, "episode/score": 0.20577972642695386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20577972642695386}
{"step": 740400, "time": 37002.919090509415, "episode/length": 232.0, "episode/score": 0.2655875200034643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2655875200034643}
{"step": 740608, "time": 37012.215703725815, "episode/length": 164.0, "episode/score": 0.1745941194376428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1745941194376428}
{"step": 741136, "time": 37033.54932117462, "episode/length": 198.0, "episode/score": 0.22465591965465137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22465591965465137}
{"step": 741456, "time": 37047.0126645565, "episode/length": 207.0, "episode/score": 0.21354345188956358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21354345188956358}
{"step": 741560, "time": 37052.20832705498, "episode/length": 161.0, "episode/score": 0.1746208806598588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1746208806598588}
{"step": 741608, "time": 37055.48248171806, "episode/length": 150.0, "episode/score": 0.1747578094500568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1747578094500568}
{"step": 741720, "time": 37061.24431228638, "episode/length": 187.0, "episode/score": 0.20732158220926067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20732158220926067}
{"step": 741776, "time": 37065.125334739685, "episode/length": 199.0, "episode/score": 0.20622282857038954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20622282857038954}
{"step": 741824, "time": 37068.469876527786, "episode/length": 151.0, "episode/score": 0.15511017066910426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15511017066910426}
{"step": 742072, "time": 37078.93466234207, "episode/length": 240.0, "episode/score": 0.28219697440454183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28219697440454183}
{"step": 742736, "time": 37105.37842440605, "episode/length": 159.0, "episode/score": 0.17040859957160137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17040859957160137}
{"step": 742976, "time": 37115.75270652771, "episode/length": 143.0, "episode/score": 0.16590098633059824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16590098633059824}
{"step": 742984, "time": 37117.3738360405, "episode/length": 177.0, "episode/score": 0.21126453190754546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21126453190754546}
{"step": 743016, "time": 37120.09905195236, "episode/length": 154.0, "episode/score": 0.17317023662235442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17317023662235442}
{"step": 743104, "time": 37125.14733552933, "episode/length": 172.0, "episode/score": 0.203362046123857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.203362046123857}
{"step": 743192, "time": 37129.69628572464, "episode/length": 139.0, "episode/score": 0.16060433894836024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16060433894836024}
{"step": 743368, "time": 37137.849966049194, "episode/length": 278.0, "episode/score": 0.32825353213456765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32825353213456765}
{"step": 743960, "time": 37161.99471259117, "episode/length": 293.0, "episode/score": 0.33336656185156244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33336656185156244}
{"step": 744256, "time": 37175.36456131935, "episode/length": 159.0, "episode/score": 0.1578365667246544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1578365667246544}
{"step": 744424, "time": 37182.98030304909, "episode/length": 175.0, "episode/score": 0.18747332760494828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18747332760494828}
{"step": 744448, "time": 37185.67326235771, "episode/length": 182.0, "episode/score": 0.20699184552631777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20699184552631777}
{"step": 744520, "time": 37189.59413719177, "episode/length": 176.0, "episode/score": 0.17806073468500472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17806073468500472}
{"step": 744528, "time": 37191.58364701271, "episode/length": 144.0, "episode/score": 0.15425063970224073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15425063970224073}
{"step": 744592, "time": 37195.61645936966, "episode/length": 174.0, "episode/score": 0.1985844171485951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1985844171485951}
{"step": 744816, "time": 37205.534694194794, "episode/length": 259.0, "episode/score": 0.28979029729271133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28979029729271133}
{"step": 745200, "time": 37222.07773756981, "episode/length": 154.0, "episode/score": 0.17162602432199492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17162602432199492}
{"step": 745256, "time": 37225.56291604042, "episode/length": 103.0, "episode/score": 0.10188822625786997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10188822625786997}
{"step": 745864, "time": 37251.017426252365, "episode/length": 158.0, "episode/score": 0.1675184050181997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1675184050181997}
{"step": 745912, "time": 37254.41504240036, "episode/length": 173.0, "episode/score": 0.19071725908725057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19071725908725057}
{"step": 745936, "time": 37256.98252391815, "episode/length": 209.0, "episode/score": 0.23037357304565376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23037357304565376}
{"step": 746000, "time": 37260.8478076458, "episode/length": 183.0, "episode/score": 0.19353089612559415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19353089612559415}
{"step": 746208, "time": 37270.226620435715, "episode/length": 219.0, "episode/score": 0.2524398403329542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2524398403329542}
{"step": 746376, "time": 37277.83220291138, "episode/length": 146.0, "episode/score": 0.16321711923592375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16321711923592375}
{"step": 746512, "time": 37284.63694524765, "episode/length": 63.0, "episode/score": 0.07714876100362744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07714876100362744}
{"step": 746648, "time": 37290.96705245972, "episode/length": 228.0, "episode/score": 0.24302779565186938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24302779565186938}
{"step": 747216, "time": 37313.86834001541, "episode/length": 162.0, "episode/score": 0.17240518796461402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17240518796461402}
{"step": 747216, "time": 37313.87648844719, "episode/length": 168.0, "episode/score": 0.17253195751618478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17253195751618478}
{"step": 747384, "time": 37323.081909656525, "episode/length": 146.0, "episode/score": 0.15580955314362654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15580955314362654}
{"step": 747392, "time": 37325.143479824066, "episode/length": 181.0, "episode/score": 0.19342245130610536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19342245130610536}
{"step": 747465, "time": 37330.172644138336, "train_stats/sum_log_reward": 1.7146788681045584, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.10091743119266, "train_stats/max_log_achievement_collect_sapling": 0.8715596330275229, "train_stats/max_log_achievement_collect_stone": 0.045871559633027525, "train_stats/max_log_achievement_collect_wood": 1.275229357798165, "train_stats/max_log_achievement_defeat_skeleton": 0.009174311926605505, "train_stats/max_log_achievement_defeat_zombie": 0.05504587155963303, "train_stats/max_log_achievement_eat_cow": 0.03669724770642202, "train_stats/max_log_achievement_make_wood_pickaxe": 0.027522935779816515, "train_stats/max_log_achievement_make_wood_sword": 0.009174311926605505, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.44036697247706424, "train_stats/max_log_achievement_place_stone": 0.01834862385321101, "train_stats/max_log_achievement_place_table": 0.21100917431192662, "train_stats/max_log_achievement_wake_up": 0.07339449541284404, "train_stats/mean_log_entropy": 2.09989529246584, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.086707705543155, "train/action_min": 0.0, "train/action_std": 4.794932967140561, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008072237066540217, "train/actor_opt_grad_steps": 45995.0, "train/actor_opt_loss": -9.244911412634547, "train/adv_mag": 0.17895213136124233, "train/adv_max": 0.13026974267429775, "train/adv_mean": 1.9344668075179457e-05, "train/adv_min": -0.17694204980655323, "train/adv_std": 0.013624570716822904, "train/cont_avg": 0.994566902281746, "train/cont_loss_mean": 0.00024009512108117784, "train/cont_loss_std": 0.0062160366555999765, "train/cont_neg_acc": 0.9947562369089278, "train/cont_neg_loss": 0.010921696604211342, "train/cont_pos_acc": 0.9999687633817158, "train/cont_pos_loss": 0.00017403653181640306, "train/cont_pred": 0.9945616523424784, "train/cont_rate": 0.994566902281746, "train/dyn_loss_mean": 11.043340001787458, "train/dyn_loss_std": 8.607247034708658, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14085817011812377, "train/extr_critic_critic_opt_grad_steps": 45995.0, "train/extr_critic_critic_opt_loss": 12126.825474330357, "train/extr_critic_mag": 0.2867608429893615, "train/extr_critic_max": 0.2867608429893615, "train/extr_critic_mean": 0.23343735625819553, "train/extr_critic_min": 0.0013909746730138386, "train/extr_critic_std": 0.06481949606585125, "train/extr_return_normed_mag": 0.21656055582894218, "train/extr_return_normed_max": 0.21656055582894218, "train/extr_return_normed_mean": 0.16383355323757445, "train/extr_return_normed_min": -0.06859454051369712, "train/extr_return_normed_std": 0.06644712160858843, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28618372905822026, "train/extr_return_raw_max": 0.28618372905822026, "train/extr_return_raw_mean": 0.2334567295416953, "train/extr_return_raw_min": 0.0010286333068968757, "train/extr_return_raw_std": 0.06644712140162785, "train/extr_reward_mag": 0.001292536183009072, "train/extr_reward_max": 0.001292536183009072, "train/extr_reward_mean": 0.0011021186170789103, "train/extr_reward_min": 1.104199697100927e-05, "train/extr_reward_std": 0.00024111941144967983, "train/image_loss_mean": 5.013615621460809, "train/image_loss_std": 10.055548667907715, "train/model_loss_mean": 11.680119469052268, "train/model_loss_std": 13.614596147385855, "train/model_opt_grad_norm": 51.61543387458438, "train/model_opt_grad_steps": 45951.62698412698, "train/model_opt_loss": 16494.252906436013, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1418.6507936507937, "train/policy_entropy_mag": 2.7608626134811884, "train/policy_entropy_max": 2.7608626134811884, "train/policy_entropy_mean": 2.063681997950115, "train/policy_entropy_min": 0.0801218067488027, "train/policy_entropy_std": 0.6069493300857998, "train/policy_logprob_mag": 7.438335403563484, "train/policy_logprob_max": -0.009558766296813412, "train/policy_logprob_mean": -2.0633220625302147, "train/policy_logprob_min": -7.438335403563484, "train/policy_logprob_std": 1.1706036613101052, "train/policy_randomness_mag": 0.9744633455125112, "train/policy_randomness_max": 0.9744633455125112, "train/policy_randomness_mean": 0.7283891813149528, "train/policy_randomness_min": 0.028279481751341668, "train/policy_randomness_std": 0.21422647826728367, "train/post_ent_mag": 59.42554625253829, "train/post_ent_max": 59.42554625253829, "train/post_ent_mean": 42.34561892918178, "train/post_ent_min": 19.989096051170712, "train/post_ent_std": 7.210330603614686, "train/prior_ent_mag": 69.39888587830559, "train/prior_ent_max": 69.39888587830559, "train/prior_ent_mean": 53.45526604425339, "train/prior_ent_min": 35.248663205949086, "train/prior_ent_std": 5.23301529127454, "train/rep_loss_mean": 11.043340001787458, "train/rep_loss_std": 8.607247034708658, "train/reward_avg": 0.00106738611874688, "train/reward_loss_mean": 0.04025978929111882, "train/reward_loss_std": 0.011208354842863859, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012711967740740096, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04025978955721098, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010672742667208826, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.3499999707564712, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.125, "eval_stats/max_log_achievement_collect_sapling": 0.6875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.3125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.1377645705579198e-06, "report/cont_loss_std": 2.2331103536998853e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001719961001072079, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3074108551336394e-07, "report/cont_pred": 0.9941415786743164, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 10.944862365722656, "report/dyn_loss_std": 8.402554512023926, "report/image_loss_mean": 4.551102161407471, "report/image_loss_std": 7.118396759033203, "report/model_loss_mean": 11.159530639648438, "report/model_loss_std": 10.480379104614258, "report/post_ent_mag": 60.884246826171875, "report/post_ent_max": 60.884246826171875, "report/post_ent_mean": 43.040740966796875, "report/post_ent_min": 19.22780418395996, "report/post_ent_std": 7.62225866317749, "report/prior_ent_mag": 68.69738006591797, "report/prior_ent_max": 68.69738006591797, "report/prior_ent_mean": 54.05897521972656, "report/prior_ent_min": 36.66808319091797, "report/prior_ent_std": 4.932012557983398, "report/rep_loss_mean": 10.944862365722656, "report/rep_loss_std": 8.402554512023926, "report/reward_avg": 0.001105571398511529, "report/reward_loss_mean": 0.04150936380028725, "report/reward_loss_std": 0.010347047820687294, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013104677200317383, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.041509367525577545, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0011007902212440968, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.1210132874548435e-05, "eval/cont_loss_std": 0.0009300481178797781, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.010266662575304508, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.135344405156502e-06, "eval/cont_pred": 0.9970988631248474, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.344381332397461, "eval/dyn_loss_std": 9.85755729675293, "eval/image_loss_mean": 8.187088012695312, "eval/image_loss_std": 14.881699562072754, "eval/model_loss_mean": 17.95172119140625, "eval/model_loss_std": 18.942062377929688, "eval/post_ent_mag": 57.84575653076172, "eval/post_ent_max": 57.84575653076172, "eval/post_ent_mean": 41.18243408203125, "eval/post_ent_min": 19.980043411254883, "eval/post_ent_std": 7.256041049957275, "eval/prior_ent_mag": 68.69738006591797, "eval/prior_ent_max": 68.69738006591797, "eval/prior_ent_mean": 54.4630126953125, "eval/prior_ent_min": 41.39796447753906, "eval/prior_ent_std": 4.72231388092041, "eval/rep_loss_mean": 15.344381332397461, "eval/rep_loss_std": 9.85755729675293, "eval/reward_avg": 0.007617187686264515, "eval/reward_loss_mean": 0.557974636554718, "eval/reward_loss_std": 3.268451452255249, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012508630752563477, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.33741500973701477, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.86951446533203, "eval/reward_pred": 0.001055756350979209, "eval/reward_rate": 0.0107421875, "replay/size": 746961.0, "replay/inserts": 20144.0, "replay/samples": 20144.0, "replay/insert_wait_avg": 1.3516737981103923e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.839975516127632e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4032.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1525929920257085e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.39404463768, "timer/env.step_count": 2518.0, "timer/env.step_total": 232.1376075744629, "timer/env.step_frac": 0.23204617102507627, "timer/env.step_avg": 0.09219126591519575, "timer/env.step_min": 0.02236199378967285, "timer/env.step_max": 3.183882474899292, "timer/replay._sample_count": 20144.0, "timer/replay._sample_total": 9.756551265716553, "timer/replay._sample_frac": 0.009752708263322533, "timer/replay._sample_avg": 0.0004843403130319973, "timer/replay._sample_min": 0.0003871917724609375, "timer/replay._sample_max": 0.009692668914794922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3022.0, "timer/agent.policy_total": 49.63221740722656, "timer/agent.policy_frac": 0.04961266780151837, "timer/agent.policy_avg": 0.016423632497427718, "timer/agent.policy_min": 0.009795665740966797, "timer/agent.policy_max": 0.12982845306396484, "timer/dataset_train_count": 1259.0, "timer/dataset_train_total": 0.13631367683410645, "timer/dataset_train_frac": 0.00013625998431795558, "timer/dataset_train_avg": 0.00010827138747744753, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0008020401000976562, "timer/agent.train_count": 1259.0, "timer/agent.train_total": 565.9610404968262, "timer/agent.train_frac": 0.5657381144265052, "timer/agent.train_avg": 0.4495322005534759, "timer/agent.train_min": 0.43809032440185547, "timer/agent.train_max": 1.0414180755615234, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48309803009033203, "timer/agent.report_frac": 0.0004829077428837545, "timer/agent.report_avg": 0.24154901504516602, "timer/agent.report_min": 0.2364521026611328, "timer/agent.report_max": 0.24664592742919922, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2173830253425944e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 20.13580564753968}
{"step": 747560, "time": 37333.6064786911, "episode/length": 287.0, "episode/score": 0.3220429711982433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3220429711982433}
{"step": 747752, "time": 37342.18511271477, "episode/length": 171.0, "episode/score": 0.1941764322018571, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1941764322018571}
{"step": 748216, "time": 37360.92733693123, "episode/length": 195.0, "episode/score": 0.2164719967840938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2164719967840938}
{"step": 748312, "time": 37366.57522702217, "episode/length": 224.0, "episode/score": 0.2646991369110765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2646991369110765}
{"step": 748536, "time": 37377.010442495346, "episode/length": 164.0, "episode/score": 0.14843192808802996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14843192808802996}
{"step": 748544, "time": 37379.034495830536, "episode/length": 165.0, "episode/score": 0.17588231393528986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17588231393528986}
{"step": 749024, "time": 37398.69034862518, "episode/length": 182.0, "episode/score": 0.1786452249998547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1786452249998547}
{"step": 749384, "time": 37413.36728620529, "episode/length": 249.0, "episode/score": 0.27331434738152893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27331434738152893}
{"step": 749456, "time": 37417.88474059105, "episode/length": 212.0, "episode/score": 0.22848813751079433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22848813751079433}
{"step": 749512, "time": 37421.328375816345, "episode/length": 264.0, "episode/score": 0.2996251185377332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2996251185377332}
{"step": 749720, "time": 37430.594069719315, "episode/length": 175.0, "episode/score": 0.18403380844210915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18403380844210915}
{"step": 749792, "time": 37435.0288131237, "episode/length": 156.0, "episode/score": 0.18401173443271546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18401173443271546}
{"step": 750000, "time": 37444.37632894516, "episode/length": 222.0, "episode/score": 0.24375523760136275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24375523760136275}
{"step": 750048, "time": 37466.629938840866, "eval_episode/length": 162.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 750048, "time": 37469.709787130356, "eval_episode/length": 186.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9625668449197861}
{"step": 750048, "time": 37471.37185740471, "eval_episode/length": 191.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 750048, "time": 37473.15679311752, "eval_episode/length": 198.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 750048, "time": 37474.72716522217, "eval_episode/length": 199.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.98}
{"step": 750048, "time": 37477.35111236572, "eval_episode/length": 221.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 750048, "time": 37479.84762811661, "eval_episode/length": 246.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.97165991902834}
{"step": 750048, "time": 37481.68227171898, "eval_episode/length": 254.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 750072, "time": 37482.35659098625, "episode/length": 190.0, "episode/score": 0.2016423673794634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2016423673794634}
{"step": 750224, "time": 37489.61875915527, "episode/length": 149.0, "episode/score": 0.16191747916400345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16191747916400345}
{"step": 750696, "time": 37508.437611579895, "episode/length": 147.0, "episode/score": 0.16253582964054658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16253582964054658}
{"step": 750744, "time": 37511.731963157654, "episode/length": 169.0, "episode/score": 0.18906355244143924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18906355244143924}
{"step": 750952, "time": 37521.0424323082, "episode/length": 153.0, "episode/score": 0.1669081603813538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1669081603813538}
{"step": 751048, "time": 37526.246376514435, "episode/length": 198.0, "episode/score": 0.22566815252594097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22566815252594097}
{"step": 751344, "time": 37539.01206612587, "episode/length": 193.0, "episode/score": 0.21941148579116998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21941148579116998}
{"step": 751784, "time": 37556.8277015686, "episode/length": 213.0, "episode/score": 0.23307436756476818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23307436756476818}
{"step": 752056, "time": 37568.709448337555, "episode/length": 256.0, "episode/score": 0.27549748511319194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27549748511319194}
{"step": 752136, "time": 37573.2426776886, "episode/length": 135.0, "episode/score": 0.15180953762683203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15180953762683203}
{"step": 752176, "time": 37576.456364393234, "episode/length": 184.0, "episode/score": 0.2031715597740913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2031715597740913}
{"step": 752200, "time": 37578.654753923416, "episode/length": 155.0, "episode/score": 0.15237070962393773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15237070962393773}
{"step": 752496, "time": 37591.73483610153, "episode/length": 218.0, "episode/score": 0.24339645615327754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24339645615327754}
{"step": 752656, "time": 37599.25213932991, "episode/length": 163.0, "episode/score": 0.17011911901317944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17011911901317944}
{"step": 752720, "time": 37603.07942485809, "episode/length": 311.0, "episode/score": 0.3364066815965998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3364066815965998}
{"step": 753568, "time": 37636.259528398514, "episode/length": 222.0, "episode/score": 0.24318614028106822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24318614028106822}
{"step": 753640, "time": 37640.33839249611, "episode/length": 142.0, "episode/score": 0.16202856947347755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16202856947347755}
{"step": 753824, "time": 37650.55843377113, "episode/length": 210.0, "episode/score": 0.23513042479407886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23513042479407886}
{"step": 753896, "time": 37654.57663011551, "episode/length": 154.0, "episode/score": 0.1633494602601786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1633494602601786}
{"step": 753992, "time": 37659.82231211662, "episode/length": 52.0, "episode/score": 0.062374998873565346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062374998873565346}
{"step": 754040, "time": 37663.134736299515, "episode/length": 229.0, "episode/score": 0.25911578929753887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25911578929753887}
{"step": 754352, "time": 37676.562489271164, "episode/length": 286.0, "episode/score": 0.32391226197250944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32391226197250944}
{"step": 754928, "time": 37699.70769047737, "episode/length": 343.0, "episode/score": 0.37928263916273863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.37928263916273863}
{"step": 755144, "time": 37709.013303518295, "episode/length": 155.0, "episode/score": 0.18030846606416162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18030846606416162}
{"step": 755152, "time": 37711.11696791649, "episode/length": 165.0, "episode/score": 0.1837430528103141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1837430528103141}
{"step": 755680, "time": 37732.42815494537, "episode/length": 204.0, "episode/score": 0.2329808729045908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2329808729045908}
{"step": 755688, "time": 37734.17584991455, "episode/length": 166.0, "episode/score": 0.1786561662738677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1786561662738677}
{"step": 755968, "time": 37746.64257359505, "episode/length": 246.0, "episode/score": 0.2813429956586333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2813429956586333}
{"step": 756008, "time": 37749.6051363945, "episode/length": 295.0, "episode/score": 0.33093163229932543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33093163229932543}
{"step": 756016, "time": 37751.67729949951, "episode/length": 411.0, "episode/score": 0.4328632540364197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4328632540364197}
{"step": 756160, "time": 37758.56046938896, "episode/length": 126.0, "episode/score": 0.14773085158594768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14773085158594768}
{"step": 756224, "time": 37762.41650891304, "episode/length": 161.0, "episode/score": 0.17658642789683654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17658642789683654}
{"step": 756256, "time": 37765.13580918312, "episode/length": 71.0, "episode/score": 0.08262121069856221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08262121069856221}
{"step": 756488, "time": 37775.037971019745, "episode/length": 40.0, "episode/score": 0.048541665775701404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048541665775701404}
{"step": 756560, "time": 37779.60447502136, "episode/length": 175.0, "episode/score": 0.18294760228673113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18294760228673113}
{"step": 757064, "time": 37799.56034708023, "episode/length": 171.0, "episode/score": 0.1902349323790986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1902349323790986}
{"step": 757320, "time": 37811.331892728806, "episode/length": 163.0, "episode/score": 0.17661340063932585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17661340063932585}
{"step": 757352, "time": 37814.002962350845, "episode/length": 172.0, "episode/score": 0.20214533093894715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20214533093894715}
{"step": 757360, "time": 37815.95685458183, "episode/length": 167.0, "episode/score": 0.1776733654569398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1776733654569398}
{"step": 757928, "time": 37838.80659890175, "episode/length": 170.0, "episode/score": 0.17578798883550917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17578798883550917}
{"step": 758232, "time": 37851.76898384094, "episode/length": 246.0, "episode/score": 0.2772822970091511, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2772822970091511}
{"step": 758464, "time": 37862.15286850929, "episode/length": 174.0, "episode/score": 0.18719214833436126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18719214833436126}
{"step": 758688, "time": 37872.155109643936, "episode/length": 166.0, "episode/score": 0.16717866596445674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16717866596445674}
{"step": 758808, "time": 37877.828053474426, "episode/length": 289.0, "episode/score": 0.3142963366390177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3142963366390177}
{"step": 758848, "time": 37881.09430503845, "episode/length": 190.0, "episode/score": 0.19395405061004567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19395405061004567}
{"step": 759120, "time": 37892.683282375336, "episode/length": 148.0, "episode/score": 0.15011873874391313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15011873874391313}
{"step": 759176, "time": 37896.051100730896, "episode/length": 368.0, "episode/score": 0.4148778279486578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4148778279486578}
{"step": 759504, "time": 37910.08802461624, "episode/length": 267.0, "episode/score": 0.291315222850244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.291315222850244}
{"step": 759704, "time": 37918.794915914536, "episode/length": 183.0, "episode/score": 0.21995832899119705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21995832899119705}
{"step": 759872, "time": 37926.887211322784, "episode/length": 147.0, "episode/score": 0.163787178928942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.163787178928942}
{"step": 759968, "time": 37932.01815390587, "episode/length": 144.0, "episode/score": 0.1465062196857616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1465062196857616}
{"step": 760032, "time": 37953.21600198746, "eval_episode/length": 121.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 760032, "time": 37956.134551763535, "eval_episode/length": 156.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 760032, "time": 37958.06470298767, "eval_episode/length": 162.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 760032, "time": 37959.78523015976, "eval_episode/length": 168.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 760032, "time": 37961.26875805855, "eval_episode/length": 169.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 760032, "time": 37963.862839221954, "eval_episode/length": 193.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 760032, "time": 37965.942081213, "eval_episode/length": 207.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9711538461538461}
{"step": 760032, "time": 37968.05331850052, "eval_episode/length": 220.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.995475113122172}
{"step": 760096, "time": 37970.43146562576, "episode/length": 155.0, "episode/score": 0.17093909150116815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17093909150116815}
{"step": 760280, "time": 37978.56423020363, "episode/length": 226.0, "episode/score": 0.256757141867638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.256757141867638}
{"step": 760320, "time": 37981.71611237526, "episode/length": 142.0, "episode/score": 0.1651420670823427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1651420670823427}
{"step": 760952, "time": 38006.62970376015, "episode/length": 180.0, "episode/score": 0.18309844951818377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18309844951818377}
{"step": 761120, "time": 38014.63206863403, "episode/length": 176.0, "episode/score": 0.199560982924595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.199560982924595}
{"step": 761200, "time": 38019.344945430756, "episode/length": 259.0, "episode/score": 0.28676012066534895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28676012066534895}
{"step": 761544, "time": 38033.43014860153, "episode/length": 42.0, "episode/score": 0.0464772720442852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0464772720442852}
{"step": 761704, "time": 38040.88766002655, "episode/length": 177.0, "episode/score": 0.1945579417879344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1945579417879344}
{"step": 761752, "time": 38044.17091798782, "episode/length": 178.0, "episode/score": 0.17230802676021995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17230802676021995}
{"step": 761760, "time": 38046.24694275856, "episode/length": 207.0, "episode/score": 0.23112607853545342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23112607853545342}
{"step": 762032, "time": 38059.61231660843, "episode/length": 269.0, "episode/score": 0.3176795758545268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3176795758545268}
{"step": 762208, "time": 38067.77974534035, "episode/length": 279.0, "episode/score": 0.33296345924100024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33296345924100024}
{"step": 762272, "time": 38071.82769656181, "episode/length": 70.0, "episode/score": 0.07743965295412636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07743965295412636}
{"step": 762352, "time": 38076.34905052185, "episode/length": 174.0, "episode/score": 0.1907941965464488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1907941965464488}
{"step": 762360, "time": 38078.001557826996, "episode/length": 154.0, "episode/score": 0.161086398844418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.161086398844418}
{"step": 763136, "time": 38109.1964161396, "episode/length": 171.0, "episode/score": 0.18668617196090054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18668617196090054}
{"step": 763248, "time": 38114.91166687012, "episode/length": 151.0, "episode/score": 0.16861626719946798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16861626719946798}
{"step": 763304, "time": 38118.30177760124, "episode/length": 193.0, "episode/score": 0.1973412882634875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1973412882634875}
{"step": 763400, "time": 38123.39394068718, "episode/length": 231.0, "episode/score": 0.26218612057800783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26218612057800783}
{"step": 763720, "time": 38136.89168572426, "episode/length": 180.0, "episode/score": 0.20281354308190203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20281354308190203}
{"step": 763776, "time": 38140.71705412865, "episode/length": 177.0, "episode/score": 0.2018072014889185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2018072014889185}
{"step": 763832, "time": 38144.12169337273, "episode/length": 202.0, "episode/score": 0.23677380519802682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23677380519802682}
{"step": 764352, "time": 38165.279802799225, "episode/length": 151.0, "episode/score": 0.166087459987466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.166087459987466}
{"step": 764624, "time": 38177.05435466766, "episode/length": 171.0, "episode/score": 0.187641642062772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.187641642062772}
{"step": 764912, "time": 38189.29665565491, "episode/length": 188.0, "episode/score": 0.21805344164022245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21805344164022245}
{"step": 765072, "time": 38196.899136304855, "episode/length": 154.0, "episode/score": 0.1483868392651857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1483868392651857}
{"step": 765136, "time": 38200.75906538963, "episode/length": 228.0, "episode/score": 0.2584136763789502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2584136763789502}
{"step": 765176, "time": 38203.5793941021, "episode/length": 181.0, "episode/score": 0.2062252561599962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2062252561599962}
{"step": 765296, "time": 38209.75114440918, "episode/length": 189.0, "episode/score": 0.2107911880239044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2107911880239044}
{"step": 765600, "time": 38222.538532972336, "episode/length": 155.0, "episode/score": 0.18294070174761146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18294070174761146}
{"step": 765632, "time": 38225.31600403786, "episode/length": 408.0, "episode/score": 0.43625276318607575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.43625276318607575}
{"step": 765960, "time": 38238.94976091385, "episode/length": 166.0, "episode/score": 0.1876670888323133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1876670888323133}
{"step": 766360, "time": 38255.43466424942, "episode/length": 152.0, "episode/score": 0.18002914618136856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18002914618136856}
{"step": 766504, "time": 38262.391503572464, "episode/length": 198.0, "episode/score": 0.2070809951615047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2070809951615047}
{"step": 766536, "time": 38265.26818943024, "episode/length": 182.0, "episode/score": 0.19739036347436922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19739036347436922}
{"step": 766736, "time": 38275.22470521927, "episode/length": 194.0, "episode/score": 0.20819076000998393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20819076000998393}
{"step": 766752, "time": 38277.28187274933, "episode/length": 181.0, "episode/score": 0.19810720113355273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19810720113355273}
{"step": 766936, "time": 38285.45851111412, "episode/length": 162.0, "episode/score": 0.17682482088503093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17682482088503093}
{"step": 767136, "time": 38294.76160168648, "episode/length": 191.0, "episode/score": 0.20756558127550306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20756558127550306}
{"step": 767408, "time": 38306.33525586128, "episode/length": 180.0, "episode/score": 0.1974268279741409, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1974268279741409}
{"step": 767488, "time": 38310.900713443756, "episode/length": 43.0, "episode/score": 0.049524349691637326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049524349691637326}
{"step": 767864, "time": 38326.31253743172, "episode/length": 169.0, "episode/score": 0.19596322005008915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19596322005008915}
{"step": 767896, "time": 38329.558867931366, "episode/length": 144.0, "episode/score": 0.15142778838344384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15142778838344384}
{"step": 767897, "time": 38332.6339507103, "train_stats/sum_log_reward": 1.9130840772919566, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.373831775700935, "train_stats/max_log_achievement_collect_sapling": 0.9065420560747663, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.5233644859813085, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.07476635514018691, "train_stats/max_log_achievement_eat_cow": 0.018691588785046728, "train_stats/max_log_achievement_make_wood_pickaxe": 0.018691588785046728, "train_stats/max_log_achievement_make_wood_sword": 0.037383177570093455, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.5046728971962616, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.2897196261682243, "train_stats/max_log_achievement_wake_up": 0.18691588785046728, "train_stats/mean_log_entropy": 2.0645031917875056, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.030098982683317, "train/action_min": 0.0, "train/action_std": 4.7890780065942, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007998169287965875, "train/actor_opt_grad_steps": 47260.0, "train/actor_opt_loss": -12.330208612356598, "train/adv_mag": 0.17568272733547557, "train/adv_max": 0.12687771368449127, "train/adv_mean": -8.892522006908979e-05, "train/adv_min": -0.17252521973660612, "train/adv_std": 0.013499535711878162, "train/cont_avg": 0.9946173720472441, "train/cont_loss_mean": 0.0001613732497020461, "train/cont_loss_std": 0.004824672497743736, "train/cont_neg_acc": 0.9925853023378868, "train/cont_neg_loss": 0.01752829039895463, "train/cont_pos_acc": 0.999976800182673, "train/cont_pos_loss": 6.638082334467434e-05, "train/cont_pred": 0.9946267684613626, "train/cont_rate": 0.9946173720472441, "train/dyn_loss_mean": 10.91950026084119, "train/dyn_loss_std": 8.643080722628616, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13471957351865732, "train/extr_critic_critic_opt_grad_steps": 47260.0, "train/extr_critic_critic_opt_loss": 12103.281826710137, "train/extr_critic_mag": 0.28727305123186486, "train/extr_critic_max": 0.28727305123186486, "train/extr_critic_mean": 0.23193909591577183, "train/extr_critic_min": 0.00129205786337064, "train/extr_critic_std": 0.06454919523552177, "train/extr_return_normed_mag": 0.21923506342050597, "train/extr_return_normed_max": 0.21923506342050597, "train/extr_return_normed_mean": 0.16447150871509642, "train/extr_return_normed_min": -0.06632354101679457, "train/extr_return_normed_std": 0.06604442441850666, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2866137661333159, "train/extr_return_raw_max": 0.2866137661333159, "train/extr_return_raw_mean": 0.23185021635584943, "train/extr_return_raw_min": 0.0010551617840143638, "train/extr_return_raw_std": 0.06604442440384016, "train/extr_reward_mag": 0.0012996600368830162, "train/extr_reward_max": 0.0012996600368830162, "train/extr_reward_mean": 0.0011020427923576217, "train/extr_reward_min": 1.1560485118956078e-05, "train/extr_reward_std": 0.00024102713285274364, "train/image_loss_mean": 4.818761849966575, "train/image_loss_std": 9.737469613082766, "train/model_loss_mean": 11.411025820754645, "train/model_loss_std": 13.346245683084323, "train/model_opt_grad_norm": 52.214313642246516, "train/model_opt_grad_steps": 47215.51968503937, "train/model_opt_loss": 15706.624823142225, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1377.9527559055118, "train/policy_entropy_mag": 2.760788328065647, "train/policy_entropy_max": 2.760788328065647, "train/policy_entropy_mean": 2.0479805169143077, "train/policy_entropy_min": 0.07993570480525024, "train/policy_entropy_std": 0.6120310819993807, "train/policy_logprob_mag": 7.438329790520855, "train/policy_logprob_max": -0.009532914694955968, "train/policy_logprob_mean": -2.047633935147383, "train/policy_logprob_min": -7.438329790520855, "train/policy_logprob_std": 1.1834919893835474, "train/policy_randomness_mag": 0.9744371269631573, "train/policy_randomness_max": 0.9744371269631573, "train/policy_randomness_mean": 0.7228472495642234, "train/policy_randomness_min": 0.02821379590515546, "train/policy_randomness_std": 0.21602011489586567, "train/post_ent_mag": 59.5161269180418, "train/post_ent_max": 59.5161269180418, "train/post_ent_mean": 42.34970897764671, "train/post_ent_min": 19.879755170326533, "train/post_ent_std": 7.222992191164512, "train/prior_ent_mag": 69.38195806788647, "train/prior_ent_max": 69.38195806788647, "train/prior_ent_mean": 53.352867186538816, "train/prior_ent_min": 34.93137041227085, "train/prior_ent_std": 5.277521644051619, "train/rep_loss_mean": 10.91950026084119, "train/rep_loss_std": 8.643080722628616, "train/reward_avg": 0.0010711781764916313, "train/reward_loss_mean": 0.04040238991614402, "train/reward_loss_std": 0.010957815097718258, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012759974622350977, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04040238974014605, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010701298042691833, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.975000006146729, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.8125, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 6.0191705415491015e-06, "report/cont_loss_std": 0.00011729618563549593, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002028404560405761, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.6644513531646226e-06, "report/cont_pred": 0.9931608438491821, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 10.292221069335938, "report/dyn_loss_std": 8.590917587280273, "report/image_loss_mean": 5.6629838943481445, "report/image_loss_std": 9.273710250854492, "report/model_loss_mean": 11.879887580871582, "report/model_loss_std": 12.859545707702637, "report/post_ent_mag": 63.59206008911133, "report/post_ent_max": 63.59206008911133, "report/post_ent_mean": 43.352745056152344, "report/post_ent_min": 21.70721435546875, "report/post_ent_std": 7.619076728820801, "report/prior_ent_mag": 69.01869201660156, "report/prior_ent_max": 69.01869201660156, "report/prior_ent_mean": 53.967254638671875, "report/prior_ent_min": 35.57221603393555, "report/prior_ent_std": 5.424247741699219, "report/rep_loss_mean": 10.292221069335938, "report/rep_loss_std": 8.590917587280273, "report/reward_avg": 0.0011037159711122513, "report/reward_loss_mean": 0.04156549647450447, "report/reward_loss_std": 0.009524941444396973, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012902021408081055, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04156549647450447, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0011059324024245143, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 2.0093154944333946e-06, "eval/cont_loss_std": 3.82037615054287e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0002442290133330971, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.816945645165106e-07, "eval/cont_pred": 0.9941415190696716, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.897586822509766, "eval/dyn_loss_std": 10.805039405822754, "eval/image_loss_mean": 11.5173978805542, "eval/image_loss_std": 17.696144104003906, "eval/model_loss_mean": 22.381214141845703, "eval/model_loss_std": 22.445363998413086, "eval/post_ent_mag": 56.805049896240234, "eval/post_ent_max": 56.805049896240234, "eval/post_ent_mean": 39.938018798828125, "eval/post_ent_min": 15.418611526489258, "eval/post_ent_std": 7.218891143798828, "eval/prior_ent_mag": 69.01869201660156, "eval/prior_ent_max": 69.01869201660156, "eval/prior_ent_mean": 53.889827728271484, "eval/prior_ent_min": 35.022064208984375, "eval/prior_ent_std": 5.0128092765808105, "eval/rep_loss_mean": 16.897586822509766, "eval/rep_loss_std": 10.805039405822754, "eval/reward_avg": 0.01064453087747097, "eval/reward_loss_mean": 0.7252624034881592, "eval/reward_loss_std": 3.742260217666626, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 0.0012902021408081055, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.40600788593292236, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.838300704956055, "eval/reward_pred": 0.0010830763494595885, "eval/reward_rate": 0.015625, "replay/size": 767393.0, "replay/inserts": 20432.0, "replay/samples": 20432.0, "replay/insert_wait_avg": 1.3423647466075541e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.892014369800302e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1681132957714947e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.4492602348328, "timer/env.step_count": 2554.0, "timer/env.step_total": 232.31831693649292, "timer/env.step_frac": 0.23175069916463428, "timer/env.step_avg": 0.09096253599706065, "timer/env.step_min": 0.02267146110534668, "timer/env.step_max": 2.0840988159179688, "timer/replay._sample_count": 20432.0, "timer/replay._sample_total": 9.94208312034607, "timer/replay._sample_frac": 0.009917791867108613, "timer/replay._sample_avg": 0.0004865937314186604, "timer/replay._sample_min": 0.0003790855407714844, "timer/replay._sample_max": 0.0218813419342041, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3030.0, "timer/agent.policy_total": 48.28449583053589, "timer/agent.policy_frac": 0.048166523479926365, "timer/agent.policy_avg": 0.015935477171794023, "timer/agent.policy_min": 0.009564638137817383, "timer/agent.policy_max": 0.09664177894592285, "timer/dataset_train_count": 1277.0, "timer/dataset_train_total": 0.137221097946167, "timer/dataset_train_frac": 0.0001368858289286599, "timer/dataset_train_avg": 0.00010745583237757791, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.00023603439331054688, "timer/agent.train_count": 1277.0, "timer/agent.train_total": 572.9028503894806, "timer/agent.train_frac": 0.5715030905956008, "timer/agent.train_avg": 0.4486318327247303, "timer/agent.train_min": 0.43671488761901855, "timer/agent.train_max": 1.0978150367736816, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4829075336456299, "timer/agent.report_frac": 0.0004817276572507066, "timer/agent.report_avg": 0.24145376682281494, "timer/agent.report_min": 0.23487401008605957, "timer/agent.report_max": 0.2480335235595703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.249282836914062e-05, "timer/dataset_eval_frac": 8.229127562009068e-08, "timer/dataset_eval_avg": 8.249282836914062e-05, "timer/dataset_eval_min": 8.249282836914062e-05, "timer/dataset_eval_max": 8.249282836914062e-05, "fps": 20.381807488899074}
{"step": 767984, "time": 38336.00954461098, "episode/length": 202.0, "episode/score": 0.21962576950863877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21962576950863877}
{"step": 768024, "time": 38338.78290987015, "episode/length": 158.0, "episode/score": 0.18169735487026628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18169735487026628}
{"step": 768296, "time": 38350.60118365288, "episode/length": 169.0, "episode/score": 0.19897879735799506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19897879735799506}
{"step": 768392, "time": 38355.79373908043, "episode/length": 231.0, "episode/score": 0.27169443952152506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27169443952152506}
{"step": 768640, "time": 38366.777482032776, "episode/length": 76.0, "episode/score": 0.07729045207452145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07729045207452145}
{"step": 768704, "time": 38370.731993198395, "episode/length": 161.0, "episode/score": 0.18318643587554106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18318643587554106}
{"step": 768960, "time": 38381.80128097534, "episode/length": 183.0, "episode/score": 0.2128083295901888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2128083295901888}
{"step": 769184, "time": 38392.33201432228, "episode/length": 149.0, "episode/score": 0.15000020061415853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15000020061415853}
{"step": 769376, "time": 38401.5537507534, "episode/length": 188.0, "episode/score": 0.2181220507773105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2181220507773105}
{"step": 769560, "time": 38409.66429948807, "episode/length": 207.0, "episode/score": 0.230236860250443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.230236860250443}
{"step": 769728, "time": 38417.634093523026, "episode/length": 166.0, "episode/score": 0.16178130021580728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16178130021580728}
{"step": 769816, "time": 38422.20580267906, "episode/length": 189.0, "episode/score": 0.2178640125457605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2178640125457605}
{"step": 769848, "time": 38424.93944859505, "episode/length": 150.0, "episode/score": 0.16459354869584786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16459354869584786}
{"step": 770016, "time": 38448.66884946823, "eval_episode/length": 71.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9305555555555556}
{"step": 770016, "time": 38454.77414608002, "eval_episode/length": 141.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 770016, "time": 38456.78960561752, "eval_episode/length": 153.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9805194805194806}
{"step": 770016, "time": 38458.947383880615, "eval_episode/length": 167.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 770016, "time": 38460.797478437424, "eval_episode/length": 173.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 770016, "time": 38464.20648932457, "eval_episode/length": 218.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 770016, "time": 38465.72088551521, "eval_episode/length": 220.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.995475113122172}
{"step": 770016, "time": 38468.47204089165, "eval_episode/length": 173.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 770616, "time": 38491.92529439926, "episode/length": 238.0, "episode/score": 0.25085696672977065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25085696672977065}
{"step": 770800, "time": 38500.554648160934, "episode/length": 154.0, "episode/score": 0.18236706424613658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18236706424613658}
{"step": 771224, "time": 38517.72554779053, "episode/length": 175.0, "episode/score": 0.19577842364924436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19577842364924436}
{"step": 771480, "time": 38528.82014012337, "episode/length": 203.0, "episode/score": 0.24158332878141664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24158332878141664}
{"step": 771512, "time": 38531.44170284271, "episode/length": 290.0, "episode/score": 0.3154628727461386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3154628727461386}
{"step": 771520, "time": 38533.46114039421, "episode/length": 319.0, "episode/score": 0.3619222061242908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3619222061242908}
{"step": 771552, "time": 38536.18001127243, "episode/length": 271.0, "episode/score": 0.30324814661071287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30324814661071287}
{"step": 771600, "time": 38539.458335876465, "episode/length": 233.0, "episode/score": 0.254557554881103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.254557554881103}
{"step": 772272, "time": 38566.10903811455, "episode/length": 183.0, "episode/score": 0.1930892996278999, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1930892996278999}
{"step": 772536, "time": 38577.15371155739, "episode/length": 163.0, "episode/score": 0.18108692046371289, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18108692046371289}
{"step": 772704, "time": 38585.20969462395, "episode/length": 152.0, "episode/score": 0.15885571943726973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15885571943726973}
{"step": 772880, "time": 38593.45484161377, "episode/length": 159.0, "episode/score": 0.15659203370069008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15659203370069008}
{"step": 773048, "time": 38601.11488366127, "episode/length": 303.0, "episode/score": 0.32052134633886453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32052134633886453}
{"step": 773128, "time": 38605.616420030594, "episode/length": 201.0, "episode/score": 0.23065250583204033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23065250583204033}
{"step": 773384, "time": 38616.493062496185, "episode/length": 228.0, "episode/score": 0.2714274924601341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2714274924601341}
{"step": 773408, "time": 38619.24714565277, "episode/length": 235.0, "episode/score": 0.26754189121311356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26754189121311356}
{"step": 773608, "time": 38627.803714990616, "episode/length": 166.0, "episode/score": 0.17623714133605972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17623714133605972}
{"step": 773928, "time": 38640.98737311363, "episode/length": 173.0, "episode/score": 0.1839598587657747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1839598587657747}
{"step": 774072, "time": 38647.82861876488, "episode/length": 170.0, "episode/score": 0.1767665336283244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1767665336283244}
{"step": 774400, "time": 38661.712900877, "episode/length": 168.0, "episode/score": 0.196993408833805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.196993408833805}
{"step": 774464, "time": 38665.59498691559, "episode/length": 166.0, "episode/score": 0.1829025478227777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1829025478227777}
{"step": 774592, "time": 38671.83642601967, "episode/length": 213.0, "episode/score": 0.23398929278755531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23398929278755531}
{"step": 774640, "time": 38675.22903060913, "episode/length": 153.0, "episode/score": 0.17978520991346159, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17978520991346159}
{"step": 774760, "time": 38681.09064745903, "episode/length": 171.0, "episode/score": 0.18877637503555889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18877637503555889}
{"step": 775032, "time": 38692.76798391342, "episode/length": 137.0, "episode/score": 0.1613124969881028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1613124969881028}
{"step": 775352, "time": 38706.163828372955, "episode/length": 159.0, "episode/score": 0.18117360805626959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18117360805626959}
{"step": 775424, "time": 38710.664568424225, "episode/length": 226.0, "episode/score": 0.2529669651084987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2529669651084987}
{"step": 775624, "time": 38719.46786355972, "episode/length": 152.0, "episode/score": 0.16664721129200188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16664721129200188}
{"step": 775920, "time": 38732.07198023796, "episode/length": 181.0, "episode/score": 0.206106364770676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.206106364770676}
{"step": 776008, "time": 38736.516144275665, "episode/length": 155.0, "episode/score": 0.1724750891517033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1724750891517033}
{"step": 776072, "time": 38740.54839873314, "episode/length": 184.0, "episode/score": 0.21106820920249447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21106820920249447}
{"step": 776384, "time": 38753.92002701759, "episode/length": 217.0, "episode/score": 0.253729696116352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.253729696116352}
{"step": 776728, "time": 38768.43563866615, "episode/length": 211.0, "episode/score": 0.2484621751209488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2484621751209488}
{"step": 776768, "time": 38771.719708919525, "episode/length": 176.0, "episode/score": 0.1963549147003505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1963549147003505}
{"step": 776992, "time": 38781.46121454239, "episode/length": 170.0, "episode/score": 0.19194604477888788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19194604477888788}
{"step": 777264, "time": 38793.17433309555, "episode/length": 148.0, "episode/score": 0.1664853401343862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1664853401343862}
{"step": 777408, "time": 38800.15875053406, "episode/length": 174.0, "episode/score": 0.19976696629601065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19976696629601065}
{"step": 777760, "time": 38814.71445965767, "episode/length": 171.0, "episode/score": 0.19864702447739546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19864702447739546}
{"step": 777848, "time": 38819.32577133179, "episode/length": 302.0, "episode/score": 0.3534967959894857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3534967959894857}
{"step": 777912, "time": 38823.19497203827, "episode/length": 114.0, "episode/score": 0.12429140889435075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12429140889435075}
{"step": 777936, "time": 38825.78934812546, "episode/length": 251.0, "episode/score": 0.2793077868336695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2793077868336695}
{"step": 778216, "time": 38837.54462003708, "episode/length": 185.0, "episode/score": 0.21580018535314593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21580018535314593}
{"step": 778488, "time": 38850.847750902176, "episode/length": 214.0, "episode/score": 0.2350170946738217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2350170946738217}
{"step": 778768, "time": 38862.998577833176, "episode/length": 187.0, "episode/score": 0.21308511545066722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21308511545066722}
{"step": 779216, "time": 38881.38001704216, "episode/length": 162.0, "episode/score": 0.18718712378540658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18718712378540658}
{"step": 779336, "time": 38887.265894174576, "episode/length": 240.0, "episode/score": 0.28494161451089894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28494161451089894}
{"step": 779472, "time": 38894.10116434097, "episode/length": 191.0, "episode/score": 0.2157846515692654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2157846515692654}
{"step": 779560, "time": 38898.64502429962, "episode/length": 213.0, "episode/score": 0.24466848597876378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24466848597876378}
{"step": 779720, "time": 38906.06240439415, "episode/length": 244.0, "episode/score": 0.27878210466587916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27878210466587916}
{"step": 779832, "time": 38911.68237924576, "episode/length": 167.0, "episode/score": 0.19305205695854966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19305205695854966}
{"step": 779840, "time": 38913.690698862076, "episode/length": 202.0, "episode/score": 0.2306296257484064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2306296257484064}
{"step": 780000, "time": 38940.145562171936, "eval_episode/length": 141.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 780000, "time": 38941.84881687164, "eval_episode/length": 146.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9591836734693877}
{"step": 780000, "time": 38943.60117292404, "eval_episode/length": 150.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 780000, "time": 38945.7966902256, "eval_episode/length": 168.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 780000, "time": 38948.51354598999, "eval_episode/length": 193.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 780000, "time": 38950.051832675934, "eval_episode/length": 196.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 780000, "time": 38952.70730352402, "eval_episode/length": 224.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 780000, "time": 38958.83160448074, "eval_episode/length": 184.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 780136, "time": 38963.662984371185, "episode/length": 170.0, "episode/score": 0.19239415701304097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19239415701304097}
{"step": 780528, "time": 38979.92263293266, "episode/length": 163.0, "episode/score": 0.18714509616984287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18714509616984287}
{"step": 780648, "time": 38985.63667654991, "episode/length": 146.0, "episode/score": 0.17758332972880453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17758332972880453}
{"step": 780752, "time": 38991.20078873634, "episode/length": 176.0, "episode/score": 0.1913929867951083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1913929867951083}
{"step": 781192, "time": 39008.95403933525, "episode/length": 168.0, "episode/score": 0.19261011568596587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19261011568596587}
{"step": 781248, "time": 39012.85051989555, "episode/length": 190.0, "episode/score": 0.2288509688914928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2288509688914928}
{"step": 781368, "time": 39018.716795921326, "episode/length": 225.0, "episode/score": 0.25953520665643737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25953520665643737}
{"step": 782088, "time": 39047.27134847641, "episode/length": 179.0, "episode/score": 0.18856068927743763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18856068927743763}
{"step": 782144, "time": 39051.182094335556, "episode/length": 201.0, "episode/score": 0.21733007626608014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21733007626608014}
{"step": 782280, "time": 39057.554866075516, "episode/length": 190.0, "episode/score": 0.20596655975168687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20596655975168687}
{"step": 782312, "time": 39060.276134729385, "episode/length": 271.0, "episode/score": 0.2974722899743938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2974722899743938}
{"step": 782624, "time": 39073.690985918045, "episode/length": 156.0, "episode/score": 0.1575654117623344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1575654117623344}
{"step": 782728, "time": 39078.80003738403, "episode/length": 184.0, "episode/score": 0.2104801550594857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2104801550594857}
{"step": 782936, "time": 39087.83137464523, "episode/length": 217.0, "episode/score": 0.24591774483269546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24591774483269546}
{"step": 783152, "time": 39097.49095797539, "episode/length": 414.0, "episode/score": 0.4388286031971802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4388286031971802}
{"step": 783552, "time": 39113.431624889374, "episode/length": 175.0, "episode/score": 0.1792498919458012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1792498919458012}
{"step": 783896, "time": 39127.271590948105, "episode/length": 225.0, "episode/score": 0.2555295920537901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2555295920537901}
{"step": 784000, "time": 39132.84338927269, "episode/length": 214.0, "episode/score": 0.23216226224394632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23216226224394632}
{"step": 784136, "time": 39139.30834579468, "episode/length": 188.0, "episode/score": 0.22424999572103843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22424999572103843}
{"step": 784232, "time": 39144.84579920769, "episode/length": 239.0, "episode/score": 0.2663439684365585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2663439684365585}
{"step": 784248, "time": 39147.38514780998, "episode/length": 189.0, "episode/score": 0.21051055691350484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21051055691350484}
{"step": 784272, "time": 39149.923062324524, "episode/length": 166.0, "episode/score": 0.17222837903682375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17222837903682375}
{"step": 784616, "time": 39163.84243154526, "episode/length": 182.0, "episode/score": 0.1833878232027928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1833878232027928}
{"step": 784848, "time": 39174.136049985886, "episode/length": 161.0, "episode/score": 0.1635051378980279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1635051378980279}
{"step": 785296, "time": 39192.38697600365, "episode/length": 144.0, "episode/score": 0.16433383709045302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16433383709045302}
{"step": 785648, "time": 39206.95020890236, "episode/length": 218.0, "episode/score": 0.2457722700855811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2457722700855811}
{"step": 785664, "time": 39209.10059809685, "episode/length": 178.0, "episode/score": 0.19550804110258468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19550804110258468}
{"step": 786128, "time": 39227.69592642784, "episode/length": 188.0, "episode/score": 0.20776686185854487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20776686185854487}
{"step": 786192, "time": 39231.49669933319, "episode/length": 167.0, "episode/score": 0.18110745417652652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18110745417652652}
{"step": 786320, "time": 39237.60774254799, "episode/length": 255.0, "episode/score": 0.27976136405050056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27976136405050056}
{"step": 786416, "time": 39242.68967008591, "episode/length": 301.0, "episode/score": 0.34108001586719183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34108001586719183}
{"step": 786624, "time": 39253.70709657669, "episode/length": 61.0, "episode/score": 0.06425733639116515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06425733639116515}
{"step": 786808, "time": 39262.21768760681, "episode/length": 188.0, "episode/score": 0.19593463085766416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19593463085766416}
{"step": 786936, "time": 39268.41165971756, "episode/length": 160.0, "episode/score": 0.16814823756430997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16814823756430997}
{"step": 787216, "time": 39280.490360975266, "episode/length": 193.0, "episode/score": 0.2187886866959161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2187886866959161}
{"step": 787608, "time": 39296.154005765915, "episode/length": 419.0, "episode/score": 0.4393740563900792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4393740563900792}
{"step": 787624, "time": 39298.260513305664, "episode/length": 162.0, "episode/score": 0.1658732409850927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1658732409850927}
{"step": 787728, "time": 39303.86761069298, "episode/length": 191.0, "episode/score": 0.1956429767597001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1956429767597001}
{"step": 788104, "time": 39318.895664691925, "episode/length": 184.0, "episode/score": 0.2028423705996829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2028423705996829}
{"step": 788352, "time": 39329.70711135864, "episode/length": 176.0, "episode/score": 0.21427540333934303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21427540333934303}
{"step": 788377, "time": 39332.84648036957, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.132132053375244, "train/action_min": 0.0, "train/action_std": 4.847913537174463, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008214407152991043, "train/actor_opt_grad_steps": 48535.0, "train/actor_opt_loss": -12.923555865418166, "train/adv_mag": 0.18383550713770092, "train/adv_max": 0.12938578869216144, "train/adv_mean": -0.00012057205314164321, "train/adv_min": -0.18235357938101515, "train/adv_std": 0.013926755003922153, "train/cont_avg": 0.9946441650390625, "train/cont_loss_mean": 0.00013674597452162374, "train/cont_loss_std": 0.003878580038829682, "train/cont_neg_acc": 0.9912760425359011, "train/cont_neg_loss": 0.01859374070872022, "train/cont_pos_acc": 0.9999999823048711, "train/cont_pos_loss": 3.766821582257274e-05, "train/cont_pred": 0.994662398006767, "train/cont_rate": 0.9946441650390625, "train/dyn_loss_mean": 11.093797475099564, "train/dyn_loss_std": 8.617284540086985, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13340795232215896, "train/extr_critic_critic_opt_grad_steps": 48535.0, "train/extr_critic_critic_opt_loss": 12008.040809631348, "train/extr_critic_mag": 0.28672333247959614, "train/extr_critic_max": 0.28672333247959614, "train/extr_critic_mean": 0.2311928675044328, "train/extr_critic_min": 0.0015670470893383026, "train/extr_critic_std": 0.06221994437510148, "train/extr_return_normed_mag": 0.21274341957177967, "train/extr_return_normed_max": 0.21274341957177967, "train/extr_return_normed_mean": 0.1578539676265791, "train/extr_return_normed_min": -0.07218590332195163, "train/extr_return_normed_std": 0.06379556996398605, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2859616978093982, "train/extr_return_raw_max": 0.2859616978093982, "train/extr_return_raw_mean": 0.23107225040439516, "train/extr_return_raw_min": 0.0010323747992515564, "train/extr_return_raw_std": 0.06379557008040138, "train/extr_reward_mag": 0.001311984844505787, "train/extr_reward_max": 0.001311984844505787, "train/extr_reward_mean": 0.0010964074317598715, "train/extr_reward_min": 1.0687857866287231e-05, "train/extr_reward_std": 0.0002463131374952354, "train/image_loss_mean": 4.998614069074392, "train/image_loss_std": 10.202596750110388, "train/model_loss_mean": 11.695238031446934, "train/model_loss_std": 13.801424503326416, "train/model_opt_grad_norm": 52.71780887246132, "train/model_opt_grad_steps": 48489.359375, "train/model_opt_loss": 15328.573837280273, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1318.359375, "train/policy_entropy_mag": 2.7622451707720757, "train/policy_entropy_max": 2.7622451707720757, "train/policy_entropy_mean": 2.0566796213388443, "train/policy_entropy_min": 0.07991924736415967, "train/policy_entropy_std": 0.6009024726226926, "train/policy_logprob_mag": 7.438294503837824, "train/policy_logprob_max": -0.009530742463539355, "train/policy_logprob_mean": -2.0568159176036716, "train/policy_logprob_min": -7.438294503837824, "train/policy_logprob_std": 1.1736628003418446, "train/policy_randomness_mag": 0.9749513282440603, "train/policy_randomness_max": 0.9749513282440603, "train/policy_randomness_mean": 0.7259176457300782, "train/policy_randomness_min": 0.02820798716857098, "train/policy_randomness_std": 0.21209220250602812, "train/post_ent_mag": 59.45191699266434, "train/post_ent_max": 59.45191699266434, "train/post_ent_mean": 42.2508245408535, "train/post_ent_min": 20.137191846966743, "train/post_ent_std": 7.219665180891752, "train/prior_ent_mag": 69.37430316209793, "train/prior_ent_max": 69.37430316209793, "train/prior_ent_mean": 53.39810582995415, "train/prior_ent_min": 35.22640338540077, "train/prior_ent_std": 5.261119961738586, "train/rep_loss_mean": 11.093797475099564, "train/rep_loss_std": 8.617284540086985, "train/reward_avg": 0.0010658268902261625, "train/reward_loss_mean": 0.040208750375313684, "train/reward_loss_std": 0.01125310295901727, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.00127438735216856, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040208750404417515, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010654487532519852, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.801923050545156, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.730769230769231, "train_stats/max_log_achievement_collect_sapling": 0.6057692307692307, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.6346153846153846, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.038461538461538464, "train_stats/max_log_achievement_eat_cow": 0.019230769230769232, "train_stats/max_log_achievement_make_wood_pickaxe": 0.038461538461538464, "train_stats/max_log_achievement_make_wood_sword": 0.009615384615384616, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.375, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.21153846153846154, "train_stats/max_log_achievement_wake_up": 0.3076923076923077, "train_stats/mean_log_entropy": 2.0856339369828882, "eval_stats/sum_log_reward": 1.1624999735504389, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.5, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.3125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0026791803538799286, "report/cont_loss_std": 0.06913422793149948, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.012349652126431465, "report/cont_pos_acc": 0.9990166425704956, "report/cont_pos_loss": 0.002612618263810873, "report/cont_pred": 0.9919649362564087, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 11.41822624206543, "report/dyn_loss_std": 9.596577644348145, "report/image_loss_mean": 5.091465950012207, "report/image_loss_std": 12.441828727722168, "report/model_loss_mean": 11.98568344116211, "report/model_loss_std": 16.52542495727539, "report/post_ent_mag": 59.549224853515625, "report/post_ent_max": 59.549224853515625, "report/post_ent_mean": 42.670692443847656, "report/post_ent_min": 18.743961334228516, "report/post_ent_std": 8.096654891967773, "report/prior_ent_mag": 69.83635711669922, "report/prior_ent_max": 69.83635711669922, "report/prior_ent_mean": 53.66241455078125, "report/prior_ent_min": 31.689659118652344, "report/prior_ent_std": 5.51069974899292, "report/rep_loss_mean": 11.41822624206543, "report/rep_loss_std": 9.596577644348145, "report/reward_avg": 0.0010765685001388192, "report/reward_loss_mean": 0.040603116154670715, "report/reward_loss_std": 0.010790732689201832, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012508630752563477, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.040603116154670715, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010652465280145407, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0002982817532029003, "eval/cont_loss_std": 0.009251823648810387, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.6356182135932613e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00029885832918807864, "eval/cont_pred": 0.997787594795227, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.567057609558105, "eval/dyn_loss_std": 10.129520416259766, "eval/image_loss_mean": 8.344483375549316, "eval/image_loss_std": 13.977840423583984, "eval/model_loss_mean": 18.190937042236328, "eval/model_loss_std": 18.648441314697266, "eval/post_ent_mag": 57.30180358886719, "eval/post_ent_max": 57.30180358886719, "eval/post_ent_mean": 41.355587005615234, "eval/post_ent_min": 18.57412338256836, "eval/post_ent_std": 7.2336626052856445, "eval/prior_ent_mag": 69.83635711669922, "eval/prior_ent_max": 69.83635711669922, "eval/prior_ent_mean": 54.419654846191406, "eval/prior_ent_min": 34.54724884033203, "eval/prior_ent_std": 4.772765636444092, "eval/rep_loss_mean": 15.567057609558105, "eval/rep_loss_std": 10.129520416259766, "eval/reward_avg": 0.0078125, "eval/reward_loss_mean": 0.5059201717376709, "eval/reward_loss_std": 3.112278461456299, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 0.0013003349304199219, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.30417579412460327, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.962800979614258, "eval/reward_pred": 0.0010353894904255867, "eval/reward_rate": 0.009765625, "replay/size": 787873.0, "replay/inserts": 20480.0, "replay/samples": 20480.0, "replay/insert_wait_avg": 1.3069016858935357e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.417650289833545e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4656.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2215879774585212e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2012090682983, "timer/env.step_count": 2560.0, "timer/env.step_total": 224.0061388015747, "timer/env.step_frac": 0.22396107580217745, "timer/env.step_avg": 0.08750239796936513, "timer/env.step_min": 0.022037982940673828, "timer/env.step_max": 1.9758436679840088, "timer/replay._sample_count": 20480.0, "timer/replay._sample_total": 9.924309253692627, "timer/replay._sample_frac": 0.009922312794379905, "timer/replay._sample_avg": 0.0004845854127779603, "timer/replay._sample_min": 0.0003941059112548828, "timer/replay._sample_max": 0.010870933532714844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3142.0, "timer/agent.policy_total": 51.41807794570923, "timer/agent.policy_frac": 0.051407734243398784, "timer/agent.policy_avg": 0.01636476064471968, "timer/agent.policy_min": 0.009762287139892578, "timer/agent.policy_max": 0.15293478965759277, "timer/dataset_train_count": 1280.0, "timer/dataset_train_total": 0.13716769218444824, "timer/dataset_train_frac": 0.0001371400983530323, "timer/dataset_train_avg": 0.0001071622595191002, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0008435249328613281, "timer/agent.train_count": 1280.0, "timer/agent.train_total": 574.39910364151, "timer/agent.train_frac": 0.5742835525829557, "timer/agent.train_avg": 0.4487492997199297, "timer/agent.train_min": 0.43560194969177246, "timer/agent.train_max": 1.2877109050750732, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4783437252044678, "timer/agent.report_frac": 0.0004782474974710856, "timer/agent.report_avg": 0.2391718626022339, "timer/agent.report_min": 0.23134732246398926, "timer/agent.report_max": 0.24699640274047852, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.693587969521929e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 20.47563347024649}
{"step": 788464, "time": 39336.105219364166, "episode/length": 206.0, "episode/score": 0.22031470462752623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22031470462752623}
{"step": 788864, "time": 39352.569149017334, "episode/length": 156.0, "episode/score": 0.1781689195886429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1781689195886429}
{"step": 788976, "time": 39358.24226927757, "episode/length": 155.0, "episode/score": 0.16445376908268372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16445376908268372}
{"step": 789128, "time": 39365.07200551033, "episode/length": 187.0, "episode/score": 0.1942323013136047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1942323013136047}
{"step": 789144, "time": 39367.233179569244, "episode/length": 240.0, "episode/score": 0.2559904895242653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2559904895242653}
{"step": 789496, "time": 39381.79591202736, "episode/length": 173.0, "episode/score": 0.18626587037579156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18626587037579156}
{"step": 789832, "time": 39395.393812417984, "episode/length": 426.0, "episode/score": 0.4405265234672697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4405265234672697}
{"step": 790088, "time": 39427.085183382034, "eval_episode/length": 146.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9591836734693877}
{"step": 790088, "time": 39429.05615544319, "eval_episode/length": 157.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 790088, "time": 39431.50946474075, "eval_episode/length": 179.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 790088, "time": 39433.59795045853, "eval_episode/length": 184.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 790088, "time": 39436.07464361191, "eval_episode/length": 194.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 790088, "time": 39438.42407035828, "eval_episode/length": 204.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 790088, "time": 39438.43178129196, "eval_episode/length": 204.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.975609756097561}
{"step": 790088, "time": 39443.52944588661, "eval_episode/length": 227.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 790216, "time": 39448.24249577522, "episode/length": 218.0, "episode/score": 0.2646527725737542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2646527725737542}
{"step": 790424, "time": 39457.56340837479, "episode/length": 180.0, "episode/score": 0.1904530314677686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1904530314677686}
{"step": 790432, "time": 39460.06841111183, "episode/length": 259.0, "episode/score": 0.2843590596894501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2843590596894501}
{"step": 790504, "time": 39464.36382842064, "episode/length": 169.0, "episode/score": 0.16109359639085596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16109359639085596}
{"step": 790920, "time": 39481.99259185791, "episode/length": 177.0, "episode/score": 0.19832539337221533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19832539337221533}
{"step": 791064, "time": 39488.924725055695, "episode/length": 241.0, "episode/score": 0.26719229516311316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26719229516311316}
{"step": 791128, "time": 39492.76241493225, "episode/length": 161.0, "episode/score": 0.18346753956575412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18346753956575412}
{"step": 791232, "time": 39498.235503196716, "episode/length": 295.0, "episode/score": 0.3337427893347922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3337427893347922}
{"step": 791440, "time": 39507.40573120117, "episode/length": 152.0, "episode/score": 0.16287617864145432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16287617864145432}
{"step": 791680, "time": 39517.95362663269, "episode/length": 155.0, "episode/score": 0.17815901492576813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17815901492576813}
{"step": 792008, "time": 39531.548944950104, "episode/length": 197.0, "episode/score": 0.22557740665070014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22557740665070014}
{"step": 792272, "time": 39543.20068573952, "episode/length": 142.0, "episode/score": 0.1559544393348915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1559544393348915}
{"step": 792336, "time": 39547.20366477966, "episode/length": 137.0, "episode/score": 0.149805415989249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.149805415989249}
{"step": 792384, "time": 39550.465403556824, "episode/length": 234.0, "episode/score": 0.23854970432512346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23854970432512346}
{"step": 792560, "time": 39558.62825727463, "episode/length": 204.0, "episode/score": 0.21823962637063232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21823962637063232}
{"step": 792720, "time": 39566.08908343315, "episode/length": 159.0, "episode/score": 0.17743499427342613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17743499427342613}
{"step": 793440, "time": 39594.33160305023, "episode/length": 296.0, "episode/score": 0.3294136024960608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3294136024960608}
{"step": 793496, "time": 39597.78790354729, "episode/length": 185.0, "episode/score": 0.20491047801988316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20491047801988316}
{"step": 793552, "time": 39601.60294508934, "episode/length": 151.0, "episode/score": 0.16379919500104734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16379919500104734}
{"step": 793832, "time": 39613.24749469757, "episode/length": 268.0, "episode/score": 0.3096744641461555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3096744641461555}
{"step": 793920, "time": 39618.22302412987, "episode/length": 169.0, "episode/score": 0.1894983954825875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1894983954825875}
{"step": 793992, "time": 39622.175143003464, "episode/length": 214.0, "episode/score": 0.2402456756663014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2402456756663014}
{"step": 794184, "time": 39630.782868385315, "episode/length": 224.0, "episode/score": 0.2556222040147986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2556222040147986}
{"step": 794448, "time": 39642.50151395798, "episode/length": 215.0, "episode/score": 0.2466946748081682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2466946748081682}
{"step": 794808, "time": 39658.57474946976, "episode/length": 170.0, "episode/score": 0.16115425264069927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16115425264069927}
{"step": 794896, "time": 39663.56483244896, "episode/length": 174.0, "episode/score": 0.19384259035723517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19384259035723517}
{"step": 795176, "time": 39675.39881873131, "episode/length": 147.0, "episode/score": 0.16731321672523336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16731321672523336}
{"step": 795416, "time": 39685.821574926376, "episode/length": 153.0, "episode/score": 0.1629605541129422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1629605541129422}
{"step": 795456, "time": 39689.01804804802, "episode/length": 191.0, "episode/score": 0.21283527443483763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21283527443483763}
{"step": 795680, "time": 39698.87741136551, "episode/length": 265.0, "episode/score": 0.3000492772553116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3000492772553116}
{"step": 796200, "time": 39719.430549144745, "episode/length": 173.0, "episode/score": 0.18872196867687308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18872196867687308}
{"step": 796752, "time": 39741.80216002464, "episode/length": 161.0, "episode/score": 0.18063866183001664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18063866183001664}
{"step": 796800, "time": 39745.02550315857, "episode/length": 172.0, "episode/score": 0.17857948442633642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17857948442633642}
{"step": 796808, "time": 39746.55571627617, "episode/length": 238.0, "episode/score": 0.2778215824109793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2778215824109793}
{"step": 796856, "time": 39749.800800323486, "episode/length": 300.0, "episode/score": 0.3231824271224468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3231824271224468}
{"step": 796864, "time": 39751.83407354355, "episode/length": 378.0, "episode/score": 0.4391113212213895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4391113212213895}
{"step": 796984, "time": 39757.70469498634, "episode/length": 225.0, "episode/score": 0.24892474477383075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24892474477383075}
{"step": 797352, "time": 39772.983260154724, "episode/length": 208.0, "episode/score": 0.21389689373427245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21389689373427245}
{"step": 797656, "time": 39785.736864328384, "episode/length": 181.0, "episode/score": 0.19638121073239745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19638121073239745}
{"step": 798032, "time": 39801.593994140625, "episode/length": 159.0, "episode/score": 0.17607974643669877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17607974643669877}
{"step": 798088, "time": 39805.015802145004, "episode/length": 153.0, "episode/score": 0.17542289197444916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17542289197444916}
{"step": 798248, "time": 39812.4956843853, "episode/length": 157.0, "episode/score": 0.1804914094018386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1804914094018386}
{"step": 798256, "time": 39814.589572906494, "episode/length": 173.0, "episode/score": 0.19956349761741876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19956349761741876}
{"step": 798280, "time": 39816.944028139114, "episode/length": 184.0, "episode/score": 0.202257047421881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.202257047421881}
{"step": 798304, "time": 39819.67884898186, "episode/length": 186.0, "episode/score": 0.200876413640799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.200876413640799}
{"step": 798464, "time": 39827.14113974571, "episode/length": 46.0, "episode/score": 0.0566666655940935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0566666655940935}
{"step": 798704, "time": 39837.46670746803, "episode/length": 168.0, "episode/score": 0.18061491169646615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18061491169646615}
{"step": 799336, "time": 39862.38474154472, "episode/length": 209.0, "episode/score": 0.249544767545558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.249544767545558}
{"step": 799432, "time": 39867.510822057724, "episode/length": 174.0, "episode/score": 0.1856359830862857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1856359830862857}
{"step": 799560, "time": 39873.875665187836, "episode/length": 159.0, "episode/score": 0.16091176519239525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16091176519239525}
{"step": 799568, "time": 39875.90178322792, "episode/length": 163.0, "episode/score": 0.17522621230273216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17522621230273216}
{"step": 799728, "time": 39883.45125579834, "episode/length": 184.0, "episode/score": 0.2000974893771854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2000974893771854}
{"step": 799928, "time": 39892.206377744675, "episode/length": 182.0, "episode/score": 0.20085110312629695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20085110312629695}
{"step": 799936, "time": 39894.39773249626, "episode/length": 203.0, "episode/score": 0.23026019305052614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23026019305052614}
{"step": 800016, "time": 39898.83239150047, "episode/length": 163.0, "episode/score": 0.1795138275692807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1795138275692807}
{"step": 800072, "time": 39916.09379053116, "eval_episode/length": 39.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9}
{"step": 800072, "time": 39922.00438070297, "eval_episode/length": 145.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 800072, "time": 39924.28317475319, "eval_episode/length": 161.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 800072, "time": 39926.01135635376, "eval_episode/length": 166.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 800072, "time": 39928.75579166412, "eval_episode/length": 152.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 800072, "time": 39930.43065786362, "eval_episode/length": 196.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 800072, "time": 39930.438814878464, "eval_episode/length": 196.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 800072, "time": 39934.05023741722, "eval_episode/length": 202.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 800872, "time": 39964.067100048065, "episode/length": 179.0, "episode/score": 0.170631330456672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.170631330456672}
{"step": 800952, "time": 39969.17203998566, "episode/length": 201.0, "episode/score": 0.22983688969907234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22983688969907234}
{"step": 801040, "time": 39974.21075940132, "episode/length": 163.0, "episode/score": 0.18390398943847686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18390398943847686}
{"step": 801056, "time": 39976.301840782166, "episode/length": 186.0, "episode/score": 0.22030356737377588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22030356737377588}
{"step": 801200, "time": 39983.16091680527, "episode/length": 203.0, "episode/score": 0.2216184626058748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2216184626058748}
{"step": 801312, "time": 39988.896007061005, "episode/length": 172.0, "episode/score": 0.19682808270590613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19682808270590613}
{"step": 801400, "time": 39993.296439647675, "episode/length": 182.0, "episode/score": 0.18178719082652606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18178719082652606}
{"step": 801488, "time": 39998.40962433815, "episode/length": 35.0, "episode/score": 0.03575743986584712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03575743986584712}
{"step": 801944, "time": 40016.787987709045, "episode/length": 240.0, "episode/score": 0.2721003278302305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2721003278302305}
{"step": 802112, "time": 40024.76495027542, "episode/length": 154.0, "episode/score": 0.17857041105207827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17857041105207827}
{"step": 802208, "time": 40029.937250614166, "episode/length": 145.0, "episode/score": 0.15955802603639313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15955802603639313}
{"step": 802368, "time": 40037.41994690895, "episode/length": 176.0, "episode/score": 0.19957142672956252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19957142672956252}
{"step": 803024, "time": 40065.069194316864, "episode/length": 191.0, "episode/score": 0.20823342594349015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20823342594349015}
{"step": 803120, "time": 40070.18658947945, "episode/length": 214.0, "episode/score": 0.23713293716582484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23713293716582484}
{"step": 803280, "time": 40077.632887125015, "episode/length": 166.0, "episode/score": 0.1806850091479646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1806850091479646}
{"step": 803464, "time": 40085.739230155945, "episode/length": 168.0, "episode/score": 0.19793001694961276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19793001694961276}
{"step": 803712, "time": 40096.724004507065, "episode/length": 187.0, "episode/score": 0.21731051163078519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21731051163078519}
{"step": 803736, "time": 40098.97958278656, "episode/length": 170.0, "episode/score": 0.18271825119154528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18271825119154528}
{"step": 804328, "time": 40122.59047079086, "episode/length": 408.0, "episode/score": 0.45202161456290924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.45202161456290924}
{"step": 804440, "time": 40128.27487826347, "episode/length": 144.0, "episode/score": 0.16339166397665394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16339166397665394}
{"step": 804584, "time": 40135.02378821373, "episode/length": 408.0, "episode/score": 0.42109545016683114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42109545016683114}
{"step": 804760, "time": 40143.11520695686, "episode/length": 161.0, "episode/score": 0.18711332526436308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18711332526436308}
{"step": 805120, "time": 40158.35918021202, "episode/length": 175.0, "episode/score": 0.18392670177127002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18392670177127002}
{"step": 805128, "time": 40160.036955833435, "episode/length": 173.0, "episode/score": 0.1904653632445843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1904653632445843}
{"step": 805816, "time": 40187.19894576073, "episode/length": 171.0, "episode/score": 0.18090234722149034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18090234722149034}
{"step": 806192, "time": 40202.84083819389, "episode/length": 232.0, "episode/score": 0.2530190023135219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2530190023135219}
{"step": 806264, "time": 40206.95087957382, "episode/length": 187.0, "episode/score": 0.19952942021518538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19952942021518538}
{"step": 806392, "time": 40213.06237030029, "episode/length": 408.0, "episode/score": 0.43142940793222806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.43142940793222806}
{"step": 806416, "time": 40215.618932724, "episode/length": 161.0, "episode/score": 0.15925602306379005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15925602306379005}
{"step": 806480, "time": 40219.351343393326, "episode/length": 431.0, "episode/score": 0.47837222213820496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.47837222213820496}
{"step": 806480, "time": 40219.358902454376, "episode/length": 168.0, "episode/score": 0.18931608453203808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18931608453203808}
{"step": 806832, "time": 40235.26797437668, "episode/length": 280.0, "episode/score": 0.3284877390415204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3284877390415204}
{"step": 807352, "time": 40255.490356206894, "episode/length": 191.0, "episode/score": 0.20956854346877662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20956854346877662}
{"step": 807640, "time": 40267.5560297966, "episode/length": 155.0, "episode/score": 0.1660097284056974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1660097284056974}
{"step": 807648, "time": 40269.51912403107, "episode/length": 172.0, "episode/score": 0.18938760090895812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18938760090895812}
{"step": 807680, "time": 40272.19621348381, "episode/length": 157.0, "episode/score": 0.17062153904953448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17062153904953448}
{"step": 807744, "time": 40276.12891411781, "episode/length": 157.0, "episode/score": 0.16719018499316007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16719018499316007}
{"step": 807912, "time": 40284.21191859245, "episode/length": 214.0, "episode/score": 0.22080318721600634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22080318721600634}
{"step": 807936, "time": 40286.86578464508, "episode/length": 137.0, "episode/score": 0.1429160025127203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1429160025127203}
{"step": 808752, "time": 40318.48178815842, "episode/length": 174.0, "episode/score": 0.1879660229642468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1879660229642468}
{"step": 808944, "time": 40326.93290758133, "episode/length": 162.0, "episode/score": 0.17459346703344636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17459346703344636}
{"step": 809008, "time": 40330.72616171837, "episode/length": 165.0, "episode/score": 0.18003330474311952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18003330474311952}
{"step": 809017, "time": 40333.336648225784, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.199185630147771, "train/action_min": 0.0, "train/action_std": 4.925715520400409, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007611101439092742, "train/actor_opt_grad_steps": 49820.0, "train/actor_opt_loss": -11.41848260325979, "train/adv_mag": 0.1706890589738077, "train/adv_max": 0.12309005792981895, "train/adv_mean": -4.313797558978869e-05, "train/adv_min": -0.16890734301288, "train/adv_std": 0.01285955801158566, "train/cont_avg": 0.9945796996124031, "train/cont_loss_mean": 0.00014998590295037573, "train/cont_loss_std": 0.004603852059526996, "train/cont_neg_acc": 0.9981696813605553, "train/cont_neg_loss": 0.007253561038852652, "train/cont_pos_acc": 0.9999695415644683, "train/cont_pos_loss": 9.969553167919592e-05, "train/cont_pred": 0.9945600457893785, "train/cont_rate": 0.9945796996124031, "train/dyn_loss_mean": 10.926225920980292, "train/dyn_loss_std": 8.62661747599757, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1355196482162605, "train/extr_critic_critic_opt_grad_steps": 49820.0, "train/extr_critic_critic_opt_loss": 11959.24074158188, "train/extr_critic_mag": 0.2844006987505181, "train/extr_critic_max": 0.2844006987505181, "train/extr_critic_mean": 0.22899669466554656, "train/extr_critic_min": 0.0014212806095448575, "train/extr_critic_std": 0.062352000598528586, "train/extr_return_normed_mag": 0.21403478698212972, "train/extr_return_normed_max": 0.21403478698212972, "train/extr_return_normed_mean": 0.1589629141859306, "train/extr_return_normed_min": -0.06896413019461226, "train/extr_return_normed_std": 0.0637050204325554, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2840254489303559, "train/extr_return_raw_max": 0.2840254489303559, "train/extr_return_raw_mean": 0.228953579715056, "train/extr_return_raw_min": 0.0010265315225882123, "train/extr_return_raw_std": 0.06370502077909403, "train/extr_reward_mag": 0.0013227176296618558, "train/extr_reward_max": 0.0013227176296618558, "train/extr_reward_mean": 0.0011006240469454101, "train/extr_reward_min": 1.0991281317185986e-05, "train/extr_reward_std": 0.00023886887018222276, "train/image_loss_mean": 4.829347701035728, "train/image_loss_std": 9.995494361995727, "train/model_loss_mean": 11.425598344137502, "train/model_loss_std": 13.579881742019062, "train/model_opt_grad_norm": 49.12762596071229, "train/model_opt_grad_steps": 49773.40310077519, "train/model_opt_loss": 17981.550962936046, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1579.4573643410852, "train/policy_entropy_mag": 2.762469916380653, "train/policy_entropy_max": 2.762469916380653, "train/policy_entropy_mean": 2.065521756807963, "train/policy_entropy_min": 0.07976019047489462, "train/policy_entropy_std": 0.6088799469230711, "train/policy_logprob_mag": 7.438312005627063, "train/policy_logprob_max": -0.009508809110857257, "train/policy_logprob_mean": -2.064901955367983, "train/policy_logprob_min": -7.438312005627063, "train/policy_logprob_std": 1.1699565621309502, "train/policy_randomness_mag": 0.9750306546226029, "train/policy_randomness_max": 0.9750306546226029, "train/policy_randomness_mean": 0.7290385402450266, "train/policy_randomness_min": 0.028151846988949666, "train/policy_randomness_std": 0.21490790250227432, "train/post_ent_mag": 59.560162802999336, "train/post_ent_max": 59.560162802999336, "train/post_ent_mean": 42.38893148141314, "train/post_ent_min": 19.876555028811907, "train/post_ent_std": 7.256667503090792, "train/prior_ent_mag": 69.48728067560714, "train/prior_ent_max": 69.48728067560714, "train/prior_ent_mean": 53.40894941581312, "train/prior_ent_min": 35.14350123738134, "train/prior_ent_std": 5.266428755235302, "train/rep_loss_mean": 10.926225920980292, "train/rep_loss_std": 8.62661747599757, "train/reward_avg": 0.0010700861259197543, "train/reward_loss_mean": 0.04036512150782948, "train/reward_loss_std": 0.010998148139017496, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012766917546590169, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040365121536707696, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010689746195002812, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.8211538171968782, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.0576923076923075, "train_stats/max_log_achievement_collect_sapling": 0.5096153846153846, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.9038461538461537, "train_stats/max_log_achievement_defeat_skeleton": 0.009615384615384616, "train_stats/max_log_achievement_defeat_zombie": 0.04807692307692308, "train_stats/max_log_achievement_eat_cow": 0.009615384615384616, "train_stats/max_log_achievement_make_wood_pickaxe": 0.028846153846153848, "train_stats/max_log_achievement_make_wood_sword": 0.028846153846153848, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.25961538461538464, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.3269230769230769, "train_stats/max_log_achievement_wake_up": 0.2980769230769231, "train_stats/mean_log_entropy": 2.0864923756856184, "eval_stats/sum_log_reward": 1.662499975413084, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.6875, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.25, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.98828125, "report/cont_loss_mean": 2.7005748052033596e-05, "report/cont_loss_std": 0.00023772320128045976, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006099151214584708, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.0093781131436117e-05, "report/cont_pred": 0.9882684946060181, "report/cont_rate": 0.98828125, "report/dyn_loss_mean": 8.920413970947266, "report/dyn_loss_std": 8.593934059143066, "report/image_loss_mean": 4.084222793579102, "report/image_loss_std": 5.950807094573975, "report/model_loss_mean": 9.47597885131836, "report/model_loss_std": 9.641519546508789, "report/post_ent_mag": 62.848785400390625, "report/post_ent_max": 62.848785400390625, "report/post_ent_mean": 44.25868606567383, "report/post_ent_min": 21.812942504882812, "report/post_ent_std": 6.942962169647217, "report/prior_ent_mag": 69.31033325195312, "report/prior_ent_max": 69.31033325195312, "report/prior_ent_mean": 53.32279968261719, "report/prior_ent_min": 30.9110050201416, "report/prior_ent_std": 5.87069845199585, "report/rep_loss_mean": 8.920413970947266, "report/rep_loss_std": 8.593934059143066, "report/reward_avg": 0.0010453342692926526, "report/reward_loss_mean": 0.03948019817471504, "report/reward_loss_std": 0.01214548572897911, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012557506561279297, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.039480194449424744, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010355616686865687, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.16712646256201e-05, "eval/cont_loss_std": 0.00037730130134150386, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00023450113076251, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.110467853024602e-05, "eval/cont_pred": 0.9970301389694214, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.59266471862793, "eval/dyn_loss_std": 10.705242156982422, "eval/image_loss_mean": 13.574678421020508, "eval/image_loss_std": 22.863332748413086, "eval/model_loss_mean": 23.556062698364258, "eval/model_loss_std": 27.191736221313477, "eval/post_ent_mag": 61.72450256347656, "eval/post_ent_max": 61.72450256347656, "eval/post_ent_mean": 42.306182861328125, "eval/post_ent_min": 19.261859893798828, "eval/post_ent_std": 7.9708170890808105, "eval/prior_ent_mag": 69.31033325195312, "eval/prior_ent_max": 69.31033325195312, "eval/prior_ent_mean": 55.66217041015625, "eval/prior_ent_min": 43.87101364135742, "eval/prior_ent_std": 4.46246337890625, "eval/rep_loss_mean": 15.59266471862793, "eval/rep_loss_std": 10.705242156982422, "eval/reward_avg": 0.00791015662252903, "eval/reward_loss_mean": 0.6257432699203491, "eval/reward_loss_std": 3.4928271770477295, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012606382369995117, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.38392549753189087, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 21.01904296875, "eval/reward_pred": 0.0010798012372106314, "eval/reward_rate": 0.01171875, "replay/size": 808513.0, "replay/inserts": 20640.0, "replay/samples": 20640.0, "replay/insert_wait_avg": 1.316038213034933e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.862961569497752e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1501898621738373e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4745342731476, "timer/env.step_count": 2580.0, "timer/env.step_total": 224.4919137954712, "timer/env.step_frac": 0.22438543521606602, "timer/env.step_avg": 0.08701236968816713, "timer/env.step_min": 0.022330284118652344, "timer/env.step_max": 3.1258108615875244, "timer/replay._sample_count": 20640.0, "timer/replay._sample_total": 10.0234694480896, "timer/replay._sample_frac": 0.010018715224342743, "timer/replay._sample_avg": 0.00048563320969426354, "timer/replay._sample_min": 0.0003998279571533203, "timer/replay._sample_max": 0.011204004287719727, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3011.0, "timer/agent.policy_total": 47.67699956893921, "timer/agent.policy_frac": 0.04765438592954983, "timer/agent.policy_avg": 0.015834274184303956, "timer/agent.policy_min": 0.00969386100769043, "timer/agent.policy_max": 0.09397506713867188, "timer/dataset_train_count": 1290.0, "timer/dataset_train_total": 0.13925671577453613, "timer/dataset_train_frac": 0.00013919066503347555, "timer/dataset_train_avg": 0.00010795094246088072, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0009021759033203125, "timer/agent.train_count": 1290.0, "timer/agent.train_total": 578.5745394229889, "timer/agent.train_frac": 0.5783001161976878, "timer/agent.train_avg": 0.4485073949015418, "timer/agent.train_min": 0.4358336925506592, "timer/agent.train_max": 1.1923911571502686, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47948288917541504, "timer/agent.report_frac": 0.0004792554660311899, "timer/agent.report_avg": 0.23974144458770752, "timer/agent.report_min": 0.23587632179260254, "timer/agent.report_max": 0.2436065673828125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2411346435546875e-05, "timer/dataset_eval_frac": 2.2400716527811364e-08, "timer/dataset_eval_avg": 2.2411346435546875e-05, "timer/dataset_eval_min": 2.2411346435546875e-05, "timer/dataset_eval_max": 2.2411346435546875e-05, "fps": 20.629931513069984}
{"step": 809160, "time": 40338.37034893036, "episode/length": 176.0, "episode/score": 0.18082040399531252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18082040399531252}
{"step": 809312, "time": 40345.696716070175, "episode/length": 174.0, "episode/score": 0.199859716643914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.199859716643914}
{"step": 809328, "time": 40347.708761930466, "episode/length": 209.0, "episode/score": 0.22814291215399862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22814291215399862}
{"step": 809752, "time": 40364.48256802559, "episode/length": 408.0, "episode/score": 0.43380078130030597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.43380078130030597}
{"step": 809784, "time": 40367.268430233, "episode/length": 230.0, "episode/score": 0.24947910620176117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24947910620176117}
{"step": 810032, "time": 40378.266815423965, "episode/length": 159.0, "episode/score": 0.166592587195737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.166592587195737}
{"step": 810056, "time": 40403.53507733345, "eval_episode/length": 149.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9866666666666667}
{"step": 810056, "time": 40405.05679130554, "eval_episode/length": 150.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 810056, "time": 40407.06186461449, "eval_episode/length": 163.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 810056, "time": 40409.076552152634, "eval_episode/length": 176.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 810056, "time": 40410.9571890831, "eval_episode/length": 188.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 810056, "time": 40412.991780757904, "eval_episode/length": 201.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.995049504950495}
{"step": 810056, "time": 40412.999332904816, "eval_episode/length": 201.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 810056, "time": 40416.67529678345, "eval_episode/length": 214.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 810224, "time": 40423.07973098755, "episode/length": 159.0, "episode/score": 0.17704390206472453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17704390206472453}
{"step": 810496, "time": 40434.645389556885, "episode/length": 185.0, "episode/score": 0.1686404654628859, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1686404654628859}
{"step": 810640, "time": 40441.29396700859, "episode/length": 165.0, "episode/score": 0.18318876938064932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18318876938064932}
{"step": 810680, "time": 40444.02538871765, "episode/length": 168.0, "episode/score": 0.16901495106321818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16901495106321818}
{"step": 810704, "time": 40446.585550785065, "episode/length": 192.0, "episode/score": 0.21536705971811898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21536705971811898}
{"step": 810976, "time": 40458.191226005554, "episode/length": 148.0, "episode/score": 0.1772972905955612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1772972905955612}
{"step": 811568, "time": 40482.49189758301, "episode/length": 167.0, "episode/score": 0.18269750832314458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18269750832314458}
{"step": 811792, "time": 40492.204916238785, "episode/length": 161.0, "episode/score": 0.17660343799434486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17660343799434486}
{"step": 811840, "time": 40495.45413017273, "episode/length": 149.0, "episode/score": 0.17336182137478318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17336182137478318}
{"step": 811888, "time": 40498.66704964638, "episode/length": 266.0, "episode/score": 0.3101952506640373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3101952506640373}
{"step": 811896, "time": 40500.28366279602, "episode/length": 151.0, "episode/score": 0.16637758397155267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16637758397155267}
{"step": 812000, "time": 40505.80548644066, "episode/length": 245.0, "episode/score": 0.2693703188770087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2693703188770087}
{"step": 812200, "time": 40514.5480864048, "episode/length": 186.0, "episode/score": 0.2076114968795082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2076114968795082}
{"step": 812456, "time": 40525.39237999916, "episode/length": 184.0, "episode/score": 0.20031203571306833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20031203571306833}
{"step": 812872, "time": 40542.155532598495, "episode/length": 162.0, "episode/score": 0.1853244982467004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1853244982467004}
{"step": 813088, "time": 40551.9395031929, "episode/length": 149.0, "episode/score": 0.16786859105377516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16786859105377516}
{"step": 813096, "time": 40553.98638367653, "episode/length": 149.0, "episode/score": 0.17003722214303707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17003722214303707}
{"step": 813128, "time": 40557.03860640526, "episode/length": 160.0, "episode/score": 0.1840457405141933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1840457405141933}
{"step": 813304, "time": 40565.69475674629, "episode/length": 188.0, "episode/score": 0.1970006698556972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1970006698556972}
{"step": 813408, "time": 40571.81726503372, "episode/length": 175.0, "episode/score": 0.19949259699569666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19949259699569666}
{"step": 813496, "time": 40576.784754514694, "episode/length": 49.0, "episode/score": 0.05246612078099133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05246612078099133}
{"step": 813840, "time": 40591.852914094925, "episode/length": 172.0, "episode/score": 0.18875829168428027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18875829168428027}
{"step": 813848, "time": 40593.74783349037, "episode/length": 205.0, "episode/score": 0.22124426776827022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22124426776827022}
{"step": 814376, "time": 40615.079773664474, "episode/length": 187.0, "episode/score": 0.19625063291823608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19625063291823608}
{"step": 814464, "time": 40619.94041776657, "episode/length": 166.0, "episode/score": 0.184421924360322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.184421924360322}
{"step": 814664, "time": 40628.68094944954, "episode/length": 169.0, "episode/score": 0.19076581836088735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19076581836088735}
{"step": 814688, "time": 40631.25332117081, "episode/length": 148.0, "episode/score": 0.17474319002712946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17474319002712946}
{"step": 814744, "time": 40634.586894750595, "episode/length": 206.0, "episode/score": 0.2162544491538938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2162544491538938}
{"step": 814840, "time": 40639.58499097824, "episode/length": 178.0, "episode/score": 0.1784162502772233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1784162502772233}
{"step": 814960, "time": 40645.6127281189, "episode/length": 138.0, "episode/score": 0.15142238090311366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15142238090311366}
{"step": 815272, "time": 40658.52098941803, "episode/length": 178.0, "episode/score": 0.18366726848717008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18366726848717008}
{"step": 815808, "time": 40679.7152364254, "episode/length": 178.0, "episode/score": 0.1994451918849336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1994451918849336}
{"step": 815896, "time": 40684.21395921707, "episode/length": 178.0, "episode/score": 0.18564163318660576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18564163318660576}
{"step": 815936, "time": 40687.484417676926, "episode/length": 155.0, "episode/score": 0.16132518897438786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16132518897438786}
{"step": 816032, "time": 40692.471455812454, "episode/length": 170.0, "episode/score": 0.19139001810071932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19139001810071932}
{"step": 816328, "time": 40704.57174253464, "episode/length": 197.0, "episode/score": 0.21954320385975734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21954320385975734}
{"step": 816760, "time": 40721.94011759758, "episode/length": 185.0, "episode/score": 0.1990673071150013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1990673071150013}
{"step": 816888, "time": 40728.19568157196, "episode/length": 240.0, "episode/score": 0.27413792795778136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27413792795778136}
{"step": 817176, "time": 40740.199543476105, "episode/length": 170.0, "episode/score": 0.18022621621412327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18022621621412327}
{"step": 817336, "time": 40747.55054926872, "episode/length": 174.0, "episode/score": 0.2018212241650872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2018212241650872}
{"step": 817344, "time": 40749.58478522301, "episode/length": 180.0, "episode/score": 0.1809933283166174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1809933283166174}
{"step": 817400, "time": 40752.94884610176, "episode/length": 170.0, "episode/score": 0.17494036167545346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17494036167545346}
{"step": 818160, "time": 40782.41692185402, "episode/length": 414.0, "episode/score": 0.4259352144449622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4259352144449622}
{"step": 818200, "time": 40785.242317676544, "episode/length": 179.0, "episode/score": 0.19986681313321242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19986681313321242}
{"step": 818232, "time": 40787.91782426834, "episode/length": 167.0, "episode/score": 0.18985200789120427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18985200789120427}
{"step": 818416, "time": 40796.3202047348, "episode/length": 260.0, "episode/score": 0.299694929600264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.299694929600264}
{"step": 818728, "time": 40809.02809548378, "episode/length": 173.0, "episode/score": 0.19260854348522116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19260854348522116}
{"step": 818904, "time": 40817.448770046234, "episode/length": 194.0, "episode/score": 0.2207326507787002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2207326507787002}
{"step": 819008, "time": 40822.938809633255, "episode/length": 228.0, "episode/score": 0.2474820126835766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2474820126835766}
{"step": 819216, "time": 40833.23723268509, "episode/length": 226.0, "episode/score": 0.2687236778183433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2687236778183433}
{"step": 819416, "time": 40841.852727890015, "episode/length": 156.0, "episode/score": 0.17711336225056584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17711336225056584}
{"step": 819736, "time": 40854.858753442764, "episode/length": 39.0, "episode/score": 0.04639880862669088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04639880862669088}
{"step": 819952, "time": 40864.562485694885, "episode/length": 191.0, "episode/score": 0.212394595349906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.212394595349906}
{"step": 820040, "time": 40887.059918403625, "eval_episode/length": 145.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.952054794520548}
{"step": 820040, "time": 40888.62868475914, "eval_episode/length": 148.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 820040, "time": 40890.472417116165, "eval_episode/length": 157.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 820040, "time": 40892.35317444801, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 820040, "time": 40893.92231440544, "eval_episode/length": 167.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 820040, "time": 40895.72677779198, "eval_episode/length": 174.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 820040, "time": 40897.47551894188, "eval_episode/length": 177.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 820040, "time": 40899.418843746185, "eval_episode/length": 187.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 820152, "time": 40903.577873945236, "episode/length": 239.0, "episode/score": 0.27458463709263015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27458463709263015}
{"step": 820168, "time": 40905.69760847092, "episode/length": 245.0, "episode/score": 0.2652818352612485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2652818352612485}
{"step": 820208, "time": 40908.82122397423, "episode/length": 184.0, "episode/score": 0.1898834853250264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1898834853250264}
{"step": 820624, "time": 40925.57893562317, "episode/length": 214.0, "episode/score": 0.2276831506706003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2276831506706003}
{"step": 820704, "time": 40930.111333847046, "episode/length": 185.0, "episode/score": 0.19002864484855309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19002864484855309}
{"step": 820808, "time": 40935.195813417435, "episode/length": 224.0, "episode/score": 0.24387389930006975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24387389930006975}
{"step": 821136, "time": 40948.93052458763, "episode/length": 53.0, "episode/score": 0.05594047540216707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05594047540216707}
{"step": 821144, "time": 40950.449526548386, "episode/length": 148.0, "episode/score": 0.1775045669987776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1775045669987776}
{"step": 821168, "time": 40952.9175632, "episode/length": 178.0, "episode/score": 0.19425217442403664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19425217442403664}
{"step": 821528, "time": 40967.3966486454, "episode/length": 164.0, "episode/score": 0.18982460527104195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18982460527104195}
{"step": 821752, "time": 40977.19702935219, "episode/length": 199.0, "episode/score": 0.2152904541976568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2152904541976568}
{"step": 822056, "time": 40989.953862428665, "episode/length": 235.0, "episode/score": 0.2673128452047422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2673128452047422}
{"step": 822184, "time": 40996.527324676514, "episode/length": 171.0, "episode/score": 0.16974813262277166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16974813262277166}
{"step": 822416, "time": 41006.85161614418, "episode/length": 155.0, "episode/score": 0.16321940794750844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16321940794750844}
{"step": 822656, "time": 41017.21396327019, "episode/length": 140.0, "episode/score": 0.14414811491496948, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14414811491496948}
{"step": 823088, "time": 41034.7059366703, "episode/length": 83.0, "episode/score": 0.08788231565222304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08788231565222304}
{"step": 823360, "time": 41046.05722784996, "episode/length": 146.0, "episode/score": 0.162071061819006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.162071061819006}
{"step": 823400, "time": 41048.94364857674, "episode/length": 167.0, "episode/score": 0.1903541103288262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1903541103288262}
{"step": 823496, "time": 41054.04808592796, "episode/length": 294.0, "episode/score": 0.33513205550616476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33513205550616476}
{"step": 823712, "time": 41063.66536068916, "episode/length": 385.0, "episode/score": 0.40067891847593273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.40067891847593273}
{"step": 824072, "time": 41078.29378557205, "episode/length": 176.0, "episode/score": 0.19123306264282292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19123306264282292}
{"step": 824240, "time": 41086.14635801315, "episode/length": 143.0, "episode/score": 0.15483342179095416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15483342179095416}
{"step": 824552, "time": 41099.3430120945, "episode/length": 425.0, "episode/score": 0.45575823933586435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.45575823933586435}
{"step": 824560, "time": 41101.27590250969, "episode/length": 144.0, "episode/score": 0.1708685356334172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1708685356334172}
{"step": 825176, "time": 41125.28961920738, "episode/length": 427.0, "episode/score": 0.47142070968425287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.47142070968425287}
{"step": 825184, "time": 41127.77306628227, "episode/length": 210.0, "episode/score": 0.2223566149996259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2223566149996259}
{"step": 825240, "time": 41131.604434251785, "episode/length": 190.0, "episode/score": 0.20235932927062095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20235932927062095}
{"step": 825272, "time": 41134.33919978142, "episode/length": 238.0, "episode/score": 0.2680008681268191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2680008681268191}
{"step": 825560, "time": 41146.524834394455, "episode/length": 164.0, "episode/score": 0.16934556107707976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16934556107707976}
{"step": 825768, "time": 41155.6678814888, "episode/length": 211.0, "episode/score": 0.23401502244973926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23401502244973926}
{"step": 825928, "time": 41163.07582592964, "episode/length": 170.0, "episode/score": 0.19628508459641125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19628508459641125}
{"step": 826280, "time": 41177.61628508568, "episode/length": 215.0, "episode/score": 0.2385005318074036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2385005318074036}
{"step": 826456, "time": 41185.65684890747, "episode/length": 159.0, "episode/score": 0.17414647895634516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17414647895634516}
{"step": 826616, "time": 41193.19992661476, "episode/length": 171.0, "episode/score": 0.18337488457177642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18337488457177642}
{"step": 826656, "time": 41196.4465944767, "episode/length": 172.0, "episode/score": 0.20069189043897495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20069189043897495}
{"step": 826960, "time": 41209.502574682236, "episode/length": 174.0, "episode/score": 0.19347342055743866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19347342055743866}
{"step": 827112, "time": 41216.439002513885, "episode/length": 167.0, "episode/score": 0.19070488721899892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19070488721899892}
{"step": 827208, "time": 41222.069070100784, "episode/length": 159.0, "episode/score": 0.1759418415242635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1759418415242635}
{"step": 827592, "time": 41239.73527979851, "episode/length": 163.0, "episode/score": 0.1911249965778552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1911249965778552}
{"step": 827744, "time": 41246.92039132118, "episode/length": 135.0, "episode/score": 0.1551377568666794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1551377568666794}
{"step": 827760, "time": 41248.9530415535, "episode/length": 321.0, "episode/score": 0.3694512831391421, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3694512831391421}
{"step": 827880, "time": 41254.67209935188, "episode/length": 157.0, "episode/score": 0.18616212524148068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18616212524148068}
{"step": 828328, "time": 41273.02845978737, "episode/length": 233.0, "episode/score": 0.25927463462676315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25927463462676315}
{"step": 828552, "time": 41282.82836771011, "episode/length": 198.0, "episode/score": 0.2304702338151401, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2304702338151401}
{"step": 828760, "time": 41292.061321020126, "episode/length": 193.0, "episode/score": 0.20749175622950133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20749175622950133}
{"step": 828800, "time": 41295.223932504654, "episode/length": 114.0, "episode/score": 0.1300996118332023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1300996118332023}
{"step": 828968, "time": 41302.749567747116, "episode/length": 231.0, "episode/score": 0.24494599725630906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24494599725630906}
{"step": 829048, "time": 41307.18414950371, "episode/length": 181.0, "episode/score": 0.19947093155087714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19947093155087714}
{"step": 829216, "time": 41315.13334131241, "episode/length": 183.0, "episode/score": 0.20582129486592748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20582129486592748}
{"step": 829272, "time": 41318.47271323204, "episode/length": 188.0, "episode/score": 0.21078197261067544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21078197261067544}
{"step": 829424, "time": 41325.6634042263, "episode/length": 46.0, "episode/score": 0.044960947991057765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044960947991057765}
{"step": 829577, "time": 41333.515042066574, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.191643293513808, "train/action_min": 0.0, "train/action_std": 4.8811085427454275, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008087006401155115, "train/actor_opt_grad_steps": 51110.0, "train/actor_opt_loss": -11.449288500501781, "train/adv_mag": 0.17627061377893122, "train/adv_max": 0.1314714467802713, "train/adv_mean": -7.182358677717049e-05, "train/adv_min": -0.17543520362571227, "train/adv_std": 0.013437017004272734, "train/cont_avg": 0.9943450218023255, "train/cont_loss_mean": 0.0001748544539967729, "train/cont_loss_std": 0.005083366175852923, "train/cont_neg_acc": 0.9947674422301063, "train/cont_neg_loss": 0.015155671316739075, "train/cont_pos_acc": 0.999969484270081, "train/cont_pos_loss": 7.917859160789204e-05, "train/cont_pred": 0.9943453239840131, "train/cont_rate": 0.9943450218023255, "train/dyn_loss_mean": 10.899184655773547, "train/dyn_loss_std": 8.661774882974552, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12985523336733035, "train/extr_critic_critic_opt_grad_steps": 51110.0, "train/extr_critic_critic_opt_loss": 12039.596104348353, "train/extr_critic_mag": 0.28259631275206576, "train/extr_critic_max": 0.28259631275206576, "train/extr_critic_mean": 0.22909997542237126, "train/extr_critic_min": 0.0014677491298941679, "train/extr_critic_std": 0.061197054796209634, "train/extr_return_normed_mag": 0.21179448483988297, "train/extr_return_normed_max": 0.21179448483988297, "train/extr_return_normed_mean": 0.1587906689491383, "train/extr_return_normed_min": -0.06920616178549538, "train/extr_return_normed_std": 0.06277730685564899, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2820320196392, "train/extr_return_raw_max": 0.2820320196392, "train/extr_return_raw_mean": 0.22902820819570113, "train/extr_return_raw_min": 0.0010313728983088056, "train/extr_return_raw_std": 0.06277730668237967, "train/extr_reward_mag": 0.0013325306796288306, "train/extr_reward_max": 0.0013325306796288306, "train/extr_reward_mean": 0.001098956780096646, "train/extr_reward_min": 1.081015712531038e-05, "train/extr_reward_std": 0.00024203043710801375, "train/image_loss_mean": 4.692879161169363, "train/image_loss_std": 9.676481442858082, "train/model_loss_mean": 11.272695112598035, "train/model_loss_std": 13.33206720130388, "train/model_opt_grad_norm": 55.99590140350105, "train/model_opt_grad_steps": 51062.22480620155, "train/model_opt_loss": 14748.821342054263, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1308.139534883721, "train/policy_entropy_mag": 2.7639460378839065, "train/policy_entropy_max": 2.7639460378839065, "train/policy_entropy_mean": 2.0825721376626065, "train/policy_entropy_min": 0.07979427335798278, "train/policy_entropy_std": 0.601233969594157, "train/policy_logprob_mag": 7.4383047052132065, "train/policy_logprob_max": -0.009513881801114989, "train/policy_logprob_mean": -2.0819425795429436, "train/policy_logprob_min": -7.4383047052132065, "train/policy_logprob_std": 1.15844431866047, "train/policy_randomness_mag": 0.975551659284636, "train/policy_randomness_max": 0.975551659284636, "train/policy_randomness_mean": 0.7350565670996674, "train/policy_randomness_min": 0.028163876846548197, "train/policy_randomness_std": 0.2122092079515605, "train/post_ent_mag": 59.652135597643, "train/post_ent_max": 59.652135597643, "train/post_ent_mean": 42.57097362547882, "train/post_ent_min": 19.955941739932513, "train/post_ent_std": 7.274427158887996, "train/prior_ent_mag": 69.52364727877831, "train/prior_ent_max": 69.52364727877831, "train/prior_ent_mean": 53.55377200222755, "train/prior_ent_min": 34.852849649828535, "train/prior_ent_std": 5.264141729635786, "train/rep_loss_mean": 10.899184655773547, "train/rep_loss_std": 8.661774882974552, "train/reward_avg": 0.0010635415403453937, "train/reward_loss_mean": 0.040130319001600724, "train/reward_loss_std": 0.011292127935692321, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012832464173782704, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040130318914966066, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001063708107658597, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.80909087725661, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.3636363636363638, "train_stats/max_log_achievement_collect_sapling": 0.6272727272727273, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.5909090909090908, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.05454545454545454, "train_stats/max_log_achievement_eat_cow": 0.02727272727272727, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02727272727272727, "train_stats/max_log_achievement_make_wood_sword": 0.03636363636363636, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.2818181818181818, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.2909090909090909, "train_stats/max_log_achievement_wake_up": 0.19090909090909092, "train_stats/mean_log_entropy": 2.099859014424411, "eval_stats/sum_log_reward": 1.599999975413084, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.3125, "eval_stats/max_log_achievement_collect_sapling": 0.9375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.3125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 1.2554983186419122e-05, "report/cont_loss_std": 2.4036287868511863e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.183197597740218e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.2497689567680936e-05, "report/cont_pred": 0.9980344772338867, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 11.12025260925293, "report/dyn_loss_std": 8.166698455810547, "report/image_loss_mean": 4.877370834350586, "report/image_loss_std": 9.531474113464355, "report/model_loss_mean": 11.589981079101562, "report/model_loss_std": 12.799360275268555, "report/post_ent_mag": 60.10845947265625, "report/post_ent_max": 60.10845947265625, "report/post_ent_mean": 41.67256164550781, "report/post_ent_min": 18.953807830810547, "report/post_ent_std": 6.6173834800720215, "report/prior_ent_mag": 69.2625732421875, "report/prior_ent_max": 69.2625732421875, "report/prior_ent_mean": 52.851932525634766, "report/prior_ent_min": 39.98875427246094, "report/prior_ent_std": 4.7336907386779785, "report/rep_loss_mean": 11.12025260925293, "report/rep_loss_std": 8.166698455810547, "report/reward_avg": 0.0010746108600869775, "report/reward_loss_mean": 0.04044610261917114, "report/reward_loss_std": 0.011651708744466305, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013206005096435547, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04044610261917114, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001094326376914978, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.574835525592789e-05, "eval/cont_loss_std": 0.0002892318298108876, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.899082796328003e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.580961700004991e-05, "eval/cont_pred": 0.9970446228981018, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.239849090576172, "eval/dyn_loss_std": 11.326117515563965, "eval/image_loss_mean": 11.369945526123047, "eval/image_loss_std": 19.62405776977539, "eval/model_loss_mean": 20.980932235717773, "eval/model_loss_std": 24.31249237060547, "eval/post_ent_mag": 58.63751983642578, "eval/post_ent_max": 58.63751983642578, "eval/post_ent_mean": 41.5341682434082, "eval/post_ent_min": 20.015853881835938, "eval/post_ent_std": 7.60811710357666, "eval/prior_ent_mag": 69.2625732421875, "eval/prior_ent_max": 69.2625732421875, "eval/prior_ent_mean": 53.950313568115234, "eval/prior_ent_min": 38.15046310424805, "eval/prior_ent_std": 5.188910961151123, "eval/rep_loss_mean": 15.239849090576172, "eval/rep_loss_std": 11.326117515563965, "eval/reward_avg": 0.01093750074505806, "eval/reward_loss_mean": 0.4670531153678894, "eval/reward_loss_std": 3.030036211013794, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012753009796142578, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.18357573449611664, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.917926788330078, "eval/reward_pred": 0.0010880372719839215, "eval/reward_rate": 0.013671875, "replay/size": 829073.0, "replay/inserts": 20560.0, "replay/samples": 20560.0, "replay/insert_wait_avg": 1.3106064109950678e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.014273550723777e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3224.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1790774892045013e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1680495738983, "timer/env.step_count": 2570.0, "timer/env.step_total": 236.3435070514679, "timer/env.step_frac": 0.23630379629918927, "timer/env.step_avg": 0.09196245410562953, "timer/env.step_min": 0.022449970245361328, "timer/env.step_max": 2.034242630004883, "timer/replay._sample_count": 20560.0, "timer/replay._sample_total": 9.973819494247437, "timer/replay._sample_frac": 0.0099721436797512, "timer/replay._sample_avg": 0.0004851079520548364, "timer/replay._sample_min": 0.0003914833068847656, "timer/replay._sample_max": 0.02307295799255371, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2973.0, "timer/agent.policy_total": 48.04029893875122, "timer/agent.policy_frac": 0.04803222714344638, "timer/agent.policy_avg": 0.01615886274428228, "timer/agent.policy_min": 0.009689092636108398, "timer/agent.policy_max": 0.12084817886352539, "timer/dataset_train_count": 1285.0, "timer/dataset_train_total": 0.13467168807983398, "timer/dataset_train_frac": 0.00013464906036261424, "timer/dataset_train_avg": 0.00010480287010103813, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.00037097930908203125, "timer/agent.train_count": 1285.0, "timer/agent.train_total": 574.7200770378113, "timer/agent.train_frac": 0.5746235118015011, "timer/agent.train_avg": 0.44725297823954185, "timer/agent.train_min": 0.4335908889770508, "timer/agent.train_max": 1.016214370727539, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47945117950439453, "timer/agent.report_frac": 0.00047937062147571617, "timer/agent.report_avg": 0.23972558975219727, "timer/agent.report_min": 0.23441243171691895, "timer/agent.report_max": 0.24503874778747559, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2172927856445312e-05, "timer/dataset_eval_frac": 2.216920233143985e-08, "timer/dataset_eval_avg": 2.2172927856445312e-05, "timer/dataset_eval_min": 2.2172927856445312e-05, "timer/dataset_eval_max": 2.2172927856445312e-05, "fps": 20.556284806588874}
{"step": 829656, "time": 41336.256625175476, "episode/length": 165.0, "episode/score": 0.18233283431618474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18233283431618474}
{"step": 829664, "time": 41338.390535116196, "episode/length": 138.0, "episode/score": 0.16791666334029287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16791666334029287}
{"step": 829792, "time": 41344.50645518303, "episode/length": 45.0, "episode/score": 0.05416666576638818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05416666576638818}
{"step": 830024, "time": 41373.26589512825, "eval_episode/length": 151.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.993421052631579}
{"step": 830024, "time": 41375.21640872955, "eval_episode/length": 161.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 830024, "time": 41377.2757999897, "eval_episode/length": 170.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9941520467836257}
{"step": 830024, "time": 41380.39407873154, "eval_episode/length": 206.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 830024, "time": 41382.90114355087, "eval_episode/length": 226.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 830024, "time": 41387.81563901901, "eval_episode/length": 301.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9966887417218543}
{"step": 830024, "time": 41390.27876162529, "eval_episode/length": 150.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 830024, "time": 41392.85381269455, "eval_episode/length": 156.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9617834394904459}
{"step": 830080, "time": 41395.22143626213, "episode/length": 159.0, "episode/score": 0.16433815934578888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16433815934578888}
{"step": 830304, "time": 41405.68662214279, "episode/length": 166.0, "episode/score": 0.19141282574855722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19141282574855722}
{"step": 830360, "time": 41409.05300784111, "episode/length": 199.0, "episode/score": 0.20454484862557365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20454484862557365}
{"step": 830696, "time": 41422.89853286743, "episode/length": 184.0, "episode/score": 0.19369232379540335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19369232379540335}
{"step": 830776, "time": 41427.274722099304, "episode/length": 187.0, "episode/score": 0.2118016025342513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2118016025342513}
{"step": 830904, "time": 41434.00399231911, "episode/length": 154.0, "episode/score": 0.15993002089089714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15993002089089714}
{"step": 831168, "time": 41446.302872657776, "episode/length": 171.0, "episode/score": 0.18499531386623858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18499531386623858}
{"step": 831384, "time": 41455.71549201012, "episode/length": 215.0, "episode/score": 0.23808780212857528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23808780212857528}
{"step": 831560, "time": 41463.96119213104, "episode/length": 149.0, "episode/score": 0.16474273057247046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16474273057247046}
{"step": 832032, "time": 41483.46467399597, "episode/length": 166.0, "episode/score": 0.19710931217923644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19710931217923644}
{"step": 832088, "time": 41486.83123254776, "episode/length": 222.0, "episode/score": 0.2403268554371607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2403268554371607}
{"step": 832112, "time": 41489.4278614521, "episode/length": 166.0, "episode/score": 0.1788087582026492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1788087582026492}
{"step": 832232, "time": 41495.141167879105, "episode/length": 165.0, "episode/score": 0.18560526759029017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18560526759029017}
{"step": 832408, "time": 41503.29431056976, "episode/length": 46.0, "episode/score": 0.05604166560806334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05604166560806334}
{"step": 832824, "time": 41520.439616680145, "episode/length": 157.0, "episode/score": 0.18329166341573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18329166341573}
{"step": 832888, "time": 41524.310180187225, "episode/length": 187.0, "episode/score": 0.21963095675710065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21963095675710065}
{"step": 833040, "time": 41531.86172866821, "episode/length": 233.0, "episode/score": 0.2774208223563619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2774208223563619}
{"step": 833136, "time": 41537.05534386635, "episode/length": 381.0, "episode/score": 0.414002121098747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.414002121098747}
{"step": 833384, "time": 41547.64437007904, "episode/length": 161.0, "episode/score": 0.18623624688916607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18623624688916607}
{"step": 833400, "time": 41549.74236702919, "episode/length": 44.0, "episode/score": 0.05218333232187433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05218333232187433}
{"step": 833640, "time": 41560.30150485039, "episode/length": 175.0, "episode/score": 0.1934811771297973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1934811771297973}
{"step": 833992, "time": 41575.05980873108, "episode/length": 197.0, "episode/score": 0.21527942108332354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21527942108332354}
{"step": 834016, "time": 41577.75092816353, "episode/length": 148.0, "episode/score": 0.15750533279242518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15750533279242518}
{"step": 834592, "time": 41600.768078804016, "episode/length": 212.0, "episode/score": 0.21941162678558612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21941162678558612}
{"step": 834616, "time": 41602.96849536896, "episode/length": 184.0, "episode/score": 0.21025212270433258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21025212270433258}
{"step": 834656, "time": 41606.24798631668, "episode/length": 156.0, "episode/score": 0.15781183976832835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15781183976832835}
{"step": 835184, "time": 41627.53669500351, "episode/length": 224.0, "episode/score": 0.25947619346879947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25947619346879947}
{"step": 835344, "time": 41635.04536700249, "episode/length": 403.0, "episode/score": 0.4191716973309667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4191716973309667}
{"step": 835480, "time": 41641.557990312576, "episode/length": 182.0, "episode/score": 0.20959356847015442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20959356847015442}
{"step": 835792, "time": 41656.64346241951, "episode/length": 224.0, "episode/score": 0.24573834226066538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24573834226066538}
{"step": 836016, "time": 41666.56471848488, "episode/length": 169.0, "episode/score": 0.1650917267324985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1650917267324985}
{"step": 836184, "time": 41676.266557216644, "episode/length": 195.0, "episode/score": 0.22185209924646188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22185209924646188}
{"step": 836552, "time": 41691.70406150818, "episode/length": 244.0, "episode/score": 0.26900446529180044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26900446529180044}
{"step": 836664, "time": 41698.06338381767, "episode/length": 184.0, "episode/score": 0.21396241367256152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21396241367256152}
{"step": 836808, "time": 41705.07368159294, "episode/length": 395.0, "episode/score": 0.44762756395721226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44762756395721226}
{"step": 836840, "time": 41707.87477207184, "episode/length": 186.0, "episode/score": 0.20888352256952203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20888352256952203}
{"step": 837176, "time": 41721.99215841293, "episode/length": 144.0, "episode/score": 0.1707422423096432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1707422423096432}
{"step": 837296, "time": 41728.11186861992, "episode/length": 226.0, "episode/score": 0.2591824262162845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2591824262162845}
{"step": 837472, "time": 41736.14642524719, "episode/length": 209.0, "episode/score": 0.2158249414897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2158249414897}
{"step": 838120, "time": 41761.89419436455, "episode/length": 195.0, "episode/score": 0.21131663113919785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21131663113919785}
{"step": 838128, "time": 41764.59240150452, "episode/length": 182.0, "episode/score": 0.20717789452464785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20717789452464785}
{"step": 838168, "time": 41767.56295919418, "episode/length": 165.0, "episode/score": 0.1980120672888006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1980120672888006}
{"step": 838224, "time": 41771.34314393997, "episode/length": 176.0, "episode/score": 0.17851314436848043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17851314436848043}
{"step": 838416, "time": 41780.134553194046, "episode/length": 154.0, "episode/score": 0.17110819357912987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17110819357912987}
{"step": 838784, "time": 41795.311512470245, "episode/length": 324.0, "episode/score": 0.36004373014657176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.36004373014657176}
{"step": 839088, "time": 41808.342998981476, "episode/length": 201.0, "episode/score": 0.21965413833640923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21965413833640923}
{"step": 839408, "time": 41821.97451686859, "episode/length": 160.0, "episode/score": 0.17911129702770268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17911129702770268}
{"step": 839424, "time": 41824.57320189476, "episode/length": 265.0, "episode/score": 0.30397539294790477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30397539294790477}
{"step": 839624, "time": 41833.850694179535, "episode/length": 186.0, "episode/score": 0.18235422585166816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18235422585166816}
{"step": 840008, "time": 41864.811987400055, "eval_episode/length": 59.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 840008, "time": 41869.8044822216, "eval_episode/length": 143.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 840008, "time": 41872.088260650635, "eval_episode/length": 161.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 840008, "time": 41873.69479942322, "eval_episode/length": 163.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 840008, "time": 41875.19537782669, "eval_episode/length": 164.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 840008, "time": 41877.16085243225, "eval_episode/length": 175.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 840008, "time": 41879.864909887314, "eval_episode/length": 144.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.993103448275862}
{"step": 840008, "time": 41884.562103271484, "eval_episode/length": 281.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9822695035460993}
{"step": 840032, "time": 41885.69622039795, "episode/length": 232.0, "episode/score": 0.2600440800852084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2600440800852084}
{"step": 840080, "time": 41889.14148449898, "episode/length": 161.0, "episode/score": 0.17837460064583865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17837460064583865}
{"step": 840088, "time": 41890.860349178314, "episode/length": 232.0, "episode/score": 0.25248461654882703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25248461654882703}
{"step": 840336, "time": 41901.85089302063, "episode/length": 155.0, "episode/score": 0.17135750647321402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17135750647321402}
{"step": 840832, "time": 41921.82488107681, "episode/length": 150.0, "episode/score": 0.15696556070361112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15696556070361112}
{"step": 840864, "time": 41924.404520750046, "episode/length": 305.0, "episode/score": 0.32764104202396993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32764104202396993}
{"step": 840960, "time": 41929.53562927246, "episode/length": 193.0, "episode/score": 0.21150490050422377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21150490050422377}
{"step": 841048, "time": 41934.11031413078, "episode/length": 202.0, "episode/score": 0.21064252696851327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21064252696851327}
{"step": 841312, "time": 41945.55155324936, "episode/length": 43.0, "episode/score": 0.05101807433675276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05101807433675276}
{"step": 841336, "time": 41947.96184134483, "episode/length": 155.0, "episode/score": 0.17642031341711117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17642031341711117}
{"step": 841480, "time": 41954.79192471504, "episode/length": 174.0, "episode/score": 0.20055455990950577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20055455990950577}
{"step": 842208, "time": 41983.96321058273, "episode/length": 171.0, "episode/score": 0.1688552765708664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1688552765708664}
{"step": 842256, "time": 41987.35522389412, "episode/length": 173.0, "episode/score": 0.19541845243657008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19541845243657008}
{"step": 842552, "time": 41999.71714568138, "episode/length": 154.0, "episode/score": 0.1835416631656699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1835416631656699}
{"step": 842576, "time": 42002.42364549637, "episode/length": 279.0, "episode/score": 0.29323661513717525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29323661513717525}
{"step": 842696, "time": 42008.23623371124, "episode/length": 151.0, "episode/score": 0.1682142582067172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1682142582067172}
{"step": 842840, "time": 42015.12139558792, "episode/length": 223.0, "episode/score": 0.2601195757433743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2601195757433743}
{"step": 843112, "time": 42026.78170084953, "episode/length": 384.0, "episode/score": 0.4162043117803478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4162043117803478}
{"step": 843208, "time": 42031.866505622864, "episode/length": 233.0, "episode/score": 0.26603459965463117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26603459965463117}
{"step": 843816, "time": 42057.72694468498, "episode/length": 194.0, "episode/score": 0.2174720132497896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2174720132497896}
{"step": 844096, "time": 42069.94107270241, "episode/length": 156.0, "episode/score": 0.16703176464307035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16703176464307035}
{"step": 844208, "time": 42075.65052986145, "episode/length": 203.0, "episode/score": 0.23359135565988254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23359135565988254}
{"step": 844232, "time": 42078.28299546242, "episode/length": 191.0, "episode/score": 0.22068083745944023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22068083745944023}
{"step": 844376, "time": 42085.73905134201, "episode/length": 270.0, "episode/score": 0.31423026750053396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31423026750053396}
{"step": 844496, "time": 42091.91274857521, "episode/length": 160.0, "episode/score": 0.17732845044611167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17732845044611167}
{"step": 844592, "time": 42096.96960520744, "episode/length": 184.0, "episode/score": 0.21318104117654002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21318104117654002}
{"step": 844664, "time": 42100.98436713219, "episode/length": 263.0, "episode/score": 0.29567951304852613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29567951304852613}
{"step": 845232, "time": 42123.78506541252, "episode/length": 176.0, "episode/score": 0.18198516474330972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18198516474330972}
{"step": 845280, "time": 42127.213643074036, "episode/length": 147.0, "episode/score": 0.16690849552014697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16690849552014697}
{"step": 845624, "time": 42141.41279673576, "episode/length": 173.0, "episode/score": 0.19922817106726143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19922817106726143}
{"step": 845664, "time": 42144.569459438324, "episode/length": 181.0, "episode/score": 0.21027084245451988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21027084245451988}
{"step": 846080, "time": 42161.87995362282, "episode/length": 185.0, "episode/score": 0.19677734595461516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19677734595461516}
{"step": 846112, "time": 42165.0665974617, "episode/length": 216.0, "episode/score": 0.24496110269046767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24496110269046767}
{"step": 846504, "time": 42181.51259112358, "episode/length": 229.0, "episode/score": 0.25280595255844673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25280595255844673}
{"step": 846528, "time": 42184.17483210564, "episode/length": 161.0, "episode/score": 0.1849903094844194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1849903094844194}
{"step": 846624, "time": 42189.28870224953, "episode/length": 265.0, "episode/score": 0.3111643853108035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3111643853108035}
{"step": 846992, "time": 42204.455421209335, "episode/length": 165.0, "episode/score": 0.17326928183410928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17326928183410928}
{"step": 847344, "time": 42219.35091948509, "episode/length": 214.0, "episode/score": 0.24118694011940534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24118694011940534}
{"step": 847424, "time": 42223.85190939903, "episode/length": 163.0, "episode/score": 0.1690080782154837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1690080782154837}
{"step": 847496, "time": 42227.72117328644, "episode/length": 176.0, "episode/score": 0.18424152041006892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18424152041006892}
{"step": 848200, "time": 42255.410309791565, "episode/length": 211.0, "episode/score": 0.21783780196528824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21783780196528824}
{"step": 848200, "time": 42255.41852903366, "episode/length": 150.0, "episode/score": 0.15831143611603693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15831143611603693}
{"step": 848464, "time": 42269.6042778492, "episode/length": 397.0, "episode/score": 0.4395151304356659, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4395151304356659}
{"step": 848512, "time": 42272.86360192299, "episode/length": 145.0, "episode/score": 0.15953756673707176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15953756673707176}
{"step": 848608, "time": 42278.158153533936, "episode/length": 259.0, "episode/score": 0.28124471773571713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28124471773571713}
{"step": 848736, "time": 42284.30445766449, "episode/length": 263.0, "episode/score": 0.30524182673570976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30524182673570976}
{"step": 848888, "time": 42291.269800662994, "episode/length": 173.0, "episode/score": 0.1854202981958224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1854202981958224}
{"step": 848952, "time": 42295.18788909912, "episode/length": 190.0, "episode/score": 0.20338706934717266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20338706934717266}
{"step": 849712, "time": 42325.29867911339, "episode/length": 188.0, "episode/score": 0.19944526014432995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19944526014432995}
{"step": 849881, "time": 42333.740421295166, "train_stats/sum_log_reward": 2.020792066091948, "train_stats/max_log_achievement_collect_coal": 0.009900990099009901, "train_stats/max_log_achievement_collect_drink": 3.9207920792079207, "train_stats/max_log_achievement_collect_sapling": 0.6732673267326733, "train_stats/max_log_achievement_collect_stone": 0.0297029702970297, "train_stats/max_log_achievement_collect_wood": 1.5445544554455446, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.06930693069306931, "train_stats/max_log_achievement_eat_cow": 0.019801980198019802, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07920792079207921, "train_stats/max_log_achievement_make_wood_sword": 0.039603960396039604, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.33663366336633666, "train_stats/max_log_achievement_place_stone": 0.009900990099009901, "train_stats/max_log_achievement_place_table": 0.21782178217821782, "train_stats/max_log_achievement_wake_up": 0.297029702970297, "train_stats/mean_log_entropy": 2.093368504307058, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.231734148160679, "train/action_min": 0.0, "train/action_std": 4.958891523165966, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008504680398206307, "train/actor_opt_grad_steps": 52390.0, "train/actor_opt_loss": -10.52298871198977, "train/adv_mag": 0.18467124393136483, "train/adv_max": 0.1381680168739454, "train/adv_mean": -7.100091499441486e-06, "train/adv_min": -0.18343223173787274, "train/adv_std": 0.014156352449941822, "train/cont_avg": 0.9945250984251969, "train/cont_loss_mean": 0.00012777658128564193, "train/cont_loss_std": 0.0037940028604430513, "train/cont_neg_acc": 0.9921603559509037, "train/cont_neg_loss": 0.01298071330396615, "train/cont_pos_acc": 0.9999922537428187, "train/cont_pos_loss": 4.910456700387709e-05, "train/cont_pred": 0.9945346408002959, "train/cont_rate": 0.9945250984251969, "train/dyn_loss_mean": 10.933139335452102, "train/dyn_loss_std": 8.724084993047038, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14151926995731715, "train/extr_critic_critic_opt_grad_steps": 52390.0, "train/extr_critic_critic_opt_loss": 12011.23555148868, "train/extr_critic_mag": 0.2822869471677645, "train/extr_critic_max": 0.2822869471677645, "train/extr_critic_mean": 0.22735772311218141, "train/extr_critic_min": 0.0016143190579151544, "train/extr_critic_std": 0.06129505464763153, "train/extr_return_normed_mag": 0.20982851639507324, "train/extr_return_normed_max": 0.20982851639507324, "train/extr_return_normed_mean": 0.15585784813550513, "train/extr_return_normed_min": -0.07045298198780675, "train/extr_return_normed_std": 0.0629518343297046, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28132127072867447, "train/extr_return_raw_max": 0.28132127072867447, "train/extr_return_raw_mean": 0.22735060798370932, "train/extr_return_raw_min": 0.0010397734604482576, "train/extr_return_raw_std": 0.0629518343003716, "train/extr_reward_mag": 0.001361986783545787, "train/extr_reward_max": 0.001361986783545787, "train/extr_reward_mean": 0.00110782808477543, "train/extr_reward_min": 1.0706308319812685e-05, "train/extr_reward_std": 0.00023723762231699273, "train/image_loss_mean": 4.826901895793404, "train/image_loss_std": 10.11965486947007, "train/model_loss_mean": 11.42734621453473, "train/model_loss_std": 13.733099667106087, "train/model_opt_grad_norm": 48.130214375773754, "train/model_opt_grad_steps": 52341.17322834646, "train/model_opt_loss": 17207.176419475887, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1515.748031496063, "train/policy_entropy_mag": 2.763759986622127, "train/policy_entropy_max": 2.763759986622127, "train/policy_entropy_mean": 2.0487888704134725, "train/policy_entropy_min": 0.07989106902221996, "train/policy_entropy_std": 0.6218044009264998, "train/policy_logprob_mag": 7.438299231641874, "train/policy_logprob_max": -0.009526935875357136, "train/policy_logprob_mean": -2.0487175363255297, "train/policy_logprob_min": -7.438299231641874, "train/policy_logprob_std": 1.1829039862775428, "train/policy_randomness_mag": 0.975485989427942, "train/policy_randomness_max": 0.975485989427942, "train/policy_randomness_mean": 0.7231325629189258, "train/policy_randomness_min": 0.028198041373819815, "train/policy_randomness_std": 0.21946966601169016, "train/post_ent_mag": 59.811226341668075, "train/post_ent_max": 59.811226341668075, "train/post_ent_mean": 42.56335761603408, "train/post_ent_min": 19.94744877552423, "train/post_ent_std": 7.339474400197427, "train/prior_ent_mag": 69.59024324191837, "train/prior_ent_max": 69.59024324191837, "train/prior_ent_mean": 53.5560964749554, "train/prior_ent_min": 35.16246631952721, "train/prior_ent_std": 5.2157093971733035, "train/rep_loss_mean": 10.933139335452102, "train/rep_loss_std": 8.724084993047038, "train/reward_avg": 0.0010723023470051176, "train/reward_loss_mean": 0.04043303069284582, "train/reward_loss_std": 0.010989214454990202, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012984397843128115, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04043303092750977, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010723167238390352, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.474999996367842, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.25, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 0.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00010319223656551912, "report/cont_loss_std": 0.0022951404098421335, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0014592064544558525, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.520001913188025e-05, "report/cont_pred": 0.9940571784973145, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 10.81953239440918, "report/dyn_loss_std": 8.680469512939453, "report/image_loss_mean": 5.192689418792725, "report/image_loss_std": 10.783016204833984, "report/model_loss_mean": 11.72659683227539, "report/model_loss_std": 13.91906452178955, "report/post_ent_mag": 61.44384765625, "report/post_ent_max": 61.44384765625, "report/post_ent_mean": 42.850242614746094, "report/post_ent_min": 21.545597076416016, "report/post_ent_std": 8.261250495910645, "report/prior_ent_mag": 69.48928833007812, "report/prior_ent_max": 69.48928833007812, "report/prior_ent_mean": 53.94874572753906, "report/prior_ent_min": 35.675926208496094, "report/prior_ent_std": 5.210219383239746, "report/rep_loss_mean": 10.81953239440918, "report/rep_loss_std": 8.680469512939453, "report/reward_avg": 0.001120788394473493, "report/reward_loss_mean": 0.04208425432443619, "report/reward_loss_std": 0.009131044149398804, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013053417205810547, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04208425059914589, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0011227549985051155, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.1010084310546517e-05, "eval/cont_loss_std": 0.0004018427280243486, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.002891493495553732, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.925280104042031e-06, "eval/cont_pred": 0.9951244592666626, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.723094940185547, "eval/dyn_loss_std": 11.066865921020508, "eval/image_loss_mean": 7.149842262268066, "eval/image_loss_std": 10.993345260620117, "eval/model_loss_mean": 17.800941467285156, "eval/model_loss_std": 16.095523834228516, "eval/post_ent_mag": 58.54850769042969, "eval/post_ent_max": 58.54850769042969, "eval/post_ent_mean": 40.82781982421875, "eval/post_ent_min": 17.030010223388672, "eval/post_ent_std": 7.650373935699463, "eval/prior_ent_mag": 69.48928833007812, "eval/prior_ent_max": 69.48928833007812, "eval/prior_ent_mean": 54.37782287597656, "eval/prior_ent_min": 37.71935272216797, "eval/prior_ent_std": 4.358917236328125, "eval/rep_loss_mean": 16.723094940185547, "eval/rep_loss_std": 11.066865921020508, "eval/reward_avg": 0.007519531063735485, "eval/reward_loss_mean": 0.6172212362289429, "eval/reward_loss_std": 3.4374849796295166, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012853145599365234, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.3573344349861145, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.828420639038086, "eval/reward_pred": 0.0010724309831857681, "eval/reward_rate": 0.0126953125, "replay/size": 849377.0, "replay/inserts": 20304.0, "replay/samples": 20304.0, "replay/insert_wait_avg": 1.3306185051246925e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.841603975769476e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4880.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1754329087304286e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.209077835083, "timer/env.step_count": 2538.0, "timer/env.step_total": 224.13432669639587, "timer/env.step_frac": 0.22408747497225945, "timer/env.step_avg": 0.08831139743750822, "timer/env.step_min": 0.022449016571044922, "timer/env.step_max": 4.011402130126953, "timer/replay._sample_count": 20304.0, "timer/replay._sample_total": 9.933202028274536, "timer/replay._sample_frac": 0.009931125650023692, "timer/replay._sample_avg": 0.0004892238981616694, "timer/replay._sample_min": 0.0003407001495361328, "timer/replay._sample_max": 0.011144161224365234, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3148.0, "timer/agent.policy_total": 50.56126403808594, "timer/agent.policy_frac": 0.05055069500821168, "timer/agent.policy_avg": 0.01606139264233988, "timer/agent.policy_min": 0.009864330291748047, "timer/agent.policy_max": 0.11376428604125977, "timer/dataset_train_count": 1269.0, "timer/dataset_train_total": 0.1388542652130127, "timer/dataset_train_frac": 0.00013882523993239275, "timer/dataset_train_avg": 0.00010942022475414712, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0005939006805419922, "timer/agent.train_count": 1269.0, "timer/agent.train_total": 572.322074174881, "timer/agent.train_frac": 0.5722024393276371, "timer/agent.train_avg": 0.4510024225176367, "timer/agent.train_min": 0.4356837272644043, "timer/agent.train_max": 2.6559360027313232, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48474597930908203, "timer/agent.report_frac": 0.00048464465085469675, "timer/agent.report_avg": 0.24237298965454102, "timer/agent.report_min": 0.23723912239074707, "timer/agent.report_max": 0.24750685691833496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.058547973632812e-05, "timer/dataset_eval_frac": 8.056863462062605e-08, "timer/dataset_eval_avg": 8.058547973632812e-05, "timer/dataset_eval_min": 8.058547973632812e-05, "timer/dataset_eval_max": 8.058547973632812e-05, "fps": 20.299455419770524}
{"step": 850008, "time": 42338.43854546547, "episode/length": 186.0, "episode/score": 0.2128949087186811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2128949087186811}
{"step": 850096, "time": 42364.32209587097, "eval_episode/length": 163.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 850096, "time": 42366.352898836136, "eval_episode/length": 174.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 850096, "time": 42368.04812383652, "eval_episode/length": 175.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 850096, "time": 42369.622099637985, "eval_episode/length": 177.0, "eval_episode/score": 2.1000000163912773, "eval_episode/reward_rate": 0.9887640449438202}
{"step": 850096, "time": 42371.343559741974, "eval_episode/length": 184.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 850096, "time": 42372.98977684975, "eval_episode/length": 186.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 850096, "time": 42375.73236703873, "eval_episode/length": 215.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 850096, "time": 42378.07346868515, "eval_episode/length": 233.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 850264, "time": 42384.10474514961, "episode/length": 257.0, "episode/score": 0.2824612106837776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2824612106837776}
{"step": 850360, "time": 42389.253509521484, "episode/length": 183.0, "episode/score": 0.1867483849096061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1867483849096061}
{"step": 850936, "time": 42412.3701171875, "episode/length": 308.0, "episode/score": 0.3419554303472978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3419554303472978}
{"step": 850968, "time": 42415.5481197834, "episode/length": 278.0, "episode/score": 0.3197819217334654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3197819217334654}
{"step": 851224, "time": 42427.12964010239, "episode/length": 188.0, "episode/score": 0.20402561045284529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20402561045284529}
{"step": 851552, "time": 42441.02850842476, "episode/length": 148.0, "episode/score": 0.15650329167101518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15650329167101518}
{"step": 851840, "time": 42453.222855091095, "episode/length": 196.0, "episode/score": 0.21021610570005578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21021610570005578}
{"step": 851904, "time": 42457.274652957916, "episode/length": 411.0, "episode/score": 0.424064454611198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.424064454611198}
{"step": 852128, "time": 42468.75759077072, "episode/length": 148.0, "episode/score": 0.1658766188561458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1658766188561458}
{"step": 852176, "time": 42471.98455643654, "episode/length": 150.0, "episode/score": 0.15470148467056788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15470148467056788}
{"step": 852616, "time": 42489.704503536224, "episode/length": 54.0, "episode/score": 0.06668560461548623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06668560461548623}
{"step": 852616, "time": 42489.71650195122, "episode/length": 457.0, "episode/score": 0.5205045255897858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.5205045255897858}
{"step": 852648, "time": 42494.03115320206, "episode/length": 329.0, "episode/score": 0.36219005548718997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.36219005548718997}
{"step": 852664, "time": 42496.08254933357, "episode/length": 179.0, "episode/score": 0.19862983694656577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19862983694656577}
{"step": 852920, "time": 42507.20330905914, "episode/length": 37.0, "episode/score": 0.03814880913705565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03814880913705565}
{"step": 853248, "time": 42521.72893047333, "episode/length": 175.0, "episode/score": 0.17789382525916153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17789382525916153}
{"step": 853392, "time": 42528.639619112015, "episode/length": 229.0, "episode/score": 0.2681959777432894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2681959777432894}
{"step": 853400, "time": 42530.17110943794, "episode/length": 186.0, "episode/score": 0.21078815790679073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21078815790679073}
{"step": 853408, "time": 42532.19988536835, "episode/length": 60.0, "episode/score": 0.06589104197200868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06589104197200868}
{"step": 853432, "time": 42534.40064358711, "episode/length": 162.0, "episode/score": 0.16149061388750852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16149061388750852}
{"step": 854008, "time": 42557.71732902527, "episode/length": 169.0, "episode/score": 0.18224355548136373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18224355548136373}
{"step": 854120, "time": 42563.74176120758, "episode/length": 187.0, "episode/score": 0.18065540934458113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18065540934458113}
{"step": 854544, "time": 42581.7805120945, "episode/length": 161.0, "episode/score": 0.19168560246180277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19168560246180277}
{"step": 854656, "time": 42587.541090488434, "episode/length": 157.0, "episode/score": 0.16835981346594053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16835981346594053}
{"step": 854704, "time": 42590.72797679901, "episode/length": 158.0, "episode/score": 0.16964773162499114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16964773162499114}
{"step": 854744, "time": 42593.54620409012, "episode/length": 167.0, "episode/score": 0.17957631729768764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17957631729768764}
{"step": 854792, "time": 42596.872329711914, "episode/length": 172.0, "episode/score": 0.18232676442858065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18232676442858065}
{"step": 855056, "time": 42608.642183065414, "episode/length": 298.0, "episode/score": 0.34194729539467517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34194729539467517}
{"step": 855392, "time": 42622.724516391754, "episode/length": 172.0, "episode/score": 0.1995235625577152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1995235625577152}
{"step": 855776, "time": 42638.64158153534, "episode/length": 206.0, "episode/score": 0.2348010699192855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2348010699192855}
{"step": 856128, "time": 42653.28852438927, "episode/length": 197.0, "episode/score": 0.2138408538744443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2138408538744443}
{"step": 856136, "time": 42654.901263952255, "episode/length": 184.0, "episode/score": 0.18760864652813325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18760864652813325}
{"step": 856256, "time": 42661.10906076431, "episode/length": 188.0, "episode/score": 0.1883924962871788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1883924962871788}
{"step": 856416, "time": 42668.69953942299, "episode/length": 213.0, "episode/score": 0.2529432413825816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2529432413825816}
{"step": 856752, "time": 42682.59782862663, "episode/length": 211.0, "episode/score": 0.23033999275003225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23033999275003225}
{"step": 857016, "time": 42693.70521736145, "episode/length": 202.0, "episode/score": 0.21138482564447258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21138482564447258}
{"step": 857328, "time": 42707.48869013786, "episode/length": 193.0, "episode/score": 0.2171333166797922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2171333166797922}
{"step": 857696, "time": 42722.76456260681, "episode/length": 194.0, "episode/score": 0.21949999639764428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21949999639764428}
{"step": 857712, "time": 42725.03699731827, "episode/length": 197.0, "episode/score": 0.20643200759741376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20643200759741376}
{"step": 857928, "time": 42734.54917907715, "episode/length": 208.0, "episode/score": 0.2308613479744963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2308613479744963}
{"step": 858168, "time": 42745.08089518547, "episode/length": 421.0, "episode/score": 0.42325934340942695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42325934340942695}
{"step": 858240, "time": 42749.60811877251, "episode/length": 227.0, "episode/score": 0.25966666219756007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25966666219756007}
{"step": 858336, "time": 42754.71239876747, "episode/length": 125.0, "episode/score": 0.13717177148419069, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13717177148419069}
{"step": 858488, "time": 42761.85471391678, "episode/length": 216.0, "episode/score": 0.22040301093466041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22040301093466041}
{"step": 859088, "time": 42785.979548454285, "episode/length": 258.0, "episode/score": 0.27685287601798336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27685287601798336}
{"step": 859184, "time": 42791.29271173477, "episode/length": 183.0, "episode/score": 0.18478861386029166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18478861386029166}
{"step": 859192, "time": 42792.97623729706, "episode/length": 186.0, "episode/score": 0.2050515590149189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2050515590149189}
{"step": 859224, "time": 42795.802941799164, "episode/length": 161.0, "episode/score": 0.15941769204391676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15941769204391676}
{"step": 859248, "time": 42798.56417942047, "episode/length": 134.0, "episode/score": 0.1494609488813694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1494609488813694}
{"step": 859816, "time": 42821.15849399567, "episode/length": 165.0, "episode/score": 0.1820796769484332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1820796769484332}
{"step": 859976, "time": 42828.6618244648, "episode/length": 216.0, "episode/score": 0.23034140703998673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23034140703998673}
{"step": 860080, "time": 42850.563938856125, "eval_episode/length": 88.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9438202247191011}
{"step": 860080, "time": 42854.17575454712, "eval_episode/length": 134.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.9925925925925926}
{"step": 860080, "time": 42856.47338724136, "eval_episode/length": 153.0, "eval_episode/score": 3.1000000163912773, "eval_episode/reward_rate": 0.987012987012987}
{"step": 860080, "time": 42858.18649935722, "eval_episode/length": 157.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 860080, "time": 42860.10052037239, "eval_episode/length": 166.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 860080, "time": 42863.28864073753, "eval_episode/length": 207.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 860080, "time": 42864.92644190788, "eval_episode/length": 209.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 860080, "time": 42869.352013111115, "eval_episode/length": 273.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9708029197080292}
{"step": 860488, "time": 42886.29822516441, "episode/length": 154.0, "episode/score": 0.17209902071249417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17209902071249417}
{"step": 860720, "time": 42896.69447994232, "episode/length": 191.0, "episode/score": 0.22137880169339041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22137880169339041}
{"step": 860832, "time": 42902.45788502693, "episode/length": 204.0, "episode/score": 0.2321433526724377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2321433526724377}
{"step": 860904, "time": 42906.49731016159, "episode/length": 209.0, "episode/score": 0.2283957865724915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2283957865724915}
{"step": 861200, "time": 42919.3568072319, "episode/length": 152.0, "episode/score": 0.1786071649476071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1786071649476071}
{"step": 861480, "time": 42931.10951089859, "episode/length": 298.0, "episode/score": 0.32249552169400886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32249552169400886}
{"step": 861736, "time": 42942.34695148468, "episode/length": 424.0, "episode/score": 0.42529333221318666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.42529333221318666}
{"step": 862120, "time": 42958.17831540108, "episode/length": 203.0, "episode/score": 0.2268813098485225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2268813098485225}
{"step": 862280, "time": 42965.76102852821, "episode/length": 180.0, "episode/score": 0.20668883127154913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20668883127154913}
{"step": 862368, "time": 42970.88134407997, "episode/length": 182.0, "episode/score": 0.1810259756348387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1810259756348387}
{"step": 862496, "time": 42977.14997053146, "episode/length": 161.0, "episode/score": 0.18953714645954278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18953714645954278}
{"step": 862576, "time": 42981.66721534729, "episode/length": 136.0, "episode/score": 0.15102358779631686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15102358779631686}
{"step": 862752, "time": 42989.7387509346, "episode/length": 366.0, "episode/score": 0.39685771903509703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39685771903509703}
{"step": 862872, "time": 42995.58170390129, "episode/length": 268.0, "episode/score": 0.3065095964950615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3065095964950615}
{"step": 863208, "time": 43009.84263753891, "episode/length": 183.0, "episode/score": 0.19183227041480677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19183227041480677}
{"step": 863480, "time": 43021.47619795799, "episode/length": 169.0, "episode/score": 0.19063473433106992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19063473433106992}
{"step": 863576, "time": 43026.5157828331, "episode/length": 161.0, "episode/score": 0.16924823097906483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16924823097906483}
{"step": 863592, "time": 43028.852194070816, "episode/length": 152.0, "episode/score": 0.15764260854257373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15764260854257373}
{"step": 864016, "time": 43046.73888349533, "episode/length": 179.0, "episode/score": 0.19341281940319277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19341281940319277}
{"step": 864360, "time": 43061.02093434334, "episode/length": 185.0, "episode/score": 0.21788136533564284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21788136533564284}
{"step": 864360, "time": 43061.0294315815, "episode/length": 200.0, "episode/score": 0.20714136468654942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20714136468654942}
{"step": 864544, "time": 43071.33855891228, "episode/length": 118.0, "episode/score": 0.1295707325261901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1295707325261901}
{"step": 864752, "time": 43080.62305021286, "episode/length": 158.0, "episode/score": 0.17081054416075858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17081054416075858}
{"step": 864776, "time": 43082.842747449875, "episode/length": 149.0, "episode/score": 0.16291153442148243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16291153442148243}
{"step": 865160, "time": 43098.7667992115, "episode/length": 243.0, "episode/score": 0.262538290137627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.262538290137627}
{"step": 865368, "time": 43108.145833969116, "episode/length": 73.0, "episode/score": 0.08565079202526249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08565079202526249}
{"step": 865584, "time": 43118.182087183, "episode/length": 385.0, "episode/score": 0.43508174669000255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.43508174669000255}
{"step": 865824, "time": 43129.084174871445, "episode/length": 182.0, "episode/score": 0.20895832989481278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20895832989481278}
{"step": 865984, "time": 43136.65307545662, "episode/length": 179.0, "episode/score": 0.2156041623384226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2156041623384226}
{"step": 866016, "time": 43139.32996034622, "episode/length": 206.0, "episode/score": 0.2340844116260996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2340844116260996}
{"step": 866112, "time": 43144.61850690842, "episode/length": 169.0, "episode/score": 0.18740535768301925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18740535768301925}
{"step": 866504, "time": 43160.533346414566, "episode/length": 167.0, "episode/score": 0.18104050686088158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18104050686088158}
{"step": 866576, "time": 43164.8970208168, "episode/length": 150.0, "episode/score": 0.17397641534626018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17397641534626018}
{"step": 866744, "time": 43172.429767370224, "episode/length": 340.0, "episode/score": 0.3891240010561887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3891240010561887}
{"step": 866880, "time": 43179.3383936882, "episode/length": 161.0, "episode/score": 0.16701515197200933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16701515197200933}
{"step": 867048, "time": 43186.87548971176, "episode/length": 152.0, "episode/score": 0.16945408788888017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16945408788888017}
{"step": 867120, "time": 43191.369406461716, "episode/length": 141.0, "episode/score": 0.13792632757031242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13792632757031242}
{"step": 867520, "time": 43208.027455329895, "episode/length": 175.0, "episode/score": 0.20644728090337594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20644728090337594}
{"step": 867736, "time": 43217.435584545135, "episode/length": 153.0, "episode/score": 0.17146231210426777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17146231210426777}
{"step": 868272, "time": 43239.398445129395, "episode/length": 211.0, "episode/score": 0.23781802648954908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23781802648954908}
{"step": 868376, "time": 43246.239874601364, "episode/length": 156.0, "episode/score": 0.1814267543868482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1814267543868482}
{"step": 868488, "time": 43252.53992533684, "episode/length": 200.0, "episode/score": 0.21368987146888685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21368987146888685}
{"step": 868536, "time": 43255.83022212982, "episode/length": 185.0, "episode/score": 0.20623709340725327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20623709340725327}
{"step": 868552, "time": 43258.036019563675, "episode/length": 225.0, "episode/score": 0.2518997748102265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2518997748102265}
{"step": 868728, "time": 43266.320650815964, "episode/length": 338.0, "episode/score": 0.3608055485965451, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3608055485965451}
{"step": 869088, "time": 43281.66789674759, "episode/length": 195.0, "episode/score": 0.2152404108128394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2152404108128394}
{"step": 869600, "time": 43302.29786849022, "episode/length": 165.0, "episode/score": 0.17738352036394645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17738352036394645}
{"step": 869624, "time": 43304.57595396042, "episode/length": 155.0, "episode/score": 0.17395706308889203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17395706308889203}
{"step": 869792, "time": 43312.43381047249, "episode/length": 256.0, "episode/score": 0.29613725796843937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29613725796843937}
{"step": 869920, "time": 43318.86936402321, "episode/length": 148.0, "episode/score": 0.16683636267407564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16683636267407564}
{"step": 869968, "time": 43322.26720118523, "episode/length": 176.0, "episode/score": 0.189593033552228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.189593033552228}
{"step": 870064, "time": 43341.858365535736, "eval_episode/length": 46.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9148936170212766}
{"step": 870064, "time": 43348.34002017975, "eval_episode/length": 163.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 870064, "time": 43350.31500291824, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 870064, "time": 43352.45316839218, "eval_episode/length": 184.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 870064, "time": 43354.98937416077, "eval_episode/length": 206.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.966183574879227}
{"step": 870064, "time": 43356.6662607193, "eval_episode/length": 213.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 870064, "time": 43358.44875597954, "eval_episode/length": 218.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 870064, "time": 43360.37222766876, "eval_episode/length": 177.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 870065, "time": 43360.996833086014, "train_stats/sum_log_reward": 1.818446571821148, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.689320388349515, "train_stats/max_log_achievement_collect_sapling": 0.5631067961165048, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.2815533980582525, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.038834951456310676, "train_stats/max_log_achievement_eat_cow": 0.009708737864077669, "train_stats/max_log_achievement_make_wood_pickaxe": 0.04854368932038835, "train_stats/max_log_achievement_make_wood_sword": 0.009708737864077669, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.33980582524271846, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.23300970873786409, "train_stats/max_log_achievement_wake_up": 0.2815533980582524, "train_stats/mean_log_entropy": 2.1412293610063573, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.370575435577877, "train/action_min": 0.0, "train/action_std": 4.987301031748454, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008114070010681948, "train/actor_opt_grad_steps": 53655.0, "train/actor_opt_loss": -6.402850830602268, "train/adv_mag": 0.1873877720818633, "train/adv_max": 0.14223424593607584, "train/adv_mean": 0.00022580886151163647, "train/adv_min": -0.18542179619036023, "train/adv_std": 0.013958900531251279, "train/cont_avg": 0.9945126488095238, "train/cont_loss_mean": 0.00019419722719561154, "train/cont_loss_std": 0.005837871034722346, "train/cont_neg_acc": 0.9932256255831037, "train/cont_neg_loss": 0.01699260599503436, "train/cont_pos_acc": 0.9999766122727167, "train/cont_pos_loss": 7.620053057584145e-05, "train/cont_pred": 0.994519566259687, "train/cont_rate": 0.9945126488095238, "train/dyn_loss_mean": 10.749467743767632, "train/dyn_loss_std": 8.647737476560804, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13545748139066355, "train/extr_critic_critic_opt_grad_steps": 53655.0, "train/extr_critic_critic_opt_loss": 12126.93566313244, "train/extr_critic_mag": 0.28193615353296675, "train/extr_critic_max": 0.28193615353296675, "train/extr_critic_mean": 0.2332789900283965, "train/extr_critic_min": 0.0014562833876836869, "train/extr_critic_std": 0.05816746260675173, "train/extr_return_normed_mag": 0.20005835971188923, "train/extr_return_normed_max": 0.20005835971188923, "train/extr_return_normed_mean": 0.15212420285457656, "train/extr_return_normed_min": -0.0803528180907643, "train/extr_return_normed_std": 0.05991151441066038, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28143902052016484, "train/extr_return_raw_max": 0.28143902052016484, "train/extr_return_raw_mean": 0.23350486762466885, "train/extr_return_raw_min": 0.001027842362721761, "train/extr_return_raw_std": 0.05991151472110124, "train/extr_reward_mag": 0.0013524927790202791, "train/extr_reward_max": 0.0013524927790202791, "train/extr_reward_mean": 0.0010986699194218668, "train/extr_reward_min": 1.075721922374907e-05, "train/extr_reward_std": 0.00023946035001981293, "train/image_loss_mean": 4.662853698881846, "train/image_loss_std": 9.885666828306894, "train/model_loss_mean": 11.15298561065916, "train/model_loss_std": 13.483327002752395, "train/model_opt_grad_norm": 49.97581053537036, "train/model_opt_grad_steps": 53604.87301587302, "train/model_opt_loss": 15009.246023995536, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1349.2063492063492, "train/policy_entropy_mag": 2.764375881543235, "train/policy_entropy_max": 2.764375881543235, "train/policy_entropy_mean": 2.061525657063439, "train/policy_entropy_min": 0.07970516460518988, "train/policy_entropy_std": 0.6418373345855682, "train/policy_logprob_mag": 7.438298634120396, "train/policy_logprob_max": -0.009502026792024337, "train/policy_logprob_mean": -2.0609865075065974, "train/policy_logprob_min": -7.438298634120396, "train/policy_logprob_std": 1.1760114757787614, "train/policy_randomness_mag": 0.9757033718956841, "train/policy_randomness_max": 0.9757033718956841, "train/policy_randomness_mean": 0.7276280867674995, "train/policy_randomness_min": 0.028132425384625556, "train/policy_randomness_std": 0.2265404130494784, "train/post_ent_mag": 59.45840293642075, "train/post_ent_max": 59.45840293642075, "train/post_ent_mean": 42.5960817488413, "train/post_ent_min": 19.909114663563077, "train/post_ent_std": 7.240202355006384, "train/prior_ent_mag": 69.52368672688802, "train/prior_ent_max": 69.52368672688802, "train/prior_ent_mean": 53.45232167319646, "train/prior_ent_min": 34.552830832345144, "train/prior_ent_std": 5.237613500110687, "train/rep_loss_mean": 10.749467743767632, "train/rep_loss_std": 8.647737476560804, "train/reward_avg": 0.001067153654903883, "train/reward_loss_mean": 0.040257061994264993, "train/reward_loss_std": 0.011154966251481147, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012960433959960938, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04025706208296238, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010662338158692278, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 2.2666666504616537, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.4166666666666665, "eval_stats/max_log_achievement_collect_sapling": 0.9166666666666666, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.041666666666666664, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.041666666666666664, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.375, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.9805191186605953e-05, "report/cont_loss_std": 0.0003900280862580985, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.0623405109508894e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.9903869542758912e-05, "report/cont_pred": 0.9941209554672241, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.474784851074219, "report/dyn_loss_std": 8.425045013427734, "report/image_loss_mean": 5.503375053405762, "report/image_loss_std": 7.9161906242370605, "report/model_loss_mean": 12.430113792419434, "report/model_loss_std": 11.472530364990234, "report/post_ent_mag": 59.05904769897461, "report/post_ent_max": 59.05904769897461, "report/post_ent_mean": 41.965370178222656, "report/post_ent_min": 19.63742446899414, "report/post_ent_std": 6.905445575714111, "report/prior_ent_mag": 69.43321228027344, "report/prior_ent_max": 69.43321228027344, "report/prior_ent_mean": 53.27525329589844, "report/prior_ent_min": 37.02763366699219, "report/prior_ent_std": 5.323551654815674, "report/rep_loss_mean": 11.474784851074219, "report/rep_loss_std": 8.425045013427734, "report/reward_avg": 0.0011128431651741266, "report/reward_loss_mean": 0.04184754192829132, "report/reward_loss_std": 0.00929624680429697, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012803077697753906, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04184754192829132, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0011265064822509885, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 4.126053681829944e-06, "eval/cont_loss_std": 4.271562283975072e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.8258402860737988e-06, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.135074050282128e-06, "eval/cont_pred": 0.9960896968841553, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.532597541809082, "eval/dyn_loss_std": 9.90503215789795, "eval/image_loss_mean": 9.412757873535156, "eval/image_loss_std": 17.810983657836914, "eval/model_loss_mean": 19.395721435546875, "eval/model_loss_std": 22.19959831237793, "eval/post_ent_mag": 57.32792663574219, "eval/post_ent_max": 57.32792663574219, "eval/post_ent_mean": 40.557106018066406, "eval/post_ent_min": 19.14966583251953, "eval/post_ent_std": 6.828014373779297, "eval/prior_ent_mag": 69.43321228027344, "eval/prior_ent_max": 69.43321228027344, "eval/prior_ent_mean": 54.086158752441406, "eval/prior_ent_min": 35.189884185791016, "eval/prior_ent_std": 4.929950714111328, "eval/rep_loss_mean": 15.532597541809082, "eval/rep_loss_std": 9.90503215789795, "eval/reward_avg": 0.007128905970603228, "eval/reward_loss_mean": 0.6634029150009155, "eval/reward_loss_std": 3.5279362201690674, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013003349304199219, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.44387903809547424, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.879562377929688, "eval/reward_pred": 0.0010754050454124808, "eval/reward_rate": 0.0107421875, "replay/size": 869561.0, "replay/inserts": 20184.0, "replay/samples": 20176.0, "replay/insert_wait_avg": 1.3625201279333646e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.941456279709262e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5864.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.176480219113713e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1027.2387187480927, "timer/env.step_count": 2523.0, "timer/env.step_total": 225.89548802375793, "timer/env.step_frac": 0.21990554279248672, "timer/env.step_avg": 0.08953447801179466, "timer/env.step_min": 0.022711753845214844, "timer/env.step_max": 3.207470178604126, "timer/replay._sample_count": 20176.0, "timer/replay._sample_total": 10.003004312515259, "timer/replay._sample_frac": 0.009737760201159506, "timer/replay._sample_avg": 0.0004957872874957999, "timer/replay._sample_min": 0.00040411949157714844, "timer/replay._sample_max": 0.024373769760131836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3256.0, "timer/agent.policy_total": 54.11857080459595, "timer/agent.policy_frac": 0.05268353871099296, "timer/agent.policy_avg": 0.01662118267954421, "timer/agent.policy_min": 0.009662389755249023, "timer/agent.policy_max": 0.1258411407470703, "timer/dataset_train_count": 1261.0, "timer/dataset_train_total": 0.13781046867370605, "timer/dataset_train_frac": 0.00013415622499282078, "timer/dataset_train_avg": 0.00010928665239786365, "timer/dataset_train_min": 9.417533874511719e-05, "timer/dataset_train_max": 0.00034332275390625, "timer/agent.train_count": 1261.0, "timer/agent.train_total": 567.2655189037323, "timer/agent.train_frac": 0.5522236541035614, "timer/agent.train_avg": 0.4498537025406283, "timer/agent.train_min": 0.4352264404296875, "timer/agent.train_max": 1.1641223430633545, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48279762268066406, "timer/agent.report_frac": 0.0004699955461852674, "timer/agent.report_avg": 0.24139881134033203, "timer/agent.report_min": 0.23380017280578613, "timer/agent.report_max": 0.24899744987487793, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.082389831542969e-05, "timer/dataset_eval_frac": 7.868073587990403e-08, "timer/dataset_eval_avg": 8.082389831542969e-05, "timer/dataset_eval_min": 8.082389831542969e-05, "timer/dataset_eval_max": 8.082389831542969e-05, "fps": 19.648552646160237}
{"step": 870144, "time": 43364.29366803169, "episode/length": 200.0, "episode/score": 0.23800877104804385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23800877104804385}
{"step": 870736, "time": 43388.33557486534, "episode/length": 280.0, "episode/score": 0.3269226131524192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3269226131524192}
{"step": 870744, "time": 43390.01245903969, "episode/length": 118.0, "episode/score": 0.13601514906258672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13601514906258672}
{"step": 870928, "time": 43398.59542131424, "episode/length": 229.0, "episode/score": 0.26524568360764533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26524568360764533}
{"step": 871152, "time": 43408.58498954773, "episode/length": 193.0, "episode/score": 0.20678958533972036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20678958533972036}
{"step": 871192, "time": 43411.461211919785, "episode/length": 195.0, "episode/score": 0.21902111564850202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21902111564850202}
{"step": 871248, "time": 43415.23655629158, "episode/length": 159.0, "episode/score": 0.1582120798411779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1582120798411779}
{"step": 871840, "time": 43439.21166753769, "episode/length": 211.0, "episode/score": 0.2322130838292651, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2322130838292651}
{"step": 872000, "time": 43446.70419764519, "episode/length": 259.0, "episode/score": 0.287460427138285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.287460427138285}
{"step": 872312, "time": 43460.012912750244, "episode/length": 196.0, "episode/score": 0.2031464703668462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2031464703668462}
{"step": 872320, "time": 43462.025611400604, "episode/length": 173.0, "episode/score": 0.18126226836830028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18126226836830028}
{"step": 872536, "time": 43471.46844673157, "episode/length": 223.0, "episode/score": 0.24979550936404848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24979550936404848}
{"step": 872600, "time": 43475.51925611496, "episode/length": 168.0, "episode/score": 0.16329911338652892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16329911338652892}
{"step": 872608, "time": 43477.72654175758, "episode/length": 181.0, "episode/score": 0.2210416621528566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2210416621528566}
{"step": 872776, "time": 43485.2923412323, "episode/length": 197.0, "episode/score": 0.21110778458933055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21110778458933055}
{"step": 873216, "time": 43503.61808347702, "episode/length": 151.0, "episode/score": 0.18145832984009758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18145832984009758}
{"step": 873224, "time": 43505.28578257561, "episode/length": 172.0, "episode/score": 0.1827945769600774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1827945769600774}
{"step": 873896, "time": 43532.05570435524, "episode/length": 169.0, "episode/score": 0.1920718014898739, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1920718014898739}
{"step": 874088, "time": 43540.96451950073, "episode/length": 184.0, "episode/score": 0.20512594347746926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20512594347746926}
{"step": 874096, "time": 43543.12604475021, "episode/length": 221.0, "episode/score": 0.24113227300949802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24113227300949802}
{"step": 874240, "time": 43550.22186255455, "episode/length": 204.0, "episode/score": 0.22004521105918684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22004521105918684}
{"step": 874272, "time": 43553.03257393837, "episode/length": 186.0, "episode/score": 0.20346429703386093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20346429703386093}
{"step": 874544, "time": 43564.78026294708, "episode/length": 164.0, "episode/score": 0.19070833013392985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19070833013392985}
{"step": 875064, "time": 43585.45260357857, "episode/length": 145.0, "episode/score": 0.148527555000328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.148527555000328}
{"step": 875064, "time": 43585.4622066021, "episode/length": 230.0, "episode/score": 0.27546473952497763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27546473952497763}
{"step": 875544, "time": 43606.83717560768, "episode/length": 181.0, "episode/score": 0.2069999964442104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2069999964442104}
{"step": 875616, "time": 43611.34697961807, "episode/length": 412.0, "episode/score": 0.4532450005872306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4532450005872306}
{"step": 875632, "time": 43613.552284002304, "episode/length": 191.0, "episode/score": 0.20036228526168998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20036228526168998}
{"step": 875680, "time": 43616.8763628006, "episode/length": 175.0, "episode/score": 0.18479103844674682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18479103844674682}
{"step": 875872, "time": 43625.689484119415, "episode/length": 165.0, "episode/score": 0.16934428580771055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16934428580771055}
{"step": 876168, "time": 43638.30304002762, "episode/length": 240.0, "episode/score": 0.2670912358280475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2670912358280475}
{"step": 876688, "time": 43661.16327095032, "episode/length": 202.0, "episode/score": 0.22077212800013513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22077212800013513}
{"step": 876816, "time": 43667.52863049507, "episode/length": 147.0, "episode/score": 0.15071676170373394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15071676170373394}
{"step": 877040, "time": 43677.45707464218, "episode/length": 169.0, "episode/score": 0.20648065214027156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20648065214027156}
{"step": 877056, "time": 43679.586678504944, "episode/length": 188.0, "episode/score": 0.21263457239001582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21263457239001582}
{"step": 877136, "time": 43684.10849046707, "episode/length": 189.0, "episode/score": 0.21471339353865915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21471339353865915}
{"step": 877240, "time": 43689.418197155, "episode/length": 170.0, "episode/score": 0.20474665561050642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20474665561050642}
{"step": 877248, "time": 43691.42392754555, "episode/length": 272.0, "episode/score": 0.318744260249332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.318744260249332}
{"step": 877664, "time": 43708.49675369263, "episode/length": 186.0, "episode/score": 0.20425594912376255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20425594912376255}
{"step": 878120, "time": 43727.03490304947, "episode/length": 162.0, "episode/score": 0.18724999675760046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18724999675760046}
{"step": 878360, "time": 43737.82818651199, "episode/length": 208.0, "episode/score": 0.23156862912583165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23156862912583165}
{"step": 878384, "time": 43740.848430395126, "episode/length": 141.0, "episode/score": 0.16737499687587842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16737499687587842}
{"step": 878472, "time": 43745.390377521515, "episode/length": 178.0, "episode/score": 0.20312752189784078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20312752189784078}
{"step": 878616, "time": 43752.3219537735, "episode/length": 184.0, "episode/score": 0.1992591606322094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1992591606322094}
{"step": 878688, "time": 43756.756432294846, "episode/length": 203.0, "episode/score": 0.21933826740132645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21933826740132645}
{"step": 879368, "time": 43783.74165701866, "episode/length": 125.0, "episode/score": 0.148291663848795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.148291663848795}
{"step": 879392, "time": 43786.341202259064, "episode/length": 114.0, "episode/score": 0.13355484903877368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13355484903877368}
{"step": 879688, "time": 43798.967693805695, "episode/length": 162.0, "episode/score": 0.1939114546548808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1939114546548808}
{"step": 879792, "time": 43804.81717586517, "episode/length": 318.0, "episode/score": 0.3607890692874207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3607890692874207}
{"step": 879840, "time": 43808.21474194527, "episode/length": 271.0, "episode/score": 0.3209404702356551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3209404702356551}
{"step": 879896, "time": 43811.681503772736, "episode/length": 159.0, "episode/score": 0.17566482479378465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17566482479378465}
{"step": 880048, "time": 43838.218587875366, "eval_episode/length": 155.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 880048, "time": 43840.15180134773, "eval_episode/length": 164.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 880048, "time": 43841.90747952461, "eval_episode/length": 171.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 880048, "time": 43843.70500302315, "eval_episode/length": 176.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 880048, "time": 43845.45481324196, "eval_episode/length": 182.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.994535519125683}
{"step": 880048, "time": 43847.884160518646, "eval_episode/length": 204.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 880048, "time": 43849.99720478058, "eval_episode/length": 219.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 880048, "time": 43855.36525130272, "eval_episode/length": 310.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9967845659163987}
{"step": 880096, "time": 43857.15705704689, "episode/length": 175.0, "episode/score": 0.1696013508226315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1696013508226315}
{"step": 880616, "time": 43878.07423830032, "episode/length": 311.0, "episode/score": 0.3602796527775354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3602796527775354}
{"step": 880624, "time": 43880.09498500824, "episode/length": 153.0, "episode/score": 0.16288159512987477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16288159512987477}
{"step": 880800, "time": 43888.12184858322, "episode/length": 178.0, "episode/score": 0.18693299058941193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18693299058941193}
{"step": 881304, "time": 43908.44499731064, "episode/length": 188.0, "episode/score": 0.2197834325088479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2197834325088479}
{"step": 881344, "time": 43911.59078884125, "episode/length": 187.0, "episode/score": 0.21998271462871344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21998271462871344}
{"step": 881376, "time": 43914.442002534866, "episode/length": 184.0, "episode/score": 0.2122039843306993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2122039843306993}
{"step": 881824, "time": 43933.175334692, "episode/length": 150.0, "episode/score": 0.16855139396830054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16855139396830054}
{"step": 882152, "time": 43947.43091726303, "episode/length": 168.0, "episode/score": 0.18253617702794145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18253617702794145}
{"step": 882184, "time": 43950.11375761032, "episode/length": 311.0, "episode/score": 0.3511269980335783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3511269980335783}
{"step": 882288, "time": 43955.861901044846, "episode/length": 207.0, "episode/score": 0.23825471254531294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23825471254531294}
{"step": 882720, "time": 43973.85216188431, "episode/length": 176.0, "episode/score": 0.20374132735014427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20374132735014427}
{"step": 882904, "time": 43981.961416721344, "episode/length": 350.0, "episode/score": 0.3913132032575959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3913132032575959}
{"step": 882976, "time": 43986.39602804184, "episode/length": 203.0, "episode/score": 0.2134895913022774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2134895913022774}
{"step": 883080, "time": 43991.89233279228, "episode/length": 156.0, "episode/score": 0.17804417513070803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17804417513070803}
{"step": 883616, "time": 44013.73970937729, "episode/length": 182.0, "episode/score": 0.18193429617895163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18193429617895163}
{"step": 883696, "time": 44018.4133541584, "episode/length": 188.0, "episode/score": 0.21644899620150682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21644899620150682}
{"step": 883856, "time": 44026.24210500717, "episode/length": 195.0, "episode/score": 0.22482525438863377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22482525438863377}
{"step": 883864, "time": 44028.18739414215, "episode/length": 310.0, "episode/score": 0.3423088962681504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3423088962681504}
{"step": 884184, "time": 44042.05084466934, "episode/length": 159.0, "episode/score": 0.18202792611737095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18202792611737095}
{"step": 884320, "time": 44048.95465731621, "episode/length": 199.0, "episode/score": 0.2121365378043265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2121365378043265}
{"step": 884368, "time": 44052.32250332832, "episode/length": 160.0, "episode/score": 0.19454166269861162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19454166269861162}
{"step": 884776, "time": 44070.44451332092, "episode/length": 224.0, "episode/score": 0.24044773869536584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24044773869536584}
{"step": 884944, "time": 44078.69533395767, "episode/length": 155.0, "episode/score": 0.16169885236104165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16169885236104165}
{"step": 885152, "time": 44088.06390166283, "episode/length": 161.0, "episode/score": 0.17388903783921705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17388903783921705}
{"step": 885320, "time": 44095.67387533188, "episode/length": 212.0, "episode/score": 0.2330214729436193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2330214729436193}
{"step": 885456, "time": 44102.601019620895, "episode/length": 158.0, "episode/score": 0.18560364332461177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18560364332461177}
{"step": 885576, "time": 44108.50396513939, "episode/length": 213.0, "episode/score": 0.24017692669440294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24017692669440294}
{"step": 885704, "time": 44114.84172415733, "episode/length": 172.0, "episode/score": 0.17868572845418385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17868572845418385}
{"step": 885984, "time": 44127.26589870453, "episode/length": 103.0, "episode/score": 0.12129166448721662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12129166448721662}
{"step": 886088, "time": 44133.13418006897, "episode/length": 163.0, "episode/score": 0.18637861441402492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18637861441402492}
{"step": 886160, "time": 44138.18208408356, "episode/length": 151.0, "episode/score": 0.17717903975517402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17717903975517402}
{"step": 886312, "time": 44145.73402714729, "episode/length": 242.0, "episode/score": 0.27768915892556834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27768915892556834}
{"step": 886632, "time": 44159.30809760094, "episode/length": 146.0, "episode/score": 0.16500629886468232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16500629886468232}
{"step": 887016, "time": 44175.26679825783, "episode/length": 211.0, "episode/score": 0.2265066041427417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2265066041427417}
{"step": 887072, "time": 44179.205199956894, "episode/length": 186.0, "episode/score": 0.2308333283290267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2308333283290267}
{"step": 887328, "time": 44190.4006459713, "episode/length": 202.0, "episode/score": 0.23190288676778437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23190288676778437}
{"step": 887456, "time": 44196.613914728165, "episode/length": 183.0, "episode/score": 0.21422400526626006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21422400526626006}
{"step": 887528, "time": 44200.75180029869, "episode/length": 151.0, "episode/score": 0.17360540980735095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17360540980735095}
{"step": 887696, "time": 44208.87778496742, "episode/length": 191.0, "episode/score": 0.20464041522973275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20464041522973275}
{"step": 887832, "time": 44215.266708135605, "episode/length": 217.0, "episode/score": 0.2585450484548346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2585450484548346}
{"step": 888056, "time": 44225.06740140915, "episode/length": 177.0, "episode/score": 0.19110209912196297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19110209912196297}
{"step": 888304, "time": 44236.30407190323, "episode/length": 153.0, "episode/score": 0.16809068639122415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16809068639122415}
{"step": 888384, "time": 44240.76886510849, "episode/length": 170.0, "episode/score": 0.19494600982761767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19494600982761767}
{"step": 888872, "time": 44260.50594806671, "episode/length": 167.0, "episode/score": 0.17966780562164786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17966780562164786}
{"step": 889032, "time": 44267.921766757965, "episode/length": 166.0, "episode/score": 0.18814632299381628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18814632299381628}
{"step": 889352, "time": 44281.65469455719, "episode/length": 161.0, "episode/score": 0.1693077187428571, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1693077187428571}
{"step": 889496, "time": 44288.72702097893, "episode/length": 148.0, "episode/score": 0.1631397696746717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1631397696746717}
{"step": 889592, "time": 44293.85645508766, "episode/length": 282.0, "episode/score": 0.32140804413575097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32140804413575097}
{"step": 889672, "time": 44298.32843899727, "episode/length": 229.0, "episode/score": 0.2599183432275822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2599183432275822}
{"step": 889808, "time": 44305.25567007065, "episode/length": 293.0, "episode/score": 0.32884174235641694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32884174235641694}
{"step": 889896, "time": 44309.94129395485, "episode/length": 188.0, "episode/score": 0.2055806460484746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2055806460484746}
{"step": 890032, "time": 44338.044137477875, "eval_episode/length": 155.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 890032, "time": 44339.77671480179, "eval_episode/length": 159.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 890032, "time": 44341.57477784157, "eval_episode/length": 166.0, "eval_episode/score": -0.8999999910593033, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 890032, "time": 44343.32869410515, "eval_episode/length": 171.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 890032, "time": 44344.94437289238, "eval_episode/length": 174.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 890032, "time": 44347.19072794914, "eval_episode/length": 189.0, "eval_episode/score": 1.100000023841858, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 890032, "time": 44349.628950595856, "eval_episode/length": 57.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9137931034482759}
{"step": 890032, "time": 44349.6368021965, "eval_episode/length": 213.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 890120, "time": 44352.77198600769, "episode/length": 77.0, "episode/score": 0.07317989287048476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07317989287048476}
{"step": 890281, "time": 44361.298725128174, "train_stats/sum_log_reward": 1.7538461161490817, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.855769230769231, "train_stats/max_log_achievement_collect_sapling": 0.5576923076923077, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.6538461538461537, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.057692307692307696, "train_stats/max_log_achievement_eat_cow": 0.019230769230769232, "train_stats/max_log_achievement_make_wood_pickaxe": 0.038461538461538464, "train_stats/max_log_achievement_make_wood_sword": 0.04807692307692308, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.3173076923076923, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.23076923076923078, "train_stats/max_log_achievement_wake_up": 0.23076923076923078, "train_stats/mean_log_entropy": 2.1121858748105855, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.380781870039683, "train/action_min": 0.0, "train/action_std": 5.060259769833277, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008374456804068316, "train/actor_opt_grad_steps": 54915.0, "train/actor_opt_loss": -9.67517619745599, "train/adv_mag": 0.1838538180149737, "train/adv_max": 0.136994770535874, "train/adv_mean": -6.0307135220408245e-05, "train/adv_min": -0.18175289017103968, "train/adv_std": 0.014073056057982501, "train/cont_avg": 0.9945359002976191, "train/cont_loss_mean": 0.00022504261830684908, "train/cont_loss_std": 0.006699592213364788, "train/cont_neg_acc": 0.993795667375837, "train/cont_neg_loss": 0.02260241970411121, "train/cont_pos_acc": 0.9999843963554927, "train/cont_pos_loss": 5.705167197243821e-05, "train/cont_pred": 0.9945424889761304, "train/cont_rate": 0.9945359002976191, "train/dyn_loss_mean": 10.895904730236719, "train/dyn_loss_std": 8.668973574562678, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13154347016224785, "train/extr_critic_critic_opt_grad_steps": 54915.0, "train/extr_critic_critic_opt_loss": 12186.476236979166, "train/extr_critic_mag": 0.2863866166462974, "train/extr_critic_max": 0.2863866166462974, "train/extr_critic_mean": 0.23533067000763758, "train/extr_critic_min": 0.0017462949904184493, "train/extr_critic_std": 0.06049155778000279, "train/extr_return_normed_mag": 0.2081336166177477, "train/extr_return_normed_max": 0.2081336166177477, "train/extr_return_normed_mean": 0.157503560540222, "train/extr_return_normed_min": -0.07675109667673943, "train/extr_return_normed_std": 0.06242869903762189, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28590048802277396, "train/extr_return_raw_max": 0.28590048802277396, "train/extr_return_raw_mean": 0.2352704362027229, "train/extr_return_raw_min": 0.001015774787418426, "train/extr_return_raw_std": 0.06242869906718769, "train/extr_reward_mag": 0.0013634505726042249, "train/extr_reward_max": 0.0013634505726042249, "train/extr_reward_mean": 0.0011061648819743403, "train/extr_reward_min": 1.1106332143147787e-05, "train/extr_reward_std": 0.00023820960239621824, "train/image_loss_mean": 4.707657993785919, "train/image_loss_std": 9.808477432008774, "train/model_loss_mean": 11.285901031796895, "train/model_loss_std": 13.44671923016745, "train/model_opt_grad_norm": 50.07549983215332, "train/model_opt_grad_steps": 54863.72222222222, "train/model_opt_loss": 15033.917495969743, "train/model_opt_model_opt_grad_overflow": 0.007936507936507936, "train/model_opt_model_opt_grad_scale": 1319.4444444444443, "train/policy_entropy_mag": 2.7647614006012207, "train/policy_entropy_max": 2.7647614006012207, "train/policy_entropy_mean": 2.048366177649725, "train/policy_entropy_min": 0.07961470893924198, "train/policy_entropy_std": 0.6487788505970485, "train/policy_logprob_mag": 7.438262337730045, "train/policy_logprob_max": -0.009489883979161581, "train/policy_logprob_mean": -2.048239816748907, "train/policy_logprob_min": -7.438262337730045, "train/policy_logprob_std": 1.1838782174246651, "train/policy_randomness_mag": 0.97583944646139, "train/policy_randomness_max": 0.97583944646139, "train/policy_randomness_mean": 0.7229833678593711, "train/policy_randomness_min": 0.028100498375438508, "train/policy_randomness_std": 0.22899046481128724, "train/post_ent_mag": 59.634447763836576, "train/post_ent_max": 59.634447763836576, "train/post_ent_mean": 42.59599270896306, "train/post_ent_min": 19.940393001314195, "train/post_ent_std": 7.240586152152409, "train/prior_ent_mag": 69.56179967002264, "train/prior_ent_max": 69.56179967002264, "train/prior_ent_mean": 53.577188098241415, "train/prior_ent_min": 35.60785961151123, "train/prior_ent_std": 5.195590004088387, "train/rep_loss_mean": 10.895904730236719, "train/rep_loss_std": 8.668973574562678, "train/reward_avg": 0.0010736014985937685, "train/reward_loss_mean": 0.04047513590563857, "train/reward_loss_std": 0.010939092013157077, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001295524930197095, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040475135846506985, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010739928176109162, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.412499918602407, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.375, "eval_stats/max_log_achievement_collect_sapling": 0.6875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 4.158649062446784e-06, "report/cont_loss_std": 8.809027349343523e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.179097802785691e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.162490313319722e-06, "report/cont_pred": 0.9960895776748657, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 9.902451515197754, "report/dyn_loss_std": 7.892469882965088, "report/image_loss_mean": 2.8098337650299072, "report/image_loss_std": 4.056244850158691, "report/model_loss_mean": 8.791577339172363, "report/model_loss_std": 7.498333930969238, "report/post_ent_mag": 57.84343719482422, "report/post_ent_max": 57.84343719482422, "report/post_ent_mean": 41.9337043762207, "report/post_ent_min": 20.565996170043945, "report/post_ent_std": 6.510965347290039, "report/prior_ent_mag": 69.53053283691406, "report/prior_ent_max": 69.53053283691406, "report/prior_ent_mean": 52.26984405517578, "report/prior_ent_min": 35.68706512451172, "report/prior_ent_std": 4.959897041320801, "report/rep_loss_mean": 9.902451515197754, "report/rep_loss_std": 7.892469882965088, "report/reward_avg": 0.001069479389116168, "report/reward_loss_mean": 0.04026876389980316, "report/reward_loss_std": 0.011712057515978813, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013257265090942383, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04026876389980316, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010789241641759872, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0014898274093866348, "eval/cont_loss_std": 0.047578174620866776, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.000507608347106725, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.0014917494263499975, "eval/cont_pred": 0.9972829222679138, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 14.511894226074219, "eval/dyn_loss_std": 9.758474349975586, "eval/image_loss_mean": 6.548046112060547, "eval/image_loss_std": 10.136946678161621, "eval/model_loss_mean": 15.719974517822266, "eval/model_loss_std": 14.436173439025879, "eval/post_ent_mag": 60.55519104003906, "eval/post_ent_max": 60.55519104003906, "eval/post_ent_mean": 42.22783660888672, "eval/post_ent_min": 19.93634796142578, "eval/post_ent_std": 7.4652228355407715, "eval/prior_ent_mag": 69.53053283691406, "eval/prior_ent_max": 69.53053283691406, "eval/prior_ent_mean": 54.733619689941406, "eval/prior_ent_min": 40.48395538330078, "eval/prior_ent_std": 4.255557060241699, "eval/rep_loss_mean": 14.511894226074219, "eval/rep_loss_std": 9.758474349975586, "eval/reward_avg": 0.013867187313735485, "eval/reward_loss_mean": 0.4633013606071472, "eval/reward_loss_std": 3.0152580738067627, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012753009796142578, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.1382315754890442, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.942699432373047, "eval/reward_pred": 0.0010479268385097384, "eval/reward_rate": 0.015625, "replay/size": 889777.0, "replay/inserts": 20216.0, "replay/samples": 20224.0, "replay/insert_wait_avg": 1.3588656065819713e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.123608518250381e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4200.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1805125645228794e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2716398239136, "timer/env.step_count": 2527.0, "timer/env.step_total": 229.27745652198792, "timer/env.step_frac": 0.22921519254744602, "timer/env.step_avg": 0.09073108687059277, "timer/env.step_min": 0.02273726463317871, "timer/env.step_max": 3.2692596912384033, "timer/replay._sample_count": 20224.0, "timer/replay._sample_total": 10.049886465072632, "timer/replay._sample_frac": 0.010047157257044496, "timer/replay._sample_avg": 0.0004969287215720249, "timer/replay._sample_min": 0.0003428459167480469, "timer/replay._sample_max": 0.01007986068725586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3052.0, "timer/agent.policy_total": 50.98403286933899, "timer/agent.policy_frac": 0.050970187336626026, "timer/agent.policy_avg": 0.01670512217212942, "timer/agent.policy_min": 0.00973367691040039, "timer/agent.policy_max": 0.16035246849060059, "timer/dataset_train_count": 1264.0, "timer/dataset_train_total": 0.13913846015930176, "timer/dataset_train_frac": 0.00013910067487647206, "timer/dataset_train_avg": 0.00011007789569565012, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.0003495216369628906, "timer/agent.train_count": 1264.0, "timer/agent.train_total": 570.0253324508667, "timer/agent.train_frac": 0.5698705329196508, "timer/agent.train_avg": 0.4509694085845464, "timer/agent.train_min": 0.43741273880004883, "timer/agent.train_max": 1.1100001335144043, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4844510555267334, "timer/agent.report_frac": 0.0004843194950643762, "timer/agent.report_avg": 0.2422255277633667, "timer/agent.report_min": 0.23508405685424805, "timer/agent.report_max": 0.24936699867248535, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.384185791015625e-05, "timer/dataset_eval_frac": 2.3835383270841645e-08, "timer/dataset_eval_avg": 2.384185791015625e-05, "timer/dataset_eval_min": 2.384185791015625e-05, "timer/dataset_eval_max": 2.384185791015625e-05, "fps": 20.210122191058453}
{"step": 890376, "time": 44364.81513643265, "episode/length": 167.0, "episode/score": 0.1832205915270606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1832205915270606}
{"step": 890872, "time": 44385.19536948204, "episode/length": 249.0, "episode/score": 0.29722444480739796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29722444480739796}
{"step": 890952, "time": 44389.624771118164, "episode/length": 199.0, "episode/score": 0.22474328044609138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22474328044609138}
{"step": 890976, "time": 44392.32548069954, "episode/length": 172.0, "episode/score": 0.1785813994720229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1785813994720229}
{"step": 891056, "time": 44396.84471702576, "episode/length": 155.0, "episode/score": 0.17955315832386987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17955315832386987}
{"step": 891104, "time": 44400.07514882088, "episode/length": 150.0, "episode/score": 0.14355588043235912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14355588043235912}
{"step": 891128, "time": 44402.27942633629, "episode/length": 181.0, "episode/score": 0.19296178544300346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19296178544300346}
{"step": 891696, "time": 44425.42863178253, "episode/length": 196.0, "episode/score": 0.21511852565572553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21511852565572553}
{"step": 891864, "time": 44432.94089412689, "episode/length": 185.0, "episode/score": 0.21069479235984545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21069479235984545}
{"step": 892064, "time": 44442.33142328262, "episode/length": 148.0, "episode/score": 0.15787323542463128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15787323542463128}
{"step": 892272, "time": 44451.709072351456, "episode/length": 164.0, "episode/score": 0.1890506724134866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1890506724134866}
{"step": 892392, "time": 44457.69750833511, "episode/length": 157.0, "episode/score": 0.17339580326915893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17339580326915893}
{"step": 892408, "time": 44460.22701764107, "episode/length": 162.0, "episode/score": 0.16732358896524602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16732358896524602}
{"step": 892576, "time": 44468.82304906845, "episode/length": 199.0, "episode/score": 0.2096477780019086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2096477780019086}
{"step": 892680, "time": 44474.46252655983, "episode/length": 202.0, "episode/score": 0.20745580138782316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20745580138782316}
{"step": 893328, "time": 44501.89178729057, "episode/length": 182.0, "episode/score": 0.19512937422859977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19512937422859977}
{"step": 893384, "time": 44505.28786468506, "episode/length": 164.0, "episode/score": 0.19502544181159465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19502544181159465}
{"step": 893608, "time": 44515.09666323662, "episode/length": 166.0, "episode/score": 0.19414393579063471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19414393579063471}
{"step": 893808, "time": 44524.43122577667, "episode/length": 263.0, "episode/score": 0.2991993395166901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2991993395166901}
{"step": 893840, "time": 44527.26970076561, "episode/length": 178.0, "episode/score": 0.1970552458651582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1970552458651582}
{"step": 893904, "time": 44531.52428865433, "episode/length": 188.0, "episode/score": 0.20948948889281382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20948948889281382}
{"step": 893968, "time": 44535.44140958786, "episode/length": 173.0, "episode/score": 0.19132385707962385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19132385707962385}
{"step": 894520, "time": 44557.52804160118, "episode/length": 229.0, "episode/score": 0.26753781620755035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26753781620755035}
{"step": 894632, "time": 44563.27202749252, "episode/length": 127.0, "episode/score": 0.1464939188417702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1464939188417702}
{"step": 894648, "time": 44565.35977983475, "episode/length": 157.0, "episode/score": 0.16525004532286403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16525004532286403}
{"step": 894992, "time": 44579.92527246475, "episode/length": 147.0, "episode/score": 0.1648029109901472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1648029109901472}
{"step": 895376, "time": 44595.827288627625, "episode/length": 191.0, "episode/score": 0.2165334302235351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2165334302235351}
{"step": 895440, "time": 44599.7411608696, "episode/length": 263.0, "episode/score": 0.30707579940963114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30707579940963114}
{"step": 895456, "time": 44601.89365005493, "episode/length": 193.0, "episode/score": 0.18949715482312968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18949715482312968}
{"step": 895480, "time": 44604.15036773682, "episode/length": 188.0, "episode/score": 0.20051483741963239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20051483741963239}
{"step": 895816, "time": 44618.23077869415, "episode/length": 145.0, "episode/score": 0.1620318746877274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1620318746877274}
{"step": 896360, "time": 44640.09307384491, "episode/length": 170.0, "episode/score": 0.16569723576549222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16569723576549222}
{"step": 896400, "time": 44643.32331418991, "episode/length": 234.0, "episode/score": 0.2620030715179382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2620030715179382}
{"step": 896784, "time": 44659.524619579315, "episode/length": 175.0, "episode/score": 0.1985425341699738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1985425341699738}
{"step": 896856, "time": 44663.59339594841, "episode/length": 176.0, "episode/score": 0.1922331215637314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1922331215637314}
{"step": 897152, "time": 44676.533725738525, "episode/length": 208.0, "episode/score": 0.2277361323358491, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2277361323358491}
{"step": 897840, "time": 44704.23889517784, "episode/length": 179.0, "episode/score": 0.21384316213698185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21384316213698185}
{"step": 897968, "time": 44710.54956769943, "episode/length": 200.0, "episode/score": 0.2225170950505344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2225170950505344}
{"step": 898024, "time": 44713.86853528023, "episode/length": 423.0, "episode/score": 0.4234741597992979, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4234741597992979}
{"step": 898120, "time": 44719.41685128212, "episode/length": 157.0, "episode/score": 0.17929322164491168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17929322164491168}
{"step": 898144, "time": 44722.54948806763, "episode/length": 169.0, "episode/score": 0.1909359777332611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1909359777332611}
{"step": 898160, "time": 44725.0545334816, "episode/length": 337.0, "episode/score": 0.38449629904380345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.38449629904380345}
{"step": 898520, "time": 44740.452212810516, "episode/length": 337.0, "episode/score": 0.3387769223240866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3387769223240866}
{"step": 898632, "time": 44746.19774675369, "episode/length": 184.0, "episode/score": 0.1983821546082254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1983821546082254}
{"step": 899264, "time": 44771.7486512661, "episode/length": 154.0, "episode/score": 0.16880940012515566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16880940012515566}
{"step": 899384, "time": 44777.59171128273, "episode/length": 176.0, "episode/score": 0.17925735552944388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17925735552944388}
{"step": 899544, "time": 44785.11589193344, "episode/length": 174.0, "episode/score": 0.18978274103074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18978274103074}
{"step": 899576, "time": 44787.89253616333, "episode/length": 216.0, "episode/score": 0.239579759397202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.239579759397202}
{"step": 899592, "time": 44790.00621199608, "episode/length": 183.0, "episode/score": 0.19477890031930656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19477890031930656}
{"step": 899712, "time": 44796.36069369316, "episode/length": 193.0, "episode/score": 0.20858405891840448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20858405891840448}
{"step": 900016, "time": 44828.74330163002, "eval_episode/length": 155.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 900016, "time": 44830.420025110245, "eval_episode/length": 158.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 900016, "time": 44832.098786354065, "eval_episode/length": 162.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 900016, "time": 44834.45504999161, "eval_episode/length": 182.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.994535519125683}
{"step": 900016, "time": 44836.05561232567, "eval_episode/length": 185.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 900016, "time": 44837.678931713104, "eval_episode/length": 188.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 900016, "time": 44840.07838225365, "eval_episode/length": 50.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9019607843137255}
{"step": 900016, "time": 44844.860704898834, "eval_episode/length": 286.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9965156794425087}
{"step": 900152, "time": 44849.71940612793, "episode/length": 95.0, "episode/score": 0.10200546140958977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10200546140958977}
{"step": 900296, "time": 44856.81082415581, "episode/length": 221.0, "episode/score": 0.24899879737131414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24899879737131414}
{"step": 900480, "time": 44865.55491399765, "episode/length": 230.0, "episode/score": 0.24708209225218525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24708209225218525}
{"step": 900664, "time": 44873.716059207916, "episode/length": 174.0, "episode/score": 0.1986517339837519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1986517339837519}
{"step": 900928, "time": 44885.388102054596, "episode/length": 151.0, "episode/score": 0.16006908983627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16006908983627}
{"step": 900968, "time": 44888.46775150299, "episode/length": 177.0, "episode/score": 0.1694116087664952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1694116087664952}
{"step": 901056, "time": 44893.384007930756, "episode/length": 182.0, "episode/score": 0.2043748082210186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2043748082210186}
{"step": 901272, "time": 44904.13554406166, "episode/length": 211.0, "episode/score": 0.2260543373499786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2260543373499786}
{"step": 901816, "time": 44925.676914691925, "episode/length": 143.0, "episode/score": 0.16178431341086252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16178431341086252}
{"step": 901984, "time": 44933.55790448189, "episode/length": 210.0, "episode/score": 0.22918225323473962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22918225323473962}
{"step": 902016, "time": 44936.339848041534, "episode/length": 191.0, "episode/score": 0.21867654809284431, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21867654809284431}
{"step": 902144, "time": 44942.52157330513, "episode/length": 248.0, "episode/score": 0.25789967524997337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25789967524997337}
{"step": 902272, "time": 44948.70570778847, "episode/length": 162.0, "episode/score": 0.1887158149691004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1887158149691004}
{"step": 902568, "time": 44960.996463537216, "episode/length": 204.0, "episode/score": 0.21964826357361744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21964826357361744}
{"step": 902904, "time": 44975.113934755325, "episode/length": 203.0, "episode/score": 0.22847125338807928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22847125338807928}
{"step": 903000, "time": 44980.29118728638, "episode/length": 242.0, "episode/score": 0.25602172138405876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25602172138405876}
{"step": 903000, "time": 44980.29890227318, "episode/length": 147.0, "episode/score": 0.16142127394118688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16142127394118688}
{"step": 903184, "time": 44990.58948612213, "episode/length": 149.0, "episode/score": 0.14798056370796075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14798056370796075}
{"step": 903344, "time": 44997.92080974579, "episode/length": 165.0, "episode/score": 0.16374329520363062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16374329520363062}
{"step": 903904, "time": 45020.09355831146, "episode/length": 166.0, "episode/score": 0.17665803278646308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17665803278646308}
{"step": 904224, "time": 45033.47277927399, "episode/length": 152.0, "episode/score": 0.16654322379054065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16654322379054065}
{"step": 904296, "time": 45037.55866193771, "episode/length": 161.0, "episode/score": 0.16118670341643337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16118670341643337}
{"step": 904360, "time": 45041.41081571579, "episode/length": 146.0, "episode/score": 0.15107156619296802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15107156619296802}
{"step": 904528, "time": 45049.337129831314, "episode/length": 147.0, "episode/score": 0.14489569173611017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14489569173611017}
{"step": 904752, "time": 45059.16172719002, "episode/length": 309.0, "episode/score": 0.3503497651449834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3503497651449834}
{"step": 905216, "time": 45077.73169755936, "episode/length": 163.0, "episode/score": 0.16757849918371903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16757849918371903}
{"step": 905464, "time": 45088.101200819016, "episode/length": 414.0, "episode/score": 0.4314200012022411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4314200012022411}
{"step": 905616, "time": 45095.3616669178, "episode/length": 164.0, "episode/score": 0.16707654752372036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16707654752372036}
{"step": 905872, "time": 45106.44890642166, "episode/length": 188.0, "episode/score": 0.21513208549913543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21513208549913543}
{"step": 905976, "time": 45111.55662250519, "episode/length": 218.0, "episode/score": 0.2344915338321698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2344915338321698}
{"step": 906008, "time": 45114.427656173706, "episode/length": 184.0, "episode/score": 0.20926275628926305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20926275628926305}
{"step": 906112, "time": 45120.03311562538, "episode/length": 400.0, "episode/score": 0.43423176659098317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.43423176659098317}
{"step": 906472, "time": 45134.92962408066, "episode/length": 156.0, "episode/score": 0.15867591633286793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15867591633286793}
{"step": 906536, "time": 45138.86640048027, "episode/length": 222.0, "episode/score": 0.23434948940393951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23434948940393951}
{"step": 906896, "time": 45154.068990945816, "episode/length": 178.0, "episode/score": 0.20117615246999776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20117615246999776}
{"step": 907040, "time": 45161.04815196991, "episode/length": 177.0, "episode/score": 0.20187914020061726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20187914020061726}
{"step": 907352, "time": 45173.91556406021, "episode/length": 167.0, "episode/score": 0.1699307665512606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1699307665512606}
{"step": 907464, "time": 45179.56417942047, "episode/length": 168.0, "episode/score": 0.1843662584433332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1843662584433332}
{"step": 907496, "time": 45182.21991586685, "episode/length": 202.0, "episode/score": 0.21735864594666054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21735864594666054}
{"step": 907960, "time": 45200.85869765282, "episode/length": 57.0, "episode/score": 0.05892248623422347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05892248623422347}
{"step": 908072, "time": 45206.374306201935, "episode/length": 261.0, "episode/score": 0.30592809208246763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30592809208246763}
{"step": 908240, "time": 45214.343569755554, "episode/length": 167.0, "episode/score": 0.17928467074307264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17928467074307264}
{"step": 908368, "time": 45220.559693574905, "episode/length": 236.0, "episode/score": 0.2615874421062472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2615874421062472}
{"step": 908416, "time": 45223.69625043869, "episode/length": 132.0, "episode/score": 0.16166666336357594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16166666336357594}
{"step": 908464, "time": 45227.014179468155, "episode/length": 177.0, "episode/score": 0.19939551791685517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19939551791685517}
{"step": 908888, "time": 45244.01128029823, "episode/length": 177.0, "episode/score": 0.19693484532035654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19693484532035654}
{"step": 909568, "time": 45272.42691445351, "episode/length": 186.0, "episode/score": 0.20952460724220145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20952460724220145}
{"step": 909640, "time": 45276.39172935486, "episode/length": 174.0, "episode/score": 0.18509560173515638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18509560173515638}
{"step": 909760, "time": 45282.67142820358, "episode/length": 173.0, "episode/score": 0.19073386788659263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19073386788659263}
{"step": 909856, "time": 45287.72802257538, "episode/length": 414.0, "episode/score": 0.44971460274427955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44971460274427955}
{"step": 909920, "time": 45291.58953142166, "episode/length": 181.0, "episode/score": 0.20431467274283932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20431467274283932}
{"step": 910000, "time": 45313.97504281998, "eval_episode/length": 145.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 910000, "time": 45316.11501979828, "eval_episode/length": 161.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 910000, "time": 45317.734431266785, "eval_episode/length": 166.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 910000, "time": 45320.386657476425, "eval_episode/length": 194.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 910000, "time": 45321.88274216652, "eval_episode/length": 195.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 910000, "time": 45324.61223268509, "eval_episode/length": 223.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 910000, "time": 45327.3164999485, "eval_episode/length": 251.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.996031746031746}
{"step": 910000, "time": 45331.623911857605, "eval_episode/length": 157.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 910112, "time": 45335.80043196678, "episode/length": 211.0, "episode/score": 0.23973317124728055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23973317124728055}
{"step": 910424, "time": 45348.77492308617, "episode/length": 191.0, "episode/score": 0.20723042195095331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20723042195095331}
{"step": 910697, "time": 45361.427226781845, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.324366569519043, "train/action_min": 0.0, "train/action_std": 4.951390348374844, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008324832562720985, "train/actor_opt_grad_steps": 56185.0, "train/actor_opt_loss": -12.763922801357694, "train/adv_mag": 0.18255553406197578, "train/adv_max": 0.13806924177333713, "train/adv_mean": -0.00011969487883334295, "train/adv_min": -0.18154512287583202, "train/adv_std": 0.013946067239885451, "train/cont_avg": 0.99456787109375, "train/cont_loss_mean": 0.0001012866476227392, "train/cont_loss_std": 0.0030644761466464, "train/cont_neg_acc": 0.9956287210807204, "train/cont_neg_loss": 0.012350543565514904, "train/cont_pos_acc": 0.9999999734573066, "train/cont_pos_loss": 2.9755674602061077e-05, "train/cont_pred": 0.9945788504555821, "train/cont_rate": 0.99456787109375, "train/dyn_loss_mean": 10.858640991151333, "train/dyn_loss_std": 8.714909501373768, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12369271655916236, "train/extr_critic_critic_opt_grad_steps": 56185.0, "train/extr_critic_critic_opt_loss": 12237.54889678955, "train/extr_critic_mag": 0.28734992165118456, "train/extr_critic_max": 0.28734992165118456, "train/extr_critic_mean": 0.23387403402011842, "train/extr_critic_min": 0.001429482363164425, "train/extr_critic_std": 0.06281970257987268, "train/extr_return_normed_mag": 0.21780030301306397, "train/extr_return_normed_max": 0.21780030301306397, "train/extr_return_normed_mean": 0.1659088459564373, "train/extr_return_normed_min": -0.06681995309190825, "train/extr_return_normed_std": 0.06447204333380796, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28564587933942676, "train/extr_return_raw_max": 0.28564587933942676, "train/extr_return_raw_mean": 0.23375442472752184, "train/extr_return_raw_min": 0.0010256227105855942, "train/extr_return_raw_std": 0.0644720432756003, "train/extr_reward_mag": 0.0013522850349545479, "train/extr_reward_max": 0.0013522850349545479, "train/extr_reward_mean": 0.0010996821301887394, "train/extr_reward_min": 1.0800547897815704e-05, "train/extr_reward_std": 0.00024373766268581676, "train/image_loss_mean": 4.625603606924415, "train/image_loss_std": 10.010383918881416, "train/model_loss_mean": 11.181179441511631, "train/model_loss_std": 13.638239152729511, "train/model_opt_grad_norm": 49.56560482084751, "train/model_opt_grad_steps": 56132.5390625, "train/model_opt_loss": 14290.883476257324, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1279.296875, "train/policy_entropy_mag": 2.7626678738743067, "train/policy_entropy_max": 2.7626678738743067, "train/policy_entropy_mean": 2.08569189440459, "train/policy_entropy_min": 0.07959542341995984, "train/policy_entropy_std": 0.6384386133868247, "train/policy_logprob_mag": 7.43827461078763, "train/policy_logprob_max": -0.009486803064646665, "train/policy_logprob_mean": -2.083421804010868, "train/policy_logprob_min": -7.43827461078763, "train/policy_logprob_std": 1.1560232676565647, "train/policy_randomness_mag": 0.9751005223952234, "train/policy_randomness_max": 0.9751005223952234, "train/policy_randomness_mean": 0.7361577120609581, "train/policy_randomness_min": 0.0280936915660277, "train/policy_randomness_std": 0.22534081432968378, "train/post_ent_mag": 59.918988317251205, "train/post_ent_max": 59.918988317251205, "train/post_ent_mean": 42.644465416669846, "train/post_ent_min": 19.746948942542076, "train/post_ent_std": 7.374062031507492, "train/prior_ent_mag": 69.67210936546326, "train/prior_ent_max": 69.67210936546326, "train/prior_ent_mean": 53.63149079680443, "train/prior_ent_min": 35.44906893372536, "train/prior_ent_std": 5.135990429669619, "train/rep_loss_mean": 10.858640991151333, "train/rep_loss_std": 8.714909501373768, "train/reward_avg": 0.0010683629452614696, "train/reward_loss_mean": 0.04028996161650866, "train/reward_loss_std": 0.01117467963922536, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012981705367565155, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04028996147098951, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010693625599742518, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 1.9155339602995844, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.9320388349514563, "train_stats/max_log_achievement_collect_sapling": 0.5825242718446602, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 1.4466019417475728, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.05825242718446602, "train_stats/max_log_achievement_eat_cow": 0.02912621359223301, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02912621359223301, "train_stats/max_log_achievement_make_wood_sword": 0.02912621359223301, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.39805825242718446, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.23300970873786409, "train_stats/max_log_achievement_wake_up": 0.24271844660194175, "train_stats/mean_log_entropy": 2.1510941310993674, "eval_stats/sum_log_reward": 1.9124999279156327, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 0.8125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0005378385540097952, "report/cont_loss_std": 0.012130715884268284, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.04010193422436714, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00026551936753094196, "report/cont_pred": 0.993171751499176, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 10.438264846801758, "report/dyn_loss_std": 8.869033813476562, "report/image_loss_mean": 5.015727519989014, "report/image_loss_std": 9.36210823059082, "report/model_loss_mean": 11.31812858581543, "report/model_loss_std": 13.249490737915039, "report/post_ent_mag": 60.34929656982422, "report/post_ent_max": 60.34929656982422, "report/post_ent_mean": 44.60465621948242, "report/post_ent_min": 20.78887939453125, "report/post_ent_std": 7.599175930023193, "report/prior_ent_mag": 69.73426055908203, "report/prior_ent_max": 69.73426055908203, "report/prior_ent_mean": 54.62912368774414, "report/prior_ent_min": 40.6308479309082, "report/prior_ent_std": 4.931087493896484, "report/rep_loss_mean": 10.438264846801758, "report/rep_loss_std": 8.869033813476562, "report/reward_avg": 0.0010274334345012903, "report/reward_loss_mean": 0.038904450833797455, "report/reward_loss_std": 0.012286470271646976, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012655258178710938, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.038904450833797455, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010259667178615928, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 8.73218959895894e-06, "eval/cont_loss_std": 0.00022966015967540443, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.048417400146718e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.75182740855962e-06, "eval/cont_pred": 0.9970617294311523, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.817743301391602, "eval/dyn_loss_std": 10.511421203613281, "eval/image_loss_mean": 9.366201400756836, "eval/image_loss_std": 14.738301277160645, "eval/model_loss_mean": 19.435672760009766, "eval/model_loss_std": 19.311891555786133, "eval/post_ent_mag": 59.391273498535156, "eval/post_ent_max": 59.391273498535156, "eval/post_ent_mean": 41.779205322265625, "eval/post_ent_min": 20.234344482421875, "eval/post_ent_std": 8.025269508361816, "eval/prior_ent_mag": 69.73426055908203, "eval/prior_ent_max": 69.73426055908203, "eval/prior_ent_mean": 55.13528823852539, "eval/prior_ent_min": 40.22161865234375, "eval/prior_ent_std": 4.386343479156494, "eval/rep_loss_mean": 15.817743301391602, "eval/rep_loss_std": 10.511421203613281, "eval/reward_avg": 0.014843749813735485, "eval/reward_loss_mean": 0.5788160562515259, "eval/reward_loss_std": 3.372614860534668, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012655258178710938, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.2347661852836609, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.958715438842773, "eval/reward_pred": 0.001068195328116417, "eval/reward_rate": 0.0166015625, "replay/size": 910193.0, "replay/inserts": 20416.0, "replay/samples": 20416.0, "replay/insert_wait_avg": 1.3394228717002749e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.032029512160251e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2184583767634836e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1270132064819, "timer/env.step_count": 2552.0, "timer/env.step_total": 226.49791026115417, "timer/env.step_frac": 0.226469145688791, "timer/env.step_avg": 0.08875309963211371, "timer/env.step_min": 0.02241349220275879, "timer/env.step_max": 3.4189109802246094, "timer/replay._sample_count": 20416.0, "timer/replay._sample_total": 10.048110485076904, "timer/replay._sample_frac": 0.010046834404424205, "timer/replay._sample_avg": 0.0004921684210950679, "timer/replay._sample_min": 0.00037097930908203125, "timer/replay._sample_max": 0.00970768928527832, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3159.0, "timer/agent.policy_total": 50.906718015670776, "timer/agent.policy_frac": 0.050900253011325065, "timer/agent.policy_avg": 0.016114820517781188, "timer/agent.policy_min": 0.009639501571655273, "timer/agent.policy_max": 0.0977017879486084, "timer/dataset_train_count": 1276.0, "timer/dataset_train_total": 0.13872456550598145, "timer/dataset_train_frac": 0.00013870694789176838, "timer/dataset_train_avg": 0.00010871831152506383, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0005602836608886719, "timer/agent.train_count": 1276.0, "timer/agent.train_total": 573.4273974895477, "timer/agent.train_frac": 0.5733545738866673, "timer/agent.train_avg": 0.449394512139144, "timer/agent.train_min": 0.4349656105041504, "timer/agent.train_max": 1.081110954284668, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4800291061401367, "timer/agent.report_frac": 0.0004799681438471775, "timer/agent.report_avg": 0.24001455307006836, "timer/agent.report_min": 0.23289132118225098, "timer/agent.report_max": 0.24713778495788574, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.511543273925781e-05, "timer/dataset_eval_frac": 8.510462332816247e-08, "timer/dataset_eval_avg": 8.511543273925781e-05, "timer/dataset_eval_min": 8.511543273925781e-05, "timer/dataset_eval_max": 8.511543273925781e-05, "fps": 20.413111914623702}
{"step": 910824, "time": 45365.99025511742, "episode/length": 156.0, "episode/score": 0.17602777492720634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17602777492720634}
{"step": 910952, "time": 45372.324675798416, "episode/length": 163.0, "episode/score": 0.18371685278543737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18371685278543737}
{"step": 911112, "time": 45379.82493495941, "episode/length": 156.0, "episode/score": 0.16564997740351828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16564997740351828}
{"step": 911224, "time": 45385.92091464996, "episode/length": 407.0, "episode/score": 0.4144363533014257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4144363533014257}
{"step": 911264, "time": 45389.6141371727, "episode/length": 187.0, "episode/score": 0.2036188031124766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2036188031124766}
{"step": 911416, "time": 45397.01047921181, "episode/length": 162.0, "episode/score": 0.17650675387267256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17650675387267256}
{"step": 911792, "time": 45412.570987463, "episode/length": 233.0, "episode/score": 0.25080720538971946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25080720538971946}
{"step": 911832, "time": 45415.26913571358, "episode/length": 175.0, "episode/score": 0.20846725787123432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20846725787123432}
{"step": 912160, "time": 45428.95603609085, "episode/length": 166.0, "episode/score": 0.19836931430836557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19836931430836557}
{"step": 912328, "time": 45436.417976379395, "episode/length": 137.0, "episode/score": 0.1462113074667286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1462113074667286}
{"step": 912600, "time": 45448.094760894775, "episode/length": 185.0, "episode/score": 0.20502380628022365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20502380628022365}
{"step": 912928, "time": 45462.32823467255, "episode/length": 207.0, "episode/score": 0.21759739915432874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21759739915432874}
{"step": 912944, "time": 45464.43670988083, "episode/length": 190.0, "episode/score": 0.2087260552070802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2087260552070802}
{"step": 913344, "time": 45480.49967432022, "episode/length": 193.0, "episode/score": 0.22508268166711787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22508268166711787}
{"step": 913376, "time": 45483.23120188713, "episode/length": 192.0, "episode/score": 0.22780901189980796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22780901189980796}
{"step": 913440, "time": 45487.17054462433, "episode/length": 310.0, "episode/score": 0.3461417339858599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3461417339858599}
{"step": 913624, "time": 45495.21873116493, "episode/length": 161.0, "episode/score": 0.185241404651606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.185241404651606}
{"step": 913968, "time": 45509.452226638794, "episode/length": 170.0, "episode/score": 0.18092121859808685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18092121859808685}
{"step": 913984, "time": 45511.59057426453, "episode/length": 227.0, "episode/score": 0.2591269841432222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2591269841432222}
{"step": 914112, "time": 45517.94653582573, "episode/length": 147.0, "episode/score": 0.17609352795261657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17609352795261657}
{"step": 914664, "time": 45539.36183452606, "episode/length": 214.0, "episode/score": 0.23327320857788436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23327320857788436}
{"step": 914720, "time": 45543.14988541603, "episode/length": 171.0, "episode/score": 0.18869587818699074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18869587818699074}
{"step": 914792, "time": 45547.14644956589, "episode/length": 176.0, "episode/score": 0.19620656191182206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19620656191182206}
{"step": 914944, "time": 45554.37431883812, "episode/length": 164.0, "episode/score": 0.18331508826668141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18331508826668141}
{"step": 915112, "time": 45561.80672121048, "episode/length": 208.0, "episode/score": 0.23798718772013672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23798718772013672}
{"step": 915320, "time": 45570.91812109947, "episode/length": 166.0, "episode/score": 0.18343626322894124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18343626322894124}
{"step": 915360, "time": 45574.19461750984, "episode/length": 173.0, "episode/score": 0.19885936031460005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19885936031460005}
{"step": 915600, "time": 45584.56594371796, "episode/length": 185.0, "episode/score": 0.1984701357123413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1984701357123413}
{"step": 916008, "time": 45600.90191030502, "episode/length": 160.0, "episode/score": 0.17225218545536336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17225218545536336}
{"step": 916176, "time": 45608.983546972275, "episode/length": 188.0, "episode/score": 0.1960842561784375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1960842561784375}
{"step": 916288, "time": 45615.112476825714, "episode/length": 186.0, "episode/score": 0.18660502753664332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18660502753664332}
{"step": 916576, "time": 45627.2031481266, "episode/length": 182.0, "episode/score": 0.20296874674022547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20296874674022547}
{"step": 916960, "time": 45642.809816122055, "episode/length": 169.0, "episode/score": 0.19219230345515825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19219230345515825}
{"step": 917016, "time": 45646.1836476326, "episode/length": 211.0, "episode/score": 0.22639285506375018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22639285506375018}
{"step": 917200, "time": 45654.58179163933, "episode/length": 148.0, "episode/score": 0.1541970403122832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1541970403122832}
{"step": 917216, "time": 45656.73031163216, "episode/length": 231.0, "episode/score": 0.25397909016828635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25397909016828635}
{"step": 917296, "time": 45661.2485666275, "episode/length": 293.0, "episode/score": 0.3319397632039909, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3319397632039909}
{"step": 917552, "time": 45673.78607416153, "episode/length": 157.0, "episode/score": 0.1549386872738978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1549386872738978}
{"step": 917592, "time": 45676.50076675415, "episode/length": 176.0, "episode/score": 0.20628100999601884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20628100999601884}
{"step": 918424, "time": 45708.69440436363, "episode/length": 182.0, "episode/score": 0.19762337580687017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19762337580687017}
{"step": 918440, "time": 45710.85109829903, "episode/length": 152.0, "episode/score": 0.17579043077876122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17579043077876122}
{"step": 918576, "time": 45717.58069610596, "episode/length": 171.0, "episode/score": 0.19505599677813734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19505599677813734}
{"step": 918648, "time": 45721.44041776657, "episode/length": 168.0, "episode/score": 0.18792070961262652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18792070961262652}
{"step": 918720, "time": 45725.88446712494, "episode/length": 267.0, "episode/score": 0.28969110775506124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28969110775506124}
{"step": 918760, "time": 45728.7361843586, "episode/length": 217.0, "episode/score": 0.24696482026411104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24696482026411104}
{"step": 918952, "time": 45737.41521549225, "episode/length": 174.0, "episode/score": 0.1870556049307197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1870556049307197}
{"step": 919672, "time": 45765.37413620949, "episode/length": 259.0, "episode/score": 0.3032759340976554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3032759340976554}
{"step": 919784, "time": 45771.025307416916, "episode/length": 169.0, "episode/score": 0.1845168365398422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1845168365398422}
{"step": 919792, "time": 45773.12641096115, "episode/length": 151.0, "episode/score": 0.17486069319420494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17486069319420494}
{"step": 919944, "time": 45779.94742512703, "episode/length": 187.0, "episode/score": 0.20255776730664365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20255776730664365}
{"step": 920088, "time": 45801.05799603462, "eval_episode/length": 44.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8888888888888888}
{"step": 920088, "time": 45806.84986281395, "eval_episode/length": 153.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.974025974025974}
{"step": 920088, "time": 45806.856533527374, "eval_episode/length": 153.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 920088, "time": 45810.23841667175, "eval_episode/length": 160.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 920088, "time": 45812.85252118111, "eval_episode/length": 188.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 920088, "time": 45816.11241698265, "eval_episode/length": 234.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9957446808510638}
{"step": 920088, "time": 45817.96516728401, "eval_episode/length": 197.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 920088, "time": 45820.487100601196, "eval_episode/length": 269.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 920168, "time": 45823.429371118546, "episode/length": 180.0, "episode/score": 0.20226668819486804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20226668819486804}
{"step": 920216, "time": 45826.64181756973, "episode/length": 181.0, "episode/score": 0.21162499647471122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21162499647471122}
{"step": 920416, "time": 45835.68092751503, "episode/length": 182.0, "episode/score": 0.1961380958218797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1961380958218797}
{"step": 920488, "time": 45839.56562376022, "episode/length": 39.0, "episode/score": 0.04958333226386458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04958333226386458}
{"step": 921184, "time": 45866.68575501442, "episode/length": 188.0, "episode/score": 0.22118890906040178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22118890906040178}
{"step": 921400, "time": 45876.568450689316, "episode/length": 200.0, "episode/score": 0.2378858650163238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2378858650163238}
{"step": 921424, "time": 45879.78070831299, "episode/length": 204.0, "episode/score": 0.21362010914344864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21362010914344864}
{"step": 921440, "time": 45882.482414245605, "episode/length": 186.0, "episode/score": 0.20539511037350167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20539511037350167}
{"step": 921712, "time": 45894.11428666115, "episode/length": 152.0, "episode/score": 0.1738706419328082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1738706419328082}
{"step": 921912, "time": 45902.73134469986, "episode/length": 407.0, "episode/score": 0.46682402186888794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.46682402186888794}
{"step": 922040, "time": 45908.99197411537, "episode/length": 202.0, "episode/score": 0.22002468311075063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22002468311075063}
{"step": 922208, "time": 45916.88278269768, "episode/length": 248.0, "episode/score": 0.2934469031824847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2934469031824847}
{"step": 923048, "time": 45949.97085189819, "episode/length": 205.0, "episode/score": 0.23037675110845157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23037675110845157}
{"step": 923088, "time": 45953.19570851326, "episode/length": 205.0, "episode/score": 0.2226441679722484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2226441679722484}
{"step": 923432, "time": 45967.17859458923, "episode/length": 214.0, "episode/score": 0.23393336187291425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23393336187291425}
{"step": 923448, "time": 45969.23710036278, "episode/length": 175.0, "episode/score": 0.179153160343958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.179153160343958}
{"step": 923592, "time": 45975.98263335228, "episode/length": 209.0, "episode/score": 0.23747941414421803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23747941414421803}
{"step": 923656, "time": 45979.78658461571, "episode/length": 180.0, "episode/score": 0.21358441161282826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21358441161282826}
{"step": 923656, "time": 45979.7925863266, "episode/length": 75.0, "episode/score": 0.08932291498058476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08932291498058476}
{"step": 924288, "time": 46006.22296714783, "episode/length": 357.0, "episode/score": 0.39085732994772115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.39085732994772115}
{"step": 924320, "time": 46008.97301220894, "episode/length": 153.0, "episode/score": 0.1525942643856979, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1525942643856979}
{"step": 924440, "time": 46014.696430683136, "episode/length": 406.0, "episode/score": 0.4356148561100781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4356148561100781}
{"step": 924912, "time": 46033.964447021484, "episode/length": 184.0, "episode/score": 0.2221666622790508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2221666622790508}
{"step": 924936, "time": 46036.15566658974, "episode/length": 159.0, "episode/score": 0.17922466537493165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17922466537493165}
{"step": 925024, "time": 46041.19820904732, "episode/length": 170.0, "episode/score": 0.1832970666255278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1832970666255278}
{"step": 925296, "time": 46052.79044151306, "episode/length": 230.0, "episode/score": 0.2502785232172755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2502785232172755}
{"step": 925296, "time": 46052.799818754196, "episode/length": 212.0, "episode/score": 0.23514110227915808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23514110227915808}
{"step": 925560, "time": 46065.72720527649, "episode/length": 154.0, "episode/score": 0.18194257642608136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18194257642608136}
{"step": 925576, "time": 46068.36171293259, "episode/length": 141.0, "episode/score": 0.1726166631160595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1726166631160595}
{"step": 925712, "time": 46077.364814043045, "episode/length": 177.0, "episode/score": 0.19751407706644386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19751407706644386}
{"step": 926128, "time": 46094.16286087036, "episode/length": 148.0, "episode/score": 0.1623448952104809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1623448952104809}
{"step": 926328, "time": 46102.783574581146, "episode/length": 176.0, "episode/score": 0.17657303583655448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17657303583655448}
{"step": 926400, "time": 46107.20737981796, "episode/length": 137.0, "episode/score": 0.16108064819854917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16108064819854917}
{"step": 926528, "time": 46113.3533642292, "episode/length": 153.0, "episode/score": 0.1866666629211977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1866666629211977}
{"step": 927064, "time": 46134.31288909912, "episode/length": 187.0, "episode/score": 0.21762294191103138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21762294191103138}
{"step": 927392, "time": 46148.17920231819, "episode/length": 157.0, "episode/score": 0.17205500821546593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17205500821546593}
{"step": 927392, "time": 46148.22351002693, "episode/length": 209.0, "episode/score": 0.22506462245655712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22506462245655712}
{"step": 927536, "time": 46156.66019034386, "episode/length": 150.0, "episode/score": 0.17191666376311332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17191666376311332}
{"step": 927560, "time": 46158.79103946686, "episode/length": 316.0, "episode/score": 0.34735183737757325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34735183737757325}
{"step": 927760, "time": 46168.01604485512, "episode/length": 272.0, "episode/score": 0.32067339773311687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.32067339773311687}
{"step": 927952, "time": 46176.61667728424, "episode/length": 177.0, "episode/score": 0.1885804445046233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1885804445046233}
{"step": 928696, "time": 46205.99378156662, "episode/length": 162.0, "episode/score": 0.17611208814196289, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17611208814196289}
{"step": 928896, "time": 46215.54412531853, "episode/length": 166.0, "episode/score": 0.1939087265272974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1939087265272974}
{"step": 928904, "time": 46217.69255709648, "episode/length": 312.0, "episode/score": 0.3594226129062008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3594226129062008}
{"step": 929000, "time": 46223.31278371811, "episode/length": 241.0, "episode/score": 0.2842785016837297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2842785016837297}
{"step": 929160, "time": 46230.73077750206, "episode/length": 150.0, "episode/score": 0.16735269050695933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16735269050695933}
{"step": 929392, "time": 46241.158847332, "episode/length": 203.0, "episode/score": 0.21774104646101478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21774104646101478}
{"step": 929480, "time": 46245.721677064896, "episode/length": 260.0, "episode/score": 0.3091028931521578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3091028931521578}
{"step": 929648, "time": 46253.7897939682, "episode/length": 263.0, "episode/score": 0.2830773647292517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2830773647292517}
{"step": 930072, "time": 46289.35169649124, "eval_episode/length": 111.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9553571428571429}
{"step": 930072, "time": 46292.659146785736, "eval_episode/length": 157.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 930072, "time": 46294.22328090668, "eval_episode/length": 159.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 930072, "time": 46295.91143107414, "eval_episode/length": 163.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.975609756097561}
{"step": 930072, "time": 46297.9376950264, "eval_episode/length": 172.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 930072, "time": 46299.88338851929, "eval_episode/length": 183.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 930072, "time": 46301.83333611488, "eval_episode/length": 195.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 930072, "time": 46306.09238600731, "eval_episode/length": 266.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9812734082397003}
{"step": 930112, "time": 46307.76373338699, "episode/length": 176.0, "episode/score": 0.19806670332400245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19806670332400245}
{"step": 930224, "time": 46313.401857852936, "episode/length": 164.0, "episode/score": 0.17921580072652432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17921580072652432}
{"step": 930424, "time": 46321.897765636444, "episode/length": 177.0, "episode/score": 0.20429886446800083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20429886446800083}
{"step": 930560, "time": 46328.6861641407, "episode/length": 174.0, "episode/score": 0.19505956835564575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19505956835564575}
{"step": 930656, "time": 46333.64296889305, "episode/length": 157.0, "episode/score": 0.1806092862789228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1806092862789228}
{"step": 930752, "time": 46338.61739754677, "episode/length": 231.0, "episode/score": 0.27300964550158824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27300964550158824}
{"step": 930816, "time": 46342.44449663162, "episode/length": 145.0, "episode/score": 0.1517715748232149, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1517715748232149}
{"step": 931016, "time": 46350.940388679504, "episode/length": 191.0, "episode/score": 0.20744556596764596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20744556596764596}
{"step": 931241, "time": 46361.72191286087, "train_stats/sum_log_reward": 1.7355139913542248, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.317757009345794, "train_stats/max_log_achievement_collect_sapling": 0.411214953271028, "train_stats/max_log_achievement_collect_stone": 0.037383177570093455, "train_stats/max_log_achievement_collect_wood": 1.5514018691588785, "train_stats/max_log_achievement_defeat_skeleton": 0.009345794392523364, "train_stats/max_log_achievement_defeat_zombie": 0.06542056074766354, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.08411214953271028, "train_stats/max_log_achievement_make_wood_sword": 0.018691588785046728, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.3177570093457944, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.3177570093457944, "train_stats/max_log_achievement_wake_up": 0.2616822429906542, "train_stats/mean_log_entropy": 2.113825736758865, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.214454174041748, "train/action_min": 0.0, "train/action_std": 4.874666396528482, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008268495326774428, "train/actor_opt_grad_steps": 57465.0, "train/actor_opt_loss": -7.379953097668476, "train/adv_mag": 0.1814987909165211, "train/adv_max": 0.13941522425739095, "train/adv_mean": 0.0001256201729429307, "train/adv_min": -0.1781722399755381, "train/adv_std": 0.013540756837755907, "train/cont_avg": 0.9948959350585938, "train/cont_loss_mean": 0.0001582148689537044, "train/cont_loss_std": 0.0048271097895649095, "train/cont_neg_acc": 0.9888578876852989, "train/cont_neg_loss": 0.026181602708158724, "train/cont_pos_acc": 0.9999769665300846, "train/cont_pos_loss": 5.6854794666882924e-05, "train/cont_pred": 0.9948934568092227, "train/cont_rate": 0.9948959350585938, "train/dyn_loss_mean": 10.74830936640501, "train/dyn_loss_std": 8.688392672687769, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13348398864036426, "train/extr_critic_critic_opt_grad_steps": 57465.0, "train/extr_critic_critic_opt_loss": 12184.065559387207, "train/extr_critic_mag": 0.286016839556396, "train/extr_critic_max": 0.286016839556396, "train/extr_critic_mean": 0.23377143824473023, "train/extr_critic_min": 0.0013295290991663933, "train/extr_critic_std": 0.06299386714817956, "train/extr_return_normed_mag": 0.21608585945796221, "train/extr_return_normed_max": 0.21608585945796221, "train/extr_return_normed_mean": 0.1643834781134501, "train/extr_return_normed_min": -0.06854073982685804, "train/extr_return_normed_std": 0.06453417005832307, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28559932904317975, "train/extr_return_raw_max": 0.28559932904317975, "train/extr_return_raw_mean": 0.23389695421792567, "train/extr_return_raw_min": 0.0009727291762828827, "train/extr_return_raw_std": 0.0645341703784652, "train/extr_reward_mag": 0.0013383813202381134, "train/extr_reward_max": 0.0013383813202381134, "train/extr_reward_mean": 0.0011030260975530837, "train/extr_reward_min": 1.137610524892807e-05, "train/extr_reward_std": 0.0002386245586194491, "train/image_loss_mean": 4.716344246640801, "train/image_loss_std": 10.279581051319838, "train/model_loss_mean": 11.205897480249405, "train/model_loss_std": 13.874490715563297, "train/model_opt_grad_norm": 47.52121390402317, "train/model_opt_grad_steps": 57411.375, "train/model_opt_loss": 14776.935447692871, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1318.359375, "train/policy_entropy_mag": 2.764185329899192, "train/policy_entropy_max": 2.764185329899192, "train/policy_entropy_mean": 2.095035648904741, "train/policy_entropy_min": 0.07962995336856693, "train/policy_entropy_std": 0.6132330477703363, "train/policy_logprob_mag": 7.438275419175625, "train/policy_logprob_max": -0.009490982847637497, "train/policy_logprob_mean": -2.0943779023364186, "train/policy_logprob_min": -7.438275419175625, "train/policy_logprob_std": 1.1467696465551853, "train/policy_randomness_mag": 0.975636116694659, "train/policy_randomness_max": 0.975636116694659, "train/policy_randomness_mean": 0.7394556454382837, "train/policy_randomness_min": 0.028105879100621678, "train/policy_randomness_std": 0.21644435601774603, "train/post_ent_mag": 60.3616438806057, "train/post_ent_max": 60.3616438806057, "train/post_ent_mean": 42.721063673496246, "train/post_ent_min": 19.78128969669342, "train/post_ent_std": 7.371724855154753, "train/prior_ent_mag": 69.71312826871872, "train/prior_ent_max": 69.71312826871872, "train/prior_ent_mean": 53.58038040995598, "train/prior_ent_min": 35.27791255712509, "train/prior_ent_std": 5.217432469129562, "train/rep_loss_mean": 10.74830936640501, "train/rep_loss_std": 8.688392672687769, "train/reward_avg": 0.001071588773811527, "train/reward_loss_mean": 0.04040954387164675, "train/reward_loss_std": 0.010985377120960038, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001296473667025566, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04040954395895824, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010730912272265414, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.2874999782070518, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.25, "eval_stats/max_log_achievement_collect_sapling": 0.6875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.25, "eval_stats/max_log_achievement_wake_up": 0.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.221635769383283e-06, "report/cont_loss_std": 0.00019257266831118613, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0014413119060918689, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.8488356090529123e-07, "report/cont_pred": 0.995124101638794, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 10.148882865905762, "report/dyn_loss_std": 8.507696151733398, "report/image_loss_mean": 4.568624019622803, "report/image_loss_std": 10.24670124053955, "report/model_loss_mean": 10.699172973632812, "report/model_loss_std": 13.778177261352539, "report/post_ent_mag": 60.88134765625, "report/post_ent_max": 60.88134765625, "report/post_ent_mean": 44.56468200683594, "report/post_ent_min": 20.495677947998047, "report/post_ent_std": 7.44508695602417, "report/prior_ent_mag": 69.72647857666016, "report/prior_ent_max": 69.72647857666016, "report/prior_ent_mean": 54.53095245361328, "report/prior_ent_min": 37.58634567260742, "report/prior_ent_std": 5.12188720703125, "report/rep_loss_mean": 10.148882865905762, "report/rep_loss_std": 8.507696151733398, "report/reward_avg": 0.0010930675780400634, "report/reward_loss_mean": 0.04121225327253342, "report/reward_loss_std": 0.0096720140427351, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012902021408081055, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04121225327253342, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010788233485072851, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 9.445357562753998e-08, "eval/cont_loss_std": 1.1546574114618124e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.9990031432826072e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.5518977859492225e-08, "eval/cont_pred": 0.998046875, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 16.26620864868164, "eval/dyn_loss_std": 10.412641525268555, "eval/image_loss_mean": 9.612320899963379, "eval/image_loss_std": 14.160499572753906, "eval/model_loss_mean": 19.93866729736328, "eval/model_loss_std": 18.68025779724121, "eval/post_ent_mag": 56.23594284057617, "eval/post_ent_max": 56.23594284057617, "eval/post_ent_mean": 40.56981658935547, "eval/post_ent_min": 21.968095779418945, "eval/post_ent_std": 7.185493469238281, "eval/prior_ent_mag": 69.72647857666016, "eval/prior_ent_max": 69.72647857666016, "eval/prior_ent_mean": 53.96330261230469, "eval/prior_ent_min": 40.281341552734375, "eval/prior_ent_std": 4.436453819274902, "eval/rep_loss_mean": 16.26620864868164, "eval/rep_loss_std": 10.412641525268555, "eval/reward_avg": 0.013085938058793545, "eval/reward_loss_mean": 0.5666211843490601, "eval/reward_loss_std": 3.298535108566284, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012460947036743164, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.26333051919937134, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.96796989440918, "eval/reward_pred": 0.001021430711261928, "eval/reward_rate": 0.0146484375, "replay/size": 930737.0, "replay/inserts": 20544.0, "replay/samples": 20544.0, "replay/insert_wait_avg": 1.3536149839003137e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.0798181046578e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4296.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1160054020375512e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2875020503998, "timer/env.step_count": 2568.0, "timer/env.step_total": 233.96428656578064, "timer/env.step_frac": 0.23389704068700068, "timer/env.step_avg": 0.09110758822655009, "timer/env.step_min": 0.022285938262939453, "timer/env.step_max": 3.2702338695526123, "timer/replay._sample_count": 20544.0, "timer/replay._sample_total": 10.045066356658936, "timer/replay._sample_frac": 0.010042179209545709, "timer/replay._sample_avg": 0.0004889537751488968, "timer/replay._sample_min": 0.0003733634948730469, "timer/replay._sample_max": 0.025171279907226562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3105.0, "timer/agent.policy_total": 50.310221910476685, "timer/agent.policy_frac": 0.05029576177583971, "timer/agent.policy_avg": 0.016202970019477195, "timer/agent.policy_min": 0.00951838493347168, "timer/agent.policy_max": 0.1180422306060791, "timer/dataset_train_count": 1284.0, "timer/dataset_train_total": 0.13884925842285156, "timer/dataset_train_frac": 0.00013880935044998253, "timer/dataset_train_avg": 0.0001081380517311928, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.0010845661163330078, "timer/agent.train_count": 1284.0, "timer/agent.train_total": 573.4527702331543, "timer/agent.train_frac": 0.5732879487724127, "timer/agent.train_avg": 0.4466143070351669, "timer/agent.train_min": 0.4328117370605469, "timer/agent.train_max": 1.1165869235992432, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47772955894470215, "timer/agent.report_frac": 0.00047759225019351645, "timer/agent.report_avg": 0.23886477947235107, "timer/agent.report_min": 0.23340177536010742, "timer/agent.report_max": 0.24432778358459473, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.86020063567144e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 20.537839794845873}
{"step": 931256, "time": 46361.88935613632, "episode/length": 29.0, "episode/score": 0.036666665924713016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036666665924713016}
{"step": 931344, "time": 46367.345599889755, "episode/length": 153.0, "episode/score": 0.17093418743024813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17093418743024813}
{"step": 931480, "time": 46373.65434718132, "episode/length": 156.0, "episode/score": 0.16575000561351771, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16575000561351771}
{"step": 931936, "time": 46392.16828417778, "episode/length": 171.0, "episode/score": 0.19148213995504193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19148213995504193}
{"step": 932048, "time": 46397.80079174042, "episode/length": 173.0, "episode/score": 0.17997443725471385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17997443725471385}
{"step": 932184, "time": 46404.13249826431, "episode/length": 178.0, "episode/score": 0.19595669725094922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19595669725094922}
{"step": 932264, "time": 46408.55696439743, "episode/length": 229.0, "episode/score": 0.23782089974520204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23782089974520204}
{"step": 932632, "time": 46423.66963291168, "episode/length": 171.0, "episode/score": 0.17551797763007926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17551797763007926}
{"step": 932656, "time": 46426.318182468414, "episode/length": 163.0, "episode/score": 0.1886699275491992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1886699275491992}
{"step": 932664, "time": 46427.93535709381, "episode/length": 230.0, "episode/score": 0.2689822185639059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2689822185639059}
{"step": 932984, "time": 46441.28198266029, "episode/length": 187.0, "episode/score": 0.21250074020645116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21250074020645116}
{"step": 933440, "time": 46460.35728240013, "episode/length": 187.0, "episode/score": 0.20161320410988992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20161320410988992}
{"step": 933448, "time": 46461.86532330513, "episode/length": 174.0, "episode/score": 0.19192261614080053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19192261614080053}
{"step": 933520, "time": 46466.19472718239, "episode/length": 166.0, "episode/score": 0.19613207364454865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19613207364454865}
{"step": 934008, "time": 46486.94948077202, "episode/length": 168.0, "episode/score": 0.1951930189425184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1951930189425184}
{"step": 934320, "time": 46500.10847425461, "episode/length": 166.0, "episode/score": 0.1842536500917049, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1842536500917049}
{"step": 934352, "time": 46502.77471327782, "episode/length": 210.0, "episode/score": 0.23978485764746438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23978485764746438}
{"step": 934488, "time": 46509.025604486465, "episode/length": 277.0, "episode/score": 0.3261414670050726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3261414670050726}
{"step": 934496, "time": 46511.0234978199, "episode/length": 232.0, "episode/score": 0.27552087341609877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27552087341609877}
{"step": 934984, "time": 46530.0954477787, "episode/length": 191.0, "episode/score": 0.19525278599758167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19525278599758167}
{"step": 935008, "time": 46532.619883060455, "episode/length": 195.0, "episode/score": 0.20614717337593902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20614717337593902}
{"step": 935296, "time": 46544.76492142677, "episode/length": 221.0, "episode/score": 0.25273473451670725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25273473451670725}
{"step": 935624, "time": 46558.046434402466, "episode/length": 201.0, "episode/score": 0.2079730408240721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2079730408240721}
{"step": 935728, "time": 46563.59996294975, "episode/length": 175.0, "episode/score": 0.18929406745519373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18929406745519373}
{"step": 935904, "time": 46571.59834814072, "episode/length": 193.0, "episode/score": 0.21722653025062755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21722653025062755}
{"step": 936336, "time": 46588.90352892876, "episode/length": 165.0, "episode/score": 0.1864271387239569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1864271387239569}
{"step": 936352, "time": 46590.98230075836, "episode/length": 170.0, "episode/score": 0.18499789009365486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18499789009365486}
{"step": 936480, "time": 46597.36310362816, "episode/length": 247.0, "episode/score": 0.3014821366814431, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3014821366814431}
{"step": 936512, "time": 46599.996191978455, "episode/length": 151.0, "episode/score": 0.17013302374107298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17013302374107298}
{"step": 936960, "time": 46617.98284816742, "episode/length": 166.0, "episode/score": 0.18803221685811877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18803221685811877}
{"step": 936984, "time": 46620.19993972778, "episode/length": 156.0, "episode/score": 0.17054690290387953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17054690290387953}
{"step": 937560, "time": 46642.88400578499, "episode/length": 383.0, "episode/score": 0.41725636939372635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.41725636939372635}
{"step": 937624, "time": 46646.71350836754, "episode/length": 158.0, "episode/score": 0.18027437869022833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18027437869022833}
{"step": 937640, "time": 46648.8180167675, "episode/length": 144.0, "episode/score": 0.13733040268925834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13733040268925834}
{"step": 937672, "time": 46651.52577018738, "episode/length": 166.0, "episode/score": 0.19018778464669595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19018778464669595}
{"step": 937936, "time": 46663.15234231949, "episode/length": 253.0, "episode/score": 0.2817344080467592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2817344080467592}
{"step": 938080, "time": 46670.44333863258, "episode/length": 195.0, "episode/score": 0.21804152359982254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21804152359982254}
{"step": 938184, "time": 46675.4874727726, "episode/length": 152.0, "episode/score": 0.1795423445000779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1795423445000779}
{"step": 938416, "time": 46685.83575296402, "episode/length": 178.0, "episode/score": 0.18906974259152776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18906974259152776}
{"step": 938872, "time": 46703.805147886276, "episode/length": 155.0, "episode/score": 0.17479642567013798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17479642567013798}
{"step": 939024, "time": 46711.15373110771, "episode/length": 168.0, "episode/score": 0.18289842329613748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18289842329613748}
{"step": 939432, "time": 46727.54516410828, "episode/length": 155.0, "episode/score": 0.16905732485429326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16905732485429326}
{"step": 939440, "time": 46729.53027129173, "episode/length": 234.0, "episode/score": 0.26553751912069856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26553751912069856}
{"step": 939456, "time": 46731.57682585716, "episode/length": 226.0, "episode/score": 0.25876208233421494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25876208233421494}
{"step": 939656, "time": 46740.17382359505, "episode/length": 154.0, "episode/score": 0.1646537885080761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1646537885080761}
{"step": 940040, "time": 46755.88239240646, "episode/length": 262.0, "episode/score": 0.28780735115469724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28780735115469724}
{"step": 940056, "time": 46776.1279168129, "eval_episode/length": 150.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 940056, "time": 46777.99515128136, "eval_episode/length": 155.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 940056, "time": 46780.739107847214, "eval_episode/length": 186.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 940056, "time": 46782.34092974663, "eval_episode/length": 188.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 940056, "time": 46784.30018901825, "eval_episode/length": 199.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.995}
{"step": 940056, "time": 46787.12765669823, "eval_episode/length": 234.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9659574468085106}
{"step": 940056, "time": 46789.16432785988, "eval_episode/length": 247.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9798387096774194}
{"step": 940056, "time": 46791.57236599922, "eval_episode/length": 268.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9814126394052045}
{"step": 940184, "time": 46796.27995443344, "episode/length": 144.0, "episode/score": 0.1613564625968138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1613564625968138}
{"step": 940296, "time": 46801.925400972366, "episode/length": 177.0, "episode/score": 0.2074175501766149, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2074175501766149}
{"step": 940312, "time": 46804.44272828102, "episode/length": 278.0, "episode/score": 0.33429950318168267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33429950318168267}
{"step": 940672, "time": 46819.94472980499, "episode/length": 153.0, "episode/score": 0.1647805423963291, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1647805423963291}
{"step": 940688, "time": 46822.08487200737, "episode/length": 153.0, "episode/score": 0.1694795685889403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1694795685889403}
{"step": 940824, "time": 46828.50405263901, "episode/length": 173.0, "episode/score": 0.2006028609648638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2006028609648638}
{"step": 941056, "time": 46838.82279586792, "episode/length": 174.0, "episode/score": 0.19012062233377947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19012062233377947}
{"step": 941320, "time": 46849.73844623566, "episode/length": 159.0, "episode/score": 0.1748200953079504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1748200953079504}
{"step": 941632, "time": 46862.98394417763, "episode/length": 180.0, "episode/score": 0.19745032154423825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19745032154423825}
{"step": 941712, "time": 46867.51923751831, "episode/length": 174.0, "episode/score": 0.19083178599612438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19083178599612438}
{"step": 941800, "time": 46872.13466000557, "episode/length": 138.0, "episode/score": 0.17104166303761303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17104166303761303}
{"step": 942088, "time": 46884.79649806023, "episode/length": 223.0, "episode/score": 0.24361019579555432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24361019579555432}
{"step": 942216, "time": 46892.208134651184, "episode/length": 173.0, "episode/score": 0.20128594410198275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20128594410198275}
{"step": 942248, "time": 46894.958725214005, "episode/length": 196.0, "episode/score": 0.2302276280543083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2302276280543083}
{"step": 942376, "time": 46901.18005204201, "episode/length": 131.0, "episode/score": 0.144695128838066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.144695128838066}
{"step": 942672, "time": 46913.782794713974, "episode/length": 201.0, "episode/score": 0.23144527964177541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23144527964177541}
{"step": 942984, "time": 46926.406898736954, "episode/length": 147.0, "episode/score": 0.14850312620274053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14850312620274053}
{"step": 943016, "time": 46929.26675248146, "episode/length": 162.0, "episode/score": 0.17741707515597227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17741707515597227}
{"step": 943120, "time": 46934.786236763, "episode/length": 185.0, "episode/score": 0.20327256812743144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20327256812743144}
{"step": 943144, "time": 46936.84138393402, "episode/length": 111.0, "episode/score": 0.1263147895115253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1263147895115253}
{"step": 943848, "time": 46964.19953870773, "episode/length": 219.0, "episode/score": 0.24368507022063568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24368507022063568}
{"step": 943896, "time": 46967.38375091553, "episode/length": 209.0, "episode/score": 0.23863842811806535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23863842811806535}
{"step": 943912, "time": 46969.524119377136, "episode/length": 191.0, "episode/score": 0.21611981289061077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21611981289061077}
{"step": 943960, "time": 46972.775195360184, "episode/length": 160.0, "episode/score": 0.18414830686106143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18414830686106143}
{"step": 944160, "time": 46981.847475767136, "episode/length": 146.0, "episode/score": 0.16201286823343253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16201286823343253}
{"step": 944328, "time": 46989.35548090935, "episode/length": 147.0, "episode/score": 0.15984298190869595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15984298190869595}
{"step": 944816, "time": 47009.217417001724, "episode/length": 211.0, "episode/score": 0.2262271298777705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2262271298777705}
{"step": 945048, "time": 47019.55951952934, "episode/length": 253.0, "episode/score": 0.29505838703971676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29505838703971676}
{"step": 945216, "time": 47027.529603242874, "episode/length": 170.0, "episode/score": 0.18145932822517352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18145932822517352}
{"step": 945256, "time": 47030.34575819969, "episode/length": 167.0, "episode/score": 0.16800251164931979, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16800251164931979}
{"step": 945608, "time": 47044.77359390259, "episode/length": 205.0, "episode/score": 0.22681073220064718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22681073220064718}
{"step": 945800, "time": 47053.440708875656, "episode/length": 183.0, "episode/score": 0.21067919483084552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21067919483084552}
{"step": 945824, "time": 47056.14104294777, "episode/length": 240.0, "episode/score": 0.254356365696367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.254356365696367}
{"step": 946264, "time": 47073.40943169594, "episode/length": 180.0, "episode/score": 0.20816963897959795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20816963897959795}
{"step": 946312, "time": 47076.64815711975, "episode/length": 136.0, "episode/score": 0.15458375146590697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15458375146590697}
{"step": 946448, "time": 47083.575286626816, "episode/length": 285.0, "episode/score": 0.3242373952025446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3242373952025446}
{"step": 946728, "time": 47095.25033044815, "episode/length": 209.0, "episode/score": 0.23707521540200105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23707521540200105}
{"step": 946896, "time": 47103.119096279144, "episode/length": 160.0, "episode/score": 0.1688649958505266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1688649958505266}
{"step": 947352, "time": 47121.66558074951, "episode/length": 193.0, "episode/score": 0.22200291494300473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22200291494300473}
{"step": 947400, "time": 47124.856790065765, "episode/length": 62.0, "episode/score": 0.07123685765509435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07123685765509435}
{"step": 948224, "time": 47157.24758434296, "episode/length": 244.0, "episode/score": 0.27319174579770333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27319174579770333}
{"step": 948392, "time": 47164.64045071602, "episode/length": 207.0, "episode/score": 0.23799759445500968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23799759445500968}
{"step": 948448, "time": 47168.58284497261, "episode/length": 398.0, "episode/score": 0.44568061882227994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44568061882227994}
{"step": 948504, "time": 47171.92525792122, "episode/length": 273.0, "episode/score": 0.3033285364790572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3033285364790572}
{"step": 948600, "time": 47176.91467833519, "episode/length": 155.0, "episode/score": 0.16981460040688034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16981460040688034}
{"step": 948600, "time": 47176.922943115234, "episode/length": 268.0, "episode/score": 0.3144968370816059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3144968370816059}
{"step": 949256, "time": 47204.55357813835, "episode/length": 231.0, "episode/score": 0.2595685818664606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2595685818664606}
{"step": 949344, "time": 47209.416118860245, "episode/length": 439.0, "episode/score": 0.44739513152808286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44739513152808286}
{"step": 949368, "time": 47211.704583883286, "episode/length": 114.0, "episode/score": 0.13891343091972885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13891343091972885}
{"step": 949880, "time": 47231.94507789612, "episode/length": 171.0, "episode/score": 0.19647671609709505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19647671609709505}
{"step": 949936, "time": 47235.74674797058, "episode/length": 166.0, "episode/score": 0.1898471647164115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1898471647164115}
{"step": 949960, "time": 47237.97399878502, "episode/length": 216.0, "episode/score": 0.24142457947255025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24142457947255025}
{"step": 950000, "time": 47241.22952604294, "episode/length": 200.0, "episode/score": 0.21519361706441487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21519361706441487}
{"step": 950040, "time": 47244.60385417938, "episode/length": 179.0, "episode/score": 0.18888502246636563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18888502246636563}
{"step": 950040, "time": 47264.11241698265, "eval_episode/length": 155.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 950040, "time": 47265.72697973251, "eval_episode/length": 158.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 950040, "time": 47267.27882552147, "eval_episode/length": 160.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 950040, "time": 47269.14602828026, "eval_episode/length": 171.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 950040, "time": 47270.7764942646, "eval_episode/length": 175.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9829545454545454}
{"step": 950040, "time": 47272.290741205215, "eval_episode/length": 176.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 950040, "time": 47274.13395500183, "eval_episode/length": 182.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.994535519125683}
{"step": 950040, "time": 47276.511275053024, "eval_episode/length": 204.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 950760, "time": 47305.97951936722, "episode/length": 173.0, "episode/score": 0.16713224883142175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16713224883142175}
{"step": 950888, "time": 47312.275478601456, "episode/length": 115.0, "episode/score": 0.13683333079097793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13683333079097793}
{"step": 950896, "time": 47314.32388854027, "episode/length": 204.0, "episode/score": 0.22103935277436904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22103935277436904}
{"step": 951040, "time": 47321.28339099884, "episode/length": 211.0, "episode/score": 0.24193950058588598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24193950058588598}
{"step": 951336, "time": 47333.94094610214, "episode/length": 166.0, "episode/score": 0.19256857939762995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19256857939762995}
{"step": 951360, "time": 47336.44417357445, "episode/length": 164.0, "episode/score": 0.17099848747602664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17099848747602664}
{"step": 951456, "time": 47341.51590895653, "episode/length": 196.0, "episode/score": 0.21683921983640175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21683921983640175}
{"step": 951904, "time": 47359.7616956234, "episode/length": 245.0, "episode/score": 0.28277380447252654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28277380447252654}
{"step": 951905, "time": 47362.323273420334, "train_stats/sum_log_reward": 2.1277777578819683, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.8703703703703702, "train_stats/max_log_achievement_collect_sapling": 0.6759259259259259, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.0185185185185186, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.05555555555555555, "train_stats/max_log_achievement_eat_cow": 0.009259259259259259, "train_stats/max_log_achievement_make_wood_pickaxe": 0.037037037037037035, "train_stats/max_log_achievement_make_wood_sword": 0.018518518518518517, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.4444444444444444, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.25925925925925924, "train_stats/max_log_achievement_wake_up": 0.2222222222222222, "train_stats/mean_log_entropy": 2.0991899051048137, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.0418109745942346, "train/action_min": 0.0, "train/action_std": 4.839468811833581, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008452506387577385, "train/actor_opt_grad_steps": 58750.0, "train/actor_opt_loss": -11.001979144275651, "train/adv_mag": 0.18248370613238607, "train/adv_max": 0.13520239316677862, "train/adv_mean": -2.901866052574645e-05, "train/adv_min": -0.17998229082702666, "train/adv_std": 0.013559443183070006, "train/cont_avg": 0.9944358648255814, "train/cont_loss_mean": 0.00011773443158897972, "train/cont_loss_std": 0.003561888809695684, "train/cont_neg_acc": 0.9964808669201163, "train/cont_neg_loss": 0.012820675836234502, "train/cont_pos_acc": 0.9999847680099251, "train/cont_pos_loss": 4.2970374988704656e-05, "train/cont_pred": 0.9944308256918146, "train/cont_rate": 0.9944358648255814, "train/dyn_loss_mean": 10.738325233607329, "train/dyn_loss_std": 8.760984176813169, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.125048427589873, "train/extr_critic_critic_opt_grad_steps": 58750.0, "train/extr_critic_critic_opt_loss": 12247.214268410853, "train/extr_critic_mag": 0.28872583078783615, "train/extr_critic_max": 0.28872583078783615, "train/extr_critic_mean": 0.23444384348022845, "train/extr_critic_min": 0.0014324021893878315, "train/extr_critic_std": 0.06670850580341595, "train/extr_return_normed_mag": 0.23030060252477957, "train/extr_return_normed_max": 0.23030060252477957, "train/extr_return_normed_mean": 0.17661588182745053, "train/extr_return_normed_min": -0.056768824021483574, "train/extr_return_normed_std": 0.06819814998050068, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.28809962392777433, "train/extr_return_raw_max": 0.28809962392777433, "train/extr_return_raw_mean": 0.23441490634929302, "train/extr_return_raw_min": 0.0010301974392676538, "train/extr_return_raw_std": 0.06819814974947493, "train/extr_reward_mag": 0.0013435422912124516, "train/extr_reward_max": 0.0013435422912124516, "train/extr_reward_mean": 0.0011073202481348963, "train/extr_reward_min": 1.1975451033244761e-05, "train/extr_reward_std": 0.0002361088056007198, "train/image_loss_mean": 4.608796202859213, "train/image_loss_std": 9.994030771329422, "train/model_loss_mean": 11.09239950845408, "train/model_loss_std": 13.65081518749858, "train/model_opt_grad_norm": 47.40644051307856, "train/model_opt_grad_steps": 58695.19379844961, "train/model_opt_loss": 14791.902237766473, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1337.2093023255813, "train/policy_entropy_mag": 2.762789190277573, "train/policy_entropy_max": 2.762789190277573, "train/policy_entropy_mean": 2.064615245013274, "train/policy_entropy_min": 0.07954769032870153, "train/policy_entropy_std": 0.6256584414215975, "train/policy_logprob_mag": 7.438149012336435, "train/policy_logprob_max": -0.009480083123022733, "train/policy_logprob_mean": -2.0640966189924135, "train/policy_logprob_min": -7.438149012336435, "train/policy_logprob_std": 1.1696473849836246, "train/policy_randomness_mag": 0.9751433420550916, "train/policy_randomness_max": 0.9751433420550916, "train/policy_randomness_mean": 0.7287185741949451, "train/policy_randomness_min": 0.028076843856725583, "train/policy_randomness_std": 0.22082997592844705, "train/post_ent_mag": 60.27087946455608, "train/post_ent_max": 60.27087946455608, "train/post_ent_mean": 42.77338764279388, "train/post_ent_min": 19.604832094769144, "train/post_ent_std": 7.4257132101428605, "train/prior_ent_mag": 69.75207986757736, "train/prior_ent_max": 69.75207986757736, "train/prior_ent_mean": 53.61701504019804, "train/prior_ent_min": 35.660106673721195, "train/prior_ent_std": 5.242491836695708, "train/rep_loss_mean": 10.738325233607329, "train/rep_loss_std": 8.760984176813169, "train/reward_avg": 0.0010742965098398255, "train/reward_loss_mean": 0.040490453875111056, "train/reward_loss_std": 0.010948130052334578, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012926907502403555, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040490453846232836, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001074098046082108, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.6624999674968421, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.0, "eval_stats/max_log_achievement_collect_sapling": 0.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.4611200072067732e-07, "report/cont_loss_std": 1.010819914881722e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.502918277969002e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.368696018744231e-07, "report/cont_pred": 0.9960936903953552, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 10.555220603942871, "report/dyn_loss_std": 8.337638854980469, "report/image_loss_mean": 3.573734760284424, "report/image_loss_std": 8.919528007507324, "report/model_loss_mean": 9.946608543395996, "report/model_loss_std": 12.565458297729492, "report/post_ent_mag": 60.35097122192383, "report/post_ent_max": 60.35097122192383, "report/post_ent_mean": 43.116912841796875, "report/post_ent_min": 20.110698699951172, "report/post_ent_std": 7.278364181518555, "report/prior_ent_mag": 69.55290985107422, "report/prior_ent_max": 69.55290985107422, "report/prior_ent_mean": 53.781551361083984, "report/prior_ent_min": 32.467979431152344, "report/prior_ent_std": 4.890388011932373, "report/rep_loss_mean": 10.555220603942871, "report/rep_loss_std": 8.337638854980469, "report/reward_avg": 0.001054419786669314, "report/reward_loss_mean": 0.03974126651883125, "report/reward_loss_std": 0.012154536321759224, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012803077697753906, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.03974127024412155, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.001050498685799539, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0005210559465922415, "eval/cont_loss_std": 0.016646170988678932, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.112663312596851e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0005241205217316747, "eval/cont_pred": 0.9937366843223572, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 15.453288078308105, "eval/dyn_loss_std": 10.493037223815918, "eval/image_loss_mean": 8.879842758178711, "eval/image_loss_std": 13.389670372009277, "eval/model_loss_mean": 19.1219482421875, "eval/model_loss_std": 18.36722755432129, "eval/post_ent_mag": 58.86845779418945, "eval/post_ent_max": 58.86845779418945, "eval/post_ent_mean": 41.29985046386719, "eval/post_ent_min": 19.78866958618164, "eval/post_ent_std": 7.361044406890869, "eval/prior_ent_mag": 69.55290985107422, "eval/prior_ent_max": 69.55290985107422, "eval/prior_ent_mean": 54.090354919433594, "eval/prior_ent_min": 34.831695556640625, "eval/prior_ent_std": 4.818275451660156, "eval/rep_loss_mean": 15.453288078308105, "eval/rep_loss_std": 10.493037223815918, "eval/reward_avg": 0.008007812313735485, "eval/reward_loss_mean": 0.9696112275123596, "eval/reward_loss_std": 4.305613040924072, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 0.0012557506561279297, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.6727118492126465, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.941043853759766, "eval/reward_pred": 0.0010652148630470037, "eval/reward_rate": 0.0146484375, "replay/size": 951401.0, "replay/inserts": 20664.0, "replay/samples": 20656.0, "replay/insert_wait_avg": 1.3204401793795595e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.095451143709474e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1639881737624544e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.5876944065094, "timer/env.step_count": 2583.0, "timer/env.step_total": 233.78266859054565, "timer/env.step_frac": 0.23364535652141113, "timer/env.step_avg": 0.09050819535057904, "timer/env.step_min": 0.022570371627807617, "timer/env.step_max": 3.3858091831207275, "timer/replay._sample_count": 20656.0, "timer/replay._sample_total": 10.087029933929443, "timer/replay._sample_frac": 0.010081105324718674, "timer/replay._sample_avg": 0.000488334137002781, "timer/replay._sample_min": 0.00040268898010253906, "timer/replay._sample_max": 0.02182745933532715, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3057.0, "timer/agent.policy_total": 47.91674304008484, "timer/agent.policy_frac": 0.047888599178212234, "timer/agent.policy_avg": 0.015674433444581234, "timer/agent.policy_min": 0.009735584259033203, "timer/agent.policy_max": 0.1094968318939209, "timer/dataset_train_count": 1291.0, "timer/dataset_train_total": 0.13874411582946777, "timer/dataset_train_frac": 0.00013866262458060984, "timer/dataset_train_avg": 0.00010747026787720199, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.001073598861694336, "timer/agent.train_count": 1291.0, "timer/agent.train_total": 578.9619917869568, "timer/agent.train_frac": 0.5786219389099758, "timer/agent.train_avg": 0.44846010208129883, "timer/agent.train_min": 0.43514156341552734, "timer/agent.train_max": 1.2423732280731201, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4774940013885498, "timer/agent.report_frac": 0.00047721354565705663, "timer/agent.report_avg": 0.2387470006942749, "timer/agent.report_min": 0.2309248447418213, "timer/agent.report_max": 0.24656915664672852, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.193450927734375e-05, "timer/dataset_eval_frac": 2.1921626060326506e-08, "timer/dataset_eval_avg": 2.193450927734375e-05, "timer/dataset_eval_min": 2.193450927734375e-05, "timer/dataset_eval_max": 2.193450927734375e-05, "fps": 20.651598087829395}
{"step": 951920, "time": 47363.05080676079, "episode/length": 144.0, "episode/score": 0.15174884720909176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15174884720909176}
{"step": 952128, "time": 47372.748183727264, "episode/length": 154.0, "episode/score": 0.18433332990389317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18433332990389317}
{"step": 952184, "time": 47376.093255996704, "episode/length": 160.0, "episode/score": 0.18569857614056673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18569857614056673}
{"step": 952648, "time": 47394.73795580864, "episode/length": 64.0, "episode/score": 0.07737499853828922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07737499853828922}
{"step": 952760, "time": 47400.86172771454, "episode/length": 174.0, "episode/score": 0.18784335114469286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18784335114469286}
{"step": 952808, "time": 47404.5699737072, "episode/length": 168.0, "episode/score": 0.18861298304545926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18861298304545926}
{"step": 953056, "time": 47416.19277000427, "episode/length": 214.0, "episode/score": 0.22750524153889273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22750524153889273}
{"step": 953232, "time": 47424.163204431534, "episode/length": 165.0, "episode/score": 0.18559346307301894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18559346307301894}
{"step": 953560, "time": 47437.58520579338, "episode/length": 171.0, "episode/score": 0.20462878392572748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20462878392572748}
{"step": 954064, "time": 47457.787162303925, "episode/length": 267.0, "episode/score": 0.3093005897535477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3093005897535477}
{"step": 954232, "time": 47465.14389514923, "episode/length": 183.0, "episode/score": 0.204946584195568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.204946584195568}
{"step": 954232, "time": 47465.15375208855, "episode/length": 177.0, "episode/score": 0.2022071286555729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2022071286555729}
{"step": 954304, "time": 47471.24460935593, "episode/length": 407.0, "episode/score": 0.4213128378796682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4213128378796682}
{"step": 954352, "time": 47474.655925273895, "episode/length": 212.0, "episode/score": 0.24032354207520257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24032354207520257}
{"step": 954440, "time": 47479.10093617439, "episode/length": 150.0, "episode/score": 0.1546612272504717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1546612272504717}
{"step": 954704, "time": 47490.536366939545, "episode/length": 58.0, "episode/score": 0.06393154653778765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06393154653778765}
{"step": 954944, "time": 47500.96032714844, "episode/length": 235.0, "episode/score": 0.2738187318027485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2738187318027485}
{"step": 955192, "time": 47511.41376161575, "episode/length": 203.0, "episode/score": 0.22602172950064414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22602172950064414}
{"step": 955456, "time": 47522.736734867096, "episode/length": 143.0, "episode/score": 0.15978447682937258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15978447682937258}
{"step": 955576, "time": 47528.66801714897, "episode/length": 188.0, "episode/score": 0.20018290930238436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20018290930238436}
{"step": 955656, "time": 47533.566143512726, "episode/length": 162.0, "episode/score": 0.17965191215262166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17965191215262166}
{"step": 955688, "time": 47536.63516879082, "episode/length": 181.0, "episode/score": 0.19970402422950428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19970402422950428}
{"step": 955984, "time": 47549.994472026825, "episode/length": 192.0, "episode/score": 0.22556619021997903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22556619021997903}
{"step": 956296, "time": 47563.41547870636, "episode/length": 198.0, "episode/score": 0.22325134851416806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22325134851416806}
{"step": 956616, "time": 47577.377729177475, "episode/length": 208.0, "episode/score": 0.2421704740736459, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2421704740736459}
{"step": 956720, "time": 47583.445692777634, "episode/length": 190.0, "episode/score": 0.21583227245355374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21583227245355374}
{"step": 956920, "time": 47592.13840842247, "episode/length": 153.0, "episode/score": 0.17312438129192742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17312438129192742}
{"step": 956920, "time": 47592.145340681076, "episode/length": 182.0, "episode/score": 0.19117742587150133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19117742587150133}
{"step": 957048, "time": 47600.10228538513, "episode/length": 183.0, "episode/score": 0.20986400959191087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20986400959191087}
{"step": 957168, "time": 47606.214430093765, "episode/length": 188.0, "episode/score": 0.20084510275773937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20084510275773937}
{"step": 957408, "time": 47616.44042849541, "episode/length": 85.0, "episode/score": 0.09010367048176704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09010367048176704}
{"step": 957672, "time": 47627.377923727036, "episode/length": 210.0, "episode/score": 0.2458802957462467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2458802957462467}
{"step": 957784, "time": 47632.90132665634, "episode/length": 185.0, "episode/score": 0.20197316125631914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20197316125631914}
{"step": 958072, "time": 47644.843301057816, "episode/length": 143.0, "episode/score": 0.15867931938919355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15867931938919355}
{"step": 958552, "time": 47665.63459968567, "episode/length": 172.0, "episode/score": 0.19809669835558452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19809669835558452}
{"step": 958584, "time": 47668.69953918457, "episode/length": 146.0, "episode/score": 0.16518352889670496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16518352889670496}
{"step": 958616, "time": 47671.30951809883, "episode/length": 195.0, "episode/score": 0.21808634603621613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21808634603621613}
{"step": 958648, "time": 47674.008758068085, "episode/length": 215.0, "episode/score": 0.22982387095544254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22982387095544254}
{"step": 958808, "time": 47681.4229323864, "episode/length": 273.0, "episode/score": 0.3023134781833505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3023134781833505}
{"step": 958984, "time": 47689.34596610069, "episode/length": 163.0, "episode/score": 0.18764671308599645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18764671308599645}
{"step": 959240, "time": 47700.284343242645, "episode/length": 145.0, "episode/score": 0.1401840185835681, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1401840185835681}
{"step": 959424, "time": 47708.9243850708, "episode/length": 204.0, "episode/score": 0.19889411573967664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19889411573967664}
{"step": 959584, "time": 47716.31198096275, "episode/length": 116.0, "episode/score": 0.13981660290392028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13981660290392028}
{"step": 959920, "time": 47730.09011054039, "episode/length": 166.0, "episode/score": 0.1893080400323015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1893080400323015}
{"step": 960024, "time": 47752.71330118179, "eval_episode/length": 129.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 960024, "time": 47755.93912935257, "eval_episode/length": 172.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 960024, "time": 47757.50752615929, "eval_episode/length": 176.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 960024, "time": 47759.54822611809, "eval_episode/length": 189.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 960024, "time": 47762.724954366684, "eval_episode/length": 232.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 960024, "time": 47765.08778882027, "eval_episode/length": 255.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.99609375}
{"step": 960024, "time": 47766.689410209656, "eval_episode/length": 259.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 960024, "time": 47771.43160891533, "eval_episode/length": 177.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 960184, "time": 47777.695949316025, "episode/length": 74.0, "episode/score": 0.0800404749243171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0800404749243171}
{"step": 960560, "time": 47793.34513092041, "episode/length": 250.0, "episode/score": 0.2640561364532914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2640561364532914}
{"step": 960720, "time": 47800.93386268616, "episode/length": 216.0, "episode/score": 0.239139339841131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.239139339841131}
{"step": 960816, "time": 47805.955268383026, "episode/length": 173.0, "episode/score": 0.2004038563609356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2004038563609356}
{"step": 960824, "time": 47807.54782676697, "episode/length": 275.0, "episode/score": 0.3028492906723841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3028492906723841}
{"step": 961104, "time": 47819.50667023659, "episode/length": 232.0, "episode/score": 0.2625863050634507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2625863050634507}
{"step": 961424, "time": 47832.77785420418, "episode/length": 187.0, "episode/score": 0.2182158504438121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2182158504438121}
{"step": 961752, "time": 47846.248592853546, "episode/length": 195.0, "episode/score": 0.20630762344808318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20630762344808318}
{"step": 962088, "time": 47860.01292538643, "episode/length": 170.0, "episode/score": 0.17286318486367236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17286318486367236}
{"step": 962128, "time": 47863.231457948685, "episode/length": 414.0, "episode/score": 0.4512088238971046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4512088238971046}
{"step": 962280, "time": 47870.12593817711, "episode/length": 214.0, "episode/score": 0.24398505900171585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24398505900171585}
{"step": 962384, "time": 47875.72021961212, "episode/length": 194.0, "episode/score": 0.20068758509660256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20068758509660256}
{"step": 962432, "time": 47878.94317650795, "episode/length": 165.0, "episode/score": 0.18699353347619763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18699353347619763}
{"step": 962944, "time": 47899.2350692749, "episode/length": 189.0, "episode/score": 0.2216666627500672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2216666627500672}
{"step": 963040, "time": 47904.1511759758, "episode/length": 160.0, "episode/score": 0.16973015837356797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16973015837356797}
{"step": 963040, "time": 47904.15891575813, "episode/length": 277.0, "episode/score": 0.3036028338574397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3036028338574397}
{"step": 963568, "time": 47926.54239487648, "episode/length": 160.0, "episode/score": 0.17160835978211253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17160835978211253}
{"step": 963576, "time": 47928.13198804855, "episode/length": 180.0, "episode/score": 0.20294719779121806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20294719779121806}
{"step": 963648, "time": 47932.49842453003, "episode/length": 151.0, "episode/score": 0.1602835690791835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1602835690791835}
{"step": 963848, "time": 47941.15584564209, "episode/length": 182.0, "episode/score": 0.21890277351485565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21890277351485565}
{"step": 963880, "time": 47943.71592473984, "episode/length": 223.0, "episode/score": 0.25176759952228167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25176759952228167}
{"step": 964256, "time": 47959.14786529541, "episode/length": 163.0, "episode/score": 0.18363690167461755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18363690167461755}
{"step": 964416, "time": 47966.39393115044, "episode/length": 171.0, "episode/score": 0.2012877254292107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2012877254292107}
{"step": 964440, "time": 47968.57554149628, "episode/length": 174.0, "episode/score": 0.164353606682198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.164353606682198}
{"step": 964744, "time": 47981.06389713287, "episode/length": 146.0, "episode/score": 0.15032700437768654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15032700437768654}
{"step": 965136, "time": 47997.053059101105, "episode/length": 156.0, "episode/score": 0.17831357340764953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17831357340764953}
{"step": 965152, "time": 47999.073160648346, "episode/length": 196.0, "episode/score": 0.20197703080339124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20197703080339124}
{"step": 965288, "time": 48005.33554291725, "episode/length": 204.0, "episode/score": 0.23129852070815105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23129852070815105}
{"step": 965744, "time": 48023.86206793785, "episode/length": 185.0, "episode/score": 0.2172219379353919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2172219379353919}
{"step": 965848, "time": 48028.866908311844, "episode/length": 175.0, "episode/score": 0.18847118949088326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18847118949088326}
{"step": 965912, "time": 48032.74644899368, "episode/length": 186.0, "episode/score": 0.20703832925937604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20703832925937604}
{"step": 966144, "time": 48043.01248335838, "episode/length": 174.0, "episode/score": 0.19920813813405402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19920813813405402}
{"step": 966528, "time": 48058.512125492096, "episode/length": 171.0, "episode/score": 0.17365414401228918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17365414401228918}
{"step": 966712, "time": 48068.15306639671, "episode/length": 177.0, "episode/score": 0.18659202587059553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18659202587059553}
{"step": 967152, "time": 48085.966869831085, "episode/length": 175.0, "episode/score": 0.19123713321459945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19123713321459945}
{"step": 967232, "time": 48090.371992111206, "episode/length": 422.0, "episode/score": 0.43643635726130015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.43643635726130015}
{"step": 967280, "time": 48093.61249732971, "episode/length": 178.0, "episode/score": 0.1789489558113928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1789489558113928}
{"step": 967312, "time": 48096.352959394455, "episode/length": 271.0, "episode/score": 0.3035979124069854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3035979124069854}
{"step": 967352, "time": 48099.266765117645, "episode/length": 150.0, "episode/score": 0.17872841676762619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17872841676762619}
{"step": 967568, "time": 48108.829031705856, "episode/length": 206.0, "episode/score": 0.23859686872401653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23859686872401653}
{"step": 968000, "time": 48126.11253452301, "episode/length": 160.0, "episode/score": 0.17676685547667148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17676685547667148}
{"step": 968592, "time": 48149.401309490204, "episode/length": 163.0, "episode/score": 0.1834159942372935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1834159942372935}
{"step": 968608, "time": 48151.5708360672, "episode/length": 181.0, "episode/score": 0.1985210089242173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1985210089242173}
{"step": 968624, "time": 48153.678317308426, "episode/length": 173.0, "episode/score": 0.19448855260361597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19448855260361597}
{"step": 968632, "time": 48155.185722112656, "episode/length": 164.0, "episode/score": 0.18650348687970109, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18650348687970109}
{"step": 968752, "time": 48161.27066922188, "episode/length": 277.0, "episode/score": 0.3291487500810035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3291487500810035}
{"step": 968864, "time": 48166.93984413147, "episode/length": 161.0, "episode/score": 0.1867210023556254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1867210023556254}
{"step": 969176, "time": 48179.50039219856, "episode/length": 227.0, "episode/score": 0.24630306440121785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24630306440121785}
{"step": 969320, "time": 48186.335110902786, "episode/length": 164.0, "episode/score": 0.1901689269761846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1901689269761846}
{"step": 969984, "time": 48213.069793224335, "episode/length": 171.0, "episode/score": 0.18102985781024472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18102985781024472}
{"step": 970008, "time": 48234.10403871536, "eval_episode/length": 58.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9491525423728814}
{"step": 970008, "time": 48239.71419262886, "eval_episode/length": 144.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.993103448275862}
{"step": 970008, "time": 48242.03376674652, "eval_episode/length": 151.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.993421052631579}
{"step": 970008, "time": 48244.21290397644, "eval_episode/length": 157.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 970008, "time": 48247.03858971596, "eval_episode/length": 175.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 970008, "time": 48250.803522109985, "eval_episode/length": 64.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9230769230769231}
{"step": 970008, "time": 48253.87070226669, "eval_episode/length": 180.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 970008, "time": 48256.465426683426, "eval_episode/length": 255.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9765625}
{"step": 970048, "time": 48258.2107667923, "episode/length": 177.0, "episode/score": 0.2042881793813649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2042881793813649}
{"step": 970096, "time": 48261.936074495316, "episode/length": 187.0, "episode/score": 0.21015309106496716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21015309106496716}
{"step": 970312, "time": 48271.12006354332, "episode/length": 180.0, "episode/score": 0.18178497671760852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18178497671760852}
{"step": 970432, "time": 48277.20727849007, "episode/length": 224.0, "episode/score": 0.24165191312204115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24165191312204115}
{"step": 970616, "time": 48285.17197751999, "episode/length": 232.0, "episode/score": 0.2756957238398172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2756957238398172}
{"step": 970696, "time": 48289.65538430214, "episode/length": 189.0, "episode/score": 0.1958590295553222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1958590295553222}
{"step": 970952, "time": 48300.53237724304, "episode/length": 203.0, "episode/score": 0.22157594823602267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22157594823602267}
{"step": 971480, "time": 48321.676357507706, "episode/length": 186.0, "episode/score": 0.20289143319041614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20289143319041614}
{"step": 971632, "time": 48329.507781505585, "episode/length": 191.0, "episode/score": 0.2048577112800558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2048577112800558}
{"step": 971688, "time": 48333.455392599106, "episode/length": 25.0, "episode/score": 0.03133333270670846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03133333270670846}
{"step": 971816, "time": 48340.32594895363, "episode/length": 187.0, "episode/score": 0.21189176396637777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21189176396637777}
{"step": 971824, "time": 48342.74706149101, "episode/length": 173.0, "episode/score": 0.19307683324313984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19307683324313984}
{"step": 971896, "time": 48347.198751688, "episode/length": 159.0, "episode/score": 0.1691605209766749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1691605209766749}
{"step": 972136, "time": 48358.18359065056, "episode/length": 179.0, "episode/score": 0.2012548444577078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2012548444577078}
{"step": 972177, "time": 48362.366085767746, "train_stats/sum_log_reward": 1.95185181553717, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 3.8333333333333335, "train_stats/max_log_achievement_collect_sapling": 0.5648148148148148, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.287037037037037, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.05555555555555555, "train_stats/max_log_achievement_eat_cow": 0.009259259259259259, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07407407407407407, "train_stats/max_log_achievement_make_wood_sword": 0.07407407407407407, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.37962962962962965, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.3148148148148148, "train_stats/max_log_achievement_wake_up": 0.14814814814814814, "train_stats/mean_log_entropy": 2.0862539123605797, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.032236654927411, "train/action_min": 0.0, "train/action_std": 4.824868172172486, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008469840808676219, "train/actor_opt_grad_steps": 60030.0, "train/actor_opt_loss": -11.642104619169814, "train/adv_mag": 0.177706486010176, "train/adv_max": 0.13232659319723686, "train/adv_mean": -1.3222004595514219e-05, "train/adv_min": -0.17611476767250872, "train/adv_std": 0.013890477227355083, "train/cont_avg": 0.9945943036417323, "train/cont_loss_mean": 7.139892106925266e-05, "train/cont_loss_std": 0.0020685538110829325, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0027170589109929764, "train/cont_pos_acc": 0.9999768100385591, "train/cont_pos_loss": 5.6853638991047926e-05, "train/cont_pred": 0.9945789406618734, "train/cont_rate": 0.9945943036417323, "train/dyn_loss_mean": 10.787382456261343, "train/dyn_loss_std": 8.777761831058292, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1292465770191799, "train/extr_critic_critic_opt_grad_steps": 60030.0, "train/extr_critic_critic_opt_loss": 12140.8491941437, "train/extr_critic_mag": 0.2883386630711593, "train/extr_critic_max": 0.2883386630711593, "train/extr_critic_mean": 0.23286793058312785, "train/extr_critic_min": 0.0013653743924118401, "train/extr_critic_std": 0.06460805301825831, "train/extr_return_normed_mag": 0.2229046828634157, "train/extr_return_normed_max": 0.2229046828634157, "train/extr_return_normed_mean": 0.16763907659241534, "train/extr_return_normed_min": -0.06418553713386453, "train/extr_return_normed_std": 0.06607696742523374, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.288120294415106, "train/extr_return_raw_max": 0.288120294415106, "train/extr_return_raw_mean": 0.23285469178139695, "train/extr_return_raw_min": 0.0010300743298267754, "train/extr_return_raw_std": 0.06607696786522865, "train/extr_reward_mag": 0.001345959235364058, "train/extr_reward_max": 0.001345959235364058, "train/extr_reward_mean": 0.001105602069823878, "train/extr_reward_min": 1.0812376427838182e-05, "train/extr_reward_std": 0.00023753812085602463, "train/image_loss_mean": 4.678719839711827, "train/image_loss_std": 9.988741326519824, "train/model_loss_mean": 11.191669291398657, "train/model_loss_std": 13.648887078593097, "train/model_opt_grad_norm": 47.956885615671716, "train/model_opt_grad_steps": 59973.83464566929, "train/model_opt_loss": 14454.3169675812, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1289.3700787401574, "train/policy_entropy_mag": 2.7649346543109323, "train/policy_entropy_max": 2.7649346543109323, "train/policy_entropy_mean": 2.0863814607379942, "train/policy_entropy_min": 0.07957776624152041, "train/policy_entropy_std": 0.629539557563977, "train/policy_logprob_mag": 7.438272603853481, "train/policy_logprob_max": -0.009483966675740996, "train/policy_logprob_mean": -2.086389001898878, "train/policy_logprob_min": -7.438272603853481, "train/policy_logprob_std": 1.157148514206954, "train/policy_randomness_mag": 0.9759005983983438, "train/policy_randomness_max": 0.9759005983983438, "train/policy_randomness_mean": 0.7364011054902565, "train/policy_randomness_min": 0.028087459357939368, "train/policy_randomness_std": 0.22219983857917033, "train/post_ent_mag": 59.882064518966075, "train/post_ent_max": 59.882064518966075, "train/post_ent_mean": 42.77496782438023, "train/post_ent_min": 19.75695732447106, "train/post_ent_std": 7.360486210800532, "train/prior_ent_mag": 69.71754233292707, "train/prior_ent_max": 69.71754233292707, "train/prior_ent_mean": 53.62681150060939, "train/prior_ent_min": 34.9720969312773, "train/prior_ent_std": 5.241443986967792, "train/rep_loss_mean": 10.787382456261343, "train/rep_loss_std": 8.777761831058292, "train/reward_avg": 0.0010729822711505758, "train/reward_loss_mean": 0.040448619566095155, "train/reward_loss_std": 0.010970315690643676, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0013016715763122077, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.040448619507429166, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.001073459464887993, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.4124999847263098, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.8125, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.3125, "eval_stats/max_log_achievement_wake_up": 0.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 5.355689791031182e-05, "report/cont_loss_std": 0.0011513050412759185, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00015582854393869638, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 5.315582893672399e-05, "report/cont_pred": 0.9960421323776245, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.667707443237305, "report/dyn_loss_std": 9.265562057495117, "report/image_loss_mean": 4.830219268798828, "report/image_loss_std": 12.164554595947266, "report/model_loss_mean": 11.870990753173828, "report/model_loss_std": 15.817534446716309, "report/post_ent_mag": 59.300567626953125, "report/post_ent_max": 59.300567626953125, "report/post_ent_mean": 41.958091735839844, "report/post_ent_min": 20.789979934692383, "report/post_ent_std": 7.4799065589904785, "report/prior_ent_mag": 69.96110534667969, "report/prior_ent_max": 69.96110534667969, "report/prior_ent_mean": 54.033817291259766, "report/prior_ent_min": 35.946720123291016, "report/prior_ent_std": 5.710519313812256, "report/rep_loss_mean": 11.667707443237305, "report/rep_loss_std": 9.265562057495117, "report/reward_avg": 0.001063226256519556, "report/reward_loss_mean": 0.040092259645462036, "report/reward_loss_std": 0.011980554088950157, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012704133987426758, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.040092259645462036, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010487665422260761, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0011861477978527546, "eval/cont_loss_std": 0.03474361449480057, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.18852435052394867, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.199360308935866e-05, "eval/cont_pred": 0.9947382211685181, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 15.657540321350098, "eval/dyn_loss_std": 10.774110794067383, "eval/image_loss_mean": 9.108591079711914, "eval/image_loss_std": 15.238802909851074, "eval/model_loss_mean": 19.750871658325195, "eval/model_loss_std": 20.68119239807129, "eval/post_ent_mag": 60.708587646484375, "eval/post_ent_max": 60.708587646484375, "eval/post_ent_mean": 41.42024230957031, "eval/post_ent_min": 19.940603256225586, "eval/post_ent_std": 7.663334846496582, "eval/prior_ent_mag": 69.96110534667969, "eval/prior_ent_max": 69.96110534667969, "eval/prior_ent_mean": 54.518821716308594, "eval/prior_ent_min": 32.172550201416016, "eval/prior_ent_std": 4.818187236785889, "eval/rep_loss_mean": 15.657540321350098, "eval/rep_loss_std": 10.774110794067383, "eval/reward_avg": 0.02226562425494194, "eval/reward_loss_mean": 1.246570348739624, "eval/reward_loss_std": 4.83291482925415, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012508630752563477, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.6711992621421814, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.98775291442871, "eval/reward_pred": 0.0010691673960536718, "eval/reward_rate": 0.0283203125, "replay/size": 971673.0, "replay/inserts": 20272.0, "replay/samples": 20272.0, "replay/insert_wait_avg": 1.3041397484626559e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.970180677069203e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4512.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2102173575272797e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0322840213776, "timer/env.step_count": 2534.0, "timer/env.step_total": 236.01248836517334, "timer/env.step_frac": 0.23600486917893157, "timer/env.step_avg": 0.09313831427197054, "timer/env.step_min": 0.022661209106445312, "timer/env.step_max": 3.284451961517334, "timer/replay._sample_count": 20272.0, "timer/replay._sample_total": 9.833935499191284, "timer/replay._sample_frac": 0.00983361803045657, "timer/replay._sample_avg": 0.00048509942280935693, "timer/replay._sample_min": 0.00037407875061035156, "timer/replay._sample_max": 0.010647296905517578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3098.0, "timer/agent.policy_total": 49.93364238739014, "timer/agent.policy_frac": 0.0499320303806539, "timer/agent.policy_avg": 0.016118025302579126, "timer/agent.policy_min": 0.009554147720336914, "timer/agent.policy_max": 0.12922072410583496, "timer/dataset_train_count": 1267.0, "timer/dataset_train_total": 0.13489460945129395, "timer/dataset_train_frac": 0.00013489025465142915, "timer/dataset_train_avg": 0.00010646772648089498, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.00025081634521484375, "timer/agent.train_count": 1267.0, "timer/agent.train_total": 567.6712191104889, "timer/agent.train_frac": 0.5676528929923564, "timer/agent.train_avg": 0.4480435825655003, "timer/agent.train_min": 0.4337031841278076, "timer/agent.train_max": 1.2026686668395996, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4812049865722656, "timer/agent.report_frac": 0.0004811894518417157, "timer/agent.report_avg": 0.2406024932861328, "timer/agent.report_min": 0.23349976539611816, "timer/agent.report_max": 0.24770522117614746, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2411346435546875e-05, "timer/dataset_eval_frac": 2.24106229305171e-08, "timer/dataset_eval_avg": 2.2411346435546875e-05, "timer/dataset_eval_min": 2.2411346435546875e-05, "timer/dataset_eval_max": 2.2411346435546875e-05, "fps": 20.271118014128533}
{"step": 972464, "time": 48373.08104753494, "episode/length": 188.0, "episode/score": 0.19852031372738566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19852031372738566}
{"step": 972912, "time": 48391.01628422737, "episode/length": 159.0, "episode/score": 0.18393191068662418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18393191068662418}
{"step": 972928, "time": 48393.103962183, "episode/length": 154.0, "episode/score": 0.18177624597365138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18177624597365138}
{"step": 972960, "time": 48395.730085134506, "episode/length": 363.0, "episode/score": 0.3895474403479966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3895474403479966}
{"step": 973360, "time": 48411.95522618294, "episode/length": 191.0, "episode/score": 0.204538611764292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.204538611764292}
{"step": 973408, "time": 48415.343710660934, "episode/length": 158.0, "episode/score": 0.18106838669336867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18106838669336867}
{"step": 973608, "time": 48423.868878126144, "episode/length": 84.0, "episode/score": 0.09621498069327572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09621498069327572}
{"step": 973928, "time": 48437.134068489075, "episode/length": 182.0, "episode/score": 0.1998388152892403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1998388152892403}
{"step": 974088, "time": 48444.59105205536, "episode/length": 140.0, "episode/score": 0.16082210456715984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16082210456715984}
{"step": 974208, "time": 48450.70704746246, "episode/length": 161.0, "episode/score": 0.16339955714329335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16339955714329335}
{"step": 974288, "time": 48455.075112104416, "episode/length": 308.0, "episode/score": 0.34234814534784164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34234814534784164}
{"step": 974416, "time": 48461.259038209915, "episode/length": 314.0, "episode/score": 0.34593292965291766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34593292965291766}
{"step": 974608, "time": 48469.90249347687, "episode/length": 155.0, "episode/score": 0.1730265306396177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1730265306396177}
{"step": 974968, "time": 48485.673189878464, "episode/length": 194.0, "episode/score": 0.20168489783509358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20168489783509358}
{"step": 975224, "time": 48496.59280991554, "episode/length": 161.0, "episode/score": 0.18039736772607284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18039736772607284}
{"step": 975744, "time": 48517.43856048584, "episode/length": 191.0, "episode/score": 0.21776963922775394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21776963922775394}
{"step": 975784, "time": 48520.22066068649, "episode/length": 211.0, "episode/score": 0.22640608696474374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22640608696474374}
{"step": 975872, "time": 48525.07999539375, "episode/length": 157.0, "episode/score": 0.17497462590608848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17497462590608848}
{"step": 976200, "time": 48538.18808913231, "episode/length": 238.0, "episode/score": 0.2736556107975048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2736556107975048}
{"step": 976408, "time": 48547.27202677727, "episode/length": 349.0, "episode/score": 0.388800301806441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.388800301806441}
{"step": 976544, "time": 48553.809643507004, "episode/length": 265.0, "episode/score": 0.29921739236851863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.29921739236851863}
{"step": 976560, "time": 48555.94299578667, "episode/length": 166.0, "episode/score": 0.1856101161101833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1856101161101833}
{"step": 977256, "time": 48582.643876791, "episode/length": 188.0, "episode/score": 0.1991833137726644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1991833137726644}
{"step": 977344, "time": 48587.54916095734, "episode/length": 194.0, "episode/score": 0.2249583293159958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2249583293159958}
{"step": 977344, "time": 48587.55722951889, "episode/length": 183.0, "episode/score": 0.20820643588376697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20820643588376697}
{"step": 977488, "time": 48595.84712719917, "episode/length": 314.0, "episode/score": 0.34549074056349127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.34549074056349127}
{"step": 977712, "time": 48605.56502819061, "episode/length": 162.0, "episode/score": 0.18270113020844292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18270113020844292}
{"step": 977896, "time": 48616.109020233154, "episode/length": 168.0, "episode/score": 0.1887801027551177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1887801027551177}
{"step": 977960, "time": 48620.07665300369, "episode/length": 174.0, "episode/score": 0.1918629897336359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1918629897336359}
{"step": 978264, "time": 48632.5770983696, "episode/length": 257.0, "episode/score": 0.28708008969260845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.28708008969260845}
{"step": 978632, "time": 48647.45088791847, "episode/length": 142.0, "episode/score": 0.16506785426099668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16506785426099668}
{"step": 978648, "time": 48649.549607515335, "episode/length": 162.0, "episode/score": 0.1648503058422648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1648503058422648}
{"step": 978680, "time": 48652.26838350296, "episode/length": 166.0, "episode/score": 0.18502381118014455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18502381118014455}
{"step": 978928, "time": 48663.10316514969, "episode/length": 128.0, "episode/score": 0.13895190454786643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13895190454786643}
{"step": 978952, "time": 48665.2255628109, "episode/length": 211.0, "episode/score": 0.23875237531319726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23875237531319726}
{"step": 979184, "time": 48675.44670534134, "episode/length": 183.0, "episode/score": 0.20006691065282212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20006691065282212}
{"step": 979280, "time": 48680.51498246193, "episode/length": 164.0, "episode/score": 0.1780239228028222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1780239228028222}
{"step": 979688, "time": 48696.70576906204, "episode/length": 177.0, "episode/score": 0.19975622452329844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19975622452329844}
{"step": 980096, "time": 48732.618356227875, "eval_episode/length": 156.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 980096, "time": 48735.10456061363, "eval_episode/length": 167.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 980096, "time": 48737.21027517319, "eval_episode/length": 170.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 980096, "time": 48739.29374432564, "eval_episode/length": 172.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 980096, "time": 48741.72512054443, "eval_episode/length": 184.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 980096, "time": 48743.82255125046, "eval_episode/length": 189.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 980096, "time": 48745.819503068924, "eval_episode/length": 206.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 980096, "time": 48750.61557197571, "eval_episode/length": 292.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9965870307167235}
{"step": 980136, "time": 48751.86675906181, "episode/length": 185.0, "episode/score": 0.2072855891965446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2072855891965446}
{"step": 980368, "time": 48762.2065410614, "episode/length": 176.0, "episode/score": 0.19244013948264183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19244013948264183}
{"step": 980704, "time": 48776.15134835243, "episode/length": 177.0, "episode/score": 0.18413304184105073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18413304184105073}
{"step": 980728, "time": 48778.40633034706, "episode/length": 261.0, "episode/score": 0.2992021051722986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2992021051722986}
{"step": 980784, "time": 48782.16370892525, "episode/length": 231.0, "episode/score": 0.2758501907464961, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2758501907464961}
{"step": 980912, "time": 48788.369002342224, "episode/length": 152.0, "episode/score": 0.1757418396155117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1757418396155117}
{"step": 981088, "time": 48796.32956290245, "episode/length": 300.0, "episode/score": 0.3440318496868713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3440318496868713}
{"step": 981248, "time": 48804.35011291504, "episode/length": 257.0, "episode/score": 0.2970964699070464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2970964699070464}
{"step": 981800, "time": 48825.911593437195, "episode/length": 178.0, "episode/score": 0.203703307066462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.203703307066462}
{"step": 981864, "time": 48830.22158575058, "episode/length": 215.0, "episode/score": 0.24316963870660402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24316963870660402}
{"step": 982072, "time": 48839.81147861481, "episode/length": 170.0, "episode/score": 0.17998478162189713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17998478162189713}
{"step": 982344, "time": 48851.356140851974, "episode/length": 201.0, "episode/score": 0.2108569691699813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2108569691699813}
{"step": 982648, "time": 48864.12101531029, "episode/length": 194.0, "episode/score": 0.22513294113014126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22513294113014126}
{"step": 982744, "time": 48869.35597252846, "episode/length": 244.0, "episode/score": 0.27423610093683237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27423610093683237}
{"step": 982776, "time": 48872.07840013504, "episode/length": 190.0, "episode/score": 0.2128003762481967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2128003762481967}
{"step": 983088, "time": 48886.69073176384, "episode/length": 271.0, "episode/score": 0.30919193249428645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.30919193249428645}
{"step": 983192, "time": 48891.7463684082, "episode/length": 165.0, "episode/score": 0.16438618857500842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16438618857500842}
{"step": 983360, "time": 48899.50787496567, "episode/length": 194.0, "episode/score": 0.2257449089847796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2257449089847796}
{"step": 983472, "time": 48905.0152964592, "episode/length": 174.0, "episode/score": 0.1944372879988805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1944372879988805}
{"step": 983888, "time": 48921.796870946884, "episode/length": 192.0, "episode/score": 0.2070908591085754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2070908591085754}
{"step": 983912, "time": 48924.001089811325, "episode/length": 157.0, "episode/score": 0.16765066128937178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16765066128937178}
{"step": 984136, "time": 48933.570719242096, "episode/length": 173.0, "episode/score": 0.20280104258745268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20280104258745268}
{"step": 984200, "time": 48937.51127886772, "episode/length": 177.0, "episode/score": 0.1980406305519864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1980406305519864}
{"step": 984496, "time": 48949.97563242912, "episode/length": 162.0, "episode/score": 0.18369507947318198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18369507947318198}
{"step": 984512, "time": 48952.03710126877, "episode/length": 177.0, "episode/score": 0.1956679212871677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1956679212871677}
{"step": 985344, "time": 48983.925161123276, "episode/length": 178.0, "episode/score": 0.19722983862448018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19722983862448018}
{"step": 985384, "time": 48986.653962135315, "episode/length": 238.0, "episode/score": 0.2642113633246481, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2642113633246481}
{"step": 985416, "time": 48989.36661481857, "episode/length": 159.0, "episode/score": 0.1679370824876969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1679370824876969}
{"step": 985552, "time": 48996.073705911636, "episode/length": 168.0, "episode/score": 0.195070000276246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.195070000276246}
{"step": 985664, "time": 49001.73134493828, "episode/length": 221.0, "episode/score": 0.22477639898897905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22477639898897905}
{"step": 985728, "time": 49005.543818712234, "episode/length": 151.0, "episode/score": 0.15950349252307205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15950349252307205}
{"step": 985952, "time": 49015.13775777817, "episode/length": 181.0, "episode/score": 0.17134471956524067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17134471956524067}
{"step": 986688, "time": 49043.40830230713, "episode/length": 167.0, "episode/score": 0.18891961838562565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18891961838562565}
{"step": 986752, "time": 49047.27740573883, "episode/length": 170.0, "episode/score": 0.20353842706390424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20353842706390424}
{"step": 986808, "time": 49051.105498313904, "episode/length": 156.0, "episode/score": 0.15773186551541585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15773186551541585}
{"step": 986824, "time": 49053.62231731415, "episode/length": 432.0, "episode/score": 0.4170684127839195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4170684127839195}
{"step": 987000, "time": 49062.217366695404, "episode/length": 158.0, "episode/score": 0.18013691117630515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18013691117630515}
{"step": 987160, "time": 49069.48430299759, "episode/length": 186.0, "episode/score": 0.21904166275635362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21904166275635362}
{"step": 987288, "time": 49075.61686491966, "episode/length": 166.0, "episode/score": 0.1974923207253596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1974923207253596}
{"step": 987400, "time": 49081.09045267105, "episode/length": 247.0, "episode/score": 0.2662739440875157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2662739440875157}
{"step": 987720, "time": 49094.44397997856, "episode/length": 128.0, "episode/score": 0.14452642532705795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14452642532705795}
{"step": 988168, "time": 49112.20966172218, "episode/length": 169.0, "episode/score": 0.1894732569990083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1894732569990083}
{"step": 988232, "time": 49115.97632479668, "episode/length": 184.0, "episode/score": 0.18630562557427766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18630562557427766}
{"step": 988432, "time": 49125.22962522507, "episode/length": 200.0, "episode/score": 0.22433327997168817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22433327997168817}
{"step": 988584, "time": 49132.68690228462, "episode/length": 197.0, "episode/score": 0.22667162017296505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22667162017296505}
{"step": 988680, "time": 49138.28643035889, "episode/length": 159.0, "episode/score": 0.18740727816657454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18740727816657454}
{"step": 988744, "time": 49142.74437522888, "episode/length": 197.0, "episode/score": 0.2189424748203237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2189424748203237}
{"step": 989104, "time": 49158.186346530914, "episode/length": 226.0, "episode/score": 0.25409014195429336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.25409014195429336}
{"step": 989272, "time": 49165.494272470474, "episode/length": 73.0, "episode/score": 0.08109458274611825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08109458274611825}
{"step": 989664, "time": 49181.596472263336, "episode/length": 178.0, "episode/score": 0.19961217308627965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19961217308627965}
{"step": 989792, "time": 49187.79795885086, "episode/length": 202.0, "episode/score": 0.23302777367644012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23302777367644012}
{"step": 989832, "time": 49190.63297247887, "episode/length": 155.0, "episode/score": 0.17982722498709336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17982722498709336}
{"step": 990000, "time": 49198.45724916458, "episode/length": 195.0, "episode/score": 0.21170910847740743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21170910847740743}
{"step": 990080, "time": 49220.64791202545, "eval_episode/length": 138.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9568345323741008}
{"step": 990080, "time": 49223.39427280426, "eval_episode/length": 168.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 990080, "time": 49225.334976673126, "eval_episode/length": 177.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 990080, "time": 49226.93241071701, "eval_episode/length": 179.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 990080, "time": 49226.939510822296, "eval_episode/length": 179.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 990080, "time": 49231.225479364395, "eval_episode/length": 208.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 990080, "time": 49233.068180799484, "eval_episode/length": 214.0, "eval_episode/score": 2.1000000163912773, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 990080, "time": 49235.64536809921, "eval_episode/length": 240.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.995850622406639}
{"step": 990168, "time": 49238.79765510559, "episode/length": 177.0, "episode/score": 0.19169699793474138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19169699793474138}
{"step": 990360, "time": 49247.879348278046, "episode/length": 156.0, "episode/score": 0.16309666929737432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16309666929737432}
{"step": 991080, "time": 49275.745295763016, "episode/length": 176.0, "episode/score": 0.1984206920114957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1984206920114957}
{"step": 991240, "time": 49283.74328637123, "episode/length": 439.0, "episode/score": 0.44760614770075335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44760614770075335}
{"step": 991328, "time": 49289.883031606674, "episode/length": 165.0, "episode/score": 0.19894791260594502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19894791260594502}
{"step": 991592, "time": 49300.841994524, "episode/length": 153.0, "episode/score": 0.16593099078636442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16593099078636442}
{"step": 991600, "time": 49302.852274656296, "episode/length": 290.0, "episode/score": 0.33549938854503125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33549938854503125}
{"step": 991632, "time": 49305.49855041504, "episode/length": 182.0, "episode/score": 0.2013391008867984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2013391008867984}
{"step": 991864, "time": 49315.2102792263, "episode/length": 253.0, "episode/score": 0.2738108262519745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2738108262519745}
{"step": 991984, "time": 49321.353630781174, "episode/length": 273.0, "episode/score": 0.3059906604912612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3059906604912612}
{"step": 992472, "time": 49340.346566200256, "episode/length": 173.0, "episode/score": 0.17695033976451668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17695033976451668}
{"step": 993017, "time": 49362.86064529419, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.085775522085337, "train/action_min": 0.0, "train/action_std": 4.760966634750366, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008114833789519393, "train/actor_opt_grad_steps": 61315.0, "train/actor_opt_loss": -12.442788261633654, "train/adv_mag": 0.1780105173587799, "train/adv_max": 0.12954527999346072, "train/adv_mean": -0.00013002347904095867, "train/adv_min": -0.17738919842701692, "train/adv_std": 0.01342565337769114, "train/cont_avg": 0.99453125, "train/cont_loss_mean": 0.000211603052638792, "train/cont_loss_std": 0.006467480104060996, "train/cont_neg_acc": 0.9964010995167952, "train/cont_neg_loss": 0.012006927991905059, "train/cont_pos_acc": 0.9999621762679174, "train/cont_pos_loss": 0.00014608635662144345, "train/cont_pred": 0.9945261643483089, "train/cont_rate": 0.99453125, "train/dyn_loss_mean": 10.802363718472995, "train/dyn_loss_std": 8.662283600293673, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12859839421625321, "train/extr_critic_critic_opt_grad_steps": 61315.0, "train/extr_critic_critic_opt_loss": 12122.070650540865, "train/extr_critic_mag": 0.2859218111405006, "train/extr_critic_max": 0.2859218111405006, "train/extr_critic_mean": 0.23005530123527235, "train/extr_critic_min": 0.0013050602032588078, "train/extr_critic_std": 0.06502269967817344, "train/extr_return_normed_mag": 0.22316243614141756, "train/extr_return_normed_max": 0.22316243614141756, "train/extr_return_normed_mean": 0.16757470827836257, "train/extr_return_normed_min": -0.061338227356855686, "train/extr_return_normed_std": 0.06652672012838033, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2855130014511255, "train/extr_return_raw_max": 0.2855130014511255, "train/extr_return_raw_mean": 0.22992527576593252, "train/extr_return_raw_min": 0.0010123381247887245, "train/extr_return_raw_std": 0.06652672027166073, "train/extr_reward_mag": 0.0013434281715979943, "train/extr_reward_max": 0.0013434281715979943, "train/extr_reward_mean": 0.0011002512451691122, "train/extr_reward_min": 1.1783379774827223e-05, "train/extr_reward_std": 0.0002415656437873482, "train/image_loss_mean": 4.631949676000155, "train/image_loss_std": 9.871663431020883, "train/model_loss_mean": 11.154059179012592, "train/model_loss_std": 13.450549961970403, "train/model_opt_grad_norm": 47.401012860811676, "train/model_opt_grad_steps": 61257.17692307692, "train/model_opt_loss": 8528.039167668268, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 769.2307692307693, "train/policy_entropy_mag": 2.764083589040316, "train/policy_entropy_max": 2.764083589040316, "train/policy_entropy_mean": 2.1189884699307955, "train/policy_entropy_min": 0.07956757362072285, "train/policy_entropy_std": 0.6023432722458473, "train/policy_logprob_mag": 7.438211455711952, "train/policy_logprob_max": -0.00948267190788801, "train/policy_logprob_mean": -2.119232964515686, "train/policy_logprob_min": -7.438211455711952, "train/policy_logprob_std": 1.132882837148813, "train/policy_randomness_mag": 0.9756002077689537, "train/policy_randomness_max": 0.9756002077689537, "train/policy_randomness_mean": 0.7479099379136012, "train/policy_randomness_min": 0.028083861776842522, "train/policy_randomness_std": 0.2126007434267264, "train/post_ent_mag": 59.70348369891827, "train/post_ent_max": 59.70348369891827, "train/post_ent_mean": 42.777704943143405, "train/post_ent_min": 19.68513240814209, "train/post_ent_std": 7.2992420820089485, "train/prior_ent_mag": 69.79006823026216, "train/prior_ent_max": 69.79006823026216, "train/prior_ent_mean": 53.64526531512921, "train/prior_ent_min": 35.33927310063289, "train/prior_ent_std": 5.164605162693904, "train/rep_loss_mean": 10.802363718472995, "train/rep_loss_std": 8.662283600293673, "train/reward_avg": 0.0010737411821117768, "train/reward_loss_mean": 0.040479705998530756, "train/reward_loss_std": 0.010942168103960844, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.001293772917527419, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04047970614181115, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010736179914182195, "train/reward_rate": 0.0, "train_stats/sum_log_reward": 2.3058823075364616, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 2.9411764705882355, "train_stats/max_log_achievement_collect_sapling": 0.7941176470588235, "train_stats/max_log_achievement_collect_stone": 0.09803921568627451, "train_stats/max_log_achievement_collect_wood": 1.9019607843137254, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.0784313725490196, "train_stats/max_log_achievement_eat_cow": 0.00980392156862745, "train_stats/max_log_achievement_make_wood_pickaxe": 0.09803921568627451, "train_stats/max_log_achievement_make_wood_sword": 0.049019607843137254, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.5, "train_stats/max_log_achievement_place_stone": 0.029411764705882353, "train_stats/max_log_achievement_place_table": 0.3431372549019608, "train_stats/max_log_achievement_wake_up": 0.2647058823529412, "train_stats/mean_log_entropy": 2.1384995381037393, "eval_stats/sum_log_reward": 1.7249999837949872, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_sapling": 0.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.25, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.4375, "eval_stats/max_log_achievement_wake_up": 0.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.9514738596626557e-05, "report/cont_loss_std": 0.0006137306336313486, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.9554370737751015e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.9514543964760378e-05, "report/cont_pred": 0.9950980544090271, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 10.37005615234375, "report/dyn_loss_std": 9.201610565185547, "report/image_loss_mean": 3.801456928253174, "report/image_loss_std": 12.303264617919922, "report/model_loss_mean": 10.064279556274414, "report/model_loss_std": 15.739143371582031, "report/post_ent_mag": 58.585609436035156, "report/post_ent_max": 58.585609436035156, "report/post_ent_mean": 42.39903259277344, "report/post_ent_min": 20.738906860351562, "report/post_ent_std": 7.832759857177734, "report/prior_ent_mag": 69.99484252929688, "report/prior_ent_max": 69.99484252929688, "report/prior_ent_mean": 52.73826599121094, "report/prior_ent_min": 35.52009582519531, "report/prior_ent_std": 5.326805114746094, "report/rep_loss_mean": 10.37005615234375, "report/rep_loss_std": 9.201610565185547, "report/reward_avg": 0.001081335823982954, "report/reward_loss_mean": 0.04076995700597763, "report/reward_loss_std": 0.010241704992949963, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0013104677200317383, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.04076995700597763, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010839874157682061, "report/reward_rate": 0.0, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 7.69212329032598e-06, "eval/cont_loss_std": 0.00024130463134497404, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001121699227951467, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.4424810618484116e-08, "eval/cont_pred": 0.9931716918945312, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 17.252586364746094, "eval/dyn_loss_std": 10.67750072479248, "eval/image_loss_mean": 10.64326286315918, "eval/image_loss_std": 26.443519592285156, "eval/model_loss_mean": 21.815532684326172, "eval/model_loss_std": 30.738571166992188, "eval/post_ent_mag": 56.952369689941406, "eval/post_ent_max": 56.952369689941406, "eval/post_ent_mean": 40.047916412353516, "eval/post_ent_min": 19.452129364013672, "eval/post_ent_std": 7.471128940582275, "eval/prior_ent_mag": 69.99484252929688, "eval/prior_ent_max": 69.99484252929688, "eval/prior_ent_mean": 54.618587493896484, "eval/prior_ent_min": 37.35687255859375, "eval/prior_ent_std": 4.755898475646973, "eval/rep_loss_mean": 17.252586364746094, "eval/rep_loss_std": 10.67750072479248, "eval/reward_avg": 0.00869140587747097, "eval/reward_loss_mean": 0.8207095265388489, "eval/reward_loss_std": 3.9363412857055664, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0013360977172851562, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.5249406099319458, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.716100692749023, "eval/reward_pred": 0.0010912471916526556, "eval/reward_rate": 0.0146484375, "replay/size": 992513.0, "replay/inserts": 20840.0, "replay/samples": 20848.0, "replay/insert_wait_avg": 1.343049380692319e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.939928783788556e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4272.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.117028993613711e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4819059371948, "timer/env.step_count": 2605.0, "timer/env.step_total": 225.37848091125488, "timer/env.step_frac": 0.22526992199837245, "timer/env.step_avg": 0.08651765102159496, "timer/env.step_min": 0.022390127182006836, "timer/env.step_max": 3.0722436904907227, "timer/replay._sample_count": 20848.0, "timer/replay._sample_total": 10.01997423171997, "timer/replay._sample_frac": 0.010015147872498329, "timer/replay._sample_avg": 0.00048062040635648363, "timer/replay._sample_min": 0.0004010200500488281, "timer/replay._sample_max": 0.0111083984375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3139.0, "timer/agent.policy_total": 49.199108839035034, "timer/agent.policy_frac": 0.04917541091655035, "timer/agent.policy_avg": 0.015673497559424987, "timer/agent.policy_min": 0.009654998779296875, "timer/agent.policy_max": 0.11182093620300293, "timer/dataset_train_count": 1303.0, "timer/dataset_train_total": 0.13754749298095703, "timer/dataset_train_frac": 0.00013748123995516973, "timer/dataset_train_avg": 0.00010556215884954492, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0005061626434326172, "timer/agent.train_count": 1303.0, "timer/agent.train_total": 583.2946670055389, "timer/agent.train_frac": 0.5830137092375913, "timer/agent.train_avg": 0.44765515503111203, "timer/agent.train_min": 0.4323742389678955, "timer/agent.train_max": 2.8390772342681885, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48224902153015137, "timer/agent.report_frac": 0.00048201673480382216, "timer/agent.report_avg": 0.24112451076507568, "timer/agent.report_min": 0.23587632179260254, "timer/agent.report_max": 0.24637269973754883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7404929998205144e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 20.8297113153699}
{"step": 993024, "time": 49362.90236711502, "episode/length": 211.0, "episode/score": 0.2388571030555795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2388571030555795}
{"step": 993144, "time": 49368.978372097015, "episode/length": 192.0, "episode/score": 0.21623766217498996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21623766217498996}
{"step": 993336, "time": 49377.62713885307, "episode/length": 217.0, "episode/score": 0.2201985742854049, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2201985742854049}
{"step": 993376, "time": 49380.83298969269, "episode/length": 217.0, "episode/score": 0.24981567280474337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24981567280474337}
{"step": 993408, "time": 49383.52384185791, "episode/length": 192.0, "episode/score": 0.2051671734025149, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2051671734025149}
{"step": 993472, "time": 49387.474539756775, "episode/length": 278.0, "episode/score": 0.3076375577102226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3076375577102226}
{"step": 993520, "time": 49390.65756726265, "episode/length": 191.0, "episode/score": 0.2160447953124276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2160447953124276}
{"step": 993768, "time": 49400.93775725365, "episode/length": 161.0, "episode/score": 0.19164571458986757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19164571458986757}
{"step": 994480, "time": 49429.066730737686, "episode/length": 181.0, "episode/score": 0.21396519765312405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21396519765312405}
{"step": 994552, "time": 49433.4643509388, "episode/length": 175.0, "episode/score": 0.19924999686190858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19924999686190858}
{"step": 994560, "time": 49436.06736969948, "episode/length": 135.0, "episode/score": 0.15572681432240643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15572681432240643}
{"step": 994704, "time": 49443.39140295982, "episode/length": 165.0, "episode/score": 0.18468141263292637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18468141263292637}
{"step": 994776, "time": 49447.86406326294, "episode/length": 179.0, "episode/score": 0.2018411138560623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2018411138560623}
{"step": 994976, "time": 49457.397993564606, "episode/length": 181.0, "episode/score": 0.20715029406710528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20715029406710528}
{"step": 995032, "time": 49461.324576854706, "episode/length": 202.0, "episode/score": 0.2183285499631893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2183285499631893}
{"step": 995360, "time": 49475.35987687111, "episode/length": 198.0, "episode/score": 0.21061734810791677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21061734810791677}
{"step": 995712, "time": 49489.89050078392, "episode/length": 125.0, "episode/score": 0.13681074426494888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13681074426494888}
{"step": 995952, "time": 49500.17901515961, "episode/length": 183.0, "episode/score": 0.19615428426186554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19615428426186554}
{"step": 996056, "time": 49505.202912569046, "episode/length": 187.0, "episode/score": 0.19507997238906682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19507997238906682}
{"step": 996112, "time": 49508.99104762077, "episode/length": 193.0, "episode/score": 0.20245282422547461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20245282422547461}
{"step": 996160, "time": 49512.23223543167, "episode/length": 172.0, "episode/score": 0.1864280879490252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1864280879490252}
{"step": 996440, "time": 49523.696380376816, "episode/length": 182.0, "episode/score": 0.21203075008816086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21203075008816086}
{"step": 996584, "time": 49530.31662225723, "episode/length": 152.0, "episode/score": 0.1728493462796905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1728493462796905}
{"step": 996800, "time": 49540.07875561714, "episode/length": 220.0, "episode/score": 0.23434600133259664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23434600133259664}
{"step": 997032, "time": 49549.84704017639, "episode/length": 164.0, "episode/score": 0.17599243209770066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17599243209770066}
{"step": 997200, "time": 49557.611605644226, "episode/length": 155.0, "episode/score": 0.17854857396378065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17854857396378065}
{"step": 997384, "time": 49565.55852103233, "episode/length": 152.0, "episode/score": 0.17612760640622582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17612760640622582}
{"step": 997440, "time": 49569.47398543358, "episode/length": 165.0, "episode/score": 0.18166775454119488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18166775454119488}
{"step": 997552, "time": 49575.07667803764, "episode/length": 186.0, "episode/score": 0.19488316264323657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19488316264323657}
{"step": 998096, "time": 49596.32514381409, "episode/length": 188.0, "episode/score": 0.2201369008544134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2201369008544134}
{"step": 998328, "time": 49606.19378185272, "episode/length": 235.0, "episode/score": 0.2616441379686876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2616441379686876}
{"step": 998368, "time": 49609.29507446289, "episode/length": 195.0, "episode/score": 0.21627164499841456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21627164499841456}
{"step": 998400, "time": 49611.8692240715, "episode/length": 170.0, "episode/score": 0.1883666061767144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1883666061767144}
{"step": 998800, "time": 49628.04934883118, "episode/length": 169.0, "episode/score": 0.19811211632622872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19811211632622872}
{"step": 998968, "time": 49635.62419939041, "episode/length": 220.0, "episode/score": 0.24957883073511766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24957883073511766}
{"step": 999128, "time": 49642.992401361465, "episode/length": 217.0, "episode/score": 0.2503026078520634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2503026078520634}
{"step": 999152, "time": 49645.6773481369, "episode/length": 199.0, "episode/score": 0.23829166206996888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23829166206996888}
{"step": 999656, "time": 49666.907948970795, "episode/length": 194.0, "episode/score": 0.2400211813092028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2400211813092028}
{"step": 1000000, "time": 49681.40391588211, "episode/length": 199.0, "episode/score": 0.20935793655553425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20935793655553425}
{"step": 1000016, "time": 49683.45310211182, "episode/length": 210.0, "episode/score": 0.23425703052271274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23425703052271274}
{"step": 1000064, "time": 49707.90792441368, "eval_episode/length": 161.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 1000064, "time": 49710.43247437477, "eval_episode/length": 184.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 1000064, "time": 49712.170835733414, "eval_episode/length": 188.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 1000064, "time": 49714.07251095772, "eval_episode/length": 198.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 1000064, "time": 49715.79398012161, "eval_episode/length": 202.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9704433497536946}
{"step": 1000064, "time": 49717.51674795151, "eval_episode/length": 207.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 1000064, "time": 49719.1585919857, "eval_episode/length": 211.0, "eval_episode/score": 1.100000023841858, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 1000064, "time": 49726.01639842987, "eval_episode/length": 142.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.993006993006993}
{"step": 1000152, "time": 49729.024998664856, "episode/length": 222.0, "episode/score": 0.2373214239723893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2373214239723893}
{"step": 1000288, "time": 49735.81676387787, "episode/length": 185.0, "episode/score": 0.20363021056255093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20363021056255093}
{"step": 1000432, "time": 49742.52338171005, "episode/length": 182.0, "episode/score": 0.1981439500777924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1981439500777924}
{"step": 1000472, "time": 49745.19840478897, "episode/length": 167.0, "episode/score": 0.1922147778677754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1922147778677754}
{"step": 1000560, "time": 49750.16238236427, "episode/length": 175.0, "episode/score": 0.19669443885322835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19669443885322835}
{"step": 1000968, "time": 49766.57044196129, "episode/length": 163.0, "episode/score": 0.18752678239252418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18752678239252418}
{"step": 1001304, "time": 49780.59023451805, "episode/length": 160.0, "episode/score": 0.1859475075325463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1859475075325463}
{"step": 1001416, "time": 49786.21462082863, "episode/length": 157.0, "episode/score": 0.1655660691903904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1655660691903904}
{"step": 1001440, "time": 49788.89850473404, "episode/length": 179.0, "episode/score": 0.18408796422590967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18408796422590967}
{"step": 1001856, "time": 49805.73468995094, "episode/length": 161.0, "episode/score": 0.1777924981797696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1777924981797696}
{"step": 1001888, "time": 49808.58760404587, "episode/length": 176.0, "episode/score": 0.19453568063909188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19453568063909188}
{"step": 1001992, "time": 49813.63055753708, "episode/length": 194.0, "episode/score": 0.23252380508347414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23252380508347414}
{"step": 1002008, "time": 49815.73074603081, "episode/length": 214.0, "episode/score": 0.23741979548503878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23741979548503878}
{"step": 1002464, "time": 49834.33633351326, "episode/length": 186.0, "episode/score": 0.19607410964817973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19607410964817973}
{"step": 1002864, "time": 49850.75782728195, "episode/length": 177.0, "episode/score": 0.19056117840955267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19056117840955267}
{"step": 1003000, "time": 49857.04213762283, "episode/length": 211.0, "episode/score": 0.2362371899507707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2362371899507707}
{"step": 1003056, "time": 49860.69059538841, "episode/length": 149.0, "episode/score": 0.17965967003328842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17965967003328842}
{"step": 1003160, "time": 49865.86399126053, "episode/length": 217.0, "episode/score": 0.2574470699146332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2574470699146332}
{"step": 1003344, "time": 49874.53642296791, "episode/length": 181.0, "episode/score": 0.20370058353000786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20370058353000786}
{"step": 1003440, "time": 49880.08174800873, "episode/length": 178.0, "episode/score": 0.18203941095453047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18203941095453047}
{"step": 1003536, "time": 49885.20855808258, "episode/length": 192.0, "episode/score": 0.20052469742040557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20052469742040557}
{"step": 1004048, "time": 49905.66457557678, "episode/length": 197.0, "episode/score": 0.23474908616117318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23474908616117318}
{"step": 1004216, "time": 49913.16134405136, "episode/length": 168.0, "episode/score": 0.18375104973347334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18375104973347334}
{"step": 1004560, "time": 49927.71593308449, "episode/length": 151.0, "episode/score": 0.15642625123837206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.15642625123837206}
{"step": 1004600, "time": 49930.46371150017, "episode/length": 199.0, "episode/score": 0.2165048869119346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2165048869119346}
{"step": 1004688, "time": 49935.51989340782, "episode/length": 190.0, "episode/score": 0.20786495054016996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20786495054016996}
{"step": 1004760, "time": 49939.55183362961, "episode/length": 152.0, "episode/score": 0.16693257486804214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16693257486804214}
{"step": 1005296, "time": 49961.00914478302, "episode/length": 279.0, "episode/score": 0.31554501893879205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.31554501893879205}
{"step": 1005320, "time": 49963.29666399956, "episode/length": 158.0, "episode/score": 0.1662727299335529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1662727299335529}
{"step": 1005872, "time": 49985.34003043175, "episode/length": 147.0, "episode/score": 0.16836986499583873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16836986499583873}
{"step": 1005904, "time": 49988.11676073074, "episode/length": 307.0, "episode/score": 0.35556192572221335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.35556192572221335}
{"step": 1005920, "time": 49990.14872956276, "episode/length": 164.0, "episode/score": 0.18569792844391486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18569792844391486}
{"step": 1005968, "time": 49993.31613254547, "episode/length": 175.0, "episode/score": 0.19590130825599772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19590130825599772}
{"step": 1006144, "time": 50001.17604017258, "episode/length": 240.0, "episode/score": 0.2651486810409551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2651486810409551}
{"step": 1006256, "time": 50006.81479763985, "episode/length": 186.0, "episode/score": 0.19989459017961053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19989459017961053}
{"step": 1006800, "time": 50028.47917032242, "episode/length": 187.0, "episode/score": 0.2147603165030887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2147603165030887}
{"step": 1007072, "time": 50040.015409231186, "episode/length": 137.0, "episode/score": 0.13879159742373304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13879159742373304}
{"step": 1007624, "time": 50062.378383398056, "episode/length": 218.0, "episode/score": 0.23988977305452863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23988977305452863}
{"step": 1007624, "time": 50062.44097208977, "episode/length": 287.0, "episode/score": 0.3192077519433951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3192077519433951}
{"step": 1007664, "time": 50068.39070034027, "episode/length": 189.0, "episode/score": 0.21652577213262703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21652577213262703}
{"step": 1007856, "time": 50077.080770492554, "episode/length": 199.0, "episode/score": 0.2337083292659372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2337083292659372}
{"step": 1007856, "time": 50077.08898758888, "episode/length": 243.0, "episode/score": 0.26509050039931026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.26509050039931026}
{"step": 1008408, "time": 50100.36061954498, "episode/length": 166.0, "episode/score": 0.185179345367942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.185179345367942}
{"step": 1008704, "time": 50113.17282509804, "episode/length": 134.0, "episode/score": 0.160916663473472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.160916663473472}
{"step": 1008952, "time": 50123.6473171711, "episode/length": 165.0, "episode/score": 0.19554611552302958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19554611552302958}
{"step": 1009104, "time": 50131.15362429619, "episode/length": 155.0, "episode/score": 0.1642369855690049, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1642369855690049}
{"step": 1009328, "time": 50141.04458999634, "episode/length": 425.0, "episode/score": 0.4505900564681724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4505900564681724}
{"step": 1009360, "time": 50143.7065114975, "episode/length": 187.0, "episode/score": 0.18837799551329226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18837799551329226}
{"step": 1009944, "time": 50166.65689301491, "episode/length": 191.0, "episode/score": 0.21294913844030816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21294913844030816}
{"step": 1010000, "time": 50170.42832040787, "episode/length": 161.0, "episode/score": 0.16917293090955354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16917293090955354}
{"step": 1010048, "time": 50191.42460513115, "eval_episode/length": 136.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9708029197080292}
{"step": 1010048, "time": 50193.217910289764, "eval_episode/length": 143.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 1010048, "time": 50196.15459561348, "eval_episode/length": 178.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.994413407821229}
{"step": 1010048, "time": 50198.73196840286, "eval_episode/length": 201.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.995049504950495}
{"step": 1010048, "time": 50198.73985791206, "eval_episode/length": 201.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.995049504950495}
{"step": 1010048, "time": 50202.9188811779, "eval_episode/length": 223.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 1010048, "time": 50206.445464134216, "eval_episode/length": 137.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 1010048, "time": 50209.59785652161, "eval_episode/length": 171.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 1010256, "time": 50217.351261138916, "episode/length": 431.0, "episode/score": 0.44049270564573817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.44049270564573817}
{"step": 1010432, "time": 50225.4089550972, "episode/length": 184.0, "episode/score": 0.22091397418262204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22091397418262204}
{"step": 1010840, "time": 50241.90974235535, "episode/length": 184.0, "episode/score": 0.19971961501869373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19971961501869373}
{"step": 1011032, "time": 50250.52852654457, "episode/length": 420.0, "episode/score": 0.4176599695620098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.4176599695620098}
{"step": 1011056, "time": 50253.2618997097, "episode/length": 243.0, "episode/score": 0.27178926988199237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.27178926988199237}
{"step": 1011584, "time": 50274.115961551666, "episode/length": 197.0, "episode/score": 0.19353425275403424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19353425275403424}
{"step": 1011760, "time": 50282.10384583473, "episode/length": 226.0, "episode/score": 0.2604613049479667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2604613049479667}
{"step": 1011832, "time": 50285.98025846481, "episode/length": 174.0, "episode/score": 0.18248895353099215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18248895353099215}
{"step": 1012160, "time": 50299.78507733345, "episode/length": 164.0, "episode/score": 0.17279044554015854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17279044554015854}
{"step": 1012312, "time": 50306.563470602036, "episode/length": 159.0, "episode/score": 0.19445832935161889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19445832935161889}
{"step": 1012536, "time": 50316.24902153015, "episode/length": 184.0, "episode/score": 0.192823866254912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.192823866254912}
{"step": 1012776, "time": 50326.78671002388, "episode/length": 430.0, "episode/score": 0.43009084049663215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.43009084049663215}
{"step": 1012776, "time": 50326.7956366539, "episode/length": 314.0, "episode/score": 0.33960532566743495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.33960532566743495}
{"step": 1012936, "time": 50335.8047516346, "episode/length": 168.0, "episode/score": 0.19289350685903628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19289350685903628}
{"step": 1013360, "time": 50353.404868364334, "episode/length": 190.0, "episode/score": 0.2210171192909911, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2210171192909911}
{"step": 1013408, "time": 50356.71831583977, "episode/length": 205.0, "episode/score": 0.24866347697570745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24866347697570745}
{"step": 1013521, "time": 50362.902505874634, "train_stats/sum_log_reward": 2.033962241672682, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 4.0754716981132075, "train_stats/max_log_achievement_collect_sapling": 0.5849056603773585, "train_stats/max_log_achievement_collect_stone": 0.0660377358490566, "train_stats/max_log_achievement_collect_wood": 1.990566037735849, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.03773584905660377, "train_stats/max_log_achievement_eat_cow": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.08490566037735849, "train_stats/max_log_achievement_make_wood_sword": 0.07547169811320754, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 0.4056603773584906, "train_stats/max_log_achievement_place_stone": 0.05660377358490566, "train_stats/max_log_achievement_place_table": 0.3584905660377358, "train_stats/max_log_achievement_wake_up": 0.2641509433962264, "train_stats/mean_log_entropy": 2.1585524734461083, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.001584053039551, "train/action_min": 0.0, "train/action_std": 4.747961886227131, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00789183541201055, "train/actor_opt_grad_steps": 62605.0, "train/actor_opt_loss": -6.2019156437017955, "train/adv_mag": 0.1809584904112853, "train/adv_max": 0.13262710924027488, "train/adv_mean": 0.00019746290612787654, "train/adv_min": -0.17954154283506796, "train/adv_std": 0.01315346933552064, "train/cont_avg": 0.9947586059570312, "train/cont_loss_mean": 5.92153528038708e-05, "train/cont_loss_std": 0.001760141725185571, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.0015504548438811765, "train/cont_pos_acc": 0.999976959079504, "train/cont_pos_loss": 5.280225001923211e-05, "train/cont_pred": 0.9947264646179974, "train/cont_rate": 0.9947586059570312, "train/dyn_loss_mean": 10.39366552978754, "train/dyn_loss_std": 8.708494428545237, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12628544829203747, "train/extr_critic_critic_opt_grad_steps": 62605.0, "train/extr_critic_critic_opt_loss": 12221.839065551758, "train/extr_critic_mag": 0.28295980021357536, "train/extr_critic_max": 0.28295980021357536, "train/extr_critic_mean": 0.23297242575790733, "train/extr_critic_min": 0.0014815079048275948, "train/extr_critic_std": 0.06183135746687185, "train/extr_return_normed_mag": 0.2160916964057833, "train/extr_return_normed_max": 0.2160916964057833, "train/extr_return_normed_mean": 0.16648893628735095, "train/extr_return_normed_min": -0.0656076006416697, "train/extr_return_normed_std": 0.06324048251553904, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2827727359253913, "train/extr_return_raw_max": 0.2827727359253913, "train/extr_return_raw_mean": 0.23316997883375734, "train/extr_return_raw_min": 0.0010734396055340767, "train/extr_return_raw_std": 0.06324048261740245, "train/extr_reward_mag": 0.001354108564555645, "train/extr_reward_max": 0.001354108564555645, "train/extr_reward_mean": 0.0010989832426275825, "train/extr_reward_min": 1.1157244443893433e-05, "train/extr_reward_std": 0.00024141818562384287, "train/image_loss_mean": 4.38310625962913, "train/image_loss_std": 9.426298167556524, "train/model_loss_mean": 10.65986305475235, "train/model_loss_std": 13.115413092076778, "train/model_opt_grad_norm": 45.9488959312439, "train/model_opt_grad_steps": 62546.96875, "train/model_opt_loss": 16532.57382965088, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1542.96875, "train/policy_entropy_mag": 2.7643879633396864, "train/policy_entropy_max": 2.7643879633396864, "train/policy_entropy_mean": 2.124854037538171, "train/policy_entropy_min": 0.07950849150074646, "train/policy_entropy_std": 0.6057447218336165, "train/policy_logprob_mag": 7.438173782080412, "train/policy_logprob_max": -0.00947446883219527, "train/policy_logprob_mean": -2.125423622317612, "train/policy_logprob_min": -7.438173782080412, "train/policy_logprob_std": 1.128561147954315, "train/policy_randomness_mag": 0.9757076390087605, "train/policy_randomness_max": 0.9757076390087605, "train/policy_randomness_mean": 0.7499802261590958, "train/policy_randomness_min": 0.02806300835800357, "train/policy_randomness_std": 0.2138013051589951, "train/post_ent_mag": 60.1557699739933, "train/post_ent_max": 60.1557699739933, "train/post_ent_mean": 43.06122061610222, "train/post_ent_min": 19.698807641863823, "train/post_ent_std": 7.347774360328913, "train/prior_ent_mag": 69.88460725545883, "train/prior_ent_max": 69.88460725545883, "train/prior_ent_mean": 53.574828922748566, "train/prior_ent_min": 35.373250618577, "train/prior_ent_std": 5.255949415266514, "train/rep_loss_mean": 10.39366552978754, "train/rep_loss_std": 8.708494428545237, "train/reward_avg": 0.0010745909285105881, "train/reward_loss_mean": 0.04049826454138383, "train/reward_loss_std": 0.010935172096651513, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0012913215905427933, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.04049826442496851, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0010742884369392414, "train/reward_rate": 0.0, "eval_stats/sum_log_reward": 1.6624999856576324, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 2.1875, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 1.1985105174971977e-07, "report/cont_loss_std": 1.2074699498043628e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.948020892290515e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.1708646496799702e-07, "report/cont_pred": 0.9990233778953552, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 13.280905723571777, "report/dyn_loss_std": 9.207258224487305, "report/image_loss_mean": 4.794759750366211, "report/image_loss_std": 10.172087669372559, "report/model_loss_mean": 12.803699493408203, "report/model_loss_std": 13.790471076965332, "report/post_ent_mag": 61.3829231262207, "report/post_ent_max": 61.3829231262207, "report/post_ent_mean": 41.12312316894531, "report/post_ent_min": 18.9368839263916, "report/post_ent_std": 7.899319648742676, "report/prior_ent_mag": 69.88430786132812, "report/prior_ent_max": 69.88430786132812, "report/prior_ent_mean": 54.37532043457031, "report/prior_ent_min": 39.86503982543945, "report/prior_ent_std": 4.308055400848389, "report/rep_loss_mean": 13.280905723571777, "report/rep_loss_std": 9.207258224487305, "report/reward_avg": 0.0010743701132014394, "report/reward_loss_mean": 0.040397126227617264, "report/reward_loss_std": 0.01202684547752142, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0012704133987426758, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.040397126227617264, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0010623857378959656, "report/reward_rate": 0.0, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.0001074885149137117, "eval/cont_loss_std": 0.0033043851144611835, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.015113646164536476, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.201282536087092e-06, "eval/cont_pred": 0.993257999420166, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 16.705364227294922, "eval/dyn_loss_std": 10.79508113861084, "eval/image_loss_mean": 8.577737808227539, "eval/image_loss_std": 12.59387493133545, "eval/model_loss_mean": 19.529205322265625, "eval/model_loss_std": 17.891164779663086, "eval/post_ent_mag": 56.818275451660156, "eval/post_ent_max": 56.818275451660156, "eval/post_ent_mean": 40.280025482177734, "eval/post_ent_min": 20.15281105041504, "eval/post_ent_std": 7.333876132965088, "eval/prior_ent_mag": 69.88430786132812, "eval/prior_ent_max": 69.88430786132812, "eval/prior_ent_mean": 53.94768524169922, "eval/prior_ent_min": 42.361793518066406, "eval/prior_ent_std": 4.8651041984558105, "eval/rep_loss_mean": 16.705364227294922, "eval/rep_loss_std": 10.79508113861084, "eval/reward_avg": 0.00839843787252903, "eval/reward_loss_mean": 0.928141176700592, "eval/reward_loss_std": 4.242318153381348, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0012902021408081055, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.6507694125175476, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 20.938533782958984, "eval/reward_pred": 0.0011016394710168242, "eval/reward_rate": 0.013671875, "replay/size": 1000000.0, "replay/inserts": 20504.0, "replay/samples": 20496.0, "replay/insert_wait_avg": 1.2728603287130141e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.571790666900325e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4968.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.110412456371166e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0307779312134, "timer/env.step_count": 2563.0, "timer/env.step_total": 229.97341918945312, "timer/env.step_frac": 0.22996634130121915, "timer/env.step_avg": 0.08972821661703204, "timer/env.step_min": 0.02249765396118164, "timer/env.step_max": 4.2641074657440186, "timer/replay._sample_count": 20496.0, "timer/replay._sample_total": 9.944476842880249, "timer/replay._sample_frac": 0.00994417078187595, "timer/replay._sample_avg": 0.0004851911027947038, "timer/replay._sample_min": 0.0003879070281982422, "timer/replay._sample_max": 0.01046609878540039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3184.0, "timer/agent.policy_total": 50.94286870956421, "timer/agent.policy_frac": 0.05094130084171098, "timer/agent.policy_avg": 0.01599964469521489, "timer/agent.policy_min": 0.009447574615478516, "timer/agent.policy_max": 0.1302342414855957, "timer/dataset_train_count": 1281.0, "timer/dataset_train_total": 0.1349782943725586, "timer/dataset_train_frac": 0.00013497414014775755, "timer/dataset_train_avg": 0.00010536947257810976, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.0006113052368164062, "timer/agent.train_count": 1281.0, "timer/agent.train_total": 571.1280677318573, "timer/agent.train_frac": 0.5711104901324767, "timer/agent.train_avg": 0.4458454861294749, "timer/agent.train_min": 0.4342825412750244, "timer/agent.train_max": 1.0733189582824707, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4787428379058838, "timer/agent.report_frac": 0.0004787281036452399, "timer/agent.report_avg": 0.2393714189529419, "timer/agent.report_min": 0.23236894607543945, "timer/agent.report_max": 0.24637389183044434, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.535385131835938e-05, "timer/dataset_eval_frac": 8.53512243842463e-08, "timer/dataset_eval_avg": 8.535385131835938e-05, "timer/dataset_eval_min": 8.535385131835938e-05, "timer/dataset_eval_max": 8.535385131835938e-05, "fps": 20.503126368108212}
{"step": 1013536, "time": 50363.633385658264, "episode/length": 171.0, "episode/score": 0.1838902829822473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1838902829822473}
{"step": 1013600, "time": 50367.747623205185, "episode/length": 160.0, "episode/score": 0.1741424395422655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1741424395422655}
{"step": 1014184, "time": 50390.487068891525, "episode/length": 175.0, "episode/score": 0.20677889881244482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20677889881244482}
{"step": 1014184, "time": 50390.494421482086, "episode/length": 175.0, "episode/score": 0.18555990795448452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18555990795448452}
{"step": 1014280, "time": 50397.175998449326, "episode/length": 217.0, "episode/score": 0.23335650172430178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23335650172430178}
{"step": 1014368, "time": 50402.13797903061, "episode/length": 178.0, "episode/score": 0.2089713395371291, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2089713395371291}
{"step": 1014496, "time": 50408.63697719574, "episode/length": 38.0, "episode/score": 0.04666666581761092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04666666581761092}
{"step": 1014808, "time": 50421.36745238304, "episode/length": 180.0, "episode/score": 0.19990134526051406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19990134526051406}
{"step": 1014840, "time": 50424.05497455597, "episode/length": 154.0, "episode/score": 0.1742748447577469, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1742748447577469}
{"step": 1015016, "time": 50432.03463745117, "episode/length": 184.0, "episode/score": 0.19389659243097412, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19389659243097412}
{"step": 1015544, "time": 50453.030304670334, "episode/length": 266.0, "episode/score": 0.3263194374740124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.3263194374740124}
{"step": 1015624, "time": 50457.35846781731, "episode/length": 167.0, "episode/score": 0.19112136031981208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19112136031981208}
{"step": 1015832, "time": 50468.130422353745, "episode/length": 182.0, "episode/score": 0.2017268848085223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2017268848085223}
{"step": 1015904, "time": 50472.511316776276, "episode/length": 175.0, "episode/score": 0.2024231966743173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2024231966743173}
{"step": 1016168, "time": 50483.49836206436, "episode/length": 169.0, "episode/score": 0.17880436269024358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17880436269024358}
{"step": 1016256, "time": 50488.55810236931, "episode/length": 258.0, "episode/score": 0.2891561630367505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2891561630367505}
{"step": 1016424, "time": 50495.9333794117, "episode/length": 175.0, "episode/score": 0.19701943010659306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19701943010659306}
{"step": 1016544, "time": 50502.03497004509, "episode/length": 212.0, "episode/score": 0.23738040162606922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.23738040162606922}
{"step": 1016808, "time": 50512.93276619911, "episode/length": 157.0, "episode/score": 0.18398213959881105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18398213959881105}
{"step": 1016992, "time": 50521.30834650993, "episode/length": 135.0, "episode/score": 0.13840702785091707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13840702785091707}
{"step": 1017112, "time": 50527.2454969883, "episode/length": 185.0, "episode/score": 0.1821973817768594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1821973817768594}
{"step": 1017400, "time": 50539.15602970123, "episode/length": 142.0, "episode/score": 0.1686904731031973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1686904731031973}
{"step": 1017584, "time": 50547.75902843475, "episode/length": 176.0, "episode/score": 0.19336960392502078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19336960392502078}
{"step": 1017624, "time": 50550.59863066673, "episode/length": 223.0, "episode/score": 0.24666033518678887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.24666033518678887}
{"step": 1017824, "time": 50559.86545777321, "episode/length": 159.0, "episode/score": 0.18568638710712548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.18568638710712548}
{"step": 1017896, "time": 50563.86995124817, "episode/length": 183.0, "episode/score": 0.20755131433816132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.20755131433816132}
{"step": 1018120, "time": 50573.50289130211, "episode/length": 163.0, "episode/score": 0.16569819334563363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16569819334563363}
{"step": 1018264, "time": 50580.32464647293, "episode/length": 158.0, "episode/score": 0.16468935503507964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16468935503507964}
{"step": 1018312, "time": 50583.61157488823, "episode/length": 149.0, "episode/score": 0.16553247863066645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.16553247863066645}
{"step": 1018728, "time": 50600.39974594116, "episode/length": 165.0, "episode/score": 0.1873996178046582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1873996178046582}
{"step": 1019000, "time": 50611.857637643814, "episode/length": 176.0, "episode/score": 0.19508735729232285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19508735729232285}
{"step": 1019376, "time": 50627.48671030998, "episode/length": 138.0, "episode/score": 0.17029166308930144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.17029166308930144}
{"step": 1019400, "time": 50629.66865515709, "episode/length": 196.0, "episode/score": 0.22862440968219744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.22862440968219744}
{"step": 1019416, "time": 50631.78212738037, "episode/length": 161.0, "episode/score": 0.1804038671843955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1804038671843955}
{"step": 1019440, "time": 50634.4970934391, "episode/length": 226.0, "episode/score": 0.2623302260435594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.2623302260435594}
{"step": 1019472, "time": 50637.24040699005, "episode/length": 196.0, "episode/score": 0.21392045840912033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.21392045840912033}
{"step": 1019712, "time": 50647.59200000763, "episode/length": 174.0, "episode/score": 0.19582681409337965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.19582681409337965}
