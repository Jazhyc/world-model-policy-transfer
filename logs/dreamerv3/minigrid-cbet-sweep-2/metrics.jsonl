{"step": 1560, "time": 110.19855570793152, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 110.23225665092468, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 110.37887668609619, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 110.38866877555847, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 110.40024971961975, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 110.41044163703918, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 110.42493438720703, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 110.43759655952454, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 235.99556636810303, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.822998046875, "train/action_min": 0.0, "train/action_std": 2.1133739948272705, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0004033049917779863, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.1397099494934082, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.7497403621673584, "train/cont_loss_std": 0.27163586020469666, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.4638671875, "train/cont_pos_loss": 0.7497403621673584, "train/cont_pred": 0.48923513293266296, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.577972412109375, "train/dyn_loss_std": 0.37124544382095337, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 5.921273231506348, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 24316.328125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 4692.8173828125, "train/image_loss_std": 37.75703430175781, "train/model_loss_mean": 4705.45556640625, "train/model_loss_std": 37.7386589050293, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 47054556.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.941624402999878, "train/policy_entropy_max": 1.941624402999878, "train/policy_entropy_mean": 1.7410811185836792, "train/policy_entropy_min": 0.9961992502212524, "train/policy_entropy_std": 0.11228011548519135, "train/policy_logprob_mag": 4.452409744262695, "train/policy_logprob_max": -0.3048003911972046, "train/policy_logprob_mean": -1.7398244142532349, "train/policy_logprob_min": -4.452409744262695, "train/policy_logprob_std": 0.6136934757232666, "train/policy_randomness_mag": 0.9977976083755493, "train/policy_randomness_max": 0.9977976083755493, "train/policy_randomness_mean": 0.8947386741638184, "train/policy_randomness_min": 0.5119451880455017, "train/policy_randomness_std": 0.05770057067275047, "train/post_ent_mag": 105.79574584960938, "train/post_ent_max": 105.79574584960938, "train/post_ent_mean": 105.53489685058594, "train/post_ent_min": 105.23838806152344, "train/post_ent_std": 0.09764961153268814, "train/prior_ent_mag": 106.72933959960938, "train/prior_ent_max": 106.72933959960938, "train/prior_ent_mean": 105.60894775390625, "train/prior_ent_min": 104.66175842285156, "train/prior_ent_std": 0.31851720809936523, "train/rep_loss_mean": 10.577972412109375, "train/rep_loss_std": 0.37124544382095337, "train/reward_avg": 0.00031761935679242015, "train/reward_loss_mean": 5.541263580322266, "train/reward_loss_std": 2.5506679435238766e-07, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263580322266, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.7907793521881104, "report/cont_loss_std": 0.286454439163208, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.408203125, "report/cont_pos_loss": 0.7907793521881104, "report/cont_pred": 0.4712430238723755, "report/cont_rate": 1.0, "report/dyn_loss_mean": 10.532546997070312, "report/dyn_loss_std": 0.382307767868042, "report/image_loss_mean": 4693.06591796875, "report/image_loss_std": 39.87846374511719, "report/model_loss_mean": 4705.7177734375, "report/model_loss_std": 39.861053466796875, "report/post_ent_mag": 105.82089233398438, "report/post_ent_max": 105.82089233398438, "report/post_ent_mean": 105.56126403808594, "report/post_ent_min": 105.17806243896484, "report/post_ent_std": 0.09430450201034546, "report/prior_ent_mag": 106.69634246826172, "report/prior_ent_max": 106.69634246826172, "report/prior_ent_mean": 105.63992309570312, "report/prior_ent_min": 104.66748046875, "report/prior_ent_std": 0.2898692190647125, "report/rep_loss_mean": 10.532546997070312, "report/rep_loss_std": 0.382307767868042, "report/reward_avg": 0.00031761935679242015, "report/reward_loss_mean": 5.541263580322266, "report/reward_loss_std": 2.5506679435238766e-07, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263580322266, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.7777142524719238, "eval/cont_loss_std": 0.2713219225406647, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.41015625, "eval/cont_pos_loss": 0.7777142524719238, "eval/cont_pred": 0.47572970390319824, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 10.620635986328125, "eval/dyn_loss_std": 0.41300082206726074, "eval/image_loss_mean": 4696.7236328125, "eval/image_loss_std": 37.5607795715332, "eval/model_loss_mean": 4709.4150390625, "eval/model_loss_std": 37.56890869140625, "eval/post_ent_mag": 105.85568237304688, "eval/post_ent_max": 105.85568237304688, "eval/post_ent_mean": 105.552734375, "eval/post_ent_min": 105.24344635009766, "eval/post_ent_std": 0.09881675988435745, "eval/prior_ent_mag": 106.46621704101562, "eval/prior_ent_max": 106.46621704101562, "eval/prior_ent_mean": 105.56928253173828, "eval/prior_ent_min": 104.7506103515625, "eval/prior_ent_std": 0.3079077899456024, "eval/rep_loss_mean": 10.620635986328125, "eval/rep_loss_std": 0.41300082206726074, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.0910413123124482e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.451087134225028e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.5078842498344366e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.812972477504186e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 155.1142692565918, "timer/env.step_count": 196.0, "timer/env.step_total": 1.4518191814422607, "timer/env.step_frac": 0.009359675214925874, "timer/env.step_avg": 0.007407240721644188, "timer/env.step_min": 0.0064661502838134766, "timer/env.step_max": 0.021087646484375, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.08539795875549316, "timer/replay._sample_frac": 0.0005505486965498118, "timer/replay._sample_avg": 0.0007624817746026176, "timer/replay._sample_min": 0.0003490447998046875, "timer/replay._sample_max": 0.0012001991271972656, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.111659526824951, "timer/agent.save_frac": 0.01361357363797279, "timer/agent.save_avg": 2.111659526824951, "timer/agent.save_min": 2.111659526824951, "timer/agent.save_max": 2.111659526824951, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 24.169708251953125, "timer/agent.policy_frac": 0.15581872878485034, "timer/agent.policy_avg": 0.08334382155845906, "timer/agent.policy_min": 0.010308265686035156, "timer/agent.policy_max": 17.59629511833191, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 4.57763671875e-05, "timer/dataset_train_frac": 2.9511383708855443e-07, "timer/dataset_train_avg": 4.57763671875e-05, "timer/dataset_train_min": 4.57763671875e-05, "timer/dataset_train_max": 4.57763671875e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 91.07736897468567, "timer/agent.train_frac": 0.5871630599247091, "timer/agent.train_avg": 91.07736897468567, "timer/agent.train_min": 91.07736897468567, "timer/agent.train_max": 91.07736897468567, "timer/agent.report_count": 2.0, "timer/agent.report_total": 31.10870337486267, "timer/agent.report_frac": 0.2005534598715886, "timer/agent.report_avg": 15.554351687431335, "timer/agent.report_min": 7.736789703369141, "timer/agent.report_max": 23.37191367149353, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.100799560546875e-05, "timer/dataset_eval_frac": 2.6437281239183004e-07, "timer/dataset_eval_avg": 4.100799560546875e-05, "timer/dataset_eval_min": 4.100799560546875e-05, "timer/dataset_eval_max": 4.100799560546875e-05}
{"step": 2312, "time": 259.5124387741089, "episode/length": 288.0, "episode/score": 0.10079566610318125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10079566610318125}
{"step": 2312, "time": 259.5206456184387, "episode/length": 288.0, "episode/score": 0.07935351937817359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07935351937817359}
{"step": 2312, "time": 259.53467059135437, "episode/length": 288.0, "episode/score": 0.061302597448616325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061302597448616325}
{"step": 2312, "time": 259.55153727531433, "episode/length": 288.0, "episode/score": 0.07243090450072032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07243090450072032}
{"step": 2312, "time": 259.5658071041107, "episode/length": 288.0, "episode/score": 0.08697820188604055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08697820188604055}
{"step": 2312, "time": 259.5891845226288, "episode/length": 288.0, "episode/score": 0.055539670061989455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055539670061989455}
{"step": 2312, "time": 259.60465574264526, "episode/length": 288.0, "episode/score": 0.06475114376564761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06475114376564761}
{"step": 2312, "time": 259.62122893333435, "episode/length": 288.0, "episode/score": 0.07738856177343223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07738856177343223}
{"step": 4624, "time": 333.31543946266174, "episode/length": 288.0, "episode/score": 0.06338908472747562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06338908472747562}
{"step": 4624, "time": 333.3233275413513, "episode/length": 288.0, "episode/score": 0.07065810383829785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07065810383829785}
{"step": 4624, "time": 333.3333728313446, "episode/length": 288.0, "episode/score": 0.05480729653191929, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05480729653191929}
{"step": 4624, "time": 333.342960357666, "episode/length": 288.0, "episode/score": 0.06908130729289041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06908130729289041}
{"step": 4624, "time": 333.3523461818695, "episode/length": 288.0, "episode/score": 0.07501951673935991, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07501951673935991}
{"step": 4624, "time": 333.3617615699768, "episode/length": 288.0, "episode/score": 0.07327029835005305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07327029835005305}
{"step": 4624, "time": 333.3719947338104, "episode/length": 288.0, "episode/score": 0.04000346072950833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04000346072950833}
{"step": 4624, "time": 333.38280296325684, "episode/length": 288.0, "episode/score": 0.07189722765372153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07189722765372153}
{"step": 6936, "time": 406.4374074935913, "episode/length": 288.0, "episode/score": 0.07449109801888198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07449109801888198}
{"step": 6936, "time": 406.44534826278687, "episode/length": 288.0, "episode/score": 0.059083824157539766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059083824157539766}
{"step": 6936, "time": 406.45687556266785, "episode/length": 288.0, "episode/score": 0.04752460954500748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04752460954500748}
{"step": 6936, "time": 406.4683458805084, "episode/length": 288.0, "episode/score": 0.06452968181429242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06452968181429242}
{"step": 6936, "time": 406.47816371917725, "episode/length": 288.0, "episode/score": 0.07029045139853451, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07029045139853451}
{"step": 6936, "time": 406.4879825115204, "episode/length": 288.0, "episode/score": 0.09127067505551167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09127067505551167}
{"step": 6936, "time": 406.50032472610474, "episode/length": 288.0, "episode/score": 0.05522164102711713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05522164102711713}
{"step": 6936, "time": 406.5104777812958, "episode/length": 288.0, "episode/score": 0.06969674928717495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06969674928717495}
{"step": 9248, "time": 480.57269525527954, "episode/length": 288.0, "episode/score": 0.06511831016581482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06511831016581482}
{"step": 9248, "time": 480.5805811882019, "episode/length": 288.0, "episode/score": 0.09217163194446698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09217163194446698}
{"step": 9248, "time": 480.590368270874, "episode/length": 288.0, "episode/score": 0.07207232005620767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07207232005620767}
{"step": 9248, "time": 480.6011357307434, "episode/length": 288.0, "episode/score": 0.07109633772071788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07109633772071788}
{"step": 9248, "time": 480.6118059158325, "episode/length": 288.0, "episode/score": 0.05600625216334265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05600625216334265}
{"step": 9248, "time": 480.6210470199585, "episode/length": 288.0, "episode/score": 0.06252438481152467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06252438481152467}
{"step": 9248, "time": 480.62989711761475, "episode/length": 288.0, "episode/score": 0.07233915255565648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07233915255565648}
{"step": 9248, "time": 480.63926815986633, "episode/length": 288.0, "episode/score": 0.06804959753600315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06804959753600315}
{"step": 10088, "time": 510.4384820461273, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 10088, "time": 511.67449045181274, "eval_episode/length": 235.0, "eval_episode/score": 0.265625, "eval_episode/reward_rate": 0.00423728813559322}
{"step": 10088, "time": 512.6488378047943, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 512.6594049930573, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 512.6705825328827, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 512.6809415817261, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 512.6884386539459, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 512.6958334445953, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11560, "time": 559.2662930488586, "episode/length": 288.0, "episode/score": 0.05631707095912475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05631707095912475}
{"step": 11560, "time": 559.2834887504578, "episode/length": 288.0, "episode/score": 0.0791042076901931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0791042076901931}
{"step": 11560, "time": 559.2982521057129, "episode/length": 288.0, "episode/score": 0.0668917555286157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0668917555286157}
{"step": 11560, "time": 559.3141210079193, "episode/length": 288.0, "episode/score": 0.061832139624527827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061832139624527827}
{"step": 11560, "time": 559.3290650844574, "episode/length": 288.0, "episode/score": 0.06925057744453511, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06925057744453511}
{"step": 11560, "time": 559.3437347412109, "episode/length": 288.0, "episode/score": 0.06474179745057995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06474179745057995}
{"step": 11560, "time": 559.3600642681122, "episode/length": 288.0, "episode/score": 0.06369247078384888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06369247078384888}
{"step": 11560, "time": 559.3769884109497, "episode/length": 288.0, "episode/score": 0.0723179421712814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0723179421712814}
{"step": 13872, "time": 632.8255152702332, "episode/length": 288.0, "episode/score": 0.06057460755701527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06057460755701527}
{"step": 13872, "time": 632.8336749076843, "episode/length": 288.0, "episode/score": 0.0684424978240088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0684424978240088}
{"step": 13872, "time": 632.8414881229401, "episode/length": 288.0, "episode/score": 0.0638447616134954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0638447616134954}
{"step": 13872, "time": 632.8484206199646, "episode/length": 288.0, "episode/score": 0.05167683155980285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05167683155980285}
{"step": 13872, "time": 632.8571774959564, "episode/length": 288.0, "episode/score": 0.06757711859071946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06757711859071946}
{"step": 13872, "time": 632.8670465946198, "episode/length": 288.0, "episode/score": 0.05093696904003764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05093696904003764}
{"step": 13872, "time": 632.8762300014496, "episode/length": 288.0, "episode/score": 0.06926609883922197, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06926609883922197}
{"step": 13872, "time": 632.8850433826447, "episode/length": 288.0, "episode/score": 0.07790028156676954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07790028156676954}
{"step": 16184, "time": 705.8337213993073, "episode/length": 288.0, "episode/score": 0.05657895025430548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05657895025430548}
{"step": 16184, "time": 705.8414838314056, "episode/length": 288.0, "episode/score": 0.058709082816790215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058709082816790215}
{"step": 16184, "time": 705.8555731773376, "episode/length": 288.0, "episode/score": 0.05995726135867585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05995726135867585}
{"step": 16184, "time": 705.8710207939148, "episode/length": 288.0, "episode/score": 0.0638266269630492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0638266269630492}
{"step": 16184, "time": 705.8854546546936, "episode/length": 288.0, "episode/score": 0.03818763389222113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03818763389222113}
{"step": 16184, "time": 705.8984928131104, "episode/length": 288.0, "episode/score": 0.06010339818638499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06010339818638499}
{"step": 16184, "time": 705.912083864212, "episode/length": 288.0, "episode/score": 0.047146400018249324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047146400018249324}
{"step": 16184, "time": 705.92604637146, "episode/length": 288.0, "episode/score": 0.039260053270453454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039260053270453454}
{"step": 18496, "time": 780.3012599945068, "episode/length": 288.0, "episode/score": 0.03525086303875469, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03525086303875469}
{"step": 18496, "time": 780.3091785907745, "episode/length": 288.0, "episode/score": 0.04498998213466621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04498998213466621}
{"step": 18496, "time": 780.3179144859314, "episode/length": 288.0, "episode/score": 0.035715394579028725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035715394579028725}
{"step": 18496, "time": 780.3258123397827, "episode/length": 288.0, "episode/score": 0.06437145226414032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06437145226414032}
{"step": 18496, "time": 780.3332459926605, "episode/length": 288.0, "episode/score": 0.058981532441293893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058981532441293893}
{"step": 18496, "time": 780.3414912223816, "episode/length": 288.0, "episode/score": 0.06008215581141485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06008215581141485}
{"step": 18496, "time": 780.3491425514221, "episode/length": 288.0, "episode/score": 0.07077387625702158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07077387625702158}
{"step": 18496, "time": 780.3586990833282, "episode/length": 288.0, "episode/score": 0.056309038611402684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056309038611402684}
{"step": 20072, "time": 836.3554604053497, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 836.3632280826569, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 836.3721916675568, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 836.380588054657, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 836.3872547149658, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 836.3946528434753, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 836.4019682407379, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 836.4149041175842, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20808, "time": 859.6226277351379, "episode/length": 288.0, "episode/score": 0.05904306766007039, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05904306766007039}
{"step": 20808, "time": 859.6307253837585, "episode/length": 288.0, "episode/score": 0.06943086637562601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06943086637562601}
{"step": 20808, "time": 859.6383991241455, "episode/length": 288.0, "episode/score": 0.06503535205371236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06503535205371236}
{"step": 20808, "time": 859.6473157405853, "episode/length": 288.0, "episode/score": 0.03527960939965169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03527960939965169}
{"step": 20808, "time": 859.6564514636993, "episode/length": 288.0, "episode/score": 0.06818027842047059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06818027842047059}
{"step": 20808, "time": 859.6672620773315, "episode/length": 288.0, "episode/score": 0.06708711757408992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06708711757408992}
{"step": 20808, "time": 859.6786029338837, "episode/length": 288.0, "episode/score": 0.051653956345433016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051653956345433016}
{"step": 20808, "time": 859.6897501945496, "episode/length": 288.0, "episode/score": 0.06035080171562868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06035080171562868}
{"step": 21976, "time": 896.7601518630981, "episode/length": 145.0, "episode/score": 0.5830171902739494, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.03614216163578021}
{"step": 23120, "time": 933.2984426021576, "episode/length": 288.0, "episode/score": 0.0584583503885483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0584583503885483}
{"step": 23120, "time": 933.3116099834442, "episode/length": 288.0, "episode/score": 0.07897019429088914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07897019429088914}
{"step": 23120, "time": 933.3236055374146, "episode/length": 288.0, "episode/score": 0.05920726871312354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05920726871312354}
{"step": 23120, "time": 933.3351676464081, "episode/length": 288.0, "episode/score": 0.046730383463398084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046730383463398084}
{"step": 23120, "time": 933.3469741344452, "episode/length": 288.0, "episode/score": 0.01592468837287697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01592468837287697}
{"step": 23120, "time": 933.3588886260986, "episode/length": 288.0, "episode/score": 0.061359726914588464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061359726914588464}
{"step": 23120, "time": 933.3708662986755, "episode/length": 288.0, "episode/score": 0.032212715466584996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032212715466584996}
{"step": 24288, "time": 970.6089980602264, "episode/length": 288.0, "episode/score": 0.04269806687381106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04269806687381106}
{"step": 25432, "time": 1007.2489831447601, "episode/length": 288.0, "episode/score": 0.06440825543683104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06440825543683104}
{"step": 25432, "time": 1007.2601180076599, "episode/length": 288.0, "episode/score": 0.03927886524559199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03927886524559199}
{"step": 25432, "time": 1007.2700324058533, "episode/length": 288.0, "episode/score": 0.07310000730518595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07310000730518595}
{"step": 25432, "time": 1007.2788283824921, "episode/length": 288.0, "episode/score": 0.04560313210032518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04560313210032518}
{"step": 25432, "time": 1007.2886831760406, "episode/length": 288.0, "episode/score": 0.047282418725103526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047282418725103526}
{"step": 25432, "time": 1007.2988705635071, "episode/length": 288.0, "episode/score": 0.06545205578095192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06545205578095192}
{"step": 25432, "time": 1007.308450460434, "episode/length": 288.0, "episode/score": 0.0498651428337098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0498651428337098}
{"step": 26600, "time": 1044.4990682601929, "episode/length": 288.0, "episode/score": 0.03942011124399869, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03942011124399869}
{"step": 27744, "time": 1081.027577638626, "episode/length": 288.0, "episode/score": 0.04063811246788873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04063811246788873}
{"step": 27744, "time": 1081.0456082820892, "episode/length": 288.0, "episode/score": 0.04799624034149019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04799624034149019}
{"step": 27744, "time": 1081.0605857372284, "episode/length": 288.0, "episode/score": 0.08229640377055603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08229640377055603}
{"step": 27744, "time": 1081.0736787319183, "episode/length": 288.0, "episode/score": 0.06681166647240389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06681166647240389}
{"step": 27744, "time": 1081.084422826767, "episode/length": 288.0, "episode/score": 0.08893054391421629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08893054391421629}
{"step": 27744, "time": 1081.0938832759857, "episode/length": 288.0, "episode/score": 0.06437701104812277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06437701104812277}
{"step": 27744, "time": 1081.1073923110962, "episode/length": 288.0, "episode/score": 0.06926172187809243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06926172187809243}
{"step": 28912, "time": 1118.3118135929108, "episode/length": 288.0, "episode/score": 0.06564449978202447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06564449978202447}
{"step": 29936, "time": 1150.989649772644, "episode/length": 273.0, "episode/score": 0.21001674459836295, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.06314175172298064}
{"step": 30056, "time": 1154.595829486847, "episode/length": 288.0, "episode/score": 0.07300702622666222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07300702622666222}
{"step": 30056, "time": 1154.608929157257, "episode/length": 288.0, "episode/score": 0.06057005582118791, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06057005582118791}
{"step": 30056, "time": 1154.617060661316, "episode/length": 288.0, "episode/score": 0.07021382067978266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07021382067978266}
{"step": 30056, "time": 1154.626496553421, "episode/length": 288.0, "episode/score": 0.04025226022793049, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04025226022793049}
{"step": 30056, "time": 1154.6366982460022, "episode/length": 288.0, "episode/score": 0.05447248838481755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05447248838481755}
{"step": 30056, "time": 1154.6455166339874, "episode/length": 288.0, "episode/score": 0.055660219549622525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055660219549622525}
{"step": 30056, "time": 1161.3215618133545, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1161.3304884433746, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1161.3390054702759, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1161.3460755348206, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1161.3535463809967, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1161.368868112564, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1161.3808155059814, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1161.3947851657867, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 31224, "time": 1198.384928703308, "episode/length": 288.0, "episode/score": 0.065665124785653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.065665124785653}
{"step": 31417, "time": 1205.4259114265442, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.996840610299059, "train/action_min": 0.0, "train/action_std": 2.0008330947609356, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.000596197934286739, "train/actor_opt_grad_steps": 935.0, "train/actor_opt_loss": 13.737850030263266, "train/adv_mag": 0.0017309286712764833, "train/adv_max": 0.0017309286712764833, "train/adv_mean": 0.0010174489495479299, "train/adv_min": 0.00012560068706037446, "train/adv_std": 0.00047273455044060384, "train/cont_avg": 0.9970020581317204, "train/cont_loss_mean": 0.024676476109636487, "train/cont_loss_std": 0.29823698263246784, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.798667171786975, "train/cont_pos_acc": 0.9971333062776955, "train/cont_pos_loss": 0.007302473545283519, "train/cont_pred": 0.9941193866793827, "train/cont_rate": 0.9970020581317204, "train/dyn_loss_mean": 1.065811694950186, "train/dyn_loss_std": 0.004682445559302978, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.502988129774089, "train/extr_critic_critic_opt_grad_steps": 935.0, "train/extr_critic_critic_opt_loss": 11064.01570375504, "train/extr_critic_mag": 0.016181471527263683, "train/extr_critic_max": 0.016181470245443363, "train/extr_critic_mean": 0.016138043018978455, "train/extr_critic_min": 0.016105917833184682, "train/extr_critic_std": 9.33198372962237e-06, "train/extr_return_normed_mag": 0.00321056936658998, "train/extr_return_normed_max": 0.0032105681151920126, "train/extr_return_normed_mean": 0.002520099797139173, "train/extr_return_normed_min": 0.0016415595168198446, "train/extr_return_normed_std": 0.000472666372733788, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.01784596925391427, "train/extr_return_raw_max": 0.01784596797594326, "train/extr_return_raw_mean": 0.017155500379950974, "train/extr_return_raw_min": 0.016276959382445534, "train/extr_return_raw_std": 0.0004726663691349272, "train/extr_reward_mag": 0.00020954557644423618, "train/extr_reward_max": 0.00020954557644423618, "train/extr_reward_mean": 0.0002092991528448321, "train/extr_reward_min": 0.00020888095260948264, "train/extr_reward_std": 9.143165899901927e-08, "train/image_loss_mean": 26.343529335753892, "train/image_loss_std": 0.3846928550591392, "train/model_loss_mean": 27.129579056655206, "train/model_loss_std": 0.6223778698633435, "train/model_opt_grad_norm": 109.91641170398609, "train/model_opt_grad_steps": 925.0, "train/model_opt_loss": 516.3758752781857, "train/model_opt_model_opt_grad_overflow": 0.005376344086021506, "train/model_opt_model_opt_grad_scale": 14.22841061827957, "train/policy_entropy_mag": 1.9457552535559541, "train/policy_entropy_max": 1.9457552535559541, "train/policy_entropy_mean": 1.9404565941902898, "train/policy_entropy_min": 1.8144639387566557, "train/policy_entropy_std": 0.004104979604142168, "train/policy_logprob_mag": 2.5393748450022873, "train/policy_logprob_max": -1.3402148896968493, "train/policy_logprob_mean": -1.9404248274782652, "train/policy_logprob_min": -2.5393748450022873, "train/policy_logprob_std": 0.0925775813239236, "train/policy_randomness_mag": 0.9999204592038227, "train/policy_randomness_max": 0.9999204592038227, "train/policy_randomness_mean": 0.9971974860596401, "train/policy_randomness_min": 0.9324500655294746, "train/policy_randomness_std": 0.0021095423735753302, "train/post_ent_mag": 82.74254829652848, "train/post_ent_max": 82.74254829652848, "train/post_ent_mean": 82.54107834190451, "train/post_ent_min": 82.49058458881993, "train/post_ent_std": 0.0370087074641619, "train/prior_ent_mag": 87.73843170494162, "train/prior_ent_max": 87.73843170494162, "train/prior_ent_mean": 87.60139744256132, "train/prior_ent_min": 87.38035001036941, "train/prior_ent_std": 0.054426251449972714, "train/rep_loss_mean": 1.065811694950186, "train/rep_loss_std": 0.004682445559302978, "train/reward_avg": 0.0002381682329590843, "train/reward_loss_mean": 0.12188524550568032, "train/reward_loss_std": 0.026294386524526203, "train/reward_max_data": 0.015950941602118632, "train/reward_max_pred": 0.00020941739441246115, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.12156836274931188, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 12.082561874389649, "train/reward_pred": 0.00020906777103601765, "train/reward_rate": 2.6251680107526882e-05, "train_stats/mean_log_entropy": 1.9278389204116095, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020271409302949905, "report/cont_loss_std": 0.3394842743873596, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.283119201660156, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0018693117890506983, "report/cont_pred": 0.9981325268745422, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.284120112657547, "report/image_loss_std": 0.08224879950284958, "report/model_loss_mean": 0.9151760339736938, "report/model_loss_std": 0.34928545355796814, "report/post_ent_mag": 66.81355285644531, "report/post_ent_max": 66.81355285644531, "report/post_ent_mean": 66.39496612548828, "report/post_ent_min": 66.35453796386719, "report/post_ent_std": 0.06845799833536148, "report/prior_ent_mag": 75.27195739746094, "report/prior_ent_max": 75.27195739746094, "report/prior_ent_mean": 75.10929870605469, "report/prior_ent_min": 75.04354095458984, "report/prior_ent_std": 0.04180605337023735, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002146722690667957, "report/reward_loss_mean": 0.01078448910266161, "report/reward_loss_std": 0.016378453001379967, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002262592315673828, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010784488171339035, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00022546527907252312, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0018693190068006516, "eval/cont_loss_std": 2.2830639068160963e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0018693190068006516, "eval/cont_pred": 0.9981324672698975, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2716955244541168, "eval/image_loss_std": 0.08145783096551895, "eval/model_loss_mean": 0.875393807888031, "eval/model_loss_std": 0.08145777136087418, "eval/post_ent_mag": 66.8134765625, "eval/post_ent_max": 66.8134765625, "eval/post_ent_mean": 66.39227294921875, "eval/post_ent_min": 66.3547134399414, "eval/post_ent_std": 0.06351318210363388, "eval/prior_ent_mag": 75.28343200683594, "eval/prior_ent_max": 75.28343200683594, "eval/prior_ent_mean": 75.10914611816406, "eval/prior_ent_min": 75.049072265625, "eval/prior_ent_std": 0.0400257334113121, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001828900072723627, "eval/reward_loss_std": 3.150940301566152e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002262592315673828, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001828900072723627, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00022546341642737389, "eval/reward_rate": 0.0, "replay/size": 30913.0, "replay/inserts": 29856.0, "replay/samples": 29856.0, "replay/insert_wait_avg": 1.3325758685636368e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.638080642920983e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.251835036580263e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4007091522216797e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 969.4215621948242, "timer/env.step_count": 3732.0, "timer/env.step_total": 37.43532371520996, "timer/env.step_frac": 0.03861614510662865, "timer/env.step_avg": 0.010030901317044469, "timer/env.step_min": 0.008454322814941406, "timer/env.step_max": 0.03587770462036133, "timer/replay._sample_count": 29856.0, "timer/replay._sample_total": 15.09274172782898, "timer/replay._sample_frac": 0.015568811667091636, "timer/replay._sample_avg": 0.0005055178767359653, "timer/replay._sample_min": 0.0003285408020019531, "timer/replay._sample_max": 0.010221242904663086, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4599.0, "timer/agent.policy_total": 48.162593126297, "timer/agent.policy_frac": 0.049681784483165625, "timer/agent.policy_avg": 0.010472405550401609, "timer/agent.policy_min": 0.008905649185180664, "timer/agent.policy_max": 0.40802788734436035, "timer/dataset_train_count": 1866.0, "timer/dataset_train_total": 0.20422840118408203, "timer/dataset_train_frac": 0.00021067037205330734, "timer/dataset_train_avg": 0.00010944716033444911, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.00037288665771484375, "timer/agent.train_count": 1866.0, "timer/agent.train_total": 834.2225377559662, "timer/agent.train_frac": 0.8605363964333949, "timer/agent.train_avg": 0.4470645968681491, "timer/agent.train_min": 0.43665003776550293, "timer/agent.train_max": 0.669914722442627, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4840078353881836, "timer/agent.report_frac": 0.0004992748812935035, "timer/agent.report_avg": 0.2420039176940918, "timer/agent.report_min": 0.23656249046325684, "timer/agent.report_max": 0.24744534492492676, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.246394929586009e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 30.79728372683613}
{"step": 32248, "time": 1231.5567500591278, "episode/length": 288.0, "episode/score": 0.0722805110934246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0722805110934246}
{"step": 32368, "time": 1235.5773150920868, "episode/length": 288.0, "episode/score": 0.06576555117499083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06576555117499083}
{"step": 32368, "time": 1235.5863354206085, "episode/length": 288.0, "episode/score": 0.0828092527407307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0828092527407307}
{"step": 32368, "time": 1235.5940811634064, "episode/length": 288.0, "episode/score": 0.05210757796885446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05210757796885446}
{"step": 32368, "time": 1235.6037256717682, "episode/length": 288.0, "episode/score": 0.08274931816896469, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08274931816896469}
{"step": 32368, "time": 1235.6135938167572, "episode/length": 288.0, "episode/score": 0.06709340062371894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06709340062371894}
{"step": 32368, "time": 1235.6230101585388, "episode/length": 288.0, "episode/score": 0.058145134929361575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058145134929361575}
{"step": 33536, "time": 1273.1580021381378, "episode/length": 288.0, "episode/score": 0.047092938634676784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047092938634676784}
{"step": 34560, "time": 1305.737164735794, "episode/length": 288.0, "episode/score": 0.07603179774338287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07603179774338287}
{"step": 34680, "time": 1309.3599050045013, "episode/length": 288.0, "episode/score": 0.031902628562818336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031902628562818336}
{"step": 34680, "time": 1309.3724851608276, "episode/length": 288.0, "episode/score": 0.04662294191709293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04662294191709293}
{"step": 34680, "time": 1309.3854427337646, "episode/length": 288.0, "episode/score": 0.058698340743433164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058698340743433164}
{"step": 34680, "time": 1309.3945834636688, "episode/length": 288.0, "episode/score": 0.044494383062243514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044494383062243514}
{"step": 34680, "time": 1309.40571808815, "episode/length": 288.0, "episode/score": 0.06726407222382136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06726407222382136}
{"step": 34680, "time": 1309.4314723014832, "episode/length": 288.0, "episode/score": 0.06535382593705208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06535382593705208}
{"step": 35848, "time": 1346.5533165931702, "episode/length": 288.0, "episode/score": 0.06318749408032431, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06318749408032431}
{"step": 36872, "time": 1378.9865186214447, "episode/length": 288.0, "episode/score": 0.03537587247328133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03537587247328133}
{"step": 36992, "time": 1383.014146566391, "episode/length": 288.0, "episode/score": 0.06653838933991096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06653838933991096}
{"step": 36992, "time": 1383.0227303504944, "episode/length": 288.0, "episode/score": 0.05513257441714359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05513257441714359}
{"step": 36992, "time": 1383.0316853523254, "episode/length": 288.0, "episode/score": 0.05441233092284392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05441233092284392}
{"step": 36992, "time": 1383.0408909320831, "episode/length": 288.0, "episode/score": 0.0726270552601136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0726270552601136}
{"step": 36992, "time": 1383.0493483543396, "episode/length": 288.0, "episode/score": 0.045946895953221656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045946895953221656}
{"step": 36992, "time": 1383.060464143753, "episode/length": 288.0, "episode/score": 0.0660441641739169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0660441641739169}
{"step": 38160, "time": 1420.1254165172577, "episode/length": 288.0, "episode/score": 0.05226312528282051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05226312528282051}
{"step": 39184, "time": 1452.6763317584991, "episode/length": 288.0, "episode/score": 0.045877315282808695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045877315282808695}
{"step": 39304, "time": 1456.2285306453705, "episode/length": 288.0, "episode/score": 0.04459886990869677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04459886990869677}
{"step": 39304, "time": 1456.2478115558624, "episode/length": 288.0, "episode/score": 0.0745086940056865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0745086940056865}
{"step": 39304, "time": 1456.264206647873, "episode/length": 288.0, "episode/score": 0.039376327654053966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039376327654053966}
{"step": 39304, "time": 1456.2808079719543, "episode/length": 288.0, "episode/score": 0.03206782771513872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03206782771513872}
{"step": 39304, "time": 1456.2962460517883, "episode/length": 288.0, "episode/score": 0.034058340144099475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034058340144099475}
{"step": 39304, "time": 1456.3105854988098, "episode/length": 288.0, "episode/score": 0.03587764084454648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03587764084454648}
{"step": 40040, "time": 1485.0254919528961, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1485.0404987335205, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1485.0501165390015, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1485.0606331825256, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1485.0720825195312, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1485.0867838859558, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1485.0987584590912, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1485.1094279289246, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40472, "time": 1498.8306741714478, "episode/length": 288.0, "episode/score": 0.06302861291615613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06302861291615613}
{"step": 41496, "time": 1531.853587627411, "episode/length": 288.0, "episode/score": 0.050231230320989084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050231230320989084}
{"step": 41616, "time": 1535.8544754981995, "episode/length": 288.0, "episode/score": 0.04834662561876257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04834662561876257}
{"step": 41616, "time": 1535.8652300834656, "episode/length": 288.0, "episode/score": 0.03585149965735468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03585149965735468}
{"step": 41616, "time": 1535.8753430843353, "episode/length": 288.0, "episode/score": 0.03584708280305904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03584708280305904}
{"step": 41616, "time": 1535.885993719101, "episode/length": 288.0, "episode/score": 0.05564051435335671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05564051435335671}
{"step": 41616, "time": 1535.8927631378174, "episode/length": 288.0, "episode/score": 0.06388067555755583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06388067555755583}
{"step": 41616, "time": 1535.902132511139, "episode/length": 288.0, "episode/score": 0.0710249775325309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0710249775325309}
{"step": 42784, "time": 1572.8377873897552, "episode/length": 288.0, "episode/score": 0.05220410928596664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05220410928596664}
{"step": 43200, "time": 1586.137751340866, "episode/length": 197.0, "episode/score": 0.4214232308954138, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.03704822609910252}
{"step": 43808, "time": 1605.379032611847, "episode/length": 288.0, "episode/score": 0.04993495397407344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04993495397407344}
{"step": 43928, "time": 1608.9467062950134, "episode/length": 288.0, "episode/score": 0.04674490874675996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04674490874675996}
{"step": 43928, "time": 1608.9651856422424, "episode/length": 288.0, "episode/score": 0.060272511774954296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060272511774954296}
{"step": 43928, "time": 1608.981882095337, "episode/length": 288.0, "episode/score": 0.05965934847745302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05965934847745302}
{"step": 43928, "time": 1608.9983479976654, "episode/length": 288.0, "episode/score": 0.0416505362168067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0416505362168067}
{"step": 43928, "time": 1609.016042470932, "episode/length": 288.0, "episode/score": 0.06922671094787347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06922671094787347}
{"step": 44016, "time": 1612.1397948265076, "episode/length": 101.0, "episode/score": 0.7010115455622241, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.016636558298060322}
{"step": 45096, "time": 1646.1806795597076, "episode/length": 288.0, "episode/score": 0.041294683048320735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041294683048320735}
{"step": 46120, "time": 1678.6129052639008, "episode/length": 288.0, "episode/score": 0.05293573468375712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05293573468375712}
{"step": 46240, "time": 1682.62278008461, "episode/length": 288.0, "episode/score": 0.0587302768892215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0587302768892215}
{"step": 46240, "time": 1682.6355407238007, "episode/length": 288.0, "episode/score": 0.06127960380122488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06127960380122488}
{"step": 46240, "time": 1682.6468434333801, "episode/length": 288.0, "episode/score": 0.05503661177756669, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05503661177756669}
{"step": 46240, "time": 1682.6574611663818, "episode/length": 288.0, "episode/score": 0.07344568409254748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07344568409254748}
{"step": 46240, "time": 1682.667929649353, "episode/length": 288.0, "episode/score": 0.0636217374866277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0636217374866277}
{"step": 46328, "time": 1685.2229006290436, "episode/length": 288.0, "episode/score": 0.0658263987165526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0658263987165526}
{"step": 47408, "time": 1719.518209695816, "episode/length": 288.0, "episode/score": 0.06665840373644016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06665840373644016}
{"step": 48432, "time": 1751.9138429164886, "episode/length": 288.0, "episode/score": 0.06977324187751321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06977324187751321}
{"step": 48552, "time": 1755.4563975334167, "episode/length": 288.0, "episode/score": 0.07107086106825022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07107086106825022}
{"step": 48552, "time": 1755.4659011363983, "episode/length": 288.0, "episode/score": 0.05034713434628202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05034713434628202}
{"step": 48552, "time": 1755.4738132953644, "episode/length": 288.0, "episode/score": 0.047249163342385714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047249163342385714}
{"step": 48552, "time": 1755.4811046123505, "episode/length": 288.0, "episode/score": 0.06108857279947699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06108857279947699}
{"step": 48552, "time": 1755.4888925552368, "episode/length": 288.0, "episode/score": 0.06258064465356483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06258064465356483}
{"step": 48640, "time": 1758.500139951706, "episode/length": 288.0, "episode/score": 0.05485878451793269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05485878451793269}
{"step": 49720, "time": 1793.0858750343323, "episode/length": 288.0, "episode/score": 0.048077383755455116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048077383755455116}
{"step": 50024, "time": 1808.035519361496, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1808.0429091453552, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1808.0513491630554, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1808.0579767227173, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1808.0642547607422, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1808.0710208415985, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1808.0790860652924, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1808.0856380462646, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50744, "time": 1831.003000497818, "episode/length": 288.0, "episode/score": 0.05710084264183024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05710084264183024}
{"step": 50864, "time": 1835.0884404182434, "episode/length": 288.0, "episode/score": 0.05998306738740666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05998306738740666}
{"step": 50864, "time": 1835.100521326065, "episode/length": 288.0, "episode/score": 0.06977413160052492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06977413160052492}
{"step": 50864, "time": 1835.113489151001, "episode/length": 288.0, "episode/score": 0.06592242039107532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06592242039107532}
{"step": 50864, "time": 1835.1243691444397, "episode/length": 288.0, "episode/score": 0.02544881854146297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02544881854146297}
{"step": 50864, "time": 1835.1332259178162, "episode/length": 288.0, "episode/score": 0.05789419774862381, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05789419774862381}
{"step": 50952, "time": 1837.6952450275421, "episode/length": 288.0, "episode/score": 0.06877632920475207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06877632920475207}
{"step": 52032, "time": 1872.3200178146362, "episode/length": 288.0, "episode/score": 0.05502899179418819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05502899179418819}
{"step": 53056, "time": 1904.6571023464203, "episode/length": 288.0, "episode/score": 0.07454549914996278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07454549914996278}
{"step": 53176, "time": 1908.2103061676025, "episode/length": 288.0, "episode/score": 0.059445928432751316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059445928432751316}
{"step": 53176, "time": 1908.2192311286926, "episode/length": 288.0, "episode/score": 0.05294343250102429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05294343250102429}
{"step": 53176, "time": 1908.2269413471222, "episode/length": 288.0, "episode/score": 0.05653644184280893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05653644184280893}
{"step": 53176, "time": 1908.234675168991, "episode/length": 288.0, "episode/score": 0.06328922705023388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06328922705023388}
{"step": 53176, "time": 1908.2415609359741, "episode/length": 288.0, "episode/score": 0.054006022351813954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054006022351813954}
{"step": 53264, "time": 1911.352369070053, "episode/length": 288.0, "episode/score": 0.06370305603667248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06370305603667248}
{"step": 54344, "time": 1945.4424395561218, "episode/length": 288.0, "episode/score": 0.05322815938313852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05322815938313852}
{"step": 55368, "time": 1977.9385721683502, "episode/length": 288.0, "episode/score": 0.06866751697742757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06866751697742757}
{"step": 55488, "time": 1981.9589550495148, "episode/length": 288.0, "episode/score": 0.0561656037297098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0561656037297098}
{"step": 55488, "time": 1981.9730775356293, "episode/length": 288.0, "episode/score": 0.02144297083003721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02144297083003721}
{"step": 55488, "time": 1981.9864008426666, "episode/length": 288.0, "episode/score": 0.04599212948028253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04599212948028253}
{"step": 55488, "time": 1981.9995307922363, "episode/length": 288.0, "episode/score": 0.06701615162415919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06701615162415919}
{"step": 55488, "time": 1982.011973619461, "episode/length": 288.0, "episode/score": 0.049151704639825766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049151704639825766}
{"step": 55576, "time": 1984.571984052658, "episode/length": 288.0, "episode/score": 0.05945851335258112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05945851335258112}
{"step": 56656, "time": 2018.846122264862, "episode/length": 288.0, "episode/score": 0.0605176231022142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0605176231022142}
{"step": 57664, "time": 2051.3105823993683, "episode/length": 271.0, "episode/score": 0.20397754222426556, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.05085254040818654}
{"step": 57680, "time": 2051.82284784317, "episode/length": 288.0, "episode/score": 0.06307510832317575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06307510832317575}
{"step": 57800, "time": 2055.400988340378, "episode/length": 288.0, "episode/score": 0.058486945336198914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058486945336198914}
{"step": 57800, "time": 2055.4159796237946, "episode/length": 288.0, "episode/score": 0.06496130251258592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06496130251258592}
{"step": 57800, "time": 2055.4312040805817, "episode/length": 288.0, "episode/score": 0.03484983450420032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03484983450420032}
{"step": 57800, "time": 2055.445399045944, "episode/length": 288.0, "episode/score": 0.057010068910472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057010068910472}
{"step": 57888, "time": 2058.4621245861053, "episode/length": 288.0, "episode/score": 0.04980943331287335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04980943331287335}
{"step": 58968, "time": 2092.7757210731506, "episode/length": 288.0, "episode/score": 0.050345857557147156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050345857557147156}
{"step": 59976, "time": 2124.7770099639893, "episode/length": 288.0, "episode/score": 0.037597064062538266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037597064062538266}
{"step": 59992, "time": 2125.2918589115143, "episode/length": 288.0, "episode/score": 0.050182646771361306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050182646771361306}
{"step": 60008, "time": 2131.761312007904, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2131.7756626605988, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2131.7892820835114, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2131.801778316498, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2131.812151670456, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2131.826906442642, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2131.8418865203857, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2131.8558218479156, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60112, "time": 2135.4000601768494, "episode/length": 288.0, "episode/score": 0.06999286511575065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06999286511575065}
{"step": 60112, "time": 2135.4102261066437, "episode/length": 288.0, "episode/score": 0.05370458116175314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05370458116175314}
{"step": 60112, "time": 2135.4190254211426, "episode/length": 288.0, "episode/score": 0.05345233318217879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05345233318217879}
{"step": 60112, "time": 2135.427836418152, "episode/length": 288.0, "episode/score": 0.06161820927957251, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06161820927957251}
{"step": 60200, "time": 2137.993896007538, "episode/length": 288.0, "episode/score": 0.07677903763004679, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07677903763004679}
{"step": 61280, "time": 2172.531636238098, "episode/length": 288.0, "episode/score": 0.07288541256860981, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07288541256860981}
{"step": 62288, "time": 2204.4814534187317, "episode/length": 288.0, "episode/score": 0.055052491779974844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055052491779974844}
{"step": 62297, "time": 2205.5187973976135, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.997352718689281, "train/action_min": 0.0, "train/action_std": 1.9995017008460247, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0002640771217085662, "train/actor_opt_grad_steps": 2830.0, "train/actor_opt_loss": 4.976420188235804, "train/adv_mag": 0.0010178737496773815, "train/adv_max": 0.0010178737496773815, "train/adv_mean": 0.0005588818319929628, "train/adv_min": 2.6608802802822134e-06, "train/adv_std": 0.00026187056907328387, "train/cont_avg": 0.9965592616580311, "train/cont_loss_mean": 0.023068055574458884, "train/cont_loss_std": 0.3221463306319606, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.724737124240145, "train/cont_pos_acc": 0.9999999882643704, "train/cont_pos_loss": 0.0033636612906916925, "train/cont_pred": 0.9966423103846417, "train/cont_rate": 0.9965592616580311, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0898771767789218, "train/extr_critic_critic_opt_grad_steps": 2830.0, "train/extr_critic_critic_opt_loss": 11468.55070535136, "train/extr_critic_mag": 0.044587913572479404, "train/extr_critic_max": 0.044587913572479404, "train/extr_critic_mean": 0.04448246216604129, "train/extr_critic_min": 0.04441424663820415, "train/extr_critic_std": 2.0003436953494273e-05, "train/extr_return_normed_mag": 0.0019938728622513114, "train/extr_return_normed_max": 0.0019938728622513114, "train/extr_return_normed_mean": 0.0015953246505877939, "train/extr_return_normed_min": 0.00107335658271078, "train/extr_return_normed_std": 0.0002606440591640949, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.04543988844814078, "train/extr_return_raw_max": 0.04543988844814078, "train/extr_return_raw_mean": 0.045041342512004735, "train/extr_return_raw_min": 0.04451937216860025, "train/extr_return_raw_std": 0.00026064405912639565, "train/extr_reward_mag": 0.00022215793787506578, "train/extr_reward_max": 0.00022215793787506578, "train/extr_reward_mean": 0.00022197507436138726, "train/extr_reward_min": 0.00022174533784698327, "train/extr_reward_std": 8.30610583692438e-08, "train/image_loss_mean": 0.27302522656213435, "train/image_loss_std": 0.08450066116807374, "train/model_loss_mean": 0.9072169917852767, "train/model_loss_std": 0.3544803001179596, "train/model_opt_grad_norm": 86.7534994807268, "train/model_opt_grad_steps": 2820.0, "train/model_opt_loss": 48.31180363986159, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 53.331444300518136, "train/policy_entropy_mag": 1.9458853506671332, "train/policy_entropy_max": 1.9458853506671332, "train/policy_entropy_mean": 1.9447080872837126, "train/policy_entropy_min": 1.9165329729337148, "train/policy_entropy_std": 0.0009293357372390096, "train/policy_logprob_mag": 2.264289510064792, "train/policy_logprob_max": -1.636932740557379, "train/policy_logprob_mean": -1.944714116926638, "train/policy_logprob_min": -2.264289510064792, "train/policy_logprob_std": 0.048695513235472644, "train/policy_randomness_mag": 0.9999873144021306, "train/policy_randomness_max": 0.9999873144021306, "train/policy_randomness_mean": 0.9993823179926897, "train/policy_randomness_min": 0.9849031737431343, "train/policy_randomness_std": 0.0004775841245994725, "train/post_ent_mag": 56.48553022078282, "train/post_ent_max": 56.48553022078282, "train/post_ent_mean": 56.09833089798843, "train/post_ent_min": 56.06346776695449, "train/post_ent_std": 0.06202872728668346, "train/prior_ent_mag": 65.4336914497336, "train/prior_ent_max": 65.4336914497336, "train/prior_ent_mean": 65.2274478655405, "train/prior_ent_min": 65.16655982220111, "train/prior_ent_std": 0.05005471576294751, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00024277061661898396, "train/reward_loss_mean": 0.011123692090840229, "train/reward_loss_std": 0.0374175302607099, "train/reward_max_data": 0.028903282378978757, "train/reward_max_pred": 0.0002221443492513864, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.010300259916546123, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.822920044263205, "train/reward_pred": 0.0002218251788525461, "train/reward_rate": 8.095854922279793e-05, "train_stats/mean_log_entropy": 1.9378832679874491, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.030933910980820656, "report/cont_loss_std": 0.38338473439216614, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.5040788650512695, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004078443627804518, "report/cont_pred": 0.9959297776222229, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24675098061561584, "report/image_loss_std": 0.08327698707580566, "report/model_loss_mean": 0.8878415822982788, "report/model_loss_std": 0.40003663301467896, "report/post_ent_mag": 48.60706329345703, "report/post_ent_max": 48.60706329345703, "report/post_ent_mean": 48.313194274902344, "report/post_ent_min": 48.28551483154297, "report/post_ent_std": 0.04642904922366142, "report/prior_ent_mag": 58.01536560058594, "report/prior_ent_max": 58.01536560058594, "report/prior_ent_mean": 57.78589630126953, "report/prior_ent_min": 57.73798370361328, "report/prior_ent_std": 0.05285659804940224, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00020696688443422318, "report/reward_loss_mean": 0.010156682692468166, "report/reward_loss_std": 0.016730746254324913, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00021779537200927734, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010156682692468166, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002173430984839797, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004078443627804518, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004078443627804518, "eval/cont_pred": 0.9959297776222229, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26856058835983276, "eval/image_loss_std": 0.09121710807085037, "eval/model_loss_mean": 0.8740494251251221, "eval/model_loss_std": 0.09121706336736679, "eval/post_ent_mag": 48.603851318359375, "eval/post_ent_max": 48.603851318359375, "eval/post_ent_mean": 48.31047821044922, "eval/post_ent_min": 48.285919189453125, "eval/post_ent_std": 0.04108675941824913, "eval/prior_ent_mag": 58.01536560058594, "eval/prior_ent_max": 58.01536560058594, "eval/prior_ent_mean": 57.781097412109375, "eval/prior_ent_min": 57.73122024536133, "eval/prior_ent_std": 0.048748426139354706, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014103981666266918, "eval/reward_loss_std": 2.615210405565449e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00021779537200927734, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014103981666266918, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00021732400637120008, "eval/reward_rate": 0.0, "replay/size": 61793.0, "replay/inserts": 30880.0, "replay/samples": 30880.0, "replay/insert_wait_avg": 1.332688825735774e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.694865330513278e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1480253323001707e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0687823295593, "timer/env.step_count": 3860.0, "timer/env.step_total": 38.14312934875488, "timer/env.step_frac": 0.038140505955904666, "timer/env.step_avg": 0.009881639727656705, "timer/env.step_min": 0.008151769638061523, "timer/env.step_max": 0.05291128158569336, "timer/replay._sample_count": 30880.0, "timer/replay._sample_total": 16.08364772796631, "timer/replay._sample_frac": 0.016082541533294414, "timer/replay._sample_avg": 0.000520843514506681, "timer/replay._sample_min": 0.0003688335418701172, "timer/replay._sample_max": 0.033599138259887695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4727.0, "timer/agent.policy_total": 48.53854966163635, "timer/agent.policy_frac": 0.048535211296737706, "timer/agent.policy_avg": 0.010268362526261128, "timer/agent.policy_min": 0.008685111999511719, "timer/agent.policy_max": 0.09147000312805176, "timer/dataset_train_count": 1930.0, "timer/dataset_train_total": 0.214493989944458, "timer/dataset_train_frac": 0.00021447923756285633, "timer/dataset_train_avg": 0.00011113678235464145, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.00028514862060546875, "timer/agent.train_count": 1930.0, "timer/agent.train_total": 863.2471482753754, "timer/agent.train_frac": 0.8631877762092806, "timer/agent.train_avg": 0.4472783151685883, "timer/agent.train_min": 0.43682026863098145, "timer/agent.train_max": 0.5859193801879883, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4685025215148926, "timer/agent.report_frac": 0.0004684702990363955, "timer/agent.report_avg": 0.2342512607574463, "timer/agent.report_min": 0.2248525619506836, "timer/agent.report_max": 0.24364995956420898, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.266109883045054e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 30.877125779099956}
{"step": 62304, "time": 2205.543116092682, "episode/length": 288.0, "episode/score": 0.03651208642941128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03651208642941128}
{"step": 62424, "time": 2209.528665781021, "episode/length": 288.0, "episode/score": 0.063565135502472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.063565135502472}
{"step": 62424, "time": 2209.537987470627, "episode/length": 288.0, "episode/score": 0.06052148427204429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06052148427204429}
{"step": 62424, "time": 2209.5464532375336, "episode/length": 288.0, "episode/score": 0.07484742798499155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07484742798499155}
{"step": 62424, "time": 2209.5544769763947, "episode/length": 288.0, "episode/score": 0.055810208810953554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055810208810953554}
{"step": 62512, "time": 2212.7206230163574, "episode/length": 288.0, "episode/score": 0.05499660310385934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05499660310385934}
{"step": 63592, "time": 2246.767968893051, "episode/length": 288.0, "episode/score": 0.07960345150081594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07960345150081594}
{"step": 64600, "time": 2278.846526861191, "episode/length": 288.0, "episode/score": 0.04693867469978841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04693867469978841}
{"step": 64616, "time": 2279.3618364334106, "episode/length": 288.0, "episode/score": 0.05704777047913012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05704777047913012}
{"step": 64736, "time": 2283.3891744613647, "episode/length": 288.0, "episode/score": 0.06744540016370593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06744540016370593}
{"step": 64736, "time": 2283.3974044322968, "episode/length": 288.0, "episode/score": 0.042428557622486096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042428557622486096}
{"step": 64736, "time": 2283.4070115089417, "episode/length": 288.0, "episode/score": 0.08317760152090159, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08317760152090159}
{"step": 64736, "time": 2283.4151356220245, "episode/length": 288.0, "episode/score": 0.07334254923279104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07334254923279104}
{"step": 64824, "time": 2286.0143609046936, "episode/length": 288.0, "episode/score": 0.06024796584318892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06024796584318892}
{"step": 65904, "time": 2321.0254373550415, "episode/length": 288.0, "episode/score": 0.0517943669011629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0517943669011629}
{"step": 66912, "time": 2353.074172258377, "episode/length": 288.0, "episode/score": 0.07635721151291364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07635721151291364}
{"step": 66928, "time": 2353.591897249222, "episode/length": 288.0, "episode/score": 0.04109533318080594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04109533318080594}
{"step": 67048, "time": 2357.1765038967133, "episode/length": 288.0, "episode/score": 0.032648434681846084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032648434681846084}
{"step": 67048, "time": 2357.1885964870453, "episode/length": 288.0, "episode/score": 0.06048235030743854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06048235030743854}
{"step": 67048, "time": 2357.202626466751, "episode/length": 288.0, "episode/score": 0.03834043846120494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03834043846120494}
{"step": 67048, "time": 2357.216542005539, "episode/length": 288.0, "episode/score": 0.044116659679843906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044116659679843906}
{"step": 67136, "time": 2360.2278068065643, "episode/length": 288.0, "episode/score": 0.037701078187978965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037701078187978965}
{"step": 68216, "time": 2394.3205258846283, "episode/length": 288.0, "episode/score": 0.04668209567677195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04668209567677195}
{"step": 69224, "time": 2426.2991120815277, "episode/length": 288.0, "episode/score": 0.03975497694108299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03975497694108299}
{"step": 69240, "time": 2426.8340032100677, "episode/length": 288.0, "episode/score": 0.06935385353727952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06935385353727952}
{"step": 69360, "time": 2430.8675100803375, "episode/length": 288.0, "episode/score": 0.05892277266275414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05892277266275414}
{"step": 69360, "time": 2430.876793384552, "episode/length": 288.0, "episode/score": 0.07153227975715026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07153227975715026}
{"step": 69360, "time": 2430.886860847473, "episode/length": 288.0, "episode/score": 0.04986274176388861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04986274176388861}
{"step": 69360, "time": 2430.8962297439575, "episode/length": 288.0, "episode/score": 0.03501460701409087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03501460701409087}
{"step": 69448, "time": 2433.489803791046, "episode/length": 288.0, "episode/score": 0.058017373638051595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058017373638051595}
{"step": 70096, "time": 2459.4253408908844, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2459.434417486191, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2459.4445011615753, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2459.4510464668274, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2459.4601414203644, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2459.4697160720825, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2459.478260755539, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2459.488371372223, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70528, "time": 2473.2147114276886, "episode/length": 288.0, "episode/score": 0.05139842764083369, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05139842764083369}
{"step": 71536, "time": 2505.148140668869, "episode/length": 288.0, "episode/score": 0.05585882848976098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05585882848976098}
{"step": 71552, "time": 2505.661175966263, "episode/length": 288.0, "episode/score": 0.052062159070828784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052062159070828784}
{"step": 71672, "time": 2509.224086999893, "episode/length": 288.0, "episode/score": 0.05402008586929696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05402008586929696}
{"step": 71672, "time": 2509.2322459220886, "episode/length": 288.0, "episode/score": 0.04224564547456566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04224564547456566}
{"step": 71672, "time": 2509.2394676208496, "episode/length": 288.0, "episode/score": 0.042947208326950204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042947208326950204}
{"step": 71672, "time": 2509.2466650009155, "episode/length": 288.0, "episode/score": 0.026118358027872546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026118358027872546}
{"step": 71760, "time": 2512.358076572418, "episode/length": 288.0, "episode/score": 0.04536136508437494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04536136508437494}
{"step": 72840, "time": 2546.4727561473846, "episode/length": 288.0, "episode/score": 0.041700819751099516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041700819751099516}
{"step": 73176, "time": 2557.1130471229553, "episode/length": 204.0, "episode/score": 0.4020286891441174, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.03952867838734164}
{"step": 73864, "time": 2579.4903178215027, "episode/length": 288.0, "episode/score": 0.0404210379892902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0404210379892902}
{"step": 73984, "time": 2583.512204170227, "episode/length": 288.0, "episode/score": 0.03304378776977046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03304378776977046}
{"step": 73984, "time": 2583.5446202754974, "episode/length": 288.0, "episode/score": 0.05562630726183215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05562630726183215}
{"step": 73984, "time": 2583.5763494968414, "episode/length": 288.0, "episode/score": 0.04484568610723727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04484568610723727}
{"step": 73984, "time": 2583.614895105362, "episode/length": 288.0, "episode/score": 0.0747107554827835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0747107554827835}
{"step": 74072, "time": 2586.1892428398132, "episode/length": 288.0, "episode/score": 0.06467746392422669, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06467746392422669}
{"step": 75152, "time": 2620.782242298126, "episode/length": 288.0, "episode/score": 0.03939610930535764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03939610930535764}
{"step": 75488, "time": 2631.4657893180847, "episode/length": 288.0, "episode/score": 0.039530127874286336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039530127874286336}
{"step": 76176, "time": 2653.223441839218, "episode/length": 288.0, "episode/score": 0.06264068202568751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06264068202568751}
{"step": 76296, "time": 2656.819704055786, "episode/length": 288.0, "episode/score": 0.07067599721125362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07067599721125362}
{"step": 76296, "time": 2656.8336341381073, "episode/length": 288.0, "episode/score": 0.04881203439413184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04881203439413184}
{"step": 76296, "time": 2656.8433089256287, "episode/length": 288.0, "episode/score": 0.08376758402948781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08376758402948781}
{"step": 76296, "time": 2656.8515803813934, "episode/length": 288.0, "episode/score": 0.07418772805567642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07418772805567642}
{"step": 76384, "time": 2659.8597481250763, "episode/length": 288.0, "episode/score": 0.06985810870332898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06985810870332898}
{"step": 77464, "time": 2693.9043498039246, "episode/length": 288.0, "episode/score": 0.08039591262729573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08039591262729573}
{"step": 77800, "time": 2704.5375514030457, "episode/length": 288.0, "episode/score": 0.04474353097373296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04474353097373296}
{"step": 78440, "time": 2725.569062232971, "episode/length": 267.0, "episode/score": 0.22398465210324048, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.05835964730692922}
{"step": 78488, "time": 2727.084898710251, "episode/length": 288.0, "episode/score": 0.04637430812238108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04637430812238108}
{"step": 78608, "time": 2731.1071240901947, "episode/length": 288.0, "episode/score": 0.07571585547316317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07571585547316317}
{"step": 78608, "time": 2731.1197867393494, "episode/length": 288.0, "episode/score": 0.0773819270052627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0773819270052627}
{"step": 78608, "time": 2731.134658098221, "episode/length": 288.0, "episode/score": 0.06971832184160576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06971832184160576}
{"step": 78696, "time": 2733.7054636478424, "episode/length": 288.0, "episode/score": 0.07078208253892626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07078208253892626}
{"step": 79776, "time": 2768.1716601848602, "episode/length": 288.0, "episode/score": 0.06637356182693566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06637356182693566}
{"step": 80080, "time": 2783.3192851543427, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2783.3293595314026, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2783.338644504547, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2783.3457176685333, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2783.3540513515472, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2783.3681902885437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2783.386748313904, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2783.409932613373, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80112, "time": 2784.459169626236, "episode/length": 288.0, "episode/score": 0.06521707866056659, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06521707866056659}
{"step": 80752, "time": 2804.7730491161346, "episode/length": 288.0, "episode/score": 0.05705089245009276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05705089245009276}
{"step": 80800, "time": 2806.2916371822357, "episode/length": 288.0, "episode/score": 0.045709325995971994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045709325995971994}
{"step": 80920, "time": 2809.882105112076, "episode/length": 288.0, "episode/score": 0.042924027730009584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042924027730009584}
{"step": 80920, "time": 2809.8904445171356, "episode/length": 288.0, "episode/score": 0.05714158068417419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05714158068417419}
{"step": 80920, "time": 2809.898094177246, "episode/length": 288.0, "episode/score": 0.06537275101777595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06537275101777595}
{"step": 81008, "time": 2812.977459669113, "episode/length": 288.0, "episode/score": 0.06917706046215244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06917706046215244}
{"step": 82088, "time": 2847.443877696991, "episode/length": 288.0, "episode/score": 0.044012016624435546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044012016624435546}
{"step": 82424, "time": 2858.160721540451, "episode/length": 288.0, "episode/score": 0.04624861683265635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04624861683265635}
{"step": 83064, "time": 2878.501867055893, "episode/length": 288.0, "episode/score": 0.05101809546556524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05101809546556524}
{"step": 83112, "time": 2880.014898777008, "episode/length": 288.0, "episode/score": 0.07112556511265211, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07112556511265211}
{"step": 83232, "time": 2884.0657093524933, "episode/length": 288.0, "episode/score": 0.0666919025208017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0666919025208017}
{"step": 83232, "time": 2884.0824773311615, "episode/length": 288.0, "episode/score": 0.05491279483027256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05491279483027256}
{"step": 83232, "time": 2884.099833011627, "episode/length": 288.0, "episode/score": 0.05619517595260959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05619517595260959}
{"step": 83320, "time": 2886.657970428467, "episode/length": 288.0, "episode/score": 0.03887466877972656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03887466877972656}
{"step": 83488, "time": 2892.182540655136, "episode/length": 31.0, "episode/score": 0.91675698210571, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.013631994841546202}
{"step": 84400, "time": 2921.080924987793, "episode/length": 288.0, "episode/score": 0.059304286923236305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059304286923236305}
{"step": 84736, "time": 2931.95218873024, "episode/length": 288.0, "episode/score": 0.05078257013599341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05078257013599341}
{"step": 85376, "time": 2952.148556947708, "episode/length": 288.0, "episode/score": 0.0482166557939081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0482166557939081}
{"step": 85424, "time": 2953.683434486389, "episode/length": 288.0, "episode/score": 0.04442048042744773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04442048042744773}
{"step": 85544, "time": 2957.237081050873, "episode/length": 288.0, "episode/score": 0.03285532633975663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03285532633975663}
{"step": 85544, "time": 2957.251743078232, "episode/length": 288.0, "episode/score": 0.047936652786745526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047936652786745526}
{"step": 85632, "time": 2960.2574667930603, "episode/length": 288.0, "episode/score": 0.047234676885352656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047234676885352656}
{"step": 85800, "time": 2965.5432896614075, "episode/length": 288.0, "episode/score": 0.052329171160550914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052329171160550914}
{"step": 86712, "time": 2994.488879919052, "episode/length": 288.0, "episode/score": 0.053894188302393786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053894188302393786}
{"step": 87048, "time": 3005.123917579651, "episode/length": 288.0, "episode/score": 0.049294570561642104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049294570561642104}
{"step": 87688, "time": 3025.5002150535583, "episode/length": 288.0, "episode/score": 0.043965685059134785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043965685059134785}
{"step": 87736, "time": 3027.0264592170715, "episode/length": 288.0, "episode/score": 0.0630183289966908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0630183289966908}
{"step": 87856, "time": 3031.0641157627106, "episode/length": 288.0, "episode/score": 0.04529464168319919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04529464168319919}
{"step": 87856, "time": 3031.0809674263, "episode/length": 288.0, "episode/score": 0.06739261626839266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06739261626839266}
{"step": 87944, "time": 3033.660879135132, "episode/length": 288.0, "episode/score": 0.051904138492886887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051904138492886887}
{"step": 88112, "time": 3039.2361345291138, "episode/length": 288.0, "episode/score": 0.08372243103627852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08372243103627852}
{"step": 89024, "time": 3068.2193167209625, "episode/length": 288.0, "episode/score": 0.04382968592122438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04382968592122438}
{"step": 89208, "time": 3073.8384206295013, "episode/length": 168.0, "episode/score": 0.5036094999023533, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.02860950702697096}
{"step": 89360, "time": 3078.936716079712, "episode/length": 288.0, "episode/score": 0.02822764622186469, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02822764622186469}
{"step": 89568, "time": 3085.770872116089, "episode/length": 44.0, "episode/score": 0.8748816219136586, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.012381581354560467}
{"step": 90000, "time": 3099.442672729492, "episode/length": 288.0, "episode/score": 0.06209625020213139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06209625020213139}
{"step": 90048, "time": 3100.984885931015, "episode/length": 288.0, "episode/score": 0.04415485629488103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04415485629488103}
{"step": 90064, "time": 3104.013873577118, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 90064, "time": 3107.8612134456635, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3107.8775985240936, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3107.8945367336273, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3107.908728837967, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3107.923542022705, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3107.9363646507263, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3107.9515674114227, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90168, "time": 3111.669759273529, "episode/length": 288.0, "episode/score": 0.06712660148730265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06712660148730265}
{"step": 90256, "time": 3114.676591873169, "episode/length": 288.0, "episode/score": 0.06324513979464541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06324513979464541}
{"step": 90424, "time": 3119.7397215366364, "episode/length": 288.0, "episode/score": 0.05439267325149899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05439267325149899}
{"step": 91336, "time": 3148.65038394928, "episode/length": 288.0, "episode/score": 0.08158201356610562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08158201356610562}
{"step": 91672, "time": 3159.277714252472, "episode/length": 288.0, "episode/score": 0.054805245521947654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054805245521947654}
{"step": 91880, "time": 3165.9448294639587, "episode/length": 288.0, "episode/score": 0.08542674251472704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08542674251472704}
{"step": 92312, "time": 3179.716691017151, "episode/length": 288.0, "episode/score": 0.06053284966105821, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06053284966105821}
{"step": 92360, "time": 3181.2291781902313, "episode/length": 288.0, "episode/score": 0.064550742299474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.064550742299474}
{"step": 92480, "time": 3185.2451503276825, "episode/length": 288.0, "episode/score": 0.07214837191480683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07214837191480683}
{"step": 92560, "time": 3187.7634947299957, "episode/length": 30.0, "episode/score": 0.9204893364285454, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.014239307790376188}
{"step": 92568, "time": 3187.803092479706, "episode/length": 288.0, "episode/score": 0.06749405811211773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06749405811211773}
{"step": 92736, "time": 3193.305748462677, "episode/length": 288.0, "episode/score": 0.07879370760895199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07879370760895199}
{"step": 93105, "time": 3205.543235063553, "train_stats/mean_log_entropy": 1.9372315174710435, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.999871288556509, "train/action_min": 0.0, "train/action_std": 1.9994716996355995, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00013016775426716627, "train/actor_opt_grad_steps": 4760.0, "train/actor_opt_loss": -0.34121055768228525, "train/adv_mag": 0.0005668355586306419, "train/adv_max": 0.0005668355586306419, "train/adv_mean": 0.0002803801514106227, "train/adv_min": -6.523516048421515e-05, "train/adv_std": 0.00013991158403095204, "train/cont_avg": 0.996533962111399, "train/cont_loss_mean": 0.02316614213264475, "train/cont_loss_std": 0.32171289626645244, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.696399300186722, "train/cont_pos_acc": 0.9999999839407174, "train/cont_pos_loss": 0.0034245502992673086, "train/cont_pred": 0.9965814836902321, "train/cont_rate": 0.996533962111399, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.041525275538159157, "train/extr_critic_critic_opt_grad_steps": 4760.0, "train/extr_critic_critic_opt_loss": 12843.835365730247, "train/extr_critic_mag": 0.05992252839043968, "train/extr_critic_max": 0.05992252839043968, "train/extr_critic_mean": 0.05980338285546846, "train/extr_critic_min": 0.059734811436944674, "train/extr_critic_std": 2.9876858358205538e-05, "train/extr_return_normed_mag": 0.0010355450405975697, "train/extr_return_normed_max": 0.0010355450405975697, "train/extr_return_normed_mean": 0.0008113415195658523, "train/extr_return_normed_min": 0.0005178497283878722, "train/extr_return_normed_std": 0.000134356432804193, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.06030799265120931, "train/extr_return_raw_max": 0.06030799265120931, "train/extr_return_raw_mean": 0.060083792192639464, "train/extr_return_raw_min": 0.05979029733899961, "train/extr_return_raw_std": 0.0001343564328513171, "train/extr_reward_mag": 0.0002242011727446719, "train/extr_reward_max": 0.0002242011727446719, "train/extr_reward_mean": 0.00022403096653209815, "train/extr_reward_min": 0.00022382007361693704, "train/extr_reward_std": 7.238189359108502e-08, "train/image_loss_mean": 0.2638846269852139, "train/image_loss_std": 0.08494557119867345, "train/model_loss_mean": 0.8977599554728968, "train/model_loss_std": 0.3562596886191961, "train/model_opt_grad_norm": 71.06774189805738, "train/model_opt_grad_steps": 4750.0, "train/model_opt_loss": 183.81811839681833, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 204.82512953367876, "train/policy_entropy_mag": 1.945897072708051, "train/policy_entropy_max": 1.945897072708051, "train/policy_entropy_mean": 1.9452649046102337, "train/policy_entropy_min": 1.930758616467214, "train/policy_entropy_std": 0.0004968880779783054, "train/policy_logprob_mag": 2.1670256328088633, "train/policy_logprob_max": -1.7241852808492788, "train/policy_logprob_mean": -1.9452092202833897, "train/policy_logprob_min": -2.1670256328088633, "train/policy_logprob_std": 0.035810508219998115, "train/policy_randomness_mag": 0.9999933400302353, "train/policy_randomness_max": 0.9999933400302353, "train/policy_randomness_mean": 0.9996684697007886, "train/policy_randomness_min": 0.9922137115285804, "train/policy_randomness_std": 0.0002553499723878723, "train/post_ent_mag": 44.043979585479576, "train/post_ent_max": 44.043979585479576, "train/post_ent_mean": 43.87739284297963, "train/post_ent_min": 43.84105095344504, "train/post_ent_std": 0.026635720008511308, "train/prior_ent_mag": 52.69288324939155, "train/prior_ent_max": 52.69288324939155, "train/prior_ent_mean": 52.56092593336352, "train/prior_ent_min": 52.50566251290277, "train/prior_ent_std": 0.03071115919210287, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00023360029822022416, "train/reward_loss_mean": 0.010709164596592206, "train/reward_loss_std": 0.041875152230996235, "train/reward_max_data": 0.03494063093824013, "train/reward_max_pred": 0.0002246570093026433, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009858983619514988, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.853274245011178, "train/reward_pred": 0.00022435365208554916, "train/reward_rate": 9.613827720207254e-05, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.032113492488861084, "report/cont_loss_std": 0.4274957478046417, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.13498067855835, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002168115694075823, "report/cont_pred": 0.9978342652320862, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.27375125885009766, "report/image_loss_std": 0.07483068853616714, "report/model_loss_mean": 0.9142964482307434, "report/model_loss_std": 0.4350612163543701, "report/post_ent_mag": 41.58806610107422, "report/post_ent_max": 41.58806610107422, "report/post_ent_mean": 41.566253662109375, "report/post_ent_min": 41.48834991455078, "report/post_ent_std": 0.01914413832128048, "report/prior_ent_mag": 43.87867736816406, "report/prior_ent_max": 43.87867736816406, "report/prior_ent_mean": 43.83409881591797, "report/prior_ent_min": 43.79100799560547, "report/prior_ent_std": 0.01259820256382227, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00016706733731552958, "report/reward_loss_mean": 0.008431699126958847, "report/reward_loss_std": 0.015427161008119583, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00023162364959716797, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008431699126958847, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00023161270655691624, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.002168115694075823, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002168115694075823, "eval/cont_pred": 0.9978342652320862, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2834082543849945, "eval/image_loss_std": 0.08488301932811737, "eval/model_loss_mean": 0.8869548439979553, "eval/model_loss_std": 0.08488301187753677, "eval/post_ent_mag": 41.58917236328125, "eval/post_ent_max": 41.58917236328125, "eval/post_ent_mean": 41.56883239746094, "eval/post_ent_min": 41.49688720703125, "eval/post_ent_std": 0.01707538776099682, "eval/prior_ent_mag": 43.883392333984375, "eval/prior_ent_max": 43.883392333984375, "eval/prior_ent_mean": 43.83429718017578, "eval/prior_ent_min": 43.795989990234375, "eval/prior_ent_std": 0.011794534511864185, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013784747570753098, "eval/reward_loss_std": 2.900886784118484e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00023162364959716797, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013784747570753098, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002316134050488472, "eval/reward_rate": 0.0, "replay/size": 92601.0, "replay/inserts": 30808.0, "replay/samples": 30800.0, "replay/insert_wait_avg": 1.3304248904909478e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0931259625917905e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.205326914099811e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0089547634125, "timer/env.step_count": 3851.0, "timer/env.step_total": 37.38924741744995, "timer/env.step_frac": 0.03738891260858329, "timer/env.step_avg": 0.00970897102504543, "timer/env.step_min": 0.008034467697143555, "timer/env.step_max": 0.053922414779663086, "timer/replay._sample_count": 30800.0, "timer/replay._sample_total": 16.1514892578125, "timer/replay._sample_frac": 0.016151344626342577, "timer/replay._sample_avg": 0.0005243990018770292, "timer/replay._sample_min": 0.0003726482391357422, "timer/replay._sample_max": 0.03253889083862305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4718.0, "timer/agent.policy_total": 48.5435254573822, "timer/agent.policy_frac": 0.048543090765489086, "timer/agent.policy_avg": 0.010289004971891098, "timer/agent.policy_min": 0.008975028991699219, "timer/agent.policy_max": 0.09775137901306152, "timer/dataset_train_count": 1925.0, "timer/dataset_train_total": 0.21565723419189453, "timer/dataset_train_frac": 0.00021565530304967708, "timer/dataset_train_avg": 0.00011202973204773742, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.00041556358337402344, "timer/agent.train_count": 1925.0, "timer/agent.train_total": 863.5590653419495, "timer/agent.train_frac": 0.8635513324440729, "timer/agent.train_avg": 0.4486021118659478, "timer/agent.train_min": 0.4375581741333008, "timer/agent.train_max": 0.9977796077728271, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4725193977355957, "timer/agent.report_frac": 0.00047251516647407114, "timer/agent.report_avg": 0.23625969886779785, "timer/agent.report_min": 0.22528815269470215, "timer/agent.report_max": 0.24723124504089355, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.170938707044864e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 30.807226165935347}
{"step": 93648, "time": 3222.8979041576385, "episode/length": 288.0, "episode/score": 0.09271066356512847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09271066356512847}
{"step": 93984, "time": 3233.5540902614594, "episode/length": 288.0, "episode/score": 0.05813084870399621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05813084870399621}
{"step": 94192, "time": 3240.134439468384, "episode/length": 288.0, "episode/score": 0.0693250633455591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0693250633455591}
{"step": 94672, "time": 3255.2109293937683, "episode/length": 288.0, "episode/score": 0.07901071116498315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07901071116498315}
{"step": 94792, "time": 3258.771726369858, "episode/length": 288.0, "episode/score": 0.06640280687429367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06640280687429367}
{"step": 94872, "time": 3261.4793581962585, "episode/length": 288.0, "episode/score": 0.08404399740186363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08404399740186363}
{"step": 94880, "time": 3261.9704763889313, "episode/length": 288.0, "episode/score": 0.05006855818567146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05006855818567146}
{"step": 95048, "time": 3267.0855255126953, "episode/length": 288.0, "episode/score": 0.04988958570936575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04988958570936575}
{"step": 95960, "time": 3295.8160378932953, "episode/length": 288.0, "episode/score": 0.06352403156472519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06352403156472519}
{"step": 96296, "time": 3306.3794808387756, "episode/length": 288.0, "episode/score": 0.07612117760504589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07612117760504589}
{"step": 96504, "time": 3312.9564690589905, "episode/length": 288.0, "episode/score": 0.04971215072339419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04971215072339419}
{"step": 96984, "time": 3328.209344148636, "episode/length": 288.0, "episode/score": 0.05290103535980961, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05290103535980961}
{"step": 97104, "time": 3332.2409274578094, "episode/length": 288.0, "episode/score": 0.06528899887950956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06528899887950956}
{"step": 97184, "time": 3334.7506330013275, "episode/length": 288.0, "episode/score": 0.059458842063122574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059458842063122574}
{"step": 97192, "time": 3334.78862118721, "episode/length": 288.0, "episode/score": 0.07077940080421286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07077940080421286}
{"step": 97360, "time": 3340.2941913604736, "episode/length": 288.0, "episode/score": 0.08424066316922563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08424066316922563}
{"step": 98272, "time": 3369.1347181797028, "episode/length": 288.0, "episode/score": 0.07756591132181256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07756591132181256}
{"step": 98608, "time": 3380.2435386180878, "episode/length": 288.0, "episode/score": 0.08822232160548538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08822232160548538}
{"step": 98816, "time": 3386.9371552467346, "episode/length": 288.0, "episode/score": 0.07535250437013019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07535250437013019}
{"step": 98848, "time": 3387.9696204662323, "episode/length": 232.0, "episode/score": 0.32810483185846806, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0531048270621568}
{"step": 99416, "time": 3405.6991064548492, "episode/length": 288.0, "episode/score": 0.09241153217368492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09241153217368492}
{"step": 99496, "time": 3408.2291131019592, "episode/length": 288.0, "episode/score": 0.07614851091074115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07614851091074115}
{"step": 99504, "time": 3408.708657979965, "episode/length": 288.0, "episode/score": 0.07601432980050049, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07601432980050049}
{"step": 99672, "time": 3413.867935657501, "episode/length": 288.0, "episode/score": 0.07981037497967236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07981037497967236}
{"step": 100048, "time": 3431.526247739792, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3431.542112350464, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3431.557149887085, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3431.5738065242767, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3431.5886042118073, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3431.606294631958, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3431.6243290901184, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3431.6401464939117, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100584, "time": 3448.560849905014, "episode/length": 288.0, "episode/score": 0.06583276757754675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06583276757754675}
{"step": 100920, "time": 3459.1697537899017, "episode/length": 288.0, "episode/score": 0.06578569128799927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06578569128799927}
{"step": 101128, "time": 3465.697943210602, "episode/length": 288.0, "episode/score": 0.08852748138883726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08852748138883726}
{"step": 101160, "time": 3466.70974111557, "episode/length": 288.0, "episode/score": 0.07771000381410431, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07771000381410431}
{"step": 101728, "time": 3484.927186489105, "episode/length": 288.0, "episode/score": 0.03943684266812397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03943684266812397}
{"step": 101808, "time": 3487.4483513832092, "episode/length": 288.0, "episode/score": 0.08288342032312812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08288342032312812}
{"step": 101816, "time": 3487.4854388237, "episode/length": 288.0, "episode/score": 0.05513924808514048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05513924808514048}
{"step": 101984, "time": 3493.0108921527863, "episode/length": 288.0, "episode/score": 0.07395834211069996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07395834211069996}
{"step": 102896, "time": 3521.948589324951, "episode/length": 288.0, "episode/score": 0.05461462197331457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05461462197331457}
{"step": 103232, "time": 3532.6791405677795, "episode/length": 288.0, "episode/score": 0.0755455566834371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0755455566834371}
{"step": 103440, "time": 3539.2422518730164, "episode/length": 288.0, "episode/score": 0.07996109905263893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07996109905263893}
{"step": 103472, "time": 3540.272110939026, "episode/length": 288.0, "episode/score": 0.07676868494149858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07676868494149858}
{"step": 104040, "time": 3557.907892227173, "episode/length": 288.0, "episode/score": 0.07411675548360108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07411675548360108}
{"step": 104120, "time": 3560.4496009349823, "episode/length": 288.0, "episode/score": 0.06879605627102592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06879605627102592}
{"step": 104128, "time": 3561.0253913402557, "episode/length": 288.0, "episode/score": 0.0708011049335937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0708011049335937}
{"step": 104296, "time": 3566.124767780304, "episode/length": 288.0, "episode/score": 0.07029938157199922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07029938157199922}
{"step": 104384, "time": 3569.1214044094086, "episode/length": 42.0, "episode/score": 0.8871883062457755, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.018438301449464234}
{"step": 105208, "time": 3595.0952458381653, "episode/length": 288.0, "episode/score": 0.055803464623693344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055803464623693344}
{"step": 105544, "time": 3605.819335460663, "episode/length": 288.0, "episode/score": 0.0548163595711344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0548163595711344}
{"step": 105752, "time": 3612.3372349739075, "episode/length": 288.0, "episode/score": 0.09403160472641048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09403160472641048}
{"step": 105784, "time": 3613.3435587882996, "episode/length": 288.0, "episode/score": 0.045516212851396176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045516212851396176}
{"step": 106320, "time": 3630.490987062454, "episode/length": 70.0, "episode/score": 0.8084464302044694, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.02719640156630021}
{"step": 106432, "time": 3634.0130269527435, "episode/length": 288.0, "episode/score": 0.0287068123593599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0287068123593599}
{"step": 106440, "time": 3634.052899837494, "episode/length": 288.0, "episode/score": 0.062157567673637004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062157567673637004}
{"step": 106608, "time": 3640.1039967536926, "episode/length": 288.0, "episode/score": 0.06160451083223961, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06160451083223961}
{"step": 106696, "time": 3642.6509051322937, "episode/length": 288.0, "episode/score": 0.06212316303157195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06212316303157195}
{"step": 107408, "time": 3665.2779734134674, "episode/length": 274.0, "episode/score": 0.2143223265558163, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.07057233070020175}
{"step": 107856, "time": 3679.3975455760956, "episode/length": 288.0, "episode/score": 0.06405734483189462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06405734483189462}
{"step": 108096, "time": 3687.072265625, "episode/length": 288.0, "episode/score": 0.05974989254997354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05974989254997354}
{"step": 108632, "time": 3703.84552526474, "episode/length": 288.0, "episode/score": 0.08117041269696301, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08117041269696301}
{"step": 108744, "time": 3707.4021611213684, "episode/length": 288.0, "episode/score": 0.044087027675914214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044087027675914214}
{"step": 108752, "time": 3707.902912378311, "episode/length": 288.0, "episode/score": 0.056450424799777466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056450424799777466}
{"step": 108920, "time": 3713.114243745804, "episode/length": 288.0, "episode/score": 0.06941121908522518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06941121908522518}
{"step": 109008, "time": 3716.1121804714203, "episode/length": 288.0, "episode/score": 0.062190161780847575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062190161780847575}
{"step": 109720, "time": 3738.3255109786987, "episode/length": 288.0, "episode/score": 0.07943179779556431, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07943179779556431}
{"step": 110032, "time": 3749.8120160102844, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 110032, "time": 3750.1405942440033, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 110032, "time": 3754.0852880477905, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3754.099102497101, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3754.1107494831085, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3754.125041246414, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3754.1357305049896, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3754.1454784870148, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110168, "time": 3758.1783096790314, "episode/length": 288.0, "episode/score": 0.077242916353498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.077242916353498}
{"step": 110408, "time": 3765.726530790329, "episode/length": 288.0, "episode/score": 0.04483859228025722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04483859228025722}
{"step": 110944, "time": 3782.933793783188, "episode/length": 288.0, "episode/score": 0.06363340009409058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06363340009409058}
{"step": 111056, "time": 3786.464099884033, "episode/length": 288.0, "episode/score": 0.04594488582677059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04594488582677059}
{"step": 111064, "time": 3786.5017681121826, "episode/length": 288.0, "episode/score": 0.05274456207473577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05274456207473577}
{"step": 111232, "time": 3791.9857218265533, "episode/length": 288.0, "episode/score": 0.08483449404195653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08483449404195653}
{"step": 111320, "time": 3794.5377793312073, "episode/length": 288.0, "episode/score": 0.06165088248127404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06165088248127404}
{"step": 112032, "time": 3817.363737821579, "episode/length": 288.0, "episode/score": 0.03581572790756127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03581572790756127}
{"step": 112480, "time": 3831.729887485504, "episode/length": 288.0, "episode/score": 0.06478999246843387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06478999246843387}
{"step": 112720, "time": 3839.328467130661, "episode/length": 288.0, "episode/score": 0.0450705476348503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0450705476348503}
{"step": 113256, "time": 3856.068515777588, "episode/length": 288.0, "episode/score": 0.056618268388263004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056618268388263004}
{"step": 113368, "time": 3859.583987236023, "episode/length": 288.0, "episode/score": 0.05548602273239567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05548602273239567}
{"step": 113376, "time": 3860.0599541664124, "episode/length": 288.0, "episode/score": 0.0627962808428606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0627962808428606}
{"step": 113544, "time": 3865.204094648361, "episode/length": 288.0, "episode/score": 0.05384876821386797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05384876821386797}
{"step": 113632, "time": 3868.2013845443726, "episode/length": 288.0, "episode/score": 0.058084993847614896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058084993847614896}
{"step": 114344, "time": 3890.451199531555, "episode/length": 288.0, "episode/score": 0.054940805116132196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054940805116132196}
{"step": 114792, "time": 3905.1557619571686, "episode/length": 288.0, "episode/score": 0.039756320252763544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039756320252763544}
{"step": 115032, "time": 3912.704384803772, "episode/length": 288.0, "episode/score": 0.06537339491785588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06537339491785588}
{"step": 115568, "time": 3929.859565973282, "episode/length": 288.0, "episode/score": 0.05502319397157862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05502319397157862}
{"step": 115680, "time": 3933.3997831344604, "episode/length": 288.0, "episode/score": 0.09981430513573741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09981430513573741}
{"step": 115688, "time": 3933.437722682953, "episode/length": 288.0, "episode/score": 0.07499510406455556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07499510406455556}
{"step": 115856, "time": 3938.9624392986298, "episode/length": 288.0, "episode/score": 0.046630831415427565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046630831415427565}
{"step": 115944, "time": 3941.5154962539673, "episode/length": 288.0, "episode/score": 0.06642036174196164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06642036174196164}
{"step": 116656, "time": 3964.2338926792145, "episode/length": 288.0, "episode/score": 0.049216832859031, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049216832859031}
{"step": 117104, "time": 3978.439004421234, "episode/length": 288.0, "episode/score": 0.06533690923782842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06533690923782842}
{"step": 117344, "time": 3986.1383893489838, "episode/length": 288.0, "episode/score": 0.059224614444133294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059224614444133294}
{"step": 117880, "time": 4002.79576086998, "episode/length": 288.0, "episode/score": 0.07292474935718474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07292474935718474}
{"step": 117992, "time": 4006.317799091339, "episode/length": 288.0, "episode/score": 0.05228108436159573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05228108436159573}
{"step": 118000, "time": 4006.7965219020844, "episode/length": 288.0, "episode/score": 0.07085754932046484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07085754932046484}
{"step": 118168, "time": 4011.9805483818054, "episode/length": 288.0, "episode/score": 0.06510546061690548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06510546061690548}
{"step": 118256, "time": 4014.9658205509186, "episode/length": 288.0, "episode/score": 0.07264744975617532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07264744975617532}
{"step": 118968, "time": 4037.089065551758, "episode/length": 288.0, "episode/score": 0.07408272033887897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07408272033887897}
{"step": 119416, "time": 4051.279716491699, "episode/length": 288.0, "episode/score": 0.09075283386368937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09075283386368937}
{"step": 119656, "time": 4058.813583135605, "episode/length": 288.0, "episode/score": 0.056175386129098115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056175386129098115}
{"step": 120016, "time": 4075.676326274872, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4075.693363904953, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4075.710931301117, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4075.7369639873505, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4075.7613196372986, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4075.7873227596283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4075.8044312000275, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4075.820874929428, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120192, "time": 4081.3718280792236, "episode/length": 288.0, "episode/score": 0.05972012103961788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05972012103961788}
{"step": 120304, "time": 4084.9085881710052, "episode/length": 288.0, "episode/score": 0.05661417453723061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05661417453723061}
{"step": 120312, "time": 4084.9478907585144, "episode/length": 288.0, "episode/score": 0.055512839841298955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055512839841298955}
{"step": 120480, "time": 4090.415657520294, "episode/length": 288.0, "episode/score": 0.05645890509651963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05645890509651963}
{"step": 120568, "time": 4092.950091600418, "episode/length": 288.0, "episode/score": 0.05884068211662452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05884068211662452}
{"step": 121280, "time": 4115.6268746852875, "episode/length": 288.0, "episode/score": 0.04301936296394615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04301936296394615}
{"step": 121728, "time": 4129.711713314056, "episode/length": 288.0, "episode/score": 0.027687566721169787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027687566721169787}
{"step": 121968, "time": 4137.3444402217865, "episode/length": 288.0, "episode/score": 0.0451519118454371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0451519118454371}
{"step": 122504, "time": 4154.028262138367, "episode/length": 288.0, "episode/score": 0.07405587288178594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07405587288178594}
{"step": 122616, "time": 4157.621322154999, "episode/length": 288.0, "episode/score": 0.02477711141045802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02477711141045802}
{"step": 122624, "time": 4158.1112360954285, "episode/length": 288.0, "episode/score": 0.06546360108296767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06546360108296767}
{"step": 122792, "time": 4163.379474163055, "episode/length": 288.0, "episode/score": 0.054603956552682575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054603956552682575}
{"step": 122880, "time": 4166.573227405548, "episode/length": 288.0, "episode/score": 0.04438392228257726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04438392228257726}
{"step": 123592, "time": 4189.204741001129, "episode/length": 288.0, "episode/score": 0.05510962189987367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05510962189987367}
{"step": 124040, "time": 4203.466628313065, "episode/length": 288.0, "episode/score": 0.077198457479426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.077198457479426}
{"step": 124089, "time": 4205.979248046875, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.999456059747409, "train/action_min": 0.0, "train/action_std": 2.0001402043308003, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00011682686431531269, "train/actor_opt_grad_steps": 6690.0, "train/actor_opt_loss": -0.8072237273572023, "train/adv_mag": 0.0005258554930514005, "train/adv_max": 0.0005256205488363079, "train/adv_mean": 0.0002559580559555925, "train/adv_min": -6.718879536643547e-05, "train/adv_std": 0.00012842889948988723, "train/cont_avg": 0.9963315657383419, "train/cont_loss_mean": 0.024295624495131674, "train/cont_loss_std": 0.33242529198778265, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.673809298670105, "train/cont_pos_acc": 0.9999999811612262, "train/cont_pos_loss": 0.003488130702207666, "train/cont_pred": 0.9965180915254386, "train/cont_rate": 0.9963315657383419, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02538433524664163, "train/extr_critic_critic_opt_grad_steps": 6690.0, "train/extr_critic_critic_opt_loss": 13332.893149894753, "train/extr_critic_mag": 0.07043146654731869, "train/extr_critic_max": 0.07043146654731869, "train/extr_critic_mean": 0.07030701421085417, "train/extr_critic_min": 0.07023266374756018, "train/extr_critic_std": 2.6155268719209305e-05, "train/extr_return_normed_mag": 0.0009378050815873813, "train/extr_return_normed_max": 0.0009375592124276828, "train/extr_return_normed_mean": 0.0007311265477642219, "train/extr_return_normed_min": 0.00045886647361547837, "train/extr_return_normed_std": 0.00012328325894034233, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.07076940322632616, "train/extr_return_raw_max": 0.07076940322632616, "train/extr_return_raw_mean": 0.07056297408175592, "train/extr_return_raw_min": 0.07029071048751397, "train/extr_return_raw_std": 0.0001232832586104738, "train/extr_reward_mag": 0.0002518972584620659, "train/extr_reward_max": 0.0002518972584620659, "train/extr_reward_mean": 0.00025171026883953265, "train/extr_reward_min": 0.0002515297479580103, "train/extr_reward_std": 9.18026268458059e-08, "train/image_loss_mean": 0.2584841845103496, "train/image_loss_std": 0.08414868647570437, "train/model_loss_mean": 0.8939598916108127, "train/model_loss_std": 0.37327127606448735, "train/model_opt_grad_norm": 60.952077440647265, "train/model_opt_grad_steps": 6680.0, "train/model_opt_loss": 701.8062478495385, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 785.2979274611399, "train/policy_entropy_mag": 1.9459014111849928, "train/policy_entropy_max": 1.9459014111849928, "train/policy_entropy_mean": 1.945457511615259, "train/policy_entropy_min": 1.9356878989718738, "train/policy_entropy_std": 0.0003442544041628529, "train/policy_logprob_mag": 2.1195941008434396, "train/policy_logprob_max": -1.764462498803213, "train/policy_logprob_mean": -1.9454169643975292, "train/policy_logprob_min": -2.1195941008434396, "train/policy_logprob_std": 0.030054191967057442, "train/policy_randomness_mag": 0.9999955673291894, "train/policy_randomness_max": 0.9999955673291894, "train/policy_randomness_mean": 0.9997674464561779, "train/policy_randomness_min": 0.9947468589006928, "train/policy_randomness_std": 0.0001769117751476051, "train/post_ent_mag": 40.36186657050731, "train/post_ent_max": 40.36186657050731, "train/post_ent_mean": 40.32706763707294, "train/post_ent_min": 40.10892668412757, "train/post_ent_std": 0.05168986130370686, "train/prior_ent_mag": 43.97733324673509, "train/prior_ent_max": 43.97733324673509, "train/prior_ent_mean": 43.931536264370145, "train/prior_ent_min": 43.87822936853597, "train/prior_ent_std": 0.012244843366348374, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00026549706208384524, "train/reward_loss_mean": 0.011180061837320501, "train/reward_loss_std": 0.05298237460593022, "train/reward_max_data": 0.06484024219306601, "train/reward_max_pred": 0.00025186019857930395, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00994017663764058, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.111151530192448, "train/reward_pred": 0.00025160044945602745, "train/reward_rate": 0.0001366175518134715, "train_stats/mean_log_entropy": 1.9381740545784985, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0311957485973835, "report/cont_loss_std": 0.3983606994152069, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.718134880065918, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032912427559494972, "report/cont_pred": 0.9967143535614014, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.26888900995254517, "report/image_loss_std": 0.07975941151380539, "report/model_loss_mean": 0.9111721515655518, "report/model_loss_std": 0.4099278450012207, "report/post_ent_mag": 41.7393798828125, "report/post_ent_max": 41.7393798828125, "report/post_ent_mean": 41.68389892578125, "report/post_ent_min": 41.220458984375, "report/post_ent_std": 0.10374376177787781, "report/prior_ent_mag": 44.07083511352539, "report/prior_ent_max": 44.07083511352539, "report/prior_ent_mean": 44.03386306762695, "report/prior_ent_min": 43.95623016357422, "report/prior_ent_std": 0.013644617050886154, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00023001310182735324, "report/reward_loss_mean": 0.011087371036410332, "report/reward_loss_std": 0.01712619699537754, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00027358531951904297, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.011087371036410332, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00027358531951904297, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0032912427559494972, "eval/cont_loss_std": 6.984919309616089e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0032912427559494972, "eval/cont_pred": 0.9967143535614014, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26260071992874146, "eval/image_loss_std": 0.07536786049604416, "eval/model_loss_mean": 0.8674684166908264, "eval/model_loss_std": 0.07536786049604416, "eval/post_ent_mag": 41.73751449584961, "eval/post_ent_max": 41.73751449584961, "eval/post_ent_mean": 41.693450927734375, "eval/post_ent_min": 41.22425079345703, "eval/post_ent_std": 0.09180528670549393, "eval/prior_ent_mag": 44.07083511352539, "eval/prior_ent_max": 44.07083511352539, "eval/prior_ent_mean": 44.033355712890625, "eval/prior_ent_min": 43.96384811401367, "eval/prior_ent_std": 0.012480804696679115, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0015764236450195312, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00027358531951904297, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015764236450195312, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00027358531951904297, "eval/reward_rate": 0.0, "replay/size": 123585.0, "replay/inserts": 30984.0, "replay/samples": 30992.0, "replay/insert_wait_avg": 1.3367261130650346e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.945313464013583e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1663123398091142e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4169549942017, "timer/env.step_count": 3873.0, "timer/env.step_total": 37.34533452987671, "timer/env.step_frac": 0.03732976969596958, "timer/env.step_avg": 0.009642482450265093, "timer/env.step_min": 0.008008241653442383, "timer/env.step_max": 0.03858447074890137, "timer/replay._sample_count": 30992.0, "timer/replay._sample_total": 16.326187133789062, "timer/replay._sample_frac": 0.01631938268567598, "timer/replay._sample_avg": 0.0005267871429333074, "timer/replay._sample_min": 0.0003707408905029297, "timer/replay._sample_max": 0.011304855346679688, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4740.0, "timer/agent.policy_total": 48.316235065460205, "timer/agent.policy_frac": 0.0482960977662961, "timer/agent.policy_avg": 0.01019329853701692, "timer/agent.policy_min": 0.008877277374267578, "timer/agent.policy_max": 0.08390235900878906, "timer/dataset_train_count": 1937.0, "timer/dataset_train_total": 0.22043609619140625, "timer/dataset_train_frac": 0.0002203442225673633, "timer/dataset_train_avg": 0.00011380283747620353, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0010712146759033203, "timer/agent.train_count": 1937.0, "timer/agent.train_total": 865.104341506958, "timer/agent.train_frac": 0.8647437822682364, "timer/agent.train_avg": 0.44662072354515125, "timer/agent.train_min": 0.43644142150878906, "timer/agent.train_max": 0.6066498756408691, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46805357933044434, "timer/agent.report_frac": 0.0004678585033908758, "timer/agent.report_avg": 0.23402678966522217, "timer/agent.report_min": 0.223724365234375, "timer/agent.report_max": 0.24432921409606934, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.312637028958517e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 30.970505967817882}
{"step": 124280, "time": 4211.786422014236, "episode/length": 288.0, "episode/score": 0.07764195430638665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07764195430638665}
{"step": 124816, "time": 4228.97287106514, "episode/length": 288.0, "episode/score": 0.07195826576617037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07195826576617037}
{"step": 124928, "time": 4232.493770360947, "episode/length": 288.0, "episode/score": 0.053175994735283894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053175994735283894}
{"step": 124936, "time": 4232.531309127808, "episode/length": 288.0, "episode/score": 0.05061404573893924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05061404573893924}
{"step": 125104, "time": 4238.007432222366, "episode/length": 288.0, "episode/score": 0.06160631999125599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06160631999125599}
{"step": 125192, "time": 4240.540733337402, "episode/length": 288.0, "episode/score": 0.05039879663820557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05039879663820557}
{"step": 125904, "time": 4263.245712757111, "episode/length": 288.0, "episode/score": 0.061339927005406025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061339927005406025}
{"step": 126328, "time": 4276.5239934921265, "episode/length": 141.0, "episode/score": 0.5882592952805226, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.02888427856328235}
{"step": 126352, "time": 4277.528690338135, "episode/length": 288.0, "episode/score": 0.03446828628989351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03446828628989351}
{"step": 126592, "time": 4285.211416959763, "episode/length": 288.0, "episode/score": 0.07415680123938273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07415680123938273}
{"step": 127128, "time": 4301.850068092346, "episode/length": 288.0, "episode/score": 0.048861652721541304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048861652721541304}
{"step": 127240, "time": 4305.382835626602, "episode/length": 288.0, "episode/score": 0.052697380886002065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052697380886002065}
{"step": 127248, "time": 4305.864154100418, "episode/length": 288.0, "episode/score": 0.046604067899238544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046604067899238544}
{"step": 127416, "time": 4310.982784986496, "episode/length": 288.0, "episode/score": 0.0754595843233119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0754595843233119}
{"step": 128216, "time": 4336.166090250015, "episode/length": 288.0, "episode/score": 0.06596156671639619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06596156671639619}
{"step": 128640, "time": 4349.845991611481, "episode/length": 288.0, "episode/score": 0.060113271841032656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060113271841032656}
{"step": 128664, "time": 4350.389117479324, "episode/length": 288.0, "episode/score": 0.03507614157064154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03507614157064154}
{"step": 128904, "time": 4357.979769706726, "episode/length": 288.0, "episode/score": 0.06091816071887024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06091816071887024}
{"step": 129440, "time": 4375.220437526703, "episode/length": 288.0, "episode/score": 0.047198962288405255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047198962288405255}
{"step": 129552, "time": 4378.829602718353, "episode/length": 288.0, "episode/score": 0.030041924218835447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030041924218835447}
{"step": 129560, "time": 4378.87069940567, "episode/length": 288.0, "episode/score": 0.06207230690114329, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06207230690114329}
{"step": 129728, "time": 4384.429762601852, "episode/length": 288.0, "episode/score": 0.05194391697756373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05194391697756373}
{"step": 130000, "time": 4395.656423807144, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 130000, "time": 4398.900744438171, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4398.912878751755, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4398.937069654465, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4398.953320503235, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4398.968319892883, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4398.9831800460815, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4398.997181177139, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130520, "time": 4415.28000664711, "episode/length": 119.0, "episode/score": 0.656421883351868, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.028296842792769894}
{"step": 130528, "time": 4415.770826816559, "episode/length": 288.0, "episode/score": 0.053712802672748694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053712802672748694}
{"step": 130952, "time": 4428.94664812088, "episode/length": 288.0, "episode/score": 0.0519638226742245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0519638226742245}
{"step": 130976, "time": 4429.930588960648, "episode/length": 288.0, "episode/score": 0.08037315176954962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08037315176954962}
{"step": 131216, "time": 4438.1709525585175, "episode/length": 288.0, "episode/score": 0.043492676041807954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043492676041807954}
{"step": 131624, "time": 4450.835894107819, "episode/length": 136.0, "episode/score": 0.5976480109945328, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.022647994277292582}
{"step": 131752, "time": 4454.895838260651, "episode/length": 288.0, "episode/score": 0.030336404363310976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030336404363310976}
{"step": 131864, "time": 4458.4496331214905, "episode/length": 288.0, "episode/score": 0.05394587241721638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05394587241721638}
{"step": 132040, "time": 4464.813875436783, "episode/length": 288.0, "episode/score": 0.052338691618274424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052338691618274424}
{"step": 132832, "time": 4490.030675649643, "episode/length": 288.0, "episode/score": 0.042885583573252006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042885583573252006}
{"step": 133264, "time": 4503.71880531311, "episode/length": 288.0, "episode/score": 0.07042867606264736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07042867606264736}
{"step": 133288, "time": 4504.257488250732, "episode/length": 288.0, "episode/score": 0.07427934340375941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07427934340375941}
{"step": 133528, "time": 4511.7758939266205, "episode/length": 288.0, "episode/score": 0.0715192490098957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0715192490098957}
{"step": 133936, "time": 4524.903388500214, "episode/length": 288.0, "episode/score": 0.04304164187345805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04304164187345805}
{"step": 134064, "time": 4528.907702922821, "episode/length": 288.0, "episode/score": 0.06328769130112732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06328769130112732}
{"step": 134176, "time": 4532.428097009659, "episode/length": 288.0, "episode/score": 0.08951883048916898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08951883048916898}
{"step": 134352, "time": 4538.000179052353, "episode/length": 288.0, "episode/score": 0.06204169758518674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06204169758518674}
{"step": 135144, "time": 4562.816777944565, "episode/length": 288.0, "episode/score": 0.078983999962702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.078983999962702}
{"step": 135576, "time": 4576.559885025024, "episode/length": 288.0, "episode/score": 0.07475972436452594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07475972436452594}
{"step": 135600, "time": 4577.5465223789215, "episode/length": 288.0, "episode/score": 0.07017828792982073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07017828792982073}
{"step": 135840, "time": 4585.28697347641, "episode/length": 288.0, "episode/score": 0.06424675807272706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06424675807272706}
{"step": 136248, "time": 4597.862283229828, "episode/length": 288.0, "episode/score": 0.06687818882016927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06687818882016927}
{"step": 136376, "time": 4601.901890039444, "episode/length": 288.0, "episode/score": 0.07018726511705609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07018726511705609}
{"step": 136488, "time": 4605.495059728622, "episode/length": 288.0, "episode/score": 0.03897889982687275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03897889982687275}
{"step": 136664, "time": 4611.201822280884, "episode/length": 288.0, "episode/score": 0.049718115216762726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049718115216762726}
{"step": 137456, "time": 4636.297732114792, "episode/length": 288.0, "episode/score": 0.04042951315489063, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04042951315489063}
{"step": 137888, "time": 4650.078013658524, "episode/length": 288.0, "episode/score": 0.07708645894967958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07708645894967958}
{"step": 137896, "time": 4650.117374181747, "episode/length": 286.0, "episode/score": 0.16636178697012838, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.06011178515404936}
{"step": 138152, "time": 4658.263572692871, "episode/length": 288.0, "episode/score": 0.05693872236435027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05693872236435027}
{"step": 138384, "time": 4665.859209537506, "episode/length": 115.0, "episode/score": 0.6621166786379149, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.021491649999745732}
{"step": 138560, "time": 4671.509070634842, "episode/length": 288.0, "episode/score": 0.04927154291459601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04927154291459601}
{"step": 138688, "time": 4675.620730161667, "episode/length": 288.0, "episode/score": 0.073081255905322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.073081255905322}
{"step": 138800, "time": 4679.196856975555, "episode/length": 288.0, "episode/score": 0.05619217223568285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05619217223568285}
{"step": 138976, "time": 4684.762341737747, "episode/length": 288.0, "episode/score": 0.05467244655972081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05467244655972081}
{"step": 140088, "time": 4722.54106926918, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 140088, "time": 4725.790911197662, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4725.800954341888, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4725.810936689377, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4725.8270263671875, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4725.8385264873505, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4725.847275018692, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4725.862221240997, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140200, "time": 4729.404237747192, "episode/length": 288.0, "episode/score": 0.043453707274409226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043453707274409226}
{"step": 140208, "time": 4729.8866674900055, "episode/length": 288.0, "episode/score": 0.06448557907458508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06448557907458508}
{"step": 140464, "time": 4738.033753871918, "episode/length": 288.0, "episode/score": 0.057892843254876425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057892843254876425}
{"step": 140696, "time": 4745.1249804496765, "episode/length": 288.0, "episode/score": 0.06637945803669254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06637945803669254}
{"step": 140872, "time": 4750.664391517639, "episode/length": 288.0, "episode/score": 0.055797125087451604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055797125087451604}
{"step": 141000, "time": 4754.70876789093, "episode/length": 288.0, "episode/score": 0.04711359241548507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04711359241548507}
{"step": 141112, "time": 4758.285411834717, "episode/length": 288.0, "episode/score": 0.07285872007651051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07285872007651051}
{"step": 141288, "time": 4764.0425889492035, "episode/length": 288.0, "episode/score": 0.0424848612476012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0424848612476012}
{"step": 142512, "time": 4802.810235977173, "episode/length": 288.0, "episode/score": 0.07183604708427538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07183604708427538}
{"step": 142520, "time": 4802.85026216507, "episode/length": 288.0, "episode/score": 0.0715063464343757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0715063464343757}
{"step": 142776, "time": 4810.905834674835, "episode/length": 288.0, "episode/score": 0.09136195375367606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09136195375367606}
{"step": 143008, "time": 4818.494559288025, "episode/length": 288.0, "episode/score": 0.07088160769231422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07088160769231422}
{"step": 143184, "time": 4824.229470729828, "episode/length": 288.0, "episode/score": 0.052750848661247574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052750848661247574}
{"step": 143312, "time": 4828.290770769119, "episode/length": 288.0, "episode/score": 0.07814308876268683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07814308876268683}
{"step": 143424, "time": 4831.818053245544, "episode/length": 288.0, "episode/score": 0.058562005023304664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058562005023304664}
{"step": 143600, "time": 4837.376847028732, "episode/length": 288.0, "episode/score": 0.07915026077964171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07915026077964171}
{"step": 144824, "time": 4875.810955524445, "episode/length": 288.0, "episode/score": 0.04547842080847886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04547842080847886}
{"step": 144832, "time": 4876.291809797287, "episode/length": 288.0, "episode/score": 0.048943363508072935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048943363508072935}
{"step": 145088, "time": 4884.509313106537, "episode/length": 288.0, "episode/score": 0.0655324111807829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0655324111807829}
{"step": 145320, "time": 4891.633381605148, "episode/length": 288.0, "episode/score": 0.045156550209469515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045156550209469515}
{"step": 145496, "time": 4897.231978416443, "episode/length": 288.0, "episode/score": 0.058353939498772434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058353939498772434}
{"step": 145624, "time": 4901.303015470505, "episode/length": 288.0, "episode/score": 0.03901564196991103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03901564196991103}
{"step": 145736, "time": 4904.833813667297, "episode/length": 288.0, "episode/score": 0.06546759890352405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06546759890352405}
{"step": 145912, "time": 4910.419767141342, "episode/length": 288.0, "episode/score": 0.073671367565737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.073671367565737}
{"step": 146832, "time": 4939.821751117706, "episode/length": 250.0, "episode/score": 0.2685831780264323, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.04983317884133953}
{"step": 147144, "time": 4949.6410121917725, "episode/length": 288.0, "episode/score": 0.059927314295293854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059927314295293854}
{"step": 147400, "time": 4957.860900640488, "episode/length": 288.0, "episode/score": 0.07142840136489781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07142840136489781}
{"step": 147632, "time": 4965.993395090103, "episode/length": 288.0, "episode/score": 0.05058554258084769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05058554258084769}
{"step": 147808, "time": 4971.707206249237, "episode/length": 288.0, "episode/score": 0.050655984933285936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050655984933285936}
{"step": 147936, "time": 4975.762858629227, "episode/length": 288.0, "episode/score": 0.056702068407446404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056702068407446404}
{"step": 148048, "time": 4979.32204246521, "episode/length": 288.0, "episode/score": 0.060753009870950336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060753009870950336}
{"step": 148224, "time": 4984.8939752578735, "episode/length": 288.0, "episode/score": 0.05528917206768824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05528917206768824}
{"step": 149144, "time": 5013.841974020004, "episode/length": 288.0, "episode/score": 0.057833001857858335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057833001857858335}
{"step": 149456, "time": 5023.912571191788, "episode/length": 288.0, "episode/score": 0.06141066161333697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06141066161333697}
{"step": 149712, "time": 5032.162637710571, "episode/length": 288.0, "episode/score": 0.04529336449242294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04529336449242294}
{"step": 149944, "time": 5039.265266418457, "episode/length": 288.0, "episode/score": 0.0400470432638258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0400470432638258}
{"step": 150072, "time": 5048.845119476318, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5048.859463691711, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5048.877305269241, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5048.890583515167, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5048.900513887405, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5048.90953373909, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5048.9192943573, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5048.9322102069855, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150120, "time": 5050.443572282791, "episode/length": 288.0, "episode/score": 0.05031063734503505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05031063734503505}
{"step": 150248, "time": 5054.489376544952, "episode/length": 288.0, "episode/score": 0.06171167789847232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06171167789847232}
{"step": 150360, "time": 5058.035381793976, "episode/length": 288.0, "episode/score": 0.09212856028511851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09212856028511851}
{"step": 150536, "time": 5063.701896429062, "episode/length": 288.0, "episode/score": 0.06629975099616559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06629975099616559}
{"step": 151456, "time": 5093.045550823212, "episode/length": 288.0, "episode/score": 0.05072270937932899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05072270937932899}
{"step": 151768, "time": 5102.643250465393, "episode/length": 288.0, "episode/score": 0.0766536870021639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0766536870021639}
{"step": 152024, "time": 5110.707837343216, "episode/length": 288.0, "episode/score": 0.053769423090145096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053769423090145096}
{"step": 152256, "time": 5118.221417665482, "episode/length": 288.0, "episode/score": 0.042471984584594225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042471984584594225}
{"step": 152432, "time": 5123.9561223983765, "episode/length": 288.0, "episode/score": 0.04881672778320478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04881672778320478}
{"step": 152560, "time": 5127.967694044113, "episode/length": 288.0, "episode/score": 0.07898850667147883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07898850667147883}
{"step": 152672, "time": 5131.495148658752, "episode/length": 288.0, "episode/score": 0.02850443696104321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02850443696104321}
{"step": 152848, "time": 5137.012146234512, "episode/length": 288.0, "episode/score": 0.04992053928805262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04992053928805262}
{"step": 153312, "time": 5151.610348939896, "episode/length": 109.0, "episode/score": 0.6789981922441797, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.019623181138157975}
{"step": 153768, "time": 5165.81032204628, "episode/length": 288.0, "episode/score": 0.05143079921923288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05143079921923288}
{"step": 154080, "time": 5175.825325965881, "episode/length": 288.0, "episode/score": 0.07179310849008402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07179310849008402}
{"step": 154336, "time": 5183.947254180908, "episode/length": 288.0, "episode/score": 0.06762010519057071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06762010519057071}
{"step": 154568, "time": 5191.015469312668, "episode/length": 288.0, "episode/score": 0.06673854267367574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06673854267367574}
{"step": 154872, "time": 5200.580453157425, "episode/length": 288.0, "episode/score": 0.028315962807027972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028315962807027972}
{"step": 154984, "time": 5204.107656240463, "episode/length": 288.0, "episode/score": 0.05248997724125104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05248997724125104}
{"step": 155017, "time": 5206.137539148331, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9973226330943943, "train/action_min": 0.0, "train/action_std": 1.9994670822448337, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 9.465773140637447e-05, "train/actor_opt_grad_steps": 8625.0, "train/actor_opt_loss": -2.036274988089026, "train/adv_mag": 0.0004746932728388875, "train/adv_max": 0.00047032285443286307, "train/adv_mean": 0.00019161072409072395, "train/adv_min": -0.00010615633320562618, "train/adv_std": 0.00010654262373885937, "train/cont_avg": 0.9967028431056701, "train/cont_loss_mean": 0.02216746181624068, "train/cont_loss_std": 0.3151158029909639, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.673133252198214, "train/cont_pos_acc": 0.999999985252459, "train/cont_pos_loss": 0.0034696249754561743, "train/cont_pred": 0.9965364825479763, "train/cont_rate": 0.9967028431056701, "train/dyn_loss_mean": 1.0006610695848759, "train/dyn_loss_std": 4.392700058590506e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.021249818481197676, "train/extr_critic_critic_opt_grad_steps": 8625.0, "train/extr_critic_critic_opt_loss": 13509.374682868878, "train/extr_critic_mag": 0.07871692512453217, "train/extr_critic_max": 0.07871692512453217, "train/extr_critic_mean": 0.07859729706626578, "train/extr_critic_min": 0.07848392811018168, "train/extr_critic_std": 3.0506067221923922e-05, "train/extr_return_normed_mag": 0.0007387346674486534, "train/extr_return_normed_max": 0.0007370279468211931, "train/extr_return_normed_mean": 0.0005622918932147644, "train/extr_return_normed_min": 0.0003387108061116995, "train/extr_return_normed_std": 9.750102989312733e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.07896360605187022, "train/extr_return_raw_max": 0.07896360605187022, "train/extr_return_raw_mean": 0.07878887338429383, "train/extr_return_raw_min": 0.07856528891116074, "train/extr_return_raw_std": 9.750103019082276e-05, "train/extr_reward_mag": 0.0002665507424737989, "train/extr_reward_max": 0.0002665507424737989, "train/extr_reward_mean": 0.0002663481325576005, "train/extr_reward_min": 0.0002661925001242726, "train/extr_reward_std": 8.532147688424303e-08, "train/image_loss_mean": 0.25458886612629156, "train/image_loss_std": 0.08490298488705429, "train/model_loss_mean": 0.8883944421084886, "train/model_loss_std": 0.35528715331222593, "train/model_opt_grad_norm": 54.535145179512575, "train/model_opt_grad_steps": 8614.798969072164, "train/model_opt_loss": 2232.5327444174854, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2512.8865979381444, "train/policy_entropy_mag": 1.9458903313912068, "train/policy_entropy_max": 1.9458903313912068, "train/policy_entropy_mean": 1.9450943685069526, "train/policy_entropy_min": 1.9197928585957007, "train/policy_entropy_std": 0.0007853800631620316, "train/policy_logprob_mag": 2.2858769266875747, "train/policy_logprob_max": -1.6860305611620243, "train/policy_logprob_mean": -1.9450750811812805, "train/policy_logprob_min": -2.2858769266875747, "train/policy_logprob_std": 0.039479138127998595, "train/policy_randomness_mag": 0.9999898745841587, "train/policy_randomness_max": 0.9999898745841587, "train/policy_randomness_mean": 0.9995808263414914, "train/policy_randomness_min": 0.9865784245667998, "train/policy_randomness_std": 0.00040360554403471807, "train/post_ent_mag": 41.79529835022602, "train/post_ent_max": 41.79529835022602, "train/post_ent_mean": 41.7665646346574, "train/post_ent_min": 41.64551445872513, "train/post_ent_std": 0.027178746892965025, "train/prior_ent_mag": 42.29174503837664, "train/prior_ent_max": 42.29174503837664, "train/prior_ent_mean": 42.264721998234386, "train/prior_ent_min": 42.19889033209417, "train/prior_ent_std": 0.013877695066297484, "train/rep_loss_mean": 1.0006610695848759, "train/rep_loss_std": 4.392700058590506e-05, "train/reward_avg": 0.00026564278809975393, "train/reward_loss_mean": 0.011241454167829193, "train/reward_loss_std": 0.05006481278399678, "train/reward_max_data": 0.06009342946645026, "train/reward_max_pred": 0.000266389748484818, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.010096942302626893, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.443126097969387, "train/reward_pred": 0.0002661023850639149, "train/reward_rate": 0.0001208118556701031, "train_stats/mean_log_entropy": 1.9379566306466456, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02595917321741581, "report/cont_loss_std": 0.37621623277664185, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.033649444580078, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0023996077943593264, "report/cont_pred": 0.9976033568382263, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2606651782989502, "report/image_loss_std": 0.08176938444375992, "report/model_loss_mean": 0.8962839841842651, "report/model_loss_std": 0.3841288387775421, "report/post_ent_mag": 41.51069259643555, "report/post_ent_max": 41.51069259643555, "report/post_ent_mean": 41.49479293823242, "report/post_ent_min": 41.487518310546875, "report/post_ent_std": 0.0027520523872226477, "report/prior_ent_mag": 41.874176025390625, "report/prior_ent_max": 41.874176025390625, "report/prior_ent_mean": 41.85739517211914, "report/prior_ent_min": 41.78963851928711, "report/prior_ent_std": 0.01319904811680317, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001959535584319383, "report/reward_loss_mean": 0.009659617207944393, "report/reward_loss_std": 0.016414929181337357, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00023794174194335938, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009659618139266968, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00023633625824004412, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.00239960802718997, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00239960802718997, "eval/cont_pred": 0.9976033568382263, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25409600138664246, "eval/image_loss_std": 0.07884225994348526, "eval/model_loss_mean": 0.8578100204467773, "eval/model_loss_std": 0.07884248346090317, "eval/post_ent_mag": 41.50938034057617, "eval/post_ent_max": 41.50938034057617, "eval/post_ent_mean": 41.494598388671875, "eval/post_ent_min": 41.487510681152344, "eval/post_ent_std": 0.0025960379280149937, "eval/prior_ent_mag": 41.8724365234375, "eval/prior_ent_max": 41.8724365234375, "eval/prior_ent_mean": 41.85778045654297, "eval/prior_ent_min": 41.78963851928711, "eval/prior_ent_std": 0.012047401629388332, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013143504038453102, "eval/reward_loss_std": 3.26135273098771e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00023794174194335938, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013143504038453102, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023623520974069834, "eval/reward_rate": 0.0, "replay/size": 154513.0, "replay/inserts": 30928.0, "replay/samples": 30928.0, "replay/insert_wait_avg": 1.3349914082084613e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0793358935510564e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38048.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1782401435790453e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.296401023864746e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1395411491394, "timer/env.step_count": 3866.0, "timer/env.step_total": 37.5753059387207, "timer/env.step_frac": 0.03757006336890496, "timer/env.step_avg": 0.009719427299203493, "timer/env.step_min": 0.007872343063354492, "timer/env.step_max": 0.040111541748046875, "timer/replay._sample_count": 30928.0, "timer/replay._sample_total": 16.38086438179016, "timer/replay._sample_frac": 0.016378578896069734, "timer/replay._sample_avg": 0.0005296451235705562, "timer/replay._sample_min": 0.00037980079650878906, "timer/replay._sample_max": 0.027838468551635742, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4733.0, "timer/agent.policy_total": 48.378594160079956, "timer/agent.policy_frac": 0.04837184429734071, "timer/agent.policy_avg": 0.010221549579564749, "timer/agent.policy_min": 0.008759021759033203, "timer/agent.policy_max": 0.08456945419311523, "timer/dataset_train_count": 1933.0, "timer/dataset_train_total": 0.2207026481628418, "timer/dataset_train_frac": 0.00022067185535856233, "timer/dataset_train_avg": 0.0001141762277096957, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0008337497711181641, "timer/agent.train_count": 1933.0, "timer/agent.train_total": 864.6367177963257, "timer/agent.train_frac": 0.864516082228762, "timer/agent.train_avg": 0.44730300972391396, "timer/agent.train_min": 0.43552231788635254, "timer/agent.train_max": 1.0872883796691895, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4766058921813965, "timer/agent.report_frac": 0.0004765393953265624, "timer/agent.report_avg": 0.23830294609069824, "timer/agent.report_min": 0.2315981388092041, "timer/agent.report_max": 0.24500775337219238, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.839897155761719e-05, "timer/dataset_eval_frac": 4.83922188517892e-08, "timer/dataset_eval_avg": 4.839897155761719e-05, "timer/dataset_eval_min": 4.839897155761719e-05, "timer/dataset_eval_max": 4.839897155761719e-05, "fps": 30.923172279802984}
{"step": 155160, "time": 5210.421344995499, "episode/length": 288.0, "episode/score": 0.03964579242186517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03964579242186517}
{"step": 155624, "time": 5225.146448373795, "episode/length": 288.0, "episode/score": 0.06689766024911137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06689766024911137}
{"step": 156080, "time": 5240.216194629669, "episode/length": 288.0, "episode/score": 0.058395320349916346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058395320349916346}
{"step": 156392, "time": 5249.965037345886, "episode/length": 288.0, "episode/score": 0.05991321729872823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05991321729872823}
{"step": 156648, "time": 5258.060401916504, "episode/length": 288.0, "episode/score": 0.0498440873409578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0498440873409578}
{"step": 156824, "time": 5263.632846832275, "episode/length": 229.0, "episode/score": 0.32559140231285255, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.041216391556076815}
{"step": 156880, "time": 5265.609375238419, "episode/length": 288.0, "episode/score": 0.05906598403505825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05906598403505825}
{"step": 157184, "time": 5275.228608608246, "episode/length": 288.0, "episode/score": 0.04810776708427511, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04810776708427511}
{"step": 157472, "time": 5284.261500120163, "episode/length": 288.0, "episode/score": 0.047609397036353585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047609397036353585}
{"step": 157936, "time": 5298.845781087875, "episode/length": 288.0, "episode/score": 0.0637895245243385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0637895245243385}
{"step": 158392, "time": 5313.0545246601105, "episode/length": 288.0, "episode/score": 0.027463382877485287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027463382877485287}
{"step": 158704, "time": 5323.166016101837, "episode/length": 288.0, "episode/score": 0.05384309841230106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05384309841230106}
{"step": 158960, "time": 5331.290203094482, "episode/length": 288.0, "episode/score": 0.036362700392956526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036362700392956526}
{"step": 159056, "time": 5334.336017847061, "episode/length": 139.0, "episode/score": 0.5955050124742769, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.029879986234263356}
{"step": 159136, "time": 5336.87203001976, "episode/length": 288.0, "episode/score": 0.04114027721979596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04114027721979596}
{"step": 159192, "time": 5338.440323591232, "episode/length": 288.0, "episode/score": 0.026541836825018095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026541836825018095}
{"step": 159496, "time": 5348.037389278412, "episode/length": 288.0, "episode/score": 0.06054826365476629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06054826365476629}
{"step": 159784, "time": 5357.103686332703, "episode/length": 288.0, "episode/score": 0.02589699722182104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02589699722182104}
{"step": 160056, "time": 5370.606909990311, "eval_episode/length": 263.0, "eval_episode/score": 0.17812499403953552, "eval_episode/reward_rate": 0.003787878787878788}
{"step": 160056, "time": 5371.061363220215, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5371.084321975708, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5371.107867717743, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5371.128144025803, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5371.144967794418, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5371.162657260895, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5371.181666612625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160704, "time": 5391.947172403336, "episode/length": 288.0, "episode/score": 0.05625225543575141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05625225543575141}
{"step": 161016, "time": 5401.561227560043, "episode/length": 288.0, "episode/score": 0.054114993548068924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054114993548068924}
{"step": 161272, "time": 5409.628962278366, "episode/length": 288.0, "episode/score": 0.0490394705851287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0490394705851287}
{"step": 161368, "time": 5412.627818584442, "episode/length": 288.0, "episode/score": 0.044426316829373036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044426316829373036}
{"step": 161448, "time": 5415.141578674316, "episode/length": 288.0, "episode/score": 0.039900665144656955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039900665144656955}
{"step": 161504, "time": 5417.1164717674255, "episode/length": 288.0, "episode/score": 0.04457049264054547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04457049264054547}
{"step": 161808, "time": 5426.8498339653015, "episode/length": 288.0, "episode/score": 0.04916474595223974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04916474595223974}
{"step": 162096, "time": 5436.058793067932, "episode/length": 288.0, "episode/score": 0.05238439551185081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05238439551185081}
{"step": 163016, "time": 5464.839376211166, "episode/length": 288.0, "episode/score": 0.04340827569980377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04340827569980377}
{"step": 163328, "time": 5474.899364948273, "episode/length": 288.0, "episode/score": 0.06526647845657862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06526647845657862}
{"step": 163584, "time": 5483.038008451462, "episode/length": 288.0, "episode/score": 0.0596812243052085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0596812243052085}
{"step": 163680, "time": 5486.071196079254, "episode/length": 288.0, "episode/score": 0.07833918204384815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07833918204384815}
{"step": 163760, "time": 5488.570256233215, "episode/length": 288.0, "episode/score": 0.07575106643774632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07575106643774632}
{"step": 163816, "time": 5490.126167535782, "episode/length": 288.0, "episode/score": 0.08648943752506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08648943752506}
{"step": 164120, "time": 5500.178901672363, "episode/length": 288.0, "episode/score": 0.06711128934873045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06711128934873045}
{"step": 164408, "time": 5509.190235614777, "episode/length": 288.0, "episode/score": 0.05519617318702785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05519617318702785}
{"step": 165328, "time": 5538.418524265289, "episode/length": 288.0, "episode/score": 0.07004318097415307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07004318097415307}
{"step": 165640, "time": 5548.1408450603485, "episode/length": 288.0, "episode/score": 0.07303508055156271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07303508055156271}
{"step": 165896, "time": 5556.2885138988495, "episode/length": 288.0, "episode/score": 0.054067718879196036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054067718879196036}
{"step": 165992, "time": 5559.317023515701, "episode/length": 288.0, "episode/score": 0.04697280157893147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04697280157893147}
{"step": 166072, "time": 5561.844329595566, "episode/length": 288.0, "episode/score": 0.07720231643008901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07720231643008901}
{"step": 166128, "time": 5563.815274715424, "episode/length": 288.0, "episode/score": 0.05455834525866976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05455834525866976}
{"step": 166432, "time": 5573.482903003693, "episode/length": 288.0, "episode/score": 0.02888867218547375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02888867218547375}
{"step": 166720, "time": 5582.530001401901, "episode/length": 288.0, "episode/score": 0.04542431904468458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04542431904468458}
{"step": 167136, "time": 5595.572751760483, "episode/length": 142.0, "episode/score": 0.5976221541092741, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.04137214931296285}
{"step": 167640, "time": 5611.382888555527, "episode/length": 288.0, "episode/score": 0.04873044990767994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04873044990767994}
{"step": 167952, "time": 5621.476042985916, "episode/length": 288.0, "episode/score": 0.04817830372769549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04817830372769549}
{"step": 168208, "time": 5629.533627748489, "episode/length": 221.0, "episode/score": 0.365175084593659, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.05580009767874117}
{"step": 168208, "time": 5629.5550854206085, "episode/length": 288.0, "episode/score": 0.08756169923697144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08756169923697144}
{"step": 168384, "time": 5635.257614135742, "episode/length": 288.0, "episode/score": 0.04540219328839612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04540219328839612}
{"step": 168440, "time": 5636.834619998932, "episode/length": 288.0, "episode/score": 0.05303637807145378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05303637807145378}
{"step": 168920, "time": 5651.948430776596, "episode/length": 274.0, "episode/score": 0.21218763290954712, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.06843763705393258}
{"step": 169448, "time": 5668.742488861084, "episode/length": 288.0, "episode/score": 0.0625805943902833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0625805943902833}
{"step": 169952, "time": 5684.8393976688385, "episode/length": 288.0, "episode/score": 0.0672134464553551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0672134464553551}
{"step": 170040, "time": 5689.06493973732, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 170040, "time": 5689.187624931335, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 170040, "time": 5693.760872840881, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5693.774141073227, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5693.785120725632, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5693.802629232407, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5693.816937446594, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5693.833238601685, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170264, "time": 5700.923598051071, "episode/length": 288.0, "episode/score": 0.08302615899040688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08302615899040688}
{"step": 170520, "time": 5709.01566696167, "episode/length": 288.0, "episode/score": 0.06509251645900349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06509251645900349}
{"step": 170520, "time": 5709.037935256958, "episode/length": 288.0, "episode/score": 0.05164711361072705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05164711361072705}
{"step": 170696, "time": 5714.63808465004, "episode/length": 288.0, "episode/score": 0.05991562753752078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05991562753752078}
{"step": 170752, "time": 5716.632100343704, "episode/length": 288.0, "episode/score": 0.04761734116252114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04761734116252114}
{"step": 171232, "time": 5732.043972015381, "episode/length": 288.0, "episode/score": 0.0700143158919957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0700143158919957}
{"step": 171760, "time": 5748.628839492798, "episode/length": 288.0, "episode/score": 0.050259030311934794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050259030311934794}
{"step": 172264, "time": 5764.80724978447, "episode/length": 288.0, "episode/score": 0.06737464389689762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06737464389689762}
{"step": 172576, "time": 5774.844393014908, "episode/length": 288.0, "episode/score": 0.08786185716340356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08786185716340356}
{"step": 172832, "time": 5782.989111185074, "episode/length": 288.0, "episode/score": 0.062367385710729195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062367385710729195}
{"step": 172832, "time": 5783.008405208588, "episode/length": 288.0, "episode/score": 0.04466602493653227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04466602493653227}
{"step": 173008, "time": 5788.538205623627, "episode/length": 288.0, "episode/score": 0.06558560754046994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06558560754046994}
{"step": 173064, "time": 5790.079447031021, "episode/length": 288.0, "episode/score": 0.05698591299267264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05698591299267264}
{"step": 173544, "time": 5805.126203298569, "episode/length": 288.0, "episode/score": 0.06873131876676553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06873131876676553}
{"step": 174072, "time": 5821.749852895737, "episode/length": 288.0, "episode/score": 0.058721051218526554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058721051218526554}
{"step": 174576, "time": 5837.783772468567, "episode/length": 288.0, "episode/score": 0.04738770365167966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04738770365167966}
{"step": 174888, "time": 5847.475674152374, "episode/length": 288.0, "episode/score": 0.06245913012958226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06245913012958226}
{"step": 175144, "time": 5855.518492937088, "episode/length": 288.0, "episode/score": 0.07723120046304643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07723120046304643}
{"step": 175144, "time": 5855.535298585892, "episode/length": 288.0, "episode/score": 0.043965283765516006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043965283765516006}
{"step": 175320, "time": 5861.114635229111, "episode/length": 288.0, "episode/score": 0.058597412078682964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058597412078682964}
{"step": 175376, "time": 5863.104697227478, "episode/length": 288.0, "episode/score": 0.051365121820538207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051365121820538207}
{"step": 175856, "time": 5878.398687839508, "episode/length": 288.0, "episode/score": 0.06182997767533038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06182997767533038}
{"step": 176384, "time": 5895.013801336288, "episode/length": 288.0, "episode/score": 0.05942099577339377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05942099577339377}
{"step": 176888, "time": 5910.745227575302, "episode/length": 288.0, "episode/score": 0.046578123086021606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046578123086021606}
{"step": 177200, "time": 5920.902097225189, "episode/length": 288.0, "episode/score": 0.04379702731350221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04379702731350221}
{"step": 177456, "time": 5929.006101846695, "episode/length": 288.0, "episode/score": 0.0557441555446303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0557441555446303}
{"step": 177456, "time": 5929.022390604019, "episode/length": 288.0, "episode/score": 0.07593001583165915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07593001583165915}
{"step": 177632, "time": 5934.746992111206, "episode/length": 288.0, "episode/score": 0.06523385469810705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06523385469810705}
{"step": 177688, "time": 5936.300127744675, "episode/length": 288.0, "episode/score": 0.06898565444683413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06898565444683413}
{"step": 178168, "time": 5951.421518087387, "episode/length": 288.0, "episode/score": 0.04497293185673357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04497293185673357}
{"step": 178696, "time": 5968.207588672638, "episode/length": 288.0, "episode/score": 0.07106404368218477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07106404368218477}
{"step": 179200, "time": 5984.2895975112915, "episode/length": 288.0, "episode/score": 0.0503584053491295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0503584053491295}
{"step": 179512, "time": 5993.975691080093, "episode/length": 288.0, "episode/score": 0.04669206167670836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04669206167670836}
{"step": 179768, "time": 6002.043305873871, "episode/length": 288.0, "episode/score": 0.05933373779146223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05933373779146223}
{"step": 179768, "time": 6002.058167695999, "episode/length": 288.0, "episode/score": 0.045450848128552934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045450848128552934}
{"step": 179944, "time": 6007.572964191437, "episode/length": 288.0, "episode/score": 0.058131528421313305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058131528421313305}
{"step": 180000, "time": 6009.573447465897, "episode/length": 288.0, "episode/score": 0.03911053801414255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03911053801414255}
{"step": 180024, "time": 6012.897643566132, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 180024, "time": 6015.315661907196, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6015.329495191574, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6015.33989739418, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6015.348707914352, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6015.357905387878, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6015.367915868759, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6015.378349781036, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180480, "time": 6030.6435561180115, "episode/length": 288.0, "episode/score": 0.061189099609350706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061189099609350706}
{"step": 181008, "time": 6047.306285619736, "episode/length": 288.0, "episode/score": 0.039748748483589225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039748748483589225}
{"step": 181512, "time": 6062.972987174988, "episode/length": 288.0, "episode/score": 0.06992468353018921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06992468353018921}
{"step": 181824, "time": 6073.03738117218, "episode/length": 288.0, "episode/score": 0.039280299394590656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039280299394590656}
{"step": 182080, "time": 6081.155751466751, "episode/length": 288.0, "episode/score": 0.04224365315798195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04224365315798195}
{"step": 182080, "time": 6081.173735618591, "episode/length": 288.0, "episode/score": 0.049128603124415804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049128603124415804}
{"step": 182256, "time": 6086.712991476059, "episode/length": 288.0, "episode/score": 0.05422536613303919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05422536613303919}
{"step": 182312, "time": 6088.247093439102, "episode/length": 288.0, "episode/score": 0.05015778091893708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05015778091893708}
{"step": 182792, "time": 6103.434534311295, "episode/length": 288.0, "episode/score": 0.039885846658137325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039885846658137325}
{"step": 183320, "time": 6120.214739084244, "episode/length": 288.0, "episode/score": 0.03534184759115533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03534184759115533}
{"step": 183824, "time": 6136.268058300018, "episode/length": 288.0, "episode/score": 0.05943528449438418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05943528449438418}
{"step": 184136, "time": 6146.042131900787, "episode/length": 288.0, "episode/score": 0.052734484708025775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052734484708025775}
{"step": 184392, "time": 6154.112893819809, "episode/length": 288.0, "episode/score": 0.053460741460753525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053460741460753525}
{"step": 184392, "time": 6154.124557733536, "episode/length": 288.0, "episode/score": 0.04912617507829964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04912617507829964}
{"step": 184568, "time": 6159.682292461395, "episode/length": 288.0, "episode/score": 0.0421021755437323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0421021755437323}
{"step": 184624, "time": 6161.681564331055, "episode/length": 288.0, "episode/score": 0.03551860731357692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03551860731357692}
{"step": 185104, "time": 6176.854670524597, "episode/length": 288.0, "episode/score": 0.046984213356495275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046984213356495275}
{"step": 185632, "time": 6193.483754634857, "episode/length": 288.0, "episode/score": 0.03805588300923546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03805588300923546}
{"step": 186009, "time": 6206.179003238678, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.000067992531574, "train/action_min": 0.0, "train/action_std": 2.0011116686262613, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 8.723292369963246e-05, "train/actor_opt_grad_steps": 10560.0, "train/actor_opt_loss": -4.0301309797739115, "train/adv_mag": 0.000422901594577058, "train/adv_max": 0.0003838903931756094, "train/adv_mean": 8.713977885768593e-05, "train/adv_min": -0.0002245685674365938, "train/adv_std": 9.554905405453478e-05, "train/cont_avg": 0.9964378238341969, "train/cont_loss_mean": 0.023652741206578252, "train/cont_loss_std": 0.3248784549092787, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.66020366769088, "train/cont_pos_acc": 0.9999999842495498, "train/cont_pos_loss": 0.0035095391071213343, "train/cont_pred": 0.9964967126055703, "train/cont_rate": 0.9964378238341969, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.021081379523990588, "train/extr_critic_critic_opt_grad_steps": 10560.0, "train/extr_critic_critic_opt_loss": 13523.55461666127, "train/extr_critic_mag": 0.08341966083012714, "train/extr_critic_max": 0.08341966083012714, "train/extr_critic_mean": 0.08329209832020992, "train/extr_critic_min": 0.08312450851183481, "train/extr_critic_std": 5.189674024284029e-05, "train/extr_return_normed_mag": 0.0005136890809770692, "train/extr_return_normed_max": 0.0004699142948951128, "train/extr_return_normed_mean": 0.0003032223918936499, "train/extr_return_normed_min": 9.492618741149112e-05, "train/extr_return_normed_std": 7.704056275976367e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08354590891093171, "train/extr_return_raw_max": 0.08354590891093171, "train/extr_return_raw_mean": 0.08337922108605736, "train/extr_return_raw_min": 0.08317092080344808, "train/extr_return_raw_std": 7.704056314971541e-05, "train/extr_reward_mag": 0.0002640893422260186, "train/extr_reward_max": 0.0002640893422260186, "train/extr_reward_mean": 0.00026386654433623014, "train/extr_reward_min": 0.0002636273290209202, "train/extr_reward_std": 9.305651575388099e-08, "train/image_loss_mean": 0.2501873661199382, "train/image_loss_std": 0.08406986975608094, "train/model_loss_mean": 0.8854674922369923, "train/model_loss_std": 0.3750659669773566, "train/model_opt_grad_norm": 49.560878467065685, "train/model_opt_grad_steps": 10548.305699481865, "train/model_opt_loss": 2442.518043636658, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2759.0673575129535, "train/policy_entropy_mag": 1.9458867490600429, "train/policy_entropy_max": 1.9458867490600429, "train/policy_entropy_mean": 1.9448089791085437, "train/policy_entropy_min": 1.9265961597620513, "train/policy_entropy_std": 0.0008163676240392165, "train/policy_logprob_mag": 2.2410938282704724, "train/policy_logprob_max": -1.7079717272921546, "train/policy_logprob_mean": -1.9447866048219908, "train/policy_logprob_min": -2.2410938282704724, "train/policy_logprob_std": 0.045362683370168966, "train/policy_randomness_mag": 0.9999880361433474, "train/policy_randomness_max": 0.9999880361433474, "train/policy_randomness_mean": 0.9994341666216677, "train/policy_randomness_min": 0.9900746296106843, "train/policy_randomness_std": 0.00041952998277253515, "train/post_ent_mag": 43.347657850986934, "train/post_ent_max": 43.347657850986934, "train/post_ent_mean": 43.30965678555978, "train/post_ent_min": 43.29365365616398, "train/post_ent_std": 0.0091079938324371, "train/prior_ent_mag": 41.84275772410971, "train/prior_ent_max": 41.84275772410971, "train/prior_ent_mean": 41.79539549041906, "train/prior_ent_min": 41.74479341259892, "train/prior_ent_std": 0.01492275807938968, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0002859524344733477, "train/reward_loss_mean": 0.011627361528247285, "train/reward_loss_std": 0.06036823262204778, "train/reward_max_data": 0.07511550270942634, "train/reward_max_pred": 0.0002642814359516677, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.010060005483502242, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.062492942810058, "train/reward_pred": 0.0002640345636899993, "train/reward_rate": 0.00017203691709844558, "train_stats/mean_log_entropy": 1.93795737039263, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020050395280122757, "report/cont_loss_std": 0.3067602813243866, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.679203987121582, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003422127105295658, "report/cont_pred": 0.996583878993988, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.23624461889266968, "report/image_loss_std": 0.083402618765831, "report/model_loss_mean": 0.8644514679908752, "report/model_loss_std": 0.3221403658390045, "report/post_ent_mag": 45.854774475097656, "report/post_ent_max": 45.854774475097656, "report/post_ent_mean": 45.75346374511719, "report/post_ent_min": 45.713340759277344, "report/post_ent_std": 0.024175474420189857, "report/prior_ent_mag": 41.85096740722656, "report/prior_ent_max": 41.85096740722656, "report/prior_ent_mean": 41.68041229248047, "report/prior_ent_min": 41.59598159790039, "report/prior_ent_std": 0.040841229259967804, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001591971085872501, "report/reward_loss_mean": 0.008156418800354004, "report/reward_loss_std": 0.014427265152335167, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002663135528564453, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008156418800354004, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00026601681020110846, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003422127105295658, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003422127105295658, "eval/cont_pred": 0.996583878993988, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2562028169631958, "eval/image_loss_std": 0.08025974780321121, "eval/model_loss_mean": 0.8609933853149414, "eval/model_loss_std": 0.08026000112295151, "eval/post_ent_mag": 45.83393096923828, "eval/post_ent_max": 45.83393096923828, "eval/post_ent_mean": 45.749366760253906, "eval/post_ent_min": 45.71296310424805, "eval/post_ent_std": 0.023380910977721214, "eval/prior_ent_mag": 41.80668640136719, "eval/prior_ent_max": 41.80668640136719, "eval/prior_ent_mean": 41.689430236816406, "eval/prior_ent_min": 41.584877014160156, "eval/prior_ent_std": 0.03902021050453186, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013683699071407318, "eval/reward_loss_std": 3.2221994388237363e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002663135528564453, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013683699071407318, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002660836325958371, "eval/reward_rate": 0.0, "replay/size": 185505.0, "replay/inserts": 30992.0, "replay/samples": 30992.0, "replay/insert_wait_avg": 1.3154486620247703e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.785070207602719e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44984.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1679966694480959e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3560056686401367e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0268111228943, "timer/env.step_count": 3874.0, "timer/env.step_total": 37.206684589385986, "timer/env.step_frac": 0.03720568706313777, "timer/env.step_avg": 0.009604203559469796, "timer/env.step_min": 0.007889270782470703, "timer/env.step_max": 0.036376953125, "timer/replay._sample_count": 30992.0, "timer/replay._sample_total": 16.291974306106567, "timer/replay._sample_frac": 0.016291537511692204, "timer/replay._sample_avg": 0.0005256832184469078, "timer/replay._sample_min": 0.0003578662872314453, "timer/replay._sample_max": 0.01153421401977539, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4741.0, "timer/agent.policy_total": 48.1486713886261, "timer/agent.policy_frac": 0.048147380503290385, "timer/agent.policy_avg": 0.010155804975453722, "timer/agent.policy_min": 0.008791923522949219, "timer/agent.policy_max": 0.09264826774597168, "timer/dataset_train_count": 1937.0, "timer/dataset_train_total": 0.21875333786010742, "timer/dataset_train_frac": 0.00021874747299472613, "timer/dataset_train_avg": 0.00011293409285498576, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0006887912750244141, "timer/agent.train_count": 1937.0, "timer/agent.train_total": 864.8583302497864, "timer/agent.train_frac": 0.8648351430484829, "timer/agent.train_avg": 0.44649371721723613, "timer/agent.train_min": 0.4362006187438965, "timer/agent.train_max": 0.5826830863952637, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4723968505859375, "timer/agent.report_frac": 0.0004723841854354885, "timer/agent.report_avg": 0.23619842529296875, "timer/agent.report_min": 0.22464275360107422, "timer/agent.report_max": 0.24775409698486328, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 3.5046591489458235e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 30.990636717701076}
{"step": 186136, "time": 6209.969607591629, "episode/length": 288.0, "episode/score": 0.053685517017129314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053685517017129314}
{"step": 186448, "time": 6220.019828557968, "episode/length": 288.0, "episode/score": 0.03531855992042665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03531855992042665}
{"step": 186704, "time": 6228.109239578247, "episode/length": 288.0, "episode/score": 0.04905766348883844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04905766348883844}
{"step": 186704, "time": 6228.121648311615, "episode/length": 288.0, "episode/score": 0.05092745248322217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05092745248322217}
{"step": 186880, "time": 6233.741681575775, "episode/length": 288.0, "episode/score": 0.055673328266948374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055673328266948374}
{"step": 186936, "time": 6235.289101839066, "episode/length": 288.0, "episode/score": 0.04361204364673199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04361204364673199}
{"step": 187416, "time": 6250.436709403992, "episode/length": 288.0, "episode/score": 0.04516343562181646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04516343562181646}
{"step": 187944, "time": 6267.184084415436, "episode/length": 288.0, "episode/score": 0.02488108420612889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02488108420612889}
{"step": 188224, "time": 6276.254620552063, "episode/length": 100.0, "episode/score": 0.7074866675202145, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.019986638882045327}
{"step": 188448, "time": 6283.847455501556, "episode/length": 288.0, "episode/score": 0.04994274772650442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04994274772650442}
{"step": 188760, "time": 6293.666254758835, "episode/length": 288.0, "episode/score": 0.04156836582876622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04156836582876622}
{"step": 189016, "time": 6301.789860010147, "episode/length": 288.0, "episode/score": 0.04795884570751241, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04795884570751241}
{"step": 189016, "time": 6301.806240797043, "episode/length": 288.0, "episode/score": 0.04948088722721877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04948088722721877}
{"step": 189192, "time": 6307.355382204056, "episode/length": 288.0, "episode/score": 0.06494294791278321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06494294791278321}
{"step": 189248, "time": 6309.360195875168, "episode/length": 288.0, "episode/score": 0.06805666145797318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06805666145797318}
{"step": 190008, "time": 6338.445230722427, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6338.45961689949, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6338.473186016083, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6338.486613512039, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6338.50018620491, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6338.513372182846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6338.523496866226, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6338.536283969879, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190256, "time": 6346.580701112747, "episode/length": 288.0, "episode/score": 0.04316744256226457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04316744256226457}
{"step": 190536, "time": 6355.259268283844, "episode/length": 288.0, "episode/score": 0.06792020687527156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06792020687527156}
{"step": 190760, "time": 6362.319296121597, "episode/length": 288.0, "episode/score": 0.05142566492489209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05142566492489209}
{"step": 191072, "time": 6372.426029205322, "episode/length": 288.0, "episode/score": 0.01215977265101742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01215977265101742}
{"step": 191328, "time": 6380.551158428192, "episode/length": 288.0, "episode/score": 0.05267387856261507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05267387856261507}
{"step": 191328, "time": 6380.571458816528, "episode/length": 288.0, "episode/score": 0.04268717715453363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04268717715453363}
{"step": 191504, "time": 6386.193886995316, "episode/length": 288.0, "episode/score": 0.05373970391414673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05373970391414673}
{"step": 191560, "time": 6387.734420061111, "episode/length": 288.0, "episode/score": 0.01390895788887292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01390895788887292}
{"step": 192568, "time": 6419.7465035915375, "episode/length": 288.0, "episode/score": 0.04908221964609538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04908221964609538}
{"step": 192848, "time": 6428.731810092926, "episode/length": 288.0, "episode/score": 0.060583989571114216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060583989571114216}
{"step": 193072, "time": 6436.62468123436, "episode/length": 288.0, "episode/score": 0.046022385181260006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046022385181260006}
{"step": 193384, "time": 6446.345954656601, "episode/length": 288.0, "episode/score": 0.041229576587028305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041229576587028305}
{"step": 193640, "time": 6454.438207864761, "episode/length": 288.0, "episode/score": 0.046449337596527585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046449337596527585}
{"step": 193640, "time": 6454.454936027527, "episode/length": 288.0, "episode/score": 0.059815765694395395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059815765694395395}
{"step": 193816, "time": 6460.00196146965, "episode/length": 288.0, "episode/score": 0.07370415210459669, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07370415210459669}
{"step": 193872, "time": 6462.01140999794, "episode/length": 288.0, "episode/score": 0.06516563676805731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06516563676805731}
{"step": 194144, "time": 6470.608486175537, "episode/length": 161.0, "episode/score": 0.544954920748296, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.04807993383337816}
{"step": 194472, "time": 6480.807260513306, "episode/length": 103.0, "episode/score": 0.7100466575033124, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.03192160502328534}
{"step": 194880, "time": 6493.960471391678, "episode/length": 288.0, "episode/score": 0.048220816818115964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048220816818115964}
{"step": 195384, "time": 6509.72372174263, "episode/length": 288.0, "episode/score": 0.0680852876945437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0680852876945437}
{"step": 195696, "time": 6519.762079238892, "episode/length": 288.0, "episode/score": 0.060909281959311556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060909281959311556}
{"step": 195952, "time": 6527.840046882629, "episode/length": 288.0, "episode/score": 0.06638782364370854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06638782364370854}
{"step": 196128, "time": 6533.468167543411, "episode/length": 288.0, "episode/score": 0.05498093026551487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05498093026551487}
{"step": 196184, "time": 6534.995305776596, "episode/length": 288.0, "episode/score": 0.06266177446048005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06266177446048005}
{"step": 196456, "time": 6543.551716566086, "episode/length": 288.0, "episode/score": 0.04456610301269848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04456610301269848}
{"step": 196784, "time": 6554.593798398972, "episode/length": 288.0, "episode/score": 0.07665576631040949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07665576631040949}
{"step": 197192, "time": 6567.415014028549, "episode/length": 288.0, "episode/score": 0.06363778898526107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06363778898526107}
{"step": 197696, "time": 6583.458052396774, "episode/length": 288.0, "episode/score": 0.05016587549459928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05016587549459928}
{"step": 198008, "time": 6593.193137645721, "episode/length": 288.0, "episode/score": 0.06271004186794471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06271004186794471}
{"step": 198264, "time": 6601.30704498291, "episode/length": 288.0, "episode/score": 0.0714757440015319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0714757440015319}
{"step": 198440, "time": 6606.869333744049, "episode/length": 288.0, "episode/score": 0.07140718936807389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07140718936807389}
{"step": 198496, "time": 6608.8442142009735, "episode/length": 288.0, "episode/score": 0.03228914985402298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03228914985402298}
{"step": 198768, "time": 6617.445878744125, "episode/length": 288.0, "episode/score": 0.0657078900360375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0657078900360375}
{"step": 199096, "time": 6627.718693494797, "episode/length": 288.0, "episode/score": 0.03758319989651682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03758319989651682}
{"step": 199504, "time": 6640.774173974991, "episode/length": 288.0, "episode/score": 0.048814794295253705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048814794295253705}
{"step": 200008, "time": 6656.564752101898, "episode/length": 288.0, "episode/score": 0.05445659287693161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05445659287693161}
{"step": 200096, "time": 6665.533207178116, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6665.54608798027, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6665.562556266785, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6665.577873468399, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6665.594553947449, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6665.610210895538, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6665.627405881882, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6665.644483566284, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200320, "time": 6672.728053808212, "episode/length": 288.0, "episode/score": 0.035306651549262824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035306651549262824}
{"step": 200576, "time": 6680.896771430969, "episode/length": 288.0, "episode/score": 0.05309742842337073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05309742842337073}
{"step": 200752, "time": 6686.476804733276, "episode/length": 288.0, "episode/score": 0.07348410350527956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07348410350527956}
{"step": 200808, "time": 6688.014642238617, "episode/length": 288.0, "episode/score": 0.05781333225434082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05781333225434082}
{"step": 201080, "time": 6696.53959941864, "episode/length": 288.0, "episode/score": 0.05240929263754879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05240929263754879}
{"step": 201408, "time": 6707.15061545372, "episode/length": 288.0, "episode/score": 0.05310572809446512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05310572809446512}
{"step": 201816, "time": 6719.837899446487, "episode/length": 288.0, "episode/score": 0.04884615438527362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04884615438527362}
{"step": 202320, "time": 6735.916090965271, "episode/length": 288.0, "episode/score": 0.046383955484657236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046383955484657236}
{"step": 202632, "time": 6745.758504152298, "episode/length": 288.0, "episode/score": 0.04571719123418916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04571719123418916}
{"step": 202888, "time": 6753.8073081970215, "episode/length": 288.0, "episode/score": 0.06892998361502123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06892998361502123}
{"step": 203064, "time": 6759.334471464157, "episode/length": 288.0, "episode/score": 0.053864493431319715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053864493431319715}
{"step": 203120, "time": 6761.30984711647, "episode/length": 288.0, "episode/score": 0.0645310635380838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0645310635380838}
{"step": 203392, "time": 6769.873054265976, "episode/length": 288.0, "episode/score": 0.04200306728034775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04200306728034775}
{"step": 203720, "time": 6780.114908218384, "episode/length": 288.0, "episode/score": 0.04542909847498322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04542909847498322}
{"step": 204128, "time": 6793.172079801559, "episode/length": 288.0, "episode/score": 0.06461326052703953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06461326052703953}
{"step": 204632, "time": 6808.888206481934, "episode/length": 288.0, "episode/score": 0.05774114831604038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05774114831604038}
{"step": 204944, "time": 6819.393632650375, "episode/length": 288.0, "episode/score": 0.08450565980467672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08450565980467672}
{"step": 205200, "time": 6827.445984840393, "episode/length": 288.0, "episode/score": 0.06518027341724064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06518027341724064}
{"step": 205376, "time": 6833.119181394577, "episode/length": 288.0, "episode/score": 0.0751980398579235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0751980398579235}
{"step": 205432, "time": 6834.682720184326, "episode/length": 288.0, "episode/score": 0.08332643917719906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08332643917719906}
{"step": 205704, "time": 6843.308416843414, "episode/length": 288.0, "episode/score": 0.07572245925132393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07572245925132393}
{"step": 206032, "time": 6853.887676477432, "episode/length": 288.0, "episode/score": 0.053276631088806425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053276631088806425}
{"step": 206440, "time": 6866.604368925095, "episode/length": 288.0, "episode/score": 0.07401875143523284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07401875143523284}
{"step": 206944, "time": 6882.67067193985, "episode/length": 288.0, "episode/score": 0.07559139910904378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07559139910904378}
{"step": 207256, "time": 6892.41873550415, "episode/length": 288.0, "episode/score": 0.06257185490858319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06257185490858319}
{"step": 207512, "time": 6900.527147769928, "episode/length": 288.0, "episode/score": 0.08252711780767186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08252711780767186}
{"step": 207688, "time": 6906.064432144165, "episode/length": 288.0, "episode/score": 0.06779629160678269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06779629160678269}
{"step": 207744, "time": 6908.044713020325, "episode/length": 288.0, "episode/score": 0.05698113484709211, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05698113484709211}
{"step": 208016, "time": 6916.566891908646, "episode/length": 288.0, "episode/score": 0.06098582119892626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06098582119892626}
{"step": 208344, "time": 6926.8098702430725, "episode/length": 288.0, "episode/score": 0.05288058530959461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05288058530959461}
{"step": 208752, "time": 6939.809084892273, "episode/length": 288.0, "episode/score": 0.07594805920251702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07594805920251702}
{"step": 209256, "time": 6955.509347200394, "episode/length": 288.0, "episode/score": 0.06278625543654925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06278625543654925}
{"step": 209568, "time": 6965.548811912537, "episode/length": 288.0, "episode/score": 0.05824274029652088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05824274029652088}
{"step": 209824, "time": 6973.615987300873, "episode/length": 288.0, "episode/score": 0.05475541316536692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05475541316536692}
{"step": 210000, "time": 6979.142743349075, "episode/length": 288.0, "episode/score": 0.07785420062174353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07785420062174353}
{"step": 210056, "time": 6980.756996631622, "episode/length": 288.0, "episode/score": 0.08829289230260429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08829289230260429}
{"step": 210080, "time": 6986.907685518265, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6986.928069591522, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6986.942901134491, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6986.963976860046, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6986.981186628342, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6986.997849702835, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6987.016963481903, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6987.034718513489, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210328, "time": 6994.559930801392, "episode/length": 288.0, "episode/score": 0.07773682666316972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07773682666316972}
{"step": 210656, "time": 7005.0268750190735, "episode/length": 288.0, "episode/score": 0.09260450935050812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09260450935050812}
{"step": 211064, "time": 7017.770086050034, "episode/length": 288.0, "episode/score": 0.1071984372599104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1071984372599104}
{"step": 211568, "time": 7033.840656757355, "episode/length": 288.0, "episode/score": 0.11965780867421927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11965780867421927}
{"step": 211880, "time": 7043.569187879562, "episode/length": 288.0, "episode/score": 0.1486308863090926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1486308863090926}
{"step": 212136, "time": 7051.648965597153, "episode/length": 288.0, "episode/score": 0.13584165893280442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13584165893280442}
{"step": 212312, "time": 7057.203852891922, "episode/length": 288.0, "episode/score": 0.12362846601672572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12362846601672572}
{"step": 212368, "time": 7059.186212539673, "episode/length": 288.0, "episode/score": 0.09673877310660828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09673877310660828}
{"step": 212640, "time": 7067.762373685837, "episode/length": 288.0, "episode/score": 0.11487185139776557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11487185139776557}
{"step": 212968, "time": 7078.029129743576, "episode/length": 288.0, "episode/score": 0.12865938054324033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12865938054324033}
{"step": 213376, "time": 7091.620232582092, "episode/length": 288.0, "episode/score": 0.11153769612224096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11153769612224096}
{"step": 213880, "time": 7107.371490478516, "episode/length": 288.0, "episode/score": 0.06386163020601998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06386163020601998}
{"step": 214192, "time": 7117.480917930603, "episode/length": 288.0, "episode/score": 0.10017588373966646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10017588373966646}
{"step": 214448, "time": 7125.556086540222, "episode/length": 288.0, "episode/score": 0.107988981646713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.107988981646713}
{"step": 214624, "time": 7131.177139997482, "episode/length": 288.0, "episode/score": 0.11623419247882794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11623419247882794}
{"step": 214680, "time": 7132.753282546997, "episode/length": 288.0, "episode/score": 0.11260419309576264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11260419309576264}
{"step": 214952, "time": 7141.316366195679, "episode/length": 288.0, "episode/score": 0.0866502812143608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0866502812143608}
{"step": 215280, "time": 7151.8134043216705, "episode/length": 288.0, "episode/score": 0.1315042670622688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1315042670622688}
{"step": 215688, "time": 7164.532919645309, "episode/length": 288.0, "episode/score": 0.07479698457723316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07479698457723316}
{"step": 216192, "time": 7180.638461112976, "episode/length": 288.0, "episode/score": 0.10873075208428418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10873075208428418}
{"step": 216504, "time": 7190.227152824402, "episode/length": 288.0, "episode/score": 0.11291851375040096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11291851375040096}
{"step": 216760, "time": 7198.459401845932, "episode/length": 288.0, "episode/score": 0.1177095100091492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1177095100091492}
{"step": 216936, "time": 7204.024538993835, "episode/length": 288.0, "episode/score": 0.11713056179519299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11713056179519299}
{"step": 216985, "time": 7206.536145925522, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7237460736146906, "train/action_min": 0.0, "train/action_std": 1.929408590203708, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0003818605703028092, "train/actor_opt_grad_steps": 12495.0, "train/actor_opt_loss": -1.942574519625644, "train/adv_mag": 0.0019264915554793839, "train/adv_max": 0.001880698674118396, "train/adv_mean": 0.0002607291991137469, "train/adv_min": -0.0010165837161319772, "train/adv_std": 0.00036045814235454674, "train/cont_avg": 0.9964662532216495, "train/cont_loss_mean": 0.023510841771566607, "train/cont_loss_std": 0.32453929978907686, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.650189946095149, "train/cont_pos_acc": 0.9999999815655738, "train/cont_pos_loss": 0.0035489446125905387, "train/cont_pred": 0.9964574372645506, "train/cont_rate": 0.9964662532216495, "train/dyn_loss_mean": 1.0000019958338786, "train/dyn_loss_std": 5.833196847401943e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.039276439705101494, "train/extr_critic_critic_opt_grad_steps": 12495.0, "train/extr_critic_critic_opt_loss": 13486.731425177191, "train/extr_critic_mag": 0.08677213585253843, "train/extr_critic_max": 0.08677213585253843, "train/extr_critic_mean": 0.08620961056542151, "train/extr_critic_min": 0.08490923016341691, "train/extr_critic_std": 0.000229900898206718, "train/extr_return_normed_mag": 0.002238800806790283, "train/extr_return_normed_max": 0.002063735705061057, "train/extr_return_normed_mean": 0.0009867845277083164, "train/extr_return_normed_min": -0.00022446076126442742, "train/extr_return_normed_std": 0.00033099697421422797, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0875472777436689, "train/extr_return_raw_max": 0.0875472777436689, "train/extr_return_raw_mean": 0.08647033103655294, "train/extr_return_raw_min": 0.08525908127734341, "train/extr_return_raw_std": 0.0003309969729390601, "train/extr_reward_mag": 0.0004603426481030651, "train/extr_reward_max": 0.0004603426481030651, "train/extr_reward_mean": 0.0003031112178506032, "train/extr_reward_min": 0.00020916806053869504, "train/extr_reward_std": 5.760752898201988e-05, "train/image_loss_mean": 0.22111143048891088, "train/image_loss_std": 0.09203901771724839, "train/model_loss_mean": 0.8550886204562236, "train/model_loss_std": 0.3582552236687277, "train/model_opt_grad_norm": 45.779360594208704, "train/model_opt_grad_steps": 12481.659793814433, "train/model_opt_loss": 2562.803187419459, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3015.463917525773, "train/policy_entropy_mag": 1.9141384959220886, "train/policy_entropy_max": 1.9141384959220886, "train/policy_entropy_mean": 1.8460381633227634, "train/policy_entropy_min": 1.622219882675053, "train/policy_entropy_std": 0.030379108668751438, "train/policy_logprob_mag": 3.089446114510605, "train/policy_logprob_max": -0.9717901802247333, "train/policy_logprob_mean": -1.8459740360987555, "train/policy_logprob_min": -3.089446114510605, "train/policy_logprob_std": 0.31244601151838747, "train/policy_randomness_mag": 0.983672656963781, "train/policy_randomness_max": 0.983672656963781, "train/policy_randomness_mean": 0.9486760057739376, "train/policy_randomness_min": 0.8336561572613176, "train/policy_randomness_std": 0.01561177432712302, "train/post_ent_mag": 50.03392703262801, "train/post_ent_max": 50.03392703262801, "train/post_ent_mean": 49.61725824886991, "train/post_ent_min": 49.204421348178506, "train/post_ent_std": 0.19272284889497707, "train/prior_ent_mag": 48.867334877092816, "train/prior_ent_max": 48.867334877092816, "train/prior_ent_mean": 45.68242448629792, "train/prior_ent_min": 44.259543861310505, "train/prior_ent_std": 0.7528073901176145, "train/rep_loss_mean": 1.0000019958338786, "train/rep_loss_std": 5.833196847401943e-05, "train/reward_avg": 0.00024090844592662797, "train/reward_loss_mean": 0.010465126501434703, "train/reward_loss_std": 0.03949595116482107, "train/reward_max_data": 0.04161726920169385, "train/reward_max_pred": 0.0004236857915661999, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009666112434003771, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.865499748903162, "train/reward_pred": 0.00025395647749861644, "train/reward_rate": 9.060889175257732e-05, "train_stats/mean_log_entropy": 1.848742494799874, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.009378134272992611, "report/cont_loss_std": 0.1725231111049652, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.527421474456787, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003984153736382723, "report/cont_pred": 0.9960238933563232, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1961761713027954, "report/image_loss_std": 0.09048692137002945, "report/model_loss_mean": 0.8167061805725098, "report/model_loss_std": 0.19446952641010284, "report/post_ent_mag": 52.75621795654297, "report/post_ent_max": 52.75621795654297, "report/post_ent_mean": 52.05902099609375, "report/post_ent_min": 51.25721740722656, "report/post_ent_std": 0.3391397297382355, "report/prior_ent_mag": 52.43505859375, "report/prior_ent_max": 52.43505859375, "report/prior_ent_mean": 46.69731903076172, "report/prior_ent_min": 44.29111862182617, "report/prior_ent_std": 1.0891735553741455, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002554570965003222, "report/reward_loss_mean": 0.011151837185025215, "report/reward_loss_std": 0.01640513725578785, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.001057267189025879, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01115183811634779, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00031267653685063124, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020166093483567238, "eval/cont_loss_std": 0.2985265552997589, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.527421474456787, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003984153736382723, "eval/cont_pred": 0.9960238933563232, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20278212428092957, "eval/image_loss_std": 0.09544132649898529, "eval/model_loss_mean": 0.8245139718055725, "eval/model_loss_std": 0.32061612606048584, "eval/post_ent_mag": 52.71885681152344, "eval/post_ent_max": 52.71885681152344, "eval/post_ent_mean": 52.07373046875, "eval/post_ent_min": 51.31840133666992, "eval/post_ent_std": 0.31151455640792847, "eval/prior_ent_mag": 51.86634063720703, "eval/prior_ent_max": 51.86634063720703, "eval/prior_ent_mean": 46.719112396240234, "eval/prior_ent_min": 44.09797668457031, "eval/prior_ent_std": 0.9568802118301392, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0015657143667340279, "eval/reward_loss_std": 0.0016451175324618816, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.001067519187927246, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015657143667340279, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002757456386461854, "eval/reward_rate": 0.0, "replay/size": 216481.0, "replay/inserts": 30976.0, "replay/samples": 30976.0, "replay/insert_wait_avg": 1.3151506254495668e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.861859408291904e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 51920.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1542126656678584e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1622905731201172e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3396356105804, "timer/env.step_count": 3872.0, "timer/env.step_total": 37.259310483932495, "timer/env.step_frac": 0.03724666019175619, "timer/env.step_avg": 0.009622755806800748, "timer/env.step_min": 0.007821321487426758, "timer/env.step_max": 0.03790640830993652, "timer/replay._sample_count": 30976.0, "timer/replay._sample_total": 16.261778116226196, "timer/replay._sample_frac": 0.01625625691248397, "timer/replay._sample_avg": 0.0005249799236901535, "timer/replay._sample_min": 0.0003604888916015625, "timer/replay._sample_max": 0.009873628616333008, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4739.0, "timer/agent.policy_total": 48.16551494598389, "timer/agent.policy_frac": 0.04814916177602515, "timer/agent.policy_avg": 0.010163645272416942, "timer/agent.policy_min": 0.008764982223510742, "timer/agent.policy_max": 0.08899998664855957, "timer/dataset_train_count": 1936.0, "timer/dataset_train_total": 0.2207789421081543, "timer/dataset_train_frac": 0.00022070398317607077, "timer/dataset_train_avg": 0.00011403870976660863, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0010755062103271484, "timer/agent.train_count": 1936.0, "timer/agent.train_total": 865.8030853271484, "timer/agent.train_frac": 0.865509127606131, "timer/agent.train_avg": 0.44721233746237005, "timer/agent.train_min": 0.43677711486816406, "timer/agent.train_max": 1.247493028640747, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4757041931152344, "timer/agent.report_frac": 0.0004755426818861149, "timer/agent.report_avg": 0.2378520965576172, "timer/agent.report_min": 0.2317206859588623, "timer/agent.report_max": 0.24398350715637207, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.2413917837036613e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 30.96496839631422}
{"step": 216992, "time": 7206.563695430756, "episode/length": 288.0, "episode/score": 0.09796293660133415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09796293660133415}
{"step": 217264, "time": 7215.602232456207, "episode/length": 288.0, "episode/score": 0.09907913629956511, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09907913629956511}
{"step": 217592, "time": 7225.84738779068, "episode/length": 288.0, "episode/score": 0.12480662017605937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12480662017605937}
{"step": 218000, "time": 7238.961990356445, "episode/length": 288.0, "episode/score": 0.10978323292169989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10978323292169989}
{"step": 218504, "time": 7254.78190946579, "episode/length": 288.0, "episode/score": 0.09794384864829908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09794384864829908}
{"step": 218816, "time": 7264.8938200473785, "episode/length": 288.0, "episode/score": 0.11788048794653605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11788048794653605}
{"step": 219072, "time": 7273.008695602417, "episode/length": 288.0, "episode/score": 0.10790052863444544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10790052863444544}
{"step": 219248, "time": 7278.553813934326, "episode/length": 288.0, "episode/score": 0.10161210082787875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10161210082787875}
{"step": 219304, "time": 7280.10112953186, "episode/length": 288.0, "episode/score": 0.0895879108969666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0895879108969666}
{"step": 219576, "time": 7288.808734178543, "episode/length": 288.0, "episode/score": 0.09864490876390164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09864490876390164}
{"step": 219904, "time": 7299.385466814041, "episode/length": 288.0, "episode/score": 0.09948352883282041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09948352883282041}
{"step": 220064, "time": 7309.590270519257, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7309.61896944046, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7309.639852046967, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7309.666040658951, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7309.683667898178, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7309.710627555847, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7309.7358984947205, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7309.76264500618, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220312, "time": 7317.499995708466, "episode/length": 288.0, "episode/score": 0.09770490703704127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09770490703704127}
{"step": 220816, "time": 7333.512562274933, "episode/length": 288.0, "episode/score": 0.10180968986333028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10180968986333028}
{"step": 221128, "time": 7343.214682817459, "episode/length": 288.0, "episode/score": 0.1242316803761696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1242316803761696}
{"step": 221384, "time": 7351.84669137001, "episode/length": 288.0, "episode/score": 0.11665875727680941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11665875727680941}
{"step": 221560, "time": 7357.425277471542, "episode/length": 288.0, "episode/score": 0.07955953592818332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07955953592818332}
{"step": 221616, "time": 7359.4213082790375, "episode/length": 288.0, "episode/score": 0.111326251887931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.111326251887931}
{"step": 221888, "time": 7367.994387626648, "episode/length": 288.0, "episode/score": 0.12222759462974864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12222759462974864}
{"step": 222216, "time": 7378.3262667655945, "episode/length": 288.0, "episode/score": 0.10936159575658166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10936159575658166}
{"step": 222624, "time": 7391.424406051636, "episode/length": 288.0, "episode/score": 0.08895735016335493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08895735016335493}
{"step": 223128, "time": 7407.247508049011, "episode/length": 288.0, "episode/score": 0.06823729471727802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06823729471727802}
{"step": 223440, "time": 7417.3210027217865, "episode/length": 288.0, "episode/score": 0.09196934964211323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09196934964211323}
{"step": 223696, "time": 7425.381975412369, "episode/length": 288.0, "episode/score": 0.10288952863504619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10288952863504619}
{"step": 223872, "time": 7431.004557847977, "episode/length": 288.0, "episode/score": 0.12884495811169927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12884495811169927}
{"step": 223928, "time": 7432.548611164093, "episode/length": 288.0, "episode/score": 0.10207382301541656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10207382301541656}
{"step": 224200, "time": 7441.090603590012, "episode/length": 288.0, "episode/score": 0.11110915379424569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11110915379424569}
{"step": 224528, "time": 7451.634986400604, "episode/length": 288.0, "episode/score": 0.10175675267464612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10175675267464612}
{"step": 224936, "time": 7464.464422464371, "episode/length": 288.0, "episode/score": 0.09104925515680407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09104925515680407}
{"step": 225440, "time": 7480.529758214951, "episode/length": 288.0, "episode/score": 0.07861597739622539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07861597739622539}
{"step": 225752, "time": 7490.149988889694, "episode/length": 288.0, "episode/score": 0.09701509345813975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09701509345813975}
{"step": 226008, "time": 7498.348113059998, "episode/length": 288.0, "episode/score": 0.13624938692134947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13624938692134947}
{"step": 226184, "time": 7503.921492576599, "episode/length": 288.0, "episode/score": 0.11210953340014385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11210953340014385}
{"step": 226240, "time": 7505.926779747009, "episode/length": 288.0, "episode/score": 0.07990479152670105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07990479152670105}
{"step": 226512, "time": 7514.568812847137, "episode/length": 288.0, "episode/score": 0.07380108455066647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07380108455066647}
{"step": 226840, "time": 7524.797260761261, "episode/length": 288.0, "episode/score": 0.11932771995668645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11932771995668645}
{"step": 227248, "time": 7537.8752155303955, "episode/length": 288.0, "episode/score": 0.08413507353549221, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08413507353549221}
{"step": 227752, "time": 7553.638896942139, "episode/length": 288.0, "episode/score": 0.08734488773825433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08734488773825433}
{"step": 228064, "time": 7563.731803417206, "episode/length": 288.0, "episode/score": 0.12264440499859575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12264440499859575}
{"step": 228320, "time": 7571.84339928627, "episode/length": 288.0, "episode/score": 0.12149056456996732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12149056456996732}
{"step": 228496, "time": 7577.40375161171, "episode/length": 288.0, "episode/score": 0.09111325428136752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09111325428136752}
{"step": 228552, "time": 7578.960310459137, "episode/length": 288.0, "episode/score": 0.10806137972917895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10806137972917895}
{"step": 228824, "time": 7587.670570373535, "episode/length": 288.0, "episode/score": 0.13704139036053675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13704139036053675}
{"step": 229152, "time": 7598.210974693298, "episode/length": 288.0, "episode/score": 0.09513536199619921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09513536199619921}
{"step": 229560, "time": 7611.484700679779, "episode/length": 288.0, "episode/score": 0.11760292008807482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11760292008807482}
{"step": 230048, "time": 7632.177454710007, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7632.222232580185, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7632.251204967499, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7632.268927097321, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7632.282639741898, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7632.297860383987, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7632.310425281525, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7632.327036857605, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230064, "time": 7632.844318389893, "episode/length": 288.0, "episode/score": 0.10236046524732956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10236046524732956}
{"step": 230376, "time": 7642.590543270111, "episode/length": 288.0, "episode/score": 0.095471754938103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.095471754938103}
{"step": 230632, "time": 7650.638508796692, "episode/length": 288.0, "episode/score": 0.11319320615336892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11319320615336892}
{"step": 230808, "time": 7656.1650450229645, "episode/length": 288.0, "episode/score": 0.07065870235589955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07065870235589955}
{"step": 230864, "time": 7658.159207820892, "episode/length": 288.0, "episode/score": 0.12806376776995876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12806376776995876}
{"step": 231136, "time": 7666.701356172562, "episode/length": 288.0, "episode/score": 0.05323142441034179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05323142441034179}
{"step": 231464, "time": 7676.865376472473, "episode/length": 288.0, "episode/score": 0.14104245503153834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14104245503153834}
{"step": 231872, "time": 7689.918645143509, "episode/length": 288.0, "episode/score": 0.11713120173010338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11713120173010338}
{"step": 232376, "time": 7705.7014055252075, "episode/length": 288.0, "episode/score": 0.10241342230403916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10241342230403916}
{"step": 232688, "time": 7715.744988679886, "episode/length": 288.0, "episode/score": 0.09724992370513519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09724992370513519}
{"step": 232944, "time": 7723.867387533188, "episode/length": 288.0, "episode/score": 0.08861556459635267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08861556459635267}
{"step": 233120, "time": 7729.436173200607, "episode/length": 288.0, "episode/score": 0.10797181445695969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10797181445695969}
{"step": 233176, "time": 7731.077818393707, "episode/length": 288.0, "episode/score": 0.12901893296304934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12901893296304934}
{"step": 233448, "time": 7739.654417037964, "episode/length": 288.0, "episode/score": 0.07907334366746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07907334366746}
{"step": 233776, "time": 7750.232896327972, "episode/length": 288.0, "episode/score": 0.11701379615249152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11701379615249152}
{"step": 234184, "time": 7762.97953414917, "episode/length": 288.0, "episode/score": 0.10746956986645273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10746956986645273}
{"step": 234688, "time": 7779.099534988403, "episode/length": 288.0, "episode/score": 0.14708078801027114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14708078801027114}
{"step": 235000, "time": 7788.732124090195, "episode/length": 288.0, "episode/score": 0.08754717814815649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08754717814815649}
{"step": 235064, "time": 7790.850624799728, "episode/length": 235.0, "episode/score": 0.3803002791769359, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.11467528034108909}
{"step": 235256, "time": 7796.9099817276, "episode/length": 288.0, "episode/score": 0.12063309407972156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12063309407972156}
{"step": 235432, "time": 7802.471623420715, "episode/length": 288.0, "episode/score": 0.13226407388719963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13226407388719963}
{"step": 235760, "time": 7813.012680053711, "episode/length": 288.0, "episode/score": 0.1195838951573478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1195838951573478}
{"step": 236088, "time": 7823.261148929596, "episode/length": 288.0, "episode/score": 0.11523199807788842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11523199807788842}
{"step": 236496, "time": 7836.418976545334, "episode/length": 288.0, "episode/score": 0.140760385264457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.140760385264457}
{"step": 237000, "time": 7852.197141647339, "episode/length": 288.0, "episode/score": 0.09025355280709846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09025355280709846}
{"step": 237312, "time": 7862.266436338425, "episode/length": 288.0, "episode/score": 0.10138143640938324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10138143640938324}
{"step": 237376, "time": 7864.288756132126, "episode/length": 288.0, "episode/score": 0.10029254232961193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10029254232961193}
{"step": 237568, "time": 7870.524978876114, "episode/length": 288.0, "episode/score": 0.11627412325913156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11627412325913156}
{"step": 237744, "time": 7876.411042690277, "episode/length": 288.0, "episode/score": 0.04459472011649268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04459472011649268}
{"step": 238072, "time": 7886.649396657944, "episode/length": 288.0, "episode/score": 0.09365861260960173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09365861260960173}
{"step": 238400, "time": 7897.24329996109, "episode/length": 288.0, "episode/score": 0.12187262876182103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12187262876182103}
{"step": 238808, "time": 7909.898255586624, "episode/length": 288.0, "episode/score": 0.0811538133399381, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0811538133399381}
{"step": 239312, "time": 7926.122448205948, "episode/length": 288.0, "episode/score": 0.10870977952527028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10870977952527028}
{"step": 239624, "time": 7935.742536783218, "episode/length": 288.0, "episode/score": 0.074955301172281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.074955301172281}
{"step": 239688, "time": 7937.77717757225, "episode/length": 288.0, "episode/score": 0.12335295620243869, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12335295620243869}
{"step": 239880, "time": 7944.005251646042, "episode/length": 288.0, "episode/score": 0.09373684676359062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09373684676359062}
{"step": 240032, "time": 7954.829057693481, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7954.8466284275055, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7954.862326145172, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7954.879578590393, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7954.896661043167, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7954.913475036621, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7954.93446803093, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7954.957319974899, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240056, "time": 7955.494642019272, "episode/length": 288.0, "episode/score": 0.08073155142938049, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08073155142938049}
{"step": 240384, "time": 7966.160537958145, "episode/length": 288.0, "episode/score": 0.06395579250443006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06395579250443006}
{"step": 240712, "time": 7976.424167871475, "episode/length": 288.0, "episode/score": 0.12030856974666904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12030856974666904}
{"step": 241120, "time": 7989.61868929863, "episode/length": 288.0, "episode/score": 0.07975841918567994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07975841918567994}
{"step": 241624, "time": 8005.433440446854, "episode/length": 288.0, "episode/score": 0.12517259466812902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12517259466812902}
{"step": 241936, "time": 8015.561598062515, "episode/length": 288.0, "episode/score": 0.09383704104527624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09383704104527624}
{"step": 242000, "time": 8017.581700801849, "episode/length": 288.0, "episode/score": 0.09670879075872563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09670879075872563}
{"step": 242192, "time": 8023.6683077812195, "episode/length": 288.0, "episode/score": 0.09783646971493454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09783646971493454}
{"step": 242368, "time": 8029.206186771393, "episode/length": 288.0, "episode/score": 0.1014414413010627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1014414413010627}
{"step": 242696, "time": 8039.436136722565, "episode/length": 288.0, "episode/score": 0.08124077658419537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08124077658419537}
{"step": 243024, "time": 8050.021347045898, "episode/length": 288.0, "episode/score": 0.041953260071409204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041953260071409204}
{"step": 243432, "time": 8062.7398138046265, "episode/length": 288.0, "episode/score": 0.09971245725751032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09971245725751032}
{"step": 243936, "time": 8078.868133306503, "episode/length": 288.0, "episode/score": 0.1082159603636228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1082159603636228}
{"step": 244152, "time": 8085.460084438324, "episode/length": 89.0, "episode/score": 0.7773926991580993, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.05551765859900115}
{"step": 244248, "time": 8088.471624612808, "episode/length": 288.0, "episode/score": 0.08451050480198319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08451050480198319}
{"step": 244312, "time": 8090.540911436081, "episode/length": 288.0, "episode/score": 0.11143607608710226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11143607608710226}
{"step": 244504, "time": 8096.685194730759, "episode/length": 288.0, "episode/score": 0.07991252656074721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07991252656074721}
{"step": 244680, "time": 8102.233225822449, "episode/length": 288.0, "episode/score": 0.09825135607218272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09825135607218272}
{"step": 245008, "time": 8112.844962120056, "episode/length": 288.0, "episode/score": 0.14054187925410133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14054187925410133}
{"step": 245336, "time": 8123.1735227108, "episode/length": 288.0, "episode/score": 0.1203097091786276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1203097091786276}
{"step": 246248, "time": 8152.5174124240875, "episode/length": 288.0, "episode/score": 0.1076034340901515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1076034340901515}
{"step": 246464, "time": 8159.548454523087, "episode/length": 288.0, "episode/score": 0.11562135611757185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11562135611757185}
{"step": 246560, "time": 8162.580530881882, "episode/length": 288.0, "episode/score": 0.09566087933626477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09566087933626477}
{"step": 246624, "time": 8164.60338973999, "episode/length": 288.0, "episode/score": 0.10382330972004183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10382330972004183}
{"step": 246816, "time": 8170.6784591674805, "episode/length": 288.0, "episode/score": 0.0722680443484478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0722680443484478}
{"step": 246992, "time": 8176.245234251022, "episode/length": 288.0, "episode/score": 0.11623267082961775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11623267082961775}
{"step": 247320, "time": 8186.520530939102, "episode/length": 288.0, "episode/score": 0.074493361194925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.074493361194925}
{"step": 247648, "time": 8197.057030916214, "episode/length": 288.0, "episode/score": 0.08882363209198729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08882363209198729}
{"step": 247929, "time": 8206.63681268692, "train_stats/mean_log_entropy": 1.6549301622090515, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1564795933856864, "train/action_min": 0.0, "train/action_std": 1.7888885890881632, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0007699470929505901, "train/actor_opt_grad_steps": 14430.0, "train/actor_opt_loss": 2.442181688477647, "train/adv_mag": 0.003672971201993023, "train/adv_max": 0.0036595062270683328, "train/adv_mean": 0.0005470553375315374, "train/adv_min": -0.0017244142571879175, "train/adv_std": 0.0006680573064440601, "train/cont_avg": 0.9964327639248705, "train/cont_loss_mean": 0.023677810291889957, "train/cont_loss_std": 0.3270831707228033, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6682509751844155, "train/cont_pos_acc": 0.9999999857937116, "train/cont_pos_loss": 0.003484265685776355, "train/cont_pred": 0.996521881824948, "train/cont_rate": 0.9964327639248705, "train/dyn_loss_mean": 1.0000022686824896, "train/dyn_loss_std": 6.320885620248827e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.07361110349950607, "train/extr_critic_critic_opt_grad_steps": 14430.0, "train/extr_critic_critic_opt_loss": 12641.322235265545, "train/extr_critic_mag": 0.1079015565042051, "train/extr_critic_max": 0.1079015565042051, "train/extr_critic_mean": 0.10703002730953878, "train/extr_critic_min": 0.10524343579544304, "train/extr_critic_std": 0.0003643507239531841, "train/extr_return_normed_mag": 0.005331574480768313, "train/extr_return_normed_max": 0.005331574480768313, "train/extr_return_normed_mean": 0.0021673254689070216, "train/extr_return_normed_min": -0.00016841192010770808, "train/extr_return_normed_std": 0.000724576006781001, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.11074135217024254, "train/extr_return_raw_max": 0.11074135217024254, "train/extr_return_raw_mean": 0.10757710819417331, "train/extr_return_raw_min": 0.10524136576936653, "train/extr_return_raw_std": 0.0007245760046698423, "train/extr_reward_mag": 0.0012614578780732624, "train/extr_reward_max": 0.0012614578780732624, "train/extr_reward_mean": 0.00042396864459917454, "train/extr_reward_min": 3.52674197656503e-05, "train/extr_reward_std": 0.00026716944923530297, "train/image_loss_mean": 0.19939496248497246, "train/image_loss_std": 0.0980715926524271, "train/model_loss_mean": 0.8339056916187464, "train/model_loss_std": 0.3719044211537727, "train/model_opt_grad_norm": 40.31437537830728, "train/model_opt_grad_steps": 14415.015544041451, "train/model_opt_loss": 2278.7823410429487, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2733.160621761658, "train/policy_entropy_mag": 1.901337891045012, "train/policy_entropy_max": 1.901337891045012, "train/policy_entropy_mean": 1.6529042239016203, "train/policy_entropy_min": 1.2093712699845665, "train/policy_entropy_std": 0.09300383377260495, "train/policy_logprob_mag": 3.69726874297147, "train/policy_logprob_max": -0.41966028194971033, "train/policy_logprob_mean": -1.652632294541196, "train/policy_logprob_min": -3.69726874297147, "train/policy_logprob_std": 0.7464877434962772, "train/policy_randomness_mag": 0.9770944476745289, "train/policy_randomness_max": 0.9770944476745289, "train/policy_randomness_mean": 0.8494247933125867, "train/policy_randomness_min": 0.6214939286362939, "train/policy_randomness_std": 0.04779451884753964, "train/post_ent_mag": 44.166222132549386, "train/post_ent_max": 44.166222132549386, "train/post_ent_mean": 43.596495475176084, "train/post_ent_min": 42.91194225963533, "train/post_ent_std": 0.23476846215020808, "train/prior_ent_mag": 46.11512708911006, "train/prior_ent_max": 46.11512708911006, "train/prior_ent_mean": 43.39619115720759, "train/prior_ent_min": 40.77871296936984, "train/prior_ent_std": 0.9739600895599998, "train/rep_loss_mean": 1.0000022686824896, "train/rep_loss_std": 6.320885620248827e-05, "train/reward_avg": 0.00028706425010742995, "train/reward_loss_mean": 0.010831536556270765, "train/reward_loss_std": 0.05179483990228392, "train/reward_max_data": 0.07023316174335392, "train/reward_max_pred": 0.0010801522842960654, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009603047545593947, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.006460208159227, "train/reward_pred": 0.0002694496362581077, "train/reward_rate": 0.0001366175518134715, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02556154504418373, "report/cont_loss_std": 0.3477075695991516, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.578005790710449, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0037872574757784605, "report/cont_pred": 0.9962196946144104, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1876813769340515, "report/image_loss_std": 0.09494619816541672, "report/model_loss_mean": 0.8227505683898926, "report/model_loss_std": 0.36200594902038574, "report/post_ent_mag": 40.02197265625, "report/post_ent_max": 40.02197265625, "report/post_ent_mean": 39.470237731933594, "report/post_ent_min": 38.923526763916016, "report/post_ent_std": 0.2034466564655304, "report/prior_ent_mag": 42.83580017089844, "report/prior_ent_max": 42.83580017089844, "report/prior_ent_mean": 40.848838806152344, "report/prior_ent_min": 38.708431243896484, "report/prior_ent_std": 0.8281803727149963, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.000212158149224706, "report/reward_loss_mean": 0.009507579728960991, "report/reward_loss_std": 0.015506039373576641, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0014014244079589844, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009507578797638416, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002693524584174156, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020117972046136856, "eval/cont_loss_std": 0.3012711703777313, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.578005790710449, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0037872574757784605, "eval/cont_pred": 0.9962196946144104, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2314346432685852, "eval/image_loss_std": 0.11090631037950516, "eval/model_loss_mean": 0.8529466390609741, "eval/model_loss_std": 0.3268267810344696, "eval/post_ent_mag": 39.975833892822266, "eval/post_ent_max": 39.975833892822266, "eval/post_ent_mean": 39.47678756713867, "eval/post_ent_min": 38.905799865722656, "eval/post_ent_std": 0.20344936847686768, "eval/prior_ent_mag": 43.43266677856445, "eval/prior_ent_max": 43.43266677856445, "eval/prior_ent_mean": 40.87538528442383, "eval/prior_ent_min": 38.910037994384766, "eval/prior_ent_std": 0.7901517748832703, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013939440250396729, "eval/reward_loss_std": 0.0016133239259943366, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0013132095336914062, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013939440250396729, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00025308248586952686, "eval/reward_rate": 0.0, "replay/size": 247425.0, "replay/inserts": 30944.0, "replay/samples": 30944.0, "replay/insert_wait_avg": 1.3342780189159121e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.813809222248003e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 58856.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1071201839249026e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0821330547333, "timer/env.step_count": 3868.0, "timer/env.step_total": 37.20609211921692, "timer/env.step_frac": 0.03720303652018216, "timer/env.step_avg": 0.009618948324513163, "timer/env.step_min": 0.007917642593383789, "timer/env.step_max": 0.044692039489746094, "timer/replay._sample_count": 30944.0, "timer/replay._sample_total": 16.272309064865112, "timer/replay._sample_frac": 0.016270972680175407, "timer/replay._sample_avg": 0.0005258631419617733, "timer/replay._sample_min": 0.0003921985626220703, "timer/replay._sample_max": 0.025897979736328125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4735.0, "timer/agent.policy_total": 47.676833391189575, "timer/agent.policy_frac": 0.04767291786881696, "timer/agent.policy_avg": 0.010069025003419128, "timer/agent.policy_min": 0.008806943893432617, "timer/agent.policy_max": 0.08733320236206055, "timer/dataset_train_count": 1934.0, "timer/dataset_train_total": 0.217818021774292, "timer/dataset_train_frac": 0.00021780013318403228, "timer/dataset_train_avg": 0.00011262565758753464, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.00034809112548828125, "timer/agent.train_count": 1934.0, "timer/agent.train_total": 866.255823135376, "timer/agent.train_frac": 0.8661846807415835, "timer/agent.train_avg": 0.447908905447454, "timer/agent.train_min": 0.4382305145263672, "timer/agent.train_max": 0.5986931324005127, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4719839096069336, "timer/agent.report_frac": 0.00047194514731031844, "timer/agent.report_avg": 0.2359919548034668, "timer/agent.report_min": 0.22652292251586914, "timer/agent.report_max": 0.24546098709106445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.743171691894531e-05, "timer/dataset_eval_frac": 3.742864279017844e-08, "timer/dataset_eval_avg": 3.743171691894531e-05, "timer/dataset_eval_min": 3.743171691894531e-05, "timer/dataset_eval_max": 3.743171691894531e-05, "fps": 30.94093200182127}
{"step": 248560, "time": 8226.673277378082, "episode/length": 288.0, "episode/score": 0.09110653109274836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09110653109274836}
{"step": 248776, "time": 8233.257276535034, "episode/length": 288.0, "episode/score": 0.09799701687370543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09799701687370543}
{"step": 248872, "time": 8236.288629293442, "episode/length": 288.0, "episode/score": 0.08061161471954392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08061161471954392}
{"step": 248936, "time": 8238.325027704239, "episode/length": 288.0, "episode/score": 0.11882474848891889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11882474848891889}
{"step": 249128, "time": 8244.499892234802, "episode/length": 288.0, "episode/score": 0.07697985952688668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07697985952688668}
{"step": 249304, "time": 8250.103048801422, "episode/length": 288.0, "episode/score": 0.06424341665064048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06424341665064048}
{"step": 249632, "time": 8260.708892583847, "episode/length": 288.0, "episode/score": 0.08622232589692658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08622232589692658}
{"step": 249880, "time": 8268.320585250854, "episode/length": 125.0, "episode/score": 0.6467041266586762, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.03732909802050699}
{"step": 249960, "time": 8270.94006228447, "episode/length": 288.0, "episode/score": 0.09067648660641225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09067648660641225}
{"step": 250016, "time": 8277.278091669083, "eval_episode/length": 237.0, "eval_episode/score": 0.2593750059604645, "eval_episode/reward_rate": 0.004201680672268907}
{"step": 250016, "time": 8278.220584154129, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8278.24231171608, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8278.26211309433, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8278.284561395645, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8278.304914951324, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8278.328846931458, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8278.343437671661, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250064, "time": 8279.864938497543, "episode/length": 160.0, "episode/score": 0.5531961306850235, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.05319613149993074}
{"step": 250360, "time": 8288.945976734161, "episode/length": 49.0, "episode/score": 0.8608901797791191, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.01401515353910554}
{"step": 250872, "time": 8305.145762681961, "episode/length": 288.0, "episode/score": 0.06831106918724572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06831106918724572}
{"step": 251248, "time": 8317.295997619629, "episode/length": 288.0, "episode/score": 0.08225727388833093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08225727388833093}
{"step": 251440, "time": 8323.43446278572, "episode/length": 288.0, "episode/score": 0.06307237426216261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06307237426216261}
{"step": 251616, "time": 8328.983884572983, "episode/length": 288.0, "episode/score": 0.06275138057543472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06275138057543472}
{"step": 251944, "time": 8339.227734327316, "episode/length": 288.0, "episode/score": 0.05076075482656961, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05076075482656961}
{"step": 252192, "time": 8347.271364450455, "episode/length": 288.0, "episode/score": 0.036144534539488404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036144534539488404}
{"step": 252216, "time": 8347.807074308395, "episode/length": 96.0, "episode/score": 0.7329751706325851, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.03297515391534489}
{"step": 252376, "time": 8352.834997653961, "episode/length": 288.0, "episode/score": 0.04971369923444513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04971369923444513}
{"step": 252656, "time": 8361.944333791733, "episode/length": 57.0, "episode/score": 0.8621418513478432, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.04026686087061648}
{"step": 252672, "time": 8362.460478782654, "episode/length": 288.0, "episode/score": 0.06624564957562029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06624564957562029}
{"step": 253184, "time": 8378.620009183884, "episode/length": 288.0, "episode/score": 0.07947979898713697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07947979898713697}
{"step": 253560, "time": 8390.271801710129, "episode/length": 288.0, "episode/score": 0.06707679177227988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06707679177227988}
{"step": 253624, "time": 8392.46437907219, "episode/length": 118.0, "episode/score": 0.6609458283984395, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.02969578121530958}
{"step": 253928, "time": 8402.027366399765, "episode/length": 288.0, "episode/score": 0.09874695330029226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09874695330029226}
{"step": 254256, "time": 8413.056625366211, "episode/length": 288.0, "episode/score": 0.09277845403403262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09277845403403262}
{"step": 254528, "time": 8421.723403692245, "episode/length": 288.0, "episode/score": 0.09549790769045785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09549790769045785}
{"step": 254688, "time": 8426.76927781105, "episode/length": 288.0, "episode/score": 0.062455908434856156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062455908434856156}
{"step": 254968, "time": 8435.316766738892, "episode/length": 288.0, "episode/score": 0.06052227329868742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06052227329868742}
{"step": 255496, "time": 8451.987851858139, "episode/length": 288.0, "episode/score": 0.05717426015513638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05717426015513638}
{"step": 255872, "time": 8463.999804496765, "episode/length": 288.0, "episode/score": 0.06298836325274237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06298836325274237}
{"step": 255936, "time": 8466.025353431702, "episode/length": 288.0, "episode/score": 0.0887506010211041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0887506010211041}
{"step": 256240, "time": 8475.576011180878, "episode/length": 288.0, "episode/score": 0.06479938096703108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06479938096703108}
{"step": 256568, "time": 8485.75322341919, "episode/length": 288.0, "episode/score": 0.07244942895857776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07244942895857776}
{"step": 256840, "time": 8494.308031320572, "episode/length": 288.0, "episode/score": 0.08037754781909712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08037754781909712}
{"step": 257000, "time": 8499.3372797966, "episode/length": 288.0, "episode/score": 0.07365780413348944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07365780413348944}
{"step": 257280, "time": 8508.371677398682, "episode/length": 288.0, "episode/score": 0.09457650727154032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09457650727154032}
{"step": 257808, "time": 8525.03948044777, "episode/length": 288.0, "episode/score": 0.09977553125432337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09977553125432337}
{"step": 258184, "time": 8536.630636930466, "episode/length": 288.0, "episode/score": 0.06222269814810488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06222269814810488}
{"step": 258248, "time": 8538.657818555832, "episode/length": 288.0, "episode/score": 0.057606166038169704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057606166038169704}
{"step": 258552, "time": 8548.278775453568, "episode/length": 288.0, "episode/score": 0.045437992267522986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045437992267522986}
{"step": 258688, "time": 8552.774456501007, "episode/length": 264.0, "episode/score": 0.23712108521874597, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.06212108860643184}
{"step": 258936, "time": 8560.355603218079, "episode/length": 261.0, "episode/score": 0.20475530935161146, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.020380299211836927}
{"step": 259072, "time": 8564.932160377502, "episode/length": 258.0, "episode/score": 0.24355198415952373, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.04980199128414142}
{"step": 259080, "time": 8564.970451593399, "episode/length": 111.0, "episode/score": 0.686168464292308, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.03304346905369471}
{"step": 259272, "time": 8571.208686590195, "episode/length": 24.0, "episode/score": 0.9411978101785508, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.016197783938537214}
{"step": 259592, "time": 8581.304707050323, "episode/length": 288.0, "episode/score": 0.034919222935059224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034919222935059224}
{"step": 259872, "time": 8590.337978601456, "episode/length": 147.0, "episode/score": 0.5702172742791731, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.02959231625271741}
{"step": 260000, "time": 8595.848414182663, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 260000, "time": 8596.955623149872, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 260000, "time": 8597.955892086029, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 260000, "time": 8597.971363544464, "eval_episode/length": 202.0, "eval_episode/score": 0.3687500059604645, "eval_episode/reward_rate": 0.0049261083743842365}
{"step": 260000, "time": 8598.00065279007, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 260000, "time": 8598.731135368347, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 260000, "time": 8598.956879377365, "eval_episode/length": 253.0, "eval_episode/score": 0.20937499403953552, "eval_episode/reward_rate": 0.003937007874015748}
{"step": 260000, "time": 8599.195595502853, "eval_episode/length": 265.0, "eval_episode/score": 0.171875, "eval_episode/reward_rate": 0.0037593984962406013}
{"step": 260048, "time": 8600.823619365692, "episode/length": 224.0, "episode/score": 0.3513151986219043, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0513151875158826}
{"step": 260120, "time": 8602.887310266495, "episode/length": 288.0, "episode/score": 0.04158257413942579, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04158257413942579}
{"step": 260864, "time": 8626.558800935745, "episode/length": 288.0, "episode/score": 0.027629384763429243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027629384763429243}
{"step": 260944, "time": 8629.08281302452, "episode/length": 102.0, "episode/score": 0.7060914442056401, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0248414537284134}
{"step": 261016, "time": 8631.221825122833, "episode/length": 217.0, "episode/score": 0.3770874897942633, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.05521248499795206}
{"step": 261248, "time": 8638.74049282074, "episode/length": 288.0, "episode/score": 0.09135516439511093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09135516439511093}
{"step": 261392, "time": 8643.255758523941, "episode/length": 288.0, "episode/score": 0.058780791300819146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058780791300819146}
{"step": 261904, "time": 8659.32876253128, "episode/length": 288.0, "episode/score": 0.06727439311774219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06727439311774219}
{"step": 262040, "time": 8663.465839147568, "episode/length": 270.0, "episode/score": 0.22601065745652704, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.06976065862068026}
{"step": 262296, "time": 8672.015634536743, "episode/length": 159.0, "episode/score": 0.5573470314097904, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.05422199085069224}
{"step": 262328, "time": 8673.026513338089, "episode/length": 134.0, "episode/score": 0.6358296677224189, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.054579627163320765}
{"step": 262360, "time": 8674.0576338768, "episode/length": 288.0, "episode/score": 0.05170167069081799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05170167069081799}
{"step": 262528, "time": 8679.531684875488, "episode/length": 141.0, "episode/score": 0.6023969301882062, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.04302194292404238}
{"step": 262536, "time": 8679.566732168198, "episode/length": 25.0, "episode/score": 0.941570524521012, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.01969552533591923}
{"step": 262536, "time": 8679.57970738411, "episode/length": 78.0, "episode/score": 0.7695565486628766, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.013306501479746657}
{"step": 262576, "time": 8681.049224853516, "episode/length": 66.0, "episode/score": 0.8188481869258339, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.02509819966167015}
{"step": 262864, "time": 8690.089428186417, "episode/length": 249.0, "episode/score": 0.30556840038298105, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.08369340982426365}
{"step": 263096, "time": 8697.25458931923, "episode/length": 69.0, "episode/score": 0.8134246563649867, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.02904963012497319}
{"step": 263256, "time": 8703.160526037216, "episode/length": 288.0, "episode/score": 0.06767530226397866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06767530226397866}
{"step": 263776, "time": 8719.730150699615, "episode/length": 184.0, "episode/score": 0.4877972632644969, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.06279725780461831}
{"step": 264672, "time": 8748.250875711441, "episode/length": 288.0, "episode/score": 0.07096690534092431, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07096690534092431}
{"step": 264784, "time": 8751.921628952026, "episode/length": 190.0, "episode/score": 0.4731191595066093, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.06686916067076254}
{"step": 264840, "time": 8753.464240789413, "episode/length": 288.0, "episode/score": 0.07626841874343881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07626841874343881}
{"step": 264848, "time": 8753.947095394135, "episode/length": 288.0, "episode/score": 0.04327784398958556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04327784398958556}
{"step": 264864, "time": 8754.456087350845, "episode/length": 23.0, "episode/score": 0.9448749737139224, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.016749950686971715}
{"step": 264888, "time": 8754.995178222656, "episode/length": 288.0, "episode/score": 0.05854730893804572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05854730893804572}
{"step": 265176, "time": 8764.05730342865, "episode/length": 288.0, "episode/score": 0.04459896411560749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04459896411560749}
{"step": 265408, "time": 8771.618021965027, "episode/length": 288.0, "episode/score": 0.05874439401009113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05874439401009113}
{"step": 265816, "time": 8784.404476165771, "episode/length": 50.0, "episode/score": 0.8647185129739228, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0209684843357536}
{"step": 266088, "time": 8793.04928779602, "episode/length": 288.0, "episode/score": 0.06302716011032317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06302716011032317}
{"step": 266616, "time": 8809.621464729309, "episode/length": 99.0, "episode/score": 0.7215678941358874, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.030942883029865698}
{"step": 267096, "time": 8824.80586719513, "episode/length": 288.0, "episode/score": 0.04434361319499658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04434361319499658}
{"step": 267152, "time": 8826.799725532532, "episode/length": 288.0, "episode/score": 0.04351690091243654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04351690091243654}
{"step": 267160, "time": 8826.836145162582, "episode/length": 288.0, "episode/score": 0.05777608082587449, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05777608082587449}
{"step": 267176, "time": 8827.346858501434, "episode/length": 288.0, "episode/score": 0.04851496841934022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04851496841934022}
{"step": 267200, "time": 8828.331258296967, "episode/length": 288.0, "episode/score": 0.031939197889641946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031939197889641946}
{"step": 267488, "time": 8837.478504419327, "episode/length": 288.0, "episode/score": 0.037228348726671356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037228348726671356}
{"step": 267664, "time": 8843.186672449112, "episode/length": 60.0, "episode/score": 0.8331118504672759, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.020611836148191287}
{"step": 268152, "time": 8858.379007101059, "episode/length": 124.0, "episode/score": 0.6414316468866446, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.028931635780622855}
{"step": 268264, "time": 8861.878736972809, "episode/length": 74.0, "episode/score": 0.8004498797721453, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0316998392130472}
{"step": 268400, "time": 8866.377704620361, "episode/length": 288.0, "episode/score": 0.05009948185829671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05009948185829671}
{"step": 268576, "time": 8871.989467382431, "episode/length": 171.0, "episode/score": 0.5203869045909641, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.05476191732680036}
{"step": 268920, "time": 8882.591072320938, "episode/length": 64.0, "episode/score": 0.8322535074378266, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.032253481197813016}
{"step": 268928, "time": 8883.071514606476, "episode/length": 288.0, "episode/score": 0.05337259569989783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05337259569989783}
{"step": 269184, "time": 8891.145007610321, "episode/length": 128.0, "episode/score": 0.659574431888359, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.05957438470522902}
{"step": 269408, "time": 8898.225893974304, "episode/length": 288.0, "episode/score": 0.05612043166308922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05612043166308922}
{"step": 269464, "time": 8899.75853729248, "episode/length": 110.0, "episode/score": 0.6966307120114834, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.04038068261661465}
{"step": 269472, "time": 8900.236891269684, "episode/length": 288.0, "episode/score": 0.05322961840226981, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05322961840226981}
{"step": 269800, "time": 8910.419539690018, "episode/length": 288.0, "episode/score": 0.06422596642562439, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06422596642562439}
{"step": 270088, "time": 8920.089594364166, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 270088, "time": 8920.831236124039, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 270088, "time": 8920.85628914833, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 270088, "time": 8921.178610086441, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 270088, "time": 8922.274898052216, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 270088, "time": 8922.604442358017, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 270088, "time": 8922.755771875381, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 270088, "time": 8922.912193536758, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 270200, "time": 8926.45487356186, "episode/length": 158.0, "episode/score": 0.5442690591755763, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.03801900669554925}
{"step": 270520, "time": 8937.191912174225, "episode/length": 199.0, "episode/score": 0.42899999976907566, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.050874988663053955}
{"step": 270576, "time": 8939.165622711182, "episode/length": 288.0, "episode/score": 0.05812201275989537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05812201275989537}
{"step": 270856, "time": 8947.729399442673, "episode/length": 81.0, "episode/score": 0.7645579915592862, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.017682996320672828}
{"step": 270872, "time": 8948.235838651657, "episode/length": 175.0, "episode/score": 0.4922210279464707, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.03909602911062393}
{"step": 270872, "time": 8948.259156227112, "episode/length": 210.0, "episode/score": 0.40741336727387534, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.06366336808878259}
{"step": 271288, "time": 8961.450272798538, "episode/length": 95.0, "episode/score": 0.7310207621910649, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.027895747871980348}
{"step": 271392, "time": 8964.953310251236, "episode/length": 66.0, "episode/score": 0.8316704604867482, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.03792045808859257}
{"step": 271720, "time": 8975.089027404785, "episode/length": 288.0, "episode/score": 0.05600375178039485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05600375178039485}
{"step": 271768, "time": 8976.622109413147, "episode/length": 59.0, "episode/score": 0.831181180913859, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.015556187124616372}
{"step": 271776, "time": 8977.109593629837, "episode/length": 47.0, "episode/score": 0.870625273436417, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.01750029809318221}
{"step": 271784, "time": 8977.149006843567, "episode/length": 288.0, "episode/score": 0.049656440007311176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049656440007311176}
{"step": 271920, "time": 8981.649416923523, "episode/length": 130.0, "episode/score": 0.6237380959299799, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.029988114061666238}
{"step": 272096, "time": 8987.177589893341, "episode/length": 286.0, "episode/score": 0.17308962212257484, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.06683961815281236}
{"step": 272144, "time": 8988.698439598083, "episode/length": 158.0, "episode/score": 0.5461825368065547, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.03993250478652044}
{"step": 272320, "time": 8994.320531129837, "episode/length": 74.0, "episode/score": 0.790152016861839, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.021401975546041285}
{"step": 272752, "time": 9007.953039646149, "episode/length": 75.0, "episode/score": 0.7788704161002897, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.013245408940747438}
{"step": 272816, "time": 9009.958436250687, "episode/length": 279.0, "episode/score": 0.1799915490079229, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.05186655521868033}
{"step": 272912, "time": 9012.978573083878, "episode/length": 73.0, "episode/score": 0.8046768201493251, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.03280181443915353}
{"step": 273088, "time": 9018.512604475021, "episode/length": 145.0, "episode/score": 0.5841722583778619, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.03729722898299315}
{"step": 274072, "time": 9049.344438791275, "episode/length": 156.0, "episode/score": 0.5347633303148314, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.022263365344201702}
{"step": 274080, "time": 9049.823335409164, "episode/length": 288.0, "episode/score": 0.05245654803434263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05245654803434263}
{"step": 274088, "time": 9049.861721277237, "episode/length": 288.0, "episode/score": 0.052576775324780556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052576775324780556}
{"step": 274096, "time": 9050.341260910034, "episode/length": 288.0, "episode/score": 0.03985884432148623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03985884432148623}
{"step": 274408, "time": 9059.996430158615, "episode/length": 288.0, "episode/score": 0.02084321085959573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02084321085959573}
{"step": 274640, "time": 9067.523518323898, "episode/length": 67.0, "episode/score": 0.8078963525150584, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.017271369197374042}
{"step": 274648, "time": 9067.562304496765, "episode/length": 70.0, "episode/score": 0.7987282022151021, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.017478222354952777}
{"step": 275040, "time": 9080.11384153366, "episode/length": 78.0, "episode/score": 0.7759923367223678, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.01974232495859951}
{"step": 275064, "time": 9080.723731517792, "episode/length": 288.0, "episode/score": 0.06266398120959593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06266398120959593}
{"step": 275160, "time": 9083.771252155304, "episode/length": 64.0, "episode/score": 0.8193277345587262, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.019327742777647927}
{"step": 275224, "time": 9085.792327165604, "episode/length": 288.0, "episode/score": 0.04201338691336787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04201338691336787}
{"step": 275400, "time": 9091.327798128128, "episode/length": 288.0, "episode/score": 0.0325168490417127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0325168490417127}
{"step": 275488, "time": 9094.334707736969, "episode/length": 40.0, "episode/score": 0.8930172448176563, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.018017264957506995}
{"step": 275848, "time": 9105.43854022026, "episode/length": 55.0, "episode/score": 0.8464763112783658, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.01835133438680714}
{"step": 275896, "time": 9106.94746208191, "episode/length": 106.0, "episode/score": 0.6872065212787106, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.018456548304527587}
{"step": 276384, "time": 9122.623156309128, "episode/length": 288.0, "episode/score": 0.02658562356867833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02658562356867833}
{"step": 276400, "time": 9123.139237880707, "episode/length": 288.0, "episode/score": 0.034531122828298066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034531122828298066}
{"step": 276408, "time": 9123.17762184143, "episode/length": 69.0, "episode/score": 0.7931777173479304, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.008802719586014973}
{"step": 276656, "time": 9131.221547842026, "episode/length": 33.0, "episode/score": 0.9083104830656339, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.011435444904691394}
{"step": 276720, "time": 9133.2402780056, "episode/length": 102.0, "episode/score": 0.7075347186753334, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.026284768739742503}
{"step": 276960, "time": 9140.917313814163, "episode/length": 288.0, "episode/score": 0.050449159410050015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050449159410050015}
{"step": 277088, "time": 9144.93876171112, "episode/length": 45.0, "episode/score": 0.8798032498269208, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.020428226485648793}
{"step": 277376, "time": 9154.033823728561, "episode/length": 288.0, "episode/score": 0.04411458338643115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04411458338643115}
{"step": 277528, "time": 9158.58604836464, "episode/length": 54.0, "episode/score": 0.8503336046364325, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.019083563320634767}
{"step": 277536, "time": 9159.064097166061, "episode/length": 288.0, "episode/score": 0.042001092756947855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042001092756947855}
{"step": 277800, "time": 9167.165010213852, "episode/length": 288.0, "episode/score": 0.06844518937140265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06844518937140265}
{"step": 278712, "time": 9196.372463464737, "episode/length": 288.0, "episode/score": 0.048274583082729805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048274583082729805}
{"step": 278720, "time": 9196.850132226944, "episode/length": 288.0, "episode/score": 0.08848365645036438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08848365645036438}
{"step": 278968, "time": 9204.4954559803, "episode/length": 288.0, "episode/score": 0.062255598750766694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062255598750766694}
{"step": 279017, "time": 9207.014658927917, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.463295648036859, "train/action_min": 0.0, "train/action_std": 1.6063818888786512, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0024922380229840295, "train/actor_opt_grad_steps": 16370.0, "train/actor_opt_loss": 19.216895994849693, "train/adv_mag": 0.014976801092808063, "train/adv_max": 0.014926811899894324, "train/adv_mean": 0.0036782099794669568, "train/adv_min": -0.003031568840528146, "train/adv_std": 0.0025684286574594296, "train/cont_avg": 0.9963541666666667, "train/cont_loss_mean": 0.024158513703598426, "train/cont_loss_std": 0.32885288845497995, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.643726207315922, "train/cont_pos_acc": 0.999999984105428, "train/cont_pos_loss": 0.0035672862440920793, "train/cont_pred": 0.9964391503578577, "train/cont_rate": 0.9963541666666667, "train/dyn_loss_mean": 1.0000004487159924, "train/dyn_loss_std": 1.4346131744484106e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3319963108855658, "train/extr_critic_critic_opt_grad_steps": 16370.0, "train/extr_critic_critic_opt_loss": 7877.6884915865385, "train/extr_critic_mag": 0.16773517376337296, "train/extr_critic_max": 0.16773517376337296, "train/extr_critic_mean": 0.16561751102025693, "train/extr_critic_min": 0.16211771231431227, "train/extr_critic_std": 0.0009863416938363419, "train/extr_return_normed_mag": 0.021960935302269766, "train/extr_return_normed_max": 0.021960935302269766, "train/extr_return_normed_mean": 0.010147055656505716, "train/extr_return_normed_min": 0.002961098918547997, "train/extr_return_normed_std": 0.002852707280096813, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.1811095974002129, "train/extr_return_raw_max": 0.1811095974002129, "train/extr_return_raw_mean": 0.16929572560848333, "train/extr_return_raw_min": 0.16210976101649113, "train/extr_return_raw_std": 0.002852707285171327, "train/extr_reward_mag": 0.008009384839962691, "train/extr_reward_max": 0.008009384839962691, "train/extr_reward_mean": 0.0010231299290003684, "train/extr_reward_min": 1.5697723779922876e-05, "train/extr_reward_std": 0.0015353437919074144, "train/image_loss_mean": 0.18653604105497018, "train/image_loss_std": 0.10104138140495007, "train/model_loss_mean": 0.8223121331288265, "train/model_loss_std": 0.37897119525915535, "train/model_opt_grad_norm": 39.88547809307392, "train/model_opt_grad_steps": 16353.702564102565, "train/model_opt_loss": 2878.365459109575, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3500.0, "train/policy_entropy_mag": 1.6814958468461647, "train/policy_entropy_max": 1.6814958468461647, "train/policy_entropy_mean": 0.8966605686224424, "train/policy_entropy_min": 0.1881615393054791, "train/policy_entropy_std": 0.31664028450464593, "train/policy_logprob_mag": 6.10025887244787, "train/policy_logprob_max": -0.04068484007834624, "train/policy_logprob_mean": -0.896569548203395, "train/policy_logprob_min": -6.10025887244787, "train/policy_logprob_std": 0.9371527470075167, "train/policy_randomness_mag": 0.8641179787806975, "train/policy_randomness_max": 0.8641179787806975, "train/policy_randomness_mean": 0.46079240846328245, "train/policy_randomness_min": 0.09669590926705263, "train/policy_randomness_std": 0.16272092836025434, "train/post_ent_mag": 37.15958680372972, "train/post_ent_max": 37.15958680372972, "train/post_ent_mean": 36.763631850022534, "train/post_ent_min": 36.285882216233475, "train/post_ent_std": 0.1617086192736259, "train/prior_ent_mag": 39.582308803460535, "train/prior_ent_max": 39.582308803460535, "train/prior_ent_mean": 37.46228219056741, "train/prior_ent_min": 35.68621284289238, "train/prior_ent_std": 0.6952486090171032, "train/rep_loss_mean": 1.0000004487159924, "train/rep_loss_std": 1.4346131744484106e-05, "train/reward_avg": 0.00034929879893286106, "train/reward_loss_mean": 0.011617288277603877, "train/reward_loss_std": 0.05989103751877944, "train/reward_max_data": 0.12033557888860695, "train/reward_max_pred": 0.005095877402868027, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.010091498838021205, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.252266585826874, "train/reward_pred": 0.00031416928574729426, "train/reward_rate": 0.00021033653846153847, "train_stats/mean_log_entropy": 0.8472907820793047, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.03658585622906685, "report/cont_loss_std": 0.43020549416542053, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.640276908874512, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003558207768946886, "report/cont_pred": 0.996448278427124, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18921029567718506, "report/image_loss_std": 0.09997778385877609, "report/model_loss_mean": 0.8357304334640503, "report/model_loss_std": 0.44134318828582764, "report/post_ent_mag": 34.23723602294922, "report/post_ent_max": 34.23723602294922, "report/post_ent_mean": 33.94230270385742, "report/post_ent_min": 33.548587799072266, "report/post_ent_std": 0.13122539222240448, "report/prior_ent_mag": 36.92072296142578, "report/prior_ent_max": 36.92072296142578, "report/prior_ent_mean": 34.80811309814453, "report/prior_ent_min": 33.440364837646484, "report/prior_ent_std": 0.6612810492515564, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00022039387840777636, "report/reward_loss_mean": 0.009934211149811745, "report/reward_loss_std": 0.015456334687769413, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.007201790809631348, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009934211149811745, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00034162402153015137, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020072031766176224, "eval/cont_loss_std": 0.30464911460876465, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.640276908874512, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0035582073032855988, "eval/cont_pred": 0.996448278427124, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2315269112586975, "eval/image_loss_std": 0.11250020563602448, "eval/model_loss_mean": 0.8531416654586792, "eval/model_loss_std": 0.3263421058654785, "eval/post_ent_mag": 34.209049224853516, "eval/post_ent_max": 34.209049224853516, "eval/post_ent_mean": 33.9328727722168, "eval/post_ent_min": 33.56876754760742, "eval/post_ent_std": 0.12780313193798065, "eval/prior_ent_mag": 36.779239654541016, "eval/prior_ent_max": 36.779239654541016, "eval/prior_ent_mean": 34.79419708251953, "eval/prior_ent_min": 33.051368713378906, "eval/prior_ent_std": 0.639879584312439, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0015426692552864552, "eval/reward_loss_std": 0.0016664463328197598, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.005578398704528809, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015426692552864552, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000276896171271801, "eval/reward_rate": 0.0, "replay/size": 278513.0, "replay/inserts": 31088.0, "replay/samples": 31088.0, "replay/insert_wait_avg": 1.3298615314760468e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.840288176956216e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 64784.0, "eval_replay/inserts": 5928.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1330513175521625e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3605079650879, "timer/env.step_count": 3886.0, "timer/env.step_total": 37.199692726135254, "timer/env.step_frac": 0.037186286773561346, "timer/env.step_avg": 0.00957274645551602, "timer/env.step_min": 0.007954835891723633, "timer/env.step_max": 0.035332441329956055, "timer/replay._sample_count": 31088.0, "timer/replay._sample_total": 15.875333547592163, "timer/replay._sample_frac": 0.015869612425909764, "timer/replay._sample_avg": 0.0005106579242020124, "timer/replay._sample_min": 0.0003807544708251953, "timer/replay._sample_max": 0.01090550422668457, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4627.0, "timer/agent.policy_total": 46.13986420631409, "timer/agent.policy_frac": 0.04612323641221185, "timer/agent.policy_avg": 0.009971874693389688, "timer/agent.policy_min": 0.008654594421386719, "timer/agent.policy_max": 0.08112955093383789, "timer/dataset_train_count": 1943.0, "timer/dataset_train_total": 0.22156834602355957, "timer/dataset_train_frac": 0.00022148849765597924, "timer/dataset_train_avg": 0.00011403414617784847, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.0010743141174316406, "timer/agent.train_count": 1943.0, "timer/agent.train_total": 868.5867719650269, "timer/agent.train_frac": 0.8682737523614238, "timer/agent.train_avg": 0.4470338507282691, "timer/agent.train_min": 0.4376037120819092, "timer/agent.train_max": 1.34102463722229, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46871352195739746, "timer/agent.report_frac": 0.0004685446078942526, "timer/agent.report_avg": 0.23435676097869873, "timer/agent.report_min": 0.2236623764038086, "timer/agent.report_max": 0.24505114555358887, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.3366572159187686e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 31.076258560069725}
{"step": 279272, "time": 9214.819436311722, "episode/length": 288.0, "episode/score": 0.05283190821057815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05283190821057815}
{"step": 279688, "time": 9227.936845302582, "episode/length": 288.0, "episode/score": 0.07225340577093675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07225340577093675}
{"step": 279840, "time": 9233.022450447083, "episode/length": 288.0, "episode/score": 0.06870900942311664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06870900942311664}
{"step": 279848, "time": 9233.060898542404, "episode/length": 288.0, "episode/score": 0.07662198856149871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07662198856149871}
{"step": 280008, "time": 9238.111659765244, "episode/length": 91.0, "episode/score": 0.754395498787062, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.03877048206982181}
{"step": 280072, "time": 9241.013456344604, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 280072, "time": 9242.804780721664, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 280072, "time": 9246.06516122818, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9246.084087848663, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9246.102024555206, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9246.119179964066, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9246.138488054276, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9246.152517080307, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280112, "time": 9247.648510217667, "episode/length": 288.0, "episode/score": 0.06744576047276496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06744576047276496}
{"step": 280424, "time": 9257.203561067581, "episode/length": 91.0, "episode/score": 0.743319665609306, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.027694678345142165}
{"step": 280560, "time": 9261.79826593399, "episode/length": 230.0, "episode/score": 0.358440337847469, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.07719034430851934}
{"step": 280616, "time": 9263.355761051178, "episode/length": 62.0, "episode/score": 0.8398930947696499, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.03364308997333865}
{"step": 280712, "time": 9266.387679338455, "episode/length": 217.0, "episode/score": 0.3857820163384531, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.06390701683903899}
{"step": 280848, "time": 9270.900439739227, "episode/length": 52.0, "episode/score": 0.851802754284904, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.014302748731893189}
{"step": 281032, "time": 9276.49371623993, "episode/length": 288.0, "episode/score": 0.09151693908290781, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09151693908290781}
{"step": 281992, "time": 9306.758973121643, "episode/length": 267.0, "episode/score": 0.2424158877976197, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.07679088856014005}
{"step": 282024, "time": 9307.771684885025, "episode/length": 175.0, "episode/score": 0.5203619726031548, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.06723697376730797}
{"step": 282152, "time": 9311.821695327759, "episode/length": 288.0, "episode/score": 0.07550837200540172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07550837200540172}
{"step": 282216, "time": 9313.885133504868, "episode/length": 187.0, "episode/score": 0.4541344208104192, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.038509407690412445}
{"step": 282320, "time": 9317.418759822845, "episode/length": 288.0, "episode/score": 0.07093283251663252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07093283251663252}
{"step": 282832, "time": 9333.692233800888, "episode/length": 247.0, "episode/score": 0.32190956050760633, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0937845553620491}
{"step": 282872, "time": 9334.732580184937, "episode/length": 288.0, "episode/score": 0.08675928456068505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08675928456068505}
{"step": 283080, "time": 9341.259617805481, "episode/length": 115.0, "episode/score": 0.6789750717355219, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.038350057416437267}
{"step": 283160, "time": 9343.78545832634, "episode/length": 141.0, "episode/score": 0.593849314848967, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0344743449015823}
{"step": 283240, "time": 9346.29468011856, "episode/length": 275.0, "episode/score": 0.20879072632908446, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.06816572955960964}
{"step": 283248, "time": 9346.77692937851, "episode/length": 156.0, "episode/score": 0.56820802243044, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.055708035166276204}
{"step": 283480, "time": 9354.01129102707, "episode/length": 157.0, "episode/score": 0.5530422617587192, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.04366726225930506}
{"step": 283584, "time": 9357.504715681076, "episode/length": 88.0, "episode/score": 0.7514313269800823, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.026431303356503122}
{"step": 283720, "time": 9361.621137857437, "episode/length": 174.0, "episode/score": 0.48468251942040297, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.02843250866362723}
{"step": 283816, "time": 9364.707640647888, "episode/length": 41.0, "episode/score": 0.8831707519893826, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.01129574056903948}
{"step": 284184, "time": 9376.408342123032, "episode/length": 74.0, "episode/score": 0.7915899027630076, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.022839867500806577}
{"step": 284248, "time": 9378.457701921463, "episode/length": 124.0, "episode/score": 0.6496231108135362, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.03712306949773847}
{"step": 284400, "time": 9383.590831041336, "episode/length": 164.0, "episode/score": 0.5255645704394283, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.03806455182461832}
{"step": 284416, "time": 9384.100374698639, "episode/length": 86.0, "episode/score": 0.7663466467677154, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.035096681797085694}
{"step": 284552, "time": 9388.168681621552, "episode/length": 163.0, "episode/score": 0.5336719172623248, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.04304692363024287}
{"step": 284848, "time": 9397.683819770813, "episode/length": 128.0, "episode/score": 0.6392973033522367, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.03929727542129058}
{"step": 284896, "time": 9399.179165840149, "episode/length": 61.0, "episode/score": 0.8346085131505561, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.02523351689330866}
{"step": 285144, "time": 9406.763110399246, "episode/length": 288.0, "episode/score": 0.04062818398926993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04062818398926993}
{"step": 285152, "time": 9407.241793394089, "episode/length": 248.0, "episode/score": 0.2883927188531743, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.06339273153662361}
{"step": 285304, "time": 9411.931613206863, "episode/length": 93.0, "episode/score": 0.7420356120605334, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.032660581059133165}
{"step": 285640, "time": 9422.460131406784, "episode/length": 60.0, "episode/score": 0.843175797166225, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.03067582338877628}
{"step": 285784, "time": 9426.98106431961, "episode/length": 170.0, "episode/score": 0.5307350216043574, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.06198500993372136}
{"step": 286000, "time": 9433.974604845047, "episode/length": 106.0, "episode/score": 0.6905042777057133, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.02175430775832865}
{"step": 286272, "time": 9442.666823863983, "episode/length": 177.0, "episode/score": 0.4832100260675247, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.036335010444588534}
{"step": 286496, "time": 9449.72907280922, "episode/length": 288.0, "episode/score": 0.05773325845729005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05773325845729005}
{"step": 286560, "time": 9451.758290290833, "episode/length": 288.0, "episode/score": 0.051070063561382995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051070063561382995}
{"step": 286608, "time": 9453.268505096436, "episode/length": 41.0, "episode/score": 0.8937402642869756, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.021865296347755248}
{"step": 286928, "time": 9463.847816705704, "episode/length": 39.0, "episode/score": 0.8969798091357006, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.01885482343732292}
{"step": 287208, "time": 9472.54089307785, "episode/length": 288.0, "episode/score": 0.05988822668746252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05988822668746252}
{"step": 287312, "time": 9476.076099157333, "episode/length": 93.0, "episode/score": 0.743443681219901, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.034068675509729474}
{"step": 287376, "time": 9478.097551107407, "episode/length": 55.0, "episode/score": 0.8477480417325864, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.01962305589159996}
{"step": 287400, "time": 9478.643194675446, "episode/length": 261.0, "episode/score": 0.2441775990388919, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0598025962769384}
{"step": 287800, "time": 9491.223740816116, "episode/length": 224.0, "episode/score": 0.35309835484872565, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.05309834314607542}
{"step": 287880, "time": 9493.749754190445, "episode/length": 59.0, "episode/score": 0.8342088876606795, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.01858388580967585}
{"step": 287952, "time": 9496.25677037239, "episode/length": 288.0, "episode/score": 0.055669040580539786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055669040580539786}
{"step": 287992, "time": 9497.296998739243, "episode/length": 76.0, "episode/score": 0.7919142221973061, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.02941420600393485}
{"step": 288056, "time": 9499.299221277237, "episode/length": 105.0, "episode/score": 0.7033723748737657, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.03149739201592183}
{"step": 288096, "time": 9500.903433561325, "episode/length": 288.0, "episode/score": 0.05906002426451096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05906002426451096}
{"step": 288672, "time": 9519.04498910904, "episode/length": 108.0, "episode/score": 0.6910429031681247, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.028542896468422896}
{"step": 288728, "time": 9520.587284088135, "episode/length": 96.0, "episode/score": 0.7337016314461948, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.033701613673940756}
{"step": 288744, "time": 9521.098618507385, "episode/length": 85.0, "episode/score": 0.7631761433736415, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.028801158478529487}
{"step": 288808, "time": 9523.129638195038, "episode/length": 288.0, "episode/score": 0.055198511388084626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055198511388084626}
{"step": 289624, "time": 9548.977294445038, "episode/length": 288.0, "episode/score": 0.05610393144218051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05610393144218051}
{"step": 290056, "time": 9563.178313016891, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 290056, "time": 9563.20406126976, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 290056, "time": 9563.687029838562, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 290056, "time": 9563.697038888931, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 290056, "time": 9563.895236730576, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 290056, "time": 9563.941637992859, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 290056, "time": 9564.235929727554, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 290056, "time": 9564.71661067009, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 290192, "time": 9569.220041751862, "episode/length": 288.0, "episode/score": 0.050932711337452474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050932711337452474}
{"step": 290304, "time": 9572.7228474617, "episode/length": 288.0, "episode/score": 0.030266950755333255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030266950755333255}
{"step": 290408, "time": 9575.771191596985, "episode/length": 288.0, "episode/score": 0.0489122095148673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0489122095148673}
{"step": 290984, "time": 9594.045854330063, "episode/length": 288.0, "episode/score": 0.03782431688401289, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03782431688401289}
{"step": 291040, "time": 9596.064429283142, "episode/length": 288.0, "episode/score": 0.039604866366033775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039604866366033775}
{"step": 291056, "time": 9596.57655954361, "episode/length": 288.0, "episode/score": 0.022463068706088052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022463068706088052}
{"step": 291120, "time": 9598.604118585587, "episode/length": 288.0, "episode/score": 0.02514600234329123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02514600234329123}
{"step": 291384, "time": 9606.677816867828, "episode/length": 134.0, "episode/score": 0.5936279950827839, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.012377959944274153}
{"step": 291416, "time": 9607.683557510376, "episode/length": 152.0, "episode/score": 0.5441082273451343, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.019108274295433603}
{"step": 291560, "time": 9612.190366268158, "episode/length": 62.0, "episode/score": 0.8176636348984516, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.01141365465122135}
{"step": 291592, "time": 9613.193615913391, "episode/length": 245.0, "episode/score": 0.26915343803844394, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.03477843885335119}
{"step": 292232, "time": 9633.382808685303, "episode/length": 148.0, "episode/score": 0.5662156245415702, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.028715578449833856}
{"step": 292328, "time": 9636.4361577034, "episode/length": 239.0, "episode/score": 0.28323274108402074, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.030107725583320644}
{"step": 292456, "time": 9640.460546016693, "episode/length": 111.0, "episode/score": 0.6829170677031868, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.029792091178336477}
{"step": 292552, "time": 9643.45997953415, "episode/length": 178.0, "episode/score": 0.4635826324702066, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.019832624111586483}
{"step": 292888, "time": 9654.143092632294, "episode/length": 187.0, "episode/score": 0.44500856651652043, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.029383558511511865}
{"step": 292912, "time": 9655.142523288727, "episode/length": 186.0, "episode/score": 0.4628185950256807, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.044068604902065545}
{"step": 293296, "time": 9667.190253973007, "episode/length": 288.0, "episode/score": 0.04742947829822697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04742947829822697}
{"step": 293904, "time": 9686.43232536316, "episode/length": 288.0, "episode/score": 0.04273266063333381, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04273266063333381}
{"step": 294544, "time": 9706.524201631546, "episode/length": 288.0, "episode/score": 0.015894795008875917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015894795008875917}
{"step": 294640, "time": 9709.537533283234, "episode/length": 288.0, "episode/score": 0.029873854275706435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029873854275706435}
{"step": 294696, "time": 9711.197420358658, "episode/length": 98.0, "episode/score": 0.7142716800381663, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.020521656276343947}
{"step": 294768, "time": 9713.70460653305, "episode/length": 288.0, "episode/score": 0.031416591849023234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031416591849023234}
{"step": 294864, "time": 9716.748247623444, "episode/length": 288.0, "episode/score": 0.05095350598176651, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05095350598176651}
{"step": 295200, "time": 9727.83257985115, "episode/length": 288.0, "episode/score": 0.044219700266154405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044219700266154405}
{"step": 295224, "time": 9728.373699188232, "episode/length": 288.0, "episode/score": 0.04062754227678056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04062754227678056}
{"step": 295608, "time": 9740.431414842606, "episode/length": 288.0, "episode/score": 0.03274311397774454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03274311397774454}
{"step": 295704, "time": 9743.537783384323, "episode/length": 125.0, "episode/score": 0.6228277518556808, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.013452766960568852}
{"step": 295968, "time": 9752.02876663208, "episode/length": 137.0, "episode/score": 0.5934403270997848, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.021565374050084074}
{"step": 296856, "time": 9779.806228399277, "episode/length": 288.0, "episode/score": 0.04466659697945374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04466659697945374}
{"step": 296928, "time": 9782.311989307404, "episode/length": 285.0, "episode/score": 0.14946361724099688, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.04008861731375646}
{"step": 297080, "time": 9786.864423751831, "episode/length": 288.0, "episode/score": 0.023780207234608497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023780207234608497}
{"step": 297240, "time": 9791.90003156662, "episode/length": 191.0, "episode/score": 0.4419912023663528, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.03886621070751062}
{"step": 297360, "time": 9795.905884027481, "episode/length": 173.0, "episode/score": 0.4927521336410621, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.03337715376054007}
{"step": 297384, "time": 9796.446959257126, "episode/length": 65.0, "episode/score": 0.8200309579712837, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.023155968041209007}
{"step": 297512, "time": 9800.562958955765, "episode/length": 288.0, "episode/score": 0.045994805558848384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045994805558848384}
{"step": 297536, "time": 9801.618942022324, "episode/length": 288.0, "episode/score": 0.03533171719604411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03533171719604411}
{"step": 297896, "time": 9812.725246191025, "episode/length": 63.0, "episode/score": 0.8207700545517866, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.01764503977577192}
{"step": 297920, "time": 9813.704206466675, "episode/length": 288.0, "episode/score": 0.04358328631462882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04358328631462882}
{"step": 298008, "time": 9816.25995850563, "episode/length": 80.0, "episode/score": 0.7648569255812276, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.014856921492139463}
{"step": 298208, "time": 9822.816633701324, "episode/length": 159.0, "episode/score": 0.5327555804705639, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.029630545208362946}
{"step": 298280, "time": 9824.855642795563, "episode/length": 95.0, "episode/score": 0.7236669812727712, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.02054200347899382}
{"step": 298616, "time": 9835.49042892456, "episode/length": 134.0, "episode/score": 0.6080973434976045, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.026847302181806754}
{"step": 298648, "time": 9836.501170873642, "episode/length": 93.0, "episode/score": 0.733297327034677, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.023922303272854606}
{"step": 299032, "time": 9848.59704875946, "episode/length": 127.0, "episode/score": 0.6306463491678755, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.02752135895258334}
{"step": 299216, "time": 9854.583820343018, "episode/length": 266.0, "episode/score": 0.21454595803592724, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.04579595729668995}
{"step": 299552, "time": 9865.232933998108, "episode/length": 288.0, "episode/score": 0.03726580211758801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03726580211758801}
{"step": 299584, "time": 9866.240300655365, "episode/length": 207.0, "episode/score": 0.3856539834877992, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.03252898411207639}
{"step": 299840, "time": 9874.297429323196, "episode/length": 77.0, "episode/score": 0.7779543299968736, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.018579346679189257}
{"step": 300040, "time": 9885.579720973969, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9885.60007929802, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9885.619280815125, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9885.63290476799, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9885.649134397507, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9885.65873169899, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9885.670110940933, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9885.682053565979, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300520, "time": 9900.774166107178, "episode/length": 288.0, "episode/score": 0.0437351994621622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0437351994621622}
{"step": 300592, "time": 9903.2780148983, "episode/length": 288.0, "episode/score": 0.04341953937017706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04341953937017706}
{"step": 300928, "time": 9913.829837322235, "episode/length": 288.0, "episode/score": 0.02204381774686226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02204381774686226}
{"step": 300960, "time": 9914.837931156158, "episode/length": 288.0, "episode/score": 0.04863272216914538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04863272216914538}
{"step": 301040, "time": 9917.345926761627, "episode/length": 55.0, "episode/score": 0.8434260075954967, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.015301027735347361}
{"step": 301344, "time": 9926.990124940872, "episode/length": 288.0, "episode/score": 0.035840388763176634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035840388763176634}
{"step": 301640, "time": 9936.09141945839, "episode/length": 256.0, "episode/score": 0.24192033571137017, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.04192032990806638}
{"step": 301864, "time": 9943.115370035172, "episode/length": 288.0, "episode/score": 0.050760849845147504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050760849845147504}
{"step": 302048, "time": 9949.19607424736, "episode/length": 135.0, "episode/score": 0.6153069891831819, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.03718198999808919}
{"step": 302152, "time": 9952.331550836563, "episode/length": 35.0, "episode/score": 0.9010725066985401, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.010447492379455525}
{"step": 302152, "time": 9952.34727883339, "episode/length": 288.0, "episode/score": 0.06141539792633921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06141539792633921}
{"step": 302504, "time": 9963.520268678665, "episode/length": 196.0, "episode/score": 0.42982326079099664, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.04232325839284101}
{"step": 302616, "time": 9967.045602321625, "episode/length": 121.0, "episode/score": 0.6567752115997081, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.03490024366048772}
{"step": 302728, "time": 9970.577707529068, "episode/length": 71.0, "episode/score": 0.800264167041405, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.022139155621061946}
{"step": 302832, "time": 9974.07899928093, "episode/length": 288.0, "episode/score": 0.03848270583867475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03848270583867475}
{"step": 303240, "time": 9987.27288389206, "episode/length": 91.0, "episode/score": 0.7296510659011801, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.014026063503024488}
{"step": 303352, "time": 9990.804124593735, "episode/length": 288.0, "episode/score": 0.042145686291647166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042145686291647166}
{"step": 303656, "time": 10000.338658332825, "episode/length": 288.0, "episode/score": 0.03769239218399889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03769239218399889}
{"step": 304216, "time": 10018.013593673706, "episode/length": 69.0, "episode/score": 0.7970586677254232, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.01268364148540968}
{"step": 304360, "time": 10022.543194770813, "episode/length": 288.0, "episode/score": 0.0464668505727559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0464668505727559}
{"step": 304464, "time": 10026.052382469177, "episode/length": 288.0, "episode/score": 0.04958379890524611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04958379890524611}
{"step": 304600, "time": 10030.12476849556, "episode/length": 233.0, "episode/score": 0.3253013830699274, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.05342637471130729}
{"step": 304744, "time": 10034.65608215332, "episode/length": 47.0, "episode/score": 0.8713532514050257, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.018228267068707282}
{"step": 304928, "time": 10040.756129980087, "episode/length": 88.0, "episode/score": 0.7505430322398752, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.025543000219840906}
{"step": 304928, "time": 10040.771847009659, "episode/length": 288.0, "episode/score": 0.05025535977642903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05025535977642903}
{"step": 305144, "time": 10047.39149069786, "episode/length": 288.0, "episode/score": 0.017580332205852756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017580332205852756}
{"step": 305224, "time": 10049.950685739517, "episode/length": 77.0, "episode/score": 0.7850516170719857, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.025676626594759}
{"step": 305360, "time": 10054.557696819305, "episode/length": 111.0, "episode/score": 0.6858592056148609, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.03273419419451784}
{"step": 305552, "time": 10060.638247013092, "episode/length": 288.0, "episode/score": 0.07250126354711028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07250126354711028}
{"step": 305576, "time": 10061.172095775604, "episode/length": 43.0, "episode/score": 0.878462910043595, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.01283785680686833}
{"step": 305664, "time": 10064.15705871582, "episode/length": 288.0, "episode/score": 0.0662405664737662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0662405664737662}
{"step": 305928, "time": 10072.311151742935, "episode/length": 124.0, "episode/score": 0.6550047846700409, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.042504743354243146}
{"step": 306400, "time": 10087.419917583466, "episode/length": 91.0, "episode/score": 0.7646650649687672, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.04904004749482738}
{"step": 307056, "time": 10108.13127207756, "episode/length": 288.0, "episode/score": 0.09409078833834883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09409078833834883}
{"step": 307240, "time": 10113.699635744095, "episode/length": 288.0, "episode/score": 0.07480830643453373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07480830643453373}
{"step": 307456, "time": 10120.704491615295, "episode/length": 288.0, "episode/score": 0.0950814577803385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0950814577803385}
{"step": 307672, "time": 10127.29286313057, "episode/length": 288.0, "episode/score": 0.07121057064011893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07121057064011893}
{"step": 307832, "time": 10132.45287847519, "episode/length": 178.0, "episode/score": 0.5109040077666123, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.06715400656753445}
{"step": 307864, "time": 10133.461221456528, "episode/length": 288.0, "episode/score": 0.054531735761770506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054531735761770506}
{"step": 307888, "time": 10134.440134525299, "episode/length": 288.0, "episode/score": 0.06481749753322674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06481749753322674}
{"step": 308240, "time": 10145.528279304504, "episode/length": 288.0, "episode/score": 0.09774975409675335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09774975409675335}
{"step": 308776, "time": 10162.356120824814, "episode/length": 113.0, "episode/score": 0.6898729256215006, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.042997894620100396}
{"step": 309368, "time": 10181.066508054733, "episode/length": 288.0, "episode/score": 0.07882362484792793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07882362484792793}
{"step": 309552, "time": 10187.087734937668, "episode/length": 288.0, "episode/score": 0.06628072900383586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06628072900383586}
{"step": 309768, "time": 10193.736780881882, "episode/length": 288.0, "episode/score": 0.054125744461032355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054125744461032355}
{"step": 309800, "time": 10194.747366189957, "episode/length": 53.0, "episode/score": 0.85532971270095, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.020954706990778504}
{"step": 309880, "time": 10197.278570890427, "episode/length": 255.0, "episode/score": 0.24963436994841004, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.04650937053048665}
{"step": 309984, "time": 10200.765522003174, "episode/length": 288.0, "episode/score": 0.058816272192586894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058816272192586894}
{"step": 310024, "time": 10202.863623142242, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 310024, "time": 10203.191490888596, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 310024, "time": 10203.560097932816, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 310024, "time": 10204.385424375534, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 310024, "time": 10205.704215765, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 310024, "time": 10206.048402071, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 310024, "time": 10206.527962684631, "eval_episode/length": 255.0, "eval_episode/score": 0.203125, "eval_episode/reward_rate": 0.00390625}
{"step": 310024, "time": 10207.11145567894, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10207.135163068771, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10207.154715299606, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310025, "time": 10208.2006649971, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2094795777625644, "train/action_min": 0.0, "train/action_std": 1.617897185468182, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0024483763221555305, "train/actor_opt_grad_steps": 18315.0, "train/actor_opt_loss": 15.08670779018058, "train/adv_mag": 0.02123486120061776, "train/adv_max": 0.020798100715445487, "train/adv_mean": 0.005332849017351044, "train/adv_min": -0.0072796028299429985, "train/adv_std": 0.0037370285681765716, "train/cont_avg": 0.9962095280283505, "train/cont_loss_mean": 0.024621884470575096, "train/cont_loss_std": 0.32948836402812215, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.511771248273201, "train/cont_pos_acc": 0.9999999846379781, "train/cont_pos_loss": 0.003741551165411383, "train/cont_pred": 0.9962637885329649, "train/cont_rate": 0.9962095280283505, "train/dyn_loss_mean": 1.00014468873899, "train/dyn_loss_std": 0.0005896938624203161, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4574961741262874, "train/extr_critic_critic_opt_grad_steps": 18315.0, "train/extr_critic_critic_opt_loss": 8427.854322295829, "train/extr_critic_mag": 0.3427141210467545, "train/extr_critic_max": 0.3427141210467545, "train/extr_critic_mean": 0.337374969011115, "train/extr_critic_min": 0.3296833818720788, "train/extr_critic_std": 0.0024726215330523812, "train/extr_return_normed_mag": 0.034652024430712476, "train/extr_return_normed_max": 0.03458591227986149, "train/extr_return_normed_mean": 0.016921162046612117, "train/extr_return_normed_min": 0.003754398411082238, "train/extr_return_normed_std": 0.004646717223276375, "train/extr_return_rate": 6.711770109496243e-07, "train/extr_return_raw_mag": 0.3603725596187041, "train/extr_return_raw_max": 0.3603725596187041, "train/extr_return_raw_mean": 0.34270782584382087, "train/extr_return_raw_min": 0.3295410457499248, "train/extr_return_raw_std": 0.004646717229277164, "train/extr_reward_mag": 0.015555771970257317, "train/extr_reward_max": 0.015555771970257317, "train/extr_reward_mean": 0.001788680296158418, "train/extr_reward_min": 1.221342185108932e-05, "train/extr_reward_std": 0.0033482130618103464, "train/image_loss_mean": 0.17083666523553662, "train/image_loss_std": 0.1061728801386258, "train/model_loss_mean": 0.808306551471199, "train/model_loss_std": 0.3974349740316573, "train/model_opt_grad_norm": 36.92555612387116, "train/model_opt_grad_steps": 18297.41237113402, "train/model_opt_loss": 2561.774935692856, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3170.103092783505, "train/policy_entropy_mag": 1.5876550305749952, "train/policy_entropy_max": 1.5876550305749952, "train/policy_entropy_mean": 0.39869185083920194, "train/policy_entropy_min": 0.06491328176763869, "train/policy_entropy_std": 0.31222988841767163, "train/policy_logprob_mag": 6.548976728596638, "train/policy_logprob_max": -0.008643337871072833, "train/policy_logprob_mean": -0.3993942282863499, "train/policy_logprob_min": -6.548976728596638, "train/policy_logprob_std": 0.8513901319700418, "train/policy_randomness_mag": 0.8158933369769263, "train/policy_randomness_max": 0.8158933369769263, "train/policy_randomness_mean": 0.20488709265116564, "train/policy_randomness_min": 0.03335882976804812, "train/policy_randomness_std": 0.160454431452702, "train/post_ent_mag": 35.262563154869476, "train/post_ent_max": 35.262563154869476, "train/post_ent_mean": 34.89768909179058, "train/post_ent_min": 34.528634533439714, "train/post_ent_std": 0.14238627665897005, "train/prior_ent_mag": 38.64429328367882, "train/prior_ent_max": 38.64429328367882, "train/prior_ent_mean": 35.79146908238991, "train/prior_ent_min": 34.263875312411905, "train/prior_ent_std": 0.6627920093302874, "train/rep_loss_mean": 1.00014468873899, "train/rep_loss_std": 0.0005896938624203161, "train/reward_avg": 0.0005009265291893413, "train/reward_loss_mean": 0.012761167418595749, "train/reward_loss_std": 0.07987151735164609, "train/reward_max_data": 0.22825660632164746, "train/reward_max_pred": 0.010959193878567097, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.010219109479875602, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.644990633515751, "train/reward_pred": 0.00044134398262237303, "train/reward_rate": 0.0004530444587628866, "train_stats/mean_log_entropy": 0.35629048620819287, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014134380035102367, "report/cont_loss_std": 0.26031967997550964, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.897304534912109, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002621325897052884, "report/cont_pred": 0.9973821640014648, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.16843479871749878, "report/image_loss_std": 0.12291774153709412, "report/model_loss_mean": 0.7912591099739075, "report/model_loss_std": 0.2974041998386383, "report/post_ent_mag": 37.34083557128906, "report/post_ent_max": 37.34083557128906, "report/post_ent_mean": 36.86334228515625, "report/post_ent_min": 36.42092514038086, "report/post_ent_std": 0.16472865641117096, "report/prior_ent_mag": 43.79620361328125, "report/prior_ent_max": 43.79620361328125, "report/prior_ent_mean": 40.22502899169922, "report/prior_ent_min": 38.08929443359375, "report/prior_ent_std": 0.8563239574432373, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001948597200680524, "report/reward_loss_mean": 0.008689923211932182, "report/reward_loss_std": 0.014584881253540516, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.006727099418640137, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008689924143254757, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002804861869663, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03821811079978943, "eval/cont_loss_std": 0.463225781917572, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.071971416473389, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002655713353306055, "eval/cont_pred": 0.9973503351211548, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23661699891090393, "eval/image_loss_std": 0.1228087991476059, "eval/model_loss_mean": 0.8760827779769897, "eval/model_loss_std": 0.4750395119190216, "eval/post_ent_mag": 37.28995132446289, "eval/post_ent_max": 37.28995132446289, "eval/post_ent_mean": 36.82610321044922, "eval/post_ent_min": 36.46626281738281, "eval/post_ent_std": 0.15952341258525848, "eval/prior_ent_mag": 43.64653015136719, "eval/prior_ent_max": 43.64653015136719, "eval/prior_ent_mean": 40.18708038330078, "eval/prior_ent_min": 37.88117980957031, "eval/prior_ent_std": 0.8857742547988892, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001247655600309372, "eval/reward_loss_std": 0.0016634264029562473, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.003617525100708008, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001247655600309372, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00021253852173686028, "eval/reward_rate": 0.0, "replay/size": 309521.0, "replay/inserts": 31008.0, "replay/samples": 31008.0, "replay/insert_wait_avg": 1.3328465883945903e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.722431008660756e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 72552.0, "eval_replay/inserts": 7768.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1394247335950575e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2516975402832031e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.1665370464325, "timer/env.step_count": 3876.0, "timer/env.step_total": 37.15754437446594, "timer/env.step_frac": 0.0371142492277912, "timer/env.step_avg": 0.009586569756054165, "timer/env.step_min": 0.007734060287475586, "timer/env.step_max": 0.0489649772644043, "timer/replay._sample_count": 31008.0, "timer/replay._sample_total": 15.803032875061035, "timer/replay._sample_frac": 0.015784619531613565, "timer/replay._sample_avg": 0.0005096437330708539, "timer/replay._sample_min": 0.00038123130798339844, "timer/replay._sample_max": 0.02779865264892578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4847.0, "timer/agent.policy_total": 48.711108446121216, "timer/agent.policy_frac": 0.04865435134280969, "timer/agent.policy_avg": 0.01004974385106689, "timer/agent.policy_min": 0.008585691452026367, "timer/agent.policy_max": 0.09755516052246094, "timer/dataset_train_count": 1938.0, "timer/dataset_train_total": 0.22063803672790527, "timer/dataset_train_frac": 0.00022038095418052555, "timer/dataset_train_avg": 0.0001138483161650698, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0004878044128417969, "timer/agent.train_count": 1938.0, "timer/agent.train_total": 864.959623336792, "timer/agent.train_frac": 0.863951791565599, "timer/agent.train_avg": 0.44631559511702373, "timer/agent.train_min": 0.4348487854003906, "timer/agent.train_max": 0.5735328197479248, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48317909240722656, "timer/agent.report_frac": 0.0004826161028440541, "timer/agent.report_avg": 0.24158954620361328, "timer/agent.report_min": 0.23821020126342773, "timer/agent.report_max": 0.24496889114379883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.952945660350474e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 30.97128599487881}
{"step": 310200, "time": 10213.501853466034, "episode/length": 288.0, "episode/score": 0.03846750613047334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03846750613047334}
{"step": 310552, "time": 10224.721176624298, "episode/length": 288.0, "episode/score": 0.04871717391353059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04871717391353059}
{"step": 310592, "time": 10226.207131385803, "episode/length": 98.0, "episode/score": 0.7217073904724316, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.027957384762260062}
{"step": 310752, "time": 10231.256540298462, "episode/length": 95.0, "episode/score": 0.7254903498872523, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.022365364992140258}
{"step": 310760, "time": 10231.293897867203, "episode/length": 123.0, "episode/score": 0.6384943430774683, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.02286931514652224}
{"step": 310832, "time": 10233.793010473251, "episode/length": 78.0, "episode/score": 0.7666196536986831, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.010369621678648855}
{"step": 311088, "time": 10241.842221021652, "episode/length": 288.0, "episode/score": 0.05514796473499928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05514796473499928}
{"step": 311392, "time": 10252.014428138733, "episode/length": 78.0, "episode/score": 0.7852452988819323, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.02899525169880235}
{"step": 311480, "time": 10254.573541879654, "episode/length": 199.0, "episode/score": 0.42332926027893336, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.045204260436094046}
{"step": 311864, "time": 10266.759771108627, "episode/length": 288.0, "episode/score": 0.043903588529701665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043903588529701665}
{"step": 311928, "time": 10268.790152311325, "episode/length": 136.0, "episode/score": 0.6056011787298416, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.030601167309498578}
{"step": 312176, "time": 10276.83524274826, "episode/length": 135.0, "episode/score": 0.608513513250557, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.030388483855688264}
{"step": 312280, "time": 10279.888726711273, "episode/length": 99.0, "episode/score": 0.6991741836225174, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.008549191841439097}
{"step": 312328, "time": 10281.47190284729, "episode/length": 49.0, "episode/score": 0.8647426228853305, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.017867623042491232}
{"step": 312416, "time": 10284.475549697876, "episode/length": 232.0, "episode/score": 0.2899079145253154, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.014907901405308621}
{"step": 312904, "time": 10299.70428609848, "episode/length": 288.0, "episode/score": 0.04400609846840098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04400609846840098}
{"step": 312952, "time": 10301.228875875473, "episode/length": 96.0, "episode/score": 0.7159462786665358, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0159462908057435}
{"step": 313064, "time": 10304.734053134918, "episode/length": 288.0, "episode/score": 0.036767063054242044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036767063054242044}
{"step": 313576, "time": 10321.045161485672, "episode/length": 83.0, "episode/score": 0.7669918881418312, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.026366857140430966}
{"step": 313648, "time": 10323.51675772667, "episode/length": 86.0, "episode/score": 0.7551182404697556, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.023868264468774214}
{"step": 313704, "time": 10325.06204867363, "episode/length": 288.0, "episode/score": 0.033111304103499606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033111304103499606}
{"step": 314016, "time": 10335.126129627228, "episode/length": 118.0, "episode/score": 0.6528493335637222, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.021599327853550676}
{"step": 314176, "time": 10340.200796604156, "episode/length": 288.0, "episode/score": 0.07515150119402847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07515150119402847}
{"step": 314240, "time": 10342.32789516449, "episode/length": 66.0, "episode/score": 0.8182972128088579, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.02454724286147325}
{"step": 314272, "time": 10343.337699174881, "episode/length": 31.0, "episode/score": 0.9171749350137475, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.014049947152955156}
{"step": 314472, "time": 10349.406439781189, "episode/length": 24.0, "episode/score": 0.9387407621144064, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.013740720798608663}
{"step": 314592, "time": 10353.407309293747, "episode/length": 288.0, "episode/score": 0.05464129228695924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05464129228695924}
{"step": 314640, "time": 10354.928092956543, "episode/length": 288.0, "episode/score": 0.05141756453130597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05141756453130597}
{"step": 314728, "time": 10357.49103808403, "episode/length": 288.0, "episode/score": 0.05111360769114981, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05111360769114981}
{"step": 314832, "time": 10361.002546072006, "episode/length": 44.0, "episode/score": 0.8787047041427059, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.016204685062234603}
{"step": 314904, "time": 10363.049023389816, "episode/length": 21.0, "episode/score": 0.9433184762725091, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.00894348103389575}
{"step": 315144, "time": 10370.695504188538, "episode/length": 62.0, "episode/score": 0.8249462430001984, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.018696293064607516}
{"step": 315400, "time": 10378.802823066711, "episode/length": 144.0, "episode/score": 0.5851643241241504, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.035164330334907845}
{"step": 315672, "time": 10387.440929889679, "episode/length": 134.0, "episode/score": 0.6261553602739127, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.04490536251199728}
{"step": 315888, "time": 10394.553826332092, "episode/length": 288.0, "episode/score": 0.03369361670721105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03369361670721105}
{"step": 315960, "time": 10396.65132522583, "episode/length": 288.0, "episode/score": 0.025199909959496836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025199909959496836}
{"step": 316144, "time": 10402.723757982254, "episode/length": 92.0, "episode/score": 0.7270130306389149, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.014513069585660787}
{"step": 316344, "time": 10408.811183929443, "episode/length": 83.0, "episode/score": 0.771375234821619, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.03075020689067287}
{"step": 316488, "time": 10413.343779325485, "episode/length": 288.0, "episode/score": 0.04178575245310867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04178575245310867}
{"step": 316784, "time": 10422.867658138275, "episode/length": 111.0, "episode/score": 0.6854015746871198, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.032276612830600016}
{"step": 316888, "time": 10425.901443958282, "episode/length": 115.0, "episode/score": 0.6726246291501923, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.031999629368471005}
{"step": 317144, "time": 10434.079222917557, "episode/length": 288.0, "episode/score": 0.04558472389811641, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04558472389811641}
{"step": 317216, "time": 10436.5745241642, "episode/length": 288.0, "episode/score": 0.052010592306828585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052010592306828585}
{"step": 317328, "time": 10440.106996059418, "episode/length": 147.0, "episode/score": 0.5795785780913434, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.03895360215148003}
{"step": 317368, "time": 10441.151592254639, "episode/length": 127.0, "episode/score": 0.6344259051994641, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.031300944146209986}
{"step": 317456, "time": 10444.17475771904, "episode/length": 288.0, "episode/score": 0.02008119237220285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02008119237220285}
{"step": 317512, "time": 10445.723854064941, "episode/length": 22.0, "episode/score": 0.9439818147004075, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.012731861650706833}
{"step": 317744, "time": 10453.344450473785, "episode/length": 35.0, "episode/score": 0.9096513734519363, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.019026374266843504}
{"step": 317888, "time": 10457.87407541275, "episode/length": 92.0, "episode/score": 0.7447573320574747, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.032257356714239904}
{"step": 318272, "time": 10470.099310159683, "episode/length": 65.0, "episode/score": 0.8215746453606698, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.024699622019397793}
{"step": 318376, "time": 10473.163573741913, "episode/length": 185.0, "episode/score": 0.46882838505010227, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.04695338621425549}
{"step": 318448, "time": 10475.64122581482, "episode/length": 69.0, "episode/score": 0.8002880670151171, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.01591303175291614}
{"step": 318672, "time": 10482.717832803726, "episode/length": 144.0, "episode/score": 0.6009336497851621, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.05093361452296108}
{"step": 318720, "time": 10484.23370218277, "episode/length": 241.0, "episode/score": 0.30822899756324773, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.06135399499046912}
{"step": 318800, "time": 10486.753762960434, "episode/length": 288.0, "episode/score": 0.04225942993465992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04225942993465992}
{"step": 318960, "time": 10491.932738542557, "episode/length": 63.0, "episode/score": 0.8194733176308091, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.01634827946986661}
{"step": 319176, "time": 10498.568646669388, "episode/length": 46.0, "episode/score": 0.878946344437054, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.02269632771981378}
{"step": 319528, "time": 10510.148302078247, "episode/length": 288.0, "episode/score": 0.05969351405195766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05969351405195766}
{"step": 319632, "time": 10513.667844772339, "episode/length": 169.0, "episode/score": 0.4945335978973162, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.022658571657302673}
{"step": 319680, "time": 10515.192083597183, "episode/length": 288.0, "episode/score": 0.032040379053540846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032040379053540846}
{"step": 319952, "time": 10523.891285896301, "episode/length": 159.0, "episode/score": 0.5316216324797551, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.028496606239741595}
{"step": 320008, "time": 10526.031247138977, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 320008, "time": 10526.644777536392, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 320008, "time": 10528.13985490799, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 320008, "time": 10528.89450955391, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 320008, "time": 10529.170883893967, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 320008, "time": 10529.276557207108, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 320008, "time": 10529.415501832962, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 320008, "time": 10529.462195634842, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 320024, "time": 10529.979935884476, "episode/length": 205.0, "episode/score": 0.39518976869521794, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.03581476051704158}
{"step": 320104, "time": 10532.484275817871, "episode/length": 71.0, "episode/score": 0.7876501872590325, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.009525219319812095}
{"step": 320544, "time": 10546.571608066559, "episode/length": 54.0, "episode/score": 0.8496129815541735, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.01836295531415999}
{"step": 320800, "time": 10554.710740089417, "episode/length": 105.0, "episode/score": 0.6975127509062986, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.02563772756502658}
{"step": 320880, "time": 10557.21240901947, "episode/length": 212.0, "episode/score": 0.3728641524081695, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.03536414685515865}
{"step": 321032, "time": 10561.765766143799, "episode/length": 288.0, "episode/score": 0.013310332143532833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013310332143532833}
{"step": 321048, "time": 10562.276457071304, "episode/length": 260.0, "episode/score": 0.21503877317695697, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.027538778415646448}
{"step": 321088, "time": 10563.776918888092, "episode/length": 181.0, "episode/score": 0.4587093648545988, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.02433437718298137}
{"step": 321272, "time": 10569.386172533035, "episode/length": 198.0, "episode/score": 0.39673761602989543, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.01548761483081762}
{"step": 321392, "time": 10573.460003614426, "episode/length": 37.0, "episode/score": 0.8934854812946469, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.009110525276355474}
{"step": 321744, "time": 10584.696786880493, "episode/length": 117.0, "episode/score": 0.6604700467827342, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.02609509076444283}
{"step": 322216, "time": 10599.391902446747, "episode/length": 117.0, "episode/score": 0.6565115218826918, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.022136545942828434}
{"step": 322336, "time": 10603.374113798141, "episode/length": 288.0, "episode/score": 0.032837675882205986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032837675882205986}
{"step": 322496, "time": 10608.417200088501, "episode/length": 180.0, "episode/score": 0.4838317052833645, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.046331693612728486}
{"step": 322520, "time": 10608.974491119385, "episode/length": 185.0, "episode/score": 0.44483070481430786, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.02295569812042686}
{"step": 322584, "time": 10611.09127831459, "episode/length": 104.0, "episode/score": 0.690419035528123, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.015419046715635432}
{"step": 322816, "time": 10618.631485462189, "episode/length": 177.0, "episode/score": 0.4614407476103679, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.014565738070132284}
{"step": 322856, "time": 10619.686846733093, "episode/length": 288.0, "episode/score": 0.032987302065407675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032987302065407675}
{"step": 323192, "time": 10630.277387619019, "episode/length": 288.0, "episode/score": 0.034340270680388585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034340270680388585}
{"step": 323248, "time": 10632.266525506973, "episode/length": 90.0, "episode/score": 0.7331529945146258, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.014402987355083496}
{"step": 323424, "time": 10637.806538581848, "episode/length": 135.0, "episode/score": 0.6058208408045971, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.02769581140972832}
{"step": 323792, "time": 10649.509003400803, "episode/length": 150.0, "episode/score": 0.562281745998348, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.031031738838805722}
{"step": 323832, "time": 10650.55422949791, "episode/length": 79.0, "episode/score": 0.7720893893130096, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.018964395523767053}
{"step": 324016, "time": 10656.55422592163, "episode/length": 73.0, "episode/score": 0.7822718655975791, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.010396856860609205}
{"step": 324400, "time": 10668.663305282593, "episode/length": 70.0, "episode/score": 0.8015651765944654, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.02031519970290674}
{"step": 324424, "time": 10669.201927661896, "episode/length": 240.0, "episode/score": 0.2756572427055062, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.025657233043034466}
{"step": 324528, "time": 10672.814364433289, "episode/length": 288.0, "episode/score": 0.0268999935523766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0268999935523766}
{"step": 324656, "time": 10676.858474969864, "episode/length": 107.0, "episode/score": 0.6825961314413007, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.016971151194070444}
{"step": 324656, "time": 10676.879432678223, "episode/length": 229.0, "episode/score": 0.30574961593652006, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.021374600435819957}
{"step": 324944, "time": 10685.926165819168, "episode/length": 67.0, "episode/score": 0.8178239993627017, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.027199016045017288}
{"step": 324952, "time": 10685.96273636818, "episode/length": 36.0, "episode/score": 0.8897338308983649, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0022338147049936197}
{"step": 325040, "time": 10688.94731593132, "episode/length": 76.0, "episode/score": 0.7819246689475108, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.019424681086718465}
{"step": 325168, "time": 10692.975838422775, "episode/length": 288.0, "episode/score": 0.024485844999276196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024485844999276196}
{"step": 325560, "time": 10705.210633039474, "episode/length": 288.0, "episode/score": 0.015287102242808714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015287102242808714}
{"step": 325896, "time": 10715.783167362213, "episode/length": 118.0, "episode/score": 0.6620352898523834, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.03078525783234909}
{"step": 326008, "time": 10719.31962966919, "episode/length": 120.0, "episode/score": 0.6447635108430347, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.019763481448165976}
{"step": 326152, "time": 10723.847120761871, "episode/length": 122.0, "episode/score": 0.638718647889192, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.019968657411965296}
{"step": 326328, "time": 10729.3750603199, "episode/length": 288.0, "episode/score": 0.03785995723140445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03785995723140445}
{"step": 326440, "time": 10733.01226758957, "episode/length": 67.0, "episode/score": 0.8106624633190904, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.020037472841863746}
{"step": 326600, "time": 10738.058490037918, "episode/length": 129.0, "episode/score": 0.6252157287248394, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.028340693462638455}
{"step": 326648, "time": 10739.56933927536, "episode/length": 25.0, "episode/score": 0.9344342936772136, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.012559285499037287}
{"step": 326672, "time": 10740.575940132141, "episode/length": 251.0, "episode/score": 0.23612057002074494, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.020495567447966323}
{"step": 326840, "time": 10745.642249584198, "episode/length": 288.0, "episode/score": 0.03764682942502873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03764682942502873}
{"step": 326848, "time": 10746.120347738266, "episode/length": 236.0, "episode/score": 0.29687818620902817, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.03437818995178077}
{"step": 327328, "time": 10761.308779478073, "episode/length": 90.0, "episode/score": 0.7391946322621834, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.020444633077090657}
{"step": 327480, "time": 10765.907659769058, "episode/length": 100.0, "episode/score": 0.7227881503855542, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.03528813606646963}
{"step": 327792, "time": 10776.456757068634, "episode/length": 182.0, "episode/score": 0.48540991750599005, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.05415989722644099}
{"step": 327984, "time": 10782.489877223969, "episode/length": 141.0, "episode/score": 0.604891299032488, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.04551628761214488}
{"step": 328248, "time": 10790.637414932251, "episode/length": 56.0, "episode/score": 0.8471844466687344, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.02218443524839131}
{"step": 328304, "time": 10792.72746706009, "episode/length": 121.0, "episode/score": 0.6582430304899844, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.03636801301604464}
{"step": 328320, "time": 10793.244590759277, "episode/length": 288.0, "episode/score": 0.058743829471723075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058743829471723075}
{"step": 328464, "time": 10797.820908784866, "episode/length": 288.0, "episode/score": 0.0686177583056633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0686177583056633}
{"step": 328600, "time": 10801.881669521332, "episode/length": 139.0, "episode/score": 0.6121303342929423, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0465052990307413}
{"step": 328888, "time": 10810.955403089523, "episode/length": 112.0, "episode/score": 0.6790286780437782, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.02902867249076735}
{"step": 328960, "time": 10813.45967388153, "episode/length": 288.0, "episode/score": 0.09096290129548379, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09096290129548379}
{"step": 329000, "time": 10814.48907327652, "episode/length": 86.0, "episode/score": 0.7595682507442234, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0283182332702836}
{"step": 329008, "time": 10814.969779014587, "episode/length": 85.0, "episode/score": 0.7554566189710386, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.02108161181149626}
{"step": 329152, "time": 10819.490539312363, "episode/length": 288.0, "episode/score": 0.055986770035474365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055986770035474365}
{"step": 329384, "time": 10826.690137147903, "episode/length": 47.0, "episode/score": 0.8712805918335107, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.01815560749719225}
{"step": 329408, "time": 10827.686841487885, "episode/length": 31.0, "episode/score": 0.9190321406622388, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.015907172723018448}
{"step": 329648, "time": 10835.232914686203, "episode/length": 130.0, "episode/score": 0.6463966128832226, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.05264660470504623}
{"step": 329912, "time": 10843.32838177681, "episode/length": 112.0, "episode/score": 0.6841206659955787, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.034120682677894365}
{"step": 329936, "time": 10844.307107686996, "episode/length": 68.0, "episode/score": 0.8117378575799421, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.024237853877934867}
{"step": 330096, "time": 10850.249654769897, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 330096, "time": 10851.357564687729, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 330096, "time": 10851.543873786926, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 330096, "time": 10851.603494167328, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 330096, "time": 10852.764707565308, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 330096, "time": 10852.823553323746, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 330096, "time": 10854.582611083984, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10854.603908061981, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10854.627919197083, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10854.646963357925, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330240, "time": 10859.200103282928, "episode/length": 73.0, "episode/score": 0.8037856100118006, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.03191058698484994}
{"step": 330560, "time": 10869.306654214859, "episode/length": 288.0, "episode/score": 0.0657650883089218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0657650883089218}
{"step": 330776, "time": 10875.844472646713, "episode/length": 288.0, "episode/score": 0.04621196759342183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04621196759342183}
{"step": 331200, "time": 10889.470914363861, "episode/length": 288.0, "episode/score": 0.0521877636449517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0521877636449517}
{"step": 331272, "time": 10891.513041496277, "episode/length": 288.0, "episode/score": 0.05201389983312765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05201389983312765}
{"step": 331400, "time": 10895.537299871445, "episode/length": 77.0, "episode/score": 0.7874313178144803, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0280563344967959}
{"step": 331512, "time": 10899.065602302551, "episode/length": 29.0, "episode/score": 0.9220222214022442, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.012647227613001633}
{"step": 331704, "time": 10905.121051073074, "episode/length": 182.0, "episode/score": 0.4792381795585925, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.04798817476228123}
{"step": 331720, "time": 10905.625936746597, "episode/length": 288.0, "episode/score": 0.05216898541368664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05216898541368664}
{"step": 331904, "time": 10911.687766313553, "episode/length": 22.0, "episode/score": 0.9399125716627168, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.008662566866405541}
{"step": 331904, "time": 10911.704495668411, "episode/length": 62.0, "episode/score": 0.8402738207275888, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.03402381593127757}
{"step": 332032, "time": 10915.738017320633, "episode/length": 103.0, "episode/score": 0.700295214510561, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.022170191483610324}
{"step": 332072, "time": 10916.774082660675, "episode/length": 266.0, "episode/score": 0.22655850674868816, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.057808504583363174}
{"step": 332224, "time": 10921.752846717834, "episode/length": 288.0, "episode/score": 0.04957434049765652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04957434049765652}
{"step": 332256, "time": 10922.75526714325, "episode/length": 43.0, "episode/score": 0.8847797751632243, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.019154737002281763}
{"step": 332784, "time": 10939.360758304596, "episode/length": 93.0, "episode/score": 0.7308042829258738, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.021429229689147178}
{"step": 332872, "time": 10941.959768533707, "episode/length": 288.0, "episode/score": 0.05459562428688969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05459562428688969}
{"step": 333040, "time": 10947.481355428696, "episode/length": 31.0, "episode/score": 0.9205618936534847, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.01743688223314166}
{"step": 333120, "time": 10950.060199022293, "episode/length": 176.0, "episode/score": 0.4949320620398794, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.044932059641723754}
{"step": 333312, "time": 10956.106078863144, "episode/length": 131.0, "episode/score": 0.6285679837646967, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0379429965005329}
{"step": 333320, "time": 10956.143520832062, "episode/length": 136.0, "episode/score": 0.6161353523400521, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.04113534994189649}
{"step": 333520, "time": 10962.672385454178, "episode/length": 180.0, "episode/score": 0.4763051069799076, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.03880509266082299}
{"step": 333800, "time": 10971.37706065178, "episode/length": 59.0, "episode/score": 0.8323947800206497, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.016769744758448724}
{"step": 333824, "time": 10972.367024898529, "episode/length": 288.0, "episode/score": 0.047506729198744324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047506729198744324}
{"step": 333904, "time": 10974.895590782166, "episode/length": 73.0, "episode/score": 0.7900441300855618, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.018169076848835175}
{"step": 333960, "time": 10976.437553882599, "episode/length": 54.0, "episode/score": 0.8438174540276577, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.012567433928552418}
{"step": 333992, "time": 10977.441495656967, "episode/length": 108.0, "episode/score": 0.6919793796650993, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.029479348663699056}
{"step": 334088, "time": 10980.458285093307, "episode/length": 130.0, "episode/score": 0.6305726407686052, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.03682265890029157}
{"step": 334216, "time": 10984.484993457794, "episode/length": 288.0, "episode/score": 0.04129046659465985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04129046659465985}
{"step": 334408, "time": 10990.51585817337, "episode/length": 62.0, "episode/score": 0.8229424420009082, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.016692483974452443}
{"step": 334448, "time": 10991.988802909851, "episode/length": 77.0, "episode/score": 0.7819176293063492, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.02254264497003078}
{"step": 334480, "time": 10992.99562883377, "episode/length": 60.0, "episode/score": 0.8303529928657554, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.01785299368066262}
{"step": 334632, "time": 10997.562987327576, "episode/length": 67.0, "episode/score": 0.8049257240415955, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.014300748101732097}
{"step": 334760, "time": 11001.702830553055, "episode/length": 43.0, "episode/score": 0.8804104297298636, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.014785391568921114}
{"step": 335032, "time": 11010.302829027176, "episode/length": 49.0, "episode/score": 0.8554580309006496, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.008583042088162074}
{"step": 335184, "time": 11015.376893281937, "episode/length": 288.0, "episode/score": 0.04770357295683425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04770357295683425}
{"step": 335256, "time": 11017.449068784714, "episode/length": 181.0, "episode/score": 0.4622289367478061, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.02785394049055867}
{"step": 335312, "time": 11019.474791526794, "episode/length": 107.0, "episode/score": 0.678253162941246, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.012628206922954632}
{"step": 335448, "time": 11023.554772615433, "episode/length": 185.0, "episode/score": 0.4637680243847626, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.04189303084581297}
{"step": 335984, "time": 11041.274991750717, "episode/length": 90.0, "episode/score": 0.7523175410804015, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.03356753290222514}
{"step": 336128, "time": 11045.866107463837, "episode/length": 136.0, "episode/score": 0.6009304354975029, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.02593044332934369}
{"step": 336472, "time": 11056.456174612045, "episode/length": 60.0, "episode/score": 0.8438525301853019, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.03135255329374331}
{"step": 336528, "time": 11058.438104867935, "episode/length": 288.0, "episode/score": 0.03785713398264079, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03785713398264079}
{"step": 336704, "time": 11064.09440279007, "episode/length": 156.0, "episode/score": 0.5526386504625975, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.040138682523377156}
{"step": 336792, "time": 11066.687508106232, "episode/length": 288.0, "episode/score": 0.026977098772476893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026977098772476893}
{"step": 336848, "time": 11068.673735141754, "episode/length": 46.0, "episode/score": 0.8796834728857448, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.023433502938360107}
{"step": 337072, "time": 11075.744690179825, "episode/length": 288.0, "episode/score": 0.030898585384932176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030898585384932176}
{"step": 337192, "time": 11079.31362771988, "episode/length": 49.0, "episode/score": 0.869217336602162, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.022342320592144915}
{"step": 337216, "time": 11080.292697668076, "episode/length": 45.0, "episode/score": 0.8742027908360797, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.014827783676537365}
{"step": 337224, "time": 11080.328064918518, "episode/length": 136.0, "episode/score": 0.6006500649453983, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.02565009700617793}
{"step": 337296, "time": 11082.826072216034, "episode/length": 95.0, "episode/score": 0.7411169413659877, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.03799195949767409}
{"step": 337496, "time": 11088.876361370087, "episode/length": 288.0, "episode/score": 0.042502266291194246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042502266291194246}
{"step": 337624, "time": 11092.969106912613, "episode/length": 288.0, "episode/score": 0.029151627356100107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029151627356100107}
{"step": 337680, "time": 11094.943401813507, "episode/length": 47.0, "episode/score": 0.8757138246312479, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.02258887469565707}
{"step": 337704, "time": 11095.47871351242, "episode/length": 59.0, "episode/score": 0.8401546844066843, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.02452969870830657}
{"step": 338016, "time": 11105.545894145966, "episode/length": 102.0, "episode/score": 0.7078911428118886, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.026641166872025224}
{"step": 338056, "time": 11106.610304355621, "episode/length": 43.0, "episode/score": 0.8806415109340833, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.015016501251238878}
{"step": 338304, "time": 11114.612713575363, "episode/length": 30.0, "episode/score": 0.9229093555009626, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.016659326106093886}
{"step": 338352, "time": 11116.140959262848, "episode/length": 159.0, "episode/score": 0.5501767185825202, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.047051706879869926}
{"step": 338632, "time": 11124.785823345184, "episode/length": 118.0, "episode/score": 0.6760756176060454, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.044825608869075495}
{"step": 339016, "time": 11136.860394239426, "episode/length": 288.0, "episode/score": 0.04583885234177387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04583885234177387}
{"step": 339256, "time": 11144.401498556137, "episode/length": 154.0, "episode/score": 0.5563054712365556, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.03755545113745029}
{"step": 339528, "time": 11153.09871673584, "episode/length": 288.0, "episode/score": 0.05470119977712784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05470119977712784}
{"step": 339528, "time": 11153.117492437363, "episode/length": 146.0, "episode/score": 0.5701674767265672, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.026417460009326987}
{"step": 339808, "time": 11162.150428771973, "episode/length": 288.0, "episode/score": 0.055589080572758576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055589080572758576}
{"step": 339936, "time": 11166.1759390831, "episode/length": 288.0, "episode/score": 0.039803861408131525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039803861408131525}
{"step": 340080, "time": 11171.282211303711, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 340080, "time": 11171.682336330414, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 340080, "time": 11171.879613399506, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 340080, "time": 11171.904408693314, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 340080, "time": 11172.053165435791, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 340080, "time": 11172.23320388794, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 340080, "time": 11172.48056936264, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 340080, "time": 11172.521189451218, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 340168, "time": 11175.078964948654, "episode/length": 113.0, "episode/score": 0.6780391717377938, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.031164148710843165}
{"step": 340256, "time": 11178.05541586876, "episode/length": 90.0, "episode/score": 0.7592800712286589, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.04053007204356618}
{"step": 340328, "time": 11180.110512971878, "episode/length": 99.0, "episode/score": 0.7195161261061003, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.028891090843899292}
{"step": 340616, "time": 11189.242202043533, "episode/length": 288.0, "episode/score": 0.046336774725944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046336774725944}
{"step": 340680, "time": 11191.245369672775, "episode/length": 52.0, "episode/score": 0.8548132998234905, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.017313295027179265}
{"step": 340944, "time": 11199.817304849625, "episode/length": 288.0, "episode/score": 0.04753067112176268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04753067112176268}
{"step": 340992, "time": 11201.3512301445, "episode/length": 131.0, "episode/score": 0.6318498290311254, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.04122482663296978}
{"step": 341056, "time": 11203.385503292084, "episode/length": 155.0, "episode/score": 0.5702587731320818, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.05463375881299726}
{"step": 341160, "time": 11206.478698015213, "episode/length": 67.0, "episode/score": 0.8143337802828228, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.023708804939587935}
{"step": 341193, "time": 11208.486485004425, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.390149303318299, "train/action_min": 0.0, "train/action_std": 1.521275047174434, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.003405404071318773, "train/actor_opt_grad_steps": 20255.0, "train/actor_opt_loss": 12.284150972616734, "train/adv_mag": 0.0581109379370188, "train/adv_max": 0.03267273245398531, "train/adv_mean": 0.005639471281028818, "train/adv_min": -0.03947504310263801, "train/adv_std": 0.005686126453153904, "train/cont_avg": 0.9961591897551546, "train/cont_loss_mean": 0.023887174576040858, "train/cont_loss_std": 0.3184626947718759, "train/cont_neg_acc": 0.00405872200128328, "train/cont_neg_loss": 5.191280300753104, "train/cont_pos_acc": 0.999969750950017, "train/cont_pos_loss": 0.003943061920545381, "train/cont_pred": 0.9960910001980889, "train/cont_rate": 0.9961591897551546, "train/dyn_loss_mean": 1.000023754601626, "train/dyn_loss_std": 0.0006495096323052757, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3884770501088159, "train/extr_critic_critic_opt_grad_steps": 20255.0, "train/extr_critic_critic_opt_loss": 11205.329979965367, "train/extr_critic_mag": 0.4993341178009191, "train/extr_critic_max": 0.4993341178009191, "train/extr_critic_mean": 0.4918058019937928, "train/extr_critic_min": 0.479576031571811, "train/extr_critic_std": 0.0033705270478319492, "train/extr_return_normed_mag": 0.07235128532365426, "train/extr_return_normed_max": 0.049313620347337626, "train/extr_return_normed_mean": 0.019004412862375024, "train/extr_return_normed_min": -0.025806836092594973, "train/extr_return_normed_std": 0.006812055413995283, "train/extr_return_rate": 0.4551922348421322, "train/extr_return_raw_mag": 0.5277544433615872, "train/extr_return_raw_max": 0.5277544433615872, "train/extr_return_raw_mean": 0.49744525674692136, "train/extr_return_raw_min": 0.4526339869216545, "train/extr_return_raw_std": 0.006812055413995283, "train/extr_reward_mag": 0.03249388810285588, "train/extr_reward_max": 0.03249388810285588, "train/extr_reward_mean": 0.0021166567988909744, "train/extr_reward_min": 1.2111418026009786e-05, "train/extr_reward_std": 0.004592917492906035, "train/image_loss_mean": 0.1519878623795878, "train/image_loss_std": 0.10844533517956734, "train/model_loss_mean": 0.7898604700860289, "train/model_loss_std": 0.40200318926081213, "train/model_opt_grad_norm": 34.571933736506196, "train/model_opt_grad_steps": 20236.0, "train/model_opt_loss": 3326.0547233660195, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4201.030927835051, "train/policy_entropy_mag": 1.5657120998372738, "train/policy_entropy_max": 1.5657120998372738, "train/policy_entropy_mean": 0.37558473539106624, "train/policy_entropy_min": 0.06473473935704871, "train/policy_entropy_std": 0.29628321290323417, "train/policy_logprob_mag": 6.550547673530185, "train/policy_logprob_max": -0.00861578084739674, "train/policy_logprob_mean": -0.3754661497996025, "train/policy_logprob_min": -6.550547673530185, "train/policy_logprob_std": 0.8172639795799845, "train/policy_randomness_mag": 0.8046169010634275, "train/policy_randomness_max": 0.8046169010634275, "train/policy_randomness_mean": 0.1930123834112256, "train/policy_randomness_min": 0.03326707719297139, "train/policy_randomness_std": 0.15225946077520086, "train/post_ent_mag": 36.054001523047376, "train/post_ent_max": 36.054001523047376, "train/post_ent_mean": 35.572883940234625, "train/post_ent_min": 35.17364590438371, "train/post_ent_std": 0.16250393213224165, "train/prior_ent_mag": 42.21277262500881, "train/prior_ent_max": 42.21277262500881, "train/prior_ent_mean": 38.57781742528542, "train/prior_ent_min": 36.512779216176455, "train/prior_ent_std": 0.8531264810218024, "train/rep_loss_mean": 1.000023754601626, "train/rep_loss_std": 0.0006495096323052757, "train/reward_avg": 0.0006101508982648794, "train/reward_loss_mean": 0.013971158610560844, "train/reward_loss_std": 0.10533687848232917, "train/reward_max_data": 0.3125167968994986, "train/reward_max_pred": 0.01733312901762343, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.010379342674325729, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.359265947341919, "train/reward_pred": 0.0005624789742215239, "train/reward_rate": 0.0006745328608247423, "train_stats/mean_log_entropy": 0.31189265019779827, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.021086271852254868, "report/cont_loss_std": 0.30868586897850037, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.62456750869751, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003033402608707547, "report/cont_pred": 0.9967942833900452, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12323275208473206, "report/image_loss_std": 0.099930040538311, "report/model_loss_mean": 0.755573570728302, "report/model_loss_std": 0.32271429896354675, "report/post_ent_mag": 35.72050476074219, "report/post_ent_max": 35.72050476074219, "report/post_ent_mean": 35.2440071105957, "report/post_ent_min": 34.921417236328125, "report/post_ent_std": 0.15161490440368652, "report/prior_ent_mag": 40.2005729675293, "report/prior_ent_max": 40.2005729675293, "report/prior_ent_mean": 37.37200164794922, "report/prior_ent_min": 35.54106903076172, "report/prior_ent_std": 0.8514216542243958, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00023981208505574614, "report/reward_loss_mean": 0.011254523880779743, "report/reward_loss_std": 0.015998106449842453, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.011705279350280762, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.011254524812102318, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0005535462405532598, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009827204048633575, "eval/cont_loss_std": 0.20014262199401855, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.400100231170654, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003580602118745446, "eval/cont_pred": 0.9964919686317444, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2624269723892212, "eval/image_loss_std": 0.14420126378536224, "eval/model_loss_mean": 0.8736607432365417, "eval/model_loss_std": 0.2439715564250946, "eval/post_ent_mag": 35.67585754394531, "eval/post_ent_max": 35.67585754394531, "eval/post_ent_mean": 35.199615478515625, "eval/post_ent_min": 34.87186813354492, "eval/post_ent_std": 0.14219868183135986, "eval/prior_ent_mag": 41.57391357421875, "eval/prior_ent_max": 41.57391357421875, "eval/prior_ent_mean": 37.32225799560547, "eval/prior_ent_min": 35.398372650146484, "eval/prior_ent_std": 0.9339438676834106, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014065206050872803, "eval/reward_loss_std": 0.0017573541263118386, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.007170915603637695, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014065206050872803, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002434736816212535, "eval/reward_rate": 0.0, "replay/size": 340689.0, "replay/inserts": 31168.0, "replay/samples": 31168.0, "replay/insert_wait_avg": 1.338740822226115e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.627465839503483e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 77120.0, "eval_replay/inserts": 4568.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1133333429981238e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2663376331329, "timer/env.step_count": 3896.0, "timer/env.step_total": 37.59713101387024, "timer/env.step_frac": 0.0375871201492534, "timer/env.step_avg": 0.009650187631896878, "timer/env.step_min": 0.007790088653564453, "timer/env.step_max": 0.03912687301635742, "timer/replay._sample_count": 31168.0, "timer/replay._sample_total": 15.79832410812378, "timer/replay._sample_frac": 0.01579411754024069, "timer/replay._sample_avg": 0.0005068764151733759, "timer/replay._sample_min": 0.00037860870361328125, "timer/replay._sample_max": 0.01089930534362793, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4467.0, "timer/agent.policy_total": 45.29486346244812, "timer/agent.policy_frac": 0.045282802947889354, "timer/agent.policy_avg": 0.010139884365893916, "timer/agent.policy_min": 0.008617401123046875, "timer/agent.policy_max": 0.0885772705078125, "timer/dataset_train_count": 1948.0, "timer/dataset_train_total": 0.2237555980682373, "timer/dataset_train_frac": 0.0002236960193998891, "timer/dataset_train_avg": 0.0001148642700555633, "timer/dataset_train_min": 9.918212890625e-05, "timer/dataset_train_max": 0.0010218620300292969, "timer/agent.train_count": 1948.0, "timer/agent.train_total": 869.9907040596008, "timer/agent.train_frac": 0.8697590544916316, "timer/agent.train_avg": 0.44660713760759796, "timer/agent.train_min": 0.4364900588989258, "timer/agent.train_max": 0.5968365669250488, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4729423522949219, "timer/agent.report_frac": 0.0004728164234877838, "timer/agent.report_avg": 0.23647117614746094, "timer/agent.report_min": 0.23519444465637207, "timer/agent.report_max": 0.2377479076385498, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.66957707709732e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 31.159117702405315}
{"step": 341328, "time": 11212.826221942902, "episode/length": 288.0, "episode/score": 0.04594046932049878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04594046932049878}
{"step": 341384, "time": 11214.365334272385, "episode/length": 27.0, "episode/score": 0.9267121581524407, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.011087158653026563}
{"step": 341392, "time": 11214.866908788681, "episode/length": 55.0, "episode/score": 0.841224827164524, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.013099812845439374}
{"step": 341696, "time": 11224.451792240143, "episode/length": 87.0, "episode/score": 0.7433432391082988, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.015218233555287952}
{"step": 341720, "time": 11225.01431965828, "episode/length": 82.0, "episode/score": 0.7656374299435811, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.02188742439057023}
{"step": 342056, "time": 11235.605803251266, "episode/length": 41.0, "episode/score": 0.8871153953634803, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.015240383943137203}
{"step": 342136, "time": 11238.126637458801, "episode/length": 92.0, "episode/score": 0.7451497281872435, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.03264972868782934}
{"step": 342328, "time": 11244.241920471191, "episode/length": 78.0, "episode/score": 0.7785405983486271, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.022290551165497163}
{"step": 342440, "time": 11247.777366399765, "episode/length": 138.0, "episode/score": 0.5989520427647221, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.030202004603779642}
{"step": 342480, "time": 11249.250750780106, "episode/length": 288.0, "episode/score": 0.03713090128519525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03713090128519525}
{"step": 342640, "time": 11254.265030145645, "episode/length": 288.0, "episode/score": 0.02552341967270877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02552341967270877}
{"step": 342672, "time": 11255.284481287003, "episode/length": 66.0, "episode/score": 0.8130149288288067, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.019264933590193323}
{"step": 342904, "time": 11262.402377843857, "episode/length": 71.0, "episode/score": 0.7957297779205419, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.01760476650019882}
{"step": 342904, "time": 11262.422610282898, "episode/length": 57.0, "episode/score": 0.8320783065406658, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.01020331606343916}
{"step": 342992, "time": 11265.412326812744, "episode/length": 288.0, "episode/score": 0.02220359233092495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02220359233092495}
{"step": 343304, "time": 11275.028940677643, "episode/length": 78.0, "episode/score": 0.7837160155314677, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.027465977370525252}
{"step": 343376, "time": 11277.527713775635, "episode/length": 91.0, "episode/score": 0.7472851709551378, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.03166016855698217}
{"step": 343472, "time": 11280.547528982162, "episode/length": 70.0, "episode/score": 0.7948025656587561, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.013552536263887305}
{"step": 343696, "time": 11287.5675842762, "episode/length": 288.0, "episode/score": 0.03368246415186604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03368246415186604}
{"step": 343776, "time": 11290.073519945145, "episode/length": 49.0, "episode/score": 0.8565494111931002, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.009674384953086701}
{"step": 343904, "time": 11294.091066122055, "episode/length": 177.0, "episode/score": 0.49824800440808303, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.051372999611771775}
{"step": 343952, "time": 11295.619248390198, "episode/length": 80.0, "episode/score": 0.7669217883094461, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.016921758914577367}
{"step": 344256, "time": 11305.694810152054, "episode/length": 69.0, "episode/score": 0.7998108726415012, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.015435831325703475}
{"step": 344368, "time": 11309.218827486038, "episode/length": 288.0, "episode/score": 0.024186443002690794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024186443002690794}
{"step": 344568, "time": 11315.294582605362, "episode/length": 136.0, "episode/score": 0.6095059777326242, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.03450596631228109}
{"step": 345192, "time": 11336.149219989777, "episode/length": 102.0, "episode/score": 0.7157530315027998, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.03450302670648853}
{"step": 345216, "time": 11337.138012886047, "episode/length": 288.0, "episode/score": 0.04735100014022464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04735100014022464}
{"step": 345304, "time": 11339.727270126343, "episode/length": 288.0, "episode/score": 0.04194696832610134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04194696832610134}
{"step": 345608, "time": 11349.295129776001, "episode/length": 51.0, "episode/score": 0.8618771714341165, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.021252169035960833}
{"step": 345640, "time": 11350.304938793182, "episode/length": 52.0, "episode/score": 0.8526530833378274, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.015153092860600736}
{"step": 345968, "time": 11360.904836654663, "episode/length": 82.0, "episode/score": 0.7622419373024059, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.018491937802991743}
{"step": 346064, "time": 11363.93796658516, "episode/length": 56.0, "episode/score": 0.8345882559729034, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.00958823849896362}
{"step": 346088, "time": 11364.479500770569, "episode/length": 288.0, "episode/score": 0.04334164263389084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04334164263389084}
{"step": 346216, "time": 11368.52967953682, "episode/length": 288.0, "episode/score": 0.04183237212464519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04183237212464519}
{"step": 346264, "time": 11370.04287981987, "episode/length": 288.0, "episode/score": 0.03521437375172809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03521437375172809}
{"step": 346568, "time": 11379.634719848633, "episode/length": 288.0, "episode/score": 0.02829578969431168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02829578969431168}
{"step": 346656, "time": 11382.631546258926, "episode/length": 73.0, "episode/score": 0.7949643363863288, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0230892982253863}
{"step": 346712, "time": 11384.203227996826, "episode/length": 55.0, "episode/score": 0.8466498067896282, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.018524792470543616}
{"step": 346880, "time": 11389.74335885048, "episode/length": 288.0, "episode/score": 0.02779815380904438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02779815380904438}
{"step": 346936, "time": 11391.441076040268, "episode/length": 120.0, "episode/score": 0.6600914405469211, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.03509141720564912}
{"step": 347664, "time": 11414.657654762268, "episode/length": 97.0, "episode/score": 0.7291140119663169, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.03223900717000561}
{"step": 347728, "time": 11416.667477369308, "episode/length": 144.0, "episode/score": 0.6002251775654486, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.05022516645942687}
{"step": 347952, "time": 11423.861429691315, "episode/length": 288.0, "episode/score": 0.041519646586039016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041519646586039016}
{"step": 348040, "time": 11426.418456077576, "episode/length": 10.0, "episode/score": 0.9775368890695972, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.008786860431428067}
{"step": 348088, "time": 11427.927091360092, "episode/length": 233.0, "episode/score": 0.332624735853301, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.060749742977918686}
{"step": 348400, "time": 11437.94525194168, "episode/length": 288.0, "episode/score": 0.04815742000130285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04815742000130285}
{"step": 348472, "time": 11440.005788326263, "episode/length": 47.0, "episode/score": 0.8675252335274308, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.014400258184195991}
{"step": 348584, "time": 11443.526500701904, "episode/length": 114.0, "episode/score": 0.6737088987815696, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.029958872541556048}
{"step": 348704, "time": 11447.546509981155, "episode/length": 121.0, "episode/score": 0.654606873469902, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.032731871071746355}
{"step": 348968, "time": 11455.772459030151, "episode/length": 288.0, "episode/score": 0.05536189053589169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05536189053589169}
{"step": 349024, "time": 11457.762009382248, "episode/length": 288.0, "episode/score": 0.054959162659997673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054959162659997673}
{"step": 349160, "time": 11461.830552339554, "episode/length": 71.0, "episode/score": 0.8026060015454277, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.024480984828187502}
{"step": 349248, "time": 11464.853793621063, "episode/length": 288.0, "episode/score": 0.053747217569252825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053747217569252825}
{"step": 349640, "time": 11476.96796298027, "episode/length": 48.0, "episode/score": 0.8679507586391537, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.017950720478211224}
{"step": 349720, "time": 11479.5161485672, "episode/length": 93.0, "episode/score": 0.7410225580167662, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.03164751083363626}
{"step": 350064, "time": 11491.28225016594, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 350064, "time": 11492.21203827858, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 350064, "time": 11492.655476808548, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 350064, "time": 11492.854994058609, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 350064, "time": 11492.956144809723, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 350064, "time": 11495.299293518066, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 350064, "time": 11495.323810577393, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 350064, "time": 11495.854009866714, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11495.874678134918, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11495.89518046379, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350352, "time": 11504.945016622543, "episode/length": 288.0, "episode/score": 0.05234292337922852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05234292337922852}
{"step": 350712, "time": 11516.171748638153, "episode/length": 288.0, "episode/score": 0.06408703814986438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06408703814986438}
{"step": 350784, "time": 11518.651413917542, "episode/length": 288.0, "episode/score": 0.03321233302563087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03321233302563087}
{"step": 351016, "time": 11525.736342906952, "episode/length": 288.0, "episode/score": 0.038687761678033894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038687761678033894}
{"step": 351096, "time": 11528.240929603577, "episode/length": 181.0, "episode/score": 0.47105609976370033, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.036681112848782504}
{"step": 351336, "time": 11535.778579235077, "episode/length": 288.0, "episode/score": 0.04180618972588945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04180618972588945}
{"step": 351472, "time": 11540.283095359802, "episode/length": 288.0, "episode/score": 0.04955033344356252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04955033344356252}
{"step": 351536, "time": 11542.400082826614, "episode/length": 64.0, "episode/score": 0.8291132207100418, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.029113209604020085}
{"step": 351632, "time": 11545.436185359955, "episode/length": 159.0, "episode/score": 0.5414130064316396, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.03828796587254146}
{"step": 351656, "time": 11545.97416806221, "episode/length": 69.0, "episode/score": 0.8085164462790999, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.024141435173078207}
{"step": 351672, "time": 11546.484762907028, "episode/length": 24.0, "episode/score": 0.935127811395887, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.010127785155873426}
{"step": 352000, "time": 11557.037870645523, "episode/length": 57.0, "episode/score": 0.8374056884092624, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.015530682856251588}
{"step": 352032, "time": 11558.053731918335, "episode/length": 288.0, "episode/score": 0.047490076589383534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047490076589383534}
{"step": 352504, "time": 11573.29006576538, "episode/length": 62.0, "episode/score": 0.8354980174879074, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.029248011934896567}
{"step": 353024, "time": 11589.876621484756, "episode/length": 288.0, "episode/score": 0.02834195719606214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02834195719606214}
{"step": 353096, "time": 11591.930334091187, "episode/length": 288.0, "episode/score": 0.036824513382725854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036824513382725854}
{"step": 353648, "time": 11609.714911460876, "episode/length": 288.0, "episode/score": 0.03348512116394886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03348512116394886}
{"step": 353760, "time": 11613.250107049942, "episode/length": 82.0, "episode/score": 0.7765825948670226, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.03283259536760852}
{"step": 353872, "time": 11616.786062717438, "episode/length": 105.0, "episode/score": 0.6827636904622523, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.010888661824083101}
{"step": 353896, "time": 11617.32010769844, "episode/length": 232.0, "episode/score": 0.30225873736389985, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.027258717084350792}
{"step": 353944, "time": 11618.837860107422, "episode/length": 288.0, "episode/score": 0.030932777185284976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030932777185284976}
{"step": 353968, "time": 11619.818751335144, "episode/length": 288.0, "episode/score": 0.035869772179808024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035869772179808024}
{"step": 353984, "time": 11620.325205087662, "episode/length": 288.0, "episode/score": 0.055871216682248814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055871216682248814}
{"step": 354688, "time": 11642.490540266037, "episode/length": 98.0, "episode/score": 0.7184685723527764, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.024718525169646455}
{"step": 354816, "time": 11646.498499155045, "episode/length": 288.0, "episode/score": 0.04052547684000274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04052547684000274}
{"step": 355672, "time": 11673.256443977356, "episode/length": 106.0, "episode/score": 0.6986674920904079, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.029917474616468098}
{"step": 355856, "time": 11679.28389453888, "episode/length": 22.0, "episode/score": 0.9404117734907231, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.009161789154404687}
{"step": 355952, "time": 11682.324277162552, "episode/length": 157.0, "episode/score": 0.5487649558411363, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.039389965363909596}
{"step": 355960, "time": 11682.366012573242, "episode/length": 288.0, "episode/score": 0.011633048563624016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.011633048563624016}
{"step": 356072, "time": 11685.893241882324, "episode/length": 288.0, "episode/score": 0.020913481562331526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020913481562331526}
{"step": 356184, "time": 11689.42819404602, "episode/length": 288.0, "episode/score": 0.059403411666380634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059403411666380634}
{"step": 356256, "time": 11692.002067804337, "episode/length": 288.0, "episode/score": 0.04621136038281293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04621136038281293}
{"step": 356280, "time": 11692.563970088959, "episode/length": 288.0, "episode/score": 0.050960892278965275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050960892278965275}
{"step": 356296, "time": 11693.081750631332, "episode/length": 288.0, "episode/score": 0.04985401242004173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04985401242004173}
{"step": 356464, "time": 11698.60278081894, "episode/length": 62.0, "episode/score": 0.8145863489319822, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.008336390905526514}
{"step": 356552, "time": 11701.148502111435, "episode/length": 86.0, "episode/score": 0.7497282302384178, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.018478260291033166}
{"step": 356968, "time": 11714.267270565033, "episode/length": 88.0, "episode/score": 0.7439007275419272, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.01890071880495725}
{"step": 357944, "time": 11745.158739328384, "episode/length": 205.0, "episode/score": 0.40346186425375663, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.04408686016466845}
{"step": 358048, "time": 11748.662597417831, "episode/length": 134.0, "episode/score": 0.6062007856148739, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.02495076551576858}
{"step": 358264, "time": 11755.309418916702, "episode/length": 288.0, "episode/score": 0.04772441693256724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04772441693256724}
{"step": 358384, "time": 11759.324203968048, "episode/length": 288.0, "episode/score": 0.04518940271759675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04518940271759675}
{"step": 358496, "time": 11762.829169511795, "episode/length": 288.0, "episode/score": 0.03316048721910647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03316048721910647}
{"step": 358592, "time": 11765.862927913666, "episode/length": 288.0, "episode/score": 0.04130366684069031, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04130366684069031}
{"step": 358776, "time": 11771.505416870117, "episode/length": 288.0, "episode/score": 0.03249708012475594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03249708012475594}
{"step": 358864, "time": 11774.505588769913, "episode/length": 288.0, "episode/score": 0.044556518702165704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044556518702165704}
{"step": 359272, "time": 11787.195127487183, "episode/length": 96.0, "episode/score": 0.7213099840083146, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.021309972587971515}
{"step": 359400, "time": 11791.241636276245, "episode/length": 168.0, "episode/score": 0.5082442333332438, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.03324424045786145}
{"step": 359408, "time": 11791.721412658691, "episode/length": 78.0, "episode/score": 0.7702993469630428, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.014049293726316137}
{"step": 359416, "time": 11791.759151935577, "episode/length": 183.0, "episode/score": 0.4873153955697944, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.05919040234516615}
{"step": 359584, "time": 11797.265732765198, "episode/length": 164.0, "episode/score": 0.5163088998010039, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.028808873560990378}
{"step": 359728, "time": 11801.790999889374, "episode/length": 107.0, "episode/score": 0.6777523869795914, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.012127406732361123}
{"step": 359792, "time": 11803.829928159714, "episode/length": 149.0, "episode/score": 0.5624389673061501, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.028063981607772348}
{"step": 359928, "time": 11807.883211374283, "episode/length": 16.0, "episode/score": 0.9598989171512358, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.009898921912622427}
{"step": 360000, "time": 11810.451833724976, "episode/length": 201.0, "episode/score": 0.42148587811567495, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.04961089085151116}
{"step": 360048, "time": 11813.190393924713, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 360048, "time": 11813.298630952835, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 360048, "time": 11813.638865947723, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 360048, "time": 11814.291479349136, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 360048, "time": 11814.438358068466, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 360048, "time": 11815.391037940979, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 360048, "time": 11816.564182043076, "eval_episode/length": 242.0, "eval_episode/score": 0.24375000596046448, "eval_episode/reward_rate": 0.00411522633744856}
{"step": 360048, "time": 11817.445363759995, "eval_episode/length": 199.0, "eval_episode/score": 0.37812501192092896, "eval_episode/reward_rate": 0.005}
{"step": 360080, "time": 11818.448685646057, "episode/length": 100.0, "episode/score": 0.7043291322885921, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.016829124110415705}
{"step": 360080, "time": 11818.467319726944, "episode/length": 43.0, "episode/score": 0.8740848069857634, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.008459754505736328}
{"step": 360128, "time": 11819.998889684677, "episode/length": 88.0, "episode/score": 0.737889087815347, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.012889049654404516}
{"step": 360640, "time": 11836.626244068146, "episode/length": 69.0, "episode/score": 0.8113507325049341, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.026975697242733077}
{"step": 360944, "time": 11846.317551612854, "episode/length": 107.0, "episode/score": 0.6938128165288617, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.028187811732550472}
{"step": 361032, "time": 11848.85929608345, "episode/length": 128.0, "episode/score": 0.6306533573576871, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.030653319196744633}
{"step": 361264, "time": 11856.421000957489, "episode/length": 232.0, "episode/score": 0.3033425364638731, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.02834251618432404}
{"step": 361720, "time": 11870.608929157257, "episode/length": 288.0, "episode/score": 0.06449019872704298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06449019872704298}
{"step": 361896, "time": 11876.165477514267, "episode/length": 288.0, "episode/score": 0.0373710297354819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0373710297354819}
{"step": 362240, "time": 11887.235444784164, "episode/length": 288.0, "episode/score": 0.03606937842340585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03606937842340585}
{"step": 362440, "time": 11893.411350488663, "episode/length": 288.0, "episode/score": 0.048367314407073536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048367314407073536}
{"step": 362800, "time": 11905.169347286224, "episode/length": 69.0, "episode/score": 0.7967645147986104, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.012389495718139187}
{"step": 362952, "time": 11909.740518331528, "episode/length": 288.0, "episode/score": 0.05144881840283233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05144881840283233}
{"step": 363256, "time": 11919.29600906372, "episode/length": 288.0, "episode/score": 0.043676349087718336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043676349087718336}
{"step": 363344, "time": 11922.30251455307, "episode/length": 288.0, "episode/score": 0.05989396681582093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05989396681582093}
{"step": 363576, "time": 11929.393231630325, "episode/length": 288.0, "episode/score": 0.05950008132617768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05950008132617768}
{"step": 363616, "time": 11930.940283298492, "episode/length": 101.0, "episode/score": 0.7131079259698936, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.028732914549550514}
{"step": 363776, "time": 11935.988997936249, "episode/length": 24.0, "episode/score": 0.9327796746812282, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.00777965458212293}
{"step": 364032, "time": 11944.03265452385, "episode/length": 288.0, "episode/score": 0.04905309720106743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04905309720106743}
{"step": 364168, "time": 11948.093543052673, "episode/length": 215.0, "episode/score": 0.36348272459702, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.03535772500447365}
{"step": 364208, "time": 11949.585657596588, "episode/length": 288.0, "episode/score": 0.0531605779034976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0531605779034976}
{"step": 364536, "time": 11959.716093540192, "episode/length": 197.0, "episode/score": 0.4026870498422568, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.01831202956270772}
{"step": 364648, "time": 11963.345554113388, "episode/length": 173.0, "episode/score": 0.4715551067133674, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.012180119134882261}
{"step": 365112, "time": 11977.989254951477, "episode/length": 57.0, "episode/score": 0.8341098177671142, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.012234861748822823}
{"step": 365576, "time": 11992.74301481247, "episode/length": 170.0, "episode/score": 0.5016254774964182, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.03287546931824181}
{"step": 365656, "time": 11995.26691365242, "episode/length": 288.0, "episode/score": 0.038489254133594386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038489254133594386}
{"step": 365928, "time": 12003.82979464531, "episode/length": 288.0, "episode/score": 0.06403322669024192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06403322669024192}
{"step": 366088, "time": 12008.912925243378, "episode/length": 288.0, "episode/score": 0.03770091901679962, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03770091901679962}
{"step": 366344, "time": 12017.004460573196, "episode/length": 288.0, "episode/score": 0.05853907679124859, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05853907679124859}
{"step": 366480, "time": 12021.615056753159, "episode/length": 288.0, "episode/score": 0.05258793766324743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05258793766324743}
{"step": 366848, "time": 12033.192833185196, "episode/length": 288.0, "episode/score": 0.04576031925194002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04576031925194002}
{"step": 367424, "time": 12051.406380176544, "episode/length": 288.0, "episode/score": 0.0615558602688111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0615558602688111}
{"step": 367584, "time": 12056.474815130234, "episode/length": 250.0, "episode/score": 0.2551072896486062, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.03635728248906389}
{"step": 367776, "time": 12062.523561000824, "episode/length": 43.0, "episode/score": 0.8745754097516283, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.008950406049621051}
{"step": 367792, "time": 12063.053486824036, "episode/length": 266.0, "episode/score": 0.2061101596118533, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.03736016187031055}
{"step": 367968, "time": 12068.627220153809, "episode/length": 234.0, "episode/score": 0.3050740157046903, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.036324004002040056}
{"step": 368120, "time": 12073.194771766663, "episode/length": 158.0, "episode/score": 0.5337846970677447, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.027534696334328146}
{"step": 368240, "time": 12077.185186386108, "episode/length": 288.0, "episode/score": 0.04073629066238027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04073629066238027}
{"step": 368272, "time": 12078.219158649445, "episode/length": 240.0, "episode/score": 0.27855764245913406, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.028557630788498045}
{"step": 368280, "time": 12078.254441022873, "episode/length": 38.0, "episode/score": 0.8898995484869943, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.008649524863415081}
{"step": 368544, "time": 12086.929719209671, "episode/length": 95.0, "episode/score": 0.722331763446789, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.019206734051920193}
{"step": 368680, "time": 12091.534034013748, "episode/length": 49.0, "episode/score": 0.8522247081469914, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0053497143577487805}
{"step": 368792, "time": 12095.060902357101, "episode/length": 288.0, "episode/score": 0.06608376657470671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06608376657470671}
{"step": 369416, "time": 12114.75405049324, "episode/length": 202.0, "episode/score": 0.3954394928372267, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.02668947721429049}
{"step": 369472, "time": 12116.731765985489, "episode/length": 115.0, "episode/score": 0.649607561187338, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.00898255300916162}
{"step": 369488, "time": 12117.241329908371, "episode/length": 151.0, "episode/score": 0.5564363835773634, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.028311413629978688}
{"step": 369704, "time": 12123.792756080627, "episode/length": 182.0, "episode/score": 0.47494501057468597, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.04369500483250022}
{"step": 369896, "time": 12129.844346046448, "episode/length": 288.0, "episode/score": 0.043860834532779336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043860834532779336}
{"step": 370032, "time": 12135.007616519928, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 370032, "time": 12135.650527477264, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 370032, "time": 12135.942432641983, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 370032, "time": 12136.113066196442, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 370032, "time": 12136.156320810318, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 370032, "time": 12136.325329303741, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 370032, "time": 12137.689802408218, "eval_episode/length": 181.0, "eval_episode/score": 0.43437498807907104, "eval_episode/reward_rate": 0.005494505494505495}
{"step": 370032, "time": 12137.731940031052, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 370424, "time": 12149.97117447853, "episode/length": 287.0, "episode/score": 0.14102174820439473, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.03789675045121044}
{"step": 370744, "time": 12160.146943807602, "episode/length": 105.0, "episode/score": 0.6965590813698554, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.024684096474743455}
{"step": 370752, "time": 12160.62766957283, "episode/length": 159.0, "episode/score": 0.5311990501958235, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.02807403418580634}
{"step": 370992, "time": 12168.18260025978, "episode/length": 288.0, "episode/score": 0.029076469969822938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029076469969822938}
{"step": 371104, "time": 12171.790051698685, "episode/length": 288.0, "episode/score": 0.018624904074897586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018624904074897586}
{"step": 371304, "time": 12177.946208238602, "episode/length": 69.0, "episode/score": 0.7948275154620319, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.01045251864599095}
{"step": 371504, "time": 12184.541471242905, "episode/length": 93.0, "episode/score": 0.720457770142616, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.011082772523309359}
{"step": 371728, "time": 12191.593894720078, "episode/length": 288.0, "episode/score": 0.03878677098754224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03878677098754224}
{"step": 371776, "time": 12193.107889175415, "episode/length": 83.0, "episode/score": 0.7655171824904698, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.024892172807625457}
{"step": 371800, "time": 12193.6623442173, "episode/length": 288.0, "episode/score": 0.017859723604686906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017859723604686906}
{"step": 371888, "time": 12196.646933078766, "episode/length": 72.0, "episode/score": 0.7902220386170029, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.015222080590547193}
{"step": 371952, "time": 12198.673335790634, "episode/length": 119.0, "episode/score": 0.661618977691063, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.03349397784822372}
{"step": 372016, "time": 12200.770920753479, "episode/length": 288.0, "episode/score": 0.0462742785303476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0462742785303476}
{"step": 372249, "time": 12208.87378692627, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2586103616301547, "train/action_min": 0.0, "train/action_std": 1.4230583764843105, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008577148187617512, "train/actor_opt_grad_steps": 22195.0, "train/actor_opt_loss": 8.24990330482881, "train/adv_mag": 0.4041457369769971, "train/adv_max": 0.18511080311745712, "train/adv_mean": 0.007960682559023928, "train/adv_min": -0.35444651098595453, "train/adv_std": 0.019950420286064755, "train/cont_avg": 0.9958873630798969, "train/cont_loss_mean": 0.02221105258417383, "train/cont_loss_std": 0.29438389181735514, "train/cont_neg_acc": 0.058093585656024516, "train/cont_neg_loss": 4.442687865967552, "train/cont_pos_acc": 0.9999292105743566, "train/cont_pos_loss": 0.0038770735989920027, "train/cont_pred": 0.9959321467532325, "train/cont_rate": 0.9958873630798969, "train/dyn_loss_mean": 1.000032077130583, "train/dyn_loss_std": 0.0010081060560325342, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.6497536713507065, "train/extr_critic_critic_opt_grad_steps": 22195.0, "train/extr_critic_critic_opt_loss": 10859.271812832232, "train/extr_critic_mag": 0.7404974490096888, "train/extr_critic_max": 0.7404974490096888, "train/extr_critic_mean": 0.715473662946642, "train/extr_critic_min": 0.6804631481465605, "train/extr_critic_std": 0.008320854599623624, "train/extr_return_normed_mag": 0.40454351195355054, "train/extr_return_normed_max": 0.21699413626464373, "train/extr_return_normed_mean": 0.031572065298738364, "train/extr_return_normed_min": -0.32484524090265493, "train/extr_return_normed_std": 0.02259789168901895, "train/extr_return_rate": 0.9989707771035814, "train/extr_return_raw_mag": 0.9088564045035962, "train/extr_return_raw_max": 0.9088564045035962, "train/extr_return_raw_mean": 0.7234343698958761, "train/extr_return_raw_min": 0.3670170273362976, "train/extr_return_raw_std": 0.02259789161220884, "train/extr_reward_mag": 0.20112455997270406, "train/extr_reward_max": 0.20112455997270406, "train/extr_reward_mean": 0.002899799231000571, "train/extr_reward_min": 1.0545106278252356e-05, "train/extr_reward_std": 0.010280535714796831, "train/image_loss_mean": 0.13247316296106762, "train/image_loss_std": 0.10815518076733216, "train/model_loss_mean": 0.7704782578134045, "train/model_loss_std": 0.40847153927093927, "train/model_opt_grad_norm": 31.920280623681766, "train/model_opt_grad_steps": 22174.0, "train/model_opt_loss": 2019.2978352025611, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2628.865979381443, "train/policy_entropy_mag": 1.4849157751221018, "train/policy_entropy_max": 1.4849157751221018, "train/policy_entropy_mean": 0.21780184817682838, "train/policy_entropy_min": 0.06469263497394384, "train/policy_entropy_std": 0.23640912471665548, "train/policy_logprob_mag": 6.5510582235670585, "train/policy_logprob_max": -0.008609271493077893, "train/policy_logprob_mean": -0.21797863624452316, "train/policy_logprob_min": -6.5510582235670585, "train/policy_logprob_std": 0.7359133246018714, "train/policy_randomness_mag": 0.7630958010240928, "train/policy_randomness_max": 0.7630958010240928, "train/policy_randomness_mean": 0.111928015294456, "train/policy_randomness_min": 0.03324543982360166, "train/policy_randomness_std": 0.12149026471468591, "train/post_ent_mag": 33.717706464000585, "train/post_ent_max": 33.717706464000585, "train/post_ent_mean": 33.37274840443405, "train/post_ent_min": 33.10564973182285, "train/post_ent_std": 0.1098434191926853, "train/prior_ent_mag": 39.64673612535614, "train/prior_ent_max": 39.64673612535614, "train/prior_ent_mean": 36.30425730439806, "train/prior_ent_min": 34.47151622575583, "train/prior_ent_std": 0.8449174417662866, "train/rep_loss_mean": 1.000032077130583, "train/rep_loss_std": 0.0010081060560325342, "train/reward_avg": 0.000872926045069351, "train/reward_loss_mean": 0.01577477256489015, "train/reward_loss_std": 0.13337364448138425, "train/reward_max_data": 0.4509970377146545, "train/reward_max_pred": 0.051562251503934564, "train/reward_neg_acc": 0.9999294262571433, "train/reward_neg_loss": 0.010539871717313515, "train/reward_pos_acc": 0.04233871015810197, "train/reward_pos_loss": 5.030990475608457, "train/reward_pred": 0.0007542929169241839, "train/reward_rate": 0.0010420022551546392, "train_stats/mean_log_entropy": 0.18952441027059275, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.023604441434144974, "report/cont_loss_std": 0.3682464361190796, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.804574489593506, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003679945133626461, "report/cont_pred": 0.9963662624359131, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11273229122161865, "report/image_loss_std": 0.10223393142223358, "report/model_loss_mean": 0.7455964088439941, "report/model_loss_std": 0.38615626096725464, "report/post_ent_mag": 32.65261459350586, "report/post_ent_max": 32.65261459350586, "report/post_ent_mean": 32.38315963745117, "report/post_ent_min": 32.14818572998047, "report/post_ent_std": 0.0891137644648552, "report/prior_ent_mag": 38.91530227661133, "report/prior_ent_max": 38.91530227661133, "report/prior_ent_mean": 34.94462585449219, "report/prior_ent_min": 33.03385925292969, "report/prior_ent_std": 0.8890759944915771, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00019108450214844197, "report/reward_loss_mean": 0.009259603917598724, "report/reward_loss_std": 0.014640980400145054, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.025285005569458008, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009259604848921299, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0006103413179516792, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.031311966478824615, "eval/cont_loss_std": 0.445558100938797, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.091116905212402, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0036264564841985703, "eval/cont_pred": 0.9964554309844971, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.000049352645874, "eval/dyn_loss_std": 0.0015775562496855855, "eval/image_loss_mean": 0.20094916224479675, "eval/image_loss_std": 0.13850653171539307, "eval/model_loss_mean": 0.8334925174713135, "eval/model_loss_std": 0.4624193608760834, "eval/post_ent_mag": 32.64555358886719, "eval/post_ent_max": 32.64555358886719, "eval/post_ent_mean": 32.364471435546875, "eval/post_ent_min": 32.16884994506836, "eval/post_ent_std": 0.07920187711715698, "eval/prior_ent_mag": 39.036781311035156, "eval/prior_ent_max": 39.036781311035156, "eval/prior_ent_mean": 34.81145095825195, "eval/prior_ent_min": 33.042137145996094, "eval/prior_ent_std": 0.8147580623626709, "eval/rep_loss_mean": 1.000049352645874, "eval/rep_loss_std": 0.0015775562496855855, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012017865665256977, "eval/reward_loss_std": 0.0015108443330973387, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.004107952117919922, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012017865665256977, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002106105675920844, "eval/reward_rate": 0.0, "replay/size": 371745.0, "replay/inserts": 31056.0, "replay/samples": 31056.0, "replay/insert_wait_avg": 1.3439757255227956e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.74740151705538e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 82960.0, "eval_replay/inserts": 5840.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1198732950916029e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1324882507324219e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3411867618561, "timer/env.step_count": 3882.0, "timer/env.step_total": 37.31433391571045, "timer/env.step_frac": 0.03730160710117157, "timer/env.step_avg": 0.009612141657833707, "timer/env.step_min": 0.007927417755126953, "timer/env.step_max": 0.03895306587219238, "timer/replay._sample_count": 31056.0, "timer/replay._sample_total": 15.733798265457153, "timer/replay._sample_frac": 0.015728431932696962, "timer/replay._sample_avg": 0.0005066266829423349, "timer/replay._sample_min": 0.0003647804260253906, "timer/replay._sample_max": 0.03536558151245117, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4612.0, "timer/agent.policy_total": 46.329320669174194, "timer/agent.policy_frac": 0.04631351910955905, "timer/agent.policy_avg": 0.010045386094790588, "timer/agent.policy_min": 0.008678436279296875, "timer/agent.policy_max": 0.09163641929626465, "timer/dataset_train_count": 1941.0, "timer/dataset_train_total": 0.21962261199951172, "timer/dataset_train_frac": 0.00021954770522889173, "timer/dataset_train_avg": 0.00011314920762468404, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.00029730796813964844, "timer/agent.train_count": 1941.0, "timer/agent.train_total": 868.2007124423981, "timer/agent.train_frac": 0.8679045948840696, "timer/agent.train_avg": 0.44729557570448125, "timer/agent.train_min": 0.4380221366882324, "timer/agent.train_max": 1.5195608139038086, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48023009300231934, "timer/agent.report_frac": 0.0004800663007356951, "timer/agent.report_avg": 0.24011504650115967, "timer/agent.report_min": 0.23587298393249512, "timer/agent.report_max": 0.24435710906982422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6693773297301975e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 31.04463889278797}
{"step": 372736, "time": 12224.154255867004, "episode/length": 288.0, "episode/score": 0.030385862838983257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030385862838983257}
{"step": 372888, "time": 12228.72298002243, "episode/length": 144.0, "episode/score": 0.589897406336604, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.039897414555525756}
{"step": 373656, "time": 12253.010894060135, "episode/length": 95.0, "episode/score": 0.7248180974409308, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.021693093351842663}
{"step": 373712, "time": 12255.0295855999, "episode/length": 275.0, "episode/score": 0.1996795716544284, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.059054571858155214}
{"step": 374088, "time": 12266.81554198265, "episode/length": 288.0, "episode/score": 0.03743699373004006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03743699373004006}
{"step": 374112, "time": 12267.79509139061, "episode/length": 288.0, "episode/score": 0.034466017905913304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034466017905913304}
{"step": 374112, "time": 12267.80785369873, "episode/length": 261.0, "episode/score": 0.2191381923593383, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.03476318959738478}
{"step": 374200, "time": 12270.40076494217, "episode/length": 288.0, "episode/score": 0.04269589029766507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04269589029766507}
{"step": 374264, "time": 12272.4340736866, "episode/length": 288.0, "episode/score": 0.0527146785021273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0527146785021273}
{"step": 374704, "time": 12286.551188468933, "episode/length": 123.0, "episode/score": 0.6509595580617145, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.03533454328569974}
{"step": 374984, "time": 12295.268832445145, "episode/length": 165.0, "episode/score": 0.5122478523804546, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0278728624503799}
{"step": 375008, "time": 12296.273990154266, "episode/length": 100.0, "episode/score": 0.7115039814154898, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0240039914854151}
{"step": 375048, "time": 12297.313301801682, "episode/length": 288.0, "episode/score": 0.037493226099968524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037493226099968524}
{"step": 375472, "time": 12310.904192447662, "episode/length": 169.0, "episode/score": 0.5087629522030852, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.03688795035208159}
{"step": 375512, "time": 12311.946194410324, "episode/length": 174.0, "episode/score": 0.4890135544027032, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.032763552551699604}
{"step": 375728, "time": 12318.931299686432, "episode/length": 182.0, "episode/score": 0.4657427054176253, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.034492686796994576}
{"step": 376032, "time": 12328.599374055862, "episode/length": 130.0, "episode/score": 0.62200343998569, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.02825341676810922}
{"step": 376168, "time": 12332.652752876282, "episode/length": 144.0, "episode/score": 0.5802606617116339, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.030260633194245656}
{"step": 376288, "time": 12336.642095804214, "episode/length": 96.0, "episode/score": 0.7155978218871724, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.015597810590520567}
{"step": 376400, "time": 12340.153494119644, "episode/length": 288.0, "episode/score": 0.05235411953836433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05235411953836433}
{"step": 377016, "time": 12359.901156187057, "episode/length": 288.0, "episode/score": 0.03455757640426782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03455757640426782}
{"step": 377320, "time": 12369.457832574844, "episode/length": 230.0, "episode/score": 0.3075267175589147, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.026276710865033692}
{"step": 377360, "time": 12370.93468785286, "episode/length": 288.0, "episode/score": 0.023619194273038602, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023619194273038602}
{"step": 378040, "time": 12392.113222122192, "episode/length": 288.0, "episode/score": 0.03804516183564033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03804516183564033}
{"step": 378344, "time": 12401.588683366776, "episode/length": 288.0, "episode/score": 0.023521908279207082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023521908279207082}
{"step": 378480, "time": 12406.06577539444, "episode/length": 288.0, "episode/score": 0.03182722862786136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03182722862786136}
{"step": 378600, "time": 12409.607344150543, "episode/length": 288.0, "episode/score": 0.027349096929384586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027349096929384586}
{"step": 378712, "time": 12413.234654426575, "episode/length": 288.0, "episode/score": 0.012720437629297976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012720437629297976}
{"step": 378744, "time": 12414.239204645157, "episode/length": 49.0, "episode/score": 0.8486767125770882, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.001801672541859034}
{"step": 379328, "time": 12432.747871398926, "episode/length": 288.0, "episode/score": 0.013519741470702229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013519741470702229}
{"step": 379632, "time": 12442.439535856247, "episode/length": 288.0, "episode/score": 0.026703331634138294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026703331634138294}
{"step": 379672, "time": 12443.475936889648, "episode/length": 288.0, "episode/score": 0.031919286394369806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031919286394369806}
{"step": 380016, "time": 12457.710500001907, "eval_episode/length": 180.0, "eval_episode/score": 0.4375, "eval_episode/reward_rate": 0.0055248618784530384}
{"step": 380016, "time": 12459.607974767685, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12459.622965097427, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12459.632333755493, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12459.64453458786, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12459.656724452972, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12459.669703960419, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12459.68218255043, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380352, "time": 12470.214730501175, "episode/length": 288.0, "episode/score": 0.025809213526699182, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025809213526699182}
{"step": 380448, "time": 12473.316598176956, "episode/length": 212.0, "episode/score": 0.3516034084280477, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.014103414545672877}
{"step": 380792, "time": 12483.898855924606, "episode/length": 288.0, "episode/score": 0.007961890178378894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.007961890178378894}
{"step": 380912, "time": 12487.900354146957, "episode/length": 288.0, "episode/score": 0.011426618461683802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.011426618461683802}
{"step": 381024, "time": 12491.413310050964, "episode/length": 288.0, "episode/score": 0.005137196901571883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.005137196901571883}
{"step": 381488, "time": 12506.001665592194, "episode/length": 141.0, "episode/score": 0.5691726207709422, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.009797649834027311}
{"step": 381640, "time": 12510.551552534103, "episode/length": 105.0, "episode/score": 0.6798512135632819, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.00797618544898171}
{"step": 381640, "time": 12510.567867994308, "episode/length": 288.0, "episode/score": 0.007898513657124795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.007898513657124795}
{"step": 381752, "time": 12514.090411186218, "episode/length": 264.0, "episode/score": 0.18468460641217632, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.009684605812637415}
{"step": 381984, "time": 12521.586388349533, "episode/length": 288.0, "episode/score": 0.006090459946889837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.006090459946889837}
{"step": 382632, "time": 12541.748930215836, "episode/length": 123.0, "episode/score": 0.6205439070142234, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.004918893242290778}
{"step": 382760, "time": 12545.797795057297, "episode/length": 288.0, "episode/score": 0.01738157963723097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01738157963723097}
{"step": 383224, "time": 12560.52265906334, "episode/length": 288.0, "episode/score": 0.030989787917803824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030989787917803824}
{"step": 383336, "time": 12564.177122831345, "episode/length": 288.0, "episode/score": 0.02624211021698386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02624211021698386}
{"step": 383800, "time": 12578.719343185425, "episode/length": 288.0, "episode/score": 0.011559402101624983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.011559402101624983}
{"step": 383952, "time": 12583.747539758682, "episode/length": 288.0, "episode/score": 0.013191931427684267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013191931427684267}
{"step": 384064, "time": 12587.273635149002, "episode/length": 288.0, "episode/score": 0.01148410911201836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01148410911201836}
{"step": 384296, "time": 12594.521935939789, "episode/length": 288.0, "episode/score": 0.009153681644718858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.009153681644718858}
{"step": 384760, "time": 12609.144421339035, "episode/length": 265.0, "episode/score": 0.18474971284527442, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.01287470926550327}
{"step": 384768, "time": 12609.628512144089, "episode/length": 58.0, "episode/score": 0.8205369971852434, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0017869510935071276}
{"step": 385072, "time": 12619.700640439987, "episode/length": 288.0, "episode/score": 0.010169845422325352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010169845422325352}
{"step": 385144, "time": 12621.844370365143, "episode/length": 46.0, "episode/score": 0.8717497972497341, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.015499832279104453}
{"step": 385536, "time": 12634.335122585297, "episode/length": 288.0, "episode/score": 0.02871725293081795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02871725293081795}
{"step": 385648, "time": 12637.85144162178, "episode/length": 288.0, "episode/score": 0.03713225270513476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03713225270513476}
{"step": 386112, "time": 12652.52246594429, "episode/length": 288.0, "episode/score": 0.02484877941560626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02484877941560626}
{"step": 386264, "time": 12657.06226348877, "episode/length": 288.0, "episode/score": 0.016578045926252116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.016578045926252116}
{"step": 386376, "time": 12660.602024793625, "episode/length": 288.0, "episode/score": 0.01598464652172993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01598464652172993}
{"step": 387072, "time": 12682.805743932724, "episode/length": 288.0, "episode/score": 0.024139146787973687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024139146787973687}
{"step": 387384, "time": 12692.371099948883, "episode/length": 288.0, "episode/score": 0.01912270996305665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01912270996305665}
{"step": 387456, "time": 12694.849091768265, "episode/length": 288.0, "episode/score": 0.050424500733257105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050424500733257105}
{"step": 387848, "time": 12706.952213287354, "episode/length": 288.0, "episode/score": 0.05583236993318508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05583236993318508}
{"step": 387960, "time": 12710.503206253052, "episode/length": 288.0, "episode/score": 0.05355654324917225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05355654324917225}
{"step": 388424, "time": 12725.087989807129, "episode/length": 288.0, "episode/score": 0.028463769979978792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028463769979978792}
{"step": 388576, "time": 12730.09136915207, "episode/length": 288.0, "episode/score": 0.030870431498939865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030870431498939865}
{"step": 388688, "time": 12733.658143281937, "episode/length": 288.0, "episode/score": 0.04570540661894995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04570540661894995}
{"step": 389008, "time": 12743.949729442596, "episode/length": 193.0, "episode/score": 0.41480956845779815, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.017934572373718538}
{"step": 389136, "time": 12747.97425866127, "episode/length": 146.0, "episode/score": 0.5750708678991572, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.031320863223626816}
{"step": 389256, "time": 12751.59377360344, "episode/length": 175.0, "episode/score": 0.48469525240651024, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.03157024918326101}
{"step": 389304, "time": 12753.095341444016, "episode/length": 109.0, "episode/score": 0.6745455020615054, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.015170467890698092}
{"step": 389320, "time": 12753.601776123047, "episode/length": 280.0, "episode/score": 0.1522981586314529, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.027298160319475073}
{"step": 389344, "time": 12754.578565359116, "episode/length": 244.0, "episode/score": 0.2750013676310914, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.037501363262606446}
{"step": 389432, "time": 12757.126378536224, "episode/length": 92.0, "episode/score": 0.7206466383538412, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.008146673749919842}
{"step": 390000, "time": 12776.270229101181, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 390000, "time": 12777.2070748806, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 390000, "time": 12777.235391616821, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 390000, "time": 12777.620432853699, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 390000, "time": 12778.92301940918, "eval_episode/length": 194.0, "eval_episode/score": 0.39375001192092896, "eval_episode/reward_rate": 0.005128205128205128}
{"step": 390000, "time": 12779.60749220848, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 390000, "time": 12780.086017131805, "eval_episode/length": 205.0, "eval_episode/score": 0.359375, "eval_episode/reward_rate": 0.0048543689320388345}
{"step": 390000, "time": 12780.302070140839, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 390224, "time": 12787.306421518326, "episode/length": 112.0, "episode/score": 0.6601252676121874, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.010125274857585964}
{"step": 390328, "time": 12790.32935833931, "episode/length": 164.0, "episode/score": 0.4924323981589964, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.004932386318102999}
{"step": 390888, "time": 12808.01970410347, "episode/length": 288.0, "episode/score": 0.012834855129653988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012834855129653988}
{"step": 390960, "time": 12810.526136398315, "episode/length": 227.0, "episode/score": 0.30110039202173766, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.010475384016729095}
{"step": 391112, "time": 12815.078282356262, "episode/length": 231.0, "episode/score": 0.29561846744094566, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.01749347731733053}
{"step": 391248, "time": 12819.593407392502, "episode/length": 242.0, "episode/score": 0.25795804849768444, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.014208040747334394}
{"step": 391328, "time": 12822.133011817932, "episode/length": 137.0, "episode/score": 0.5797705852892108, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.007895586408253052}
{"step": 391520, "time": 12828.154730558395, "episode/length": 148.0, "episode/score": 0.5554660210215729, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.017965980488668265}
{"step": 391528, "time": 12828.191273450851, "episode/length": 24.0, "episode/score": 0.9268496707056926, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0018496420937168523}
{"step": 391560, "time": 12829.197063922882, "episode/length": 74.0, "episode/score": 0.7785525384786354, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.009802543699862554}
{"step": 391656, "time": 12832.284341573715, "episode/length": 288.0, "episode/score": 0.022140110490425968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022140110490425968}
{"step": 391744, "time": 12835.257375240326, "episode/length": 288.0, "episode/score": 0.006347978494488871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.006347978494488871}
{"step": 391824, "time": 12837.782885789871, "episode/length": 88.0, "episode/score": 0.7306170479290017, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.005617041229299957}
{"step": 391856, "time": 12838.795036315918, "episode/length": 24.0, "episode/score": 0.9265161426397981, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0015161079960535062}
{"step": 392080, "time": 12845.825701236725, "episode/length": 69.0, "episode/score": 0.793949187224527, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0095741938863938}
{"step": 392128, "time": 12847.367440223694, "episode/length": 74.0, "episode/score": 0.778160361162648, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.009410347197174929}
{"step": 392128, "time": 12847.383638858795, "episode/length": 109.0, "episode/score": 0.6752303678490819, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.015855332710572156}
{"step": 392344, "time": 12853.989862918854, "episode/length": 74.0, "episode/score": 0.7775113984123436, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.008761392530459489}
{"step": 392720, "time": 12866.10299038887, "episode/length": 107.0, "episode/score": 0.6761682951518395, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.010543324028660095}
{"step": 393200, "time": 12881.133892536163, "episode/length": 288.0, "episode/score": 0.00956286163379616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.00956286163379616}
{"step": 393432, "time": 12888.69159078598, "episode/length": 88.0, "episode/score": 0.7328914942373643, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.007891445126105623}
{"step": 393872, "time": 12902.802544355392, "episode/length": 288.0, "episode/score": 0.008250092028561085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.008250092028561085}
{"step": 393936, "time": 12904.803745508194, "episode/length": 91.0, "episode/score": 0.7254276185868065, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.00980263058049502}
{"step": 394000, "time": 12906.803191184998, "episode/length": 70.0, "episode/score": 0.784651774737327, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0034017506393553276}
{"step": 394136, "time": 12910.833468437195, "episode/length": 288.0, "episode/score": 0.022503059344060716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022503059344060716}
{"step": 394224, "time": 12913.822871208191, "episode/length": 43.0, "episode/score": 0.8732882992104862, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.007663275441387896}
{"step": 394392, "time": 12918.862579345703, "episode/length": 288.0, "episode/score": 0.012177281729833567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012177281729833567}
{"step": 394440, "time": 12920.363312482834, "episode/length": 288.0, "episode/score": 0.008716936748768944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.008716936748768944}
{"step": 394440, "time": 12920.377497196198, "episode/length": 288.0, "episode/score": 0.01916814259112698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01916814259112698}
{"step": 394656, "time": 12927.47800707817, "episode/length": 288.0, "episode/score": 0.03947078550820038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03947078550820038}
{"step": 394816, "time": 12932.568458557129, "episode/length": 109.0, "episode/score": 0.6678170424506646, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.008442016472585578}
{"step": 394992, "time": 12938.170626163483, "episode/length": 68.0, "episode/score": 0.8004714025119739, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.012971403677582316}
{"step": 395112, "time": 12941.76112127304, "episode/length": 56.0, "episode/score": 0.8300920790089208, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.005092090988057407}
{"step": 395224, "time": 12945.34761762619, "episode/length": 97.0, "episode/score": 0.704443851050172, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.007568874950237614}
{"step": 395312, "time": 12948.382066965103, "episode/length": 61.0, "episode/score": 0.81736677524691, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.007991765936594675}
{"step": 395712, "time": 12961.02987241745, "episode/length": 89.0, "episode/score": 0.7263065658714254, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.004431557977738976}
{"step": 396008, "time": 12970.118233680725, "episode/length": 111.0, "episode/score": 0.662832948207793, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.009707964155964532}
{"step": 396096, "time": 12973.087859392166, "episode/length": 97.0, "episode/score": 0.7155765915241545, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.018701637572235086}
{"step": 396128, "time": 12974.113996982574, "episode/length": 112.0, "episode/score": 0.6579397124381074, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.007939724671174986}
{"step": 396312, "time": 12979.664191484451, "episode/length": 288.0, "episode/score": 0.029115703284702477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029115703284702477}
{"step": 396448, "time": 12984.276913404465, "episode/length": 288.0, "episode/score": 0.020706126425210414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020706126425210414}
{"step": 396536, "time": 12986.859071731567, "episode/length": 288.0, "episode/score": 0.010515232510243777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010515232510243777}
{"step": 396704, "time": 12992.387509822845, "episode/length": 288.0, "episode/score": 0.012284401768496878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012284401768496878}
{"step": 397032, "time": 13002.493183851242, "episode/length": 40.0, "episode/score": 0.8790749634956967, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.004074939397725075}
{"step": 398024, "time": 13033.758353948593, "episode/length": 288.0, "episode/score": 0.01106258003324001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01106258003324001}
{"step": 398120, "time": 13036.82003235817, "episode/length": 252.0, "episode/score": 0.2319088686267321, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.01940886435428979}
{"step": 398136, "time": 13037.386864900589, "episode/length": 137.0, "episode/score": 0.5946496655119802, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.02277468942659766}
{"step": 398216, "time": 13039.900849342346, "episode/length": 237.0, "episode/score": 0.27708299119666435, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.017707992315706633}
{"step": 398320, "time": 13043.433883666992, "episode/length": 288.0, "episode/score": 0.03559172944399336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03559172944399336}
{"step": 398376, "time": 13044.984460830688, "episode/length": 31.0, "episode/score": 0.9125712813601865, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.00944629333932312}
{"step": 398440, "time": 13046.997688055038, "episode/length": 288.0, "episode/score": 0.020539436452679638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020539436452679638}
{"step": 398504, "time": 13049.00218129158, "episode/length": 59.0, "episode/score": 0.8287614950610731, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.013136505346366789}
{"step": 398528, "time": 13049.99757862091, "episode/length": 48.0, "episode/score": 0.8644177041096128, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0144176590365106}
{"step": 398752, "time": 13056.997279167175, "episode/length": 53.0, "episode/score": 0.8527501362199814, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.018375135486564886}
{"step": 398760, "time": 13057.034265756607, "episode/length": 288.0, "episode/score": 0.02513869671358293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02513869671358293}
{"step": 398848, "time": 13060.034564495087, "episode/length": 288.0, "episode/score": 0.02284719720717021, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02284719720717021}
{"step": 399024, "time": 13065.574818134308, "episode/length": 72.0, "episode/score": 0.7887243866971971, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.013724415574017712}
{"step": 399104, "time": 13068.076258420944, "episode/length": 42.0, "episode/score": 0.8767455742341355, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.00799562308345969}
{"step": 399248, "time": 13072.662793397903, "episode/length": 92.0, "episode/score": 0.738649932416223, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0261499321601093}
{"step": 399336, "time": 13075.198226451874, "episode/length": 72.0, "episode/score": 0.788512391581591, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.013512430379179818}
{"step": 399416, "time": 13077.697568178177, "episode/length": 70.0, "episode/score": 0.7912947771711458, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.010044781198388364}
{"step": 399416, "time": 13077.712928295135, "episode/length": 129.0, "episode/score": 0.6155148694466703, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.018639853436653198}
{"step": 399456, "time": 13079.188661575317, "episode/length": 53.0, "episode/score": 0.8479167259077798, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.013541673951621647}
{"step": 399624, "time": 13084.243954658508, "episode/length": 25.0, "episode/score": 0.933224293728756, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.01134931787402138}
{"step": 399760, "time": 13088.8064930439, "episode/length": 42.0, "episode/score": 0.8796985251390197, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.010948558046720791}
{"step": 400064, "time": 13098.351606845856, "episode/length": 75.0, "episode/score": 0.7799640928156037, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.014339081690664557}
{"step": 400088, "time": 13099.893146514893, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 400088, "time": 13100.401231765747, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 400088, "time": 13103.97951555252, "eval_episode/length": 270.0, "eval_episode/score": 0.15625, "eval_episode/reward_rate": 0.0036900369003690036}
{"step": 400088, "time": 13104.791456699371, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13104.805343151093, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13104.821201086044, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13104.83775472641, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13104.852458000183, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400104, "time": 13105.363184928894, "episode/length": 95.0, "episode/score": 0.7184089040008246, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.015283889943674467}
{"step": 400504, "time": 13117.95731472969, "episode/length": 92.0, "episode/score": 0.7304680270333535, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.017968025605810567}
{"step": 400528, "time": 13118.942397356033, "episode/length": 288.0, "episode/score": 0.04045316534251242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04045316534251242}
{"step": 400840, "time": 13128.508848190308, "episode/length": 288.0, "episode/score": 0.030536872129687254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030536872129687254}
{"step": 401168, "time": 13139.120321512222, "episode/length": 40.0, "episode/score": 0.8827792628135995, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.007779251688660338}
{"step": 401416, "time": 13147.020123720169, "episode/length": 288.0, "episode/score": 0.03150480934139921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03150480934139921}
{"step": 401416, "time": 13147.041779518127, "episode/length": 168.0, "episode/score": 0.5035685346448986, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.02856853943757187}
{"step": 401560, "time": 13151.756383895874, "episode/length": 288.0, "episode/score": 0.0245237187320555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0245237187320555}
{"step": 401736, "time": 13157.285450458527, "episode/length": 39.0, "episode/score": 0.8883589626782822, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.010233921064170204}
{"step": 401936, "time": 13163.905522584915, "episode/length": 288.0, "episode/score": 0.02599777307052875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02599777307052875}
{"step": 402416, "time": 13178.94811630249, "episode/length": 288.0, "episode/score": 0.038114765269867235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038114765269867235}
{"step": 402624, "time": 13185.487993478775, "episode/length": 132.0, "episode/score": 0.6105635357735508, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.023063551317179076}
{"step": 402792, "time": 13190.594959020615, "episode/length": 46.0, "episode/score": 0.8678722387399773, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.011622226635694233}
{"step": 402816, "time": 13191.635608196259, "episode/length": 288.0, "episode/score": 0.017143378401314635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017143378401314635}
{"step": 402840, "time": 13192.189054012299, "episode/length": 288.0, "episode/score": 0.032922684679107306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032922684679107306}
{"step": 403224, "time": 13204.29378414154, "episode/length": 185.0, "episode/score": 0.4599690651381394, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.03809406595304665}
{"step": 403296, "time": 13206.77461028099, "episode/length": 83.0, "episode/score": 0.7625691199272779, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.02194406744725086}
{"step": 403345, "time": 13208.852550983429, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.424857584635417, "train/action_min": 0.0, "train/action_std": 1.4356438279151917, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012094836855808703, "train/actor_opt_grad_steps": 24140.0, "train/actor_opt_loss": -4.953002271514673, "train/adv_mag": 0.759716092928862, "train/adv_max": 0.2624484963906117, "train/adv_mean": 0.003523109259586841, "train/adv_min": -0.7401347753329155, "train/adv_std": 0.03621858888759445, "train/cont_avg": 0.9959385016025641, "train/cont_loss_mean": 0.017619529724694216, "train/cont_loss_std": 0.2524313602477121, "train/cont_neg_acc": 0.23629505916809043, "train/cont_neg_loss": 3.458951040132282, "train/cont_pos_acc": 0.9998390582891611, "train/cont_pos_loss": 0.0033829482588678215, "train/cont_pred": 0.9958383862788861, "train/cont_rate": 0.9959385016025641, "train/dyn_loss_mean": 1.0000112399076804, "train/dyn_loss_std": 0.0003516218956718102, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.6220564180841812, "train/extr_critic_critic_opt_grad_steps": 24140.0, "train/extr_critic_critic_opt_loss": 5545.803884965945, "train/extr_critic_mag": 0.9091032364429572, "train/extr_critic_max": 0.9091032364429572, "train/extr_critic_mean": 0.8843986728252509, "train/extr_critic_min": 0.8519792813521165, "train/extr_critic_std": 0.00941796890245034, "train/extr_return_normed_mag": 0.7353066802024841, "train/extr_return_normed_max": 0.3059758730423756, "train/extr_return_normed_mean": 0.03410990260920535, "train/extr_return_normed_min": -0.7058355105228913, "train/extr_return_normed_std": 0.03837005895060989, "train/extr_return_rate": 0.997464656829834, "train/extr_return_raw_mag": 1.1597877251796234, "train/extr_return_raw_max": 1.1597877251796234, "train/extr_return_raw_mean": 0.8879217918102558, "train/extr_return_raw_min": 0.1479763416143564, "train/extr_return_raw_std": 0.03837005894105786, "train/extr_reward_mag": 0.30501966843238243, "train/extr_reward_max": 0.30501966843238243, "train/extr_reward_mean": 0.0025678573925501835, "train/extr_reward_min": 7.927723419971956e-06, "train/extr_reward_std": 0.012915202535282916, "train/image_loss_mean": 0.12178980230520933, "train/image_loss_std": 0.10724451071940935, "train/model_loss_mean": 0.7551577155406658, "train/model_loss_std": 0.3760566150530791, "train/model_opt_grad_norm": 31.0667083300077, "train/model_opt_grad_steps": 24118.020512820513, "train/model_opt_loss": 2796.0195587940707, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3717.948717948718, "train/policy_entropy_mag": 1.4213303407033284, "train/policy_entropy_max": 1.4213303407033284, "train/policy_entropy_mean": 0.17383212726085615, "train/policy_entropy_min": 0.06468724646629431, "train/policy_entropy_std": 0.21009567395234718, "train/policy_logprob_mag": 6.551079087379652, "train/policy_logprob_max": -0.008608386593942459, "train/policy_logprob_mean": -0.17368654849437568, "train/policy_logprob_min": -6.551079087379652, "train/policy_logprob_std": 0.703535304008386, "train/policy_randomness_mag": 0.7304193487534156, "train/policy_randomness_max": 0.7304193487534156, "train/policy_randomness_mean": 0.08933204643619366, "train/policy_randomness_min": 0.033242670656778876, "train/policy_randomness_std": 0.1079678251957282, "train/post_ent_mag": 31.74407499264448, "train/post_ent_max": 31.74407499264448, "train/post_ent_mean": 31.48375360537798, "train/post_ent_min": 31.28329802293044, "train/post_ent_std": 0.08399362728381768, "train/prior_ent_mag": 36.40433936485877, "train/prior_ent_max": 36.40433936485877, "train/prior_ent_mean": 33.392104946038664, "train/prior_ent_min": 31.308988150572166, "train/prior_ent_std": 0.8720177231690822, "train/rep_loss_mean": 1.0000112399076804, "train/rep_loss_std": 0.0003516218956718102, "train/reward_avg": 0.0009469155590826025, "train/reward_loss_mean": 0.01574161693167228, "train/reward_loss_std": 0.134810675909886, "train/reward_max_data": 0.4853953840043873, "train/reward_max_pred": 0.10465620358784994, "train/reward_neg_acc": 0.9998846815182613, "train/reward_neg_loss": 0.010400968181112637, "train/reward_pos_acc": 0.15011820387332997, "train/reward_pos_loss": 4.467435752246397, "train/reward_pred": 0.0008226715195446443, "train/reward_rate": 0.0011818910256410256, "train_stats/mean_log_entropy": 0.1621110715019475, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.012370132841169834, "report/cont_loss_std": 0.25994187593460083, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.6252799034118652, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0021234266459941864, "report/cont_pred": 0.9960721135139465, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12636825442314148, "report/image_loss_std": 0.10718706250190735, "report/model_loss_mean": 0.7520801424980164, "report/model_loss_std": 0.33315742015838623, "report/post_ent_mag": 31.064346313476562, "report/post_ent_max": 31.064346313476562, "report/post_ent_mean": 30.81822967529297, "report/post_ent_min": 30.647804260253906, "report/post_ent_std": 0.08661656081676483, "report/prior_ent_mag": 34.721885681152344, "report/prior_ent_max": 34.721885681152344, "report/prior_ent_mean": 31.800004959106445, "report/prior_ent_min": 29.18807601928711, "report/prior_ent_std": 1.0003684759140015, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0009750419412739575, "report/reward_loss_mean": 0.01334171462804079, "report/reward_loss_std": 0.10287520289421082, "report/reward_max_data": 0.7813175916671753, "report/reward_max_pred": 0.06386244297027588, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010159787721931934, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.268453359603882, "report/reward_pred": 0.0006630808347836137, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01863321103155613, "eval/cont_loss_std": 0.3843649923801422, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.703291893005371, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0016377957072108984, "eval/cont_pred": 0.9984204173088074, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25138214230537415, "eval/image_loss_std": 0.14756545424461365, "eval/model_loss_mean": 0.8716214895248413, "eval/model_loss_std": 0.41448134183883667, "eval/post_ent_mag": 31.07099151611328, "eval/post_ent_max": 31.07099151611328, "eval/post_ent_mean": 30.78890609741211, "eval/post_ent_min": 30.62773895263672, "eval/post_ent_std": 0.07497347891330719, "eval/prior_ent_mag": 34.99065399169922, "eval/prior_ent_max": 34.99065399169922, "eval/prior_ent_mean": 31.546401977539062, "eval/prior_ent_min": 29.32213020324707, "eval/prior_ent_std": 0.9747270941734314, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001606072299182415, "eval/reward_loss_std": 0.0019439638126641512, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0073767900466918945, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001606072299182415, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00027241522911936045, "eval/reward_rate": 0.0, "replay/size": 402841.0, "replay/inserts": 31096.0, "replay/samples": 31088.0, "replay/insert_wait_avg": 1.3318502231339793e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.722106553694667e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 89752.0, "eval_replay/inserts": 6792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1271526170422809e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9828808307648, "timer/env.step_count": 3887.0, "timer/env.step_total": 37.216808795928955, "timer/env.step_frac": 0.03721744592768429, "timer/env.step_avg": 0.00957468710983508, "timer/env.step_min": 0.007805824279785156, "timer/env.step_max": 0.03944087028503418, "timer/replay._sample_count": 31088.0, "timer/replay._sample_total": 15.772433042526245, "timer/replay._sample_frac": 0.015772703058099195, "timer/replay._sample_avg": 0.0005073479491291252, "timer/replay._sample_min": 0.0003459453582763672, "timer/replay._sample_max": 0.011432409286499023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4736.0, "timer/agent.policy_total": 47.49259376525879, "timer/agent.policy_frac": 0.047493406812927574, "timer/agent.policy_avg": 0.01002799699435363, "timer/agent.policy_min": 0.008509397506713867, "timer/agent.policy_max": 0.08513712882995605, "timer/dataset_train_count": 1943.0, "timer/dataset_train_total": 0.22101926803588867, "timer/dataset_train_frac": 0.00022102305176691675, "timer/dataset_train_avg": 0.0001137515532866128, "timer/dataset_train_min": 9.679794311523438e-05, "timer/dataset_train_max": 0.0004048347473144531, "timer/agent.train_count": 1943.0, "timer/agent.train_total": 865.3019416332245, "timer/agent.train_frac": 0.8653167551371977, "timer/agent.train_avg": 0.44534325354257565, "timer/agent.train_min": 0.4356503486633301, "timer/agent.train_max": 0.5810153484344482, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4680612087249756, "timer/agent.report_frac": 0.00046806922168119537, "timer/agent.report_avg": 0.2340306043624878, "timer/agent.report_min": 0.22148489952087402, "timer/agent.report_max": 0.24657630920410156, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.886222839355469e-05, "timer/dataset_eval_frac": 3.8862893694008806e-08, "timer/dataset_eval_avg": 3.886222839355469e-05, "timer/dataset_eval_min": 3.886222839355469e-05, "timer/dataset_eval_max": 3.886222839355469e-05, "fps": 31.096001149148982}
{"step": 403440, "time": 13212.004747152328, "episode/length": 77.0, "episode/score": 0.7889131286219424, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.029538123825631146}
{"step": 403480, "time": 13213.054943323135, "episode/length": 288.0, "episode/score": 0.025057247834197938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025057247834197938}
{"step": 403496, "time": 13213.570182323456, "episode/length": 81.0, "episode/score": 0.7785400292484042, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.03166504198424036}
{"step": 403728, "time": 13221.148254871368, "episode/length": 288.0, "episode/score": 0.04160489526437061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04160489526437061}
{"step": 403744, "time": 13221.6656498909, "episode/length": 118.0, "episode/score": 0.6739902426297704, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.04274021960281971}
{"step": 403784, "time": 13222.7234749794, "episode/length": 42.0, "episode/score": 0.8912130903145226, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0224630855182113}
{"step": 403832, "time": 13224.25690484047, "episode/length": 43.0, "episode/score": 0.8841319947650845, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.018506956604142033}
{"step": 403848, "time": 13224.76577591896, "episode/length": 68.0, "episode/score": 0.8242808692757535, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.036780846248802845}
{"step": 403944, "time": 13227.774970293045, "episode/length": 89.0, "episode/score": 0.7572901501462184, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.035415123906204826}
{"step": 404240, "time": 13237.258216381073, "episode/length": 48.0, "episode/score": 0.8687372008917009, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.018737162730758428}
{"step": 404248, "time": 13237.298218250275, "episode/length": 288.0, "episode/score": 0.04632518968799104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04632518968799104}
{"step": 404344, "time": 13240.323630809784, "episode/length": 11.0, "episode/score": 0.9742690018233588, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.008643990403015778}
{"step": 404504, "time": 13245.349341630936, "episode/length": 94.0, "episode/score": 0.7353330515893504, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.029083025349336822}
{"step": 404688, "time": 13251.438099622726, "episode/length": 92.0, "episode/score": 0.7368200673338379, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.024320067834423753}
{"step": 404984, "time": 13260.524646997452, "episode/length": 36.0, "episode/score": 0.9039152460254627, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.01641524976821529}
{"step": 405808, "time": 13286.70887184143, "episode/length": 288.0, "episode/score": 0.0460933162960373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0460933162960373}
{"step": 405880, "time": 13288.76898241043, "episode/length": 111.0, "episode/score": 0.693272755939006, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.040147744518662876}
{"step": 406040, "time": 13293.82831120491, "episode/length": 288.0, "episode/score": 0.05666185287600456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05666185287600456}
{"step": 406096, "time": 13295.813201189041, "episode/length": 288.0, "episode/score": 0.0569769558991311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0569769558991311}
{"step": 406144, "time": 13297.323796987534, "episode/length": 288.0, "episode/score": 0.05475677280605851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05475677280605851}
{"step": 406552, "time": 13309.895537853241, "episode/length": 288.0, "episode/score": 0.050934792800944706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050934792800944706}
{"step": 406656, "time": 13313.445942640305, "episode/length": 288.0, "episode/score": 0.035031024860131765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035031024860131765}
{"step": 406816, "time": 13318.473038434982, "episode/length": 288.0, "episode/score": 0.05644362543182524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05644362543182524}
{"step": 406976, "time": 13323.481439828873, "episode/length": 103.0, "episode/score": 0.7039672357874451, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.025842203767410865}
{"step": 406984, "time": 13323.518517494202, "episode/length": 110.0, "episode/score": 0.6973473354120188, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.041097306017150004}
{"step": 407248, "time": 13332.050428628922, "episode/length": 53.0, "episode/score": 0.855630198017252, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.021255165997217773}
{"step": 407304, "time": 13333.580500364304, "episode/length": 80.0, "episode/score": 0.7733772988301553, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.023377275488883242}
{"step": 407416, "time": 13337.095637083054, "episode/length": 53.0, "episode/score": 0.8605858629424574, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.026210830922423156}
{"step": 407920, "time": 13353.308732032776, "episode/length": 117.0, "episode/score": 0.6701677396290506, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.035792783610759216}
{"step": 408120, "time": 13359.332419157028, "episode/length": 288.0, "episode/score": 0.059806898073418324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059806898073418324}
{"step": 408192, "time": 13361.799653053284, "episode/length": 288.0, "episode/score": 0.05526867659159507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05526867659159507}
{"step": 408240, "time": 13363.297021150589, "episode/length": 116.0, "episode/score": 0.67353321129508, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0360332160564667}
{"step": 408352, "time": 13366.82986497879, "episode/length": 288.0, "episode/score": 0.054315192893227504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054315192893227504}
{"step": 408416, "time": 13368.825260400772, "episode/length": 61.0, "episode/score": 0.8218275144546965, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.012452544507311814}
{"step": 408616, "time": 13374.941252708435, "episode/length": 52.0, "episode/score": 0.8462396706366349, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.008739717586934148}
{"step": 408864, "time": 13382.918546438217, "episode/length": 288.0, "episode/score": 0.039893620582802214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039893620582802214}
{"step": 409344, "time": 13398.026416540146, "episode/length": 137.0, "episode/score": 0.5951609630399162, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.023285987100052807}
{"step": 409560, "time": 13404.694991111755, "episode/length": 288.0, "episode/score": 0.037667721257264475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037667721257264475}
{"step": 409728, "time": 13410.687886476517, "episode/length": 288.0, "episode/score": 0.05030881941507914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05030881941507914}
{"step": 410072, "time": 13423.021849870682, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 410072, "time": 13423.714020252228, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 410072, "time": 13426.319191932678, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13426.33364033699, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13426.343969106674, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13426.35365819931, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13426.364716053009, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13426.376918315887, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410432, "time": 13437.957740068436, "episode/length": 288.0, "episode/score": 0.045913238901107434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045913238901107434}
{"step": 410488, "time": 13439.481846094131, "episode/length": 142.0, "episode/score": 0.602057035125199, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.045807059185335675}
{"step": 410640, "time": 13444.450846195221, "episode/length": 113.0, "episode/score": 0.6700071920204778, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.023132168396898578}
{"step": 410664, "time": 13444.998485803604, "episode/length": 288.0, "episode/score": 0.03322404438540616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03322404438540616}
{"step": 410728, "time": 13447.01057100296, "episode/length": 288.0, "episode/score": 0.03347077213061311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03347077213061311}
{"step": 410928, "time": 13453.48330283165, "episode/length": 288.0, "episode/score": 0.02554125320853018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02554125320853018}
{"step": 411160, "time": 13460.612610340118, "episode/length": 53.0, "episode/score": 0.852779023417213, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.01840397018048634}
{"step": 411176, "time": 13461.174523115158, "episode/length": 288.0, "episode/score": 0.05752831559874494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05752831559874494}
{"step": 411616, "time": 13475.235342264175, "episode/length": 256.0, "episode/score": 0.26395572387963284, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.06395572111767933}
{"step": 411888, "time": 13483.79041814804, "episode/length": 119.0, "episode/score": 0.6532207045401606, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.02509570772411962}
{"step": 411936, "time": 13485.298069238663, "episode/length": 39.0, "episode/score": 0.8863937476144201, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.008268750798379187}
{"step": 411944, "time": 13485.33455991745, "episode/length": 181.0, "episode/score": 0.48209020929084545, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.047715217122686227}
{"step": 412008, "time": 13487.361764192581, "episode/length": 14.0, "episode/score": 0.9631246727818734, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.006874683969385842}
{"step": 412128, "time": 13491.461961746216, "episode/length": 185.0, "episode/score": 0.47077246805275763, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.04889748013084727}
{"step": 412240, "time": 13494.980518817902, "episode/length": 37.0, "episode/score": 0.8966664223637508, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.012291458283698375}
{"step": 412528, "time": 13504.02092552185, "episode/length": 64.0, "episode/score": 0.8239190901810503, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.023919092419134813}
{"step": 412744, "time": 13510.582508325577, "episode/length": 288.0, "episode/score": 0.04787759318753615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04787759318753615}
{"step": 412936, "time": 13516.604223012924, "episode/length": 219.0, "episode/score": 0.3612758478378737, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.045650827738768385}
{"step": 412976, "time": 13518.069646120071, "episode/length": 288.0, "episode/score": 0.05256264425520385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05256264425520385}
{"step": 413416, "time": 13531.720720767975, "episode/length": 59.0, "episode/score": 0.8381803627840441, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.02255532222494594}
{"step": 413472, "time": 13533.685887813568, "episode/length": 288.0, "episode/score": 0.03177835104298765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03177835104298765}
{"step": 413560, "time": 13536.227836608887, "episode/length": 128.0, "episode/score": 0.6348694035318658, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.03486936537092333}
{"step": 413672, "time": 13539.712198972702, "episode/length": 86.0, "episode/score": 0.7662069497853281, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.03495694738717248}
{"step": 413704, "time": 13540.71593284607, "episode/length": 119.0, "episode/score": 0.6682072397724994, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.04008219921340128}
{"step": 413848, "time": 13545.29991722107, "episode/length": 21.0, "episode/score": 0.9405388603363463, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.006163857938190631}
{"step": 414096, "time": 13553.45546245575, "episode/length": 77.0, "episode/score": 0.7871414839692079, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.027766493491981237}
{"step": 414144, "time": 13554.957665681839, "episode/length": 54.0, "episode/score": 0.8483658291647771, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.017115818058755394}
{"step": 414200, "time": 13556.505733966827, "episode/length": 79.0, "episode/score": 0.772050065901567, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.01892502458576928}
{"step": 414256, "time": 13558.475001335144, "episode/length": 288.0, "episode/score": 0.046508584497559013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046508584497559013}
{"step": 414440, "time": 13564.022765159607, "episode/length": 288.0, "episode/score": 0.02184542215172769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02184542215172769}
{"step": 414448, "time": 13564.504867076874, "episode/length": 74.0, "episode/score": 0.7912300572061213, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.022480030966107734}
{"step": 414552, "time": 13567.568314790726, "episode/length": 288.0, "episode/score": 0.042262118116752845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042262118116752845}
{"step": 414816, "time": 13576.068918704987, "episode/length": 89.0, "episode/score": 0.7589300228753473, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.03705498231624915}
{"step": 414880, "time": 13578.103904485703, "episode/length": 91.0, "episode/score": 0.7402207110155814, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.024595693541641594}
{"step": 415040, "time": 13583.221563100815, "episode/length": 104.0, "episode/score": 0.7140627451294677, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.039062709867266676}
{"step": 415600, "time": 13600.932914972305, "episode/length": 69.0, "episode/score": 0.8072018362722702, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.022826816173164843}
{"step": 415624, "time": 13601.47277379036, "episode/length": 92.0, "episode/score": 0.7335836736447163, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.02108368930839788}
{"step": 415728, "time": 13604.973558664322, "episode/length": 288.0, "episode/score": 0.044260343238534006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044260343238534006}
{"step": 416552, "time": 13630.731855154037, "episode/length": 102.0, "episode/score": 0.708166037130809, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.026916052794490497}
{"step": 416568, "time": 13631.242712020874, "episode/length": 288.0, "episode/score": 0.03880845392438914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03880845392438914}
{"step": 416752, "time": 13637.344109296799, "episode/length": 288.0, "episode/score": 0.050096210983952005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050096210983952005}
{"step": 416760, "time": 13637.383397817612, "episode/length": 288.0, "episode/score": 0.04821265004113684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04821265004113684}
{"step": 416864, "time": 13641.022562265396, "episode/length": 288.0, "episode/score": 0.037534256700041624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037534256700041624}
{"step": 417000, "time": 13645.060909748077, "episode/length": 171.0, "episode/score": 0.4870251349143473, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.02140013251619166}
{"step": 417040, "time": 13646.533842802048, "episode/length": 60.0, "episode/score": 0.8369131304250459, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.024413107083773866}
{"step": 417128, "time": 13649.08347415924, "episode/length": 288.0, "episode/score": 0.027137810990325306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027137810990325306}
{"step": 417312, "time": 13655.128436803818, "episode/length": 55.0, "episode/score": 0.8425150841302411, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.014390104270091797}
{"step": 417512, "time": 13661.17215871811, "episode/length": 117.0, "episode/score": 0.6529113730911149, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.018536415064659195}
{"step": 417688, "time": 13666.701470851898, "episode/length": 85.0, "episode/score": 0.7519631103069742, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.017588110525252887}
{"step": 417848, "time": 13672.388288736343, "episode/length": 280.0, "episode/score": 0.174874628796033, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0498746293781096}
{"step": 418040, "time": 13678.441716194153, "episode/length": 124.0, "episode/score": 0.6534318120316129, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.040931820250534656}
{"step": 418056, "time": 13678.954048633575, "episode/length": 92.0, "episode/score": 0.742116563512468, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.029616605486012304}
{"step": 418120, "time": 13680.962020397186, "episode/length": 53.0, "episode/score": 0.8513776999182028, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.017002646681476108}
{"step": 418160, "time": 13682.435782909393, "episode/length": 14.0, "episode/score": 0.9628411830004779, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.006591147738276959}
{"step": 418184, "time": 13682.9697535038, "episode/length": 178.0, "episode/score": 0.47915932835735475, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.03540932613964287}
{"step": 418208, "time": 13683.962014913559, "episode/length": 86.0, "episode/score": 0.7497541584158398, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.018504170555047494}
{"step": 418432, "time": 13690.947234869003, "episode/length": 72.0, "episode/score": 0.8010697286497361, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.02606977263144472}
{"step": 418504, "time": 13692.972039222717, "episode/length": 217.0, "episode/score": 0.34636570788154586, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.024490693742905023}
{"step": 418576, "time": 13695.440878152847, "episode/length": 48.0, "episode/score": 0.8726407814156119, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.02264077267864195}
{"step": 418664, "time": 13697.962995767593, "episode/length": 191.0, "episode/score": 0.42675521603598554, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.023630218294442784}
{"step": 418720, "time": 13699.945572853088, "episode/length": 82.0, "episode/score": 0.7746429084938882, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.030892924157569723}
{"step": 418840, "time": 13703.556468963623, "episode/length": 78.0, "episode/score": 0.7734624182395464, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.017212412529374888}
{"step": 418888, "time": 13705.060044527054, "episode/length": 90.0, "episode/score": 0.7486082936868002, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.029858289597711973}
{"step": 419072, "time": 13711.028220415115, "episode/length": 28.0, "episode/score": 0.9216342153875985, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.009134187456652398}
{"step": 419240, "time": 13716.07733464241, "episode/length": 91.0, "episode/score": 0.7394642970854193, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.023839335228899472}
{"step": 419280, "time": 13717.559655666351, "episode/length": 48.0, "episode/score": 0.8689730555017263, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.01897302450032612}
{"step": 419296, "time": 13718.066473960876, "episode/length": 27.0, "episode/score": 0.9250127551483729, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.009387799130081476}
{"step": 419344, "time": 13719.592939138412, "episode/length": 77.0, "episode/score": 0.7787636354219671, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.019388659482103776}
{"step": 419464, "time": 13723.167885303497, "episode/length": 128.0, "episode/score": 0.6333833844169021, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.033383380714894884}
{"step": 419512, "time": 13724.713539123535, "episode/length": 116.0, "episode/score": 0.6694702449336205, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0319702830771007}
{"step": 419640, "time": 13728.725318670273, "episode/length": 49.0, "episode/score": 0.8639846819462491, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.017109670243598885}
{"step": 419744, "time": 13732.358033895493, "episode/length": 49.0, "episode/score": 0.8608964138001625, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.014021402097512237}
{"step": 419872, "time": 13736.413119792938, "episode/length": 44.0, "episode/score": 0.8709884888024249, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.008488491986383906}
{"step": 419976, "time": 13739.466477870941, "episode/length": 41.0, "episode/score": 0.8785226355129225, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.006647657503776827}
{"step": 420056, "time": 13742.248594045639, "eval_episode/length": 14.0, "eval_episode/score": 0.956250011920929, "eval_episode/reward_rate": 0.06666666666666667}
{"step": 420056, "time": 13742.723514080048, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 420056, "time": 13743.15873336792, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 420056, "time": 13743.392823457718, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 420056, "time": 13743.473332881927, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 420056, "time": 13743.729677677155, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 420056, "time": 13743.789108276367, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 420056, "time": 13744.322969436646, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 420264, "time": 13750.85735464096, "episode/length": 35.0, "episode/score": 0.900404341782405, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.009779350848248214}
{"step": 420432, "time": 13756.383161306381, "episode/length": 288.0, "episode/score": 0.0426421132925725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0426421132925725}
{"step": 420600, "time": 13761.590369701385, "episode/length": 164.0, "episode/score": 0.5111950216155492, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.023695009912898968}
{"step": 420656, "time": 13763.555267572403, "episode/length": 113.0, "episode/score": 0.6706929052487567, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.023817851713715754}
{"step": 420976, "time": 13773.626677751541, "episode/length": 288.0, "episode/score": 0.02241444991307162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02241444991307162}
{"step": 421528, "time": 13790.833688020706, "episode/length": 68.0, "episode/score": 0.8010878571776061, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.013587829246660021}
{"step": 421592, "time": 13792.849879741669, "episode/length": 116.0, "episode/score": 0.6644752337186901, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0269752627817752}
{"step": 421608, "time": 13793.368720054626, "episode/length": 288.0, "episode/score": 0.04283350327290236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04283350327290236}
{"step": 421776, "time": 13798.862216472626, "episode/length": 288.0, "episode/score": 0.019455009543321466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019455009543321466}
{"step": 421976, "time": 13804.878774404526, "episode/length": 45.0, "episode/score": 0.8818757150411329, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.022500686402963765}
{"step": 422000, "time": 13805.852015256882, "episode/length": 27.0, "episode/score": 0.9323236888249085, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0166986840285972}
{"step": 422184, "time": 13811.387276172638, "episode/length": 288.0, "episode/score": 0.055693363900900295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055693363900900295}
{"step": 422576, "time": 13823.987377405167, "episode/length": 288.0, "episode/score": 0.06880447128605738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06880447128605738}
{"step": 422608, "time": 13824.995277404785, "episode/length": 75.0, "episode/score": 0.8009354647479086, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.03531046556281581}
{"step": 422704, "time": 13828.023991584778, "episode/length": 64.0, "episode/score": 0.8270141974048784, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.027014156845780235}
{"step": 422744, "time": 13829.058873414993, "episode/length": 288.0, "episode/score": 0.07202432249181356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07202432249181356}
{"step": 422840, "time": 13832.086007118225, "episode/length": 32.0, "episode/score": 0.9177263158062487, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.017726340463013912}
{"step": 422912, "time": 13834.572961807251, "episode/length": 288.0, "episode/score": 0.07496652761722089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07496652761722089}
{"step": 423040, "time": 13838.649792432785, "episode/length": 53.0, "episode/score": 0.8607883320996734, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.026413309072722768}
{"step": 423712, "time": 13859.773192167282, "episode/length": 125.0, "episode/score": 0.6450572791397917, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.03568225579851969}
{"step": 423720, "time": 13859.8124396801, "episode/length": 100.0, "episode/score": 0.7176210999809882, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.030121085661903635}
{"step": 423768, "time": 13861.320686340332, "episode/length": 279.0, "episode/score": 0.19046838311606962, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.06234338650375548}
{"step": 423808, "time": 13862.812745571136, "episode/length": 95.0, "episode/score": 0.7343355049854381, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.031210481644166066}
{"step": 423904, "time": 13865.825354099274, "episode/length": 288.0, "episode/score": 0.0417302997265665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0417302997265665}
{"step": 423912, "time": 13865.862704992294, "episode/length": 133.0, "episode/score": 0.6204173177748089, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.03604228575477464}
{"step": 424200, "time": 13874.930174350739, "episode/length": 60.0, "episode/score": 0.8221319784256593, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.009631998565510003}
{"step": 424288, "time": 13877.92618727684, "episode/length": 288.0, "episode/score": 0.024666260650406002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024666260650406002}
{"step": 424464, "time": 13883.55341553688, "episode/length": 81.0, "episode/score": 0.7734715757624144, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.026596558288474625}
{"step": 424944, "time": 13898.597174167633, "episode/length": 129.0, "episode/score": 0.6270090255291052, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.030134013826454975}
{"step": 424984, "time": 13899.63660812378, "episode/length": 97.0, "episode/score": 0.729100615026482, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.03222565900819063}
{"step": 425056, "time": 13902.12421822548, "episode/length": 288.0, "episode/score": 0.06936235533305535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06936235533305535}
{"step": 425120, "time": 13904.162165403366, "episode/length": 81.0, "episode/score": 0.7700345547970073, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.023159559558393994}
{"step": 425152, "time": 13905.169088125229, "episode/length": 20.0, "episode/score": 0.9458857100242994, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.008385705935211263}
{"step": 425608, "time": 13919.484749794006, "episode/length": 68.0, "episode/score": 0.8218958749712328, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.03439583681029035}
{"step": 426032, "time": 13933.641774892807, "episode/length": 288.0, "episode/score": 0.08738117535688161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08738117535688161}
{"step": 426080, "time": 13935.150395154953, "episode/length": 288.0, "episode/score": 0.05315397476931594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05315397476931594}
{"step": 426120, "time": 13936.186789035797, "episode/length": 124.0, "episode/score": 0.6504658411879518, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.03796584437191086}
{"step": 426224, "time": 13939.695932388306, "episode/length": 288.0, "episode/score": 0.05668425414717149, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05668425414717149}
{"step": 426328, "time": 13942.84392786026, "episode/length": 25.0, "episode/score": 0.933359142507129, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.011484165615570419}
{"step": 426600, "time": 13951.392426490784, "episode/length": 288.0, "episode/score": 0.03543873052728941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03543873052728941}
{"step": 427120, "time": 13967.909852266312, "episode/length": 111.0, "episode/score": 0.6793792078542538, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.026254239915033395}
{"step": 427120, "time": 13967.919843435287, "episode/length": 98.0, "episode/score": 0.7223934925983713, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.028643488896364033}
{"step": 427256, "time": 13972.05787229538, "episode/length": 288.0, "episode/score": 0.031043416349348263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031043416349348263}
{"step": 427416, "time": 13977.127752065659, "episode/length": 101.0, "episode/score": 0.7176417336052054, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.033266722184862374}
{"step": 427464, "time": 13978.651582241058, "episode/length": 288.0, "episode/score": 0.057989704361034455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057989704361034455}
{"step": 427608, "time": 13983.19333744049, "episode/length": 60.0, "episode/score": 0.8304376984609689, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.01793769867924766}
{"step": 427896, "time": 13992.269748926163, "episode/length": 53.0, "episode/score": 0.8535585056713444, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.01918348204776521}
{"step": 427920, "time": 13993.257936477661, "episode/length": 288.0, "episode/score": 0.05009198873273135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05009198873273135}
{"step": 427984, "time": 13995.288483381271, "episode/length": 90.0, "episode/score": 0.745703664592952, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.026953687701393392}
{"step": 428344, "time": 14006.446124792099, "episode/length": 288.0, "episode/score": 0.07949619892514193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07949619892514193}
{"step": 428392, "time": 14007.950061559677, "episode/length": 288.0, "episode/score": 0.06221946562516223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06221946562516223}
{"step": 428432, "time": 14009.44734120369, "episode/length": 63.0, "episode/score": 0.8212238238833152, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.018098791863280894}
{"step": 428792, "time": 14020.54198217392, "episode/length": 111.0, "episode/score": 0.6809319401477296, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.027806947979570396}
{"step": 428824, "time": 14021.556380748749, "episode/length": 53.0, "episode/score": 0.8520135399374453, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.017638539204028802}
{"step": 429336, "time": 14037.74664568901, "episode/length": 276.0, "episode/score": 0.19615274997926235, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.05865274816318333}
{"step": 429672, "time": 14048.332865953445, "episode/length": 41.0, "episode/score": 0.885544815392791, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.013669847453570583}
{"step": 429728, "time": 14050.351675510406, "episode/length": 288.0, "episode/score": 0.04641721793143461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04641721793143461}
{"step": 429920, "time": 14056.38459444046, "episode/length": 288.0, "episode/score": 0.044444383802272114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044444383802272114}
{"step": 430040, "time": 14061.040884494781, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 430040, "time": 14061.084458827972, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 430040, "time": 14061.12879562378, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 430040, "time": 14061.265038251877, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 430040, "time": 14061.380023479462, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 430040, "time": 14062.019578933716, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 430040, "time": 14062.274606466293, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 430040, "time": 14062.618561029434, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 430296, "time": 14070.668619394302, "episode/length": 288.0, "episode/score": 0.0428336978571906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0428336978571906}
{"step": 430304, "time": 14071.148141622543, "episode/length": 71.0, "episode/score": 0.7997992520973867, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.021674287126757008}
{"step": 430528, "time": 14078.18971824646, "episode/length": 27.0, "episode/score": 0.9265886828311523, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.010963718751099805}
{"step": 430568, "time": 14079.233425855637, "episode/length": 80.0, "episode/score": 0.7788876073278743, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.028887608142781573}
{"step": 430656, "time": 14082.22045969963, "episode/length": 288.0, "episode/score": 0.0426359691369953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0426359691369953}
{"step": 430736, "time": 14084.755459070206, "episode/length": 287.0, "episode/score": 0.1239335208562693, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.02080852135685518}
{"step": 431104, "time": 14096.419438838959, "episode/length": 288.0, "episode/score": 0.027823986819498714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027823986819498714}
{"step": 431120, "time": 14096.926064014435, "episode/length": 57.0, "episode/score": 0.8351136888433075, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.013238726844178927}
{"step": 431136, "time": 14097.43350148201, "episode/length": 288.0, "episode/score": 0.04038665127325203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04038665127325203}
{"step": 431664, "time": 14114.024500131607, "episode/length": 69.0, "episode/score": 0.8038270084020382, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.01945196708624053}
{"step": 431984, "time": 14124.208446741104, "episode/length": 288.0, "episode/score": 0.03877732449331006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03877732449331006}
{"step": 432232, "time": 14131.771724700928, "episode/length": 212.0, "episode/score": 0.3622641173387251, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.02476410421871833}
{"step": 432440, "time": 14138.292798280716, "episode/length": 96.0, "episode/score": 0.7288356554446409, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.028835693588121103}
{"step": 432496, "time": 14140.28388929367, "episode/length": 219.0, "episode/score": 0.34047290995403046, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.024847889854925143}
{"step": 432608, "time": 14143.83857679367, "episode/length": 288.0, "episode/score": 0.03615718325772832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03615718325772832}
{"step": 432880, "time": 14152.52296614647, "episode/length": 288.0, "episode/score": 0.03013210641557862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03013210641557862}
{"step": 432912, "time": 14153.563781499863, "episode/length": 37.0, "episode/score": 0.906606692372236, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.022231687575924752}
{"step": 433064, "time": 14158.157691717148, "episode/length": 77.0, "episode/score": 0.7863189326233169, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.02694392782700561}
{"step": 433152, "time": 14161.173688173294, "episode/length": 114.0, "episode/score": 0.687243147070717, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.043493135964695284}
{"step": 433168, "time": 14161.679432630539, "episode/length": 147.0, "episode/score": 0.6015495579039793, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.060924567426752674}
{"step": 433432, "time": 14169.718037128448, "episode/length": 288.0, "episode/score": 0.035465889698173214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035465889698173214}
{"step": 433448, "time": 14170.221661806107, "episode/length": 288.0, "episode/score": 0.053728332632090314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053728332632090314}
{"step": 433640, "time": 14176.287658452988, "episode/length": 58.0, "episode/score": 0.8387077983079507, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.019957775281000067}
{"step": 433648, "time": 14176.765385866165, "episode/length": 91.0, "episode/score": 0.7482593475278918, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.03263433081065159}
{"step": 433696, "time": 14178.268674373627, "episode/length": 67.0, "episode/score": 0.8129343594523561, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.022309353899345297}
{"step": 433904, "time": 14184.965205430984, "episode/length": 56.0, "episode/score": 0.8406157696390437, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.01561580169982335}
{"step": 433936, "time": 14185.983634233475, "episode/length": 131.0, "episode/score": 0.6231959061519774, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.032570918887813605}
{"step": 434152, "time": 14192.5550968647, "episode/length": 206.0, "episode/score": 0.4036789806053207, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.04742899334115691}
{"step": 434216, "time": 14195.070061922073, "episode/length": 64.0, "episode/score": 0.8210578942057509, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.021057874106645613}
{"step": 434256, "time": 14196.548256874084, "episode/length": 75.0, "episode/score": 0.7908530492170485, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.02522803489796388}
{"step": 434432, "time": 14202.07320189476, "episode/length": 124.0, "episode/score": 0.6501808733119105, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.037680847071897006}
{"step": 434633, "time": 14209.131567239761, "train_stats/mean_log_entropy": 0.12193377389766202, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.525090144230769, "train/action_min": 0.0, "train/action_std": 1.6330229771442903, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011863164432967702, "train/actor_opt_grad_steps": 26090.0, "train/actor_opt_loss": -1.9810876726053464, "train/adv_mag": 0.8224118406956012, "train/adv_max": 0.29516585912459936, "train/adv_mean": 0.004831940062360492, "train/adv_min": -0.7996070336072872, "train/adv_std": 0.03600193013031131, "train/cont_avg": 0.9955228365384615, "train/cont_loss_mean": 0.015790932077484634, "train/cont_loss_std": 0.23160593846860605, "train/cont_neg_acc": 0.3081257690221835, "train/cont_neg_loss": 2.857407305432627, "train/cont_pos_acc": 0.9998389354118934, "train/cont_pos_loss": 0.0028822542180140047, "train/cont_pred": 0.9958714955892318, "train/cont_rate": 0.9955228365384615, "train/dyn_loss_mean": 1.0000102819540562, "train/dyn_loss_std": 0.0003224197431849555, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.649881503253411, "train/extr_critic_critic_opt_grad_steps": 26090.0, "train/extr_critic_critic_opt_loss": 10017.834127103366, "train/extr_critic_mag": 0.9917194812725751, "train/extr_critic_max": 0.9917194812725751, "train/extr_critic_mean": 0.9532403163420848, "train/extr_critic_min": 0.9093461574652256, "train/extr_critic_std": 0.012035931333995019, "train/extr_return_normed_mag": 0.8045521036172525, "train/extr_return_normed_max": 0.3380964294458047, "train/extr_return_normed_mean": 0.03525805728008541, "train/extr_return_normed_min": -0.7725274617855366, "train/extr_return_normed_std": 0.03884765051591855, "train/extr_return_rate": 0.997730748470013, "train/extr_return_raw_mag": 1.2609105895727108, "train/extr_return_raw_max": 1.2609105895727108, "train/extr_return_raw_mean": 0.958072261321239, "train/extr_return_raw_min": 0.15028669834136962, "train/extr_return_raw_std": 0.03884765038696619, "train/extr_reward_mag": 0.35035618329659485, "train/extr_reward_max": 0.35035618329659485, "train/extr_reward_mean": 0.002862471092540102, "train/extr_reward_min": 7.008894895895934e-06, "train/extr_reward_std": 0.012240509724077316, "train/image_loss_mean": 0.10943812426084128, "train/image_loss_std": 0.1039210794445796, "train/model_loss_mean": 0.7422879766195248, "train/model_loss_std": 0.38189962070721845, "train/model_opt_grad_norm": 29.83190221541967, "train/model_opt_grad_steps": 26066.33846153846, "train/model_opt_loss": 2761.691924579327, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3717.948717948718, "train/policy_entropy_mag": 1.4524740255795991, "train/policy_entropy_max": 1.4524740255795991, "train/policy_entropy_mean": 0.15191688094383632, "train/policy_entropy_min": 0.06468679419694803, "train/policy_entropy_std": 0.19339694724633144, "train/policy_logprob_mag": 6.551079588669997, "train/policy_logprob_max": -0.008608234955523259, "train/policy_logprob_mean": -0.15161392310490976, "train/policy_logprob_min": -6.551079588669997, "train/policy_logprob_std": 0.6843233294976063, "train/policy_randomness_mag": 0.7464240376765912, "train/policy_randomness_max": 0.7464240376765912, "train/policy_randomness_mean": 0.0780698384038913, "train/policy_randomness_min": 0.03324243798851967, "train/policy_randomness_std": 0.09938637656279099, "train/post_ent_mag": 30.474221958258212, "train/post_ent_max": 30.474221958258212, "train/post_ent_mean": 30.20514913705679, "train/post_ent_min": 30.00749525412535, "train/post_ent_std": 0.08672551539463874, "train/prior_ent_mag": 34.11540748400566, "train/prior_ent_max": 34.11540748400566, "train/prior_ent_mean": 30.81806139823718, "train/prior_ent_min": 28.46096595372909, "train/prior_ent_std": 1.0091507722169926, "train/rep_loss_mean": 1.0000102819540562, "train/rep_loss_std": 0.0003224197431849555, "train/reward_avg": 0.001153349955730403, "train/reward_loss_mean": 0.017052725177162734, "train/reward_loss_std": 0.1589973910496785, "train/reward_max_data": 0.5619621992027626, "train/reward_max_pred": 0.12660928139319785, "train/reward_neg_acc": 0.9998194587536348, "train/reward_neg_loss": 0.010279438030929901, "train/reward_pos_acc": 0.1858649796134309, "train/reward_pos_loss": 4.496303617954254, "train/reward_pred": 0.0008896338389231226, "train/reward_rate": 0.0014973958333333334, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.013172084465622902, "report/cont_loss_std": 0.25154176354408264, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 3.7373785972595215, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002229264471679926, "report/cont_pred": 0.9970017075538635, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11360357701778412, "report/image_loss_std": 0.10304540395736694, "report/model_loss_mean": 0.7370775938034058, "report/model_loss_std": 0.2838153541088104, "report/post_ent_mag": 29.710193634033203, "report/post_ent_max": 29.710193634033203, "report/post_ent_mean": 29.40322494506836, "report/post_ent_min": 29.164142608642578, "report/post_ent_std": 0.10570219159126282, "report/prior_ent_mag": 33.612037658691406, "report/prior_ent_max": 33.612037658691406, "report/prior_ent_mean": 29.945133209228516, "report/prior_ent_min": 27.74091339111328, "report/prior_ent_std": 1.0464868545532227, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00019750097999349236, "report/reward_loss_mean": 0.010301870293915272, "report/reward_loss_std": 0.019397784024477005, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.16447186470031738, "report/reward_neg_acc": 0.9990234375, "report/reward_neg_loss": 0.010301869362592697, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0009655888425186276, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.024794412776827812, "eval/cont_loss_std": 0.4549073874950409, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.217284202575684, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0007224550354294479, "eval/cont_pred": 0.9992808103561401, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25293827056884766, "eval/image_loss_std": 0.14580689370632172, "eval/model_loss_mean": 0.8793590068817139, "eval/model_loss_std": 0.4713015556335449, "eval/post_ent_mag": 29.711528778076172, "eval/post_ent_max": 29.711528778076172, "eval/post_ent_mean": 29.3837890625, "eval/post_ent_min": 29.198474884033203, "eval/post_ent_std": 0.09195666015148163, "eval/prior_ent_mag": 33.612037658691406, "eval/prior_ent_max": 33.612037658691406, "eval/prior_ent_mean": 29.632780075073242, "eval/prior_ent_min": 27.927637100219727, "eval/prior_ent_std": 0.9868456125259399, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0016263285651803017, "eval/reward_loss_std": 0.0018850661581382155, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0097886323928833, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0016263285651803017, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00028532592114061117, "eval/reward_rate": 0.0, "replay/size": 434129.0, "replay/inserts": 31288.0, "replay/samples": 31296.0, "replay/insert_wait_avg": 1.3359151999684009e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.905844012652439e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 94176.0, "eval_replay/inserts": 4424.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1023086837575406e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2661595344543, "timer/env.step_count": 3911.0, "timer/env.step_total": 37.78727602958679, "timer/env.step_frac": 0.03777722126196273, "timer/env.step_avg": 0.009661793922164865, "timer/env.step_min": 0.007859230041503906, "timer/env.step_max": 0.04300403594970703, "timer/replay._sample_count": 31296.0, "timer/replay._sample_total": 15.923670768737793, "timer/replay._sample_frac": 0.015919433659686153, "timer/replay._sample_avg": 0.0005088084984898323, "timer/replay._sample_min": 0.000392913818359375, "timer/replay._sample_max": 0.011360883712768555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4464.0, "timer/agent.policy_total": 44.579713106155396, "timer/agent.policy_frac": 0.044567850947695525, "timer/agent.policy_avg": 0.009986494871450582, "timer/agent.policy_min": 0.008522510528564453, "timer/agent.policy_max": 0.08540105819702148, "timer/dataset_train_count": 1956.0, "timer/dataset_train_total": 0.22279691696166992, "timer/dataset_train_frac": 0.00022273763321690744, "timer/dataset_train_avg": 0.00011390435427488238, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.0009708404541015625, "timer/agent.train_count": 1956.0, "timer/agent.train_total": 870.8245363235474, "timer/agent.train_frac": 0.870592819743945, "timer/agent.train_avg": 0.4452068181613228, "timer/agent.train_min": 0.4340691566467285, "timer/agent.train_max": 0.5782918930053711, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46814656257629395, "timer/agent.report_frac": 0.0004680219940602405, "timer/agent.report_avg": 0.23407328128814697, "timer/agent.report_min": 0.22357463836669922, "timer/agent.report_max": 0.24457192420959473, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.907932691027794e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 31.27915815563978}
{"step": 434784, "time": 14213.974519729614, "episode/length": 78.0, "episode/score": 0.7761093438086846, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.019859335071714668}
{"step": 434936, "time": 14218.558091640472, "episode/length": 84.0, "episode/score": 0.7677700492376971, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.030270007921899378}
{"step": 435024, "time": 14221.559587955475, "episode/length": 100.0, "episode/score": 0.7234186662994944, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0359186369046256}
{"step": 435152, "time": 14225.607650995255, "episode/length": 155.0, "episode/score": 0.5616041192943158, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.04597913943416643}
{"step": 435376, "time": 14232.630112886429, "episode/length": 288.0, "episode/score": 0.05790047968696399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05790047968696399}
{"step": 435464, "time": 14235.177049398422, "episode/length": 54.0, "episode/score": 0.8471831676658894, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.015933126350091698}
{"step": 435616, "time": 14240.197084903717, "episode/length": 84.0, "episode/score": 0.7584109171764339, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.020910897077328627}
{"step": 435952, "time": 14250.907819032669, "episode/length": 288.0, "episode/score": 0.03735676995313497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03735676995313497}
{"step": 435992, "time": 14251.953116893768, "episode/length": 104.0, "episode/score": 0.6965173893103156, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.021517389467476278}
{"step": 436040, "time": 14253.460502386093, "episode/length": 156.0, "episode/score": 0.547459818854577, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.034959845880393914}
{"step": 436152, "time": 14258.281825304031, "episode/length": 96.0, "episode/score": 0.7451968031608658, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.04519680690361838}
{"step": 436248, "time": 14261.295960903168, "episode/length": 288.0, "episode/score": 0.03752244023098683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03752244023098683}
{"step": 436248, "time": 14261.308305740356, "episode/length": 97.0, "episode/score": 0.718266965447242, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.021392009428950587}
{"step": 436384, "time": 14265.822995901108, "episode/length": 95.0, "episode/score": 0.7280452873831109, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.02492026404183889}
{"step": 436544, "time": 14270.959887266159, "episode/length": 36.0, "episode/score": 0.9025888714559187, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.015088884191754914}
{"step": 436640, "time": 14273.980996847153, "episode/length": 60.0, "episode/score": 0.8343014403751567, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.021801441190063997}
{"step": 436744, "time": 14276.997847557068, "episode/length": 288.0, "episode/score": 0.051057111546924716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051057111546924716}
{"step": 436864, "time": 14280.985049724579, "episode/length": 102.0, "episode/score": 0.707500886732987, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.02625088723357294}
{"step": 437152, "time": 14290.020245552063, "episode/length": 112.0, "episode/score": 0.6816209231164976, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.03162092361708346}
{"step": 437256, "time": 14293.06667971611, "episode/length": 63.0, "episode/score": 0.8195696858028896, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.016444654801489378}
{"step": 437504, "time": 14301.139045476913, "episode/length": 107.0, "episode/score": 0.6986392266653638, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.03301424334767944}
{"step": 437800, "time": 14310.182672977448, "episode/length": 80.0, "episode/score": 0.7733759931070381, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0233759787879535}
{"step": 438040, "time": 14317.70515036583, "episode/length": 260.0, "episode/score": 0.2154771335389114, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.027977139999961764}
{"step": 438120, "time": 14320.197884559631, "episode/length": 216.0, "episode/score": 0.3953567526240249, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0703567649524075}
{"step": 438304, "time": 14326.178641796112, "episode/length": 288.0, "episode/score": 0.042125781396066486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042125781396066486}
{"step": 438392, "time": 14328.735503196716, "episode/length": 141.0, "episode/score": 0.5874794878561715, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.02810449999537923}
{"step": 438544, "time": 14333.807941436768, "episode/length": 92.0, "episode/score": 0.7424004496444923, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.029900465308173807}
{"step": 438624, "time": 14336.317975997925, "episode/length": 72.0, "episode/score": 0.8009383866118469, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.025938403294162526}
{"step": 438856, "time": 14343.374401569366, "episode/length": 288.0, "episode/score": 0.020656996891830204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020656996891830204}
{"step": 439152, "time": 14352.95901966095, "episode/length": 65.0, "episode/score": 0.810530315999813, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.01365533413149933}
{"step": 439176, "time": 14353.512806653976, "episode/length": 288.0, "episode/score": 0.018671742050514695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018671742050514695}
{"step": 439208, "time": 14354.528041362762, "episode/length": 112.0, "episode/score": 0.6691131906288774, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.019113191129463303}
{"step": 439232, "time": 14355.51351428032, "episode/length": 85.0, "episode/score": 0.7612699794684659, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.026894971290289504}
{"step": 439272, "time": 14356.561182022095, "episode/length": 143.0, "episode/score": 0.59438513064174, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0412600834586101}
{"step": 439432, "time": 14361.70418381691, "episode/length": 129.0, "episode/score": 0.6146325963607069, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.017757604579628605}
{"step": 439608, "time": 14367.257249355316, "episode/length": 93.0, "episode/score": 0.7284124873516475, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.019037459420701452}
{"step": 439744, "time": 14371.769158124924, "episode/length": 63.0, "episode/score": 0.8250716491677395, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.021946645465732217}
{"step": 439816, "time": 14373.832681179047, "episode/length": 288.0, "episode/score": 0.0316078261646453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0316078261646453}
{"step": 439848, "time": 14374.844191789627, "episode/length": 86.0, "episode/score": 0.7593175039976359, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.02806750875902253}
{"step": 439960, "time": 14378.382365226746, "episode/length": 97.0, "episode/score": 0.7167031573358145, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.019828201317523053}
{"step": 440024, "time": 14380.872095823288, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 440024, "time": 14381.3434612751, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 440024, "time": 14381.819814920425, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 440024, "time": 14382.197515964508, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 440024, "time": 14382.352352380753, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 440024, "time": 14382.610870599747, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 440024, "time": 14382.969455718994, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 440024, "time": 14383.507713317871, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 440048, "time": 14384.484112501144, "episode/length": 96.0, "episode/score": 0.7194429221640348, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.019442949189851788}
{"step": 440104, "time": 14386.03319978714, "episode/length": 31.0, "episode/score": 0.916044216131354, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.012919223963194781}
{"step": 440248, "time": 14390.651193380356, "episode/length": 101.0, "episode/score": 0.7135911417535681, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.029216173814347712}
{"step": 440432, "time": 14396.804320335388, "episode/length": 85.0, "episode/score": 0.7550647529914158, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.020689763061341182}
{"step": 440552, "time": 14400.36283659935, "episode/length": 117.0, "episode/score": 0.6586964044664683, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.024321398913457415}
{"step": 440848, "time": 14409.89431643486, "episode/length": 92.0, "episode/score": 0.7320848970996394, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.019584944049938713}
{"step": 441344, "time": 14425.525460720062, "episode/length": 190.0, "episode/score": 0.45853723888097875, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.052287229218507036}
{"step": 441368, "time": 14426.059475898743, "episode/length": 101.0, "episode/score": 0.7227530384645888, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.038378027044245755}
{"step": 441504, "time": 14430.551571846008, "episode/length": 192.0, "episode/score": 0.4593192566901507, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.05931924255150989}
{"step": 441520, "time": 14431.066524267197, "episode/length": 288.0, "episode/score": 0.03944000237686396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03944000237686396}
{"step": 441784, "time": 14439.1853992939, "episode/length": 168.0, "episode/score": 0.519061602287934, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.04406159657776243}
{"step": 442008, "time": 14446.212898731232, "episode/length": 79.0, "episode/score": 0.7819656906343653, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.02884067053525996}
{"step": 442360, "time": 14457.420392274857, "episode/length": 288.0, "episode/score": 0.05278517212434508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05278517212434508}
{"step": 442432, "time": 14460.400744199753, "episode/length": 80.0, "episode/score": 0.7695389395863685, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.019538935497280363}
{"step": 442560, "time": 14464.429990768433, "episode/length": 288.0, "episode/score": 0.068552158006014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.068552158006014}
{"step": 442952, "time": 14476.471053600311, "episode/length": 73.0, "episode/score": 0.7971010079698999, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.02522599620613164}
{"step": 443080, "time": 14480.551998615265, "episode/length": 80.0, "episode/score": 0.7786463809728161, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.02864638119109486}
{"step": 443160, "time": 14483.164118766785, "episode/length": 74.0, "episode/score": 0.7978001693646206, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.029050150284149368}
{"step": 443160, "time": 14483.182852506638, "episode/length": 288.0, "episode/score": 0.050465140612459436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050465140612459436}
{"step": 443400, "time": 14490.73093676567, "episode/length": 236.0, "episode/score": 0.3191348310938906, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.05663483483664322}
{"step": 443512, "time": 14494.265003919601, "episode/length": 53.0, "episode/score": 0.8546907505453305, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.020315752926023833}
{"step": 443656, "time": 14498.784517288208, "episode/length": 288.0, "episode/score": 0.04678865183961989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04678865183961989}
{"step": 443832, "time": 14504.288083791733, "episode/length": 288.0, "episode/score": 0.0481343172044717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0481343172044717}
{"step": 443920, "time": 14507.257566452026, "episode/length": 120.0, "episode/score": 0.6625536294367862, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.03755364756847257}
{"step": 444152, "time": 14514.461459636688, "episode/length": 61.0, "episode/score": 0.8225078911049195, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.01313291813073647}
{"step": 444280, "time": 14518.49252486229, "episode/length": 139.0, "episode/score": 0.6012139450184577, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.03558892593798646}
{"step": 444320, "time": 14519.979692220688, "episode/length": 288.0, "episode/score": 0.03923892883659619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03923892883659619}
{"step": 444328, "time": 14520.018091201782, "episode/length": 115.0, "episode/score": 0.6700907340366484, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.029465744106573766}
{"step": 444480, "time": 14525.005014657974, "episode/length": 164.0, "episode/score": 0.5198319316207289, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0323319156107118}
{"step": 444504, "time": 14525.54323554039, "episode/length": 83.0, "episode/score": 0.7494622590961058, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.008837261476799085}
{"step": 444856, "time": 14536.639084100723, "episode/length": 71.0, "episode/score": 0.7882250107348909, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.010099994541519663}
{"step": 445224, "time": 14548.301408052444, "episode/length": 45.0, "episode/score": 0.8717713829388458, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.012396354824545597}
{"step": 445344, "time": 14552.322025060654, "episode/length": 107.0, "episode/score": 0.7042130913366691, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.03858813331021338}
{"step": 445824, "time": 14567.390920639038, "episode/length": 288.0, "episode/score": 0.04433494669569882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04433494669569882}
{"step": 445856, "time": 14568.396416425705, "episode/length": 63.0, "episode/score": 0.83103789481072, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.02791284233069291}
{"step": 446040, "time": 14574.034883260727, "episode/length": 26.0, "episode/score": 0.9299813870793514, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.011231384681195777}
{"step": 446232, "time": 14580.0916659832, "episode/length": 288.0, "episode/score": 0.04405253000311404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04405253000311404}
{"step": 446248, "time": 14580.59932088852, "episode/length": 127.0, "episode/score": 0.6415443420999054, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.03841935162267873}
{"step": 446464, "time": 14587.679088115692, "episode/length": 288.0, "episode/score": 0.04807714604430657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04807714604430657}
{"step": 446488, "time": 14588.222666501999, "episode/length": 270.0, "episode/score": 0.228053107424671, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.07180310858882422}
{"step": 446488, "time": 14588.232216596603, "episode/length": 29.0, "episode/score": 0.9231437710250248, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.01376873576282378}
{"step": 446616, "time": 14592.268142461777, "episode/length": 71.0, "episode/score": 0.7942715008357482, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.016146504578500753}
{"step": 446640, "time": 14593.25046491623, "episode/length": 288.0, "episode/score": 0.03528267103280314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03528267103280314}
{"step": 446816, "time": 14598.802204608917, "episode/length": 288.0, "episode/score": 0.03896390324848653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03896390324848653}
{"step": 446968, "time": 14603.467377185822, "episode/length": 59.0, "episode/score": 0.8436714682823094, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.028046433020108452}
{"step": 447072, "time": 14606.997410058975, "episode/length": 104.0, "episode/score": 0.7140579955516841, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.03905795423588643}
{"step": 447480, "time": 14619.652927398682, "episode/length": 50.0, "episode/score": 0.8667964502692485, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.02304645048752718}
{"step": 447504, "time": 14620.64013171196, "episode/length": 85.0, "episode/score": 0.768533259022206, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.03415823038403687}
{"step": 447584, "time": 14623.157601118088, "episode/length": 120.0, "episode/score": 0.6581139278437149, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.03311394597540129}
{"step": 447960, "time": 14634.889278650284, "episode/length": 59.0, "episode/score": 0.8398096562730188, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.024184645166997143}
{"step": 448032, "time": 14637.40049958229, "episode/length": 195.0, "episode/score": 0.4308647879761338, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.04023979443718417}
{"step": 448152, "time": 14640.991035938263, "episode/length": 23.0, "episode/score": 0.9365859560898571, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.008460917928914569}
{"step": 448168, "time": 14641.504892349243, "episode/length": 288.0, "episode/score": 0.03651060764400427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03651060764400427}
{"step": 448520, "time": 14652.574061632156, "episode/length": 193.0, "episode/score": 0.43281659974093145, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.035941606108849555}
{"step": 448720, "time": 14659.094757080078, "episode/length": 141.0, "episode/score": 0.5909181777155936, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.031543175317438}
{"step": 448760, "time": 14660.152729988098, "episode/length": 90.0, "episode/score": 0.7319952611464942, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.013245279278180533}
{"step": 448800, "time": 14661.724932909012, "episode/length": 288.0, "episode/score": 0.04333097085191184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04333097085191184}
{"step": 448864, "time": 14663.727734565735, "episode/length": 42.0, "episode/score": 0.8776690796819366, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.008919115601884187}
{"step": 448952, "time": 14666.278648853302, "episode/length": 288.0, "episode/score": 0.032150978451568335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032150978451568335}
{"step": 449128, "time": 14671.817791223526, "episode/length": 121.0, "episode/score": 0.6466862563545419, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.024811283380358873}
{"step": 449176, "time": 14673.322606563568, "episode/length": 46.0, "episode/score": 0.8620476667047114, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.005797670447464043}
{"step": 449304, "time": 14677.350389242172, "episode/length": 224.0, "episode/score": 0.35348256590066285, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.053482545801557535}
{"step": 449568, "time": 14685.87027835846, "episode/length": 105.0, "episode/score": 0.6879652027213297, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0160902147994193}
{"step": 449712, "time": 14690.404066085815, "episode/length": 118.0, "episode/score": 0.6648846990547099, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0336346983212934}
{"step": 449800, "time": 14693.024771690369, "episode/length": 105.0, "episode/score": 0.6944712029531956, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.022596173558326882}
{"step": 450008, "time": 14700.570138931274, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 450008, "time": 14701.213829755783, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 450008, "time": 14701.343672037125, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 450008, "time": 14701.672594308853, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 450008, "time": 14702.1864528656, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 450008, "time": 14702.327209949493, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 450008, "time": 14702.352967739105, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 450008, "time": 14704.157796859741, "eval_episode/length": 260.0, "eval_episode/score": 0.1875, "eval_episode/reward_rate": 0.0038314176245210726}
{"step": 450016, "time": 14704.633617162704, "episode/length": 37.0, "episode/score": 0.8994962669368078, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.015121267437393726}
{"step": 450032, "time": 14705.158426523209, "episode/length": 145.0, "episode/score": 0.5699274047623248, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.02305241684041448}
{"step": 450040, "time": 14705.194656133652, "episode/length": 113.0, "episode/score": 0.6638808652988928, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.017005833278858518}
{"step": 450304, "time": 14713.674389600754, "episode/length": 140.0, "episode/score": 0.588093110814782, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.02559312894646837}
{"step": 450312, "time": 14713.710498809814, "episode/length": 63.0, "episode/score": 0.8177793973854932, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.014654393683485978}
{"step": 450480, "time": 14719.23157787323, "episode/length": 288.0, "episode/score": 0.03580730986186609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03580730986186609}
{"step": 450624, "time": 14724.410757303238, "episode/length": 75.0, "episode/score": 0.7788791481222574, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.013254148340536176}
{"step": 450720, "time": 14727.439828395844, "episode/length": 84.0, "episode/score": 0.7619988025240332, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.024498790821382954}
{"step": 450960, "time": 14734.970156431198, "episode/length": 81.0, "episode/score": 0.760367098584311, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.013492110723518635}
{"step": 451104, "time": 14739.49788570404, "episode/length": 133.0, "episode/score": 0.6181330746780986, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.033758064995254244}
{"step": 451144, "time": 14740.536158323288, "episode/length": 103.0, "episode/score": 0.6876958916178069, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.009570877845874293}
{"step": 451616, "time": 14755.66334271431, "episode/length": 288.0, "episode/score": 0.02511475919749273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02511475919749273}
{"step": 451880, "time": 14763.710166454315, "episode/length": 288.0, "episode/score": 0.046045573481535484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046045573481535484}
{"step": 452696, "time": 14789.43401169777, "episode/length": 101.0, "episode/score": 0.7028202785184021, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.018445299505174262}
{"step": 452792, "time": 14792.46197271347, "episode/length": 288.0, "episode/score": 0.022215455528453276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022215455528453276}
{"step": 452936, "time": 14797.030652046204, "episode/length": 288.0, "episode/score": 0.03761687312169215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03761687312169215}
{"step": 453032, "time": 14800.066150188446, "episode/length": 288.0, "episode/score": 0.021132280422477834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021132280422477834}
{"step": 453128, "time": 14803.072119474411, "episode/length": 23.0, "episode/score": 0.9386475349278953, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.01052250392649512}
{"step": 453272, "time": 14807.596797466278, "episode/length": 288.0, "episode/score": 0.039943127050321436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039943127050321436}
{"step": 453416, "time": 14812.213061332703, "episode/length": 288.0, "episode/score": 0.02080898543385956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02080898543385956}
{"step": 453456, "time": 14813.680542707443, "episode/length": 52.0, "episode/score": 0.8509451744716898, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.013445215455703874}
{"step": 453456, "time": 14813.703597784042, "episode/length": 288.0, "episode/score": 0.034555736136042015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034555736136042015}
{"step": 453896, "time": 14827.251100063324, "episode/length": 54.0, "episode/score": 0.843405482890887, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0121554830480477}
{"step": 453928, "time": 14828.274083852768, "episode/length": 288.0, "episode/score": 0.023992886754342635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023992886754342635}
{"step": 453952, "time": 14829.250564098358, "episode/length": 84.0, "episode/score": 0.7594239011749551, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.021923861139725886}
{"step": 454104, "time": 14833.782078027725, "episode/length": 80.0, "episode/score": 0.7779265067994174, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.027926515865260626}
{"step": 454160, "time": 14835.764857053757, "episode/length": 32.0, "episode/score": 0.9167837481016363, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.016783787048382237}
{"step": 454592, "time": 14849.483563661575, "episode/length": 60.0, "episode/score": 0.8279954945146528, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.015495464821469795}
{"step": 455008, "time": 14862.708534002304, "episode/length": 288.0, "episode/score": 0.034270463195866796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034270463195866796}
{"step": 455104, "time": 14865.723487138748, "episode/length": 288.0, "episode/score": 0.03874013413206967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03874013413206967}
{"step": 455440, "time": 14876.454469203949, "episode/length": 288.0, "episode/score": 0.04466578903890195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04466578903890195}
{"step": 455536, "time": 14879.478121519089, "episode/length": 53.0, "episode/score": 0.8521502369408722, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.01777523620745569}
{"step": 455544, "time": 14879.515074014664, "episode/length": 66.0, "episode/score": 0.816009500308212, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.02225950814005273}
{"step": 455728, "time": 14885.510254383087, "episode/length": 288.0, "episode/score": 0.0540326765793111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0540326765793111}
{"step": 456240, "time": 14901.65634560585, "episode/length": 288.0, "episode/score": 0.05420719507054628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05420719507054628}
{"step": 456264, "time": 14902.189573287964, "episode/length": 288.0, "episode/score": 0.03340991052050413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03340991052050413}
{"step": 456312, "time": 14903.707702636719, "episode/length": 95.0, "episode/score": 0.7306145334338225, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.027489559656373785}
{"step": 456472, "time": 14908.749517202377, "episode/length": 288.0, "episode/score": 0.028124916835736258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028124916835736258}
{"step": 456904, "time": 14922.296170711517, "episode/length": 288.0, "episode/score": 0.062158295690608156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062158295690608156}
{"step": 456936, "time": 14923.324258327484, "episode/length": 77.0, "episode/score": 0.7785589771875152, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.01918401518838664}
{"step": 456944, "time": 14923.802967071533, "episode/length": 84.0, "episode/score": 0.7634982599241198, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.025998240843648546}
{"step": 456976, "time": 14924.810489654541, "episode/length": 62.0, "episode/score": 0.8273859781758119, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.02113601617668337}
{"step": 457128, "time": 14929.365690946579, "episode/length": 22.0, "episode/score": 0.9411785991658803, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0099285933145552}
{"step": 457216, "time": 14932.423551559448, "episode/length": 38.0, "episode/score": 0.8940421023374938, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.012792088565561244}
{"step": 457496, "time": 14940.989162683487, "episode/length": 220.0, "episode/score": 0.35887697090095116, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.04637696123847945}
{"step": 457672, "time": 14946.513843536377, "episode/length": 91.0, "episode/score": 0.731851890900657, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.016226903039864737}
{"step": 457752, "time": 14949.041149377823, "episode/length": 288.0, "episode/score": 0.03417557489703427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03417557489703427}
{"step": 457848, "time": 14952.067445278168, "episode/length": 288.0, "episode/score": 0.052558768173184944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052558768173184944}
{"step": 458232, "time": 14964.245719909668, "episode/length": 47.0, "episode/score": 0.8675835450453064, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.014458569105443075}
{"step": 458408, "time": 14969.763658285141, "episode/length": 178.0, "episode/score": 0.4747997734723697, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.031049786017575798}
{"step": 458552, "time": 14974.27835893631, "episode/length": 288.0, "episode/score": 0.046174555873733425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046174555873733425}
{"step": 458624, "time": 14976.756246089935, "episode/length": 118.0, "episode/score": 0.6508837647322423, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.01963372429392507}
{"step": 458808, "time": 14982.809977769852, "episode/length": 49.0, "episode/score": 0.8610173233245746, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.014142303225469277}
{"step": 459056, "time": 14990.94660115242, "episode/length": 53.0, "episode/score": 0.8538872257275898, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.019512224994173266}
{"step": 459272, "time": 14997.554791688919, "episode/length": 57.0, "episode/score": 0.8388285502715007, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.016953591255514766}
{"step": 459440, "time": 15003.093876123428, "episode/length": 288.0, "episode/score": 0.03215728222295411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03215728222295411}
{"step": 459528, "time": 15005.65138912201, "episode/length": 288.0, "episode/score": 0.051742492438336285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051742492438336285}
{"step": 459808, "time": 15014.743044376373, "episode/length": 288.0, "episode/score": 0.0355969955341493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0355969955341493}
{"step": 459872, "time": 15016.785563707352, "episode/length": 74.0, "episode/score": 0.7984993466643289, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.029749318146940595}
{"step": 460064, "time": 15022.987676382065, "episode/length": 288.0, "episode/score": 0.046037688420852874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046037688420852874}
{"step": 460064, "time": 15023.004611730576, "episode/length": 77.0, "episode/score": 0.7755761662766076, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.016201202196555187}
{"step": 460096, "time": 15026.090614557266, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 460096, "time": 15026.319266319275, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 460096, "time": 15026.83070731163, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 460096, "time": 15027.14601111412, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 460096, "time": 15027.712531089783, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 460096, "time": 15027.85910153389, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 460096, "time": 15028.663595676422, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 460096, "time": 15028.808573246002, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 460152, "time": 15030.363379001617, "episode/length": 77.0, "episode/score": 0.7748815356531793, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.015506573654050726}
{"step": 460304, "time": 15035.378807067871, "episode/length": 53.0, "episode/score": 0.8564562618359162, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.022081250072147895}
{"step": 460544, "time": 15042.910658121109, "episode/length": 288.0, "episode/score": 0.01813524601917038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01813524601917038}
{"step": 460712, "time": 15047.975515842438, "episode/length": 112.0, "episode/score": 0.6845995455801983, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.034599539728873197}
{"step": 460712, "time": 15047.999248981476, "episode/length": 80.0, "episode/score": 0.7695940954175455, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.019594065724362508}
{"step": 460864, "time": 15053.15041089058, "episode/length": 288.0, "episode/score": 0.028154296244025545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028154296244025545}
{"step": 461120, "time": 15061.302490711212, "episode/length": 50.0, "episode/score": 0.8595969333357516, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.015846959914824765}
{"step": 461224, "time": 15064.328468799591, "episode/length": 114.0, "episode/score": 0.686499061564632, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.04274901995052005}
{"step": 461248, "time": 15065.325618505478, "episode/length": 66.0, "episode/score": 0.8133643471446987, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.01961433681574931}
{"step": 461368, "time": 15068.881079673767, "episode/length": 288.0, "episode/score": 0.04943752287670122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04943752287670122}
{"step": 461392, "time": 15069.884720087051, "episode/length": 154.0, "episode/score": 0.5498029318978581, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.031052946556002325}
{"step": 461504, "time": 15073.422439098358, "episode/length": 79.0, "episode/score": 0.7742532243785831, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.021128238680205413}
{"step": 461592, "time": 15075.979548692703, "episode/length": 130.0, "episode/score": 0.6387144693934488, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.04496447946337412}
{"step": 461920, "time": 15086.622054338455, "episode/length": 99.0, "episode/score": 0.7163458096877378, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.025720816349604547}
{"step": 462256, "time": 15097.215202569962, "episode/length": 125.0, "episode/score": 0.6310914270152637, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.02171643305430848}
{"step": 462376, "time": 15100.78072476387, "episode/length": 288.0, "episode/score": 0.04275059953582172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04275059953582172}
{"step": 462424, "time": 15102.293026208878, "episode/length": 131.0, "episode/score": 0.6215349293695454, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.03090992459942754}
{"step": 462720, "time": 15111.948731660843, "episode/length": 57.0, "episode/score": 0.8383507559987038, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.016475806419634864}
{"step": 462904, "time": 15117.500776052475, "episode/length": 122.0, "episode/score": 0.653840899887939, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.03509092380255652}
{"step": 462984, "time": 15120.022051811218, "episode/length": 69.0, "episode/score": 0.8071589463795021, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.022783911735757556}
{"step": 463536, "time": 15137.716599464417, "episode/length": 288.0, "episode/score": 0.03779817661813922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03779817661813922}
{"step": 463704, "time": 15142.944339513779, "episode/length": 288.0, "episode/score": 0.04910021976002099, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04910021976002099}
{"step": 463768, "time": 15144.965873718262, "episode/length": 97.0, "episode/score": 0.7198861189673096, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.02301116938824066}
{"step": 463816, "time": 15146.500821352005, "episode/length": 288.0, "episode/score": 0.03584397221467839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03584397221467839}
{"step": 463904, "time": 15149.488281488419, "episode/length": 288.0, "episode/score": 0.034813842011089946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034813842011089946}
{"step": 464264, "time": 15160.603321313858, "episode/length": 55.0, "episode/score": 0.8381906868376348, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.010065692876679577}
{"step": 464440, "time": 15166.164826631546, "episode/length": 91.0, "episode/score": 0.7442441492912621, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.028619167251235922}
{"step": 464440, "time": 15166.183282136917, "episode/length": 83.0, "episode/score": 0.7737634299389242, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.03313841616699165}
{"step": 464688, "time": 15174.260564804077, "episode/length": 288.0, "episode/score": 0.044720318060797126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044720318060797126}
{"step": 464712, "time": 15174.798234939575, "episode/length": 100.0, "episode/score": 0.7080842823848172, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.020584288423862063}
{"step": 465032, "time": 15184.935902833939, "episode/length": 288.0, "episode/score": 0.032683784020605344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032683784020605344}
{"step": 465072, "time": 15186.434166193008, "episode/length": 78.0, "episode/score": 0.7861008829791558, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.029850859952205155}
{"step": 465136, "time": 15188.450239658356, "episode/length": 86.0, "episode/score": 0.7528371272067034, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.021587124808547742}
{"step": 465216, "time": 15190.964409351349, "episode/length": 288.0, "episode/score": 0.01908679906796351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01908679906796351}
{"step": 465616, "time": 15203.682678461075, "episode/length": 49.0, "episode/score": 0.864871195289652, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.01799616002745097}
{"step": 465769, "time": 15209.233439445496, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3994297125400643, "train/action_min": 0.0, "train/action_std": 1.6418151653729953, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012844429383627497, "train/actor_opt_grad_steps": 28040.0, "train/actor_opt_loss": -5.492291303704946, "train/adv_mag": 0.9854404473916079, "train/adv_max": 0.3580983730462881, "train/adv_mean": 0.003239298616520104, "train/adv_min": -0.9750976385214389, "train/adv_std": 0.04224863111351927, "train/cont_avg": 0.9954176682692307, "train/cont_loss_mean": 0.01461368770374415, "train/cont_loss_std": 0.2143384245152657, "train/cont_neg_acc": 0.3939964888790219, "train/cont_neg_loss": 2.512557522208939, "train/cont_pos_acc": 0.9997786185680292, "train/cont_pos_loss": 0.0030580572231720463, "train/cont_pred": 0.9954563697179158, "train/cont_rate": 0.9954176682692307, "train/dyn_loss_mean": 1.000011631158682, "train/dyn_loss_std": 0.0003361504707031716, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4403713732002637, "train/extr_critic_critic_opt_grad_steps": 28040.0, "train/extr_critic_critic_opt_loss": 11808.350315504807, "train/extr_critic_mag": 1.1358733898554092, "train/extr_critic_max": 1.1358733898554092, "train/extr_critic_mean": 1.095102943518223, "train/extr_critic_min": 0.9729715915826651, "train/extr_critic_std": 0.012576161458706244, "train/extr_return_normed_mag": 0.975107863621834, "train/extr_return_normed_max": 0.3581416026139871, "train/extr_return_normed_mean": 0.03346095999511771, "train/extr_return_normed_min": -0.9603657863078974, "train/extr_return_normed_std": 0.04459984397085814, "train/extr_return_rate": 0.9979708017447055, "train/extr_return_raw_mag": 1.4230228564678093, "train/extr_return_raw_max": 1.4230228564678093, "train/extr_return_raw_mean": 1.098342273174188, "train/extr_return_raw_min": 0.10451546754592504, "train/extr_return_raw_std": 0.044599843794145645, "train/extr_reward_mag": 0.3981343195988582, "train/extr_reward_max": 0.3981343195988582, "train/extr_reward_mean": 0.0029729001313591233, "train/extr_reward_min": 6.0503299419696515e-06, "train/extr_reward_std": 0.01300989068710269, "train/image_loss_mean": 0.10396830817827811, "train/image_loss_std": 0.10335846780202328, "train/model_loss_mean": 0.736097128269, "train/model_loss_std": 0.36784843217868074, "train/model_opt_grad_norm": 28.0956786718124, "train/model_opt_grad_steps": 28015.194871794873, "train/model_opt_loss": 2737.018346854968, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3717.948717948718, "train/policy_entropy_mag": 1.3682773755146906, "train/policy_entropy_max": 1.3682773755146906, "train/policy_entropy_mean": 0.12281023340347486, "train/policy_entropy_min": 0.0646866363974718, "train/policy_entropy_std": 0.15952079666730684, "train/policy_logprob_mag": 6.5510800141554615, "train/policy_logprob_max": -0.008608167021511457, "train/policy_logprob_mean": -0.12256981841264628, "train/policy_logprob_min": -6.5510800141554615, "train/policy_logprob_std": 0.6577448869362855, "train/policy_randomness_mag": 0.7031555151328063, "train/policy_randomness_max": 0.7031555151328063, "train/policy_randomness_mean": 0.06311197962898474, "train/policy_randomness_min": 0.033242357541353275, "train/policy_randomness_std": 0.08197747736405103, "train/post_ent_mag": 29.907511911636742, "train/post_ent_max": 29.907511911636742, "train/post_ent_mean": 29.595179376846705, "train/post_ent_min": 29.377264599922377, "train/post_ent_std": 0.1007628620817111, "train/prior_ent_mag": 33.25008975297977, "train/prior_ent_max": 33.25008975297977, "train/prior_ent_mean": 29.41612888238369, "train/prior_ent_min": 27.50505726154034, "train/prior_ent_std": 0.951186766074254, "train/rep_loss_mean": 1.000011631158682, "train/rep_loss_std": 0.0003361504707031716, "train/reward_avg": 0.0012987244385443866, "train/reward_loss_mean": 0.017508130783262927, "train/reward_loss_std": 0.15284704332932447, "train/reward_max_data": 0.5627009795835385, "train/reward_max_pred": 0.18451030193231044, "train/reward_neg_acc": 0.9997742558136965, "train/reward_neg_loss": 0.010602165581897284, "train/reward_pos_acc": 0.23691286237872378, "train/reward_pos_loss": 4.1494392586403155, "train/reward_pred": 0.0010468477162365348, "train/reward_rate": 0.001672676282051282, "train_stats/mean_log_entropy": 0.10326590848651099, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.01598311960697174, "report/cont_loss_std": 0.2406967431306839, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.1940793991088867, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003145618597045541, "report/cont_pred": 0.9939829111099243, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08822539448738098, "report/image_loss_std": 0.09223529696464539, "report/model_loss_mean": 0.7262302041053772, "report/model_loss_std": 0.4794202744960785, "report/post_ent_mag": 29.679611206054688, "report/post_ent_max": 29.679611206054688, "report/post_ent_mean": 29.344736099243164, "report/post_ent_min": 29.121631622314453, "report/post_ent_std": 0.1117938831448555, "report/prior_ent_mag": 32.752986907958984, "report/prior_ent_max": 32.752986907958984, "report/prior_ent_mean": 28.65094757080078, "report/prior_ent_min": 27.06540870666504, "report/prior_ent_std": 0.8716543316841125, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0010966832051053643, "report/reward_loss_mean": 0.022021658718585968, "report/reward_loss_std": 0.25190865993499756, "report/reward_max_data": 0.6566666960716248, "report/reward_max_pred": 0.04286003112792969, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01112592313438654, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.5897417068481445, "report/reward_pred": 0.001185094122774899, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.031071240082383156, "eval/cont_loss_std": 0.4907873570919037, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.788084983825684, "eval/cont_pos_acc": 0.9980410933494568, "eval/cont_pos_loss": 0.005340544506907463, "eval/cont_pred": 0.9968351125717163, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2854699492454529, "eval/image_loss_std": 0.1599637269973755, "eval/model_loss_mean": 0.9182440638542175, "eval/model_loss_std": 0.517937183380127, "eval/post_ent_mag": 29.678627014160156, "eval/post_ent_max": 29.678627014160156, "eval/post_ent_mean": 29.34598159790039, "eval/post_ent_min": 29.138959884643555, "eval/post_ent_std": 0.09840241074562073, "eval/prior_ent_mag": 32.688209533691406, "eval/prior_ent_max": 32.688209533691406, "eval/prior_ent_mean": 28.534095764160156, "eval/prior_ent_min": 27.110546112060547, "eval/prior_ent_std": 0.8251076340675354, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0017028660513460636, "eval/reward_loss_std": 0.0027270778082311153, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.016832947731018066, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0017028660513460636, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000354593968950212, "eval/reward_rate": 0.0, "replay/size": 465265.0, "replay/inserts": 31136.0, "replay/samples": 31136.0, "replay/insert_wait_avg": 1.342567057183198e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.848243286038718e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 99456.0, "eval_replay/inserts": 5280.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1052597652782093e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0830056667328, "timer/env.step_count": 3892.0, "timer/env.step_total": 37.74032998085022, "timer/env.step_frac": 0.037737197579604496, "timer/env.step_avg": 0.009696898761780632, "timer/env.step_min": 0.00784754753112793, "timer/env.step_max": 0.03870582580566406, "timer/replay._sample_count": 31136.0, "timer/replay._sample_total": 16.00409197807312, "timer/replay._sample_frac": 0.01600276365800612, "timer/replay._sample_avg": 0.0005140060373224923, "timer/replay._sample_min": 0.0003783702850341797, "timer/replay._sample_max": 0.012673616409301758, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4552.0, "timer/agent.policy_total": 45.95179510116577, "timer/agent.policy_frac": 0.045947981158354696, "timer/agent.policy_avg": 0.010094858326266646, "timer/agent.policy_min": 0.008579015731811523, "timer/agent.policy_max": 0.09240221977233887, "timer/dataset_train_count": 1946.0, "timer/dataset_train_total": 0.22285246849060059, "timer/dataset_train_frac": 0.00022283397200818333, "timer/dataset_train_avg": 0.0001145182263569376, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.00040721893310546875, "timer/agent.train_count": 1946.0, "timer/agent.train_total": 868.6859993934631, "timer/agent.train_frac": 0.8686138995176003, "timer/agent.train_avg": 0.44639568314155353, "timer/agent.train_min": 0.4349508285522461, "timer/agent.train_max": 1.7332839965820312, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48116302490234375, "timer/agent.report_frac": 0.00048112308895956413, "timer/agent.report_avg": 0.24058151245117188, "timer/agent.report_min": 0.23460674285888672, "timer/agent.report_max": 0.24655628204345703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6700664552911577e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 31.13289354988416}
{"step": 465848, "time": 15211.496171236038, "episode/length": 288.0, "episode/score": 0.031072418855501382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031072418855501382}
{"step": 466104, "time": 15219.597275018692, "episode/length": 60.0, "episode/score": 0.8279897074185101, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.015489684077238053}
{"step": 466296, "time": 15225.670221328735, "episode/length": 55.0, "episode/score": 0.8430943009252587, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.01496927153038996}
{"step": 466576, "time": 15234.842434883118, "episode/length": 288.0, "episode/score": 0.0362111239211913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0362111239211913}
{"step": 466856, "time": 15243.48272895813, "episode/length": 93.0, "episode/score": 0.7359443934467436, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.026569346263613625}
{"step": 466880, "time": 15244.468965291977, "episode/length": 270.0, "episode/score": 0.17496973120282178, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.018719732366974995}
{"step": 467000, "time": 15248.54482293129, "episode/length": 288.0, "episode/score": 0.041453988389235974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041453988389235974}
{"step": 467128, "time": 15252.605004787445, "episode/length": 68.0, "episode/score": 0.7976560520035036, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.010156019983469378}
{"step": 467344, "time": 15259.694730997086, "episode/length": 60.0, "episode/score": 0.8326890577214954, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.020189049543319015}
{"step": 467344, "time": 15259.711154699326, "episode/length": 288.0, "episode/score": 0.023857188158672216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023857188158672216}
{"step": 467384, "time": 15260.872339963913, "episode/length": 288.0, "episode/score": 0.025519927827645006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025519927827645006}
{"step": 467448, "time": 15262.89126586914, "episode/length": 288.0, "episode/score": 0.052535542010218705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052535542010218705}
{"step": 467512, "time": 15264.938953876495, "episode/length": 63.0, "episode/score": 0.8193280627369859, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.01620302457604339}
{"step": 467640, "time": 15268.986954212189, "episode/length": 31.0, "episode/score": 0.911393437665879, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.008268469726658623}
{"step": 467728, "time": 15271.973487138748, "episode/length": 47.0, "episode/score": 0.8680615471491819, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.014936556671955259}
{"step": 467880, "time": 15276.545961618423, "episode/length": 93.0, "episode/score": 0.7265816010805111, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.017206547843784392}
{"step": 467920, "time": 15278.033550262451, "episode/length": 58.0, "episode/score": 0.837596300458813, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.018846296756805714}
{"step": 468112, "time": 15284.076971769333, "episode/length": 95.0, "episode/score": 0.7188416232767167, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.015716643416567422}
{"step": 468232, "time": 15287.623847007751, "episode/length": 62.0, "episode/score": 0.8326372663360644, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.026387260783053534}
{"step": 468272, "time": 15289.125643491745, "episode/length": 78.0, "episode/score": 0.7773034545775772, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.02105340134085054}
{"step": 468448, "time": 15294.741981506348, "episode/length": 70.0, "episode/score": 0.794582579816506, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.013332594921394048}
{"step": 468608, "time": 15299.75856256485, "episode/length": 288.0, "episode/score": 0.015321675393579426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015321675393579426}
{"step": 468768, "time": 15304.785300731659, "episode/length": 81.0, "episode/score": 0.7610366863691524, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.014161691130539111}
{"step": 468832, "time": 15306.792392253876, "episode/length": 74.0, "episode/score": 0.7879940855967789, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.01924409180753628}
{"step": 468896, "time": 15308.80318236351, "episode/length": 77.0, "episode/score": 0.7772823360315897, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.01790735271390531}
{"step": 469192, "time": 15317.907730817795, "episode/length": 288.0, "episode/score": 0.028962132761080284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028962132761080284}
{"step": 469448, "time": 15326.066612958908, "episode/length": 84.0, "episode/score": 0.7572960829817248, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.01979609416923722}
{"step": 469608, "time": 15331.137609243393, "episode/length": 124.0, "episode/score": 0.6351426326689307, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.022642635852889725}
{"step": 469824, "time": 15338.15711259842, "episode/length": 288.0, "episode/score": 0.036757514436885685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036757514436885685}
{"step": 469856, "time": 15339.182005405426, "episode/length": 82.0, "episode/score": 0.7642168159393918, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.020466851859339386}
{"step": 470080, "time": 15346.874980449677, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 470080, "time": 15347.467671632767, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 470080, "time": 15347.62662577629, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 470080, "time": 15347.87106013298, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 470080, "time": 15348.704372882843, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 470080, "time": 15349.105432987213, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 470080, "time": 15349.300310373306, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 470080, "time": 15349.561563491821, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 470152, "time": 15351.694259881973, "episode/length": 67.0, "episode/score": 0.8133488860570992, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.022723928030643492}
{"step": 470216, "time": 15353.721317052841, "episode/length": 44.0, "episode/score": 0.8763236853756098, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.01382366936559265}
{"step": 470232, "time": 15354.232042312622, "episode/length": 288.0, "episode/score": 0.025303828030928344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025303828030928344}
{"step": 470688, "time": 15368.925639152527, "episode/length": 58.0, "episode/score": 0.8320407933293836, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.013290784592413729}
{"step": 470760, "time": 15370.988815784454, "episode/length": 288.0, "episode/score": 0.03857844521900233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03857844521900233}
{"step": 471096, "time": 15381.66763496399, "episode/length": 117.0, "episode/score": 0.6518616945016902, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.01748672841347343}
{"step": 471144, "time": 15383.163357496262, "episode/length": 288.0, "episode/score": 0.020569736942206873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020569736942206873}
{"step": 471208, "time": 15385.177549600601, "episode/length": 288.0, "episode/score": 0.03773689932432944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03773689932432944}
{"step": 471464, "time": 15393.16474723816, "episode/length": 96.0, "episode/score": 0.7102548284203749, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.010254855446191868}
{"step": 471664, "time": 15399.678685426712, "episode/length": 64.0, "episode/score": 0.8078683170123213, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.007868317169481998}
{"step": 471760, "time": 15402.67234325409, "episode/length": 288.0, "episode/score": 0.024410830370754866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024410830370754866}
{"step": 472136, "time": 15414.35196518898, "episode/length": 288.0, "episode/score": 0.02730763492945698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02730763492945698}
{"step": 472216, "time": 15416.850086450577, "episode/length": 68.0, "episode/score": 0.8008837029991582, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.01338369123538996}
{"step": 472336, "time": 15420.844202756882, "episode/length": 14.0, "episode/score": 0.9612418899640716, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.004991893148030613}
{"step": 472448, "time": 15424.381174087524, "episode/length": 38.0, "episode/score": 0.8853721780007504, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.004122146999350207}
{"step": 472544, "time": 15427.395263671875, "episode/length": 288.0, "episode/score": 0.022726439684959132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022726439684959132}
{"step": 472760, "time": 15434.000258207321, "episode/length": 38.0, "episode/score": 0.8918611685923565, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.010611140661410445}
{"step": 472776, "time": 15434.507538080215, "episode/length": 54.0, "episode/score": 0.850570338113755, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.01932035241537733}
{"step": 473072, "time": 15444.189809083939, "episode/length": 288.0, "episode/score": 0.0305247311215453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0305247311215453}
{"step": 473256, "time": 15449.827059268951, "episode/length": 88.0, "episode/score": 0.7457719625049322, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.020771958802924928}
{"step": 473408, "time": 15454.956590175629, "episode/length": 288.0, "episode/score": 0.021996546180844234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021996546180844234}
{"step": 473480, "time": 15457.035332202911, "episode/length": 87.0, "episode/score": 0.7554881491456626, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.027363144349351387}
{"step": 473520, "time": 15458.516593933105, "episode/length": 288.0, "episode/score": 0.03415280753102934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03415280753102934}
{"step": 473568, "time": 15460.044884443283, "episode/length": 100.0, "episode/score": 0.7257747464346949, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.038274747249602115}
{"step": 473776, "time": 15466.544233322144, "episode/length": 288.0, "episode/score": 0.04280018175813893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04280018175813893}
{"step": 474040, "time": 15474.755660772324, "episode/length": 64.0, "episode/score": 0.833263559500665, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.03326351894156687}
{"step": 474072, "time": 15475.77403974533, "episode/length": 288.0, "episode/score": 0.06143246457941132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06143246457941132}
{"step": 474104, "time": 15476.788536548615, "episode/length": 66.0, "episode/score": 0.8212398448249587, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.027489857560794917}
{"step": 474312, "time": 15483.362342119217, "episode/length": 112.0, "episode/score": 0.6939801166777215, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.04398014133448669}
{"step": 474504, "time": 15489.411744594574, "episode/length": 127.0, "episode/score": 0.6556466380384336, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.05252163853901948}
{"step": 474576, "time": 15491.918226480484, "episode/length": 66.0, "episode/score": 0.8248704928719235, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.03112049047376786}
{"step": 474856, "time": 15500.601742267609, "episode/length": 43.0, "episode/score": 0.8900568397079951, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0244318015470526}
{"step": 474912, "time": 15502.660698652267, "episode/length": 41.0, "episode/score": 0.8894066814439157, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.017531663969975853}
{"step": 475376, "time": 15517.72937464714, "episode/length": 64.0, "episode/score": 0.8157763082713245, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.01577628817221921}
{"step": 475384, "time": 15517.766530275345, "episode/length": 288.0, "episode/score": 0.061456860180157946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061456860180157946}
{"step": 475568, "time": 15523.778980970383, "episode/length": 288.0, "episode/score": 0.05754280063706574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05754280063706574}
{"step": 475832, "time": 15531.99778676033, "episode/length": 56.0, "episode/score": 0.8460880351663036, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.021088023745960527}
{"step": 475856, "time": 15532.979305505753, "episode/length": 35.0, "episode/score": 0.9096943062027094, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.01906927680784065}
{"step": 476088, "time": 15540.079635858536, "episode/length": 288.0, "episode/score": 0.04701079110827777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04701079110827777}
{"step": 476232, "time": 15544.629567623138, "episode/length": 46.0, "episode/score": 0.8726800821116285, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.01643008687301517}
{"step": 476384, "time": 15549.63477730751, "episode/length": 288.0, "episode/score": 0.0331721592303893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0331721592303893}
{"step": 476416, "time": 15550.653335571289, "episode/length": 288.0, "episode/score": 0.05999829266340839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05999829266340839}
{"step": 476560, "time": 15555.185914993286, "episode/length": 90.0, "episode/score": 0.7346075140410449, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.015857505862868493}
{"step": 476624, "time": 15557.22245979309, "episode/length": 288.0, "episode/score": 0.05730972251444655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05730972251444655}
{"step": 476632, "time": 15557.261023759842, "episode/length": 49.0, "episode/score": 0.8617649820162114, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.01488994145711331}
{"step": 477008, "time": 15569.493548870087, "episode/length": 202.0, "episode/score": 0.4197414960997321, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.05099148196109127}
{"step": 477224, "time": 15576.070563316345, "episode/length": 288.0, "episode/score": 0.0511585263533334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0511585263533334}
{"step": 477264, "time": 15577.580741167068, "episode/length": 78.0, "episode/score": 0.786013421222151, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.029763367985424338}
{"step": 477424, "time": 15582.620876312256, "episode/length": 51.0, "episode/score": 0.8533655014679198, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.012740514203755993}
{"step": 477832, "time": 15595.326746225357, "episode/length": 50.0, "episode/score": 0.8604052490967433, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.01665524091856696}
{"step": 478400, "time": 15613.480650663376, "episode/length": 288.0, "episode/score": 0.04606106428440171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04606106428440171}
{"step": 478496, "time": 15616.49855017662, "episode/length": 82.0, "episode/score": 0.7669039363588581, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.023153980340566704}
{"step": 478608, "time": 15620.050045251846, "episode/length": 247.0, "episode/score": 0.27917664337098813, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.051051640641048834}
{"step": 478696, "time": 15622.715777635574, "episode/length": 288.0, "episode/score": 0.03191818361943888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03191818361943888}
{"step": 478728, "time": 15623.734731912613, "episode/length": 288.0, "episode/score": 0.025050033371257996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025050033371257996}
{"step": 478776, "time": 15625.253365278244, "episode/length": 34.0, "episode/score": 0.9051618179630623, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.011411824173819696}
{"step": 478872, "time": 15628.294177293777, "episode/length": 288.0, "episode/score": 0.03682608037274804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03682608037274804}
{"step": 479048, "time": 15633.86911034584, "episode/length": 80.0, "episode/score": 0.7681264775604291, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.018126492665317073}
{"step": 479176, "time": 15637.971302747726, "episode/length": 59.0, "episode/score": 0.8359765668134855, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.020351569997444585}
{"step": 479296, "time": 15642.020375728607, "episode/length": 64.0, "episode/score": 0.812693745565241, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.012693751775998408}
{"step": 479448, "time": 15646.611429929733, "episode/length": 49.0, "episode/score": 0.8569830480415703, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.010108036338920101}
{"step": 479536, "time": 15649.610609292984, "episode/length": 288.0, "episode/score": 0.018535299385121107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018535299385121107}
{"step": 479576, "time": 15650.734304904938, "episode/length": 288.0, "episode/score": 0.03229334749278223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03229334749278223}
{"step": 479648, "time": 15653.246651411057, "episode/length": 58.0, "episode/score": 0.8371811929700925, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.01843118423312262}
{"step": 479904, "time": 15661.38927078247, "episode/length": 31.0, "episode/score": 0.9149758660208249, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.011850893046641886}
{"step": 480064, "time": 15667.438291788101, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 480064, "time": 15667.68673491478, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 480064, "time": 15667.886642694473, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 480064, "time": 15667.915367603302, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 480064, "time": 15667.987735033035, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 480064, "time": 15668.754714250565, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 480064, "time": 15668.76938176155, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 480064, "time": 15669.140683174133, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 480128, "time": 15671.207100629807, "episode/length": 73.0, "episode/score": 0.7859658795824203, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.014090870845450354}
{"step": 480432, "time": 15680.919261693954, "episode/length": 65.0, "episode/score": 0.8207697516527332, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.02389477476117463}
{"step": 480720, "time": 15689.966883182526, "episode/length": 73.0, "episode/score": 0.7942022731700149, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.022327245239068816}
{"step": 480920, "time": 15696.038227558136, "episode/length": 288.0, "episode/score": 0.05195272626491487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05195272626491487}
{"step": 481040, "time": 15700.025424957275, "episode/length": 288.0, "episode/score": 0.020326698002008925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020326698002008925}
{"step": 481184, "time": 15704.561516284943, "episode/length": 288.0, "episode/score": 0.01434804002292367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01434804002292367}
{"step": 481424, "time": 15712.23661184311, "episode/length": 29.0, "episode/score": 0.9255976001704767, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.016222581090005406}
{"step": 481608, "time": 15717.821024179459, "episode/length": 288.0, "episode/score": 0.03039915733768339, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03039915733768339}
{"step": 481760, "time": 15722.830935001373, "episode/length": 288.0, "episode/score": 0.02423877409182751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02423877409182751}
{"step": 481888, "time": 15726.872334480286, "episode/length": 288.0, "episode/score": 0.037278444635092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037278444635092}
{"step": 482744, "time": 15753.681938648224, "episode/length": 288.0, "episode/score": 0.030073384331728903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030073384331728903}
{"step": 482992, "time": 15761.714008569717, "episode/length": 137.0, "episode/score": 0.6130802466951195, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.04120525621789284}
{"step": 483032, "time": 15762.764627218246, "episode/length": 288.0, "episode/score": 0.051759442468437555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051759442468437555}
{"step": 483232, "time": 15769.27110671997, "episode/length": 288.0, "episode/score": 0.052061103863422886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052061103863422886}
{"step": 483352, "time": 15773.470226049423, "episode/length": 288.0, "episode/score": 0.03395551956111831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03395551956111831}
{"step": 483736, "time": 15785.552553653717, "episode/length": 288.0, "episode/score": 0.02545389208916049, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02545389208916049}
{"step": 483920, "time": 15791.622708559036, "episode/length": 288.0, "episode/score": 0.053009817829604344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053009817829604344}
{"step": 484072, "time": 15796.15299320221, "episode/length": 288.0, "episode/score": 0.048725002383150695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048725002383150695}
{"step": 485056, "time": 15827.4502222538, "episode/length": 288.0, "episode/score": 0.03995048025657866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03995048025657866}
{"step": 485080, "time": 15828.009030103683, "episode/length": 215.0, "episode/score": 0.3676329557436304, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.03950794608115871}
{"step": 485120, "time": 15829.495066404343, "episode/length": 235.0, "episode/score": 0.3061207495867393, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.04049573791610328}
{"step": 485280, "time": 15834.673475265503, "episode/length": 19.0, "episode/score": 0.9472112078090333, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.006586172546832358}
{"step": 485304, "time": 15835.212140083313, "episode/length": 288.0, "episode/score": 0.06138089575350136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06138089575350136}
{"step": 485344, "time": 15836.702749490738, "episode/length": 288.0, "episode/score": 0.04240542230283495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04240542230283495}
{"step": 485456, "time": 15840.24295949936, "episode/length": 49.0, "episode/score": 0.86269130329012, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.01581631447763243}
{"step": 485688, "time": 15847.324015378952, "episode/length": 42.0, "episode/score": 0.8816364879368734, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.012886523856820986}
{"step": 485696, "time": 15847.80439043045, "episode/length": 202.0, "episode/score": 0.3952236674363405, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.026473646778441662}
{"step": 485928, "time": 15854.933255910873, "episode/length": 80.0, "episode/score": 0.7890501844007929, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.03905015576262372}
{"step": 486048, "time": 15858.95150399208, "episode/length": 288.0, "episode/score": 0.021628324654273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021628324654273}
{"step": 486232, "time": 15864.695806026459, "episode/length": 288.0, "episode/score": 0.061643399193826554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061643399193826554}
{"step": 486320, "time": 15867.695722579956, "episode/length": 77.0, "episode/score": 0.7912567456627073, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.03188177031947248}
{"step": 486576, "time": 15875.713966608047, "episode/length": 110.0, "episode/score": 0.6985437136441988, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.04229368500602959}
{"step": 487048, "time": 15890.28768658638, "episode/length": 90.0, "episode/score": 0.7576374456839403, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.03888743136485573}
{"step": 487136, "time": 15893.437670230865, "episode/length": 135.0, "episode/score": 0.6267083954526242, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.04858337211135222}
{"step": 487368, "time": 15900.534157276154, "episode/length": 98.0, "episode/score": 0.7272724758340701, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.03352245280711941}
{"step": 487392, "time": 15901.520502567291, "episode/length": 288.0, "episode/score": 0.06271985461634699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06271985461634699}
{"step": 487616, "time": 15908.552558422089, "episode/length": 288.0, "episode/score": 0.06473191130416467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06473191130416467}
{"step": 487696, "time": 15911.075304031372, "episode/length": 80.0, "episode/score": 0.7792793997023182, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.029279371064149018}
{"step": 487768, "time": 15913.116455554962, "episode/length": 288.0, "episode/score": 0.05332730202329117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05332730202329117}
{"step": 487968, "time": 15919.66857790947, "episode/length": 74.0, "episode/score": 0.81133933650176, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.04258929594266192}
{"step": 488176, "time": 15926.3004758358, "episode/length": 59.0, "episode/score": 0.8426587108990589, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.02703368465904532}
{"step": 488240, "time": 15928.32441687584, "episode/length": 288.0, "episode/score": 0.07081222487317973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07081222487317973}
{"step": 488544, "time": 15937.972700834274, "episode/length": 288.0, "episode/score": 0.06938363848166773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06938363848166773}
{"step": 488656, "time": 15941.50463438034, "episode/length": 189.0, "episode/score": 0.48431037202931293, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0749353612725372}
{"step": 488824, "time": 15946.616296291351, "episode/length": 80.0, "episode/score": 0.7848632087802798, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.034863194461195235}
{"step": 489384, "time": 15964.384553194046, "episode/length": 104.0, "episode/score": 0.7108498933125702, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.03584985275347208}
{"step": 489568, "time": 15970.428090810776, "episode/length": 92.0, "episode/score": 0.7544453026421252, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.041945327298890334}
{"step": 489704, "time": 15974.461772680283, "episode/length": 288.0, "episode/score": 0.07377777042029265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07377777042029265}
{"step": 489808, "time": 15977.963773727417, "episode/length": 52.0, "episode/score": 0.8632500543967581, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.025750063919531385}
{"step": 489928, "time": 15981.65932559967, "episode/length": 288.0, "episode/score": 0.06933509925056569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06933509925056569}
{"step": 490048, "time": 15986.319533109665, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 490048, "time": 15986.718312740326, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 490048, "time": 15986.87407207489, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 490048, "time": 15987.08436703682, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 490048, "time": 15987.289778470993, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 490048, "time": 15987.57083106041, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 490048, "time": 15988.178114652634, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 490048, "time": 15988.35669541359, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 490080, "time": 15989.376944541931, "episode/length": 288.0, "episode/score": 0.06928219724477458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06928219724477458}
{"step": 490280, "time": 15995.465292692184, "episode/length": 288.0, "episode/score": 0.0725518696092422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0725518696092422}
{"step": 490360, "time": 15997.999995946884, "episode/length": 98.0, "episode/score": 0.738682920874453, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.04493289784750232}
{"step": 490440, "time": 16000.502706289291, "episode/length": 78.0, "episode/score": 0.7755574253405939, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.019307378157463972}
{"step": 490552, "time": 16004.033252716064, "episode/length": 288.0, "episode/score": 0.08070972663063003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08070972663063003}
{"step": 490968, "time": 16017.255733013153, "episode/length": 288.0, "episode/score": 0.05945063705337361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05945063705337361}
{"step": 491096, "time": 16021.29345202446, "episode/length": 67.0, "episode/score": 0.8199589094157318, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.029333904619420537}
{"step": 491128, "time": 16022.302545785904, "episode/length": 95.0, "episode/score": 0.7339857485440007, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.030860725202728645}
{"step": 491424, "time": 16031.852266311646, "episode/length": 142.0, "episode/score": 0.596828856592083, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.04057885709266884}
{"step": 491496, "time": 16033.911320924759, "episode/length": 223.0, "episode/score": 0.35597650419686033, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.05285151097223206}
{"step": 491608, "time": 16037.95257282257, "episode/length": 13.0, "episode/score": 0.9660115108067657, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.006636472645823233}
{"step": 492240, "time": 16058.232862710953, "episode/length": 288.0, "episode/score": 0.05669498398401629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05669498398401629}
{"step": 492392, "time": 16062.785894155502, "episode/length": 288.0, "episode/score": 0.042618728699949315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042618728699949315}
{"step": 492752, "time": 16074.488854646683, "episode/length": 288.0, "episode/score": 0.06202784666072603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06202784666072603}
{"step": 493016, "time": 16082.546853542328, "episode/length": 96.0, "episode/score": 0.7352041942559708, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.03520418283562776}
{"step": 493280, "time": 16091.086524486542, "episode/length": 288.0, "episode/score": 0.054438101521213866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054438101521213866}
{"step": 493408, "time": 16095.104347467422, "episode/length": 288.0, "episode/score": 0.050930017725590915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050930017725590915}
{"step": 493440, "time": 16096.110197782516, "episode/length": 288.0, "episode/score": 0.053247956902737315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053247956902737315}
{"step": 493712, "time": 16104.77225780487, "episode/length": 164.0, "episode/score": 0.5374136570649171, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.04991364555144173}
{"step": 493736, "time": 16105.308753967285, "episode/length": 288.0, "episode/score": 0.05955911352975818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05955911352975818}
{"step": 493896, "time": 16110.339517593384, "episode/length": 76.0, "episode/score": 0.7955684036695629, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.033068386195623134}
{"step": 493920, "time": 16111.321048498154, "episode/length": 288.0, "episode/score": 0.04731533188589765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04731533188589765}
