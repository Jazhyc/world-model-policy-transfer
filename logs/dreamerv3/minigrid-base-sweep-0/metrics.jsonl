{"step": 1560, "time": 147.3372461795807, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 1560, "time": 174.42935228347778, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 174.4385073184967, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 174.4465777873993, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 174.45429348945618, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 174.46201372146606, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 174.46914529800415, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 174.47656679153442, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 174.48376941680908, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 302.08444142341614, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.850341796875, "train/action_min": 0.0, "train/action_std": 1.8601139783859253, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0009169771219603717, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.8555368185043335, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.5983694791793823, "train/cont_loss_std": 0.2452629953622818, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.69921875, "train/cont_pos_loss": 0.5983694791793823, "train/cont_pred": 0.5654678344726562, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.964998245239258, "train/dyn_loss_std": 0.3699822723865509, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 10.384238243103027, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 41313.83984375, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5008.126953125, "train/image_loss_std": 39.996585845947266, "train/model_loss_mean": 5020.84521484375, "train/model_loss_std": 39.98176193237305, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50208452.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9359170198440552, "train/policy_entropy_max": 1.9359170198440552, "train/policy_entropy_mean": 1.6487138271331787, "train/policy_entropy_min": 0.6546365022659302, "train/policy_entropy_std": 0.13819408416748047, "train/policy_logprob_mag": 4.567497253417969, "train/policy_logprob_max": -0.1781720668077469, "train/policy_logprob_mean": -1.6611658334732056, "train/policy_logprob_min": -4.567497253417969, "train/policy_logprob_std": 0.7192639112472534, "train/policy_randomness_mag": 0.9948645830154419, "train/policy_randomness_max": 0.9948645830154419, "train/policy_randomness_mean": 0.8472713828086853, "train/policy_randomness_min": 0.336416631937027, "train/policy_randomness_std": 0.07101771980524063, "train/post_ent_mag": 105.60783386230469, "train/post_ent_max": 105.60783386230469, "train/post_ent_mean": 105.30137634277344, "train/post_ent_min": 104.96648406982422, "train/post_ent_std": 0.10761893540620804, "train/prior_ent_mag": 106.45631408691406, "train/prior_ent_max": 106.45631408691406, "train/prior_ent_mean": 105.60394287109375, "train/prior_ent_min": 104.57705688476562, "train/prior_ent_std": 0.26600533723831177, "train/rep_loss_mean": 10.964998245239258, "train/rep_loss_std": 0.3699822723865509, "train/reward_avg": 0.0, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 0.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.6213110685348511, "report/cont_loss_std": 0.26524484157562256, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.6474609375, "report/cont_pos_loss": 0.6213110685348511, "report/cont_pred": 0.5552840232849121, "report/cont_rate": 1.0, "report/dyn_loss_mean": 11.010797500610352, "report/dyn_loss_std": 0.36684730648994446, "report/image_loss_mean": 5011.3955078125, "report/image_loss_std": 42.46232604980469, "report/model_loss_mean": 5024.1650390625, "report/model_loss_std": 42.483062744140625, "report/post_ent_mag": 105.6380844116211, "report/post_ent_max": 105.6380844116211, "report/post_ent_mean": 105.31108856201172, "report/post_ent_min": 104.96525573730469, "report/post_ent_std": 0.10337379574775696, "report/prior_ent_mag": 106.2550048828125, "report/prior_ent_max": 106.2550048828125, "report/prior_ent_mean": 105.55387878417969, "report/prior_ent_min": 104.42024230957031, "report/prior_ent_std": 0.28156691789627075, "report/rep_loss_mean": 11.010797500610352, "report/rep_loss_std": 0.36684730648994446, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.6718654036521912, "eval/cont_loss_std": 0.28410884737968445, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.5703125, "eval/cont_pos_loss": 0.6718654036521912, "eval/cont_pred": 0.5305405855178833, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 11.00700855255127, "eval/dyn_loss_std": 0.36701154708862305, "eval/image_loss_mean": 4997.88427734375, "eval/image_loss_std": 38.34370422363281, "eval/model_loss_mean": 5010.7021484375, "eval/model_loss_std": 38.36151885986328, "eval/post_ent_mag": 105.59358215332031, "eval/post_ent_max": 105.59358215332031, "eval/post_ent_mean": 105.2939453125, "eval/post_ent_min": 104.94235229492188, "eval/post_ent_std": 0.10977568477392197, "eval/prior_ent_mag": 106.41838073730469, "eval/prior_ent_max": 106.41838073730469, "eval/prior_ent_mean": 105.58261108398438, "eval/prior_ent_min": 104.7547607421875, "eval/prior_ent_std": 0.2764264643192291, "eval/rep_loss_mean": 11.00700855255127, "eval/rep_loss_std": 0.36701154708862305, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.8209585516432488e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.514949253627233e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.4896913831987176e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.472881044660295e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 156.86113023757935, "timer/env.step_count": 196.0, "timer/env.step_total": 1.7187867164611816, "timer/env.step_frac": 0.01095737812074881, "timer/env.step_avg": 0.008769319981944804, "timer/env.step_min": 0.007754087448120117, "timer/env.step_max": 0.01656484603881836, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.15433311462402344, "timer/replay._sample_frac": 0.0009838837345508922, "timer/replay._sample_avg": 0.001377974237714495, "timer/replay._sample_min": 0.0003781318664550781, "timer/replay._sample_max": 0.016207218170166016, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.3894846439361572, "timer/agent.save_frac": 0.015233121426047882, "timer/agent.save_avg": 2.3894846439361572, "timer/agent.save_min": 2.3894846439361572, "timer/agent.save_max": 2.3894846439361572, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 24.692988395690918, "timer/agent.policy_frac": 0.1574194216138269, "timer/agent.policy_avg": 0.08514823584721007, "timer/agent.policy_min": 0.010157346725463867, "timer/agent.policy_max": 18.89722442626953, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.361701965332031e-05, "timer/dataset_train_frac": 2.1431070656194123e-07, "timer/dataset_train_avg": 3.361701965332031e-05, "timer/dataset_train_min": 3.361701965332031e-05, "timer/dataset_train_max": 3.361701965332031e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 97.88320565223694, "timer/agent.train_frac": 0.6240118600700161, "timer/agent.train_avg": 97.88320565223694, "timer/agent.train_min": 97.88320565223694, "timer/agent.train_max": 97.88320565223694, "timer/agent.report_count": 2.0, "timer/agent.report_total": 26.997556447982788, "timer/agent.report_frac": 0.17211119419509935, "timer/agent.report_avg": 13.498778223991394, "timer/agent.report_min": 0.24686503410339355, "timer/agent.report_max": 26.750691413879395, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.933906555175781e-05, "timer/dataset_eval_frac": 2.5078912470014397e-07, "timer/dataset_eval_avg": 3.933906555175781e-05, "timer/dataset_eval_min": 3.933906555175781e-05, "timer/dataset_eval_max": 3.933906555175781e-05}
{"step": 2312, "time": 325.3082962036133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 325.3175280094147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 325.32603645324707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 325.33472776412964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 325.34305119514465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 325.35139322280884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 325.36014342308044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 325.3687562942505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2464, "time": 330.3411874771118, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.8520233631134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.86220264434814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.87133860588074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.880252122879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.88949513435364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.89810156822205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 397.9064292907715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4776, "time": 402.55074095726013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6664, "time": 461.3020215034485, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 469.73953199386597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 469.74871587753296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 469.75724959373474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 469.7662479877472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 469.77537751197815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 469.7840552330017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 7088, "time": 474.6954126358032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 8976, "time": 533.9470105171204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 542.3967111110687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 542.4059762954712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 542.4144558906555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 542.4227735996246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 542.4319133758545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 542.4402031898499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9400, "time": 546.9134030342102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 574.7800278663635, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 574.788889169693, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 574.7965941429138, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 574.8045210838318, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 574.8122305870056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 574.8193733692169, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 574.8264286518097, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 574.833731174469, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11288, "time": 612.3206250667572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 620.7472677230835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 620.7558476924896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 620.7637722492218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 620.7717161178589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 620.7798244953156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 620.7879543304443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11712, "time": 625.7390279769897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13600, "time": 684.2735788822174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 692.7042324542999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 692.7135760784149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 692.722324848175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 692.731217622757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 692.740029335022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 692.7483472824097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14024, "time": 697.2216060161591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14032, "time": 697.717000246048, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 764.5001468658447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 764.5102062225342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 764.5180566310883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 764.5259239673615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 764.5342800617218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 764.5422213077545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16336, "time": 769.447380065918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16344, "time": 769.4806087017059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 837.1161613464355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 837.1252126693726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 837.13361120224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 837.1431171894073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 837.1517462730408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 837.1597900390625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18648, "time": 841.6494309902191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18656, "time": 842.1290907859802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 888.4393498897552, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 20072, "time": 893.1039326190948, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 893.111546754837, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 893.119562625885, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 893.1266300678253, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 893.1336946487427, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 893.1406795978546, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 893.1478228569031, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20808, "time": 916.0931632518768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 916.1021785736084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 916.1109125614166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 916.119556427002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 916.1278982162476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 916.137323141098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20960, "time": 921.0716853141785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20968, "time": 921.1038110256195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 987.934323310852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 987.9431636333466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 987.9512872695923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 987.9595701694489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 987.9690501689911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 987.9774885177612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23272, "time": 992.4578347206116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23280, "time": 992.9351246356964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1060.2913672924042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1060.3002531528473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1060.3088438510895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1060.3179183006287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1060.3262119293213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 1060.3345124721527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25584, "time": 1065.232548713684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25592, "time": 1065.2648921012878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1132.2100908756256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1132.2186369895935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1132.2270996570587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1132.2354021072388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1132.2457053661346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1132.2546110153198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27896, "time": 1136.7632114887238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27904, "time": 1137.2543487548828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28832, "time": 1166.1324799060822, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1203.7912149429321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1203.8038258552551, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1203.8140127658844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1203.8409504890442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1203.874798297882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1210.4321219921112, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1210.4402964115143, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1210.4479022026062, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1210.4553520679474, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1210.4629204273224, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1210.4704399108887, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1210.4777445793152, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1210.4852483272552, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30208, "time": 1215.3852696418762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30216, "time": 1215.4165766239166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31144, "time": 1244.1594126224518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31304, "time": 1249.1333315372467, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 32137, "time": 1275.990166425705, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.001668081233639, "train/action_min": 0.0, "train/action_std": 2.0004704797455153, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00017529083559480348, "train/actor_opt_grad_steps": 960.0, "train/actor_opt_loss": -0.5167231668602505, "train/adv_mag": 0.00045825568364397874, "train/adv_max": 0.00045824888570053035, "train/adv_mean": 0.000270111238265604, "train/adv_min": 3.593779732441315e-05, "train/adv_std": 0.0001254921694376601, "train/cont_avg": 0.9968657967931938, "train/cont_loss_mean": 0.024392954407592208, "train/cont_loss_std": 0.3052271314203219, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.77046914630466, "train/cont_pos_acc": 0.9982513791603568, "train/cont_pos_loss": 0.006321924431742793, "train/cont_pred": 0.9945718374551903, "train/cont_rate": 0.9968657967931938, "train/dyn_loss_mean": 1.0708961374472574, "train/dyn_loss_std": 0.004963962949502479, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.4193594723315766, "train/extr_critic_critic_opt_grad_steps": 960.0, "train/extr_critic_critic_opt_loss": 6755.526228500286, "train/extr_critic_mag": 0.00276408457631216, "train/extr_critic_max": 0.0027640770867232876, "train/extr_critic_mean": 0.0027564688732522, "train/extr_critic_min": 0.00274768736974107, "train/extr_critic_std": 1.6233271484869368e-06, "train/extr_return_normed_mag": 0.0007217918701726423, "train/extr_return_normed_max": 0.000721787218732725, "train/extr_return_normed_mean": 0.0005394005380578446, "train/extr_return_normed_min": 0.0003078063544172391, "train/extr_return_normed_std": 0.00012541630374355306, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.003208976869586226, "train/extr_return_raw_max": 0.0032089659409504125, "train/extr_return_raw_mean": 0.003026579409451688, "train/extr_return_raw_min": 0.0027949850763301486, "train/extr_return_raw_std": 0.00012541630370545905, "train/extr_reward_mag": 5.1066513460968176e-05, "train/extr_reward_max": 5.10646410637501e-05, "train/extr_reward_mean": 5.0962715631199676e-05, "train/extr_reward_min": 5.0718247578406206e-05, "train/extr_reward_std": 4.59224990716059e-08, "train/image_loss_mean": 27.436403529650253, "train/image_loss_std": 0.3832460128902141, "train/model_loss_mean": 28.213795421635293, "train/model_loss_std": 0.662364433924253, "train/model_opt_grad_norm": 104.07730827331542, "train/model_opt_grad_steps": 950.0, "train/model_opt_loss": 536.3113660812378, "train/model_opt_model_opt_grad_overflow": 0.005235602094240838, "train/model_opt_model_opt_grad_scale": 14.367228403141361, "train/policy_entropy_mag": 1.9458152374047883, "train/policy_entropy_max": 1.9458152374047883, "train/policy_entropy_mean": 1.9415074324732675, "train/policy_entropy_min": 1.8917738342784463, "train/policy_entropy_std": 0.0027390233136186893, "train/policy_logprob_mag": 2.365297196423196, "train/policy_logprob_max": -1.5388016694503306, "train/policy_logprob_mean": -1.9415542935825767, "train/policy_logprob_min": -2.365297196423196, "train/policy_logprob_std": 0.08233421291980444, "train/policy_randomness_mag": 0.9999512839691801, "train/policy_randomness_max": 0.9999512839691801, "train/policy_randomness_mean": 0.9977375078575773, "train/policy_randomness_min": 0.9721794921066125, "train/policy_randomness_std": 0.0014075796480695303, "train/post_ent_mag": 89.32805242089077, "train/post_ent_max": 89.32805242089077, "train/post_ent_mean": 89.29569212429186, "train/post_ent_min": 88.98602107182847, "train/post_ent_std": 0.05876847399466949, "train/prior_ent_mag": 89.93986199663571, "train/prior_ent_max": 89.93986199663571, "train/prior_ent_mean": 89.86803128706848, "train/prior_ent_min": 89.57700691422868, "train/prior_ent_std": 0.05625640435134553, "train/rep_loss_mean": 1.0708961374472574, "train/rep_loss_std": 0.004963962949502479, "train/reward_avg": 0.0001253777172773618, "train/reward_loss_mean": 0.110457475014343, "train/reward_loss_std": 0.05722723272527112, "train/reward_max_data": 0.11583769867557506, "train/reward_max_pred": 5.1058399739689854e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.10851402887745384, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.949521281502463, "train/reward_pred": 5.0862139963705815e-05, "train/reward_rate": 0.00019428992146596857, "train_stats/mean_log_entropy": 1.9269928303029802, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.0082791056483984, "report/cont_loss_std": 0.18875034153461456, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.045340538024902, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0023777747992426157, "report/cont_pred": 0.9976249933242798, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.29006534814834595, "report/image_loss_std": 0.0896335169672966, "report/model_loss_mean": 0.9095121026039124, "report/model_loss_std": 0.5488298535346985, "report/post_ent_mag": 88.52690887451172, "report/post_ent_max": 88.52690887451172, "report/post_ent_mean": 88.49716186523438, "report/post_ent_min": 88.11933135986328, "report/post_ent_std": 0.06792860478162766, "report/prior_ent_mag": 87.28206634521484, "report/prior_ent_max": 87.28206634521484, "report/prior_ent_mean": 87.26710510253906, "report/prior_ent_min": 87.14157104492188, "report/prior_ent_std": 0.01987428590655327, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00020141601271461695, "report/reward_loss_mean": 0.011167636141180992, "report/reward_loss_std": 0.33952391147613525, "report/reward_max_data": 0.20624999701976776, "report/reward_max_pred": 4.279613494873047e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005523340660147369, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 10.870626449584961, "report/reward_pred": 4.261825233697891e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.00827532634139061, "eval/cont_loss_std": 0.18862859904766083, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.041443347930908, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0023778018075972795, "eval/cont_pred": 0.9976248741149902, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.28239956498146057, "eval/image_loss_std": 0.07816503196954727, "eval/model_loss_mean": 0.9011847972869873, "eval/model_loss_std": 0.5210952162742615, "eval/post_ent_mag": 88.52690124511719, "eval/post_ent_max": 88.52690124511719, "eval/post_ent_mean": 88.49691009521484, "eval/post_ent_min": 88.11912536621094, "eval/post_ent_std": 0.06800723820924759, "eval/prior_ent_mag": 87.28219604492188, "eval/prior_ent_max": 87.28219604492188, "eval/prior_ent_mean": 87.267333984375, "eval/prior_ent_min": 87.14157104492188, "eval/prior_ent_std": 0.019678715616464615, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.000885009765625, "eval/reward_loss_mean": 0.010509910993278027, "eval/reward_loss_std": 0.318486750125885, "eval/reward_max_data": 0.90625, "eval/reward_max_pred": 4.291534423828125e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005523401196114719, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.197108268737793, "eval/reward_pred": 4.261673893779516e-05, "eval/reward_rate": 0.0009765625, "replay/size": 31633.0, "replay/inserts": 30576.0, "replay/samples": 30576.0, "replay/insert_wait_avg": 1.491730216908118e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.165228123567542e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.4189274115820932e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 973.8913898468018, "timer/env.step_count": 3822.0, "timer/env.step_total": 41.21454477310181, "timer/env.step_frac": 0.042319446709129516, "timer/env.step_avg": 0.0107835020337786, "timer/env.step_min": 0.009340286254882812, "timer/env.step_max": 0.05742287635803223, "timer/replay._sample_count": 30576.0, "timer/replay._sample_total": 16.887049436569214, "timer/replay._sample_frac": 0.017339766644025506, "timer/replay._sample_avg": 0.0005522975352096159, "timer/replay._sample_min": 0.0003368854522705078, "timer/replay._sample_max": 0.025780916213989258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4689.0, "timer/agent.policy_total": 54.68350386619568, "timer/agent.policy_frac": 0.05614948898439043, "timer/agent.policy_avg": 0.011662082291788372, "timer/agent.policy_min": 0.010051488876342773, "timer/agent.policy_max": 0.10156536102294922, "timer/dataset_train_count": 1911.0, "timer/dataset_train_total": 0.2318735122680664, "timer/dataset_train_frac": 0.0002380897035187274, "timer/dataset_train_avg": 0.00012133621782735029, "timer/dataset_train_min": 0.00010085105895996094, "timer/dataset_train_max": 0.0010771751403808594, "timer/agent.train_count": 1911.0, "timer/agent.train_total": 861.426155090332, "timer/agent.train_frac": 0.8845197360517161, "timer/agent.train_avg": 0.45077245164329255, "timer/agent.train_min": 0.43924880027770996, "timer/agent.train_max": 0.7209258079528809, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4799313545227051, "timer/agent.report_frac": 0.0004927976153462049, "timer/agent.report_avg": 0.23996567726135254, "timer/agent.report_min": 0.2334918975830078, "timer/agent.report_max": 0.24643945693969727, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.5762786865234375e-05, "timer/dataset_eval_frac": 3.672153510963892e-08, "timer/dataset_eval_avg": 3.5762786865234375e-05, "timer/dataset_eval_min": 3.5762786865234375e-05, "timer/dataset_eval_max": 3.5762786865234375e-05, "fps": 31.395234405611824}
{"step": 32368, "time": 1283.2066667079926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1283.2221598625183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1283.231318950653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1283.2392630577087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1283.2478048801422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32528, "time": 1288.167322397232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33456, "time": 1317.450953245163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33616, "time": 1322.4238603115082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1355.2735657691956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1355.282796382904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1355.2913105487823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1355.3006336688995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1355.3101379871368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34840, "time": 1360.3907217979431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35768, "time": 1389.2541110515594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35928, "time": 1394.1966354846954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1427.5749588012695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1427.5848672389984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1427.5938084125519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1427.6026084423065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1427.613093137741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37152, "time": 1432.5767874717712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38080, "time": 1461.6209650039673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38240, "time": 1466.6361734867096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1500.0566608905792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1500.0654253959656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1500.0731110572815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1500.0808582305908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1500.0886158943176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39464, "time": 1505.0568771362305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 1529.5267703533173, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1529.537118434906, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1529.5452299118042, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1529.5531134605408, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1529.5605947971344, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1529.5680673122406, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1529.575365781784, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1529.5830624103546, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40392, "time": 1540.6143000125885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40552, "time": 1545.5617229938507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40664, "time": 1549.053460597992, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1579.433937072754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1579.4430923461914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1579.450968503952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1579.4590179920197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41776, "time": 1584.4284727573395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42704, "time": 1613.221605539322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42864, "time": 1618.1725525856018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42976, "time": 1621.6174037456512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1651.100334405899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1651.111263036728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1651.1196007728577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1651.1278629302979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44088, "time": 1656.0889055728912, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 44088, "time": 1656.098091840744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45176, "time": 1689.9475677013397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45288, "time": 1693.4277982711792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1723.3596572875977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1723.36962556839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1723.378722190857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1723.3879432678223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46400, "time": 1728.3823189735413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46400, "time": 1728.39235329628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47488, "time": 1762.2529051303864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47600, "time": 1765.736100435257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1795.1872026920319, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1795.1964147090912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1795.204821586609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1795.21262216568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48712, "time": 1800.159110069275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48712, "time": 1800.169400691986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49800, "time": 1834.4650361537933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49912, "time": 1837.9350385665894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 1847.8306379318237, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1847.875850200653, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1847.9189569950104, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1847.959838628769, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1848.0028269290924, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1848.0482428073883, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1848.0915384292603, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1848.126309633255, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50864, "time": 1874.4374496936798, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1874.4680933952332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1874.4897179603577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1874.516521692276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51024, "time": 1879.4905347824097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51024, "time": 1879.5114977359772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52112, "time": 1913.3051874637604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52224, "time": 1916.7524621486664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1945.9777176380157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1945.987649679184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1945.9969935417175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1946.007291316986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53312, "time": 1950.4361984729767, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 53336, "time": 1950.9720711708069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53336, "time": 1950.980830192566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54424, "time": 1984.5955793857574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54536, "time": 1988.0593547821045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 2017.8876445293427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 2017.896868944168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 2017.9059929847717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55624, "time": 2022.014600276947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55648, "time": 2023.0061140060425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55648, "time": 2023.0152261257172, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 56736, "time": 2056.739321947098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56848, "time": 2060.237124681473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2090.12108707428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2090.1299588680267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 2090.1378524303436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57936, "time": 2094.5928914546967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57960, "time": 2095.1158175468445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57960, "time": 2095.128318786621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59048, "time": 2128.8563981056213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59160, "time": 2132.324941635132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 2165.6086921691895, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2165.625345468521, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2165.642467021942, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2165.6592967510223, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2165.676199913025, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2165.693416595459, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2165.707792520523, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2165.7227313518524, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60112, "time": 2169.3355848789215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 2169.345052242279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 2169.3544039726257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60248, "time": 2173.3212563991547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60272, "time": 2174.3116750717163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60272, "time": 2174.320548772812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61360, "time": 2208.0533163547516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61472, "time": 2211.51025390625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2240.744537115097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2240.7534930706024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2240.7632415294647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62560, "time": 2245.200428247452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62584, "time": 2245.723931312561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62584, "time": 2245.7324030399323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63529, "time": 2276.093865633011, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0009024483816966, "train/action_min": 0.0, "train/action_std": 1.9991577620408973, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 9.725077473617881e-05, "train/actor_opt_grad_steps": 2895.0, "train/actor_opt_loss": -1.6488188106224548, "train/adv_mag": 0.00038809896855406006, "train/adv_max": 0.00038809896855406006, "train/adv_mean": 0.00021184843940225581, "train/adv_min": 8.190777722974213e-06, "train/adv_std": 9.901824159896933e-05, "train/cont_avg": 0.99658203125, "train/cont_loss_mean": 0.02289902497135217, "train/cont_loss_std": 0.31769948649153434, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.701587641680682, "train/cont_pos_acc": 0.9999999866193655, "train/cont_pos_loss": 0.003430697644053369, "train/cont_pred": 0.9965755033249758, "train/cont_rate": 0.99658203125, "train/dyn_loss_mean": 1.0000000139888452, "train/dyn_loss_std": 1.7674266222902403e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08599576867204539, "train/extr_critic_critic_opt_grad_steps": 2895.0, "train/extr_critic_critic_opt_loss": 4667.0998335857785, "train/extr_critic_mag": 0.010248791198341213, "train/extr_critic_max": 0.010248791198341213, "train/extr_critic_mean": 0.010223189183529846, "train/extr_critic_min": 0.010189352595076268, "train/extr_critic_std": 7.354974574197086e-06, "train/extr_return_normed_mag": 0.0007367496122130935, "train/extr_return_normed_max": 0.0007367496122130935, "train/extr_return_normed_mean": 0.0005864470332031784, "train/extr_return_normed_min": 0.0003920019205127444, "train/extr_return_normed_std": 9.846820758328398e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.010585343049440001, "train/extr_return_raw_max": 0.010585343049440001, "train/extr_return_raw_mean": 0.010435040895256917, "train/extr_return_raw_min": 0.010240595357739652, "train/extr_return_raw_std": 9.846820806587301e-05, "train/extr_reward_mag": 6.425198243588817e-05, "train/extr_reward_max": 6.425198243588817e-05, "train/extr_reward_mean": 6.415714988736222e-05, "train/extr_reward_min": 6.402451164868414e-05, "train/extr_reward_std": 3.2428096919741384e-08, "train/image_loss_mean": 0.2720228386472683, "train/image_loss_std": 0.08503608966284261, "train/model_loss_mean": 0.8965553011821241, "train/model_loss_std": 0.3600414491695713, "train/model_opt_grad_norm": 81.26744009523975, "train/model_opt_grad_steps": 2885.0, "train/model_opt_loss": 49.40800599662625, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 55.20567602040816, "train/policy_entropy_mag": 1.945883152436237, "train/policy_entropy_max": 1.945883152436237, "train/policy_entropy_mean": 1.944607535187079, "train/policy_entropy_min": 1.9241544592137239, "train/policy_entropy_std": 0.0008591739627133523, "train/policy_logprob_mag": 2.211820586603515, "train/policy_logprob_max": -1.6781840476454521, "train/policy_logprob_mean": -1.9446023009261306, "train/policy_logprob_min": -2.211820586603515, "train/policy_logprob_std": 0.0509235523070912, "train/policy_randomness_mag": 0.999986186319468, "train/policy_randomness_max": 0.999986186319468, "train/policy_randomness_mean": 0.999330648658227, "train/policy_randomness_min": 0.988819846389245, "train/policy_randomness_std": 0.0004415280979758661, "train/post_ent_mag": 86.49452038200535, "train/post_ent_max": 86.49452038200535, "train/post_ent_mean": 86.45948678620007, "train/post_ent_min": 86.05802271317462, "train/post_ent_std": 0.077786119502722, "train/prior_ent_mag": 87.24999984429807, "train/prior_ent_max": 87.24999984429807, "train/prior_ent_mean": 87.23470839675592, "train/prior_ent_min": 87.11157460115393, "train/prior_ent_std": 0.020998122113547762, "train/rep_loss_mean": 1.0000000139888452, "train/rep_loss_std": 1.7674266222902403e-07, "train/reward_avg": 7.716587706640058e-05, "train/reward_loss_mean": 0.0016334062318640705, "train/reward_loss_std": 0.03951008243625067, "train/reward_max_data": 0.07181122534129085, "train/reward_max_pred": 6.429820644612215e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00040426476349536214, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.255086595361883, "train/reward_pred": 6.415198939586324e-05, "train/reward_rate": 0.00011957908163265306, "train_stats/mean_log_entropy": 1.936780829514776, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.0025741788558661938, "report/cont_loss_std": 2.3283064365386963e-10, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0025741788558661938, "report/cont_pred": 0.9974289536476135, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2703862190246582, "report/image_loss_std": 0.07972978800535202, "report/model_loss_mean": 0.8732315301895142, "report/model_loss_std": 0.07972978055477142, "report/post_ent_mag": 84.71623229980469, "report/post_ent_max": 84.71623229980469, "report/post_ent_mean": 84.68388366699219, "report/post_ent_min": 84.27348327636719, "report/post_ent_std": 0.0728626400232315, "report/prior_ent_mag": 87.16702270507812, "report/prior_ent_max": 87.16702270507812, "report/prior_ent_mean": 87.15284729003906, "report/prior_ent_min": 87.0184555053711, "report/prior_ent_std": 0.02085760235786438, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00027111172676086426, "report/reward_loss_std": 4.4554221290127316e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 8.45193862915039e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00027111172676086426, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 8.449913002550602e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0025741788558661938, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0025741788558661938, "eval/cont_pred": 0.9974289536476135, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2762361168861389, "eval/image_loss_std": 0.07130585610866547, "eval/model_loss_mean": 0.8790814876556396, "eval/model_loss_std": 0.07130585610866547, "eval/post_ent_mag": 84.71439361572266, "eval/post_ent_max": 84.71439361572266, "eval/post_ent_mean": 84.68350219726562, "eval/post_ent_min": 84.27271270751953, "eval/post_ent_std": 0.07294555753469467, "eval/prior_ent_mag": 87.16796112060547, "eval/prior_ent_max": 87.16796112060547, "eval/prior_ent_mean": 87.15323638916016, "eval/prior_ent_min": 87.0184555053711, "eval/prior_ent_std": 0.020749086514115334, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0002711368724703789, "eval/reward_loss_std": 4.005065932233265e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 8.45193862915039e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0002711368724703789, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.450471796095371e-05, "eval/reward_rate": 0.0, "replay/size": 63025.0, "replay/inserts": 31392.0, "replay/samples": 31392.0, "replay/insert_wait_avg": 1.4980603674014653e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.931032919616388e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3597008816236168e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0909917354584, "timer/env.step_count": 3924.0, "timer/env.step_total": 41.874908208847046, "timer/env.step_frac": 0.04187109828494855, "timer/env.step_avg": 0.010671485272387116, "timer/env.step_min": 0.009254217147827148, "timer/env.step_max": 0.03692626953125, "timer/replay._sample_count": 31392.0, "timer/replay._sample_total": 17.439398527145386, "timer/replay._sample_frac": 0.017437811830384342, "timer/replay._sample_avg": 0.0005555363954875569, "timer/replay._sample_min": 0.0003657341003417969, "timer/replay._sample_max": 0.01085209846496582, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4791.0, "timer/agent.policy_total": 55.82328271865845, "timer/agent.policy_frac": 0.055818203723431485, "timer/agent.policy_avg": 0.011651697499198173, "timer/agent.policy_min": 0.009768486022949219, "timer/agent.policy_max": 0.09964466094970703, "timer/dataset_train_count": 1962.0, "timer/dataset_train_total": 0.22912907600402832, "timer/dataset_train_frac": 0.00022910822904865938, "timer/dataset_train_avg": 0.00011678342303976978, "timer/dataset_train_min": 0.00010132789611816406, "timer/dataset_train_max": 0.000469207763671875, "timer/agent.train_count": 1962.0, "timer/agent.train_total": 885.4799425601959, "timer/agent.train_frac": 0.8853993785341693, "timer/agent.train_avg": 0.4513149554333313, "timer/agent.train_min": 0.4387502670288086, "timer/agent.train_max": 0.8911898136138916, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4808022975921631, "timer/agent.report_frac": 0.00048075855253713125, "timer/agent.report_avg": 0.24040114879608154, "timer/agent.report_min": 0.23321056365966797, "timer/agent.report_max": 0.24759173393249512, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.528594970703125e-05, "timer/dataset_eval_frac": 3.5282739269353405e-08, "timer/dataset_eval_avg": 3.528594970703125e-05, "timer/dataset_eval_min": 3.528594970703125e-05, "timer/dataset_eval_max": 3.528594970703125e-05, "fps": 31.388652374193207}
{"step": 63672, "time": 2280.415673494339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63784, "time": 2283.882481813431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2313.7068598270416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2313.716572523117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64736, "time": 2313.7254173755646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64872, "time": 2317.7170448303223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64896, "time": 2318.8261427879333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64896, "time": 2318.8348593711853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65984, "time": 2353.2056810855865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66096, "time": 2356.690392971039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 2386.017553329468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 2386.0275139808655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 2386.0361018180847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67184, "time": 2390.4812140464783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67208, "time": 2391.0058917999268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67208, "time": 2391.0232393741608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67288, "time": 2393.4954555034637, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 67704, "time": 2406.39590549469, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 68296, "time": 2424.77631688118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68408, "time": 2428.263044834137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69360, "time": 2458.0732979774475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69360, "time": 2458.0828261375427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69496, "time": 2462.075483560562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69520, "time": 2463.0490567684174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69600, "time": 2465.5382533073425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70016, "time": 2478.4621999263763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 2487.355947494507, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2487.3638212680817, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2487.371474504471, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2487.3786873817444, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2487.3861112594604, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2487.39351272583, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2487.4221336841583, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2487.453830718994, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70608, "time": 2503.304861307144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70720, "time": 2506.7701938152313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71672, "time": 2535.969656229019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71672, "time": 2535.980237007141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71808, "time": 2540.423110485077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71832, "time": 2540.959447622299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71912, "time": 2543.4488682746887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72328, "time": 2556.311599254608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72920, "time": 2574.669358253479, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73032, "time": 2578.139088869095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73984, "time": 2608.654586315155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73984, "time": 2608.6639416217804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74120, "time": 2612.644415140152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74144, "time": 2613.6133918762207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74224, "time": 2616.1000316143036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74640, "time": 2629.0651893615723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75232, "time": 2647.3580145835876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75344, "time": 2650.9218904972076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76296, "time": 2680.2379381656647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76296, "time": 2680.247363805771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76432, "time": 2684.701896905899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76456, "time": 2685.2276706695557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76536, "time": 2687.7195813655853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76952, "time": 2700.6509318351746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77544, "time": 2719.100985765457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77656, "time": 2722.5699937343597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78608, "time": 2752.4008660316467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78608, "time": 2752.4156455993652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78744, "time": 2756.4289412498474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78768, "time": 2757.408102989197, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78848, "time": 2759.9146218299866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79264, "time": 2772.8585534095764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79856, "time": 2791.1844849586487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79968, "time": 2794.6674625873566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 2804.658088207245, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2804.6660170555115, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2804.674697637558, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2804.682137489319, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2804.689302921295, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2804.6997747421265, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2804.7074246406555, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2804.714735031128, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80920, "time": 2830.541310071945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80920, "time": 2830.550586938858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81056, "time": 2835.0004663467407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81080, "time": 2835.550550222397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81128, "time": 2837.0461723804474, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 81160, "time": 2838.04412150383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81576, "time": 2850.908415079117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82280, "time": 2873.278397321701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83232, "time": 2903.068296432495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83232, "time": 2903.105896949768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83368, "time": 2907.1285672187805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83392, "time": 2908.1238515377045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83440, "time": 2909.652466058731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83472, "time": 2910.6776719093323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83888, "time": 2923.8870918750763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84592, "time": 2946.021755218506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85544, "time": 2975.8154327869415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85544, "time": 2975.827611207962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85680, "time": 2980.4513115882874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85704, "time": 2980.979090690613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85752, "time": 2982.490314245224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85784, "time": 2983.4819147586823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86200, "time": 2997.014744758606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86488, "time": 3005.953558921814, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 86904, "time": 3018.979056596756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87856, "time": 3048.9080064296722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87856, "time": 3049.0296161174774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87992, "time": 3053.0288450717926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88064, "time": 3055.4995670318604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88096, "time": 3056.5005555152893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88512, "time": 3069.565520763397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88800, "time": 3078.4954748153687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89216, "time": 3091.4212889671326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 3123.2514836788177, "eval_episode/length": 236.0, "eval_episode/score": 0.26249998807907104, "eval_episode/reward_rate": 0.004219409282700422}
{"step": 90064, "time": 3125.0629546642303, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3125.071867465973, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3125.0797452926636, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3125.086942911148, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3125.0952532291412, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3125.1028921604156, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3125.1107211112976, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90168, "time": 3128.8314678668976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90168, "time": 3128.8404898643494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90304, "time": 3133.291493177414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90376, "time": 3135.336202144623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90408, "time": 3136.3370232582092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90824, "time": 3149.2344510555267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91112, "time": 3158.1421959400177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91528, "time": 3171.166873693466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92480, "time": 3200.918927669525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92480, "time": 3200.9304749965668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92616, "time": 3204.9259803295135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92688, "time": 3207.38570356369, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92720, "time": 3208.378565788269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93072, "time": 3219.3777010440826, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 93136, "time": 3221.3568303585052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93840, "time": 3243.0846798419952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94792, "time": 3272.328603744507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94792, "time": 3272.3486971855164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94889, "time": 3276.3203349113464, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.000480184749681, "train/action_min": 0.0, "train/action_std": 2.000113004932598, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.4408990777123924e-05, "train/actor_opt_grad_steps": 4855.0, "train/actor_opt_loss": -3.914204349171142, "train/adv_mag": 0.0002220581684793745, "train/adv_max": 0.00021607502439648522, "train/adv_mean": 9.32571840879792e-05, "train/adv_min": -4.2891438708317524e-05, "train/adv_std": 5.200492402963744e-05, "train/cont_avg": 0.9966567681760204, "train/cont_loss_mean": 0.02243804624803098, "train/cont_loss_std": 0.31302910649186044, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.667738309178327, "train/cont_pos_acc": 0.9999999872275761, "train/cont_pos_loss": 0.003522343907448254, "train/cont_pred": 0.9964840314826187, "train/cont_rate": 0.9966567681760204, "train/dyn_loss_mean": 1.000000045007589, "train/dyn_loss_std": 1.2191302797576527e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02476233640704684, "train/extr_critic_critic_opt_grad_steps": 4855.0, "train/extr_critic_critic_opt_loss": 6505.594771404656, "train/extr_critic_mag": 0.016501920563834056, "train/extr_critic_max": 0.016501920563834056, "train/extr_critic_mean": 0.01646183406439971, "train/extr_critic_min": 0.016416216383174975, "train/extr_critic_std": 1.335190109977461e-05, "train/extr_return_normed_mag": 0.0003674224076070348, "train/extr_return_normed_max": 0.00036417591689648674, "train/extr_return_normed_mean": 0.0002806725715867269, "train/extr_return_normed_min": 0.0001750347413578812, "train/extr_return_normed_std": 4.8251252768035814e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.016638590768929953, "train/extr_return_raw_max": 0.016638590768929953, "train/extr_return_raw_mean": 0.01655508825859549, "train/extr_return_raw_min": 0.016449449593391344, "train/extr_return_raw_std": 4.8251253116346767e-05, "train/extr_reward_mag": 6.421974727085658e-05, "train/extr_reward_max": 6.421974727085658e-05, "train/extr_reward_mean": 6.416170625164583e-05, "train/extr_reward_min": 6.407499313354492e-05, "train/extr_reward_std": 2.84549055961749e-08, "train/image_loss_mean": 0.2607796731956151, "train/image_loss_std": 0.08399076883358006, "train/model_loss_mean": 0.8845953190205048, "train/model_loss_std": 0.3523136018490305, "train/model_opt_grad_norm": 65.25918119780872, "train/model_opt_grad_steps": 4845.0, "train/model_opt_loss": 191.03213886338838, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 216.03954081632654, "train/policy_entropy_mag": 1.9458915244559853, "train/policy_entropy_max": 1.9458915244559853, "train/policy_entropy_mean": 1.9450104577200753, "train/policy_entropy_min": 1.929083443417841, "train/policy_entropy_std": 0.0006126295044609555, "train/policy_logprob_mag": 2.1903976725072276, "train/policy_logprob_max": -1.7137546600127707, "train/policy_logprob_mean": -1.9450238699815712, "train/policy_logprob_min": -2.1903976725072276, "train/policy_logprob_std": 0.04237509570179545, "train/policy_randomness_mag": 0.9999904884975783, "train/policy_randomness_max": 0.9999904884975783, "train/policy_randomness_mean": 0.9995377048545954, "train/policy_randomness_min": 0.9913528436908916, "train/policy_randomness_std": 0.0003148292923971003, "train/post_ent_mag": 82.95019651918994, "train/post_ent_max": 82.95019651918994, "train/post_ent_mean": 82.91450683438048, "train/post_ent_min": 82.51197526892837, "train/post_ent_std": 0.07848506219380973, "train/prior_ent_mag": 86.80917724297971, "train/prior_ent_max": 86.80917724297971, "train/prior_ent_mean": 86.79092469507334, "train/prior_ent_min": 86.61936405726841, "train/prior_ent_std": 0.029665871143189013, "train/rep_loss_mean": 1.000000045007589, "train/rep_loss_std": 1.2191302797576527e-06, "train/reward_avg": 7.314876659490568e-05, "train/reward_loss_mean": 0.0013775507971758442, "train/reward_loss_std": 0.037205707944442924, "train/reward_max_data": 0.07439413309401395, "train/reward_max_pred": 6.428908328620755e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00028829528235626043, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.41087904430571, "train/reward_pred": 6.420146056203818e-05, "train/reward_rate": 0.00010463169642857142, "train_stats/mean_log_entropy": 1.9362516467635695, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02561333402991295, "report/cont_loss_std": 0.33552441000938416, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.383508682250977, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004601977299898863, "report/cont_pred": 0.9954084157943726, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2554810047149658, "report/image_loss_std": 0.09132413566112518, "report/model_loss_mean": 0.8812146186828613, "report/model_loss_std": 0.34922921657562256, "report/post_ent_mag": 81.72212219238281, "report/post_ent_max": 81.72212219238281, "report/post_ent_mean": 81.68537139892578, "report/post_ent_min": 81.283203125, "report/post_ent_std": 0.07981281727552414, "report/prior_ent_mag": 86.03157043457031, "report/prior_ent_max": 86.03157043457031, "report/prior_ent_mean": 86.0064468383789, "report/prior_ent_min": 85.7738037109375, "report/prior_ent_std": 0.041110917925834656, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0001202709972858429, "report/reward_loss_std": 1.9960744168656674e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 4.5299530029296875e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0001202709972858429, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.5115710236132145e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009854678995907307, "eval/cont_loss_std": 0.1680087000131607, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.383508682250977, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0046018376015126705, "eval/cont_pred": 0.9954085350036621, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2818017899990082, "eval/image_loss_std": 0.09336791932582855, "eval/model_loss_mean": 0.9021713137626648, "eval/model_loss_std": 0.5166828632354736, "eval/post_ent_mag": 81.72163391113281, "eval/post_ent_max": 81.72163391113281, "eval/post_ent_mean": 81.68928527832031, "eval/post_ent_min": 81.28262329101562, "eval/post_ent_std": 0.07433731853961945, "eval/prior_ent_mag": 86.02875518798828, "eval/prior_ent_max": 86.02875518798828, "eval/prior_ent_mean": 86.0082778930664, "eval/prior_ent_min": 85.7738037109375, "eval/prior_ent_std": 0.03813556954264641, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.000885009765625, "eval/reward_loss_mean": 0.010514842346310616, "eval/reward_loss_std": 0.3324638307094574, "eval/reward_max_data": 0.90625, "eval/reward_max_pred": 4.5299530029296875e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00012027016782667488, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.644163131713867, "eval/reward_pred": 4.511512815952301e-05, "eval/reward_rate": 0.0009765625, "replay/size": 94385.0, "replay/inserts": 31360.0, "replay/samples": 31360.0, "replay/insert_wait_avg": 1.493408059587284e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.020093854592771e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3531010593647501e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2083349227905, "timer/env.step_count": 3920.0, "timer/env.step_total": 41.61602234840393, "timer/env.step_frac": 0.041607354083503426, "timer/env.step_avg": 0.010616332231735696, "timer/env.step_min": 0.009066581726074219, "timer/env.step_max": 0.07131338119506836, "timer/replay._sample_count": 31360.0, "timer/replay._sample_total": 17.605926036834717, "timer/replay._sample_frac": 0.017602258871591763, "timer/replay._sample_avg": 0.0005614134578072295, "timer/replay._sample_min": 0.0003733634948730469, "timer/replay._sample_max": 0.028405427932739258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4787.0, "timer/agent.policy_total": 56.14417576789856, "timer/agent.policy_frac": 0.05613248141171761, "timer/agent.policy_avg": 0.011728467885502102, "timer/agent.policy_min": 0.009367942810058594, "timer/agent.policy_max": 0.10185790061950684, "timer/dataset_train_count": 1960.0, "timer/dataset_train_total": 0.23900151252746582, "timer/dataset_train_frac": 0.0002389517305371337, "timer/dataset_train_avg": 0.00012193954720789072, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.00038886070251464844, "timer/agent.train_count": 1960.0, "timer/agent.train_total": 885.6929235458374, "timer/agent.train_frac": 0.8855084412131069, "timer/agent.train_avg": 0.45188414466624355, "timer/agent.train_min": 0.4394364356994629, "timer/agent.train_max": 1.0174918174743652, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4824190139770508, "timer/agent.report_frac": 0.0004823185301833046, "timer/agent.report_avg": 0.2412095069885254, "timer/agent.report_min": 0.23290395736694336, "timer/agent.report_max": 0.24951505661010742, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.62396240234375e-05, "timer/dataset_eval_frac": 3.623207561676134e-08, "timer/dataset_eval_avg": 3.62396240234375e-05, "timer/dataset_eval_min": 3.62396240234375e-05, "timer/dataset_eval_max": 3.62396240234375e-05, "fps": 31.35294538844928}
{"step": 94928, "time": 3277.572801589966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95000, "time": 3279.727625608444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95032, "time": 3280.7120883464813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95384, "time": 3291.5395662784576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95448, "time": 3293.524087667465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96152, "time": 3315.4926342964172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97104, "time": 3345.3745443820953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97104, "time": 3345.383755683899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97240, "time": 3349.3781695365906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97312, "time": 3351.8305819034576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97344, "time": 3352.8372054100037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97696, "time": 3363.793176174164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97760, "time": 3365.798852443695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98464, "time": 3388.354196548462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99416, "time": 3417.877113342285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99416, "time": 3417.887273311615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99552, "time": 3422.359147787094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99624, "time": 3424.377516269684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99656, "time": 3425.4014279842377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100008, "time": 3436.4097242355347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 3438.5496468544006, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 100048, "time": 3444.194219350815, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3444.202540397644, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3444.2102251052856, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3444.2176716327667, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3444.2249627113342, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3444.232362508774, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3444.240508079529, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100072, "time": 3444.7672443389893, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100776, "time": 3466.723187685013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101728, "time": 3496.580816268921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101728, "time": 3496.590080499649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101864, "time": 3500.5954928398132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101936, "time": 3503.060163974762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101968, "time": 3504.0464589595795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102320, "time": 3514.898283481598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102384, "time": 3516.8939549922943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103088, "time": 3538.735045194626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104040, "time": 3567.988899707794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104040, "time": 3567.997743844986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104176, "time": 3572.4504086971283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104248, "time": 3574.452283143997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104280, "time": 3575.467427253723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104632, "time": 3586.4463980197906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104696, "time": 3588.427092552185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105400, "time": 3610.3654260635376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106352, "time": 3640.145363330841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106352, "time": 3640.1564383506775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106488, "time": 3644.1185173988342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106560, "time": 3647.1570250988007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106592, "time": 3648.147196292877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106944, "time": 3659.066797733307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107008, "time": 3661.072112560272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107712, "time": 3682.9848754405975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108664, "time": 3712.2973215579987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108664, "time": 3712.3063683509827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108800, "time": 3716.757485151291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108872, "time": 3718.769467830658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108904, "time": 3719.7672448158264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109256, "time": 3730.790831565857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109320, "time": 3732.764457464218, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110024, "time": 3754.612784385681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 3756.151090145111, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 110032, "time": 3760.527238845825, "eval_episode/length": 238.0, "eval_episode/score": 0.2562499940395355, "eval_episode/reward_rate": 0.0041841004184100415}
{"step": 110032, "time": 3761.01530790329, "eval_episode/length": 260.0, "eval_episode/score": 0.1875, "eval_episode/reward_rate": 0.0038314176245210726}
{"step": 110032, "time": 3761.6316742897034, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3761.639402627945, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3761.64728140831, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3761.654813528061, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3761.661984205246, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110976, "time": 3790.8764202594757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110976, "time": 3790.88538146019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111112, "time": 3794.8941926956177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111184, "time": 3797.361361503601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111216, "time": 3798.3609035015106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111568, "time": 3809.2923817634583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111632, "time": 3811.318873167038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111736, "time": 3814.292435646057, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 112336, "time": 3833.129179239273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112616, "time": 3841.591493844986, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 113288, "time": 3862.6682245731354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113424, "time": 3867.1337254047394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113528, "time": 3870.119802713394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113880, "time": 3881.159742832184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113944, "time": 3883.12366271019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114048, "time": 3886.58638215065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114096, "time": 3888.065354347229, "episode/length": 5.0, "episode/score": 0.984375, "episode/reward_rate": 0.16666666666666666, "episode/intrinsic_return": 0.0}
{"step": 114648, "time": 3904.8963828086853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114928, "time": 3914.42999124527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115256, "time": 3924.3601286411285, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 115736, "time": 3939.2752113342285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115840, "time": 3942.7312290668488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116192, "time": 3953.576141834259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116256, "time": 3955.55802154541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116408, "time": 3960.0423634052277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116960, "time": 3977.389290332794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117240, "time": 3985.8050560951233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117568, "time": 3996.1029102802277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118048, "time": 4010.9790921211243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118152, "time": 4013.944126367569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118504, "time": 4024.7807006835938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118568, "time": 4026.7747387886047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118720, "time": 4031.7701489925385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119272, "time": 4048.496270418167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119552, "time": 4057.325113773346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119880, "time": 4067.249205827713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 4077.8490858078003, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4077.8571610450745, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4077.867261171341, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4077.876686811447, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4077.885237932205, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4077.8929510116577, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4077.900957107544, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4077.9115583896637, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120360, "time": 4088.2682452201843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120464, "time": 4091.7821810245514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120816, "time": 4102.624428272247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120880, "time": 4104.58352971077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121032, "time": 4109.052626609802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121584, "time": 4126.364591360092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121864, "time": 4134.750537633896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122192, "time": 4145.10249042511, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122584, "time": 4157.075755596161, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 122776, "time": 4162.993649721146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123128, "time": 4174.302136182785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123192, "time": 4176.288561105728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123344, "time": 4181.292216062546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123896, "time": 4198.094259977341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124176, "time": 4206.953149318695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124504, "time": 4216.966291189194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124896, "time": 4229.335209608078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125088, "time": 4235.362742424011, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125440, "time": 4246.413190126419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125504, "time": 4248.392427921295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125656, "time": 4252.916606664658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126208, "time": 4270.416079998016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126377, "time": 4276.42566204071, "train_stats/mean_log_entropy": 1.9354797112090247, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9990572082209708, "train/action_min": 0.0, "train/action_std": 2.000319040366236, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 3.7287227884829514e-05, "train/actor_opt_grad_steps": 6820.0, "train/actor_opt_loss": -4.770530456175962, "train/adv_mag": 0.00019829707967145794, "train/adv_max": 0.00016340914981316794, "train/adv_mean": 4.836657929036629e-05, "train/adv_min": -7.407215948637367e-05, "train/adv_std": 4.5273239119948816e-05, "train/cont_avg": 0.9964457090736041, "train/cont_loss_mean": 0.023643213090236266, "train/cont_loss_std": 0.32562843215566717, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.662218639887676, "train/cont_pos_acc": 0.9999999851744792, "train/cont_pos_loss": 0.003529417622824989, "train/cont_pred": 0.9964769470510144, "train/cont_rate": 0.9964457090736041, "train/dyn_loss_mean": 1.0000000030256164, "train/dyn_loss_std": 1.1248455036001346e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.01255236206656596, "train/extr_critic_critic_opt_grad_steps": 6820.0, "train/extr_critic_critic_opt_loss": 7022.606591549016, "train/extr_critic_mag": 0.01855840174679829, "train/extr_critic_max": 0.01855840174679829, "train/extr_critic_mean": 0.01850974904893316, "train/extr_critic_min": 0.018465519556539314, "train/extr_critic_std": 1.297011038639142e-05, "train/extr_return_normed_mag": 0.0002860989005583797, "train/extr_return_normed_max": 0.0002457718388532019, "train/extr_return_normed_mean": 0.00016675902403339425, "train/extr_return_normed_min": 7.688432818439407e-05, "train/extr_return_normed_std": 4.167856060228894e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0186371199956854, "train/extr_return_raw_max": 0.0186371199956854, "train/extr_return_raw_mean": 0.018558108224178933, "train/extr_return_raw_min": 0.01846823248501659, "train/extr_return_raw_std": 4.16785603942478e-05, "train/extr_reward_mag": 6.328076880595406e-05, "train/extr_reward_max": 6.328076880595406e-05, "train/extr_reward_mean": 6.323734480136566e-05, "train/extr_reward_min": 6.318092346191406e-05, "train/extr_reward_std": 2.0293380000677054e-08, "train/image_loss_mean": 0.25589633245153476, "train/image_loss_std": 0.08462946718265563, "train/model_loss_mean": 0.8807620109640403, "train/model_loss_std": 0.36273084751089213, "train/model_opt_grad_norm": 55.223346990982286, "train/model_opt_grad_steps": 6810.0, "train/model_opt_loss": 745.9124980481143, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 847.0812182741116, "train/policy_entropy_mag": 1.945895610121906, "train/policy_entropy_max": 1.945895610121906, "train/policy_entropy_mean": 1.9452026404705145, "train/policy_entropy_min": 1.933080301672069, "train/policy_entropy_std": 0.0004790349042652941, "train/policy_logprob_mag": 2.1472694958527074, "train/policy_logprob_max": -1.7386441793538592, "train/policy_logprob_mean": -1.9451710379063176, "train/policy_logprob_min": -2.1472694958527074, "train/policy_logprob_std": 0.03758822493066037, "train/policy_randomness_mag": 0.9999925872396092, "train/policy_randomness_max": 0.9999925872396092, "train/policy_randomness_mean": 0.9996364670356518, "train/policy_randomness_min": 0.9934068204182659, "train/policy_randomness_std": 0.00024617526263322415, "train/post_ent_mag": 80.0790049364119, "train/post_ent_max": 80.0790049364119, "train/post_ent_mean": 80.04127374639366, "train/post_ent_min": 79.61961883699833, "train/post_ent_std": 0.08276430290513838, "train/prior_ent_mag": 85.59205883045487, "train/prior_ent_max": 85.59205883045487, "train/prior_ent_mean": 85.56825449987112, "train/prior_ent_min": 85.32230477889782, "train/prior_ent_std": 0.04307732509855691, "train/rep_loss_mean": 1.0000000030256164, "train/rep_loss_std": 1.1248455036001346e-07, "train/reward_avg": 6.044649272013058e-05, "train/reward_loss_mean": 0.0012224442467358208, "train/reward_loss_std": 0.033485871788958795, "train/reward_max_data": 0.06138959421119109, "train/reward_max_pred": 6.332494280665055e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0002485485631484434, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.340598859285054, "train/reward_pred": 6.323739375711092e-05, "train/reward_rate": 9.4186230964467e-05, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020052321255207062, "report/cont_loss_std": 0.30654922127723694, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.675311088562012, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003435499034821987, "report/cont_pred": 0.9965705275535583, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2363901436328888, "report/image_loss_std": 0.09053081274032593, "report/model_loss_mean": 0.8565629720687866, "report/model_loss_std": 0.32141605019569397, "report/post_ent_mag": 79.8707275390625, "report/post_ent_max": 79.8707275390625, "report/post_ent_mean": 79.82823181152344, "report/post_ent_min": 79.33867645263672, "report/post_ent_std": 0.09489410370588303, "report/prior_ent_mag": 85.14884948730469, "report/prior_ent_max": 85.14884948730469, "report/prior_ent_mean": 85.12136840820312, "report/prior_ent_min": 84.85240936279297, "report/prior_ent_std": 0.04703405871987343, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00012047030031681061, "report/reward_loss_std": 7.012432092778909e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 4.506111145019531e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00012047030031681061, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.47611091658473e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003435499034821987, "eval/cont_loss_std": 6.984919309616089e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003435499034821987, "eval/cont_pred": 0.9965705275535583, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.27036935091018677, "eval/image_loss_std": 0.09160109609365463, "eval/model_loss_mean": 0.8739253282546997, "eval/model_loss_std": 0.09160108119249344, "eval/post_ent_mag": 79.87203979492188, "eval/post_ent_max": 79.87203979492188, "eval/post_ent_mean": 79.83312225341797, "eval/post_ent_min": 79.33790588378906, "eval/post_ent_std": 0.08793333917856216, "eval/prior_ent_mag": 85.14682006835938, "eval/prior_ent_max": 85.14682006835938, "eval/prior_ent_mean": 85.12389373779297, "eval/prior_ent_min": 84.85240936279297, "eval/prior_ent_std": 0.043646641075611115, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00012048520147800446, "eval/reward_loss_std": 7.146904295041168e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 4.506111145019531e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00012048520147800446, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.476390313357115e-05, "eval/reward_rate": 0.0, "replay/size": 125873.0, "replay/inserts": 31488.0, "replay/samples": 31488.0, "replay/insert_wait_avg": 1.4863984008145526e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.183448174135472e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3984060892459292e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0867202281952, "timer/env.step_count": 3936.0, "timer/env.step_total": 41.21366333961487, "timer/env.step_frac": 0.041210089591241575, "timer/env.step_avg": 0.01047095105173142, "timer/env.step_min": 0.00879359245300293, "timer/env.step_max": 0.04928874969482422, "timer/replay._sample_count": 31488.0, "timer/replay._sample_total": 17.697362661361694, "timer/replay._sample_frac": 0.017695828075112916, "timer/replay._sample_avg": 0.0005620351454954807, "timer/replay._sample_min": 0.0003783702850341797, "timer/replay._sample_max": 0.02837061882019043, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4803.0, "timer/agent.policy_total": 55.59567642211914, "timer/agent.policy_frac": 0.055590855570438504, "timer/agent.policy_avg": 0.011575198089135777, "timer/agent.policy_min": 0.010045766830444336, "timer/agent.policy_max": 0.08671736717224121, "timer/dataset_train_count": 1968.0, "timer/dataset_train_total": 0.25524139404296875, "timer/dataset_train_frac": 0.0002552192613703829, "timer/dataset_train_avg": 0.00012969583030638656, "timer/dataset_train_min": 0.0001010894775390625, "timer/dataset_train_max": 0.02324390411376953, "timer/agent.train_count": 1968.0, "timer/agent.train_total": 887.1682529449463, "timer/agent.train_frac": 0.8870913241828832, "timer/agent.train_avg": 0.4507968764964158, "timer/agent.train_min": 0.4390730857849121, "timer/agent.train_max": 0.7566699981689453, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48608970642089844, "timer/agent.report_frac": 0.00048604755626590533, "timer/agent.report_avg": 0.24304485321044922, "timer/agent.report_min": 0.23676657676696777, "timer/agent.report_max": 0.24932312965393066, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.6253204345703125e-05, "timer/dataset_eval_frac": 4.624919360507985e-08, "timer/dataset_eval_avg": 4.6253204345703125e-05, "timer/dataset_eval_min": 4.6253204345703125e-05, "timer/dataset_eval_max": 4.6253204345703125e-05, "fps": 31.484694609403412}
{"step": 126488, "time": 4279.753379821777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126816, "time": 4290.14279127121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127208, "time": 4302.190540790558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127400, "time": 4308.154010057449, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127752, "time": 4319.052782058716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127816, "time": 4321.074057102203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127968, "time": 4326.001527786255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128520, "time": 4343.112187385559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128800, "time": 4352.0512137413025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129128, "time": 4362.145530223846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129520, "time": 4374.521346330643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129712, "time": 4380.502144575119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 4396.671297073364, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4396.680463314056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4396.690688371658, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4396.69911813736, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4396.7084004879, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4396.718547344208, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4396.731616258621, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4396.743948221207, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130064, "time": 4398.763841867447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130128, "time": 4400.764481306076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130280, "time": 4405.231229543686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130832, "time": 4422.745686531067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131112, "time": 4431.753804683685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131440, "time": 4442.127234458923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131832, "time": 4454.175724744797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132024, "time": 4460.0558042526245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132376, "time": 4470.938555717468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132440, "time": 4472.928143978119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132592, "time": 4477.859972715378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133144, "time": 4494.833906173706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133424, "time": 4503.786194801331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133752, "time": 4513.840116739273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134144, "time": 4526.162226438522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134336, "time": 4532.125599145889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134688, "time": 4543.162281751633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134752, "time": 4545.153683662415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134904, "time": 4549.63308596611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135456, "time": 4566.868275165558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135736, "time": 4575.387814044952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136064, "time": 4585.72766661644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136456, "time": 4597.605735778809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136648, "time": 4603.638723611832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137000, "time": 4614.482445478439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137064, "time": 4616.453412294388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137216, "time": 4621.356413125992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137768, "time": 4638.27569103241, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138048, "time": 4647.145757198334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138376, "time": 4657.0554938316345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138768, "time": 4669.5126123428345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138960, "time": 4675.455878019333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139312, "time": 4686.930550813675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139376, "time": 4689.021250486374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139528, "time": 4693.49650478363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140080, "time": 4710.760032892227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 4715.41277885437, "eval_episode/length": 180.0, "eval_episode/score": 0.4375, "eval_episode/reward_rate": 0.0055248618784530384}
{"step": 140088, "time": 4717.721625089645, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4717.731096506119, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4717.739397525787, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4717.74750328064, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4717.755623340607, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4717.764779806137, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4717.772813081741, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140360, "time": 4726.294278860092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140688, "time": 4736.705882072449, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141080, "time": 4748.714797973633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141272, "time": 4754.652755737305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141624, "time": 4765.556837797165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141688, "time": 4767.540625333786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141840, "time": 4772.518900632858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142392, "time": 4789.563196897507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142672, "time": 4798.479029893875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143000, "time": 4808.507361650467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143272, "time": 4816.886491537094, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 143392, "time": 4820.8259925842285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143584, "time": 4826.742622375488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144000, "time": 4839.677364349365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144152, "time": 4844.142786502838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144176, "time": 4845.112434148788, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 144704, "time": 4861.392004728317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144984, "time": 4869.9012196063995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145584, "time": 4888.664607048035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145704, "time": 4892.1226279735565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145896, "time": 4898.037805318832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146312, "time": 4911.011943817139, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146464, "time": 4915.937833309174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146488, "time": 4916.462574481964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147016, "time": 4932.853718280792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147296, "time": 4941.695582151413, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147896, "time": 4960.701223611832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148016, "time": 4964.604504585266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148208, "time": 4970.50160241127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148624, "time": 4983.310684680939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148768, "time": 4987.729238271713, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 148776, "time": 4987.760516881943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148800, "time": 4988.83273601532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149328, "time": 5005.106755018234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149608, "time": 5013.518451452255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 5033.999229669571, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5034.007862329483, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5034.019164085388, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5034.028514623642, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5034.038152933121, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5034.049159049988, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5034.061688184738, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5034.08402466774, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150328, "time": 5041.954471349716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150520, "time": 5047.898175001144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150936, "time": 5060.856015443802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151080, "time": 5065.341009378433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151088, "time": 5065.819401979446, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151112, "time": 5066.343620300293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151640, "time": 5082.775183200836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151920, "time": 5091.591888666153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152640, "time": 5113.88633108139, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152832, "time": 5119.857202291489, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153248, "time": 5132.725572824478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153392, "time": 5137.165634870529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153400, "time": 5137.196472167969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153424, "time": 5138.157926082611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153712, "time": 5147.180160284042, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 153952, "time": 5154.585621356964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154232, "time": 5163.035655736923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155144, "time": 5191.305354356766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155560, "time": 5204.243158340454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155704, "time": 5209.19548034668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155712, "time": 5209.673090457916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155736, "time": 5210.192980289459, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156024, "time": 5219.114599227905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156264, "time": 5226.508718252182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156544, "time": 5235.497978210449, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157456, "time": 5263.701495409012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157849, "time": 5276.569329738617, "train_stats/mean_log_entropy": 1.937958293004867, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9988453144929847, "train/action_min": 0.0, "train/action_std": 1.9997490772179194, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.8565873292281303e-05, "train/actor_opt_grad_steps": 8785.0, "train/actor_opt_loss": -4.934772789706381, "train/adv_mag": 0.00021114166141772756, "train/adv_max": 0.00016974381228186648, "train/adv_mean": 3.973326643724286e-05, "train/adv_min": -9.944072297337104e-05, "train/adv_std": 4.839160673981849e-05, "train/cont_avg": 0.9964425223214286, "train/cont_loss_mean": 0.023647099859271273, "train/cont_loss_std": 0.3270018322735417, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.653009255727132, "train/cont_pos_acc": 0.9999999844906281, "train/cont_pos_loss": 0.0035461365858244958, "train/cont_pred": 0.996460252574512, "train/cont_rate": 0.9964425223214286, "train/dyn_loss_mean": 1.0024013665257667, "train/dyn_loss_std": 0.00011310602534723905, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.011364616763098545, "train/extr_critic_critic_opt_grad_steps": 8785.0, "train/extr_critic_critic_opt_loss": 7484.666416713169, "train/extr_critic_mag": 0.020500603987246145, "train/extr_critic_max": 0.020500603987246145, "train/extr_critic_mean": 0.020446022107665027, "train/extr_critic_min": 0.020391082277103345, "train/extr_critic_std": 1.794524566358465e-05, "train/extr_return_normed_mag": 0.0002880969122812456, "train/extr_return_normed_max": 0.00024158356483189428, "train/extr_return_normed_mean": 0.00015400569326045826, "train/extr_return_normed_min": 5.913513465499391e-05, "train/extr_return_normed_std": 4.283376555883237e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.02057333718225056, "train/extr_return_raw_max": 0.02057333718225056, "train/extr_return_raw_mean": 0.02048576042550255, "train/extr_return_raw_min": 0.020390888752073656, "train/extr_return_raw_std": 4.2833765648157743e-05, "train/extr_reward_mag": 6.774007057657047e-05, "train/extr_reward_max": 6.774007057657047e-05, "train/extr_reward_mean": 6.768932012257247e-05, "train/extr_reward_min": 6.764640613478057e-05, "train/extr_reward_std": 2.129369542483156e-08, "train/image_loss_mean": 0.251001417332766, "train/image_loss_std": 0.08408629354469631, "train/model_loss_mean": 0.8780972647423647, "train/model_loss_std": 0.3792317445028801, "train/model_opt_grad_norm": 49.28124290583085, "train/model_opt_grad_steps": 8774.65306122449, "train/model_opt_loss": 2155.260654371612, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2455.3571428571427, "train/policy_entropy_mag": 1.9458897770667563, "train/policy_entropy_max": 1.9458897770667563, "train/policy_entropy_mean": 1.944932371377945, "train/policy_entropy_min": 1.9319146597871975, "train/policy_entropy_std": 0.0006398205205558191, "train/policy_logprob_mag": 2.175910696691396, "train/policy_logprob_max": -1.7299105032366149, "train/policy_logprob_mean": -1.9449537493744675, "train/policy_logprob_min": -2.175910696691396, "train/policy_logprob_std": 0.04385473875671017, "train/policy_randomness_mag": 0.9999895913868534, "train/policy_randomness_max": 0.9999895913868534, "train/policy_randomness_mean": 0.999497581197291, "train/policy_randomness_min": 0.9928078000642815, "train/policy_randomness_std": 0.00032880272934859503, "train/post_ent_mag": 88.1131220058519, "train/post_ent_max": 88.1131220058519, "train/post_ent_mean": 88.08542278834751, "train/post_ent_min": 87.81009273139797, "train/post_ent_std": 0.053233750701444794, "train/prior_ent_mag": 87.6899200750857, "train/prior_ent_max": 87.6899200750857, "train/prior_ent_mean": 87.66471006432359, "train/prior_ent_min": 87.50358472551618, "train/prior_ent_std": 0.03063028913504463, "train/rep_loss_mean": 1.0024013665257667, "train/rep_loss_std": 0.00011310602534723905, "train/reward_avg": 9.802993539482004e-05, "train/reward_loss_mean": 0.0020079054959992668, "train/reward_loss_std": 0.05623684151517349, "train/reward_max_data": 0.0945631383861206, "train/reward_max_pred": 6.855628928359674e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001890297367119311, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.418417602777481, "train/reward_pred": 6.839928302761852e-05, "train/reward_rate": 0.00017438616071428572, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020121321082115173, "report/cont_loss_std": 0.3010600507259369, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.574114799499512, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0038020533975213766, "report/cont_pred": 0.9962052702903748, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.23513583838939667, "report/image_loss_std": 0.09368012100458145, "report/model_loss_mean": 0.8652443885803223, "report/model_loss_std": 0.5626775622367859, "report/post_ent_mag": 91.7488021850586, "report/post_ent_max": 91.7488021850586, "report/post_ent_mean": 91.73457336425781, "report/post_ent_min": 91.68353271484375, "report/post_ent_std": 0.010353488847613335, "report/prior_ent_mag": 89.26312255859375, "report/prior_ent_max": 89.26312255859375, "report/prior_ent_mean": 89.24072265625, "report/prior_ent_min": 89.16552734375, "report/prior_ent_std": 0.017519906163215637, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005645751953125, "report/reward_loss_mean": 0.009987179189920425, "report/reward_loss_std": 0.31543782353401184, "report/reward_max_data": 0.578125, "report/reward_max_pred": 6.079673767089844e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00012493133544921875, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 10.099066734313965, "report/reward_pred": 6.079429294914007e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009241810999810696, "eval/cont_loss_std": 0.1739872545003891, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.5741143226623535, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0038020533975213766, "eval/cont_pred": 0.9962052702903748, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24777215719223022, "eval/image_loss_std": 0.09765080362558365, "eval/model_loss_mean": 0.8671965599060059, "eval/model_loss_std": 0.5137044191360474, "eval/post_ent_mag": 91.74996185302734, "eval/post_ent_max": 91.74996185302734, "eval/post_ent_mean": 91.73486328125, "eval/post_ent_min": 91.68389129638672, "eval/post_ent_std": 0.009865391999483109, "eval/prior_ent_mag": 89.26065063476562, "eval/prior_ent_max": 89.26065063476562, "eval/prior_ent_mean": 89.24154663085938, "eval/prior_ent_min": 89.16552734375, "eval/prior_ent_std": 0.01663040928542614, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.000885009765625, "eval/reward_loss_mean": 0.010182551108300686, "eval/reward_loss_std": 0.32168665528297424, "eval/reward_max_data": 0.90625, "eval/reward_max_pred": 6.079673767089844e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00012493133544921875, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.299127578735352, "eval/reward_pred": 6.0794176533818245e-05, "eval/reward_rate": 0.0009765625, "replay/size": 157345.0, "replay/inserts": 31472.0, "replay/samples": 31472.0, "replay/insert_wait_avg": 1.489063114094504e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.081095922884144e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38048.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.4258709745836092e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2367963790893555e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1270263195038, "timer/env.step_count": 3934.0, "timer/env.step_total": 40.514832973480225, "timer/env.step_frac": 0.04050968717701388, "timer/env.step_avg": 0.01029863573296396, "timer/env.step_min": 0.008795499801635742, "timer/env.step_max": 0.040567874908447266, "timer/replay._sample_count": 31472.0, "timer/replay._sample_total": 17.753203630447388, "timer/replay._sample_frac": 0.017750948792754545, "timer/replay._sample_avg": 0.0005640951839872709, "timer/replay._sample_min": 0.00038123130798339844, "timer/replay._sample_max": 0.02593398094177246, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4801.0, "timer/agent.policy_total": 56.1144015789032, "timer/agent.policy_frac": 0.05610727447832883, "timer/agent.policy_avg": 0.011688065315330806, "timer/agent.policy_min": 0.00964498519897461, "timer/agent.policy_max": 0.7247259616851807, "timer/dataset_train_count": 1967.0, "timer/dataset_train_total": 0.23653221130371094, "timer/dataset_train_frac": 0.00023650216930358965, "timer/dataset_train_avg": 0.00012025023452145955, "timer/dataset_train_min": 0.00010228157043457031, "timer/dataset_train_max": 0.0010759830474853516, "timer/agent.train_count": 1967.0, "timer/agent.train_total": 887.4149932861328, "timer/agent.train_frac": 0.8873022825428941, "timer/agent.train_avg": 0.4511514963325535, "timer/agent.train_min": 0.4387857913970947, "timer/agent.train_max": 0.7169206142425537, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47072696685791016, "timer/agent.report_frac": 0.00047066717973835676, "timer/agent.report_avg": 0.23536348342895508, "timer/agent.report_min": 0.22531676292419434, "timer/agent.report_max": 0.24541020393371582, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1944031866811224e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 31.467479544786197}
{"step": 157872, "time": 5277.302190542221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158016, "time": 5281.894482135773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158024, "time": 5281.927119970322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158048, "time": 5282.917307853699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158336, "time": 5291.903246879578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158576, "time": 5299.344292163849, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158856, "time": 5307.804189682007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159768, "time": 5336.113014221191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 5351.498157978058, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5351.506495475769, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5351.5167763233185, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5351.526356458664, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5351.537576913834, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5351.5470468997955, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5351.555142402649, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5351.563014745712, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160184, "time": 5355.53257393837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160328, "time": 5359.978348493576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160336, "time": 5360.454884529114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160360, "time": 5360.978355884552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160648, "time": 5369.934574604034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160872, "time": 5376.859380722046, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 160888, "time": 5377.3667068481445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161168, "time": 5386.354697465897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161432, "time": 5394.315118074417, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 161640, "time": 5400.7509779930115, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 162080, "time": 5414.690061569214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162488, "time": 5427.077252626419, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 162496, "time": 5427.559221982956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162640, "time": 5432.043575525284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162648, "time": 5432.075932979584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162960, "time": 5442.1104617118835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163744, "time": 5466.398326396942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163952, "time": 5473.4628484249115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164392, "time": 5486.85755777359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164800, "time": 5499.859200716019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164808, "time": 5499.891189813614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164952, "time": 5504.32555770874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164960, "time": 5504.805063962936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165272, "time": 5514.196581125259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166056, "time": 5538.503302812576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166264, "time": 5544.897565364838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166704, "time": 5558.814500570297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167112, "time": 5571.128732442856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167120, "time": 5571.607330322266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167264, "time": 5576.041293382645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167272, "time": 5576.082204341888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167584, "time": 5585.894175767899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168368, "time": 5610.126678466797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168576, "time": 5616.518950462341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168608, "time": 5617.532086133957, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 169016, "time": 5630.00940489769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169424, "time": 5642.825413942337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169576, "time": 5647.309499502182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169584, "time": 5647.785198926926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169896, "time": 5657.282730340958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 5668.550538301468, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5668.582506656647, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5668.618305921555, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5668.653946399689, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5668.688679695129, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5668.717324733734, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5668.736200332642, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5668.749853134155, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170680, "time": 5688.584338188171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170888, "time": 5694.96443605423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170920, "time": 5695.959116220474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171328, "time": 5708.884085893631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171736, "time": 5721.1885776519775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171888, "time": 5726.092195749283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171896, "time": 5726.123935699463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172208, "time": 5736.475904464722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172992, "time": 5760.728481292725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173200, "time": 5767.1177859306335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173232, "time": 5768.126051902771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173640, "time": 5780.597816228867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174048, "time": 5793.443413972855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174200, "time": 5797.936223745346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174208, "time": 5798.521522283554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174520, "time": 5807.924936532974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175304, "time": 5832.2240381240845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175512, "time": 5838.6465537548065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175544, "time": 5839.6305112838745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175952, "time": 5852.439466238022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176360, "time": 5864.860755681992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176512, "time": 5869.780714511871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176520, "time": 5869.811674594879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176832, "time": 5879.645810127258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177616, "time": 5903.913463115692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177824, "time": 5910.300580739975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177856, "time": 5911.282094478607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178264, "time": 5923.788369894028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178672, "time": 5936.643098592758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178824, "time": 5941.102148771286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178832, "time": 5941.596968412399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179144, "time": 5951.086331367493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179928, "time": 5975.261695384979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 5984.550841331482, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5984.559144020081, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5984.566912174225, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5984.576277017593, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5984.584613323212, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5984.592834234238, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5984.60044503212, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5984.608238220215, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180136, "time": 5988.0897562503815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180168, "time": 5989.07412481308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180576, "time": 6002.318111658096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180984, "time": 6014.752096891403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181136, "time": 6019.63707280159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181144, "time": 6019.667531490326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181456, "time": 6029.469176054001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182240, "time": 6053.610382318497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182448, "time": 6060.014727115631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182480, "time": 6061.007403850555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182888, "time": 6073.455397844315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183296, "time": 6086.253336906433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183448, "time": 6090.717576503754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183456, "time": 6091.191499471664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183768, "time": 6100.6194479465485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184552, "time": 6124.60168337822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184760, "time": 6131.138110876083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184792, "time": 6132.127467870712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185200, "time": 6144.883576393127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185608, "time": 6157.162894487381, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185760, "time": 6162.135732889175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185768, "time": 6162.165324449539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186080, "time": 6171.899835109711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186864, "time": 6195.863132953644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187072, "time": 6202.224915742874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187104, "time": 6203.200972318649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187512, "time": 6215.452181339264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187712, "time": 6221.878844499588, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 187920, "time": 6228.217739105225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188072, "time": 6232.644291162491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188080, "time": 6233.116502046585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189176, "time": 6266.868597507477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189384, "time": 6273.207101345062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189416, "time": 6274.20981669426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189465, "time": 6276.66321349144, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.991943051116635, "train/action_min": 0.0, "train/action_std": 2.003949852302821, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00013085162744472554, "train/actor_opt_grad_steps": 10755.0, "train/actor_opt_loss": -5.055700770682758, "train/adv_mag": 0.0003618341823569452, "train/adv_max": 0.0003034693537035374, "train/adv_mean": 3.259237295891479e-05, "train/adv_min": -0.0002573401093332454, "train/adv_std": 7.765409160735241e-05, "train/cont_avg": 0.9964192708333334, "train/cont_loss_mean": 0.023756822392419732, "train/cont_loss_std": 0.32740604132413864, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.650773445765178, "train/cont_pos_acc": 0.9999999855503892, "train/cont_pos_loss": 0.003544841876554519, "train/cont_pred": 0.9964615365471503, "train/cont_rate": 0.9964192708333334, "train/dyn_loss_mean": 1.0000000108372082, "train/dyn_loss_std": 3.355074508675383e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.007337363938638715, "train/extr_critic_critic_opt_grad_steps": 10755.0, "train/extr_critic_critic_opt_loss": 7900.516675544508, "train/extr_critic_mag": 0.022450985932590987, "train/extr_critic_max": 0.022450985932590987, "train/extr_critic_mean": 0.022281700660559265, "train/extr_critic_min": 0.022100622605795813, "train/extr_critic_std": 4.9048382544986616e-05, "train/extr_return_normed_mag": 0.00038833171129226685, "train/extr_return_normed_max": 0.00033640289547467474, "train/extr_return_normed_mean": 0.00016303443132730736, "train/extr_return_normed_min": -3.9222753710216945e-05, "train/extr_return_normed_std": 6.224770228036138e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.022487652920788588, "train/extr_return_raw_max": 0.022487652920788588, "train/extr_return_raw_mean": 0.022314285511395547, "train/extr_return_raw_min": 0.022112027271603694, "train/extr_return_raw_std": 6.224770262601529e-05, "train/extr_reward_mag": 7.217098968197601e-05, "train/extr_reward_max": 7.217098968197601e-05, "train/extr_reward_mean": 7.207204827974431e-05, "train/extr_reward_min": 7.19873592106983e-05, "train/extr_reward_std": 4.292292828238105e-08, "train/image_loss_mean": 0.2382933236282281, "train/image_loss_std": 0.0860387496273927, "train/model_loss_mean": 0.8641312859877192, "train/model_loss_std": 0.3840463287150017, "train/model_opt_grad_norm": 43.55981287330088, "train/model_opt_grad_steps": 10742.984848484848, "train/model_opt_loss": 2367.0616344105115, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2739.89898989899, "train/policy_entropy_mag": 1.945794201258457, "train/policy_entropy_max": 1.945794201258457, "train/policy_entropy_mean": 1.9392701628232243, "train/policy_entropy_min": 1.8750274795474429, "train/policy_entropy_std": 0.005028462449601391, "train/policy_logprob_mag": 2.4365433851877847, "train/policy_logprob_max": -1.4583653916012158, "train/policy_logprob_mean": -1.9393321859716164, "train/policy_logprob_min": -2.4365433851877847, "train/policy_logprob_std": 0.10130878327169804, "train/policy_randomness_mag": 0.9999404721187822, "train/policy_randomness_max": 0.9999404721187822, "train/policy_randomness_mean": 0.9965877809909859, "train/policy_randomness_min": 0.9635735714074337, "train/policy_randomness_std": 0.0025841186814964984, "train/post_ent_mag": 92.61858433424824, "train/post_ent_max": 92.61858433424824, "train/post_ent_mean": 92.52060657077365, "train/post_ent_min": 92.44269796814581, "train/post_ent_std": 0.03108888893679838, "train/prior_ent_mag": 89.80327143813625, "train/prior_ent_max": 89.80327143813625, "train/prior_ent_mean": 89.53158912273368, "train/prior_ent_min": 89.36968454688487, "train/prior_ent_std": 0.07617262783789575, "train/rep_loss_mean": 1.0000000108372082, "train/rep_loss_std": 3.355074508675383e-07, "train/reward_avg": 0.00010483867005648496, "train/reward_loss_mean": 0.0020811149869302305, "train/reward_loss_std": 0.05954814924312664, "train/reward_max_data": 0.10486111138956715, "train/reward_max_pred": 7.217098968197601e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001954587774393572, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.08602367507087, "train/reward_pred": 7.20248302454223e-05, "train/reward_rate": 0.00018742108585858585, "train_stats/mean_log_entropy": 1.9324570396672125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014619137160480022, "report/cont_loss_std": 0.24748702347278595, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.609139919281006, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00367094948887825, "report/cont_pred": 0.9963359236717224, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18639621138572693, "report/image_loss_std": 0.09702855348587036, "report/model_loss_mean": 0.8011214733123779, "report/model_loss_std": 0.26476940512657166, "report/post_ent_mag": 95.00481414794922, "report/post_ent_max": 95.00481414794922, "report/post_ent_mean": 94.7291259765625, "report/post_ent_min": 94.55741882324219, "report/post_ent_std": 0.07680341601371765, "report/prior_ent_mag": 93.01419067382812, "report/prior_ent_max": 93.01419067382812, "report/prior_ent_mean": 91.5438461303711, "report/prior_ent_min": 90.93978881835938, "report/prior_ent_std": 0.37230879068374634, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00010617449879646301, "report/reward_loss_std": 4.491254230742925e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 4.589557647705078e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00010617449879646301, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.565669223666191e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0036709497217088938, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0036709497217088938, "eval/cont_pred": 0.9963359236717224, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1967901885509491, "eval/image_loss_std": 0.095026396214962, "eval/model_loss_mean": 0.8005674481391907, "eval/model_loss_std": 0.09502625465393066, "eval/post_ent_mag": 95.00886535644531, "eval/post_ent_max": 95.00886535644531, "eval/post_ent_mean": 94.72418975830078, "eval/post_ent_min": 94.58808135986328, "eval/post_ent_std": 0.07517632842063904, "eval/prior_ent_mag": 92.94306945800781, "eval/prior_ent_max": 92.94306945800781, "eval/prior_ent_mean": 91.68344116210938, "eval/prior_ent_min": 90.93797302246094, "eval/prior_ent_std": 0.480493426322937, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00010627694427967072, "eval/reward_loss_std": 4.7332815711342846e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 4.589557647705078e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00010627694427967072, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.56951092928648e-05, "eval/reward_rate": 0.0, "replay/size": 188961.0, "replay/inserts": 31616.0, "replay/samples": 31616.0, "replay/insert_wait_avg": 1.464589585659475e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.971065488421482e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44984.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3814596706333183e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0794672966003, "timer/env.step_count": 3952.0, "timer/env.step_total": 40.508495569229126, "timer/env.step_frac": 0.04050527672438979, "timer/env.step_avg": 0.010250125397072147, "timer/env.step_min": 0.008665323257446289, "timer/env.step_max": 0.036957502365112305, "timer/replay._sample_count": 31616.0, "timer/replay._sample_total": 17.557363748550415, "timer/replay._sample_frac": 0.01755596862318473, "timer/replay._sample_avg": 0.0005553315962977738, "timer/replay._sample_min": 0.000370025634765625, "timer/replay._sample_max": 0.025475740432739258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4819.0, "timer/agent.policy_total": 54.66791582107544, "timer/agent.policy_frac": 0.05466357185479762, "timer/agent.policy_avg": 0.011344244826950704, "timer/agent.policy_min": 0.009483575820922852, "timer/agent.policy_max": 0.09203815460205078, "timer/dataset_train_count": 1976.0, "timer/dataset_train_total": 0.24070215225219727, "timer/dataset_train_frac": 0.00024068302582279754, "timer/dataset_train_avg": 0.00012181283008714437, "timer/dataset_train_min": 0.00010561943054199219, "timer/dataset_train_max": 0.000560760498046875, "timer/agent.train_count": 1976.0, "timer/agent.train_total": 888.605687379837, "timer/agent.train_frac": 0.8885350778992618, "timer/agent.train_avg": 0.4496992345039661, "timer/agent.train_min": 0.43607401847839355, "timer/agent.train_max": 0.6824491024017334, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47280240058898926, "timer/agent.report_frac": 0.00047276483124592244, "timer/agent.report_avg": 0.23640120029449463, "timer/agent.report_min": 0.2243490219116211, "timer/agent.report_max": 0.24845337867736816, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.170715133890801e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 31.612966566037663}
{"step": 189824, "time": 6287.765226125717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 6295.101661682129, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 190008, "time": 6299.203340053558, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6299.211824178696, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6299.218993425369, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6299.226071357727, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6299.233207702637, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6299.2414581775665, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6299.248729944229, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190024, "time": 6299.748113155365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190232, "time": 6306.075088024139, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190384, "time": 6311.072048187256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190392, "time": 6311.102250099182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191488, "time": 6344.863717079163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191696, "time": 6351.194494485855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191728, "time": 6352.175685405731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192136, "time": 6364.398595333099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192336, "time": 6370.792013168335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192544, "time": 6377.123618364334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192696, "time": 6381.539064407349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192704, "time": 6382.012856006622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193800, "time": 6415.303977966309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194008, "time": 6421.618110895157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194040, "time": 6422.618713617325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194448, "time": 6435.383024215698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194648, "time": 6441.242842435837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194856, "time": 6447.601708173752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195008, "time": 6452.46941781044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195016, "time": 6452.4997770786285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195296, "time": 6461.314866304398, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 195544, "time": 6468.6613783836365, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 196352, "time": 6493.625591754913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196760, "time": 6506.357723712921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196960, "time": 6512.673753499985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197168, "time": 6519.116694927216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197320, "time": 6523.523822307587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197328, "time": 6523.995598077774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197608, "time": 6532.310226917267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197856, "time": 6540.083938121796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198664, "time": 6564.58113193512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199072, "time": 6577.252092838287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199272, "time": 6583.261240005493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199480, "time": 6589.641998767853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199632, "time": 6594.4992690086365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199640, "time": 6594.531316757202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199920, "time": 6603.2902154922485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 6615.503109455109, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6615.51137471199, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6615.51907658577, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6615.527064800262, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6615.535216331482, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6615.543239593506, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6615.551079273224, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6615.558878660202, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200168, "time": 6617.559390068054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200976, "time": 6643.305535793304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201384, "time": 6655.5231556892395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201584, "time": 6661.872147798538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201792, "time": 6668.2209260463715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201944, "time": 6672.770783185959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201952, "time": 6673.24275970459, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202232, "time": 6681.61158490181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202480, "time": 6689.395501375198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203088, "time": 6708.054630756378, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 203288, "time": 6713.929537773132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203896, "time": 6732.582323551178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204104, "time": 6738.913573741913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204256, "time": 6743.7690505981445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204264, "time": 6743.799080610275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204544, "time": 6752.577695131302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204792, "time": 6760.051362276077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205400, "time": 6779.0516765117645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205600, "time": 6785.348423480988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206208, "time": 6804.066570520401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206416, "time": 6810.4390251636505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206568, "time": 6814.867043495178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206576, "time": 6815.341225862503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206856, "time": 6823.775907039642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207104, "time": 6831.571655988693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207608, "time": 6846.722315788269, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 207712, "time": 6850.242868185043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208520, "time": 6874.634127855301, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208728, "time": 6881.1230437755585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208768, "time": 6882.583645820618, "episode/length": 273.0, "episode/score": 0.14687499403953552, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.0}
{"step": 208880, "time": 6885.999080896378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209168, "time": 6894.788826465607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209416, "time": 6902.166532993317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209784, "time": 6913.5403089523315, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 209920, "time": 6917.905274629593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210024, "time": 6920.845456600189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 6924.280313968658, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 210080, "time": 6928.8926322460175, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6928.90168094635, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6928.908986091614, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6928.916163921356, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6928.923754453659, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6928.930756807327, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6928.93842124939, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210832, "time": 6951.947271108627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211040, "time": 6958.282070636749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211192, "time": 6962.700095415115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211480, "time": 6971.638847351074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211728, "time": 6979.441470146179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212096, "time": 6990.675587654114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212232, "time": 6994.644658565521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212336, "time": 6998.0504314899445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213144, "time": 7023.085632562637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213352, "time": 7029.551502227783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213504, "time": 7034.426005363464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213792, "time": 7043.243232488632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214040, "time": 7050.6057233810425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214408, "time": 7061.894863128662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214544, "time": 7066.2620849609375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214648, "time": 7069.20242357254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215456, "time": 7094.098689556122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215664, "time": 7100.464487791061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215816, "time": 7104.898630619049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216104, "time": 7113.693559408188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216352, "time": 7121.59982919693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216720, "time": 7132.841377019882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216856, "time": 7136.762771844864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216960, "time": 7140.190939664841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217448, "time": 7154.95201253891, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 217768, "time": 7164.769299507141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217976, "time": 7171.131795167923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218416, "time": 7184.889382839203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218664, "time": 7192.205860853195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219032, "time": 7203.411013126373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219168, "time": 7207.7721247673035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219272, "time": 7210.8170692920685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219760, "time": 7225.91906619072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 7241.49382853508, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7241.503577232361, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7241.513425588608, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7241.521908998489, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7241.5302839279175, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7241.538547515869, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7241.546183824539, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7241.553908824921, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220080, "time": 7242.058384895325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220288, "time": 7248.481837511063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220728, "time": 7261.628224134445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220976, "time": 7269.551157236099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221193, "time": 7277.3834064006805, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.198752046835543, "train/action_min": 0.0, "train/action_std": 1.9071852745431843, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00028353556645199226, "train/actor_opt_grad_steps": 12735.0, "train/actor_opt_loss": -1.9044073643821358, "train/adv_mag": 0.0015330959882850599, "train/adv_max": 0.0014393098577104434, "train/adv_mean": 0.00022045121705683744, "train/adv_min": -0.0008612234201846701, "train/adv_std": 0.0003023466944998492, "train/cont_avg": 0.9965770991161617, "train/cont_loss_mean": 0.02289819058896315, "train/cont_loss_std": 0.3205328283471648, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.66539835082698, "train/cont_pos_acc": 0.9999999855503892, "train/cont_pos_loss": 0.0034964292655896506, "train/cont_pred": 0.9965097684450824, "train/cont_rate": 0.9965770991161617, "train/dyn_loss_mean": 1.000000830852624, "train/dyn_loss_std": 1.9546636560169812e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.010023664218912164, "train/extr_critic_critic_opt_grad_steps": 12735.0, "train/extr_critic_critic_opt_loss": 8334.685226286301, "train/extr_critic_mag": 0.02517371466665557, "train/extr_critic_max": 0.02517371466665557, "train/extr_critic_mean": 0.024451672475822646, "train/extr_critic_min": 0.023863505233417858, "train/extr_critic_std": 0.00015886060197836476, "train/extr_return_normed_mag": 0.0020529058752487405, "train/extr_return_normed_max": 0.0020311595213533653, "train/extr_return_normed_mean": 0.0008959391697485995, "train/extr_return_normed_min": 4.526244645768946e-05, "train/extr_return_normed_std": 0.0003113461754415913, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.025807333696219657, "train/extr_return_raw_max": 0.025807333696219657, "train/extr_return_raw_mean": 0.024672114581923293, "train/extr_return_raw_min": 0.02382143662132398, "train/extr_return_raw_std": 0.00031134617593767935, "train/extr_reward_mag": 0.00019234117835459084, "train/extr_reward_max": 0.00019234117835459084, "train/extr_reward_mean": 9.736337983897579e-05, "train/extr_reward_min": 4.5232700579094164e-05, "train/extr_reward_std": 4.651988492884813e-05, "train/image_loss_mean": 0.20249423828690943, "train/image_loss_std": 0.09680051623721316, "train/model_loss_mean": 0.8269015923895017, "train/model_loss_std": 0.36705253051236425, "train/model_opt_grad_norm": 39.72457752805768, "train/model_opt_grad_steps": 12721.262626262625, "train/model_opt_loss": 2422.4063301471747, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2929.2929292929293, "train/policy_entropy_mag": 1.9431874324577023, "train/policy_entropy_max": 1.9431874324577023, "train/policy_entropy_mean": 1.8693193251436406, "train/policy_entropy_min": 1.5292461950971623, "train/policy_entropy_std": 0.03382310326766185, "train/policy_logprob_mag": 3.535265084468957, "train/policy_logprob_max": -0.8268164551318294, "train/policy_logprob_mean": -1.8693543522044866, "train/policy_logprob_min": -3.535265084468957, "train/policy_logprob_std": 0.3096368875015866, "train/policy_randomness_mag": 0.9986008589315896, "train/policy_randomness_max": 0.9986008589315896, "train/policy_randomness_mean": 0.9606401598212695, "train/policy_randomness_min": 0.7858771297967795, "train/policy_randomness_std": 0.01738163772876365, "train/post_ent_mag": 95.26478669137666, "train/post_ent_max": 95.26478669137666, "train/post_ent_mean": 95.00304150822187, "train/post_ent_min": 94.80805514557193, "train/post_ent_std": 0.0838927710146615, "train/prior_ent_mag": 95.75497725515655, "train/prior_ent_max": 95.75497725515655, "train/prior_ent_mean": 93.37309292109326, "train/prior_ent_min": 92.1113668499571, "train/prior_ent_std": 0.6174207397482612, "train/rep_loss_mean": 1.000000830852624, "train/rep_loss_std": 1.9546636560169812e-05, "train/reward_avg": 6.978969443048529e-05, "train/reward_loss_mean": 0.0015086392199413644, "train/reward_loss_std": 0.041095468393347795, "train/reward_max_data": 0.06737689444362516, "train/reward_max_pred": 0.00017940636837121212, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00021139159056327464, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.110092004140219, "train/reward_pred": 6.54003186612343e-05, "train/reward_rate": 0.0001282354797979798, "train_stats/mean_log_entropy": 1.857979146209923, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.00835102517157793, "report/cont_loss_std": 0.1871642917394638, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.994682788848877, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002499282592907548, "report/cont_pred": 0.9975038766860962, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.19570600986480713, "report/image_loss_std": 0.10652413964271545, "report/model_loss_mean": 0.8042134046554565, "report/model_loss_std": 0.21702197194099426, "report/post_ent_mag": 96.45880126953125, "report/post_ent_max": 96.45880126953125, "report/post_ent_mean": 96.19673156738281, "report/post_ent_min": 95.87728118896484, "report/post_ent_std": 0.09948121011257172, "report/prior_ent_mag": 96.7301025390625, "report/prior_ent_max": 96.7301025390625, "report/prior_ent_mean": 94.38854217529297, "report/prior_ent_min": 92.10894775390625, "report/prior_ent_std": 0.6795526146888733, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00015632156282663345, "report/reward_loss_std": 0.00023381839855574071, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.00034809112548828125, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00015632156282663345, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.487115751951933e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02004299685359001, "eval/cont_loss_std": 0.32365041971206665, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.990786552429199, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0024991855025291443, "eval/cont_pred": 0.9975039958953857, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2059280276298523, "eval/image_loss_std": 0.09956666827201843, "eval/model_loss_mean": 0.826156735420227, "eval/model_loss_std": 0.3370232880115509, "eval/post_ent_mag": 96.48014831542969, "eval/post_ent_max": 96.48014831542969, "eval/post_ent_mean": 96.19759368896484, "eval/post_ent_min": 95.87721252441406, "eval/post_ent_std": 0.1007862538099289, "eval/prior_ent_mag": 96.76246643066406, "eval/prior_ent_max": 96.76246643066406, "eval/prior_ent_mean": 94.47142028808594, "eval/prior_ent_min": 92.22257995605469, "eval/prior_ent_std": 0.6633330583572388, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00018569966778159142, "eval/reward_loss_std": 0.0002563488087616861, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00035321712493896484, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00018569966778159142, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.711071521043777e-05, "eval/reward_rate": 0.0, "replay/size": 220689.0, "replay/inserts": 31728.0, "replay/samples": 31728.0, "replay/insert_wait_avg": 1.4287004913276215e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.684881255534101e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54232.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3398412602170529e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.7007675170898, "timer/env.step_count": 3966.0, "timer/env.step_total": 39.887404680252075, "timer/env.step_frac": 0.039859472456706076, "timer/env.step_avg": 0.010057338547718626, "timer/env.step_min": 0.008682727813720703, "timer/env.step_max": 0.049750566482543945, "timer/replay._sample_count": 31728.0, "timer/replay._sample_total": 16.48182487487793, "timer/replay._sample_frac": 0.016470283035529356, "timer/replay._sample_avg": 0.0005194725439636261, "timer/replay._sample_min": 0.0003604888916015625, "timer/replay._sample_max": 0.013993501663208008, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5122.0, "timer/agent.policy_total": 56.16644787788391, "timer/agent.policy_frac": 0.05612711581829052, "timer/agent.policy_avg": 0.010965725864483387, "timer/agent.policy_min": 0.009299755096435547, "timer/agent.policy_max": 0.09087681770324707, "timer/dataset_train_count": 1983.0, "timer/dataset_train_total": 0.23673486709594727, "timer/dataset_train_frac": 0.00023656908716411507, "timer/dataset_train_avg": 0.00011938218209578783, "timer/dataset_train_min": 0.000102996826171875, "timer/dataset_train_max": 0.0011036396026611328, "timer/agent.train_count": 1983.0, "timer/agent.train_total": 886.0792508125305, "timer/agent.train_frac": 0.8854587500827495, "timer/agent.train_avg": 0.44683774624938505, "timer/agent.train_min": 0.43595433235168457, "timer/agent.train_max": 1.2320082187652588, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.469085693359375, "timer/agent.report_frac": 0.0004687572035377339, "timer/agent.report_avg": 0.2345428466796875, "timer/agent.report_min": 0.22404980659484863, "timer/agent.report_max": 0.24503588676452637, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.430823329516301e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 31.705100462538763}
{"step": 221344, "time": 7282.008588790894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221480, "time": 7285.953600645065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221584, "time": 7289.3742961883545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222072, "time": 7304.14647936821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222392, "time": 7313.896982908249, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222600, "time": 7320.253931283951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222656, "time": 7322.206633806229, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 223040, "time": 7334.0033712387085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223288, "time": 7341.352468490601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223656, "time": 7352.628160476685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223792, "time": 7357.018775224686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224384, "time": 7375.189063310623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224704, "time": 7384.9689791202545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224912, "time": 7391.423015594482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224968, "time": 7392.915793418884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225352, "time": 7404.623536109924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225600, "time": 7412.452522516251, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225968, "time": 7423.822823524475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226104, "time": 7427.754907131195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226696, "time": 7445.781475782394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227016, "time": 7455.652944326401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227224, "time": 7462.006163358688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227280, "time": 7463.94203209877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227664, "time": 7475.684177398682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227912, "time": 7483.156318664551, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228280, "time": 7494.355842828751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228416, "time": 7498.718720674515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229008, "time": 7516.903734445572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229328, "time": 7526.69503903389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229528, "time": 7533.052723407745, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 229536, "time": 7533.52392578125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229976, "time": 7546.809999465942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 7555.2767062187195, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7555.285066604614, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7555.292478084564, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7555.30020737648, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7555.309036016464, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7555.3188507556915, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7555.326924800873, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7555.334726810455, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230224, "time": 7560.714353561401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230592, "time": 7572.074864864349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230728, "time": 7575.994669675827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231320, "time": 7594.0611934661865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231536, "time": 7600.982672691345, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 231640, "time": 7603.937521934509, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231840, "time": 7610.276128530502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231848, "time": 7610.30788397789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232288, "time": 7623.981781005859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232536, "time": 7631.386234760284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232904, "time": 7642.655335426331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233040, "time": 7647.024658918381, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233848, "time": 7671.4514627456665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233952, "time": 7674.863927364349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234152, "time": 7680.737326622009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234160, "time": 7681.206509113312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234600, "time": 7694.514785766602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234848, "time": 7702.320605754852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235216, "time": 7713.4995658397675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235352, "time": 7717.423811674118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236160, "time": 7742.366504907608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236264, "time": 7745.310987710953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236464, "time": 7751.743527173996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236472, "time": 7751.774212837219, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236912, "time": 7765.390830993652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237160, "time": 7772.702425003052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237528, "time": 7784.032933473587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237664, "time": 7788.926120758057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238472, "time": 7813.36847448349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238576, "time": 7816.773525953293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238776, "time": 7822.683377981186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238784, "time": 7823.163273334503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239224, "time": 7836.373364448547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239472, "time": 7844.277275562286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239840, "time": 7855.494171619415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239976, "time": 7859.434630155563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 7867.727823734283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7867.735971927643, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7867.742990016937, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7867.750851392746, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7867.758031129837, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7867.765125274658, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7867.772045135498, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7867.779105186462, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240784, "time": 7890.648749113083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240888, "time": 7893.563749551773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241088, "time": 7899.922587394714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241096, "time": 7899.952576160431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241536, "time": 7913.519779920578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241784, "time": 7920.829386472702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242152, "time": 7932.123739480972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242288, "time": 7936.493315696716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243096, "time": 7961.07626581192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243200, "time": 7964.481089353561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243400, "time": 7970.328082084656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243408, "time": 7970.797638654709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243768, "time": 7981.49188542366, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 243848, "time": 7983.941225528717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244096, "time": 7991.7332310676575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244464, "time": 8002.859911441803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244600, "time": 8006.7737159729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245408, "time": 8031.761551856995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245712, "time": 8041.067255735397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245720, "time": 8041.0985589027405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245800, "time": 8044.077911376953, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 246160, "time": 8055.398657798767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246408, "time": 8062.76682305336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246656, "time": 8070.518533945084, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 246776, "time": 8073.981878042221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246912, "time": 8078.3789920806885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247720, "time": 8102.859409093857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248024, "time": 8112.29674911499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248032, "time": 8112.769073724747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248112, "time": 8115.220808267593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248720, "time": 8133.7476580142975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248968, "time": 8141.215025424957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249088, "time": 8145.101042509079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249224, "time": 8149.007375717163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 8179.597797393799, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8179.631515264511, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8179.6638605594635, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8179.696514368057, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8179.707588672638, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8179.715752363205, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8179.727769851685, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8179.742227554321, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250032, "time": 8180.268004894257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250336, "time": 8189.5407202243805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250344, "time": 8189.570939779282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250384, "time": 8191.031339883804, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 250424, "time": 8192.032350540161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251280, "time": 8218.440373659134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251400, "time": 8221.879883527756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251536, "time": 8226.265100479126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252344, "time": 8250.766175031662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252648, "time": 8260.124752759933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252656, "time": 8260.598227024078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252696, "time": 8261.597436904907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252736, "time": 8263.051231861115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253193, "time": 8277.750756263733, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.983881530761719, "train/action_min": 0.0, "train/action_std": 1.9796085864305497, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0014638023656152654, "train/actor_opt_grad_steps": 14725.0, "train/actor_opt_loss": 5.608868486816063, "train/adv_mag": 0.008008189387619496, "train/adv_max": 0.007787459045648575, "train/adv_mean": 0.0011253534779314123, "train/adv_min": -0.00282208782620728, "train/adv_std": 0.0012966746991151011, "train/cont_avg": 0.9963916015625, "train/cont_loss_mean": 0.02393018755246885, "train/cont_loss_std": 0.32671186949857883, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.658639355581634, "train/cont_pos_acc": 0.9999999845027924, "train/cont_pos_loss": 0.0035196683427784594, "train/cont_pred": 0.9964866113662719, "train/cont_rate": 0.9963916015625, "train/dyn_loss_mean": 1.0000013202428817, "train/dyn_loss_std": 3.614752651628805e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0776432458567433, "train/extr_critic_critic_opt_grad_steps": 14725.0, "train/extr_critic_critic_opt_loss": 12467.883491210938, "train/extr_critic_mag": 0.061557886004447934, "train/extr_critic_max": 0.061557886004447934, "train/extr_critic_mean": 0.059176334198564294, "train/extr_critic_min": 0.05630575060844421, "train/extr_critic_std": 0.0007436690229224041, "train/extr_return_normed_mag": 0.011682959562167526, "train/extr_return_normed_max": 0.011682141190394759, "train/extr_return_normed_mean": 0.004340224729994588, "train/extr_return_normed_min": 0.00048549226485192774, "train/extr_return_normed_std": 0.0014890485981595702, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.06764361247420311, "train/extr_return_raw_max": 0.06764361247420311, "train/extr_return_raw_mean": 0.06030169874429703, "train/extr_return_raw_min": 0.05644696356728673, "train/extr_return_raw_std": 0.001489048597868532, "train/extr_reward_mag": 0.0033589160442352296, "train/extr_reward_max": 0.0033589160442352296, "train/extr_reward_mean": 0.0003261780586672103, "train/extr_reward_min": 5.447268486022949e-06, "train/extr_reward_std": 0.00048317860857423513, "train/image_loss_mean": 0.1852303658425808, "train/image_loss_std": 0.10321705088019371, "train/model_loss_mean": 0.8105364215373992, "train/model_loss_std": 0.3715829025581479, "train/model_opt_grad_norm": 37.811055240631106, "train/model_opt_grad_steps": 14709.525, "train/model_opt_loss": 2189.3519763183594, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2700.0, "train/policy_entropy_mag": 1.874899753332138, "train/policy_entropy_max": 1.874899753332138, "train/policy_entropy_mean": 1.314598205089569, "train/policy_entropy_min": 0.34151972591876983, "train/policy_entropy_std": 0.2829015278071165, "train/policy_logprob_mag": 5.717436759471894, "train/policy_logprob_max": -0.07920201788656414, "train/policy_logprob_mean": -1.3146932297945022, "train/policy_logprob_min": -5.717436759471894, "train/policy_logprob_std": 0.9200787368416786, "train/policy_randomness_mag": 0.9635079321265221, "train/policy_randomness_max": 0.9635079321265221, "train/policy_randomness_mean": 0.6755698785185814, "train/policy_randomness_min": 0.1755064314417541, "train/policy_randomness_std": 0.14538263447582722, "train/post_ent_mag": 97.71718482971191, "train/post_ent_max": 97.71718482971191, "train/post_ent_mean": 97.39813037872314, "train/post_ent_min": 97.07601184844971, "train/post_ent_std": 0.10684143181890249, "train/prior_ent_mag": 99.10213230133057, "train/prior_ent_max": 99.10213230133057, "train/prior_ent_mean": 96.58673194885255, "train/prior_ent_min": 94.675231590271, "train/prior_ent_std": 0.7016073520481586, "train/rep_loss_mean": 1.0000013202428817, "train/rep_loss_std": 3.614752651628805e-05, "train/reward_avg": 7.56835937863798e-05, "train/reward_loss_mean": 0.0013750512362457811, "train/reward_loss_std": 0.037710667692981585, "train/reward_max_data": 0.07295312497764826, "train/reward_max_pred": 0.0015696507692337036, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0001850197188468883, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.735216269126305, "train/reward_pred": 6.748207961209119e-05, "train/reward_rate": 0.00013671875, "train_stats/mean_log_entropy": 1.3209593052449433, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.01467440091073513, "report/cont_loss_std": 0.2461072951555252, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.578005790710449, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003787257708609104, "report/cont_pred": 0.9962196946144104, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.166398286819458, "report/image_loss_std": 0.10151847451925278, "report/model_loss_mean": 0.7813836932182312, "report/model_loss_std": 0.26746541261672974, "report/post_ent_mag": 98.76675415039062, "report/post_ent_max": 98.76675415039062, "report/post_ent_mean": 98.4422836303711, "report/post_ent_min": 98.13909912109375, "report/post_ent_std": 0.10348266363143921, "report/prior_ent_mag": 100.12723541259766, "report/prior_ent_max": 100.12723541259766, "report/prior_ent_mean": 98.56852722167969, "report/prior_ent_min": 96.61943054199219, "report/prior_ent_std": 0.696705162525177, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0003109630197286606, "report/reward_loss_std": 0.0015078929718583822, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.00608670711517334, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0003109630197286606, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00012855511158704758, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020117972046136856, "eval/cont_loss_std": 0.3012711703777313, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.578005790710449, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0037872574757784605, "eval/cont_pred": 0.9962196946144104, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17622284591197968, "eval/image_loss_std": 0.10377158224582672, "eval/model_loss_mean": 0.7966325879096985, "eval/model_loss_std": 0.32114845514297485, "eval/post_ent_mag": 98.83300018310547, "eval/post_ent_max": 98.83300018310547, "eval/post_ent_mean": 98.45245361328125, "eval/post_ent_min": 98.13475036621094, "eval/post_ent_std": 0.10745326429605484, "eval/prior_ent_mag": 100.01515197753906, "eval/prior_ent_max": 100.01515197753906, "eval/prior_ent_mean": 98.50816345214844, "eval/prior_ent_min": 96.44224548339844, "eval/prior_ent_std": 0.7238519191741943, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0002917028032243252, "eval/reward_loss_std": 0.0014232899993658066, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.007344722747802734, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0002917028032243252, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00012061174493283033, "eval/reward_rate": 0.0, "replay/size": 252689.0, "replay/inserts": 32000.0, "replay/samples": 32000.0, "replay/insert_wait_avg": 1.4216527342796326e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.687434554100037e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61168.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3005087257394054e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3512651920319, "timer/env.step_count": 4000.0, "timer/env.step_total": 39.74761176109314, "timer/env.step_frac": 0.039733654711240865, "timer/env.step_avg": 0.009936902940273286, "timer/env.step_min": 0.00793766975402832, "timer/env.step_max": 0.05458545684814453, "timer/replay._sample_count": 32000.0, "timer/replay._sample_total": 16.72713279724121, "timer/replay._sample_frac": 0.016721259200916987, "timer/replay._sample_avg": 0.0005227228999137878, "timer/replay._sample_min": 0.00037670135498046875, "timer/replay._sample_max": 0.03541970252990723, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4867.0, "timer/agent.policy_total": 52.949214220047, "timer/agent.policy_frac": 0.0529306215351091, "timer/agent.policy_avg": 0.010879230371901992, "timer/agent.policy_min": 0.009058952331542969, "timer/agent.policy_max": 0.08758664131164551, "timer/dataset_train_count": 2000.0, "timer/dataset_train_total": 0.23474955558776855, "timer/dataset_train_frac": 0.00023466712519497337, "timer/dataset_train_avg": 0.00011737477779388428, "timer/dataset_train_min": 0.0001010894775390625, "timer/dataset_train_max": 0.0003638267517089844, "timer/agent.train_count": 2000.0, "timer/agent.train_total": 892.5680844783783, "timer/agent.train_frac": 0.8922546664716188, "timer/agent.train_avg": 0.44628404223918916, "timer/agent.train_min": 0.4351367950439453, "timer/agent.train_max": 0.6784486770629883, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48000097274780273, "timer/agent.report_frac": 0.0004798324243191312, "timer/agent.report_avg": 0.24000048637390137, "timer/agent.report_min": 0.23234033584594727, "timer/agent.report_max": 0.24766063690185547, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.289021072982764e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 31.988233263585958}
{"step": 253592, "time": 8289.80166387558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253712, "time": 8293.70061659813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253760, "time": 8295.161182165146, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 253848, "time": 8297.624216794968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254960, "time": 8332.40183877945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 254968, "time": 8332.433435678482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255008, "time": 8333.901846408844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255048, "time": 8334.909504175186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255888, "time": 8360.908105373383, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 255904, "time": 8361.407687187195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256024, "time": 8364.873705148697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256072, "time": 8366.363721609116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256160, "time": 8369.312309503555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257272, "time": 8403.146661281586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257280, "time": 8403.617441654205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257320, "time": 8404.617486000061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257976, "time": 8424.754575967789, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 258200, "time": 8431.61564040184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258216, "time": 8432.111168384552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258336, "time": 8435.98996090889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258360, "time": 8436.530982255936, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 258472, "time": 8440.10789322853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259424, "time": 8469.468662261963, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 259584, "time": 8474.35146856308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259632, "time": 8475.827801704407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 8493.117398262024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8493.163081884384, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8493.179691076279, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8493.192919492722, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8493.20308470726, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8493.215835809708, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8493.224361419678, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8493.233250617981, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260288, "time": 8502.120043039322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260392, "time": 8505.055037498474, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 260512, "time": 8508.932996749878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260528, "time": 8509.42602467537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260648, "time": 8512.883416175842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260672, "time": 8513.83890247345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261480, "time": 8538.415855169296, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 261704, "time": 8545.24137043953, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 261736, "time": 8546.240867853165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261944, "time": 8552.604605197906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262192, "time": 8561.061940193176, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 262704, "time": 8576.70186829567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262824, "time": 8580.14937376976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262840, "time": 8580.662299156189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262960, "time": 8584.537505865097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 263520, "time": 8601.854506731033, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 264048, "time": 8618.000524759293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264256, "time": 8624.513358831406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264504, "time": 8631.900950431824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265016, "time": 8647.570842027664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265136, "time": 8651.590226650238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265152, "time": 8652.084520816803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265272, "time": 8655.53863978386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265440, "time": 8660.890394687653, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 265832, "time": 8672.677983760834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265992, "time": 8677.563512563705, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 266424, "time": 8690.904910564423, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 266552, "time": 8694.840197563171, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 266944, "time": 8707.012891054153, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 267216, "time": 8715.482491970062, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 267312, "time": 8718.446729898453, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 267328, "time": 8718.947999477386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267400, "time": 8720.923452854156, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 267448, "time": 8722.395793676376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267664, "time": 8729.237393140793, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 267824, "time": 8734.124719619751, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 267960, "time": 8738.06490278244, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 268296, "time": 8748.439696073532, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 269248, "time": 8777.952142477036, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 269280, "time": 8778.945976018906, "episode/length": 228.0, "episode/score": 0.2874999940395355, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0}
{"step": 269528, "time": 8786.29400229454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269624, "time": 8789.248517990112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269640, "time": 8789.74318099022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269744, "time": 8793.1506960392, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 269976, "time": 8800.14132475853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270024, "time": 8801.609842777252, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 8805.839096546173, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 270088, "time": 8810.90351510048, "eval_episode/length": 273.0, "eval_episode/score": 0.14687499403953552, "eval_episode/reward_rate": 0.0036496350364963502}
{"step": 270088, "time": 8811.223476171494, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8811.231410741806, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8811.238530397415, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8811.245525121689, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8811.253323793411, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8811.260447978973, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270136, "time": 8812.718363046646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270272, "time": 8817.082528352737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270936, "time": 8837.70089173317, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 270984, "time": 8839.165913820267, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 271496, "time": 8854.844958543777, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 271560, "time": 8856.810992002487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271840, "time": 8865.725043535233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271936, "time": 8868.669473648071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272288, "time": 8879.472493171692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272336, "time": 8880.944812774658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272400, "time": 8882.892620801926, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 272448, "time": 8884.379573583603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273248, "time": 8908.983548402786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273808, "time": 8926.249487638474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 273832, "time": 8926.773214578629, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 274216, "time": 8938.542492628098, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 274248, "time": 8939.526589870453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274600, "time": 8950.354853868484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274648, "time": 8951.819968223572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274712, "time": 8953.791229724884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275080, "time": 8965.036161661148, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 275144, "time": 8966.985437393188, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 275208, "time": 8968.970907211304, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 275328, "time": 8972.86402130127, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 275400, "time": 8974.84239935875, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 275560, "time": 8979.878898859024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276120, "time": 8997.019342660904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276144, "time": 8997.983455896378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276528, "time": 9009.830203056335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277392, "time": 9036.291632413864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277520, "time": 9040.266799211502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277640, "time": 9043.725487470627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277712, "time": 9046.160498380661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 277744, "time": 9047.135812282562, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 277872, "time": 9051.057622909546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278152, "time": 9059.389569044113, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 278432, "time": 9068.182267904282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278456, "time": 9068.819304704666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278840, "time": 9081.06560087204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 279904, "time": 9113.964519500732, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 279952, "time": 9115.447174549103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280024, "time": 9117.431723594666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280056, "time": 9118.425909519196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 9119.43041062355, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 280072, "time": 9120.178365468979, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 280072, "time": 9124.997661113739, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9125.006858825684, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9125.015990495682, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9125.024158239365, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9125.032460451126, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9125.04029917717, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280184, "time": 9128.612037181854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280384, "time": 9134.937742948532, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 280464, "time": 9137.392815113068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280688, "time": 9144.220614910126, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 280744, "time": 9145.697588205338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280768, "time": 9146.674347639084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 281384, "time": 9165.313324689865, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 281408, "time": 9166.292513132095, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 281416, "time": 9166.322931289673, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 281416, "time": 9166.332043886185, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 281432, "time": 9166.825369596481, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 282264, "time": 9192.301662445068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282696, "time": 9205.510173082352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 282776, "time": 9207.96220421791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283696, "time": 9236.429235696793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283720, "time": 9236.949739933014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283728, "time": 9237.434657096863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283728, "time": 9237.446934700012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283744, "time": 9237.95496892929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284576, "time": 9263.503158330917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285008, "time": 9276.738066911697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 285017, "time": 9277.77852320671, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.517720131418813, "train/action_min": 0.0, "train/action_std": 1.7949013182865314, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0019678375707124947, "train/actor_opt_grad_steps": 16720.0, "train/actor_opt_loss": 10.354752783818011, "train/adv_mag": 0.01693568839200178, "train/adv_max": 0.016606078001122977, "train/adv_mean": 0.00230163227986201, "train/adv_min": -0.004819802041329331, "train/adv_std": 0.002531319590467941, "train/cont_avg": 0.9962409704773869, "train/cont_loss_mean": 0.0247647094542638, "train/cont_loss_std": 0.3354755421403103, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.632329880589187, "train/cont_pos_acc": 0.9999999823282711, "train/cont_pos_loss": 0.0036084724522322115, "train/cont_pred": 0.9963981095869937, "train/cont_rate": 0.9962409704773869, "train/dyn_loss_mean": 1.0000218668175702, "train/dyn_loss_std": 0.00016842744711785925, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16738093030713874, "train/extr_critic_critic_opt_grad_steps": 16720.0, "train/extr_critic_critic_opt_loss": 11564.559585034547, "train/extr_critic_mag": 0.1104860072159887, "train/extr_critic_max": 0.1104860072159887, "train/extr_critic_mean": 0.10706822896123531, "train/extr_critic_min": 0.10294528402874817, "train/extr_critic_std": 0.0013394221793930398, "train/extr_return_normed_mag": 0.02439775752212534, "train/extr_return_normed_max": 0.024384855999419437, "train/extr_return_normed_mean": 0.008742032545716993, "train/extr_return_normed_min": 0.0019453866922076624, "train/extr_return_normed_std": 0.003006813153811735, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.1250126652007726, "train/extr_return_raw_max": 0.1250126652007726, "train/extr_return_raw_mean": 0.10936984685647427, "train/extr_return_raw_min": 0.10257319593100092, "train/extr_return_raw_std": 0.00300681316638927, "train/extr_reward_mag": 0.014132547618156702, "train/extr_reward_max": 0.014132547618156702, "train/extr_reward_mean": 0.0006619230843989041, "train/extr_reward_min": 2.58186953750687e-06, "train/extr_reward_std": 0.001724915440370833, "train/image_loss_mean": 0.17078149857832559, "train/image_loss_std": 0.106861053324824, "train/model_loss_mean": 0.7973305750731847, "train/model_loss_std": 0.3847988261724237, "train/model_opt_grad_norm": 35.30719958837308, "train/model_opt_grad_steps": 16702.613065326634, "train/model_opt_loss": 2054.2233162884736, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2575.3768844221104, "train/policy_entropy_mag": 1.805879952919543, "train/policy_entropy_max": 1.805879952919543, "train/policy_entropy_mean": 1.0389247949997984, "train/policy_entropy_min": 0.09235986172404122, "train/policy_entropy_std": 0.378459328532818, "train/policy_logprob_mag": 6.307712964676133, "train/policy_logprob_max": -0.013636704361131742, "train/policy_logprob_mean": -1.0388290801239972, "train/policy_logprob_min": -6.307712964676133, "train/policy_logprob_std": 0.9686263470194447, "train/policy_randomness_mag": 0.9280387696309306, "train/policy_randomness_max": 0.9280387696309306, "train/policy_randomness_mean": 0.5339017580801518, "train/policy_randomness_min": 0.0474635826695205, "train/policy_randomness_std": 0.19448963335560793, "train/post_ent_mag": 101.115046822246, "train/post_ent_max": 101.115046822246, "train/post_ent_mean": 100.73127945943095, "train/post_ent_min": 100.33104855331344, "train/post_ent_std": 0.13592590511444225, "train/prior_ent_mag": 103.118878005138, "train/prior_ent_max": 103.118878005138, "train/prior_ent_mean": 101.25553947717101, "train/prior_ent_min": 98.90098886154405, "train/prior_ent_std": 0.7614936208605168, "train/rep_loss_mean": 1.0000218668175702, "train/rep_loss_std": 0.00016842744711785925, "train/reward_avg": 0.00011535337811684582, "train/reward_loss_mean": 0.0017712283692317991, "train/reward_loss_std": 0.04497520174410609, "train/reward_max_data": 0.10687814083830197, "train/reward_max_pred": 0.006790630182429175, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00027899257431967107, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.900082574950324, "train/reward_pred": 0.00010048251028111832, "train/reward_rate": 0.0002110160175879397, "train_stats/mean_log_entropy": 1.0297583158369417, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.04245094954967499, "report/cont_loss_std": 0.4730452597141266, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.744278430938721, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0032053454779088497, "report/cont_pred": 0.9967997074127197, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1356925368309021, "report/image_loss_std": 0.10196471214294434, "report/model_loss_mean": 0.7915477156639099, "report/model_loss_std": 0.6976805329322815, "report/post_ent_mag": 102.38052368164062, "report/post_ent_max": 102.38052368164062, "report/post_ent_mean": 101.96958923339844, "report/post_ent_min": 101.53816223144531, "report/post_ent_std": 0.16890698671340942, "report/prior_ent_mag": 105.16714477539062, "report/prior_ent_max": 105.16714477539062, "report/prior_ent_mean": 103.2320556640625, "report/prior_ent_min": 100.75999450683594, "report/prior_ent_std": 0.7927444577217102, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0011962890857830644, "report/reward_loss_mean": 0.013404199853539467, "report/reward_loss_std": 0.3011881709098816, "report/reward_max_data": 0.6875, "report/reward_max_pred": 0.005865931510925293, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0002362406230531633, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.742231369018555, "report/reward_pred": 0.00010919268243014812, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020023247227072716, "eval/cont_loss_std": 0.31027916073799133, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.7440924644470215, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0032042423263192177, "eval/cont_pred": 0.9968007802963257, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0000733137130737, "eval/dyn_loss_std": 0.0023438804782927036, "eval/image_loss_mean": 0.1932440996170044, "eval/image_loss_std": 0.11757902055978775, "eval/model_loss_mean": 0.813408613204956, "eval/model_loss_std": 0.33700186014175415, "eval/post_ent_mag": 102.36640930175781, "eval/post_ent_max": 102.36640930175781, "eval/post_ent_mean": 101.92498779296875, "eval/post_ent_min": 101.46476745605469, "eval/post_ent_std": 0.17260350286960602, "eval/prior_ent_mag": 105.27658081054688, "eval/prior_ent_max": 105.27658081054688, "eval/prior_ent_mean": 103.39117431640625, "eval/prior_ent_min": 100.85795593261719, "eval/prior_ent_std": 0.7222799062728882, "eval/rep_loss_mean": 1.0000733137130737, "eval/rep_loss_std": 0.0023438804782927036, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 9.727757424116135e-05, "eval/reward_loss_std": 0.00040069042006507516, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.002301931381225586, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 9.727757424116135e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.271895159035921e-05, "eval/reward_rate": 0.0, "replay/size": 284513.0, "replay/inserts": 31824.0, "replay/samples": 31824.0, "replay/insert_wait_avg": 1.4535112558386924e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.809362200530346e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 68104.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3204800628873303e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0074646472931, "timer/env.step_count": 3978.0, "timer/env.step_total": 40.267608642578125, "timer/env.step_frac": 0.04026730806132601, "timer/env.step_avg": 0.010122576330462072, "timer/env.step_min": 0.008649349212646484, "timer/env.step_max": 0.06632733345031738, "timer/replay._sample_count": 31824.0, "timer/replay._sample_total": 16.822418212890625, "timer/replay._sample_frac": 0.0168222926404094, "timer/replay._sample_avg": 0.0005286079126725309, "timer/replay._sample_min": 0.0003616809844970703, "timer/replay._sample_max": 0.011759519577026367, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4845.0, "timer/agent.policy_total": 54.499573707580566, "timer/agent.policy_frac": 0.05449916689052196, "timer/agent.policy_avg": 0.011248622024268434, "timer/agent.policy_min": 0.009126424789428711, "timer/agent.policy_max": 0.9619176387786865, "timer/dataset_train_count": 1989.0, "timer/dataset_train_total": 0.23980331420898438, "timer/dataset_train_frac": 0.00023980152417518607, "timer/dataset_train_avg": 0.0001205647633026568, "timer/dataset_train_min": 0.00010585784912109375, "timer/dataset_train_max": 0.0010700225830078125, "timer/agent.train_count": 1989.0, "timer/agent.train_total": 889.6503789424896, "timer/agent.train_frac": 0.8896437380657685, "timer/agent.train_avg": 0.447285258392403, "timer/agent.train_min": 0.4372079372406006, "timer/agent.train_max": 0.7079799175262451, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48017406463623047, "timer/agent.report_frac": 0.0004801704803329542, "timer/agent.report_avg": 0.24008703231811523, "timer/agent.report_min": 0.23336458206176758, "timer/agent.report_max": 0.2468094825744629, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.124641418457031e-05, "timer/dataset_eval_frac": 4.124610629693459e-08, "timer/dataset_eval_avg": 4.124641418457031e-05, "timer/dataset_eval_min": 4.124641418457031e-05, "timer/dataset_eval_max": 4.124641418457031e-05, "fps": 31.823198764500827}
{"step": 285088, "time": 9280.14762878418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286008, "time": 9308.172459363937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286032, "time": 9309.259893655777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286040, "time": 9309.290284872055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286040, "time": 9309.299329519272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286056, "time": 9309.80390548706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286888, "time": 9336.066091775894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287320, "time": 9349.589150428772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287400, "time": 9352.05994772911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288320, "time": 9380.731255054474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288344, "time": 9381.251432180405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288352, "time": 9381.724961042404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288352, "time": 9381.734138965607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288368, "time": 9382.231633424759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288992, "time": 9401.553549051285, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 289200, "time": 9407.9530107975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289632, "time": 9421.262551546097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289712, "time": 9423.754101276398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289768, "time": 9425.256734848022, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 290024, "time": 9433.273941516876, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 9435.778801202774, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 290056, "time": 9436.185120821, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 290056, "time": 9440.477546215057, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9440.48604464531, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9440.493998527527, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9440.501522064209, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9440.509020805359, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9440.51653599739, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9440.52423286438, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290320, "time": 9448.851876735687, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 290632, "time": 9458.280225753784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290632, "time": 9458.290651798248, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 290656, "time": 9459.330165863037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290680, "time": 9459.868497133255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291040, "time": 9471.150768756866, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 291304, "time": 9479.004644870758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291512, "time": 9485.384457826614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292024, "time": 9501.178642749786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292336, "time": 9510.971498250961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292944, "time": 9529.73182964325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292944, "time": 9529.741418123245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292968, "time": 9530.260565757751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293352, "time": 9542.004075288773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293528, "time": 9547.38091301918, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 293584, "time": 9549.42318534851, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 293616, "time": 9550.405743598938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 293760, "time": 9554.819310426712, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 293824, "time": 9556.774408578873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294264, "time": 9570.103209495544, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 294288, "time": 9571.070341825485, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 294336, "time": 9572.548381090164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294648, "time": 9582.008901119232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295000, "time": 9593.349792718887, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 295040, "time": 9594.797620534897, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 295072, "time": 9595.782268285751, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 295112, "time": 9596.790974855423, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 295192, "time": 9599.260811805725, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 295280, "time": 9602.17888712883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295624, "time": 9612.605770349503, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 295928, "time": 9621.95887708664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 295952, "time": 9622.933243989944, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 295952, "time": 9622.941709518433, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 296072, "time": 9626.381132125854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296592, "time": 9642.722979545593, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 297120, "time": 9658.941259145737, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 297368, "time": 9666.315600633621, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 297384, "time": 9666.814154148102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297424, "time": 9668.293026685715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297592, "time": 9673.315682649612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297848, "time": 9681.144966840744, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 298240, "time": 9693.414677619934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298264, "time": 9693.93468618393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298384, "time": 9697.854318141937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298400, "time": 9698.381429672241, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 298696, "time": 9707.285888671875, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 298744, "time": 9708.752593755722, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 298904, "time": 9713.69652557373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298992, "time": 9716.63700413704, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 299056, "time": 9718.605249881744, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 299224, "time": 9723.522934675217, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 299328, "time": 9726.937381505966, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 299680, "time": 9737.746686220169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 299904, "time": 9744.552098751068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 9749.974869966507, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 300040, "time": 9750.065732002258, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 300040, "time": 9750.221081972122, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 300040, "time": 9750.759170293808, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 300040, "time": 9750.85050368309, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 300040, "time": 9751.206450462341, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 300040, "time": 9752.364298343658, "eval_episode/length": 179.0, "eval_episode/score": 0.44062501192092896, "eval_episode/reward_rate": 0.005555555555555556}
{"step": 300040, "time": 9752.45581626892, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 300648, "time": 9771.18453669548, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 300696, "time": 9772.647411346436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301216, "time": 9788.806938171387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301304, "time": 9791.283972263336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301368, "time": 9793.245710611343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301536, "time": 9798.595859766006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301640, "time": 9801.573095560074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301800, "time": 9806.458502292633, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 302216, "time": 9819.296309232712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302952, "time": 9841.773393630981, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 302960, "time": 9842.250838756561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303008, "time": 9843.742061138153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303296, "time": 9853.153673648834, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 303616, "time": 9862.922905921936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303680, "time": 9864.902020931244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303712, "time": 9865.878857135773, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 303944, "time": 9872.768525362015, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 304112, "time": 9878.159119606018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304152, "time": 9879.294640779495, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 304368, "time": 9886.13242650032, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 304432, "time": 9888.108676195145, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 305136, "time": 9909.712788820267, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 305256, "time": 9913.15672159195, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 305264, "time": 9913.627187728882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305504, "time": 9920.949989080429, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 305560, "time": 9922.45359992981, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 305696, "time": 9926.818731069565, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 305928, "time": 9933.690754652023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305976, "time": 9935.152533769608, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 306024, "time": 9936.617850065231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306144, "time": 9940.626811981201, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 306408, "time": 9948.479442596436, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 306744, "time": 9958.79763174057, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 306848, "time": 9962.235816955566, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 306992, "time": 9966.660118341446, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 307096, "time": 9969.743886232376, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 307576, "time": 9984.4803378582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307616, "time": 9985.940831184387, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 307688, "time": 9987.957087039948, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 307936, "time": 9995.829370737076, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 308264, "time": 10005.804502248764, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 308432, "time": 10011.185093641281, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 308640, "time": 10017.549029111862, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 308640, "time": 10017.556768417358, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 308720, "time": 10020.005500078201, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308744, "time": 10020.521371603012, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 309136, "time": 10032.801039457321, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 309168, "time": 10033.777224779129, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 309304, "time": 10037.727605581284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 309696, "time": 10049.96596622467, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 310000, "time": 10059.365282773972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 10061.871716022491, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 310024, "time": 10062.774107933044, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 310024, "time": 10065.018282413483, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 310024, "time": 10066.432096719742, "eval_episode/length": 279.0, "eval_episode/score": 0.12812499701976776, "eval_episode/reward_rate": 0.0035714285714285713}
{"step": 310024, "time": 10066.629256010056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10066.638228178024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10066.645776510239, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10066.653143167496, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10066.660658836365, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310456, "time": 10079.80406665802, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 310576, "time": 10083.717482566833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310952, "time": 10095.120995759964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311032, "time": 10097.60888004303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311448, "time": 10110.853668928146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311480, "time": 10111.85664844513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311688, "time": 10118.263850927353, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 312312, "time": 10137.534617424011, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312392, "time": 10140.013556718826, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 312480, "time": 10142.95208120346, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 313264, "time": 10167.12194943428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313344, "time": 10169.58942270279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313760, "time": 10182.433824062347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313792, "time": 10183.429187297821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314000, "time": 10189.755192995071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314008, "time": 10189.785953044891, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 314704, "time": 10211.329615354538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 314792, "time": 10213.788876056671, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315576, "time": 10237.722776889801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315656, "time": 10240.29996919632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316064, "time": 10253.0278236866, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 316072, "time": 10253.058782339096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316104, "time": 10254.043528079987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316320, "time": 10260.861634016037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316400, "time": 10263.315809249878, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 316712, "time": 10272.718461036682, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 316857, "time": 10278.127263307571, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3880765521945664, "train/action_min": 0.0, "train/action_std": 1.6345298511898099, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0027165992677459804, "train/actor_opt_grad_steps": 18710.0, "train/actor_opt_loss": 15.73290376432577, "train/adv_mag": 0.03403779969143508, "train/adv_max": 0.026464554008527017, "train/adv_mean": 0.004490373156086984, "train/adv_min": -0.017179812393595825, "train/adv_std": 0.004418871158397003, "train/cont_avg": 0.9963243954145728, "train/cont_loss_mean": 0.023979848058866198, "train/cont_loss_std": 0.32359257482507997, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.525613033041662, "train/cont_pos_acc": 0.9999950743799833, "train/cont_pos_loss": 0.003717939723891454, "train/cont_pred": 0.996290643610547, "train/cont_rate": 0.9963243954145728, "train/dyn_loss_mean": 1.0000073047139537, "train/dyn_loss_std": 0.0002136962871030956, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.331189395653917, "train/extr_critic_critic_opt_grad_steps": 18710.0, "train/extr_critic_critic_opt_loss": 9688.767461268746, "train/extr_critic_mag": 0.23899654587309563, "train/extr_critic_max": 0.23899654587309563, "train/extr_critic_mean": 0.23160323216088452, "train/extr_critic_min": 0.2194791570979746, "train/extr_critic_std": 0.0030732055522423077, "train/extr_return_normed_mag": 0.046945532362664764, "train/extr_return_normed_max": 0.040698247039737415, "train/extr_return_normed_mean": 0.015308271003822708, "train/extr_return_normed_min": -0.006582421947963274, "train/extr_return_normed_std": 0.005607972333404287, "train/extr_return_rate": 3.7950171092197526e-05, "train/extr_return_raw_mag": 0.2614835458784247, "train/extr_return_raw_max": 0.2614835458784247, "train/extr_return_raw_mean": 0.23609358177113174, "train/extr_return_raw_min": 0.21420287689072404, "train/extr_return_raw_std": 0.005607972339254304, "train/extr_reward_mag": 0.02403370878804269, "train/extr_reward_max": 0.02403370878804269, "train/extr_reward_mean": 0.0013417731745323008, "train/extr_reward_min": -4.205272425359218e-07, "train/extr_reward_std": 0.0035173072202959515, "train/image_loss_mean": 0.15601316521215677, "train/image_loss_std": 0.10790231296015744, "train/model_loss_mean": 0.7832093385595772, "train/model_loss_std": 0.39614145450256577, "train/model_opt_grad_norm": 32.91968240210758, "train/model_opt_grad_steps": 18691.070351758794, "train/model_opt_loss": 2812.8091458267904, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3592.964824120603, "train/policy_entropy_mag": 1.7768057099538832, "train/policy_entropy_max": 1.7768057099538832, "train/policy_entropy_mean": 0.5576338434039648, "train/policy_entropy_min": 0.06495608119808849, "train/policy_entropy_std": 0.39110238483203713, "train/policy_logprob_mag": 6.54851132301829, "train/policy_logprob_max": -0.008650166459905741, "train/policy_logprob_mean": -0.5586275380460461, "train/policy_logprob_min": -6.54851132301829, "train/policy_logprob_std": 0.9494367981675881, "train/policy_randomness_mag": 0.9130975631014187, "train/policy_randomness_max": 0.9130975631014187, "train/policy_randomness_mean": 0.28656712324176004, "train/policy_randomness_min": 0.033380824567085535, "train/policy_randomness_std": 0.2009868783567419, "train/post_ent_mag": 102.9641522354816, "train/post_ent_max": 102.9641522354816, "train/post_ent_mean": 102.43058838197334, "train/post_ent_min": 101.88246515168616, "train/post_ent_std": 0.1943380327979524, "train/prior_ent_mag": 104.99756024231263, "train/prior_ent_max": 104.99756024231263, "train/prior_ent_mean": 103.36101221439228, "train/prior_ent_min": 101.25326292718475, "train/prior_ent_std": 0.6444899092367546, "train/rep_loss_mean": 1.0000073047139537, "train/rep_loss_std": 0.0002136962871030956, "train/reward_avg": 0.00026012018186785516, "train/reward_loss_mean": 0.0032119191913916986, "train/reward_loss_std": 0.08001729879287263, "train/reward_max_data": 0.22773241251707077, "train/reward_max_pred": 0.011184271256528308, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0004508055691126425, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.085587530522733, "train/reward_pred": 0.00018537044408146162, "train/reward_rate": 0.0004563834798994975, "train_stats/mean_log_entropy": 0.5145910619110461, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.028534244745969772, "report/cont_loss_std": 0.3478657305240631, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.873164653778076, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004762751515954733, "report/cont_pred": 0.9952062964439392, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1805953085422516, "report/image_loss_std": 0.11537669599056244, "report/model_loss_mean": 0.8197269439697266, "report/model_loss_std": 0.5197180509567261, "report/post_ent_mag": 103.05059814453125, "report/post_ent_max": 103.05059814453125, "report/post_ent_mean": 102.4554443359375, "report/post_ent_min": 101.73529815673828, "report/post_ent_std": 0.22872430086135864, "report/prior_ent_mag": 104.94526672363281, "report/prior_ent_max": 104.94526672363281, "report/prior_ent_mean": 103.06268310546875, "report/prior_ent_min": 100.76083374023438, "report/prior_ent_std": 0.6939899921417236, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007263183942995965, "report/reward_loss_mean": 0.010597335174679756, "report/reward_loss_std": 0.22711871564388275, "report/reward_max_data": 0.5062500238418579, "report/reward_max_pred": 0.022276878356933594, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005798825295642018, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.129515647888184, "report/reward_pred": 0.0002717413008213043, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.042337991297245026, "eval/cont_loss_std": 0.4558240473270416, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.515264511108398, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.004667898640036583, "eval/cont_pred": 0.9953462481498718, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2084057331085205, "eval/image_loss_std": 0.10764846205711365, "eval/model_loss_mean": 0.8601455688476562, "eval/model_loss_std": 0.6296516060829163, "eval/post_ent_mag": 103.05213928222656, "eval/post_ent_max": 103.05213928222656, "eval/post_ent_mean": 102.42544555664062, "eval/post_ent_min": 101.85493469238281, "eval/post_ent_std": 0.21798330545425415, "eval/prior_ent_mag": 104.843994140625, "eval/prior_ent_max": 104.843994140625, "eval/prior_ent_mean": 103.06744384765625, "eval/prior_ent_min": 101.17568969726562, "eval/prior_ent_std": 0.7079699039459229, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0008911133045330644, "eval/reward_loss_mean": 0.009401833638548851, "eval/reward_loss_std": 0.29276174306869507, "eval/reward_max_data": 0.9125000238418579, "eval/reward_max_pred": 0.014106035232543945, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00024868291802704334, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.373074531555176, "eval/reward_pred": 0.00010341079905629158, "eval/reward_rate": 0.0009765625, "replay/size": 316353.0, "replay/inserts": 31840.0, "replay/samples": 31840.0, "replay/insert_wait_avg": 1.4827853471190487e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.026933550235614e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 74200.0, "eval_replay/inserts": 6096.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.338053876020777e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2218952178955078e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3288440704346, "timer/env.step_count": 3980.0, "timer/env.step_total": 40.82461953163147, "timer/env.step_frac": 0.040811199010829434, "timer/env.step_avg": 0.01025744209337474, "timer/env.step_min": 0.008890867233276367, "timer/env.step_max": 0.049021244049072266, "timer/replay._sample_count": 31840.0, "timer/replay._sample_total": 16.902714490890503, "timer/replay._sample_frac": 0.016897157960687935, "timer/replay._sample_avg": 0.0005308641485832445, "timer/replay._sample_min": 0.00039124488830566406, "timer/replay._sample_max": 0.032424211502075195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4742.0, "timer/agent.policy_total": 53.46223258972168, "timer/agent.policy_frac": 0.05344465763096333, "timer/agent.policy_avg": 0.01127419497885316, "timer/agent.policy_min": 0.00915384292602539, "timer/agent.policy_max": 0.09005856513977051, "timer/dataset_train_count": 1990.0, "timer/dataset_train_total": 0.24251604080200195, "timer/dataset_train_frac": 0.00024243631705667985, "timer/dataset_train_avg": 0.00012186735718693566, "timer/dataset_train_min": 0.00010585784912109375, "timer/dataset_train_max": 0.0010838508605957031, "timer/agent.train_count": 1990.0, "timer/agent.train_total": 891.3433136940002, "timer/agent.train_frac": 0.8910502970873441, "timer/agent.train_avg": 0.4479112129115579, "timer/agent.train_min": 0.43642163276672363, "timer/agent.train_max": 0.7271585464477539, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48504161834716797, "timer/agent.report_frac": 0.0004848821677214533, "timer/agent.report_avg": 0.24252080917358398, "timer/agent.report_min": 0.23485231399536133, "timer/agent.report_max": 0.25018930435180664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.9577484130859375e-05, "timer/dataset_eval_frac": 3.956447358831999e-08, "timer/dataset_eval_avg": 3.9577484130859375e-05, "timer/dataset_eval_min": 3.9577484130859375e-05, "timer/dataset_eval_max": 3.9577484130859375e-05, "fps": 31.828969610261158}
{"step": 316880, "time": 10278.805312871933, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 316920, "time": 10279.960724115372, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 317016, "time": 10282.883387088776, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 317016, "time": 10282.892994642258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317192, "time": 10288.290689229965, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 317272, "time": 10290.774784088135, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 317760, "time": 10306.157114744186, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 317784, "time": 10306.676584720612, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 317888, "time": 10310.098546028137, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 317944, "time": 10311.592589378357, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 318296, "time": 10322.389153242111, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 319208, "time": 10350.467451810837, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 319256, "time": 10351.93343448639, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 319328, "time": 10354.36562204361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319504, "time": 10360.396938085556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319584, "time": 10362.857488393784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319688, "time": 10365.83977985382, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 319920, "time": 10373.135371208191, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 10377.502855062485, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 320008, "time": 10377.572459697723, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 320008, "time": 10377.721413850784, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 320008, "time": 10378.846534967422, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 320008, "time": 10379.26437830925, "eval_episode/length": 169.0, "eval_episode/score": 0.47187501192092896, "eval_episode/reward_rate": 0.0058823529411764705}
{"step": 320008, "time": 10379.41977763176, "eval_episode/length": 176.0, "eval_episode/score": 0.44999998807907104, "eval_episode/reward_rate": 0.005649717514124294}
{"step": 320008, "time": 10379.920050621033, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 320008, "time": 10380.214432477951, "eval_episode/length": 213.0, "eval_episode/score": 0.3343749940395355, "eval_episode/reward_rate": 0.004672897196261682}
{"step": 320048, "time": 10381.657163143158, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 320064, "time": 10382.152883052826, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 320096, "time": 10383.134189367294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320152, "time": 10384.638460159302, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 320344, "time": 10390.616543769836, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 320544, "time": 10396.92744922638, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 320608, "time": 10398.91673707962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320680, "time": 10400.887686252594, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 320880, "time": 10407.211974859238, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 321344, "time": 10421.437781572342, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 321392, "time": 10422.931491851807, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 321440, "time": 10424.384957551956, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 321456, "time": 10424.877446174622, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 321712, "time": 10432.698376655579, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 321736, "time": 10433.212813138962, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 322064, "time": 10443.453294992447, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 322120, "time": 10444.9371612072, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 322296, "time": 10450.423661470413, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 322320, "time": 10451.37456035614, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 322432, "time": 10454.79122042656, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 322944, "time": 10470.418003797531, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 322992, "time": 10471.906394004822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323104, "time": 10475.315878152847, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 323184, "time": 10477.783025979996, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 323656, "time": 10492.043246746063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323952, "time": 10501.297874450684, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 323976, "time": 10501.820005178452, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 324024, "time": 10503.281398773193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324224, "time": 10509.714441537857, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 324592, "time": 10520.968045711517, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 324608, "time": 10521.462162971497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324616, "time": 10521.492342948914, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 324632, "time": 10521.987519741058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324736, "time": 10525.367500543594, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 324792, "time": 10526.876725196838, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 325208, "time": 10539.673660516739, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 325256, "time": 10541.155004739761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325264, "time": 10541.62674331665, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 325280, "time": 10542.127953529358, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 325704, "time": 10554.812391996384, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 325792, "time": 10557.741866111755, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 326312, "time": 10573.550923585892, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 326536, "time": 10580.431471586227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326768, "time": 10587.744341611862, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 326904, "time": 10591.708832263947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327048, "time": 10596.147149324417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327104, "time": 10598.089507579803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327176, "time": 10600.2100315094, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 327192, "time": 10600.710285425186, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 327520, "time": 10611.024151802063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327576, "time": 10612.521956920624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327944, "time": 10624.325964450836, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 328104, "time": 10629.360305309296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328992, "time": 10656.833456516266, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 329176, "time": 10662.346248149872, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 329288, "time": 10665.799316167831, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 329488, "time": 10672.152071237564, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 329488, "time": 10672.16194844246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329552, "time": 10674.138417243958, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 329624, "time": 10676.12538433075, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 329656, "time": 10677.113491773605, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 329832, "time": 10682.502160310745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 10692.77636051178, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 330096, "time": 10693.436469554901, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 330096, "time": 10694.21983551979, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 330096, "time": 10694.421397686005, "eval_episode/length": 163.0, "eval_episode/score": 0.4906249940395355, "eval_episode/reward_rate": 0.006097560975609756}
{"step": 330096, "time": 10696.286511421204, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 330096, "time": 10697.08827328682, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10697.096838235855, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10697.104820728302, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10697.112706184387, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330416, "time": 10706.875322341919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330576, "time": 10711.778541564941, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 331600, "time": 10743.209468364716, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 331800, "time": 10749.217982053757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331800, "time": 10749.227936267853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331864, "time": 10751.181355953217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331936, "time": 10753.580788135529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331968, "time": 10754.582003831863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332144, "time": 10759.961894273758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332248, "time": 10762.910353899002, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 332720, "time": 10777.518379211426, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 332760, "time": 10778.681311368942, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 332888, "time": 10782.58879685402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333096, "time": 10788.961468219757, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 333384, "time": 10797.754339694977, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 334112, "time": 10820.425330638885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334176, "time": 10822.388664722443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334280, "time": 10825.36483001709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334392, "time": 10828.797526597977, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 334560, "time": 10834.160721540451, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 334560, "time": 10834.170047044754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334792, "time": 10841.135305643082, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 335032, "time": 10848.504197835922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335072, "time": 10849.973799228668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335200, "time": 10853.89340186119, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 335200, "time": 10853.903113126755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335560, "time": 10864.705441713333, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 335696, "time": 10869.224555253983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336024, "time": 10879.559398889542, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 336072, "time": 10881.025914430618, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 336168, "time": 10883.982666492462, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 336272, "time": 10887.388444423676, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 336752, "time": 10902.11015510559, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 336792, "time": 10903.111394405365, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 336872, "time": 10905.598982572556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337344, "time": 10920.355700731277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337808, "time": 10934.667356491089, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 338008, "time": 10940.676100492477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338016, "time": 10941.149461746216, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 338472, "time": 10954.97125005722, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 338480, "time": 10955.443045854568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338584, "time": 10958.530642747879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339064, "time": 10973.24216222763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339104, "time": 10974.68978190422, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 339104, "time": 10974.69907283783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339184, "time": 10977.154952287674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339536, "time": 10987.906859397888, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 339720, "time": 10993.40521812439, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 340040, "time": 11003.202863454819, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 11005.064385414124, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 340080, "time": 11005.452880620956, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 340080, "time": 11006.335395336151, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 340080, "time": 11006.363513231277, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 340080, "time": 11006.455694675446, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 340080, "time": 11006.54756808281, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 340080, "time": 11006.95346069336, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 340080, "time": 11007.238087654114, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 340320, "time": 11014.59892630577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340328, "time": 11014.630722522736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340704, "time": 11026.483746767044, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 340792, "time": 11028.98107099533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340896, "time": 11032.370944023132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341488, "time": 11050.634666442871, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 341496, "time": 11050.66708946228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341632, "time": 11055.043474435806, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 341744, "time": 11058.482012987137, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 341920, "time": 11063.847244262695, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 342000, "time": 11066.285009860992, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 342032, "time": 11067.292618751526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342352, "time": 11077.047416210175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342472, "time": 11080.626085281372, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 342504, "time": 11081.603605508804, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 342672, "time": 11086.977558374405, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 342688, "time": 11087.4692299366, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 342920, "time": 11094.365720272064, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 343104, "time": 11100.236525774002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343376, "time": 11108.657205820084, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 343392, "time": 11109.150792360306, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 343744, "time": 11119.908639431, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 343800, "time": 11121.462630748749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344344, "time": 11138.737303495407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344392, "time": 11140.206363677979, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 344488, "time": 11143.166855812073, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 344784, "time": 11152.48842215538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345176, "time": 11164.285210847855, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 345232, "time": 11166.247835636139, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345248, "time": 11166.748272895813, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 345392, "time": 11171.28730893135, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 345416, "time": 11171.810235261917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345688, "time": 11180.17458987236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345704, "time": 11180.691784381866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346824, "time": 11215.108855724335, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 346856, "time": 11216.116154432297, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 346920, "time": 11218.084945678711, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 346936, "time": 11218.581476449966, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 347008, "time": 11221.026587486267, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 347144, "time": 11224.962363958359, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 347280, "time": 11229.476822376251, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 347544, "time": 11237.336993694305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347704, "time": 11242.264512777328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 347728, "time": 11243.223965168, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 347992, "time": 11251.119524478912, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 348016, "time": 11252.084529876709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348096, "time": 11254.545998334885, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 348841, "time": 11278.318140506744, "train_stats/mean_log_entropy": 0.3397302854467522, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.70602783203125, "train/action_min": 0.0, "train/action_std": 1.8737485700845717, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0034443356527481227, "train/actor_opt_grad_steps": 20705.0, "train/actor_opt_loss": 15.647017102688551, "train/adv_mag": 0.055862255841493604, "train/adv_max": 0.04336101830005646, "train/adv_mean": 0.006290680310407879, "train/adv_min": -0.027870801389217378, "train/adv_std": 0.006464497187407687, "train/cont_avg": 0.9962158203125, "train/cont_loss_mean": 0.023836550149135292, "train/cont_loss_std": 0.31740414017695, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.319209159328247, "train/cont_pos_acc": 0.9999999809265137, "train/cont_pos_loss": 0.0038591471710242332, "train/cont_pred": 0.9961413830518723, "train/cont_rate": 0.9962158203125, "train/dyn_loss_mean": 1.0000118863582612, "train/dyn_loss_std": 0.0003291869276472426, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4794829722121358, "train/extr_critic_critic_opt_grad_steps": 20705.0, "train/extr_critic_critic_opt_loss": 9913.584215698242, "train/extr_critic_mag": 0.4274871736764908, "train/extr_critic_max": 0.4274871736764908, "train/extr_critic_mean": 0.41726436525583266, "train/extr_critic_min": 0.40542240500450133, "train/extr_critic_std": 0.0040380709117744116, "train/extr_return_normed_mag": 0.073691386282444, "train/extr_return_normed_max": 0.0633700942993164, "train/extr_return_normed_mean": 0.02129603773530107, "train/extr_return_normed_min": -0.011862774193286896, "train/extr_return_normed_std": 0.007889920977177098, "train/extr_return_rate": 0.12404264789747685, "train/extr_return_raw_mag": 0.46562906101346013, "train/extr_return_raw_max": 0.46562906101346013, "train/extr_return_raw_mean": 0.42355502232909203, "train/extr_return_raw_min": 0.39039619252085683, "train/extr_return_raw_std": 0.007889920964371413, "train/extr_reward_mag": 0.04213482141494751, "train/extr_reward_max": 0.04213482141494751, "train/extr_reward_mean": 0.002048769461689517, "train/extr_reward_min": -4.725039005279541e-05, "train/extr_reward_std": 0.005469572253059596, "train/image_loss_mean": 0.14440259985625745, "train/image_loss_std": 0.10906259063631296, "train/model_loss_mean": 0.7722754257917405, "train/model_loss_std": 0.39755320504307745, "train/model_opt_grad_norm": 30.978323693275453, "train/model_opt_grad_steps": 20683.945, "train/model_opt_loss": 2316.00158203125, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3000.0, "train/policy_entropy_mag": 1.7200665897130967, "train/policy_entropy_max": 1.7200665897130967, "train/policy_entropy_mean": 0.38629932679235934, "train/policy_entropy_min": 0.06472289685159921, "train/policy_entropy_std": 0.34213839039206506, "train/policy_logprob_mag": 6.550906167030335, "train/policy_logprob_max": -0.008613961380906403, "train/policy_logprob_mean": -0.3859055545926094, "train/policy_logprob_min": -6.550906167030335, "train/policy_logprob_std": 0.8439447569847107, "train/policy_randomness_mag": 0.8839394202828408, "train/policy_randomness_max": 0.8839394202828408, "train/policy_randomness_mean": 0.198518595546484, "train/policy_randomness_min": 0.03326099142432213, "train/policy_randomness_std": 0.1758243617415428, "train/post_ent_mag": 99.66872524261474, "train/post_ent_max": 99.66872524261474, "train/post_ent_mean": 98.80397804260254, "train/post_ent_min": 98.08297988891601, "train/post_ent_std": 0.2846638032793999, "train/prior_ent_mag": 102.51369445800782, "train/prior_ent_max": 102.51369445800782, "train/prior_ent_mean": 100.0077384185791, "train/prior_ent_min": 97.38875713348389, "train/prior_ent_std": 0.8748823514580727, "train/rep_loss_mean": 1.0000118863582612, "train/rep_loss_std": 0.0003291869276472426, "train/reward_avg": 0.0003841247574746376, "train/reward_loss_mean": 0.004029121873900294, "train/reward_loss_std": 0.09326148627413204, "train/reward_max_data": 0.3114218757301569, "train/reward_max_pred": 0.018050981163978578, "train/reward_neg_acc": 0.9999999997019767, "train/reward_neg_loss": 0.0006698603746917798, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.397121583422025, "train/reward_pred": 0.0003150892193662003, "train/reward_rate": 0.0006298828125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02389637380838394, "report/cont_loss_std": 0.32669398188591003, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 4.644866943359375, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0057749212719500065, "report/cont_pred": 0.9937112331390381, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1618293970823288, "report/image_loss_std": 0.10320238769054413, "report/model_loss_mean": 0.7900680303573608, "report/model_loss_std": 0.3663305342197418, "report/post_ent_mag": 92.14408111572266, "report/post_ent_max": 92.14408111572266, "report/post_ent_mean": 90.75582885742188, "report/post_ent_min": 89.83999633789062, "report/post_ent_std": 0.41090127825737, "report/prior_ent_mag": 97.23692321777344, "report/prior_ent_max": 97.23692321777344, "report/prior_ent_mean": 92.82559967041016, "report/prior_ent_min": 89.61418151855469, "report/prior_ent_std": 1.427446961402893, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0003295898495707661, "report/reward_loss_mean": 0.004342204891145229, "report/reward_loss_std": 0.12475208938121796, "report/reward_max_data": 0.3375000059604645, "report/reward_max_pred": 0.050110459327697754, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0004427481908351183, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.993486166000366, "report/reward_pred": 0.0002564586466178298, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.012715035118162632, "eval/cont_loss_std": 0.17937889695167542, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.725922107696533, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.007130277343094349, "eval/cont_pred": 0.993026852607727, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0001014471054077, "eval/dyn_loss_std": 0.0032457830384373665, "eval/image_loss_mean": 0.22325989603996277, "eval/image_loss_std": 0.13355432450771332, "eval/model_loss_mean": 0.8363406658172607, "eval/model_loss_std": 0.2252836525440216, "eval/post_ent_mag": 92.10173034667969, "eval/post_ent_max": 92.10173034667969, "eval/post_ent_mean": 90.7116470336914, "eval/post_ent_min": 89.87649536132812, "eval/post_ent_std": 0.41054120659828186, "eval/prior_ent_mag": 97.23692321777344, "eval/prior_ent_max": 97.23692321777344, "eval/prior_ent_mean": 92.73736572265625, "eval/prior_ent_min": 89.49580383300781, "eval/prior_ent_std": 1.3482742309570312, "eval/rep_loss_mean": 1.0001014471054077, "eval/rep_loss_std": 0.0032457830384373665, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0003048796206712723, "eval/reward_loss_std": 0.002556293038651347, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.02749943733215332, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0003048796206712723, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00014246278442442417, "eval/reward_rate": 0.0, "replay/size": 348337.0, "replay/inserts": 31984.0, "replay/samples": 31984.0, "replay/insert_wait_avg": 1.4342013569460206e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.831868438377209e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 79176.0, "eval_replay/inserts": 4976.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3283115491223106e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1711053848267, "timer/env.step_count": 3998.0, "timer/env.step_total": 40.86954593658447, "timer/env.step_frac": 0.04086255413353446, "timer/env.step_avg": 0.010222497733012625, "timer/env.step_min": 0.008744478225708008, "timer/env.step_max": 0.0365450382232666, "timer/replay._sample_count": 31984.0, "timer/replay._sample_total": 17.075181007385254, "timer/replay._sample_frac": 0.01707225985179345, "timer/replay._sample_avg": 0.0005338663396506145, "timer/replay._sample_min": 0.00038361549377441406, "timer/replay._sample_max": 0.03036808967590332, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4620.0, "timer/agent.policy_total": 51.16396236419678, "timer/agent.policy_frac": 0.051155209432400955, "timer/agent.policy_avg": 0.011074450728181121, "timer/agent.policy_min": 0.008767843246459961, "timer/agent.policy_max": 0.08597159385681152, "timer/dataset_train_count": 1999.0, "timer/dataset_train_total": 0.24210405349731445, "timer/dataset_train_frac": 0.00024206263527695322, "timer/dataset_train_avg": 0.00012111258304017731, "timer/dataset_train_min": 0.0001068115234375, "timer/dataset_train_max": 0.001081228256225586, "timer/agent.train_count": 1999.0, "timer/agent.train_total": 894.8611538410187, "timer/agent.train_frac": 0.8947080644733395, "timer/agent.train_avg": 0.4476544041225706, "timer/agent.train_min": 0.43622708320617676, "timer/agent.train_max": 0.6986923217773438, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4801619052886963, "timer/agent.report_frac": 0.0004800797610564332, "timer/agent.report_avg": 0.24008095264434814, "timer/agent.report_min": 0.23391962051391602, "timer/agent.report_max": 0.24624228477478027, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.265775741876335e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 31.97788255753362}
{"step": 348952, "time": 11281.577343463898, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 349232, "time": 11290.649053096771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349320, "time": 11293.140105485916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349432, "time": 11296.590342760086, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 349592, "time": 11301.540357112885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 349704, "time": 11304.967319011688, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 349856, "time": 11309.867489337921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350016, "time": 11314.773648738861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 11317.044306993484, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 350064, "time": 11318.798289775848, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 350064, "time": 11319.785344600677, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 350064, "time": 11319.875543355942, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 350064, "time": 11320.105152368546, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 350064, "time": 11320.215079307556, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 350064, "time": 11321.460911750793, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 350064, "time": 11323.313332557678, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11323.321464061737, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11323.329321622849, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350280, "time": 11330.878908395767, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 350408, "time": 11334.819784641266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350632, "time": 11341.688978433609, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 351216, "time": 11359.955555677414, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 351264, "time": 11361.418411493301, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351544, "time": 11369.803600549698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351744, "time": 11376.176264047623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351904, "time": 11381.205393791199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352328, "time": 11394.465723514557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352720, "time": 11406.743854522705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352824, "time": 11409.822878599167, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 352944, "time": 11413.749970197678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353232, "time": 11422.572040319443, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 353384, "time": 11426.982708215714, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 353456, "time": 11429.44075679779, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 353456, "time": 11429.449316978455, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 353744, "time": 11438.298151254654, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 353856, "time": 11441.80622434616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355032, "time": 11477.785237073898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355256, "time": 11484.654973506927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355544, "time": 11493.480349302292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355696, "time": 11498.438202142715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355768, "time": 11500.463658809662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355768, "time": 11500.473654031754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356056, "time": 11509.301909923553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 356168, "time": 11512.729714870453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357048, "time": 11539.784517526627, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 357480, "time": 11553.071701049805, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 357568, "time": 11556.004573583603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357848, "time": 11564.502698898315, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 357856, "time": 11564.981652736664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357888, "time": 11565.98448252678, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 357920, "time": 11566.969629049301, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 358080, "time": 11571.892193555832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358080, "time": 11571.902050495148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358448, "time": 11583.193708181381, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 359040, "time": 11601.521549224854, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 359360, "time": 11611.352715015411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359392, "time": 11612.343780994415, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 359688, "time": 11621.305430650711, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 11633.81713938713, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 360048, "time": 11635.41142654419, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 360048, "time": 11635.716131448746, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 360048, "time": 11636.205293416977, "eval_episode/length": 171.0, "eval_episode/score": 0.46562498807907104, "eval_episode/reward_rate": 0.005813953488372093}
{"step": 360048, "time": 11638.723947525024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11638.735356092453, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11638.743680000305, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11638.751922607422, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360104, "time": 11640.240436077118, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 360168, "time": 11642.220029830933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360208, "time": 11643.671462535858, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 360232, "time": 11644.188700914383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360392, "time": 11649.214348554611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360736, "time": 11660.508778810501, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 361216, "time": 11675.234513759613, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 361352, "time": 11679.349895477295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362000, "time": 11699.42102265358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362416, "time": 11712.325606584549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362480, "time": 11714.289393901825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362520, "time": 11715.31597995758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362672, "time": 11720.1935608387, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 362704, "time": 11721.173300504684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363528, "time": 11746.282011032104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363664, "time": 11750.680028676987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363992, "time": 11760.528281450272, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 364312, "time": 11770.42935538292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364728, "time": 11783.09501004219, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364760, "time": 11784.088984489441, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 364792, "time": 11785.06374502182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364832, "time": 11786.515612602234, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365016, "time": 11791.908029317856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365496, "time": 11806.697121858597, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 365544, "time": 11808.166769266129, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 365840, "time": 11817.463303804398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365976, "time": 11821.423733472824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366304, "time": 11831.895179986954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366360, "time": 11833.418295383453, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 366512, "time": 11838.332678556442, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 367040, "time": 11854.567886590958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367072, "time": 11855.55236530304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367104, "time": 11856.538923501968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367296, "time": 11862.564955711365, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 367856, "time": 11879.79339170456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368232, "time": 11891.257735013962, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 368288, "time": 11893.227350950241, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368488, "time": 11899.165196418762, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 368616, "time": 11903.125106096268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368824, "time": 11910.033604621887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369384, "time": 11927.33888912201, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369416, "time": 11928.351506233215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369608, "time": 11934.241580486298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 11949.105557203293, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 370032, "time": 11949.134479999542, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 370032, "time": 11949.582988500595, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 370032, "time": 11949.915225505829, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 370032, "time": 11951.36268544197, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 370032, "time": 11953.816878795624, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11953.825541496277, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11953.835524082184, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11953.843293190002, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370168, "time": 11957.773297548294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370352, "time": 11963.647223711014, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 370544, "time": 11969.533234834671, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370800, "time": 11977.37164902687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370928, "time": 11981.388837337494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371136, "time": 11987.72689962387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371408, "time": 11996.052582740784, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 371664, "time": 12003.900945663452, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 371696, "time": 12004.883921146393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 371728, "time": 12005.862751722336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 372112, "time": 12017.732447385788, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 372112, "time": 12017.74052643776, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 372480, "time": 12029.010961771011, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 372688, "time": 12035.409741163254, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 373112, "time": 12048.267036437988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373720, "time": 12066.922256469727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373976, "time": 12074.855119228363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374008, "time": 12075.836932182312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374040, "time": 12076.864073991776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374424, "time": 12088.61455130577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374792, "time": 12100.01261138916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375000, "time": 12106.391812324524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375352, "time": 12117.183592557907, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 375424, "time": 12119.635294437408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376032, "time": 12138.390236139297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376288, "time": 12146.251011610031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376320, "time": 12147.234625339508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376352, "time": 12148.218658208847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377104, "time": 12171.891889333725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377312, "time": 12178.26520037651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377376, "time": 12180.228865146637, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 377464, "time": 12182.731879711151, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 377664, "time": 12189.193607330322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377736, "time": 12191.193736076355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378344, "time": 12209.887177467346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378632, "time": 12218.86125087738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379416, "time": 12242.946527004242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379624, "time": 12249.42351269722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379688, "time": 12251.41897559166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379776, "time": 12254.347907781601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379976, "time": 12260.300142526627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 12262.937079906464, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 380016, "time": 12263.324403047562, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 380016, "time": 12263.516237735748, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 380016, "time": 12263.919855594635, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 380016, "time": 12267.171830892563, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 380016, "time": 12267.895827293396, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12267.903813362122, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12267.911893844604, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12267.921098470688, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380048, "time": 12268.912846565247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380345, "time": 12278.806560516357, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5085297405417197, "train/action_min": 0.0, "train/action_std": 1.7571291953779113, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013015723273129708, "train/actor_opt_grad_steps": 22690.0, "train/actor_opt_loss": 13.262281912024402, "train/adv_mag": 0.32099389031453784, "train/adv_max": 0.20455899395918484, "train/adv_mean": 0.011315485382326147, "train/adv_min": -0.24742608869136287, "train/adv_std": 0.03314374080684206, "train/cont_avg": 0.9962226364213198, "train/cont_loss_mean": 0.022164554246535836, "train/cont_loss_std": 0.298723494775858, "train/cont_neg_acc": 0.014281623641547468, "train/cont_neg_loss": 4.83609358613024, "train/cont_pos_acc": 0.9999552018146225, "train/cont_pos_loss": 0.003890302993101895, "train/cont_pred": 0.9960585635930753, "train/cont_rate": 0.9962226364213198, "train/dyn_loss_mean": 1.0000199236845606, "train/dyn_loss_std": 0.0005210658056256101, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1158740166101964, "train/extr_critic_critic_opt_grad_steps": 22690.0, "train/extr_critic_critic_opt_loss": 10212.775434000238, "train/extr_critic_mag": 0.6724619714136656, "train/extr_critic_max": 0.6724619714136656, "train/extr_critic_mean": 0.6472911813537482, "train/extr_critic_min": 0.6103016755302545, "train/extr_critic_std": 0.01279689072806218, "train/extr_return_normed_mag": 0.33474276997716296, "train/extr_return_normed_max": 0.2569384260226022, "train/extr_return_normed_mean": 0.05049219845231566, "train/extr_return_normed_min": -0.19667845147515312, "train/extr_return_normed_std": 0.03701557965977543, "train/extr_return_rate": 0.9969490466989236, "train/extr_return_raw_mag": 0.8650528628208916, "train/extr_return_raw_max": 0.8650528628208916, "train/extr_return_raw_mean": 0.6586066702295681, "train/extr_return_raw_min": 0.41143598532313624, "train/extr_return_raw_std": 0.03701557966923048, "train/extr_reward_mag": 0.20967444490055143, "train/extr_reward_max": 0.20967444490055143, "train/extr_reward_mean": 0.003792155051525909, "train/extr_reward_min": 5.688158993793623e-08, "train/extr_reward_std": 0.01755860618547286, "train/image_loss_mean": 0.13271100667830046, "train/image_loss_std": 0.10853067252236574, "train/model_loss_mean": 0.7588228876820675, "train/model_loss_std": 0.37576260879106327, "train/model_opt_grad_norm": 29.377083544828455, "train/model_opt_grad_steps": 22667.45685279188, "train/model_opt_loss": 2437.0687571878966, "train/model_opt_model_opt_grad_overflow": 0.005076142131979695, "train/model_opt_model_opt_grad_scale": 3210.659898477157, "train/policy_entropy_mag": 1.5800123075543322, "train/policy_entropy_max": 1.5800123075543322, "train/policy_entropy_mean": 0.28249269807096666, "train/policy_entropy_min": 0.06469426950827468, "train/policy_entropy_std": 0.28877072845618734, "train/policy_logprob_mag": 6.55106414030046, "train/policy_logprob_max": -0.008609500070702908, "train/policy_logprob_mean": -0.2830132190799955, "train/policy_logprob_min": -6.55106414030046, "train/policy_logprob_std": 0.7875582318620633, "train/policy_randomness_mag": 0.811965754189467, "train/policy_randomness_max": 0.811965754189467, "train/policy_randomness_mean": 0.14517253845324976, "train/policy_randomness_min": 0.033246279916333665, "train/policy_randomness_std": 0.14839880777343276, "train/post_ent_mag": 84.96766631615344, "train/post_ent_max": 84.96766631615344, "train/post_ent_mean": 83.1480324449878, "train/post_ent_min": 82.11084766678398, "train/post_ent_std": 0.5156738090938723, "train/prior_ent_mag": 87.5214412708573, "train/prior_ent_max": 87.5214412708573, "train/prior_ent_mean": 84.18239791018104, "train/prior_ent_min": 80.56987158296072, "train/prior_ent_std": 1.1356176758175573, "train/rep_loss_mean": 1.0000199236845606, "train/rep_loss_std": 0.0005210658056256101, "train/reward_avg": 0.0004065034366706221, "train/reward_loss_mean": 0.003935349754147647, "train/reward_loss_std": 0.08976855937824088, "train/reward_max_data": 0.32760152353096733, "train/reward_max_pred": 0.0440414883763657, "train/reward_neg_acc": 0.9999206175053785, "train/reward_neg_loss": 0.0007769283119099792, "train/reward_pos_acc": 0.0639730640734085, "train/reward_pos_loss": 4.914003090424971, "train/reward_pred": 0.0003698821573135287, "train/reward_rate": 0.0006543464467005076, "train_stats/mean_log_entropy": 0.28025028053531076, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01995566487312317, "report/cont_loss_std": 0.2824828624725342, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.415592193603516, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0027178728487342596, "report/cont_pred": 0.9972375631332397, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11725355684757233, "report/image_loss_std": 0.10407313704490662, "report/model_loss_mean": 0.7425086498260498, "report/model_loss_std": 0.39811018109321594, "report/post_ent_mag": 75.00022888183594, "report/post_ent_max": 75.00022888183594, "report/post_ent_mean": 72.94611358642578, "report/post_ent_min": 71.7353744506836, "report/post_ent_std": 0.6003039479255676, "report/prior_ent_mag": 77.37461853027344, "report/prior_ent_max": 77.37461853027344, "report/prior_ent_mean": 73.6874008178711, "report/prior_ent_min": 70.36638641357422, "report/prior_ent_std": 1.292175531387329, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007659912225790322, "report/reward_loss_mean": 0.005299392156302929, "report/reward_loss_std": 0.15973545610904694, "report/reward_max_data": 0.784375011920929, "report/reward_max_pred": 0.012742280960083008, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0003056372224818915, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.113910675048828, "report/reward_pred": 0.00014829798601567745, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02534591034054756, "eval/cont_loss_std": 0.3681091070175171, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.786713600158691, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.002752310363575816, "eval/cont_pred": 0.9972712397575378, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19928503036499023, "eval/image_loss_std": 0.12884671986103058, "eval/model_loss_mean": 0.8246968984603882, "eval/model_loss_std": 0.39650774002075195, "eval/post_ent_mag": 75.0322265625, "eval/post_ent_max": 75.0322265625, "eval/post_ent_mean": 72.86241912841797, "eval/post_ent_min": 71.807861328125, "eval/post_ent_std": 0.5920298099517822, "eval/prior_ent_mag": 77.46491241455078, "eval/prior_ent_max": 77.46491241455078, "eval/prior_ent_mean": 73.3514633178711, "eval/prior_ent_min": 70.09698486328125, "eval/prior_ent_std": 1.3764705657958984, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 6.594089791178703e-05, "eval/reward_loss_std": 0.000704264035448432, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.007899641990661621, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 6.594089791178703e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 2.9681483283638954e-05, "eval/reward_rate": 0.0, "replay/size": 379841.0, "replay/inserts": 31504.0, "replay/samples": 31504.0, "replay/insert_wait_avg": 1.4430741600241983e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.858338121110985e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 88424.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3190363517682032e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4663541316986, "timer/env.step_count": 3938.0, "timer/env.step_total": 40.30797076225281, "timer/env.step_frac": 0.04028918173588752, "timer/env.step_avg": 0.010235645191024075, "timer/env.step_min": 0.008658170700073242, "timer/env.step_max": 0.039791107177734375, "timer/replay._sample_count": 31504.0, "timer/replay._sample_total": 16.78371238708496, "timer/replay._sample_frac": 0.016775888881991927, "timer/replay._sample_avg": 0.0005327486156388065, "timer/replay._sample_min": 0.0003910064697265625, "timer/replay._sample_max": 0.010346174240112305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5094.0, "timer/agent.policy_total": 57.07821178436279, "timer/agent.policy_frac": 0.05705160553240272, "timer/agent.policy_avg": 0.011204988571724145, "timer/agent.policy_min": 0.009273290634155273, "timer/agent.policy_max": 0.09601163864135742, "timer/dataset_train_count": 1969.0, "timer/dataset_train_total": 0.23774290084838867, "timer/dataset_train_frac": 0.00023763208014598844, "timer/dataset_train_avg": 0.00012074296640344778, "timer/dataset_train_min": 0.00010633468627929688, "timer/dataset_train_max": 0.00043964385986328125, "timer/agent.train_count": 1969.0, "timer/agent.train_total": 884.0598061084747, "timer/agent.train_frac": 0.8836477133463896, "timer/agent.train_avg": 0.44898923621557885, "timer/agent.train_min": 0.43693971633911133, "timer/agent.train_max": 1.5962989330291748, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4924032688140869, "timer/agent.report_frac": 0.0004921737415561987, "timer/agent.report_avg": 0.24620163440704346, "timer/agent.report_min": 0.2440018653869629, "timer/agent.report_max": 0.24840140342712402, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.3839656968579317e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 31.488608554287868}
{"step": 380656, "time": 12288.385462522507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 380944, "time": 12297.20216846466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381728, "time": 12321.379880189896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381936, "time": 12327.746905088425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381960, "time": 12328.264642953873, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 382000, "time": 12329.715173482895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382088, "time": 12332.212647914886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382288, "time": 12338.692312717438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382360, "time": 12340.698050022125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382968, "time": 12359.323989629745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383256, "time": 12368.148992538452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383304, "time": 12369.74677491188, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 384248, "time": 12398.792113780975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384272, "time": 12399.7777967453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384312, "time": 12400.78966140747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384400, "time": 12403.71892786026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384672, "time": 12412.077585220337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385072, "time": 12424.8647274971, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 385280, "time": 12431.362099409103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385568, "time": 12440.22770524025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385616, "time": 12441.702677249908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386560, "time": 12470.72349691391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386624, "time": 12472.690749645233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386712, "time": 12475.16016459465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386984, "time": 12483.481119155884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387384, "time": 12495.843200922012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387592, "time": 12502.311224222183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387880, "time": 12511.190163373947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387928, "time": 12512.661223649979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388872, "time": 12541.832237482071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388936, "time": 12543.80268907547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389024, "time": 12546.730078697205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389296, "time": 12555.20023727417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389696, "time": 12567.44747376442, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389904, "time": 12573.865706682205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 12581.868299245834, "eval_episode/length": 194.0, "eval_episode/score": 0.39375001192092896, "eval_episode/reward_rate": 0.005128205128205128}
{"step": 390000, "time": 12583.907751560211, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12583.916090726852, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12583.924129009247, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12583.932422876358, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12583.941051959991, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12583.949359893799, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12583.958040714264, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390192, "time": 12589.87613582611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 390240, "time": 12591.358497858047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391184, "time": 12620.475565433502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391248, "time": 12622.42900133133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391336, "time": 12624.918569803238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391528, "time": 12630.825033187866, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 392008, "time": 12645.6840903759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392216, "time": 12652.048826217651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392504, "time": 12660.898287057877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392552, "time": 12662.372670173645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393496, "time": 12691.945557832718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393560, "time": 12693.926479816437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393648, "time": 12696.846546649933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393840, "time": 12702.89266872406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394320, "time": 12717.689593553543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394528, "time": 12724.130360841751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394816, "time": 12733.127691984177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394864, "time": 12734.641422986984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395728, "time": 12761.481665849686, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 395808, "time": 12763.967243432999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395872, "time": 12765.934074640274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 395960, "time": 12768.44072341919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396152, "time": 12774.40232205391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396352, "time": 12780.817839384079, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 396760, "time": 12793.330733060837, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 396840, "time": 12795.796790361404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397176, "time": 12806.234306573868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398040, "time": 12832.994656085968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398120, "time": 12835.461928129196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398184, "time": 12837.431934595108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398464, "time": 12846.259184837341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398664, "time": 12852.280520439148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398800, "time": 12856.68645143509, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 399000, "time": 12862.641057729721, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 399072, "time": 12865.066600561142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399304, "time": 12872.00569152832, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 399408, "time": 12875.422988653183, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 399488, "time": 12877.896296024323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400016, "time": 12894.218387365341, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 12896.950498104095, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 400088, "time": 12897.17570400238, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 400088, "time": 12897.401051044464, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 400088, "time": 12897.74415397644, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 400088, "time": 12898.088088989258, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 400088, "time": 12900.583427906036, "eval_episode/length": 201.0, "eval_episode/score": 0.37187498807907104, "eval_episode/reward_rate": 0.0049504950495049506}
{"step": 400088, "time": 12902.419310569763, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 12902.42902135849, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400352, "time": 12910.917717933655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400496, "time": 12915.352604866028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 400688, "time": 12921.266258716583, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 400856, "time": 12926.210708618164, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 400864, "time": 12926.68341255188, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 400968, "time": 12929.719480276108, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 400976, "time": 12930.192909955978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401008, "time": 12931.183133363724, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 401112, "time": 12934.188081026077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401408, "time": 12943.860960483551, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 401512, "time": 12947.193682193756, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 401720, "time": 12953.611359119415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 402600, "time": 12980.757180213928, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 402808, "time": 12987.15654015541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403168, "time": 12998.664620637894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403176, "time": 12998.696034908295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403280, "time": 13002.112501382828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403288, "time": 13002.142421722412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403824, "time": 13018.829895019531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404032, "time": 13025.210369348526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404912, "time": 13052.464308977127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405120, "time": 13059.012728691101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405480, "time": 13069.832664966583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405488, "time": 13070.309025287628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405592, "time": 13073.286926746368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405600, "time": 13073.759331941605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406136, "time": 13090.133516788483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406328, "time": 13096.054052829742, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 406344, "time": 13096.554809093475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406352, "time": 13097.055724859238, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 406584, "time": 13103.996564865112, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 406696, "time": 13107.469190120697, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 406736, "time": 13108.933642148972, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 407000, "time": 13116.825918197632, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 407232, "time": 13124.316884279251, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 407432, "time": 13130.276708364487, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 407800, "time": 13141.672590017319, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407824, "time": 13142.63090467453, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 408056, "time": 13149.655754804611, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 408360, "time": 13159.047724246979, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 408448, "time": 13161.998184204102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408528, "time": 13164.452378034592, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 408640, "time": 13167.913591623306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408992, "time": 13178.861919641495, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 409008, "time": 13179.365448713303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409296, "time": 13188.30951666832, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 409744, "time": 13202.69960641861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409768, "time": 13203.2189245224, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 409848, "time": 13205.680171489716, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 13214.162008285522, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 410072, "time": 13214.189707279205, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 410072, "time": 13214.326892614365, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 410072, "time": 13214.877693891525, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 410072, "time": 13215.016012430191, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 410072, "time": 13215.12936925888, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 410072, "time": 13216.057012081146, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 410072, "time": 13216.085229635239, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 410112, "time": 13217.542798995972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410360, "time": 13224.980368614197, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 410368, "time": 13225.458270072937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410560, "time": 13231.363247156143, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 410840, "time": 13239.857436418533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410952, "time": 13243.31052851677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411304, "time": 13254.138290643692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411592, "time": 13263.00197839737, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 411984, "time": 13275.379706382751, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 412073, "time": 13278.866028785706, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4818522135416665, "train/action_min": 0.0, "train/action_std": 1.695471617910597, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011348910749692357, "train/actor_opt_grad_steps": 24665.0, "train/actor_opt_loss": -7.544474789969191, "train/adv_mag": 0.5423952846816091, "train/adv_max": 0.2412749875073481, "train/adv_mean": 0.0027610141997233815, "train/adv_min": -0.5051626939364154, "train/adv_std": 0.03506067315718592, "train/cont_avg": 0.9961677320075758, "train/cont_loss_mean": 0.0197154984249724, "train/cont_loss_std": 0.27853253943789186, "train/cont_neg_acc": 0.09913751376526696, "train/cont_neg_loss": 4.2574848688530675, "train/cont_pos_acc": 0.9999108522227316, "train/cont_pos_loss": 0.003484721050945797, "train/cont_pred": 0.9961808176353725, "train/cont_rate": 0.9961677320075758, "train/dyn_loss_mean": 1.0000204726903126, "train/dyn_loss_std": 0.0005275721379821518, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7187702818350359, "train/extr_critic_critic_opt_grad_steps": 24665.0, "train/extr_critic_critic_opt_loss": 10530.008396957859, "train/extr_critic_mag": 0.8608957185889735, "train/extr_critic_max": 0.8608957185889735, "train/extr_critic_mean": 0.8172164938666604, "train/extr_critic_min": 0.7842481425314238, "train/extr_critic_std": 0.013386891421043512, "train/extr_return_normed_mag": 0.5295428769154982, "train/extr_return_normed_max": 0.2989737590154012, "train/extr_return_normed_mean": 0.03758405425631079, "train/extr_return_normed_min": -0.4569900559656548, "train/extr_return_normed_std": 0.038139008451253176, "train/extr_return_rate": 0.9987387256790893, "train/extr_return_raw_mag": 1.0813672081990675, "train/extr_return_raw_max": 1.0813672081990675, "train/extr_return_raw_mean": 0.8199775363459731, "train/extr_return_raw_min": 0.3254033932180116, "train/extr_return_raw_std": 0.03813900844654953, "train/extr_reward_mag": 0.29681905893364335, "train/extr_reward_max": 0.29681905893364335, "train/extr_reward_mean": 0.0022645047837007346, "train/extr_reward_min": 1.6195605499575836e-07, "train/extr_reward_std": 0.015146433110387098, "train/image_loss_mean": 0.11751660023524303, "train/image_loss_std": 0.10522416843609377, "train/model_loss_mean": 0.7420422753902397, "train/model_loss_std": 0.3729056753970758, "train/model_opt_grad_norm": 27.97268372834331, "train/model_opt_grad_steps": 24640.939393939392, "train/model_opt_loss": 2305.378446945036, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3106.060606060606, "train/policy_entropy_mag": 1.4525032097643071, "train/policy_entropy_max": 1.4525032097643071, "train/policy_entropy_mean": 0.17485092245418615, "train/policy_entropy_min": 0.06468696990097413, "train/policy_entropy_std": 0.21404130621389908, "train/policy_logprob_mag": 6.55107972597835, "train/policy_logprob_max": -0.008608252021738073, "train/policy_logprob_mean": -0.17475705529854754, "train/policy_logprob_min": -6.55107972597835, "train/policy_logprob_std": 0.7079366614120175, "train/policy_randomness_mag": 0.7464390366968482, "train/policy_randomness_max": 0.7464390366968482, "train/policy_randomness_mean": 0.08985560451342602, "train/policy_randomness_min": 0.033242528693694054, "train/policy_randomness_std": 0.1099954784443282, "train/post_ent_mag": 67.60958685056127, "train/post_ent_max": 67.60958685056127, "train/post_ent_mean": 65.33989023921465, "train/post_ent_min": 64.24472146082407, "train/post_ent_std": 0.6169966865669597, "train/prior_ent_mag": 70.39045784690164, "train/prior_ent_max": 70.39045784690164, "train/prior_ent_mean": 66.134137741243, "train/prior_ent_min": 62.48716600976809, "train/prior_ent_std": 1.3336330122417874, "train/rep_loss_mean": 1.0000204726903126, "train/rep_loss_std": 0.0005275721379821518, "train/reward_avg": 0.0005178894676242231, "train/reward_loss_mean": 0.004797868892160066, "train/reward_loss_std": 0.10613695311864528, "train/reward_max_data": 0.3720643947822879, "train/reward_max_pred": 0.07524805177341808, "train/reward_neg_acc": 0.9998963514361718, "train/reward_neg_loss": 0.0007540584722874248, "train/reward_pos_acc": 0.1312684369298209, "train/reward_pos_loss": 4.758603443086675, "train/reward_pred": 0.00039238687910402964, "train/reward_rate": 0.000853259154040404, "train_stats/mean_log_entropy": 0.16328420806111713, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.012038635089993477, "report/cont_loss_std": 0.21119534969329834, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.480084180831909, "report/cont_pos_acc": 0.999020516872406, "report/cont_pos_loss": 0.004786788485944271, "report/cont_pred": 0.9955043792724609, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09540662914514542, "report/image_loss_std": 0.09229511767625809, "report/model_loss_mean": 0.708760142326355, "report/model_loss_std": 0.23862487077713013, "report/post_ent_mag": 60.21257781982422, "report/post_ent_max": 60.21257781982422, "report/post_ent_mean": 57.683982849121094, "report/post_ent_min": 56.61857223510742, "report/post_ent_std": 0.6991221904754639, "report/prior_ent_mag": 63.653717041015625, "report/prior_ent_max": 63.653717041015625, "report/prior_ent_mean": 58.23822784423828, "report/prior_ent_min": 54.97990798950195, "report/prior_ent_std": 1.4782253503799438, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0013148391153663397, "report/reward_loss_std": 0.014224856160581112, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.1629807949066162, "report/reward_neg_acc": 0.9990234375, "report/reward_neg_loss": 0.0013148391153663397, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0005777637707069516, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.019832855090498924, "eval/cont_loss_std": 0.27866581082344055, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.957710266113281, "eval/cont_pos_acc": 0.9970645904541016, "eval/cont_pos_loss": 0.008212743327021599, "eval/cont_pred": 0.9944161772727966, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2263103574514389, "eval/image_loss_std": 0.15633025765419006, "eval/model_loss_mean": 0.8462241888046265, "eval/model_loss_std": 0.31455230712890625, "eval/post_ent_mag": 60.191097259521484, "eval/post_ent_max": 60.191097259521484, "eval/post_ent_mean": 57.63994598388672, "eval/post_ent_min": 56.325965881347656, "eval/post_ent_std": 0.708243191242218, "eval/prior_ent_mag": 63.00922775268555, "eval/prior_ent_max": 63.00922775268555, "eval/prior_ent_mean": 57.91648864746094, "eval/prior_ent_min": 53.60752487182617, "eval/prior_ent_std": 1.5391261577606201, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 8.095381781458855e-05, "eval/reward_loss_std": 0.0007562985410913825, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.006433367729187012, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 8.095381781458855e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.740412648767233e-05, "eval/reward_rate": 0.0, "replay/size": 411569.0, "replay/inserts": 31728.0, "replay/samples": 31728.0, "replay/insert_wait_avg": 1.4511687071468874e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.965470947404132e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 94264.0, "eval_replay/inserts": 5840.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3209777335598044e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0365524291992, "timer/env.step_count": 3966.0, "timer/env.step_total": 40.86212468147278, "timer/env.step_frac": 0.040860631126146504, "timer/env.step_avg": 0.010303107584839329, "timer/env.step_min": 0.008799076080322266, "timer/env.step_max": 0.05645132064819336, "timer/replay._sample_count": 31728.0, "timer/replay._sample_total": 17.083950996398926, "timer/replay._sample_frac": 0.01708332655931438, "timer/replay._sample_avg": 0.0005384502961547821, "timer/replay._sample_min": 0.00038933753967285156, "timer/replay._sample_max": 0.03116154670715332, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4696.0, "timer/agent.policy_total": 53.347383975982666, "timer/agent.policy_frac": 0.05334543407078069, "timer/agent.policy_avg": 0.011360175463369392, "timer/agent.policy_min": 0.009419441223144531, "timer/agent.policy_max": 0.1035151481628418, "timer/dataset_train_count": 1983.0, "timer/dataset_train_total": 0.24677610397338867, "timer/dataset_train_frac": 0.00024676708403702073, "timer/dataset_train_avg": 0.00012444584164063977, "timer/dataset_train_min": 0.00010824203491210938, "timer/dataset_train_max": 0.0010793209075927734, "timer/agent.train_count": 1983.0, "timer/agent.train_total": 891.2967245578766, "timer/agent.train_frac": 0.8912641466882569, "timer/agent.train_avg": 0.4494688474825399, "timer/agent.train_min": 0.43739771842956543, "timer/agent.train_max": 0.720435619354248, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48182177543640137, "timer/agent.report_frac": 0.00048180416432379704, "timer/agent.report_avg": 0.24091088771820068, "timer/agent.report_min": 0.2329552173614502, "timer/agent.report_max": 0.24886655807495117, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.480784023771226e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 31.72613073716017}
{"step": 412160, "time": 13281.597122192383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412672, "time": 13297.279729366302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412680, "time": 13297.310993909836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412872, "time": 13303.315257549286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413264, "time": 13315.587387084961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413336, "time": 13317.578026294708, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 413432, "time": 13320.530403614044, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 413616, "time": 13326.41379904747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413776, "time": 13331.441025972366, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 413904, "time": 13335.3903028965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414296, "time": 13347.282705545425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414408, "time": 13350.738247871399, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 414472, "time": 13352.691986322403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415224, "time": 13375.895343542099, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 415304, "time": 13378.364405632019, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 415576, "time": 13386.716295003891, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415648, "time": 13389.296609163284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415744, "time": 13392.222356319427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415984, "time": 13399.611226320267, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 416088, "time": 13402.574912071228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416152, "time": 13404.550711631775, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 416216, "time": 13406.514053344727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416464, "time": 13414.392885684967, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 417888, "time": 13458.921264886856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417960, "time": 13460.906121015549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418056, "time": 13463.86109995842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418296, "time": 13471.216331481934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418400, "time": 13474.662610292435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418464, "time": 13476.622449159622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418528, "time": 13478.73477602005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418536, "time": 13478.765541553497, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 418776, "time": 13486.107149362564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419384, "time": 13504.726948261261, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 13526.227064371109, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 420056, "time": 13526.594587802887, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 420056, "time": 13526.853963375092, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 420056, "time": 13531.715543031693, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13531.724100112915, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13531.731795549393, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13531.739689826965, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13531.748252868652, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13531.755600690842, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420272, "time": 13538.752540111542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420368, "time": 13541.704458236694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420608, "time": 13549.056316137314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420712, "time": 13552.016988039017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420792, "time": 13554.493076562881, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 420848, "time": 13556.42591547966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421088, "time": 13563.814637899399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421160, "time": 13565.79916882515, "episode/length": 8.0, "episode/score": 0.9750000238418579, "episode/reward_rate": 0.1111111111111111, "episode/intrinsic_return": 0.0}
{"step": 421528, "time": 13577.167809009552, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 421696, "time": 13582.539535284042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421968, "time": 13590.904163599014, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 422064, "time": 13593.8463139534, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 422584, "time": 13609.644489526749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422680, "time": 13612.59585928917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422920, "time": 13619.919239997864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423104, "time": 13625.77983045578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423160, "time": 13627.302240133286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423840, "time": 13648.466254711151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424280, "time": 13661.838196754456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424376, "time": 13664.780779123306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424896, "time": 13680.907463312149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424992, "time": 13683.845215082169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425232, "time": 13691.32921218872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425416, "time": 13696.748738527298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 425472, "time": 13698.712214946747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426152, "time": 13719.981380939484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426592, "time": 13733.713593959808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426688, "time": 13736.668133974075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427208, "time": 13752.53118777275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427304, "time": 13755.45297074318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427544, "time": 13762.826044559479, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427728, "time": 13768.684681415558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427784, "time": 13770.173962593079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428464, "time": 13791.369842767715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428904, "time": 13804.624274015427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429000, "time": 13807.577795267105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429520, "time": 13823.794226884842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429616, "time": 13826.764249563217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429856, "time": 13834.135310173035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 13839.713931322098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 13842.620423555374, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 430040, "time": 13846.487396240234, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13846.49710559845, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13846.506597995758, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13846.517558336258, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13846.528351068497, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13846.537832021713, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 13846.547902107239, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430096, "time": 13848.478328943253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430352, "time": 13856.309662818909, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 430712, "time": 13867.113981723785, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 431312, "time": 13885.833213090897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431688, "time": 13897.093221187592, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 431832, "time": 13901.654090642929, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431864, "time": 13902.641482114792, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 431928, "time": 13904.604039907455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432352, "time": 13917.794969797134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432664, "time": 13927.118778944016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 432968, "time": 13936.539159536362, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 433024, "time": 13938.473620891571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433624, "time": 13956.695822954178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 433696, "time": 13959.25998711586, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 434000, "time": 13968.577553033829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434144, "time": 13973.002614021301, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434176, "time": 13974.150892496109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434240, "time": 13976.523800134659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434600, "time": 13987.31735920906, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 434976, "time": 13999.147371292114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435280, "time": 14008.453486680984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435600, "time": 14018.249602079391, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 435936, "time": 14028.679160118103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436008, "time": 14030.698669433594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436312, "time": 14040.021706342697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436488, "time": 14045.418463230133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436552, "time": 14047.38115644455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 436760, "time": 14053.8860206604, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 436912, "time": 14058.763951778412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437000, "time": 14061.230168819427, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 437440, "time": 14074.905962228775, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 437592, "time": 14079.442524433136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437912, "time": 14089.213944911957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438168, "time": 14097.034970998764, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 438184, "time": 14097.53046798706, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 438432, "time": 14105.3780002594, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 438800, "time": 14116.71584701538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438864, "time": 14118.71422791481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439072, "time": 14125.066427707672, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439344, "time": 14133.38899922371, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 439384, "time": 14134.395691871643, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 439512, "time": 14138.352697849274, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 439752, "time": 14145.766798496246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439904, "time": 14150.647089719772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 14155.467968940735, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 440024, "time": 14160.2925491333, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14160.30122089386, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14160.310274362564, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14160.318562030792, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14160.326511859894, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14160.333895921707, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440024, "time": 14160.343744277954, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 440224, "time": 14166.680172920227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440496, "time": 14175.137387275696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440744, "time": 14183.913183927536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440904, "time": 14188.812893390656, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 441112, "time": 14195.193991184235, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 441288, "time": 14200.704985618591, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 441352, "time": 14202.664067983627, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 441656, "time": 14211.970650911331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441688, "time": 14212.975576400757, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 441696, "time": 14213.455447912216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441936, "time": 14220.806481599808, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 441976, "time": 14221.814727306366, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 442024, "time": 14223.277606010437, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 442064, "time": 14224.746649980545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442216, "time": 14229.307301521301, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442448, "time": 14237.145541191101, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 442456, "time": 14237.176102638245, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 442896, "time": 14250.879459142685, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 443064, "time": 14255.792277812958, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 443600, "time": 14272.542167663574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443664, "time": 14274.525091648102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443785, "time": 14279.00627541542, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6149914612123117, "train/action_min": 0.0, "train/action_std": 1.7787370388232284, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008959003259081524, "train/actor_opt_grad_steps": 26650.0, "train/actor_opt_loss": -10.12748567902263, "train/adv_mag": 0.6468660148543928, "train/adv_max": 0.2580467741094043, "train/adv_mean": -0.003092961685677748, "train/adv_min": -0.6142895865679985, "train/adv_std": 0.030339133008453416, "train/cont_avg": 0.9959710662688442, "train/cont_loss_mean": 0.016050528523151825, "train/cont_loss_std": 0.2383351149248081, "train/cont_neg_acc": 0.2730840187181126, "train/cont_neg_loss": 3.224235323676369, "train/cont_pos_acc": 0.9997781251543131, "train/cont_pos_loss": 0.003158437087546903, "train/cont_pred": 0.9959715880341267, "train/cont_rate": 0.9959710662688442, "train/dyn_loss_mean": 1.0000112440118838, "train/dyn_loss_std": 0.00031624217552774067, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.37025880579597986, "train/extr_critic_critic_opt_grad_steps": 26650.0, "train/extr_critic_critic_opt_loss": 12296.89531151853, "train/extr_critic_mag": 0.7971594088041603, "train/extr_critic_max": 0.7971594088041603, "train/extr_critic_mean": 0.7620448053781711, "train/extr_critic_min": 0.7423969722872403, "train/extr_critic_std": 0.00806773067264813, "train/extr_return_normed_mag": 0.6344881587891124, "train/extr_return_normed_max": 0.2952206637991134, "train/extr_return_normed_mean": 0.01415748489870196, "train/extr_return_normed_min": -0.5896778549980278, "train/extr_return_normed_std": 0.031848092413689924, "train/extr_return_rate": 0.9971563971821388, "train/extr_return_raw_mag": 1.04001496754699, "train/extr_return_raw_max": 1.04001496754699, "train/extr_return_raw_mean": 0.7589518284078819, "train/extr_return_raw_min": 0.15511644874984895, "train/extr_return_raw_std": 0.03184809250027016, "train/extr_reward_mag": 0.33717345712172925, "train/extr_reward_max": 0.33717345712172925, "train/extr_reward_mean": 0.0016112302246576071, "train/extr_reward_min": 1.0662941477406564e-07, "train/extr_reward_std": 0.009985174466598423, "train/image_loss_mean": 0.10930241869023098, "train/image_loss_std": 0.10360380280856511, "train/model_loss_mean": 0.7299025537979663, "train/model_loss_std": 0.3357402968721174, "train/model_opt_grad_norm": 26.14228683260817, "train/model_opt_grad_steps": 26624.75376884422, "train/model_opt_loss": 3189.901324248194, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4371.859296482412, "train/policy_entropy_mag": 1.4416588580788081, "train/policy_entropy_max": 1.4416588580788081, "train/policy_entropy_mean": 0.15265702946701243, "train/policy_entropy_min": 0.06468658980412699, "train/policy_entropy_std": 0.19393804190146863, "train/policy_logprob_mag": 6.551080107089862, "train/policy_logprob_max": -0.008608153979083401, "train/policy_logprob_mean": -0.15267167146780983, "train/policy_logprob_min": -6.551080107089862, "train/policy_logprob_std": 0.6870036283929144, "train/policy_randomness_mag": 0.7408661396060158, "train/policy_randomness_max": 0.7408661396060158, "train/policy_randomness_mean": 0.07845019816828133, "train/policy_randomness_min": 0.03324233358679105, "train/policy_randomness_std": 0.09966444504919962, "train/post_ent_mag": 56.0516886687159, "train/post_ent_max": 56.0516886687159, "train/post_ent_mean": 53.45855831740489, "train/post_ent_min": 52.1709024438906, "train/post_ent_std": 0.7376817339029743, "train/prior_ent_mag": 58.276196848807025, "train/prior_ent_max": 58.276196848807025, "train/prior_ent_mean": 53.709537429426184, "train/prior_ent_min": 50.25920058974069, "train/prior_ent_std": 1.3967289930612, "train/rep_loss_mean": 1.0000112440118838, "train/rep_loss_std": 0.00031624217552774067, "train/reward_avg": 0.0005456972341480239, "train/reward_loss_mean": 0.00454283445657011, "train/reward_loss_std": 0.09831418085845664, "train/reward_max_data": 0.3763976130803027, "train/reward_max_pred": 0.1255630668084226, "train/reward_neg_acc": 0.999813308667897, "train/reward_neg_loss": 0.0007287093886319342, "train/reward_pos_acc": 0.26198830481684, "train/reward_pos_loss": 4.258431936565199, "train/reward_pred": 0.00042485767020726924, "train/reward_rate": 0.0008833228643216081, "train_stats/mean_log_entropy": 0.12489046021432117, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.022930797189474106, "report/cont_loss_std": 0.34181487560272217, "report/cont_neg_acc": 0.4285714626312256, "report/cont_neg_loss": 3.090451955795288, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0018170826369896531, "report/cont_pred": 0.9953144788742065, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.127526193857193, "report/image_loss_std": 0.10592636466026306, "report/model_loss_mean": 0.751020610332489, "report/model_loss_std": 0.3587823212146759, "report/post_ent_mag": 50.982948303222656, "report/post_ent_max": 50.982948303222656, "report/post_ent_mean": 48.28929901123047, "report/post_ent_min": 46.79123306274414, "report/post_ent_std": 0.7919459939002991, "report/prior_ent_mag": 53.797332763671875, "report/prior_ent_max": 53.797332763671875, "report/prior_ent_mean": 48.8487548828125, "report/prior_ent_min": 45.294212341308594, "report/prior_ent_std": 1.4702759981155396, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0005635595880448818, "report/reward_loss_std": 0.0028340392746031284, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.016997575759887695, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0005635595880448818, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00026153086218982935, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03925352171063423, "eval/cont_loss_std": 0.607387900352478, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.720775604248047, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0012867648620158434, "eval/cont_pred": 0.998740553855896, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1856808364391327, "eval/image_loss_std": 0.14714673161506653, "eval/model_loss_mean": 0.8250871300697327, "eval/model_loss_std": 0.6186254620552063, "eval/post_ent_mag": 50.97383117675781, "eval/post_ent_max": 50.97383117675781, "eval/post_ent_mean": 48.210906982421875, "eval/post_ent_min": 46.84498596191406, "eval/post_ent_std": 0.7733622193336487, "eval/prior_ent_mag": 54.31901168823242, "eval/prior_ent_max": 54.31901168823242, "eval/prior_ent_mean": 48.70257568359375, "eval/prior_ent_min": 45.17527770996094, "eval/prior_ent_std": 1.54412043094635, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001527080312371254, "eval/reward_loss_std": 0.0010427210945636034, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00873875617980957, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001527080312371254, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.031694985926151e-05, "eval/reward_rate": 0.0, "replay/size": 443281.0, "replay/inserts": 31712.0, "replay/samples": 31712.0, "replay/insert_wait_avg": 1.4537729240209615e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.101209501926642e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3340921962962431e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2069940567016602e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1190564632416, "timer/env.step_count": 3964.0, "timer/env.step_total": 41.11435508728027, "timer/env.step_frac": 0.04110946074027877, "timer/env.step_avg": 0.010371936197598455, "timer/env.step_min": 0.008842706680297852, "timer/env.step_max": 0.05243253707885742, "timer/replay._sample_count": 31712.0, "timer/replay._sample_total": 17.2141056060791, "timer/replay._sample_frac": 0.01721205639951906, "timer/replay._sample_avg": 0.0005428262363168234, "timer/replay._sample_min": 0.0003867149353027344, "timer/replay._sample_max": 0.028835296630859375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4831.0, "timer/agent.policy_total": 54.6273717880249, "timer/agent.policy_frac": 0.054620868820563946, "timer/agent.policy_avg": 0.01130767372966775, "timer/agent.policy_min": 0.009458065032958984, "timer/agent.policy_max": 0.10390901565551758, "timer/dataset_train_count": 1982.0, "timer/dataset_train_total": 0.24497389793395996, "timer/dataset_train_frac": 0.00024494473568004025, "timer/dataset_train_avg": 0.0001235993430544702, "timer/dataset_train_min": 0.0001049041748046875, "timer/dataset_train_max": 0.0006382465362548828, "timer/agent.train_count": 1982.0, "timer/agent.train_total": 888.4429531097412, "timer/agent.train_frac": 0.8883371908256356, "timer/agent.train_avg": 0.44825577856192794, "timer/agent.train_min": 0.4373326301574707, "timer/agent.train_max": 1.8549830913543701, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4762256145477295, "timer/agent.report_frac": 0.0004761689235597849, "timer/agent.report_avg": 0.23811280727386475, "timer/agent.report_min": 0.22871780395507812, "timer/agent.report_max": 0.24750781059265137, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.647804260253906e-05, "timer/dataset_eval_frac": 3.6473700172795155e-08, "timer/dataset_eval_avg": 3.647804260253906e-05, "timer/dataset_eval_min": 3.647804260253906e-05, "timer/dataset_eval_max": 3.647804260253906e-05, "fps": 31.707635141223992}
{"step": 443912, "time": 14282.696887254715, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 443968, "time": 14284.663470029831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444176, "time": 14291.16490149498, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 444288, "time": 14294.610149860382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444760, "time": 14308.908316135406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444768, "time": 14309.382121801376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445376, "time": 14328.167822599411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445864, "time": 14342.917696475983, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 445912, "time": 14344.401177167892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446224, "time": 14354.338470458984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446280, "time": 14355.828682661057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446488, "time": 14362.201152563095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446496, "time": 14362.675609350204, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 446600, "time": 14365.644436120987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447080, "time": 14380.48585319519, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447224, "time": 14384.915112018585, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 447240, "time": 14385.408838272095, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 447376, "time": 14389.810844421387, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 447688, "time": 14399.14548754692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447840, "time": 14404.036428689957, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 448176, "time": 14414.42517876625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448224, "time": 14415.902653932571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448912, "time": 14437.010055065155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449392, "time": 14451.883404016495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449536, "time": 14456.29723906517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449552, "time": 14456.810302972794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449848, "time": 14465.751367092133, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 450000, "time": 14470.767006874084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 14477.070640802383, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14477.081264734268, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14477.089698553085, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14477.098915815353, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14477.107533931732, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14477.116744041443, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14477.126063108444, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14477.135939359665, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450152, "time": 14481.581211805344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450488, "time": 14491.892702579498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450536, "time": 14493.386188268661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451512, "time": 14523.898397445679, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 451664, "time": 14528.9088408947, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 451736, "time": 14530.893287420273, "episode/length": 272.0, "episode/score": 0.15000000596046448, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0}
{"step": 451848, "time": 14534.32797551155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451872, "time": 14535.28896188736, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 452016, "time": 14539.711392879486, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 452464, "time": 14553.431181192398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452512, "time": 14554.8970348835, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 452584, "time": 14556.864077806473, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 452760, "time": 14562.398696899414, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 452944, "time": 14568.26748585701, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 453464, "time": 14583.977924585342, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 453824, "time": 14595.298365592957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 453976, "time": 14599.753597021103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454320, "time": 14610.505797624588, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 454480, "time": 14615.421540498734, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 454600, "time": 14619.024651288986, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 454776, "time": 14624.454005002975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454824, "time": 14625.924738645554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455072, "time": 14633.785635709763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455272, "time": 14639.71875166893, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 455328, "time": 14641.675048589706, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 455536, "time": 14648.035653591156, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 455672, "time": 14652.122667074203, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 455944, "time": 14660.427713155746, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 456120, "time": 14665.839657783508, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 456280, "time": 14670.778309583664, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 456576, "time": 14680.257241010666, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 456576, "time": 14680.26794886589, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 456592, "time": 14680.78261089325, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 456632, "time": 14681.787210702896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456736, "time": 14685.18714427948, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 456792, "time": 14686.698048830032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457512, "time": 14708.897388458252, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 457632, "time": 14712.797437429428, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 457688, "time": 14714.285029649734, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 457712, "time": 14715.256922721863, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 457824, "time": 14718.68539571762, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 457864, "time": 14719.694947004318, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 458264, "time": 14731.946547985077, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 458360, "time": 14734.891865253448, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 458520, "time": 14739.898112535477, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 458592, "time": 14742.33127784729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458824, "time": 14749.719082832336, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 458848, "time": 14750.698064565659, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 458904, "time": 14752.184559822083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459072, "time": 14757.554589271545, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 459248, "time": 14762.943656921387, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 459272, "time": 14763.458082914352, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 459568, "time": 14772.851989507675, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 459928, "time": 14783.653798341751, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 14790.041040182114, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 460096, "time": 14791.156256437302, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 460096, "time": 14792.288289308548, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 460096, "time": 14793.804126739502, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 460096, "time": 14794.819726467133, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 460096, "time": 14795.381682634354, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14795.393742084503, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14795.403522491455, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14795.412201881409, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14795.42043685913, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 14795.42848277092, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460104, "time": 14795.456490755081, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 460176, "time": 14797.892874956131, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460216, "time": 14799.012665271759, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 460672, "time": 14813.221064567566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460832, "time": 14818.130892038345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460888, "time": 14819.627270936966, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 460904, "time": 14820.12631201744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460928, "time": 14821.109098672867, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 461232, "time": 14830.604567050934, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 461384, "time": 14835.014633655548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461616, "time": 14842.379231214523, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 461728, "time": 14845.821217536926, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 462336, "time": 14864.57101559639, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 462360, "time": 14865.111102342606, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 462416, "time": 14867.057493686676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463200, "time": 14891.139513015747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463544, "time": 14901.508738517761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463696, "time": 14906.41089272499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463808, "time": 14909.863416194916, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 463880, "time": 14911.873143196106, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 463928, "time": 14913.349449634552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464648, "time": 14935.555908679962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 464672, "time": 14936.519893407822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465512, "time": 14962.24673318863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465856, "time": 14973.071596622467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466008, "time": 14977.51768541336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466120, "time": 14981.128946304321, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466192, "time": 14983.588024377823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466240, "time": 14985.064133644104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466800, "time": 15002.277735948563, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 466960, "time": 15007.71423125267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 466984, "time": 15008.305772542953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467032, "time": 15009.900972127914, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 467208, "time": 15015.288208007812, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 467432, "time": 15022.180797815323, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 467432, "time": 15022.192303180695, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 467824, "time": 15034.512506484985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468168, "time": 15044.986747980118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468320, "time": 15049.868944883347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468504, "time": 15055.282681465149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468632, "time": 15059.213083028793, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 469272, "time": 15078.968430042267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469520, "time": 15086.78777384758, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469568, "time": 15088.280674934387, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 469744, "time": 15093.666207551956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 15104.06445479393, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 15105.67058801651, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 470080, "time": 15105.850151062012, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 470080, "time": 15105.987349510193, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 470080, "time": 15106.921442747116, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 470080, "time": 15106.950246572495, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 470080, "time": 15107.10601902008, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 470080, "time": 15107.445852994919, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 470080, "time": 15108.398475170135, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 470136, "time": 15109.891059160233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470192, "time": 15111.839270591736, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 470480, "time": 15120.658716917038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470632, "time": 15125.099474906921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470784, "time": 15130.130539417267, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 470816, "time": 15131.116689920425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470944, "time": 15135.080572366714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471080, "time": 15139.043613672256, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 471272, "time": 15144.958237171173, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 471360, "time": 15147.896508693695, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 471536, "time": 15153.310380935669, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 471832, "time": 15162.30954670906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471960, "time": 15166.236286401749, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 472264, "time": 15175.530986070633, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 472392, "time": 15179.469635009766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472504, "time": 15182.915156126022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472736, "time": 15190.370591640472, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 472784, "time": 15191.869110584259, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 473088, "time": 15201.198927164078, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 473128, "time": 15202.20305609703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473192, "time": 15204.16146826744, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 473256, "time": 15206.12844157219, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473368, "time": 15209.595462322235, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 473392, "time": 15210.576725244522, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473416, "time": 15211.093980073929, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 473664, "time": 15219.002471923828, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 473688, "time": 15219.518232345581, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 473904, "time": 15226.357385635376, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 474056, "time": 15230.797036886215, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 474576, "time": 15246.9712433815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474768, "time": 15253.029643058777, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 475248, "time": 15268.259586572647, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 475504, "time": 15276.119026184082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475576, "time": 15278.094496011734, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 475577, "time": 15279.22524356842, "train_stats/mean_log_entropy": 0.13973212541069513, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4615607984138257, "train/action_min": 0.0, "train/action_std": 1.8012680622062298, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011379716628597993, "train/actor_opt_grad_steps": 28635.0, "train/actor_opt_loss": -5.6303025488036145, "train/adv_mag": 0.7038530385253405, "train/adv_max": 0.24959154893653562, "train/adv_mean": 0.004260952871606945, "train/adv_min": -0.6880939927968112, "train/adv_std": 0.04325325754141868, "train/cont_avg": 0.9961627998737373, "train/cont_loss_mean": 0.013646556919962732, "train/cont_loss_std": 0.20981596940610972, "train/cont_neg_acc": 0.34256410675171095, "train/cont_neg_loss": 2.8251301266539555, "train/cont_pos_acc": 0.9997722208499908, "train/cont_pos_loss": 0.0028530878492282947, "train/cont_pred": 0.9960657737471841, "train/cont_rate": 0.9961627998737373, "train/dyn_loss_mean": 1.000012806569687, "train/dyn_loss_std": 0.00033838618110901806, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5152918271287673, "train/extr_critic_critic_opt_grad_steps": 28635.0, "train/extr_critic_critic_opt_loss": 11005.937754004894, "train/extr_critic_mag": 0.8543857727387939, "train/extr_critic_max": 0.8543857727387939, "train/extr_critic_mean": 0.8031833659518849, "train/extr_critic_min": 0.7663401274970083, "train/extr_critic_std": 0.015501463957450758, "train/extr_return_normed_mag": 0.6733240081806375, "train/extr_return_normed_max": 0.3232333166430695, "train/extr_return_normed_mean": 0.04690722274391752, "train/extr_return_normed_min": -0.6412702458675461, "train/extr_return_normed_std": 0.04727147113193165, "train/extr_return_rate": 0.9959547089205848, "train/extr_return_raw_mag": 1.0837703615125984, "train/extr_return_raw_max": 1.0837703615125984, "train/extr_return_raw_mean": 0.8074443087433324, "train/extr_return_raw_min": 0.11926679900198271, "train/extr_return_raw_std": 0.047271471174264494, "train/extr_reward_mag": 0.35389146720520176, "train/extr_reward_max": 0.35389146720520176, "train/extr_reward_mean": 0.0025633630152283745, "train/extr_reward_min": 1.1680102107500789e-07, "train/extr_reward_std": 0.015856059261061477, "train/image_loss_mean": 0.10182929878132511, "train/image_loss_std": 0.10118082402782007, "train/model_loss_mean": 0.7204559343029754, "train/model_loss_std": 0.31807142232704644, "train/model_opt_grad_norm": 25.808610550080886, "train/model_opt_grad_steps": 28607.833333333332, "train/model_opt_loss": 2851.588962747593, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3952.020202020202, "train/policy_entropy_mag": 1.4381891753938463, "train/policy_entropy_max": 1.4381891753938463, "train/policy_entropy_mean": 0.1570600201987257, "train/policy_entropy_min": 0.06468654732511502, "train/policy_entropy_std": 0.19931167860825857, "train/policy_logprob_mag": 6.551080195590703, "train/policy_logprob_max": -0.008608140912132732, "train/policy_logprob_mean": -0.15718803885910246, "train/policy_logprob_min": -6.551080195590703, "train/policy_logprob_std": 0.6920574500103189, "train/policy_randomness_mag": 0.7390830736569683, "train/policy_randomness_max": 0.7390830736569683, "train/policy_randomness_mean": 0.08071288863441559, "train/policy_randomness_min": 0.033242311799014455, "train/policy_randomness_std": 0.10242594746552934, "train/post_ent_mag": 46.94075135510377, "train/post_ent_max": 46.94075135510377, "train/post_ent_mean": 43.82757327532527, "train/post_ent_min": 42.32748366847183, "train/post_ent_std": 0.8926608743089618, "train/prior_ent_mag": 48.94198479315247, "train/prior_ent_max": 48.94198479315247, "train/prior_ent_mean": 44.26445932099313, "train/prior_ent_min": 40.985891457759976, "train/prior_ent_std": 1.3412891999639647, "train/rep_loss_mean": 1.000012806569687, "train/rep_loss_std": 0.00033838618110901806, "train/reward_avg": 0.0006012579449614148, "train/reward_loss_mean": 0.0049723705901256335, "train/reward_loss_std": 0.10825187780581547, "train/reward_max_data": 0.4256944459195089, "train/reward_max_pred": 0.1560018484038536, "train/reward_neg_acc": 0.9998025015147045, "train/reward_neg_loss": 0.0007999698275604962, "train/reward_pos_acc": 0.2939276496569316, "train/reward_pos_loss": 4.124581685361936, "train/reward_pred": 0.0004724200727944874, "train/reward_rate": 0.0010012231691919192, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.010832262225449085, "report/cont_loss_std": 0.16146118938922882, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 1.705962061882019, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0025146477855741978, "report/cont_pred": 0.9953486919403076, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0000211000442505, "report/dyn_loss_std": 0.0006737620569765568, "report/image_loss_mean": 0.09301666915416718, "report/image_loss_std": 0.0921458750963211, "report/model_loss_mean": 0.707310676574707, "report/model_loss_std": 0.23842936754226685, "report/post_ent_mag": 42.10288619995117, "report/post_ent_max": 42.10288619995117, "report/post_ent_mean": 39.067779541015625, "report/post_ent_min": 37.678897857666016, "report/post_ent_std": 0.8870936632156372, "report/prior_ent_mag": 44.07455825805664, "report/prior_ent_max": 44.07455825805664, "report/prior_ent_mean": 40.393062591552734, "report/prior_ent_min": 37.854530334472656, "report/prior_ent_std": 1.1325069665908813, "report/rep_loss_mean": 1.0000211000442505, "report/rep_loss_std": 0.0006737620569765568, "report/reward_avg": 0.0006835937383584678, "report/reward_loss_mean": 0.0034490390680730343, "report/reward_loss_std": 0.0966743528842926, "report/reward_max_data": 0.699999988079071, "report/reward_max_pred": 0.060791015625, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0004282020963728428, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.0937652587890625, "report/reward_pred": 0.00026423693634569645, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.033025264739990234, "eval/cont_loss_std": 0.4577028155326843, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.3235578536987305, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002159059513360262, "eval/cont_pred": 0.997916042804718, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1787826418876648, "eval/image_loss_std": 0.1560979038476944, "eval/model_loss_mean": 0.8118419647216797, "eval/model_loss_std": 0.4803079664707184, "eval/post_ent_mag": 42.13251876831055, "eval/post_ent_max": 42.13251876831055, "eval/post_ent_mean": 39.030059814453125, "eval/post_ent_min": 37.53313064575195, "eval/post_ent_std": 0.8869755268096924, "eval/prior_ent_mag": 44.25461959838867, "eval/prior_ent_max": 44.25461959838867, "eval/prior_ent_mean": 40.42903137207031, "eval/prior_ent_min": 38.066650390625, "eval/prior_ent_std": 1.1936120986938477, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 3.4008175134658813e-05, "eval/reward_loss_std": 0.0003132757847197354, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0024968385696411133, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 3.4008175134658813e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 1.610198523849249e-05, "eval/reward_rate": 0.0, "replay/size": 475073.0, "replay/inserts": 31792.0, "replay/samples": 31792.0, "replay/insert_wait_avg": 1.4751024682976579e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.13166940398233e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5960.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2995412685727114e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2048380374908, "timer/env.step_count": 3974.0, "timer/env.step_total": 41.46942138671875, "timer/env.step_frac": 0.04146092861146943, "timer/env.step_avg": 0.010435184042958921, "timer/env.step_min": 0.008829832077026367, "timer/env.step_max": 0.04176974296569824, "timer/replay._sample_count": 31792.0, "timer/replay._sample_total": 17.214136838912964, "timer/replay._sample_frac": 0.017210611451039314, "timer/replay._sample_avg": 0.0005414612745002819, "timer/replay._sample_min": 0.00041961669921875, "timer/replay._sample_max": 0.032108306884765625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4719.0, "timer/agent.policy_total": 53.74200963973999, "timer/agent.policy_frac": 0.053731003486433414, "timer/agent.policy_avg": 0.011388431794816696, "timer/agent.policy_min": 0.009502887725830078, "timer/agent.policy_max": 0.09705996513366699, "timer/dataset_train_count": 1987.0, "timer/dataset_train_total": 0.2453782558441162, "timer/dataset_train_frac": 0.000245328003337371, "timer/dataset_train_avg": 0.00012349182478314856, "timer/dataset_train_min": 0.00010657310485839844, "timer/dataset_train_max": 0.0007929801940917969, "timer/agent.train_count": 1987.0, "timer/agent.train_total": 890.0754163265228, "timer/agent.train_frac": 0.8898931323637128, "timer/agent.train_avg": 0.44794937912759075, "timer/agent.train_min": 0.43652939796447754, "timer/agent.train_max": 0.7091202735900879, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47661399841308594, "timer/agent.report_frac": 0.00047651638973098123, "timer/agent.report_avg": 0.23830699920654297, "timer/agent.report_min": 0.2304372787475586, "timer/agent.report_max": 0.24617671966552734, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00012445449829101562, "timer/dataset_eval_frac": 1.2442901049669855e-07, "timer/dataset_eval_avg": 0.00012445449829101562, "timer/dataset_eval_min": 0.00012445449829101562, "timer/dataset_eval_max": 0.00012445449829101562, "fps": 31.784933957430095}
{"step": 475680, "time": 15282.424853563309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 475728, "time": 15283.90552854538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476000, "time": 15292.288400650024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476024, "time": 15292.807675600052, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 476216, "time": 15298.733752012253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476288, "time": 15301.180753231049, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 476368, "time": 15303.642727851868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476504, "time": 15307.605062246323, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 476864, "time": 15319.035816669464, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 476944, "time": 15321.50947523117, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 477256, "time": 15330.89489197731, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 477352, "time": 15333.842329978943, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 477816, "time": 15348.261811733246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477976, "time": 15353.207840919495, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 477992, "time": 15353.712024211884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478312, "time": 15363.588570356369, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478528, "time": 15370.641345739365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478640, "time": 15374.074625015259, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 478944, "time": 15383.441624403, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 479008, "time": 15385.426151752472, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 479176, "time": 15390.371653079987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479232, "time": 15392.320361852646, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 479296, "time": 15394.278385400772, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 479352, "time": 15395.786235809326, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 479568, "time": 15402.76336979866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479616, "time": 15404.237846374512, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 479664, "time": 15405.728970527649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 15418.012597322464, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 15418.941688776016, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 480064, "time": 15419.204442501068, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 480064, "time": 15419.534883737564, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 480064, "time": 15419.56390452385, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 480064, "time": 15420.712582349777, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 480064, "time": 15420.829183340073, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 480064, "time": 15421.823189735413, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 480064, "time": 15423.298063278198, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 480304, "time": 15430.826257228851, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480840, "time": 15447.094600439072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481488, "time": 15467.364956378937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481664, "time": 15472.773756504059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481880, "time": 15479.204566955566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481896, "time": 15479.705292224884, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 481928, "time": 15480.692262411118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 481976, "time": 15482.179133415222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482376, "time": 15494.6005859375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482616, "time": 15502.0065741539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 482904, "time": 15510.908859491348, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 483152, "time": 15518.893425226212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483512, "time": 15530.30368423462, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 483800, "time": 15539.185934066772, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484208, "time": 15552.101321697235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484240, "time": 15553.090018510818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484288, "time": 15554.584822177887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484688, "time": 15566.880308389664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485216, "time": 15583.227332115173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485248, "time": 15584.23382282257, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 485352, "time": 15587.21774148941, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 485464, "time": 15590.690107822418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485656, "time": 15596.591970205307, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 485704, "time": 15598.07486820221, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 485784, "time": 15600.542711257935, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 485824, "time": 15602.004178762436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485912, "time": 15604.506843566895, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 486112, "time": 15610.95398402214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 486536, "time": 15623.748397827148, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 486600, "time": 15625.71246790886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487000, "time": 15638.031499147415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487080, "time": 15640.620533943176, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 487416, "time": 15650.948154449463, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 487776, "time": 15662.25055551529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487968, "time": 15668.16808462143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488016, "time": 15669.759177207947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488224, "time": 15676.156865596771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488424, "time": 15682.096368312836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 488568, "time": 15686.516975164413, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 488912, "time": 15697.368718862534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489024, "time": 15700.875489473343, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 489128, "time": 15703.86889386177, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 489304, "time": 15709.282111406326, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 489392, "time": 15712.244070768356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489728, "time": 15722.567974090576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489944, "time": 15729.141442775726, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 15733.33952832222, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 490048, "time": 15733.36688375473, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 490048, "time": 15733.94001340866, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 490048, "time": 15738.821872234344, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15738.832121372223, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15738.844015836716, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15738.854702472687, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15738.86407327652, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15738.87347126007, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490088, "time": 15739.912010192871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490304, "time": 15746.745289325714, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 490328, "time": 15747.264160633087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490536, "time": 15753.713259458542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491224, "time": 15774.962751150131, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491440, "time": 15781.834877967834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491616, "time": 15787.787418365479, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491704, "time": 15790.405368566513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492048, "time": 15801.249835729599, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 492152, "time": 15804.271337747574, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 492400, "time": 15812.170725345612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492520, "time": 15815.636359930038, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 492536, "time": 15816.132448196411, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 492704, "time": 15821.654643535614, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 492848, "time": 15826.074259996414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493280, "time": 15839.333547115326, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 493536, "time": 15847.187175273895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493752, "time": 15853.727664470673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 493928, "time": 15859.14735007286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494032, "time": 15862.574124097824, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 494176, "time": 15866.988341093063, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 494360, "time": 15872.47494840622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494832, "time": 15887.298829555511, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494848, "time": 15887.79588675499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495112, "time": 15895.648853302002, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 495160, "time": 15897.150417089462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 495456, "time": 15906.450659275055, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 495664, "time": 15912.986328840256, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 495776, "time": 15916.421170949936, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 495848, "time": 15918.42876958847, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 496176, "time": 15928.74194598198, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 496440, "time": 15936.653672218323, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 496488, "time": 15938.140461444855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496672, "time": 15944.159405231476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 496760, "time": 15946.643053293228, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 497160, "time": 15958.916041851044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497192, "time": 15959.905153512955, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 497472, "time": 15968.857746839523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497872, "time": 15981.159110546112, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 498000, "time": 15985.083389759064, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 498160, "time": 15990.020323991776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498192, "time": 15991.037411689758, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 498288, "time": 15993.984345674515, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 498424, "time": 15997.952836036682, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 498488, "time": 16000.036969423294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 498800, "time": 16009.862639188766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499040, "time": 16017.279990434647, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 499064, "time": 16017.804852962494, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 499232, "time": 16023.195155620575, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 499296, "time": 16025.166320085526, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 499312, "time": 16025.684393167496, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 499400, "time": 16028.17467045784, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 499472, "time": 16030.770468473434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 499752, "time": 16039.677787780762, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 499928, "time": 16045.108678340912, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 16049.186110019684, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 500032, "time": 16049.326534509659, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 500032, "time": 16050.022046089172, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 500032, "time": 16050.134146213531, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 500032, "time": 16050.312078237534, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 500032, "time": 16052.552673101425, "eval_episode/length": 182.0, "eval_episode/score": 0.4312500059604645, "eval_episode/reward_rate": 0.00546448087431694}
{"step": 500032, "time": 16054.81770992279, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16054.826311826706, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500152, "time": 16058.346050024033, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 500208, "time": 16060.358093261719, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 500504, "time": 16069.228967905045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500656, "time": 16074.148316144943, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 500672, "time": 16074.643768310547, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 500736, "time": 16076.606356143951, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 501240, "time": 16091.98178434372, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 501544, "time": 16101.329860210419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501784, "time": 16108.739476442337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502520, "time": 16131.51499247551, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502640, "time": 16135.410536527634, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 502808, "time": 16140.388618707657, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 502816, "time": 16140.864444255829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502968, "time": 16145.321670293808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 502984, "time": 16145.827952861786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503048, "time": 16147.833052158356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503096, "time": 16149.41839838028, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 503344, "time": 16157.300127983093, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 503560, "time": 16163.769445896149, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 503784, "time": 16170.692162752151, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 503856, "time": 16173.170183420181, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 504832, "time": 16203.365563869476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504952, "time": 16206.85236620903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505280, "time": 16217.260895967484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505360, "time": 16219.726810216904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505360, "time": 16219.747309923172, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 505656, "time": 16228.647716999054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505656, "time": 16228.658140659332, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 505872, "time": 16235.58129119873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505944, "time": 16237.564497470856, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 506000, "time": 16239.647805452347, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 506168, "time": 16244.597469806671, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506304, "time": 16248.992738962173, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 506824, "time": 16264.723386526108, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 506896, "time": 16267.17153596878, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 506928, "time": 16268.151789665222, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 507000, "time": 16270.26764535904, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 507056, "time": 16272.19689488411, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 507112, "time": 16273.6896982193, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 507224, "time": 16277.14827299118, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 507273, "time": 16279.62185382843, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2054030293166034, "train/action_min": 0.0, "train/action_std": 1.7702107230822246, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009024113073893305, "train/actor_opt_grad_steps": 30615.0, "train/actor_opt_loss": -6.927268800636132, "train/adv_mag": 0.688156615453537, "train/adv_max": 0.24012390200537864, "train/adv_mean": 0.0006609227759253547, "train/adv_min": -0.6660242250772438, "train/adv_std": 0.030869954726611724, "train/cont_avg": 0.9957534327651515, "train/cont_loss_mean": 0.013357531487461969, "train/cont_loss_std": 0.21019335460585703, "train/cont_neg_acc": 0.3963762059580856, "train/cont_neg_loss": 2.552341391029886, "train/cont_pos_acc": 0.9998167205338526, "train/cont_pos_loss": 0.0026219257487529756, "train/cont_pred": 0.9958823160691694, "train/cont_rate": 0.9957534327651515, "train/dyn_loss_mean": 1.0000131900864417, "train/dyn_loss_std": 0.00039768825062117577, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.31821410391818394, "train/extr_critic_critic_opt_grad_steps": 30615.0, "train/extr_critic_critic_opt_loss": 8209.063172003236, "train/extr_critic_mag": 0.8830412909238026, "train/extr_critic_max": 0.8830412909238026, "train/extr_critic_mean": 0.8371639010882137, "train/extr_critic_min": 0.7937676617593477, "train/extr_critic_std": 0.01229366972910786, "train/extr_return_normed_mag": 0.6777358416355017, "train/extr_return_normed_max": 0.28011000487539506, "train/extr_return_normed_mean": 0.025423841042952103, "train/extr_return_normed_min": -0.646613640917672, "train/extr_return_normed_std": 0.03396948253867602, "train/extr_return_rate": 0.9972387073617993, "train/extr_return_raw_mag": 1.0925109672425972, "train/extr_return_raw_max": 1.0925109672425972, "train/extr_return_raw_mean": 0.8378248497693226, "train/extr_return_raw_min": 0.16578732144953023, "train/extr_return_raw_std": 0.03396948247752858, "train/extr_reward_mag": 0.3390236129664411, "train/extr_reward_max": 0.3390236129664411, "train/extr_reward_mean": 0.001748134883375241, "train/extr_reward_min": 9.091213496044429e-08, "train/extr_reward_std": 0.010987979610982078, "train/image_loss_mean": 0.09778627042065967, "train/image_loss_std": 0.10037648817053949, "train/model_loss_mean": 0.7164581607688557, "train/model_loss_std": 0.3245905824758188, "train/model_opt_grad_norm": 24.431711431687255, "train/model_opt_grad_steps": 30586.58080808081, "train/model_opt_loss": 3463.037484217172, "train/model_opt_model_opt_grad_overflow": 0.005050505050505051, "train/model_opt_model_opt_grad_scale": 4810.606060606061, "train/policy_entropy_mag": 1.3690186630595813, "train/policy_entropy_max": 1.3690186630595813, "train/policy_entropy_mean": 0.12336767479927853, "train/policy_entropy_min": 0.0646865354719186, "train/policy_entropy_std": 0.16240613188857983, "train/policy_logprob_mag": 6.551080231714731, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.12345201382883872, "train/policy_logprob_min": -6.551080231714731, "train/policy_logprob_std": 0.6610194688493555, "train/policy_randomness_mag": 0.7035364626031934, "train/policy_randomness_max": 0.7035364626031934, "train/policy_randomness_mean": 0.06339844718876511, "train/policy_randomness_min": 0.03324230545849511, "train/policy_randomness_std": 0.08346024637270455, "train/post_ent_mag": 40.895424679072214, "train/post_ent_max": 40.895424679072214, "train/post_ent_mean": 37.155671591710565, "train/post_ent_min": 35.46618817069314, "train/post_ent_std": 1.063788842974287, "train/prior_ent_mag": 41.43197275412203, "train/prior_ent_max": 41.43197275412203, "train/prior_ent_mean": 37.19377951188521, "train/prior_ent_min": 34.08845467037625, "train/prior_ent_std": 1.2586095905063128, "train/rep_loss_mean": 1.0000131900864417, "train/rep_loss_std": 0.00039768825062117577, "train/reward_avg": 0.0006800796030012237, "train/reward_loss_mean": 0.005306425119863089, "train/reward_loss_std": 0.11511293812325657, "train/reward_max_data": 0.4803345954854681, "train/reward_max_pred": 0.1687304214997725, "train/reward_neg_acc": 0.9997630239737154, "train/reward_neg_loss": 0.0008197304019686823, "train/reward_pos_acc": 0.3159472429923874, "train/reward_pos_loss": 4.028264278988186, "train/reward_pred": 0.0005109683278891625, "train/reward_rate": 0.0010850694444444445, "train_stats/mean_log_entropy": 0.10741415306837601, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.0034121712669730186, "report/cont_loss_std": 0.028986135497689247, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0034121712669730186, "report/cont_pred": 0.9969428777694702, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09918540716171265, "report/image_loss_std": 0.096834197640419, "report/model_loss_mean": 0.7048190832138062, "report/model_loss_std": 0.11670007556676865, "report/post_ent_mag": 36.20824432373047, "report/post_ent_max": 36.20824432373047, "report/post_ent_mean": 32.08348846435547, "report/post_ent_min": 30.401294708251953, "report/post_ent_std": 1.0397286415100098, "report/prior_ent_mag": 38.19438171386719, "report/prior_ent_max": 38.19438171386719, "report/prior_ent_mean": 33.710968017578125, "report/prior_ent_min": 30.76750373840332, "report/prior_ent_std": 1.2713099718093872, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.002221436472609639, "report/reward_loss_std": 0.037985656410455704, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.34367382526397705, "report/reward_neg_acc": 0.998046875, "report/reward_neg_loss": 0.002221436472609639, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.000851541175507009, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04142576828598976, "eval/cont_loss_std": 0.6375460028648376, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.156322479248047, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0017595100216567516, "eval/cont_pred": 0.9983327984809875, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18409046530723572, "eval/image_loss_std": 0.12886178493499756, "eval/model_loss_mean": 0.8256058096885681, "eval/model_loss_std": 0.6471303105354309, "eval/post_ent_mag": 36.20833969116211, "eval/post_ent_max": 36.20833969116211, "eval/post_ent_mean": 32.107627868652344, "eval/post_ent_min": 30.589187622070312, "eval/post_ent_std": 1.1310698986053467, "eval/prior_ent_mag": 38.28492736816406, "eval/prior_ent_max": 38.28492736816406, "eval/prior_ent_mean": 33.745574951171875, "eval/prior_ent_min": 30.725013732910156, "eval/prior_ent_std": 1.3573617935180664, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 8.952803909778595e-05, "eval/reward_loss_std": 0.0007855152362026274, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.006216883659362793, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 8.952803909778595e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.3994863517582417e-05, "eval/reward_rate": 0.0, "replay/size": 506769.0, "replay/inserts": 31696.0, "replay/samples": 31696.0, "replay/insert_wait_avg": 1.4889577252283534e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.137869389595136e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6552.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3402675679897359e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3820013999939, "timer/env.step_count": 3962.0, "timer/env.step_total": 41.01993131637573, "timer/env.step_frac": 0.04100426762873583, "timer/env.step_avg": 0.010353339554865152, "timer/env.step_min": 0.008002042770385742, "timer/env.step_max": 0.04028940200805664, "timer/replay._sample_count": 31696.0, "timer/replay._sample_total": 17.018991947174072, "timer/replay._sample_frac": 0.017012493150973015, "timer/replay._sample_avg": 0.0005369444708219987, "timer/replay._sample_min": 0.0004105567932128906, "timer/replay._sample_max": 0.025447845458984375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4781.0, "timer/agent.policy_total": 53.885751485824585, "timer/agent.policy_frac": 0.05386517491359667, "timer/agent.policy_avg": 0.011270811856478683, "timer/agent.policy_min": 0.009298563003540039, "timer/agent.policy_max": 0.0874013900756836, "timer/dataset_train_count": 1981.0, "timer/dataset_train_total": 0.24728155136108398, "timer/dataset_train_frac": 0.0002471871255330699, "timer/dataset_train_avg": 0.00012482662865274306, "timer/dataset_train_min": 0.00010776519775390625, "timer/dataset_train_max": 0.0011010169982910156, "timer/agent.train_count": 1981.0, "timer/agent.train_total": 890.2348239421844, "timer/agent.train_frac": 0.889894882851088, "timer/agent.train_avg": 0.4493865845240709, "timer/agent.train_min": 0.4392683506011963, "timer/agent.train_max": 0.7153375148773193, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48067688941955566, "timer/agent.report_frac": 0.0004804933402908768, "timer/agent.report_avg": 0.24033844470977783, "timer/agent.report_min": 0.23437905311584473, "timer/agent.report_max": 0.24629783630371094, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.431916542138741e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 31.68334644206163}
{"step": 507312, "time": 16280.873982906342, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 507536, "time": 16287.77573132515, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 507552, "time": 16288.280801534653, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 507576, "time": 16288.80493927002, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 507584, "time": 16289.285693883896, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 507768, "time": 16294.739879846573, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 509208, "time": 16339.791988134384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509312, "time": 16343.236997365952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509624, "time": 16352.682505846024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509840, "time": 16359.709938049316, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 509848, "time": 16359.751982212067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509864, "time": 16360.261422872543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509888, "time": 16361.248587369919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509896, "time": 16361.28021979332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 16367.64628124237, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 510016, "time": 16368.70484161377, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 510016, "time": 16370.500128030777, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 510016, "time": 16372.056905031204, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16372.073866605759, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16372.103827953339, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16372.138005256653, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16372.156904935837, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16372.17801976204, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510016, "time": 16372.201686382294, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 510080, "time": 16374.198498725891, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510560, "time": 16389.07213449478, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 511248, "time": 16410.235453128815, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 511520, "time": 16418.71502327919, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 511936, "time": 16431.518983125687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512152, "time": 16437.969954013824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512160, "time": 16438.446172237396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512200, "time": 16439.455835580826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512208, "time": 16439.932398319244, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 512208, "time": 16439.942269563675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512392, "time": 16445.39392399788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 512712, "time": 16455.374856948853, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 513008, "time": 16464.72448658943, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 513016, "time": 16464.755195379257, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 513096, "time": 16467.244967222214, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 513592, "time": 16482.657440900803, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 513656, "time": 16484.61411380768, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 513832, "time": 16490.046625375748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513840, "time": 16490.521127700806, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 513920, "time": 16493.006301641464, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 514248, "time": 16502.931016921997, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 514520, "time": 16511.431141138077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514688, "time": 16516.84611058235, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 514704, "time": 16517.350670814514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514848, "time": 16521.807530641556, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 515264, "time": 16534.6300137043, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 515872, "time": 16553.507923603058, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 515904, "time": 16554.50153708458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516128, "time": 16562.03687596321, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 516152, "time": 16562.556621074677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516376, "time": 16569.61782026291, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 516488, "time": 16573.067098379135, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 516560, "time": 16575.49130678177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516744, "time": 16580.90753221512, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 517000, "time": 16588.74059152603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517016, "time": 16589.239951610565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 517264, "time": 16597.1078915596, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 517944, "time": 16617.821360111237, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 518224, "time": 16626.665147542953, "episode/length": 261.0, "episode/score": 0.18437500298023224, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0}
{"step": 518464, "time": 16634.126932144165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518560, "time": 16637.07270169258, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 518688, "time": 16641.02053952217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518800, "time": 16644.43556380272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518872, "time": 16646.442843914032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519312, "time": 16660.268837213516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 519576, "time": 16668.11536335945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 16683.711841344833, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 520000, "time": 16685.004448890686, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 520000, "time": 16687.57791519165, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16687.58574938774, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16687.59393978119, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16687.60192012787, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16687.61002612114, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520000, "time": 16687.619325876236, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 520256, "time": 16695.572928905487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520536, "time": 16703.984925031662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 520872, "time": 16714.38771033287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521000, "time": 16718.431861162186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521112, "time": 16721.942215681076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521184, "time": 16724.39323782921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521480, "time": 16733.337643384933, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 521624, "time": 16737.79157090187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521888, "time": 16746.182103395462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521968, "time": 16748.76428294182, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 522568, "time": 16767.10163640976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523184, "time": 16786.49209880829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523312, "time": 16790.460344552994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523416, "time": 16793.423711061478, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 523424, "time": 16793.90295267105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523792, "time": 16805.265274763107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523936, "time": 16809.819542646408, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524280, "time": 16820.275498390198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524696, "time": 16833.63208913803, "episode/length": 265.0, "episode/score": 0.171875, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.0}
{"step": 525008, "time": 16843.613353967667, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 525048, "time": 16844.627194166183, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 525360, "time": 16854.4387280941, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 525624, "time": 16862.361733436584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525736, "time": 16865.808848142624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525928, "time": 16871.789891004562, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 526064, "time": 16876.18787407875, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 526552, "time": 16890.941974639893, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 526592, "time": 16892.41055393219, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526688, "time": 16895.35203242302, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 527264, "time": 16913.122886419296, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 527320, "time": 16914.652239322662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527672, "time": 16925.426685333252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527848, "time": 16930.926408290863, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 528240, "time": 16943.205191373825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528376, "time": 16947.157195091248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528864, "time": 16962.54089975357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528904, "time": 16963.550124645233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529000, "time": 16966.51091647148, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529056, "time": 16968.45413541794, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 529256, "time": 16974.39262008667, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 529640, "time": 16986.18772339821, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 529984, "time": 16997.112829208374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530080, "time": 17000.10564684868, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 17000.910358190536, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 530088, "time": 17001.5770881176, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 530088, "time": 17001.71115207672, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 530088, "time": 17001.71881723404, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 530088, "time": 17003.347651958466, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 530088, "time": 17003.737997293472, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 530088, "time": 17006.468262672424, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17006.47692489624, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17006.484399795532, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17006.491423368454, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530160, "time": 17008.94295477867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530544, "time": 17020.93072938919, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 530552, "time": 17020.962218523026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530736, "time": 17026.891950130463, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 530920, "time": 17032.36444568634, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 531176, "time": 17040.30655479431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531216, "time": 17041.771409749985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 531224, "time": 17041.804911613464, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 531248, "time": 17042.775616168976, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 531288, "time": 17043.79416012764, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 531952, "time": 17064.608572483063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532024, "time": 17066.609184503555, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 532296, "time": 17075.03431034088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533224, "time": 17104.316923379898, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 533232, "time": 17104.81392264366, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 533488, "time": 17112.821185112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533528, "time": 17113.82813000679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533600, "time": 17116.28454875946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533656, "time": 17117.781626701355, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 533944, "time": 17126.677238225937, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 534264, "time": 17136.55679178238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534336, "time": 17139.143359422684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534656, "time": 17148.985818624496, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 534944, "time": 17157.883507728577, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 534984, "time": 17158.907284498215, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 535536, "time": 17176.175117969513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535728, "time": 17182.052646160126, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 535840, "time": 17185.495404481888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535912, "time": 17187.506399154663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535968, "time": 17189.489966392517, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 536216, "time": 17196.927538633347, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 536256, "time": 17198.489038705826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536264, "time": 17198.53098988533, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 536648, "time": 17210.33496284485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536968, "time": 17220.13770365715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537016, "time": 17221.608841896057, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 537432, "time": 17234.54802083969, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 538040, "time": 17253.260329961777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538152, "time": 17256.67263317108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538280, "time": 17260.721251249313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538360, "time": 17263.18785595894, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 538528, "time": 17268.57229566574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538568, "time": 17269.577970027924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538873, "time": 17279.924847364426, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.583145295730745, "train/action_min": 0.0, "train/action_std": 1.730048626360267, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010603910072170424, "train/actor_opt_grad_steps": 32595.0, "train/actor_opt_loss": -6.271449652585116, "train/adv_mag": 0.7619148384441029, "train/adv_max": 0.2834085418720438, "train/adv_mean": 0.004394031842527299, "train/adv_min": -0.7495877276165317, "train/adv_std": 0.037046878114154545, "train/cont_avg": 0.9959901751893939, "train/cont_loss_mean": 0.012760632886901742, "train/cont_loss_std": 0.2045960529681502, "train/cont_neg_acc": 0.4001430251120311, "train/cont_neg_loss": 2.5769057291238404, "train/cont_pos_acc": 0.9998463777580646, "train/cont_pos_loss": 0.002613989325861136, "train/cont_pred": 0.9959407129673042, "train/cont_rate": 0.9959901751893939, "train/dyn_loss_mean": 1.000003498009961, "train/dyn_loss_std": 7.863410909788335e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.6077009796005006, "train/extr_critic_critic_opt_grad_steps": 32595.0, "train/extr_critic_critic_opt_loss": 6098.542555683791, "train/extr_critic_mag": 0.9578135663812811, "train/extr_critic_max": 0.9578135663812811, "train/extr_critic_mean": 0.8988402868160094, "train/extr_critic_min": 0.8165388366188666, "train/extr_critic_std": 0.015426316307951706, "train/extr_return_normed_mag": 0.7412983588498048, "train/extr_return_normed_max": 0.3205124895380001, "train/extr_return_normed_mean": 0.03714766525051961, "train/extr_return_normed_min": -0.7206791308191087, "train/extr_return_normed_std": 0.04153855394270986, "train/extr_return_rate": 0.9976441312317896, "train/extr_return_raw_mag": 1.1865991071017101, "train/extr_return_raw_max": 1.1865991071017101, "train/extr_return_raw_mean": 0.9032343285854416, "train/extr_return_raw_min": 0.14540748674460133, "train/extr_return_raw_std": 0.041538554036782846, "train/extr_reward_mag": 0.35830645067523226, "train/extr_reward_max": 0.35830645067523226, "train/extr_reward_mean": 0.0023347609464021524, "train/extr_reward_min": 1.3245476616753473e-07, "train/extr_reward_std": 0.013610196342771741, "train/image_loss_mean": 0.09343118412476598, "train/image_loss_std": 0.09909710284284871, "train/model_loss_mean": 0.7115979077238025, "train/model_loss_std": 0.31926166729042027, "train/model_opt_grad_norm": 24.692996660868328, "train/model_opt_grad_steps": 32564.70707070707, "train/model_opt_loss": 3593.700154622396, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5050.50505050505, "train/policy_entropy_mag": 1.3365857155636103, "train/policy_entropy_max": 1.3365857155636103, "train/policy_entropy_mean": 0.12240814093989555, "train/policy_entropy_min": 0.0646865043149452, "train/policy_entropy_std": 0.157600967796764, "train/policy_logprob_mag": 6.551080241347805, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.12170686147580242, "train/policy_logprob_min": -6.551080241347805, "train/policy_logprob_std": 0.654806299041016, "train/policy_randomness_mag": 0.6868692227084228, "train/policy_randomness_max": 0.6868692227084228, "train/policy_randomness_mean": 0.0629053447169788, "train/policy_randomness_min": 0.03324228833721141, "train/policy_randomness_std": 0.08099088121694747, "train/post_ent_mag": 37.0542330693717, "train/post_ent_max": 37.0542330693717, "train/post_ent_mean": 31.77627951689441, "train/post_ent_min": 29.467992878923514, "train/post_ent_std": 1.4812617735429243, "train/prior_ent_mag": 36.829703803014276, "train/prior_ent_max": 36.829703803014276, "train/prior_ent_mean": 31.83484804750693, "train/prior_ent_min": 28.588061246004973, "train/prior_ent_std": 1.4234218169944455, "train/rep_loss_mean": 1.000003498009961, "train/rep_loss_std": 7.863410909788335e-05, "train/reward_avg": 0.0007033839393636409, "train/reward_loss_mean": 0.0054039687219292224, "train/reward_loss_std": 0.11479839009810192, "train/reward_max_data": 0.4788194445498062, "train/reward_max_pred": 0.17849521745334973, "train/reward_neg_acc": 0.9997333926383896, "train/reward_neg_loss": 0.0009270844463819892, "train/reward_pos_acc": 0.29539801069160004, "train/reward_pos_loss": 4.072322351719016, "train/reward_pred": 0.0005930412220862704, "train/reward_rate": 0.0011195943813131313, "train_stats/mean_log_entropy": 0.11312133466748342, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.01958349347114563, "report/cont_loss_std": 0.2950931489467621, "report/cont_neg_acc": 0.4285714626312256, "report/cont_neg_loss": 2.5564446449279785, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.002122307661920786, "report/cont_pred": 0.9949100017547607, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09918348491191864, "report/image_loss_std": 0.09050719439983368, "report/model_loss_mean": 0.7266883850097656, "report/model_loss_std": 0.49620598554611206, "report/post_ent_mag": 34.469398498535156, "report/post_ent_max": 34.469398498535156, "report/post_ent_mean": 28.78879165649414, "report/post_ent_min": 26.250308990478516, "report/post_ent_std": 1.6592496633529663, "report/prior_ent_mag": 34.26079559326172, "report/prior_ent_max": 34.26079559326172, "report/prior_ent_mean": 29.159793853759766, "report/prior_ent_min": 25.811656951904297, "report/prior_ent_std": 1.5387089252471924, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004089355352334678, "report/reward_loss_mean": 0.007921330630779266, "report/reward_loss_std": 0.24125465750694275, "report/reward_max_data": 0.41874998807907104, "report/reward_max_pred": 0.015611648559570312, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0003787415334954858, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 7.723989963531494, "report/reward_pred": 0.00018609105609357357, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.02008149027824402, "eval/cont_loss_std": 0.34675484895706177, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.604351997375488, "eval/cont_pos_acc": 0.9980430603027344, "eval/cont_pos_loss": 0.005239472258836031, "eval/cont_pred": 0.9963415861129761, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16479696333408356, "eval/image_loss_std": 0.14244075119495392, "eval/model_loss_mean": 0.7853655219078064, "eval/model_loss_std": 0.3718859553337097, "eval/post_ent_mag": 34.4691276550293, "eval/post_ent_max": 34.4691276550293, "eval/post_ent_mean": 28.367586135864258, "eval/post_ent_min": 25.93372917175293, "eval/post_ent_std": 1.639893651008606, "eval/prior_ent_mag": 34.446441650390625, "eval/prior_ent_max": 34.446441650390625, "eval/prior_ent_mean": 28.762798309326172, "eval/prior_ent_min": 25.810344696044922, "eval/prior_ent_std": 1.490954875946045, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0004870255943387747, "eval/reward_loss_std": 0.004454548470675945, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.04966127872467041, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0004870255943387747, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023750902619212866, "eval/reward_rate": 0.0, "replay/size": 538369.0, "replay/inserts": 31600.0, "replay/samples": 31600.0, "replay/insert_wait_avg": 1.492560664309731e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.119887943509259e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.293187047920975e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2799673080444, "timer/env.step_count": 3950.0, "timer/env.step_total": 40.79156279563904, "timer/env.step_frac": 0.0407801456880291, "timer/env.step_avg": 0.010326977922946592, "timer/env.step_min": 0.008836030960083008, "timer/env.step_max": 0.03593277931213379, "timer/replay._sample_count": 31600.0, "timer/replay._sample_total": 16.989027976989746, "timer/replay._sample_frac": 0.016984272935816815, "timer/replay._sample_avg": 0.0005376274676262578, "timer/replay._sample_min": 0.0004150867462158203, "timer/replay._sample_max": 0.011286020278930664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4817.0, "timer/agent.policy_total": 54.8140811920166, "timer/agent.policy_frac": 0.054798739336480336, "timer/agent.policy_avg": 0.01137929856591584, "timer/agent.policy_min": 0.009492158889770508, "timer/agent.policy_max": 0.10371637344360352, "timer/dataset_train_count": 1975.0, "timer/dataset_train_total": 0.2466294765472412, "timer/dataset_train_frac": 0.00024656044768243333, "timer/dataset_train_avg": 0.00012487568432771706, "timer/dataset_train_min": 0.00010657310485839844, "timer/dataset_train_max": 0.0010979175567626953, "timer/agent.train_count": 1975.0, "timer/agent.train_total": 888.5529596805573, "timer/agent.train_frac": 0.8883042635271732, "timer/agent.train_avg": 0.44990023274964924, "timer/agent.train_min": 0.43395018577575684, "timer/agent.train_max": 0.7553772926330566, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48131704330444336, "timer/agent.report_frac": 0.0004811823279833993, "timer/agent.report_avg": 0.24065852165222168, "timer/agent.report_min": 0.23429441452026367, "timer/agent.report_max": 0.2470226287841797, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.313090692429252e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 31.59056808200611}
{"step": 538960, "time": 17282.6385345459, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 539032, "time": 17284.63539671898, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 539272, "time": 17292.1484913826, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 539328, "time": 17294.124127388, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 539496, "time": 17299.10927605629, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 539648, "time": 17304.03936290741, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 539680, "time": 17305.0372338295, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 539808, "time": 17308.989005804062, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 539888, "time": 17311.476755142212, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 17318.461582899094, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 540072, "time": 17318.811429977417, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 540072, "time": 17319.171007871628, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 540072, "time": 17319.687070131302, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 540072, "time": 17320.198919057846, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 540072, "time": 17322.40178847313, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 540072, "time": 17322.664412260056, "eval_episode/length": 223.0, "eval_episode/score": 0.3031249940395355, "eval_episode/reward_rate": 0.004464285714285714}
{"step": 540072, "time": 17323.01515340805, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 540088, "time": 17323.511940717697, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 540184, "time": 17326.492032766342, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 540280, "time": 17329.451142311096, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 540352, "time": 17331.88991165161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540392, "time": 17332.905137062073, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 540464, "time": 17335.39539194107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540832, "time": 17347.228607177734, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 541272, "time": 17360.71784234047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 541992, "time": 17383.067234754562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542080, "time": 17386.012627601624, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 542200, "time": 17389.49219584465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542392, "time": 17395.41097688675, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 542400, "time": 17395.891098737717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542664, "time": 17403.803431987762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542704, "time": 17405.267039060593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542776, "time": 17407.256819486618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 543144, "time": 17418.70138669014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 543360, "time": 17425.611891508102, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 544136, "time": 17450.961302280426, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 544392, "time": 17458.81831884384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544512, "time": 17462.80161547661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544608, "time": 17465.75437450409, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 544640, "time": 17466.744460105896, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 544712, "time": 17468.859416007996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 544976, "time": 17477.206526517868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545016, "time": 17478.21491932869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545088, "time": 17480.675780534744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545456, "time": 17492.02011156082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545456, "time": 17492.062079191208, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 545464, "time": 17492.104843378067, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 545688, "time": 17499.138473272324, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 546056, "time": 17510.433078289032, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 546536, "time": 17525.198366880417, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 546920, "time": 17537.099225759506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547016, "time": 17540.056649923325, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 547248, "time": 17547.394215106964, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 547328, "time": 17549.906671524048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 547440, "time": 17553.341540575027, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 547720, "time": 17561.84212589264, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 547776, "time": 17563.787808418274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548248, "time": 17578.05032491684, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 548368, "time": 17581.986635684967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549232, "time": 17609.19590306282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549328, "time": 17612.167166233063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549512, "time": 17617.60378599167, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 549560, "time": 17619.241681575775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549640, "time": 17621.692534685135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 549792, "time": 17626.60492324829, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 550032, "time": 17633.988377809525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 17635.034710407257, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 550056, "time": 17636.113057136536, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 550056, "time": 17636.230484724045, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 550056, "time": 17636.73366832733, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 550056, "time": 17640.764623641968, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17640.772844791412, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17640.79163837433, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17640.800547122955, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550056, "time": 17640.808294057846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 550088, "time": 17641.79458284378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 550560, "time": 17656.656567573547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 550680, "time": 17660.14064002037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551000, "time": 17669.982779979706, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 551768, "time": 17693.66216635704, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 551824, "time": 17695.628506183624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551872, "time": 17697.117079734802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551952, "time": 17699.612513780594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552056, "time": 17702.582178115845, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 552104, "time": 17704.05521941185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552344, "time": 17711.575405836105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552400, "time": 17713.51047706604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552728, "time": 17723.37681698799, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 552824, "time": 17726.3362364769, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 553048, "time": 17733.230880498886, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 553128, "time": 17735.70408296585, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 553168, "time": 17737.156754493713, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 553176, "time": 17737.187600135803, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 553304, "time": 17741.25471830368, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 553376, "time": 17743.696822166443, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 553984, "time": 17762.37451982498, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 553992, "time": 17762.404827594757, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 554024, "time": 17763.392169952393, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 554184, "time": 17768.365748882294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554384, "time": 17774.782670021057, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 554592, "time": 17781.1680662632, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 554656, "time": 17783.132012605667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554680, "time": 17783.672839403152, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 555176, "time": 17799.01251721382, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 555688, "time": 17814.77550315857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556296, "time": 17833.62110733986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556304, "time": 17834.09703397751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556400, "time": 17837.04750227928, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 556696, "time": 17845.934494018555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556768, "time": 17848.39831471443, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 556784, "time": 17848.89641237259, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 556904, "time": 17852.40585064888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556992, "time": 17855.356955051422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557488, "time": 17871.285283088684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557512, "time": 17871.806504011154, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 557664, "time": 17876.701994895935, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 557880, "time": 17883.129455804825, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 558032, "time": 17888.012330055237, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 558592, "time": 17905.32296562195, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 558608, "time": 17905.820251703262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559008, "time": 17918.13972377777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559080, "time": 17920.236535549164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559184, "time": 17923.672634601593, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 559304, "time": 17927.126898527145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559720, "time": 17939.969415187836, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 559784, "time": 17941.951672792435, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 559800, "time": 17942.475127220154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559824, "time": 17943.44437646866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559880, "time": 17944.9430270195, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 559936, "time": 17946.892061948776, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 560000, "time": 17948.992055892944, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 17950.677639961243, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 560040, "time": 17951.02481818199, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 560040, "time": 17951.27081489563, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 560040, "time": 17951.797981977463, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 560040, "time": 17953.61332631111, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 560040, "time": 17953.70669412613, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 560040, "time": 17954.339002132416, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 560040, "time": 17956.353971481323, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17956.365960597992, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17956.376086235046, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560040, "time": 17956.38432073593, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 560192, "time": 17961.32037448883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 560400, "time": 17967.742479801178, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 560920, "time": 17983.57136297226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561392, "time": 17998.27057337761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561496, "time": 18001.235800266266, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 562032, "time": 18018.0160779953, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 562096, "time": 18020.000648498535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562112, "time": 18020.508707761765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562248, "time": 18024.46778845787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562312, "time": 18026.429022312164, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562400, "time": 18029.37371945381, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 562712, "time": 18038.862835884094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562792, "time": 18041.31009364128, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 563128, "time": 18051.646798849106, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 563216, "time": 18054.611353874207, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 563232, "time": 18055.105619430542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563808, "time": 18072.89467573166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563936, "time": 18076.810979127884, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 564408, "time": 18091.113946199417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564624, "time": 18098.005100488663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564712, "time": 18100.62632226944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564880, "time": 18106.027163505554, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 565440, "time": 18123.82014131546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565528, "time": 18126.302683115005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565544, "time": 18126.800907850266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 565976, "time": 18140.179974079132, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 566000, "time": 18141.14442563057, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 566120, "time": 18144.623461008072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566248, "time": 18148.56752061844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566400, "time": 18153.48574757576, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 566680, "time": 18161.968894720078, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 566936, "time": 18169.817323207855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566984, "time": 18171.290005922318, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 567528, "time": 18187.99461889267, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 567752, "time": 18195.027018547058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 567808, "time": 18196.992839813232, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 567912, "time": 18199.952098846436, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 568048, "time": 18204.42922258377, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 568312, "time": 18212.340387821198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568432, "time": 18216.253454446793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568560, "time": 18220.296525239944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568680, "time": 18223.7988345623, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 568712, "time": 18224.78353357315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568976, "time": 18233.128592014313, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 569296, "time": 18242.98106122017, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 569408, "time": 18246.478628635406, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 569432, "time": 18247.004352092743, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 569520, "time": 18250.091861009598, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 18266.29692220688, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 570024, "time": 18266.369349956512, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 570024, "time": 18266.908529281616, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 570024, "time": 18267.998421907425, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 570024, "time": 18268.223670721054, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 570024, "time": 18268.338968515396, "eval_episode/length": 13.0, "eval_episode/score": 0.9593750238418579, "eval_episode/reward_rate": 0.07142857142857142}
{"step": 570024, "time": 18268.55224251747, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 570024, "time": 18268.74910759926, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 570064, "time": 18270.218996286392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570360, "time": 18279.219234466553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570361, "time": 18280.237545490265, "train_stats/mean_log_entropy": 0.10317989729526567, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5899596238499365, "train/action_min": 0.0, "train/action_std": 1.7789934897785864, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007675712944722266, "train/actor_opt_grad_steps": 34570.0, "train/actor_opt_loss": -7.347158387000791, "train/adv_mag": 0.7563169929884412, "train/adv_max": 0.24202726153552834, "train/adv_mean": 0.00033797285998054557, "train/adv_min": -0.7348912874151607, "train/adv_std": 0.025196619393294536, "train/cont_avg": 0.9958211056472082, "train/cont_loss_mean": 0.012265987876864141, "train/cont_loss_std": 0.19552298506892046, "train/cont_neg_acc": 0.43787750082138255, "train/cont_neg_loss": 2.300083308815001, "train/cont_pos_acc": 0.9998604960853074, "train/cont_pos_loss": 0.0024555160978402433, "train/cont_pred": 0.9958970362159807, "train/cont_rate": 0.9958211056472082, "train/dyn_loss_mean": 1.0000137350886, "train/dyn_loss_std": 0.00021778437061362952, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3277143990233314, "train/extr_critic_critic_opt_grad_steps": 34570.0, "train/extr_critic_critic_opt_loss": 8441.694891140545, "train/extr_critic_mag": 0.9988845199497823, "train/extr_critic_max": 0.9988845199497823, "train/extr_critic_mean": 0.9255713103386352, "train/extr_critic_min": 0.8215054902933576, "train/extr_critic_std": 0.015074240230496614, "train/extr_return_normed_mag": 0.746499625256824, "train/extr_return_normed_max": 0.2592785576273342, "train/extr_return_normed_mean": 0.027653748971447917, "train/extr_return_normed_min": -0.7183898527004997, "train/extr_return_normed_std": 0.030039654477371783, "train/extr_return_rate": 0.9987739717899845, "train/extr_return_raw_mag": 1.157534047734314, "train/extr_return_raw_max": 1.157534047734314, "train/extr_return_raw_mean": 0.9259092816846625, "train/extr_return_raw_min": 0.1798656374064799, "train/extr_return_raw_std": 0.03003965451519199, "train/extr_reward_mag": 0.31154264713907, "train/extr_reward_max": 0.31154264713907, "train/extr_reward_mean": 0.0015082249570363745, "train/extr_reward_min": 1.0650170030932741e-07, "train/extr_reward_std": 0.00880580353739714, "train/image_loss_mean": 0.08857271884601128, "train/image_loss_std": 0.09751687580861416, "train/model_loss_mean": 0.7070286848823432, "train/model_loss_std": 0.32393763868639314, "train/model_opt_grad_norm": 23.4285210982192, "train/model_opt_grad_steps": 34537.756345177666, "train/model_opt_loss": 3626.8049985624207, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5126.903553299492, "train/policy_entropy_mag": 1.3292200668209095, "train/policy_entropy_max": 1.3292200668209095, "train/policy_entropy_mean": 0.12037227026702184, "train/policy_entropy_min": 0.06468654170556722, "train/policy_entropy_std": 0.1554038895265705, "train/policy_logprob_mag": 6.55108023173918, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.12049750991279098, "train/policy_logprob_min": -6.55108023173918, "train/policy_logprob_std": 0.6577666256633506, "train/policy_randomness_mag": 0.6830840277187715, "train/policy_randomness_max": 0.6830840277187715, "train/policy_randomness_mean": 0.06185911331079938, "train/policy_randomness_min": 0.033242308756875505, "train/policy_randomness_std": 0.07986180556153283, "train/post_ent_mag": 35.149075416138935, "train/post_ent_max": 35.149075416138935, "train/post_ent_mean": 27.91312048277879, "train/post_ent_min": 24.931374361067252, "train/post_ent_std": 1.9909568359404046, "train/prior_ent_mag": 32.73972000083342, "train/prior_ent_max": 32.73972000083342, "train/prior_ent_mean": 28.065240966487053, "train/prior_ent_min": 25.12922639411113, "train/prior_ent_std": 1.3435836764156517, "train/rep_loss_mean": 1.0000137350886, "train/rep_loss_std": 0.00021778437061362952, "train/reward_avg": 0.0007726988800004158, "train/reward_loss_mean": 0.006181715954530057, "train/reward_loss_std": 0.12704819805570286, "train/reward_max_data": 0.49815989807626315, "train/reward_max_pred": 0.18047836407792145, "train/reward_neg_acc": 0.9997715738219053, "train/reward_neg_loss": 0.0009559232156267531, "train/reward_pos_acc": 0.3235159830687797, "train/reward_pos_loss": 4.0247903388656985, "train/reward_pred": 0.0006161355454862345, "train/reward_rate": 0.0012888642131979695, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.017781373113393784, "report/cont_loss_std": 0.24916641414165497, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.5746469497680664, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002711439738050103, "report/cont_pred": 0.9952792525291443, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0789271891117096, "report/image_loss_std": 0.08765343576669693, "report/model_loss_mean": 0.7137336730957031, "report/model_loss_std": 0.509539008140564, "report/post_ent_mag": 36.332611083984375, "report/post_ent_max": 36.332611083984375, "report/post_ent_mean": 28.33135986328125, "report/post_ent_min": 24.784854888916016, "report/post_ent_std": 2.3754897117614746, "report/prior_ent_mag": 31.49010467529297, "report/prior_ent_max": 31.49010467529297, "report/prior_ent_mean": 27.05381202697754, "report/prior_ent_min": 24.276691436767578, "report/prior_ent_std": 1.3504599332809448, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0023193359375, "report/reward_loss_mean": 0.017025109380483627, "report/reward_loss_std": 0.2789142429828644, "report/reward_max_data": 0.8999999761581421, "report/reward_max_pred": 0.513404369354248, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0011018518125638366, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 4.077455520629883, "report/reward_pred": 0.0010541337542235851, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.033831436187028885, "eval/cont_loss_std": 0.5963254570960999, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.811334609985352, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002163942437618971, "eval/cont_pred": 0.997972309589386, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13972711563110352, "eval/image_loss_std": 0.1399277001619339, "eval/model_loss_mean": 0.7739981412887573, "eval/model_loss_std": 0.6205458641052246, "eval/post_ent_mag": 36.33240509033203, "eval/post_ent_max": 36.33240509033203, "eval/post_ent_mean": 28.010631561279297, "eval/post_ent_min": 24.953697204589844, "eval/post_ent_std": 2.2752814292907715, "eval/prior_ent_mag": 31.480384826660156, "eval/prior_ent_max": 31.480384826660156, "eval/prior_ent_mean": 26.763105392456055, "eval/prior_ent_min": 23.814619064331055, "eval/prior_ent_std": 1.2741258144378662, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0004395809955894947, "eval/reward_loss_std": 0.002388948807492852, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0128021240234375, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0004395809955894947, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00020302832126617432, "eval/reward_rate": 0.0, "replay/size": 569857.0, "replay/inserts": 31488.0, "replay/samples": 31488.0, "replay/insert_wait_avg": 1.4816206402894928e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.962126557419939e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3243674742367723e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3560056686401367e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2956209182739, "timer/env.step_count": 3936.0, "timer/env.step_total": 40.610397815704346, "timer/env.step_frac": 0.040598396080574556, "timer/env.step_avg": 0.010317682371876104, "timer/env.step_min": 0.008820295333862305, "timer/env.step_max": 0.03548932075500488, "timer/replay._sample_count": 31488.0, "timer/replay._sample_total": 16.75759506225586, "timer/replay._sample_frac": 0.016752642630657868, "timer/replay._sample_avg": 0.0005321898838368858, "timer/replay._sample_min": 0.00037741661071777344, "timer/replay._sample_max": 0.009392499923706055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4910.0, "timer/agent.policy_total": 55.62983775138855, "timer/agent.policy_frac": 0.05561339726781991, "timer/agent.policy_avg": 0.011329905855679948, "timer/agent.policy_min": 0.009283065795898438, "timer/agent.policy_max": 0.09873795509338379, "timer/dataset_train_count": 1968.0, "timer/dataset_train_total": 0.2414109706878662, "timer/dataset_train_frac": 0.0002413396256461168, "timer/dataset_train_avg": 0.00012266817616253366, "timer/dataset_train_min": 0.0001068115234375, "timer/dataset_train_max": 0.0010912418365478516, "timer/agent.train_count": 1968.0, "timer/agent.train_total": 886.6225674152374, "timer/agent.train_frac": 0.8863605406982744, "timer/agent.train_avg": 0.45051959726384017, "timer/agent.train_min": 0.4378225803375244, "timer/agent.train_max": 2.024858236312866, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4808230400085449, "timer/agent.report_frac": 0.000480680940667468, "timer/agent.report_avg": 0.24041152000427246, "timer/agent.report_min": 0.23388051986694336, "timer/agent.report_max": 0.24694252014160156, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.719329833984375e-05, "timer/dataset_eval_frac": 3.718230647226088e-08, "timer/dataset_eval_avg": 3.719329833984375e-05, "timer/dataset_eval_min": 3.719329833984375e-05, "timer/dataset_eval_max": 3.719329833984375e-05, "fps": 31.478132028169085}
{"step": 570536, "time": 18285.421469926834, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 570624, "time": 18288.349871873856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570624, "time": 18288.35869550705, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 570704, "time": 18290.833734035492, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 571024, "time": 18300.651719093323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571120, "time": 18303.595027446747, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 571464, "time": 18314.092349290848, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 571520, "time": 18316.046903133392, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 571624, "time": 18319.013451337814, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 571744, "time": 18322.924005270004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571832, "time": 18325.42958688736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571880, "time": 18326.903074264526, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 572128, "time": 18334.741026878357, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 572176, "time": 18336.20996427536, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 572216, "time": 18337.21688723564, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 572624, "time": 18350.076421022415, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 572896, "time": 18358.404216766357, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 572936, "time": 18359.43365263939, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 572936, "time": 18359.44372034073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573088, "time": 18364.3602206707, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 573128, "time": 18365.371161937714, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 573448, "time": 18375.565440416336, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 573976, "time": 18392.143072605133, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 573984, "time": 18392.623347997665, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 573992, "time": 18392.65319919586, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 574144, "time": 18397.54229617119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574192, "time": 18399.17554473877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 574272, "time": 18401.640520572662, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 574552, "time": 18410.03453183174, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 574808, "time": 18417.9102768898, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 574936, "time": 18421.885574817657, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575152, "time": 18428.869956970215, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 575288, "time": 18432.830550670624, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 575344, "time": 18434.80670785904, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 575400, "time": 18436.301789283752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575416, "time": 18436.798050880432, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 576064, "time": 18456.933371067047, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 576296, "time": 18463.967978477478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576304, "time": 18464.442491292953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576536, "time": 18471.361996650696, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 576968, "time": 18484.696109056473, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 577328, "time": 18496.078304052353, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 577656, "time": 18505.989792585373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577712, "time": 18507.963985204697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577784, "time": 18509.9596991539, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 578376, "time": 18528.301545143127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578456, "time": 18530.75244474411, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 578608, "time": 18535.671309947968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578672, "time": 18537.654264211655, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 578776, "time": 18540.6321144104, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 578848, "time": 18543.08969116211, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578872, "time": 18543.60916543007, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 579280, "time": 18556.52983045578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 579296, "time": 18557.026499271393, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 579624, "time": 18566.89832830429, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 579736, "time": 18570.3540930748, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 579768, "time": 18571.350333690643, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 18579.395253181458, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 580008, "time": 18579.423279762268, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 580008, "time": 18579.946576595306, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 580008, "time": 18580.11683368683, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 580008, "time": 18580.35255074501, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 580008, "time": 18581.208923339844, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 580008, "time": 18582.61722779274, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 580008, "time": 18585.51281929016, "eval_episode/length": 254.0, "eval_episode/score": 0.20624999701976776, "eval_episode/reward_rate": 0.00392156862745098}
{"step": 580208, "time": 18591.88962841034, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 580264, "time": 18593.393121242523, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 580392, "time": 18597.361680984497, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 580512, "time": 18601.291172266006, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 580688, "time": 18606.714640140533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580768, "time": 18609.30396270752, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 580992, "time": 18616.16129040718, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 581016, "time": 18616.686156511307, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 581368, "time": 18627.482361793518, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 581592, "time": 18634.427230596542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 581736, "time": 18639.49726486206, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 582048, "time": 18649.31044459343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582080, "time": 18650.306709766388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582440, "time": 18661.14666032791, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 582496, "time": 18663.101960659027, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 582520, "time": 18663.646381139755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582616, "time": 18666.590785980225, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 583048, "time": 18680.022780895233, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 583288, "time": 18687.38995718956, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 583288, "time": 18687.401058912277, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 583328, "time": 18688.869245767593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 583664, "time": 18699.33337330818, "episode/length": 286.0, "episode/score": 0.10625000298023224, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.0}
{"step": 583736, "time": 18701.317594766617, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 583904, "time": 18706.70655488968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584000, "time": 18709.67969584465, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 584048, "time": 18711.16016960144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584248, "time": 18717.086402654648, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 584368, "time": 18720.994563817978, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 584832, "time": 18735.30952358246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584952, "time": 18738.793235063553, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 585024, "time": 18741.2440199852, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 585056, "time": 18742.242502212524, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 585200, "time": 18746.652769088745, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 585656, "time": 18760.63720393181, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 585680, "time": 18761.60457444191, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 585816, "time": 18765.57100534439, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 585856, "time": 18767.020824193954, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 585928, "time": 18769.019241333008, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 585976, "time": 18770.490503311157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586048, "time": 18772.94570207596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586168, "time": 18776.408104658127, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 586576, "time": 18789.28464102745, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 586600, "time": 18789.7990398407, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 586624, "time": 18790.75364756584, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 587192, "time": 18808.03844809532, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 587272, "time": 18810.49254012108, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 587336, "time": 18812.541731357574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 587536, "time": 18819.040792942047, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 587880, "time": 18829.39680838585, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 587992, "time": 18832.865176916122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588160, "time": 18838.264353513718, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 588168, "time": 18838.295783281326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588480, "time": 18848.12161707878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588576, "time": 18851.225031375885, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 588632, "time": 18852.74552345276, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 588888, "time": 18860.608859062195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589248, "time": 18871.919440984726, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 589480, "time": 18878.949707746506, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 589504, "time": 18879.915966033936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589648, "time": 18884.356334924698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589816, "time": 18889.282164812088, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 18899.7624399662, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 590096, "time": 18899.967478990555, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 590096, "time": 18900.01933979988, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 590096, "time": 18900.36311006546, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 590096, "time": 18900.39168047905, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 590096, "time": 18900.745116233826, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 590096, "time": 18901.457470417023, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 590096, "time": 18901.801288843155, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 590192, "time": 18904.765409469604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 590480, "time": 18913.73124885559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 590888, "time": 18926.139589309692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591200, "time": 18935.96715593338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591368, "time": 18941.01064991951, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 591504, "time": 18945.429712057114, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 591560, "time": 18946.930315971375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591792, "time": 18954.2705783844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591960, "time": 18959.221907138824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592128, "time": 18964.62127304077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592416, "time": 18973.589750528336, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 592504, "time": 18976.08785057068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 592584, "time": 18978.529753923416, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 592952, "time": 18989.800654649734, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 593200, "time": 18997.602473020554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593656, "time": 19011.429651260376, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 593816, "time": 19016.337032318115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594008, "time": 19022.243270397186, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 594104, "time": 19025.191952228546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594272, "time": 19030.6630320549, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594728, "time": 19044.488872528076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594816, "time": 19047.436041116714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594848, "time": 19048.44039082527, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 595016, "time": 19053.398862600327, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 595200, "time": 19059.396877527237, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 595512, "time": 19068.748138427734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 595824, "time": 19078.53143119812, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 595824, "time": 19078.540637493134, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 595968, "time": 19082.950172424316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596128, "time": 19087.875169992447, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 596416, "time": 19096.832405090332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596544, "time": 19100.793402910233, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 596664, "time": 19104.262351989746, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 597328, "time": 19125.05117869377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597824, "time": 19140.343524217606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597928, "time": 19143.360114574432, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 598136, "time": 19150.37426662445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598280, "time": 19154.794629096985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598440, "time": 19159.73025369644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598552, "time": 19163.180428266525, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 598608, "time": 19165.120090723038, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 598728, "time": 19168.577465057373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598824, "time": 19171.509459257126, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 598944, "time": 19175.419456005096, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 599064, "time": 19179.041219472885, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 599472, "time": 19191.822336912155, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 599608, "time": 19195.823942422867, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 19211.917691469193, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 600080, "time": 19212.502730846405, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 600080, "time": 19213.88074350357, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 600080, "time": 19213.88788294792, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 600080, "time": 19214.631380558014, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 600080, "time": 19214.918322324753, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 600080, "time": 19215.24273967743, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 600080, "time": 19217.02613067627, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19217.034917354584, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19217.04272866249, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 19217.05066728592, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600104, "time": 19217.57329416275, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 600240, "time": 19222.034180164337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600752, "time": 19237.86189508438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600920, "time": 19242.93560218811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601032, "time": 19246.385727405548, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 601040, "time": 19246.864132404327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601256, "time": 19253.338139533997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601384, "time": 19257.269611120224, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 601608, "time": 19264.222431898117, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 601688, "time": 19266.68802547455, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 601920, "time": 19274.24210834503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601960, "time": 19275.261741161346, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 601960, "time": 19275.269204616547, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 602089, "time": 19280.31884455681, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.876538517499211, "train/action_min": 0.0, "train/action_std": 1.7924168182141853, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011559596636821752, "train/actor_opt_grad_steps": 36545.0, "train/actor_opt_loss": -7.348122254202162, "train/adv_mag": 0.8037495278950894, "train/adv_max": 0.3437295510913386, "train/adv_mean": 0.0024837888258752165, "train/adv_min": -0.7886169837279753, "train/adv_std": 0.03815781653181396, "train/cont_avg": 0.99594085385101, "train/cont_loss_mean": 0.012458573190161413, "train/cont_loss_std": 0.19667298573708972, "train/cont_neg_acc": 0.4259050103778742, "train/cont_neg_loss": 2.4109391321541565, "train/cont_pos_acc": 0.999821766157343, "train/cont_pos_loss": 0.0026756232801937695, "train/cont_pred": 0.9958033757378356, "train/cont_rate": 0.99594085385101, "train/dyn_loss_mean": 1.0000052114929816, "train/dyn_loss_std": 0.00011552997771885736, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3655136707285889, "train/extr_critic_critic_opt_grad_steps": 36545.0, "train/extr_critic_critic_opt_loss": 11823.01740303425, "train/extr_critic_mag": 1.0654546359572747, "train/extr_critic_max": 1.0654546359572747, "train/extr_critic_mean": 0.9702641160199137, "train/extr_critic_min": 0.8036010048606179, "train/extr_critic_std": 0.01906731247789029, "train/extr_return_normed_mag": 0.793395094799273, "train/extr_return_normed_max": 0.35277261938711607, "train/extr_return_normed_mean": 0.03838074792675072, "train/extr_return_normed_min": -0.7715466154946221, "train/extr_return_normed_std": 0.04373892305908029, "train/extr_return_rate": 0.9981925848758582, "train/extr_return_raw_mag": 1.2871397119579893, "train/extr_return_raw_max": 1.2871397119579893, "train/extr_return_raw_mean": 0.9727478903351408, "train/extr_return_raw_min": 0.1628204770762511, "train/extr_return_raw_std": 0.04373892311082043, "train/extr_reward_mag": 0.3886334185648446, "train/extr_reward_max": 0.3886334185648446, "train/extr_reward_mean": 0.0019317994475855041, "train/extr_reward_min": 8.127906105735085e-08, "train/extr_reward_std": 0.01338946012864736, "train/image_loss_mean": 0.08543409094816506, "train/image_loss_std": 0.09585533129295917, "train/model_loss_mean": 0.7043878126023996, "train/model_loss_std": 0.32966933621451106, "train/model_opt_grad_norm": 22.889281923120674, "train/model_opt_grad_steps": 36510.50505050505, "train/model_opt_loss": 2995.8353456439395, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4255.050505050505, "train/policy_entropy_mag": 1.3429190371975754, "train/policy_entropy_max": 1.3429190371975754, "train/policy_entropy_mean": 0.12457156373244344, "train/policy_entropy_min": 0.06468652188777924, "train/policy_entropy_std": 0.1610121066221083, "train/policy_logprob_mag": 6.551080241347805, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.12445004340825659, "train/policy_logprob_min": -6.551080241347805, "train/policy_logprob_std": 0.6600985816030791, "train/policy_randomness_mag": 0.6901239069423291, "train/policy_randomness_max": 0.6901239069423291, "train/policy_randomness_mean": 0.06401712353331875, "train/policy_randomness_min": 0.0332422981019875, "train/policy_randomness_std": 0.08274385995335048, "train/post_ent_mag": 33.49587716959944, "train/post_ent_max": 33.49587716959944, "train/post_ent_mean": 25.741446456523857, "train/post_ent_min": 22.534040990501943, "train/post_ent_std": 2.173396763777492, "train/prior_ent_mag": 30.415994827193444, "train/prior_ent_max": 30.415994827193444, "train/prior_ent_mean": 25.766440959891888, "train/prior_ent_min": 23.069173899563875, "train/prior_ent_std": 1.3239756503490487, "train/rep_loss_mean": 1.0000052114929816, "train/rep_loss_std": 0.00011552997771885736, "train/reward_avg": 0.0009055860052349733, "train/reward_loss_mean": 0.0064919998926919594, "train/reward_loss_std": 0.13421017818994857, "train/reward_max_data": 0.5603061865526017, "train/reward_max_pred": 0.22243495902629815, "train/reward_neg_acc": 0.9997382079712068, "train/reward_neg_loss": 0.0010816324645544007, "train/reward_pos_acc": 0.32286324953803647, "train/reward_pos_loss": 3.9544699551203313, "train/reward_pred": 0.0007149759930502059, "train/reward_rate": 0.0013957938762626263, "train_stats/mean_log_entropy": 0.10643689598092872, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.013630284927785397, "report/cont_loss_std": 0.19855725765228271, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.644023895263672, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0029631154611706734, "report/cont_pred": 0.9971168041229248, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09712161123752594, "report/image_loss_std": 0.10853840410709381, "report/model_loss_mean": 0.7271109819412231, "report/model_loss_std": 0.5194165110588074, "report/post_ent_mag": 35.45830535888672, "report/post_ent_max": 35.45830535888672, "report/post_ent_mean": 24.89134979248047, "report/post_ent_min": 20.949525833129883, "report/post_ent_std": 2.942885398864746, "report/prior_ent_mag": 29.969297409057617, "report/prior_ent_max": 29.969297409057617, "report/prior_ent_mean": 25.166576385498047, "report/prior_ent_min": 22.68015480041504, "report/prior_ent_std": 1.3412325382232666, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001675414969213307, "report/reward_loss_mean": 0.016359081491827965, "report/reward_loss_std": 0.29119959473609924, "report/reward_max_data": 0.793749988079071, "report/reward_max_pred": 0.03521275520324707, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0009558716556057334, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.258584976196289, "report/reward_pred": 0.0005058924434706569, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.05393526330590248, "eval/cont_loss_std": 0.7738046050071716, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.822042465209961, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0010986246634274721, "eval/cont_pred": 0.9989275336265564, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1891552209854126, "eval/image_loss_std": 0.1506354659795761, "eval/model_loss_mean": 0.8432533740997314, "eval/model_loss_std": 0.7806894183158875, "eval/post_ent_mag": 35.54908752441406, "eval/post_ent_max": 35.54908752441406, "eval/post_ent_mean": 24.647905349731445, "eval/post_ent_min": 20.267215728759766, "eval/post_ent_std": 3.030613660812378, "eval/prior_ent_mag": 29.786151885986328, "eval/prior_ent_max": 29.786151885986328, "eval/prior_ent_mean": 24.965900421142578, "eval/prior_ent_min": 22.42972183227539, "eval/prior_ent_std": 1.4107533693313599, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001627928577363491, "eval/reward_loss_std": 0.0010273001389577985, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.008373379707336426, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001627928577363491, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 8.039164822548628e-05, "eval/reward_rate": 0.0, "replay/size": 601585.0, "replay/inserts": 31728.0, "replay/samples": 31728.0, "replay/insert_wait_avg": 1.5087068772231817e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.879580744456235e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5688.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3005297562911708e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3262033462524414e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0565936565399, "timer/env.step_count": 3966.0, "timer/env.step_total": 41.21436548233032, "timer/env.step_frac": 0.041212033142681334, "timer/env.step_avg": 0.010391922713648593, "timer/env.step_min": 0.008864879608154297, "timer/env.step_max": 0.0362858772277832, "timer/replay._sample_count": 31728.0, "timer/replay._sample_total": 16.877174615859985, "timer/replay._sample_frac": 0.016876219528888275, "timer/replay._sample_avg": 0.0005319331384222133, "timer/replay._sample_min": 0.00039887428283691406, "timer/replay._sample_max": 0.02570629119873047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4677.0, "timer/agent.policy_total": 53.14498710632324, "timer/agent.policy_frac": 0.05314197960738149, "timer/agent.policy_avg": 0.011363050482429601, "timer/agent.policy_min": 0.009577751159667969, "timer/agent.policy_max": 0.09700822830200195, "timer/dataset_train_count": 1983.0, "timer/dataset_train_total": 0.2434689998626709, "timer/dataset_train_frac": 0.00024345522184146315, "timer/dataset_train_avg": 0.00012277811389948103, "timer/dataset_train_min": 0.00010824203491210938, "timer/dataset_train_max": 0.0007405281066894531, "timer/agent.train_count": 1983.0, "timer/agent.train_total": 891.1934406757355, "timer/agent.train_frac": 0.8911430076344334, "timer/agent.train_avg": 0.4494167628218535, "timer/agent.train_min": 0.4369776248931885, "timer/agent.train_max": 0.705441951751709, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.49037599563598633, "timer/agent.report_frac": 0.0004903482450358219, "timer/agent.report_avg": 0.24518799781799316, "timer/agent.report_min": 0.24010491371154785, "timer/agent.report_max": 0.2502710819244385, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.4345855712890625e-05, "timer/dataset_eval_frac": 4.434334616078817e-08, "timer/dataset_eval_avg": 4.4345855712890625e-05, "timer/dataset_eval_min": 4.4345855712890625e-05, "timer/dataset_eval_max": 4.4345855712890625e-05, "fps": 31.725421834461148}
{"step": 602232, "time": 19284.52397251129, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 602416, "time": 19290.434084177017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602552, "time": 19294.429398298264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602608, "time": 19296.375961065292, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 603304, "time": 19317.626493692398, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 603568, "time": 19325.97084927559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603696, "time": 19330.10320687294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603752, "time": 19331.61996436119, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 604240, "time": 19346.91017484665, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 604272, "time": 19347.92728948593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604272, "time": 19347.936982870102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604424, "time": 19352.393828630447, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 604728, "time": 19361.880873680115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604920, "time": 19367.79386496544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605616, "time": 19389.4526822567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 605880, "time": 19397.403378009796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606008, "time": 19401.34889435768, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606400, "time": 19414.094292640686, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 606584, "time": 19419.665266513824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606584, "time": 19419.674973726273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606736, "time": 19424.54130244255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 607040, "time": 19433.96094727516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 607192, "time": 19438.477053165436, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 607272, "time": 19440.961401462555, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 607736, "time": 19455.360502958298, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 607744, "time": 19455.83439397812, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 607928, "time": 19461.314428806305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608104, "time": 19466.760890483856, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 608112, "time": 19467.26077413559, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 608320, "time": 19473.681792736053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608624, "time": 19483.221646547318, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 608712, "time": 19485.706553697586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608896, "time": 19491.58207345009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 608984, "time": 19494.088217258453, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 609240, "time": 19502.022698879242, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 609456, "time": 19509.02651977539, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 609584, "time": 19512.9741127491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609904, "time": 19522.8601231575, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 19527.978741645813, "eval_episode/length": 8.0, "eval_episode/score": 0.9750000238418579, "eval_episode/reward_rate": 0.1111111111111111}
{"step": 610064, "time": 19528.583491802216, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 610064, "time": 19528.781270503998, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 610064, "time": 19528.809777736664, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 610064, "time": 19528.821465730667, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 610064, "time": 19529.155951738358, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 610064, "time": 19530.109616994858, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 610064, "time": 19530.179682016373, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 610240, "time": 19535.591437339783, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610280, "time": 19536.60268187523, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 610424, "time": 19541.155564785004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610688, "time": 19549.478278636932, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 611024, "time": 19559.802895784378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611136, "time": 19563.244562625885, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 611200, "time": 19565.2243206501, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 611208, "time": 19565.254539966583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611296, "time": 19568.16213798523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611408, "time": 19571.732798814774, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 611576, "time": 19576.68835091591, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 611664, "time": 19579.61519551277, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 611768, "time": 19582.58934855461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611840, "time": 19585.02730154991, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 612648, "time": 19609.823773622513, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 613000, "time": 19620.68212223053, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 613152, "time": 19625.598545074463, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 613376, "time": 19632.656224012375, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 613488, "time": 19636.13689470291, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 613512, "time": 19636.663299798965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613720, "time": 19643.0489525795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613888, "time": 19648.45950269699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613976, "time": 19650.962248325348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614136, "time": 19655.90947508812, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 614304, "time": 19661.43114709854, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 614392, "time": 19663.947088956833, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 614520, "time": 19668.435671806335, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 614576, "time": 19670.378360033035, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 614672, "time": 19673.351813793182, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 614680, "time": 19673.38180565834, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 614960, "time": 19682.25020980835, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 615304, "time": 19692.746107578278, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 615504, "time": 19699.134956598282, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 615632, "time": 19703.084693670273, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 615664, "time": 19704.074858903885, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 615936, "time": 19712.448070526123, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 616200, "time": 19720.53309583664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 616320, "time": 19724.449667692184, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 616400, "time": 19726.915847301483, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 616616, "time": 19733.392515182495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 616880, "time": 19741.762640476227, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 616888, "time": 19741.80144429207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 616984, "time": 19744.80242753029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617216, "time": 19752.251881361008, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 617368, "time": 19756.694562911987, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 617816, "time": 19770.54299068451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617936, "time": 19774.477948904037, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 618048, "time": 19777.927201509476, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 618248, "time": 19783.970031261444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618712, "time": 19798.14971804619, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618728, "time": 19798.646642684937, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 619088, "time": 19810.000328302383, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 619192, "time": 19812.997303009033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619296, "time": 19816.423485040665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619680, "time": 19828.275718927383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619856, "time": 19833.685883045197, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 619992, "time": 19837.660919189453, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 19840.41399860382, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 620048, "time": 19840.433604955673, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 620048, "time": 19841.317510843277, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 620048, "time": 19841.489205360413, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 620048, "time": 19842.570663690567, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 620048, "time": 19842.748960256577, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 620048, "time": 19842.76694059372, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 620048, "time": 19843.548840522766, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 620376, "time": 19853.435992479324, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 620560, "time": 19859.35670399666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 620648, "time": 19861.86882209778, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 620712, "time": 19863.87454867363, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 620960, "time": 19871.87555217743, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 620968, "time": 19871.904731988907, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 621024, "time": 19873.86781811714, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621432, "time": 19886.20543241501, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 621560, "time": 19890.19615316391, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 621608, "time": 19891.69523882866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621624, "time": 19892.1970205307, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 621728, "time": 19895.66405773163, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 622168, "time": 19909.024752140045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622200, "time": 19910.03940844536, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 622304, "time": 19913.443602323532, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 622304, "time": 19913.45434999466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622352, "time": 19914.947666168213, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 622872, "time": 19931.413840055466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622880, "time": 19931.89211988449, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 623264, "time": 19943.753000497818, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 623496, "time": 19950.740687847137, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 623744, "time": 19958.724274396896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623872, "time": 19962.67670416832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623920, "time": 19964.159348487854, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 624336, "time": 19976.987131357193, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 624352, "time": 19977.481559753418, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 624480, "time": 19981.421724557877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 624512, "time": 19982.4063103199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 624520, "time": 19982.43685054779, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 624616, "time": 19985.374338150024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 624616, "time": 19985.3839199543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625144, "time": 20001.688178539276, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 625152, "time": 20002.166984319687, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 625808, "time": 20022.439194202423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625880, "time": 20024.4549908638, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 626000, "time": 20028.361598968506, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 626312, "time": 20037.76536846161, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 626544, "time": 20045.129189491272, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 626648, "time": 20048.115579128265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626664, "time": 20048.75903725624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626784, "time": 20052.666954755783, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 626832, "time": 20054.15297794342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626928, "time": 20057.09963798523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626928, "time": 20057.108775138855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626952, "time": 20057.6342151165, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 627104, "time": 20062.58914375305, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 627264, "time": 20067.53519487381, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 627800, "time": 20083.893913030624, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 628312, "time": 20099.650963544846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628344, "time": 20100.64682865143, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 628408, "time": 20102.616585969925, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 628976, "time": 20120.449873924255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629096, "time": 20123.929906845093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629264, "time": 20129.319096326828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629416, "time": 20133.789333581924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629448, "time": 20134.775676488876, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 629856, "time": 20147.660435676575, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 20153.614012479782, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 630032, "time": 20153.856234550476, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 630032, "time": 20155.193016052246, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 630032, "time": 20157.164068222046, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 630032, "time": 20159.29384279251, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20159.303325414658, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20159.31183052063, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20159.32014155388, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20159.32790875435, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 20159.335970401764, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630112, "time": 20161.806634426117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630576, "time": 20176.176137924194, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 630624, "time": 20177.654256105423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630656, "time": 20178.657913446426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630720, "time": 20180.653469085693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630824, "time": 20184.167324066162, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 631000, "time": 20189.589873075485, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 631128, "time": 20193.512858629227, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 631288, "time": 20198.544555187225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 631528, "time": 20205.958069086075, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 631624, "time": 20208.903673171997, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 631760, "time": 20213.317838430405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 631808, "time": 20214.807940483093, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 631880, "time": 20216.78427886963, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 632080, "time": 20223.15966320038, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 632152, "time": 20225.160640716553, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 632168, "time": 20225.657237529755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 632312, "time": 20230.196516275406, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 632536, "time": 20237.075188159943, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 632552, "time": 20237.57411289215, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 632792, "time": 20244.936426639557, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 632816, "time": 20245.894814014435, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 632928, "time": 20249.363092899323, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 632928, "time": 20249.37238931656, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 633112, "time": 20254.799828529358, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 633176, "time": 20256.767435073853, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 633272, "time": 20259.849456310272, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 633312, "time": 20261.29809141159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 633464, "time": 20265.76399731636, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 633913, "time": 20280.60057926178, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.8139749651578203, "train/action_min": 0.0, "train/action_std": 1.928116669606923, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011483692203709229, "train/actor_opt_grad_steps": 38530.0, "train/actor_opt_loss": -8.409804346380362, "train/adv_mag": 0.8625564461377397, "train/adv_max": 0.32160285160170127, "train/adv_mean": 0.0013823135345202772, "train/adv_min": -0.8553712592652095, "train/adv_std": 0.037996643791490016, "train/cont_avg": 0.995372369660804, "train/cont_loss_mean": 0.014289996411239531, "train/cont_loss_std": 0.22000797786024498, "train/cont_neg_acc": 0.414154122222443, "train/cont_neg_loss": 2.4903833665962245, "train/cont_pos_acc": 0.9997978489003588, "train/cont_pos_loss": 0.002821680586012876, "train/cont_pred": 0.9954945663710935, "train/cont_rate": 0.995372369660804, "train/dyn_loss_mean": 1.0000037697691415, "train/dyn_loss_std": 0.00011567200414705366, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2938293657083083, "train/extr_critic_critic_opt_grad_steps": 38530.0, "train/extr_critic_critic_opt_loss": 13209.97871191897, "train/extr_critic_mag": 1.1014528633961127, "train/extr_critic_max": 1.1014528633961127, "train/extr_critic_mean": 1.0008408984347203, "train/extr_critic_min": 0.8492431694538749, "train/extr_critic_std": 0.018682679081869186, "train/extr_return_normed_mag": 0.8519071088963418, "train/extr_return_normed_max": 0.33508487143109195, "train/extr_return_normed_mean": 0.03795678922953318, "train/extr_return_normed_min": -0.8360152666892239, "train/extr_return_normed_std": 0.043294819582010334, "train/extr_return_rate": 0.9981313275931468, "train/extr_return_raw_mag": 1.2993512495079231, "train/extr_return_raw_max": 1.2993512495079231, "train/extr_return_raw_mean": 1.0022232164090603, "train/extr_return_raw_min": 0.12825111138760745, "train/extr_return_raw_std": 0.04329481961945044, "train/extr_reward_mag": 0.38338634656302295, "train/extr_reward_max": 0.38338634656302295, "train/extr_reward_mean": 0.0018396306908443738, "train/extr_reward_min": 4.253195757841944e-08, "train/extr_reward_std": 0.01236188117105832, "train/image_loss_mean": 0.08540658693966555, "train/image_loss_std": 0.09689954520395054, "train/model_loss_mean": 0.7066386857224469, "train/model_loss_std": 0.35316996321306754, "train/model_opt_grad_norm": 21.790021342847815, "train/model_opt_grad_steps": 38493.68844221105, "train/model_opt_loss": 3256.7788276097285, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4610.552763819095, "train/policy_entropy_mag": 1.3488231070676642, "train/policy_entropy_max": 1.3488231070676642, "train/policy_entropy_mean": 0.12636870381670381, "train/policy_entropy_min": 0.0646865054515738, "train/policy_entropy_std": 0.16343899632818135, "train/policy_logprob_mag": 6.551080253256027, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1263591515358968, "train/policy_logprob_min": -6.551080253256027, "train/policy_logprob_std": 0.6611767165624916, "train/policy_randomness_mag": 0.6931579999588243, "train/policy_randomness_max": 0.6931579999588243, "train/policy_randomness_mean": 0.06494067115100784, "train/policy_randomness_min": 0.033242288939467624, "train/policy_randomness_std": 0.08399103495793127, "train/post_ent_mag": 34.21330004361407, "train/post_ent_max": 34.21330004361407, "train/post_ent_mean": 24.38032614166413, "train/post_ent_min": 20.43894694917765, "train/post_ent_std": 2.7870138002999463, "train/prior_ent_mag": 32.43947242851832, "train/prior_ent_max": 32.43947242851832, "train/prior_ent_mean": 24.66532867278286, "train/prior_ent_min": 20.871268066329574, "train/prior_ent_std": 2.005971473066052, "train/rep_loss_mean": 1.0000037697691415, "train/rep_loss_std": 0.00011567200414705366, "train/reward_avg": 0.0009077675999262154, "train/reward_loss_mean": 0.006939816552485765, "train/reward_loss_std": 0.13823526959875646, "train/reward_max_data": 0.5458071605119873, "train/reward_max_pred": 0.2071112867575794, "train/reward_neg_acc": 0.9996855375754773, "train/reward_neg_loss": 0.0011524837396818977, "train/reward_pos_acc": 0.28948281478408155, "train/reward_pos_loss": 4.063951863358352, "train/reward_pred": 0.0007416973769168683, "train/reward_rate": 0.0014280386306532663, "train_stats/mean_log_entropy": 0.10640190957494862, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.006272722966969013, "report/cont_loss_std": 0.0668802484869957, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 0.9409096240997314, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0035264831967651844, "report/cont_pred": 0.9951269030570984, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07890936732292175, "report/image_loss_std": 0.0811590924859047, "report/model_loss_mean": 0.6858628988265991, "report/model_loss_std": 0.1048261746764183, "report/post_ent_mag": 32.406944274902344, "report/post_ent_max": 32.406944274902344, "report/post_ent_mean": 22.457916259765625, "report/post_ent_min": 18.785350799560547, "report/post_ent_std": 2.6379282474517822, "report/prior_ent_mag": 35.54544448852539, "report/prior_ent_max": 35.54544448852539, "report/prior_ent_mean": 23.835586547851562, "report/prior_ent_min": 19.213722229003906, "report/prior_ent_std": 2.519864320755005, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0006808210164308548, "report/reward_loss_std": 0.0034886933863162994, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.02157425880432129, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0006808210164308548, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0003291916800662875, "report/reward_rate": 0.0, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.06331554055213928, "eval/cont_loss_std": 0.7535163760185242, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.815268516540527, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.003075953805819154, "eval/cont_pred": 0.9970592260360718, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22146357595920563, "eval/image_loss_std": 0.16448251903057098, "eval/model_loss_mean": 0.8898245692253113, "eval/model_loss_std": 0.8132568597793579, "eval/post_ent_mag": 32.3753662109375, "eval/post_ent_max": 32.3753662109375, "eval/post_ent_mean": 22.493410110473633, "eval/post_ent_min": 19.184783935546875, "eval/post_ent_std": 2.829251766204834, "eval/prior_ent_mag": 34.37944793701172, "eval/prior_ent_max": 34.37944793701172, "eval/prior_ent_mean": 23.719783782958984, "eval/prior_ent_min": 19.469097137451172, "eval/prior_ent_std": 2.6861798763275146, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005065918085165322, "eval/reward_loss_mean": 0.005045442376285791, "eval/reward_loss_std": 0.14786137640476227, "eval/reward_max_data": 0.518750011920929, "eval/reward_max_pred": 0.04231762886047363, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0004237604734953493, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.733026027679443, "eval/reward_pred": 0.00021911156363785267, "eval/reward_rate": 0.0009765625, "replay/size": 633409.0, "replay/inserts": 31824.0, "replay/samples": 31824.0, "replay/insert_wait_avg": 1.4763162506471751e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.007969431927481e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4600.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2544963670813519e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.260463476181, "timer/env.step_count": 3978.0, "timer/env.step_total": 41.27202653884888, "timer/env.step_frac": 0.041261279482563175, "timer/env.step_avg": 0.010375069517056027, "timer/env.step_min": 0.00880122184753418, "timer/env.step_max": 0.03758072853088379, "timer/replay._sample_count": 31824.0, "timer/replay._sample_total": 16.85570740699768, "timer/replay._sample_frac": 0.016851318254066994, "timer/replay._sample_avg": 0.0005296539532113399, "timer/replay._sample_min": 0.00038814544677734375, "timer/replay._sample_max": 0.011806726455688477, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4553.0, "timer/agent.policy_total": 51.2942419052124, "timer/agent.policy_frac": 0.05128088510761563, "timer/agent.policy_avg": 0.01126603160667964, "timer/agent.policy_min": 0.009547948837280273, "timer/agent.policy_max": 0.08903932571411133, "timer/dataset_train_count": 1989.0, "timer/dataset_train_total": 0.24460434913635254, "timer/dataset_train_frac": 0.0002445406552272245, "timer/dataset_train_avg": 0.0001229785566296393, "timer/dataset_train_min": 0.00010752677917480469, "timer/dataset_train_max": 0.0004565715789794922, "timer/agent.train_count": 1989.0, "timer/agent.train_total": 894.8569750785828, "timer/agent.train_frac": 0.8946239582125519, "timer/agent.train_avg": 0.44990295378510947, "timer/agent.train_min": 0.43849873542785645, "timer/agent.train_max": 0.7098281383514404, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48132920265197754, "timer/agent.report_frac": 0.0004812038666201259, "timer/agent.report_avg": 0.24066460132598877, "timer/agent.report_min": 0.23334932327270508, "timer/agent.report_max": 0.24797987937927246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.4084978919428526e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 31.814962884328292}
{"step": 633968, "time": 20282.31373333931, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 634192, "time": 20289.37687253952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634264, "time": 20291.370455741882, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 634392, "time": 20295.317740917206, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 634464, "time": 20297.751648664474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634896, "time": 20311.11482310295, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 634960, "time": 20313.08328151703, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 635128, "time": 20318.032018899918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 635240, "time": 20321.620468616486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 635488, "time": 20329.468334197998, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 635488, "time": 20329.4795422554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 635496, "time": 20329.509600162506, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 635776, "time": 20338.302480697632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636424, "time": 20358.150074243546, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 636576, "time": 20363.05073618889, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636760, "time": 20368.493958473206, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 636776, "time": 20368.99302840233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637272, "time": 20384.41341972351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637312, "time": 20385.868637800217, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 637328, "time": 20386.366856336594, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 637440, "time": 20389.811012744904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637480, "time": 20390.82043862343, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 637520, "time": 20392.274258375168, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 637800, "time": 20400.67441534996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637824, "time": 20401.646072149277, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 637992, "time": 20406.571955680847, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 638128, "time": 20411.097601890564, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 638168, "time": 20412.12236738205, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 638248, "time": 20414.593392133713, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 638336, "time": 20417.51929306984, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 638520, "time": 20422.945827245712, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 638736, "time": 20429.790914297104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 638760, "time": 20430.312180042267, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 639152, "time": 20443.241553783417, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 639216, "time": 20445.19687962532, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 639792, "time": 20462.89071726799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 20472.09210538864, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 640016, "time": 20472.5269010067, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 640016, "time": 20472.702835321426, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 640016, "time": 20472.98709344864, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 640016, "time": 20473.41264104843, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 640016, "time": 20474.794880867004, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 640016, "time": 20474.91063117981, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 640016, "time": 20475.04949450493, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 640064, "time": 20476.51741695404, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 640096, "time": 20477.496102809906, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 640304, "time": 20483.896629333496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640552, "time": 20491.330973148346, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 640560, "time": 20491.811039447784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640648, "time": 20494.349811077118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640688, "time": 20495.806248903275, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 640832, "time": 20500.337136268616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 641048, "time": 20506.765911579132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 641104, "time": 20508.730278253555, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 641192, "time": 20511.232311964035, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 641416, "time": 20518.13888168335, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 641512, "time": 20521.090269804, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 641688, "time": 20526.510822057724, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 641944, "time": 20534.54215312004, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 642024, "time": 20536.99868965149, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 642376, "time": 20547.859370470047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 642416, "time": 20549.300409317017, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 642576, "time": 20554.222098350525, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 642960, "time": 20566.134113550186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643064, "time": 20569.11630654335, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 643144, "time": 20571.599610090256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643144, "time": 20571.612602233887, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 643560, "time": 20584.421168088913, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 643696, "time": 20588.916224956512, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 643784, "time": 20591.397238731384, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 643824, "time": 20592.876754045486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644000, "time": 20598.29020833969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644112, "time": 20601.747373580933, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 644200, "time": 20604.235879182816, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 644336, "time": 20608.6569211483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644472, "time": 20612.6237449646, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 644816, "time": 20623.57580757141, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 644888, "time": 20625.570372581482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 645000, "time": 20629.027968406677, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 645120, "time": 20632.957505464554, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 645424, "time": 20642.30178117752, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 645432, "time": 20642.334113121033, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 645456, "time": 20643.313084602356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 646144, "time": 20664.60862326622, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 646392, "time": 20672.02777004242, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 646424, "time": 20673.027850151062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 646648, "time": 20680.04538989067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 646784, "time": 20684.457134246826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647112, "time": 20694.32986140251, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 647128, "time": 20694.824061632156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647352, "time": 20702.251022577286, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 647432, "time": 20704.705362081528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647464, "time": 20705.688558101654, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 647656, "time": 20711.735819101334, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 647744, "time": 20714.667955875397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648240, "time": 20729.926753997803, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 648400, "time": 20734.835333824158, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 648456, "time": 20736.34879374504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648704, "time": 20744.321727514267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 648968, "time": 20752.247168064117, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 649056, "time": 20755.17813563347, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 649264, "time": 20761.620498418808, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 649288, "time": 20762.14230108261, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 649376, "time": 20765.074092149734, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 649528, "time": 20769.67844772339, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 649744, "time": 20776.537163972855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 649976, "time": 20783.42023062706, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 20785.203110218048, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 650000, "time": 20785.640644311905, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 650000, "time": 20785.930898189545, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 650000, "time": 20786.424701929092, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 650000, "time": 20786.97579073906, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 650000, "time": 20787.455152511597, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 650000, "time": 20788.5550904274, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 650000, "time": 20788.921624422073, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 650008, "time": 20788.95124077797, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 650056, "time": 20790.449355363846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650056, "time": 20790.45809674263, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 650328, "time": 20798.869549512863, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 650552, "time": 20805.77533555031, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 650696, "time": 20810.21093249321, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 651160, "time": 20824.52205681801, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 651368, "time": 20831.039410352707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651624, "time": 20838.873738765717, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 651840, "time": 20845.76699757576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652088, "time": 20853.177587985992, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 652192, "time": 20856.61003255844, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 652320, "time": 20860.680615901947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652368, "time": 20862.14212179184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652640, "time": 20870.494020938873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652792, "time": 20874.94699048996, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 652864, "time": 20877.376201868057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653120, "time": 20885.248155117035, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 653192, "time": 20887.23282456398, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 653584, "time": 20899.65173435211, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 653680, "time": 20902.58600282669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653712, "time": 20903.5914041996, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 654176, "time": 20917.861217737198, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 654176, "time": 20917.871386051178, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 654504, "time": 20927.823734998703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 654680, "time": 20933.251784801483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655104, "time": 20946.539931297302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655784, "time": 20967.8967833519, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 655896, "time": 20971.361535310745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655992, "time": 20974.328176021576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656024, "time": 20975.31517314911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656392, "time": 20986.76440858841, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 656488, "time": 20989.723944664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656488, "time": 20989.732805252075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656992, "time": 21005.495857477188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 657056, "time": 21007.47104382515, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 657104, "time": 21009.123997449875, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 657184, "time": 21011.570541143417, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 657608, "time": 21024.31917977333, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 657616, "time": 21024.786751508713, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 657664, "time": 21026.248332738876, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 657720, "time": 21027.764995336533, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 657848, "time": 21031.66318297386, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 657896, "time": 21033.14715886116, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 657896, "time": 21033.155345916748, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 658096, "time": 21039.614553928375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658112, "time": 21040.106540203094, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 658248, "time": 21044.060119390488, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 658552, "time": 21053.404351234436, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 658632, "time": 21055.859085559845, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 658688, "time": 21057.821343421936, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 658800, "time": 21061.260624408722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 659248, "time": 21075.143090248108, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 659600, "time": 21085.96887564659, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 21102.12306022644, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 660088, "time": 21102.362208604813, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 660088, "time": 21102.549980163574, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 660088, "time": 21102.814861774445, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 660088, "time": 21102.84257864952, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 660088, "time": 21103.038930654526, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 660088, "time": 21104.324188947678, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 660088, "time": 21104.653346538544, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 660160, "time": 21107.116055727005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660208, "time": 21108.630268335342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660424, "time": 21116.819907665253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660824, "time": 21129.236637353897, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 660864, "time": 21130.687146425247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660944, "time": 21133.15326809883, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 661000, "time": 21134.64470934868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 661136, "time": 21139.034472703934, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 661144, "time": 21139.0645468235, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 661560, "time": 21151.869071006775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 661592, "time": 21152.85001182556, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 661664, "time": 21155.270258903503, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 661728, "time": 21157.249784231186, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 661888, "time": 21162.26322412491, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 661912, "time": 21162.78555059433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662376, "time": 21177.01726102829, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 662472, "time": 21179.971259832382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662496, "time": 21180.9450609684, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 662664, "time": 21185.8945376873, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 662736, "time": 21188.382801294327, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 662736, "time": 21188.41327571869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663232, "time": 21203.744406938553, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 663264, "time": 21204.72919511795, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 663448, "time": 21210.16967511177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663456, "time": 21210.649178266525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663728, "time": 21219.642701387405, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 664096, "time": 21230.886234283447, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 664200, "time": 21233.85683488846, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 664432, "time": 21241.25360774994, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 664520, "time": 21243.751625299454, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 664784, "time": 21252.22875213623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 664808, "time": 21252.755130529404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 664808, "time": 21252.78294825554, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 664928, "time": 21256.72637462616, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 665160, "time": 21263.636192321777, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 665248, "time": 21266.575167179108, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 665296, "time": 21268.03955578804, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 665616, "time": 21277.854102373123, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 665689, "time": 21280.943645954132, "train_stats/mean_log_entropy": 0.09604155307352855, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.601129396997317, "train/action_min": 0.0, "train/action_std": 1.8366073640910061, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008438487252634432, "train/actor_opt_grad_steps": 40515.0, "train/actor_opt_loss": -9.909472293926008, "train/adv_mag": 0.8106845812966125, "train/adv_max": 0.3302910990185208, "train/adv_mean": -0.00045351141926228665, "train/adv_min": -0.7816521832437227, "train/adv_std": 0.030195145077551857, "train/cont_avg": 0.9954673690025253, "train/cont_loss_mean": 0.012915212585769519, "train/cont_loss_std": 0.19892855389090724, "train/cont_neg_acc": 0.42772742735250346, "train/cont_neg_loss": 2.302168229772109, "train/cont_pos_acc": 0.9998810216031894, "train/cont_pos_loss": 0.002647755766931846, "train/cont_pred": 0.9955247252276449, "train/cont_rate": 0.9954673690025253, "train/dyn_loss_mean": 1.0000009037027455, "train/dyn_loss_std": 2.8914730082209587e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.23018005507706543, "train/extr_critic_critic_opt_grad_steps": 40515.0, "train/extr_critic_critic_opt_loss": 13292.13792712279, "train/extr_critic_mag": 1.113318387908165, "train/extr_critic_max": 1.113318387908165, "train/extr_critic_mean": 1.0090622399190459, "train/extr_critic_min": 0.780055471742996, "train/extr_critic_std": 0.01690202746352162, "train/extr_return_normed_mag": 0.8103252131529529, "train/extr_return_normed_max": 0.27979103061887955, "train/extr_return_normed_mean": 0.026966990761763437, "train/extr_return_normed_min": -0.785409041125365, "train/extr_return_normed_std": 0.03526771663584643, "train/extr_return_rate": 0.9986667253754355, "train/extr_return_raw_mag": 1.2614327970177237, "train/extr_return_raw_max": 1.2614327970177237, "train/extr_return_raw_mean": 1.0086088129366286, "train/extr_return_raw_min": 0.19623272527347912, "train/extr_return_raw_std": 0.035267716762844965, "train/extr_reward_mag": 0.35534973276986015, "train/extr_reward_max": 0.35534973276986015, "train/extr_reward_mean": 0.0018469414494712978, "train/extr_reward_min": 8.368732953312421e-08, "train/extr_reward_std": 0.010285749559930403, "train/image_loss_mean": 0.08372213629384835, "train/image_loss_std": 0.09629207608675716, "train/model_loss_mean": 0.7047262251979173, "train/model_loss_std": 0.3549435935688741, "train/model_opt_grad_norm": 21.16268114610152, "train/model_opt_grad_steps": 40476.89898989899, "train/model_opt_loss": 3541.2203788372003, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5050.50505050505, "train/policy_entropy_mag": 1.3071859135772244, "train/policy_entropy_max": 1.3071859135772244, "train/policy_entropy_mean": 0.1100581471215595, "train/policy_entropy_min": 0.06468649212308604, "train/policy_entropy_std": 0.14244235088728896, "train/policy_logprob_mag": 6.551080248572609, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11010237602573453, "train/policy_logprob_min": -6.551080248572609, "train/policy_logprob_std": 0.6473080163652246, "train/policy_randomness_mag": 0.6717607144153479, "train/policy_randomness_max": 0.6717607144153479, "train/policy_randomness_mean": 0.056558701614237795, "train/policy_randomness_min": 0.03324228154514173, "train/policy_randomness_std": 0.0732008915281657, "train/post_ent_mag": 33.038136501504916, "train/post_ent_max": 33.038136501504916, "train/post_ent_mean": 22.884163846873275, "train/post_ent_min": 18.82432707391604, "train/post_ent_std": 2.854779814228867, "train/prior_ent_mag": 33.98906575790559, "train/prior_ent_max": 33.98906575790559, "train/prior_ent_mean": 23.66479250397345, "train/prior_ent_min": 19.210826449924046, "train/prior_ent_std": 2.5564604166782265, "train/rep_loss_mean": 1.0000009037027455, "train/rep_loss_std": 2.8914730082209587e-05, "train/reward_avg": 0.0010707200212110742, "train/reward_loss_mean": 0.008088311021724208, "train/reward_loss_std": 0.15587916806801175, "train/reward_max_data": 0.6002367437262126, "train/reward_max_pred": 0.23846191288244845, "train/reward_neg_acc": 0.9997776343364908, "train/reward_neg_loss": 0.0011918035555146447, "train/reward_pos_acc": 0.32787698649224783, "train/reward_pos_loss": 3.9930454524500028, "train/reward_pred": 0.0008264362090032059, "train/reward_rate": 0.001741043244949495, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.014316129498183727, "report/cont_loss_std": 0.2575899064540863, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.139662265777588, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0017895338824018836, "report/cont_pred": 0.9950665831565857, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08101095259189606, "report/image_loss_std": 0.10088395327329636, "report/model_loss_mean": 0.7008304595947266, "report/model_loss_std": 0.31990373134613037, "report/post_ent_mag": 31.134685516357422, "report/post_ent_max": 31.134685516357422, "report/post_ent_mean": 20.362255096435547, "report/post_ent_min": 16.095443725585938, "report/post_ent_std": 3.116751194000244, "report/prior_ent_mag": 34.32060241699219, "report/prior_ent_max": 34.32060241699219, "report/prior_ent_mean": 23.55524444580078, "report/prior_ent_min": 18.525638580322266, "report/prior_ent_std": 2.825157642364502, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0010284424060955644, "report/reward_loss_mean": 0.005503379739820957, "report/reward_loss_std": 0.11121228337287903, "report/reward_max_data": 0.8218749761581421, "report/reward_max_pred": 0.5395932197570801, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0010387588990852237, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 2.2869246006011963, "report/reward_pred": 0.0012120648752897978, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.04527123272418976, "eval/cont_loss_std": 0.6674320697784424, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.038891792297363, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0011415935587137938, "eval/cont_pred": 0.9988678097724915, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12269780039787292, "eval/image_loss_std": 0.1176694855093956, "eval/model_loss_mean": 0.7832955718040466, "eval/model_loss_std": 0.8893339037895203, "eval/post_ent_mag": 31.295337677001953, "eval/post_ent_max": 31.295337677001953, "eval/post_ent_mean": 20.073854446411133, "eval/post_ent_min": 16.088314056396484, "eval/post_ent_std": 3.083613634109497, "eval/prior_ent_mag": 34.1680908203125, "eval/prior_ent_max": 34.1680908203125, "eval/prior_ent_mean": 23.174846649169922, "eval/prior_ent_min": 18.503040313720703, "eval/prior_ent_std": 2.823469638824463, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0015869140625, "eval/reward_loss_mean": 0.015326484106481075, "eval/reward_loss_std": 0.34291213750839233, "eval/reward_max_data": 0.8218749761581421, "eval/reward_max_pred": 0.02370607852935791, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0005101009737700224, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.586499214172363, "eval/reward_pred": 0.0002530311467126012, "eval/reward_rate": 0.001953125, "replay/size": 665185.0, "replay/inserts": 31776.0, "replay/samples": 31776.0, "replay/insert_wait_avg": 1.4994949972761602e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.992004459838252e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4744.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3100960202402047e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3230800628662, "timer/env.step_count": 3972.0, "timer/env.step_total": 41.28678297996521, "timer/env.step_frac": 0.041273448351677046, "timer/env.step_avg": 0.010394456943596479, "timer/env.step_min": 0.008815526962280273, "timer/env.step_max": 0.039415836334228516, "timer/replay._sample_count": 31776.0, "timer/replay._sample_total": 16.869926691055298, "timer/replay._sample_frac": 0.01686447811440589, "timer/replay._sample_avg": 0.0005309015197336133, "timer/replay._sample_min": 0.000354766845703125, "timer/replay._sample_max": 0.025246381759643555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4565.0, "timer/agent.policy_total": 51.946534395217896, "timer/agent.policy_frac": 0.05192975692608559, "timer/agent.policy_avg": 0.011379306548788147, "timer/agent.policy_min": 0.009433984756469727, "timer/agent.policy_max": 0.0926051139831543, "timer/dataset_train_count": 1986.0, "timer/dataset_train_total": 0.24347496032714844, "timer/dataset_train_frac": 0.00024339632382754483, "timer/dataset_train_avg": 0.0001225956497115551, "timer/dataset_train_min": 0.00010704994201660156, "timer/dataset_train_max": 0.0004520416259765625, "timer/agent.train_count": 1986.0, "timer/agent.train_total": 893.7639427185059, "timer/agent.train_frac": 0.893475278669304, "timer/agent.train_avg": 0.45003219673640776, "timer/agent.train_min": 0.4359755516052246, "timer/agent.train_max": 2.2229065895080566, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4823417663574219, "timer/agent.report_frac": 0.00048218598168014743, "timer/agent.report_avg": 0.24117088317871094, "timer/agent.report_min": 0.23357439041137695, "timer/agent.report_max": 0.24876737594604492, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.1699429566810545e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 31.76514787619456}
{"step": 665960, "time": 21289.060428857803, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 666040, "time": 21291.532638549805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 666120, "time": 21293.980262756348, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 666152, "time": 21294.965543031693, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 666400, "time": 21302.866233110428, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 666424, "time": 21303.383357048035, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 666632, "time": 21309.86369729042, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 666648, "time": 21310.360082149506, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 666768, "time": 21314.272936582565, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 667096, "time": 21324.11620116234, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 667120, "time": 21325.07667016983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667240, "time": 21328.55389547348, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 667304, "time": 21330.521544456482, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 667312, "time": 21331.015434503555, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 667608, "time": 21340.009941339493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667632, "time": 21341.000119686127, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 667752, "time": 21344.468843221664, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 667760, "time": 21344.94232773781, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 668160, "time": 21357.25929903984, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 668176, "time": 21357.759133577347, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 668432, "time": 21365.665836811066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668584, "time": 21370.215784311295, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 668712, "time": 21374.18183708191, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668992, "time": 21383.0219643116, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 669048, "time": 21384.519493579865, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 669552, "time": 21400.380657672882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669600, "time": 21401.846623659134, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 669616, "time": 21402.34517621994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669656, "time": 21403.346952199936, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 669672, "time": 21403.84390115738, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 670064, "time": 21416.036638259888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 21416.84013390541, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 670072, "time": 21416.89130616188, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 670072, "time": 21417.315895318985, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 670072, "time": 21418.573446273804, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 670072, "time": 21421.34894323349, "eval_episode/length": 187.0, "eval_episode/score": 0.4156250059604645, "eval_episode/reward_rate": 0.005319148936170213}
{"step": 670072, "time": 21422.301961183548, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21422.310383081436, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21422.318465948105, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21422.326910734177, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670072, "time": 21422.334572315216, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 670392, "time": 21432.23458123207, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 670744, "time": 21442.977689743042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670896, "time": 21447.838144540787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671408, "time": 21463.593091011047, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 671776, "time": 21475.33797955513, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 671864, "time": 21477.823390722275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671912, "time": 21479.29719519615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671928, "time": 21479.791930675507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671968, "time": 21481.252414226532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672128, "time": 21486.1555352211, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 672344, "time": 21492.613667488098, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 672376, "time": 21493.60035252571, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672592, "time": 21500.42680168152, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 672648, "time": 21501.914991617203, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 672816, "time": 21507.267720222473, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 672824, "time": 21507.297927618027, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 673112, "time": 21516.107454299927, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 673168, "time": 21518.04648542404, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 673344, "time": 21523.583078622818, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 673416, "time": 21525.587110996246, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 673680, "time": 21533.961684942245, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 673720, "time": 21534.983944177628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674096, "time": 21546.715122699738, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 674224, "time": 21550.779094696045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674280, "time": 21552.273838043213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674376, "time": 21555.232676267624, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 674448, "time": 21557.662157297134, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 674816, "time": 21568.960460186005, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 675128, "time": 21578.295791864395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675328, "time": 21584.71902704239, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 675408, "time": 21587.151554107666, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 675424, "time": 21587.649941444397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675480, "time": 21589.16032886505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 675616, "time": 21593.535447359085, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 675768, "time": 21597.953578472137, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 675984, "time": 21604.79721236229, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 676240, "time": 21612.71204018593, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 676248, "time": 21612.741826295853, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 676408, "time": 21617.614129543304, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 676536, "time": 21621.550719738007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676592, "time": 21623.49859404564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676672, "time": 21625.936745643616, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 676688, "time": 21626.43333888054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676696, "time": 21626.462847709656, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 677208, "time": 21642.272253513336, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 677320, "time": 21645.706258773804, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 677440, "time": 21649.621344566345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678016, "time": 21667.279732465744, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 678080, "time": 21669.389977931976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678488, "time": 21681.683105945587, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 678552, "time": 21683.669266939163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678560, "time": 21684.147767305374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678904, "time": 21694.452688217163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679008, "time": 21697.867948770523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679056, "time": 21699.470951795578, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 679096, "time": 21700.476152181625, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 679264, "time": 21705.87243294716, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 679520, "time": 21713.733986616135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679576, "time": 21715.236951112747, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 679632, "time": 21717.201138973236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679672, "time": 21718.20777487755, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 679880, "time": 21724.611222982407, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 679920, "time": 21726.06219148636, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 679952, "time": 21727.58095383644, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 21731.35388970375, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 680056, "time": 21732.293251752853, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 680056, "time": 21732.479252576828, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 680056, "time": 21733.018085479736, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 680056, "time": 21733.589502573013, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 680056, "time": 21734.985479593277, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 680056, "time": 21736.340301513672, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 680056, "time": 21736.624744415283, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 680128, "time": 21739.07802581787, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 680392, "time": 21746.956346035004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680632, "time": 21754.36878848076, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 680872, "time": 21761.873039722443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680920, "time": 21763.365842580795, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 681488, "time": 21781.030772686005, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 681600, "time": 21784.485872507095, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 681888, "time": 21793.390147209167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681984, "time": 21796.316929340363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 682024, "time": 21797.323694705963, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 682104, "time": 21799.789933919907, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 682192, "time": 21802.72759628296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 682232, "time": 21803.73346233368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 682416, "time": 21809.576602458954, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 682440, "time": 21810.093757867813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 682544, "time": 21813.51473259926, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 682600, "time": 21815.004894018173, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 682720, "time": 21819.044194698334, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 682944, "time": 21825.929886102676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683152, "time": 21832.35144662857, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 683568, "time": 21845.166611671448, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 683576, "time": 21845.196579933167, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 683800, "time": 21852.231477737427, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 683912, "time": 21855.68479990959, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 684136, "time": 21862.593852758408, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 684296, "time": 21867.50187397003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684504, "time": 21873.877749204636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684664, "time": 21878.884074926376, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 684752, "time": 21881.82024025917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684856, "time": 21884.787470579147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 685032, "time": 21890.16396379471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 685400, "time": 21901.512355327606, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 685456, "time": 21903.487847328186, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 686448, "time": 21934.044865846634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686600, "time": 21938.663815259933, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 686608, "time": 21939.13860464096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686816, "time": 21945.53049135208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686976, "time": 21950.43466424942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686992, "time": 21950.948504924774, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 687064, "time": 21952.932877779007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687112, "time": 21954.40718460083, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 687168, "time": 21956.37497472763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687240, "time": 21958.365944862366, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 687592, "time": 21969.322882413864, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 687736, "time": 21973.75005197525, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 687768, "time": 21974.73800754547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 687784, "time": 21975.241978168488, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 687928, "time": 21979.67265677452, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 688208, "time": 21989.020861387253, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 688616, "time": 22001.43409013748, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 688968, "time": 22012.16414785385, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 689304, "time": 22022.429963111877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 689440, "time": 22026.802538633347, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 689552, "time": 22030.316370248795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 22046.06942176819, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 690040, "time": 22046.825667142868, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 690040, "time": 22047.760303258896, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 690040, "time": 22048.023490667343, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 690040, "time": 22048.231106042862, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 690040, "time": 22049.696182250977, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 690040, "time": 22050.90393447876, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 690040, "time": 22051.20977807045, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22051.217678785324, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690040, "time": 22051.226778268814, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 690048, "time": 22051.704942941666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690080, "time": 22052.681462287903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690096, "time": 22053.176457881927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690456, "time": 22064.071581840515, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 690456, "time": 22064.079355239868, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 690520, "time": 22066.068895578384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 690928, "time": 22078.73343348503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691208, "time": 22087.07290673256, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 691280, "time": 22089.639588832855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691752, "time": 22103.878767728806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691864, "time": 22107.33617424965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692256, "time": 22119.711924552917, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 692392, "time": 22123.660826444626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692472, "time": 22126.135744571686, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 692768, "time": 22135.435265302658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692832, "time": 22137.393391609192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 693232, "time": 22149.80813384056, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 693240, "time": 22149.839306116104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 693312, "time": 22152.24473786354, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 693456, "time": 22156.634179353714, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 693520, "time": 22158.590814828873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 693592, "time": 22160.59997177124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 693648, "time": 22162.53971195221, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 693800, "time": 22166.95988368988, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 694304, "time": 22182.739916086197, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 694368, "time": 22184.70703601837, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 694456, "time": 22187.164234161377, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 694784, "time": 22197.37434911728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 694928, "time": 22201.781795978546, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 695544, "time": 22220.531995534897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 695624, "time": 22222.98609972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 695904, "time": 22231.842091083527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 695960, "time": 22233.374147176743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 696016, "time": 22235.327451229095, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 696168, "time": 22239.94373869896, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 696216, "time": 22241.419746637344, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 696480, "time": 22250.302691936493, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 696560, "time": 22252.7490670681, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 696576, "time": 22253.245641946793, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 696616, "time": 22254.27753329277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 696768, "time": 22259.17239880562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 696928, "time": 22264.123786449432, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 697160, "time": 22271.160827875137, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 697240, "time": 22273.636527776718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 697432, "time": 22279.549717903137, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 697449, "time": 22281.055011034012, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6138842405386304, "train/action_min": 0.0, "train/action_std": 1.8400832732119152, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007582773648707861, "train/actor_opt_grad_steps": 42500.0, "train/actor_opt_loss": -9.601812916185388, "train/adv_mag": 0.755196712873689, "train/adv_max": 0.30832527360724443, "train/adv_mean": -0.0006938662380039501, "train/adv_min": -0.7262048198649632, "train/adv_std": 0.025154983416555365, "train/cont_avg": 0.9954557945979899, "train/cont_loss_mean": 0.014596180769500216, "train/cont_loss_std": 0.22132046807594785, "train/cont_neg_acc": 0.38184474113628947, "train/cont_neg_loss": 2.603287199203653, "train/cont_pos_acc": 0.9997584436407041, "train/cont_pos_loss": 0.0029477467830643883, "train/cont_pred": 0.9954689854952559, "train/cont_rate": 0.9954557945979899, "train/dyn_loss_mean": 1.0000062827488885, "train/dyn_loss_std": 8.767939947227287e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.19462042881278835, "train/extr_critic_critic_opt_grad_steps": 42500.0, "train/extr_critic_critic_opt_loss": 12304.524296286118, "train/extr_critic_mag": 1.0626734573038379, "train/extr_critic_max": 1.0626734573038379, "train/extr_critic_mean": 0.9770978060199986, "train/extr_critic_min": 0.7699876742147321, "train/extr_critic_std": 0.014072610163621267, "train/extr_return_normed_mag": 0.7524602002833956, "train/extr_return_normed_max": 0.2539898169100584, "train/extr_return_normed_mean": 0.022881584865598, "train/extr_return_normed_min": -0.7249455604720955, "train/extr_return_normed_std": 0.029179994962248372, "train/extr_return_rate": 0.9988464904789949, "train/extr_return_raw_mag": 1.2075120989401735, "train/extr_return_raw_max": 1.2075120989401735, "train/extr_return_raw_mean": 0.9764039118086273, "train/extr_return_raw_min": 0.22857672155801975, "train/extr_return_raw_std": 0.02917999507456868, "train/extr_reward_mag": 0.3308081423217927, "train/extr_reward_max": 0.3308081423217927, "train/extr_reward_mean": 0.0016137718592463856, "train/extr_reward_min": 8.386583184477073e-08, "train/extr_reward_std": 0.00834140790762127, "train/image_loss_mean": 0.07997432564520955, "train/image_loss_std": 0.09380588233096515, "train/model_loss_mean": 0.7030259787137784, "train/model_loss_std": 0.37064841872633403, "train/model_opt_grad_norm": 20.48312461316286, "train/model_opt_grad_steps": 42459.95477386934, "train/model_opt_loss": 3568.7263171325376, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5075.37688442211, "train/policy_entropy_mag": 1.3118611729923804, "train/policy_entropy_max": 1.3118611729923804, "train/policy_entropy_mean": 0.1057176320022674, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13665156306034357, "train/policy_logprob_mag": 6.551080246067526, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10537644943699764, "train/policy_logprob_min": -6.551080246067526, "train/policy_logprob_std": 0.6421994695711375, "train/policy_randomness_mag": 0.6741633229519255, "train/policy_randomness_max": 0.6741633229519255, "train/policy_randomness_mean": 0.054328118006338424, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07022501670535486, "train/post_ent_mag": 37.511962718101, "train/post_ent_max": 37.511962718101, "train/post_ent_mean": 22.681488180879374, "train/post_ent_min": 17.37650870797622, "train/post_ent_std": 4.111948315222659, "train/prior_ent_mag": 36.690129610761325, "train/prior_ent_max": 36.690129610761325, "train/prior_ent_mean": 23.59835743544689, "train/prior_ent_min": 17.971244677826387, "train/prior_ent_std": 3.4504579167869225, "train/rep_loss_mean": 1.0000062827488885, "train/rep_loss_std": 8.767939947227287e-05, "train/reward_avg": 0.0011331222768014193, "train/reward_loss_mean": 0.008451682351641919, "train/reward_loss_std": 0.1556545931046791, "train/reward_max_data": 0.6134265093647655, "train/reward_max_pred": 0.22931087975525977, "train/reward_neg_acc": 0.9996116811306632, "train/reward_neg_loss": 0.0014061188470366312, "train/reward_pos_acc": 0.26808080971241, "train/reward_pos_loss": 3.9904936747117477, "train/reward_pred": 0.0008842864555854294, "train/reward_rate": 0.0017519236809045227, "train_stats/mean_log_entropy": 0.09116183340395849, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.02330385521054268, "report/cont_loss_std": 0.29581528902053833, "report/cont_neg_acc": 0.375, "report/cont_neg_loss": 2.526416301727295, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003594307927414775, "report/cont_pred": 0.9937687516212463, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0776270404458046, "report/image_loss_std": 0.09129959344863892, "report/model_loss_mean": 0.7031494379043579, "report/model_loss_std": 0.30911383032798767, "report/post_ent_mag": 43.35150909423828, "report/post_ent_max": 43.35150909423828, "report/post_ent_mean": 24.345760345458984, "report/post_ent_min": 18.17873764038086, "report/post_ent_std": 5.560441970825195, "report/prior_ent_mag": 41.49892807006836, "report/prior_ent_max": 41.49892807006836, "report/prior_ent_mean": 24.35847282409668, "report/prior_ent_min": 17.493118286132812, "report/prior_ent_std": 4.451446533203125, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006164551014080644, "report/reward_loss_mean": 0.002218503039330244, "report/reward_loss_std": 0.03596798703074455, "report/reward_max_data": 0.6312500238418579, "report/reward_max_pred": 0.5729639530181885, "report/reward_neg_acc": 0.9980449676513672, "report/reward_neg_loss": 0.0012405674206092954, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 1.002646565437317, "report/reward_pred": 0.0011436945060268044, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0238998644053936, "eval/cont_loss_std": 0.4770108163356781, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.636781692504883, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.003131014760583639, "eval/cont_pred": 0.9975661039352417, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11162959784269333, "eval/image_loss_std": 0.12615305185317993, "eval/model_loss_mean": 0.7496747374534607, "eval/model_loss_std": 0.8322678804397583, "eval/post_ent_mag": 43.562217712402344, "eval/post_ent_max": 43.562217712402344, "eval/post_ent_mean": 23.674001693725586, "eval/post_ent_min": 17.73680877685547, "eval/post_ent_std": 5.213144302368164, "eval/prior_ent_mag": 43.496803283691406, "eval/prior_ent_max": 43.496803283691406, "eval/prior_ent_mean": 23.867795944213867, "eval/prior_ent_min": 16.647369384765625, "eval/prior_ent_std": 4.3849897384643555, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0003631591680459678, "eval/reward_loss_mean": 0.01414525043219328, "eval/reward_loss_std": 0.43807169795036316, "eval/reward_max_data": 0.37187498807907104, "eval/reward_max_pred": 0.0523684024810791, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0004493241722229868, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 14.025077819824219, "eval/reward_pred": 0.00022552418522536755, "eval/reward_rate": 0.0009765625, "replay/size": 696945.0, "replay/inserts": 31760.0, "replay/samples": 31760.0, "replay/insert_wait_avg": 1.4783528349561716e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.946560304771443e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6592.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2909035080844916e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0962188243866, "timer/env.step_count": 3970.0, "timer/env.step_total": 41.207523584365845, "timer/env.step_frac": 0.041203559026355786, "timer/env.step_avg": 0.010379728862560667, "timer/env.step_min": 0.008836507797241211, "timer/env.step_max": 0.03736305236816406, "timer/replay._sample_count": 31760.0, "timer/replay._sample_total": 16.9299054145813, "timer/replay._sample_frac": 0.016928276595708367, "timer/replay._sample_avg": 0.000533057475270192, "timer/replay._sample_min": 0.00040340423583984375, "timer/replay._sample_max": 0.02562093734741211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4794.0, "timer/agent.policy_total": 54.346845388412476, "timer/agent.policy_frac": 0.05434161670193815, "timer/agent.policy_avg": 0.011336429993411029, "timer/agent.policy_min": 0.009202957153320312, "timer/agent.policy_max": 0.11015677452087402, "timer/dataset_train_count": 1985.0, "timer/dataset_train_total": 0.24657630920410156, "timer/dataset_train_frac": 0.00024655258620410753, "timer/dataset_train_avg": 0.00012421980312549198, "timer/dataset_train_min": 0.00010824203491210938, "timer/dataset_train_max": 0.0011146068572998047, "timer/agent.train_count": 1985.0, "timer/agent.train_total": 888.83487200737, "timer/agent.train_frac": 0.8887493575890084, "timer/agent.train_avg": 0.44777575415988413, "timer/agent.train_min": 0.43492627143859863, "timer/agent.train_max": 0.682988166809082, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48210692405700684, "timer/agent.report_frac": 0.0004820605407584919, "timer/agent.report_avg": 0.24105346202850342, "timer/agent.report_min": 0.23355436325073242, "timer/agent.report_max": 0.24855256080627441, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.367134094238281e-05, "timer/dataset_eval_frac": 7.366425305455458e-08, "timer/dataset_eval_avg": 7.367134094238281e-05, "timer/dataset_eval_min": 7.367134094238281e-05, "timer/dataset_eval_max": 7.367134094238281e-05, "fps": 31.756401928818175}
{"step": 698528, "time": 22314.446175813675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 698872, "time": 22324.828588962555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 698888, "time": 22325.33025455475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 698912, "time": 22326.295295476913, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 699080, "time": 22331.365116119385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699216, "time": 22335.78266429901, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 699232, "time": 22336.282374620438, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 699240, "time": 22336.313318490982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699400, "time": 22341.27114701271, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 699472, "time": 22343.71689581871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699640, "time": 22348.702580690384, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 699688, "time": 22350.176617860794, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 699872, "time": 22356.05025935173, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 699904, "time": 22357.032303094864, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 22361.243581533432, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 700024, "time": 22361.92196035385, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 700024, "time": 22361.993490457535, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 700024, "time": 22362.021951675415, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 700024, "time": 22362.85033106804, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 700024, "time": 22363.03049516678, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 700024, "time": 22363.10091638565, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 700024, "time": 22363.801080703735, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 700040, "time": 22364.302881002426, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 700248, "time": 22370.689770936966, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 700288, "time": 22372.154549360275, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 700296, "time": 22372.18439054489, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 700800, "time": 22387.869785308838, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 700800, "time": 22387.878395795822, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 700920, "time": 22391.464938640594, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 700976, "time": 22393.406784057617, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 701024, "time": 22394.887603998184, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 701264, "time": 22402.31473994255, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 701552, "time": 22411.180067539215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701792, "time": 22418.683626890182, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 701792, "time": 22418.69247150421, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 701912, "time": 22422.16703939438, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 702000, "time": 22425.105041742325, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702160, "time": 22430.023060798645, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 702216, "time": 22431.54314160347, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 702256, "time": 22432.99804210663, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 702552, "time": 22441.88384103775, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 702584, "time": 22442.882329940796, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 702600, "time": 22443.389323472977, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 702736, "time": 22447.79920220375, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 702944, "time": 22454.31250309944, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 702976, "time": 22455.291457414627, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 703112, "time": 22459.265114068985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 703136, "time": 22460.23365831375, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 703280, "time": 22464.65437412262, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 703384, "time": 22467.64206957817, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 703440, "time": 22469.57823896408, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 703792, "time": 22480.51528453827, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 703848, "time": 22482.00444841385, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 703984, "time": 22486.415715694427, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 704408, "time": 22499.235807418823, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 704816, "time": 22512.723087072372, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 705256, "time": 22526.02647280693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705288, "time": 22527.01717066765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705448, "time": 22531.96459197998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705592, "time": 22536.411824703217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705616, "time": 22537.3872051239, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 706160, "time": 22554.185344457626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706296, "time": 22558.15330696106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707112, "time": 22583.321434259415, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 707128, "time": 22583.813702344894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707568, "time": 22597.564193487167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707600, "time": 22598.686984062195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707760, "time": 22603.585671186447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707816, "time": 22605.090675115585, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 707904, "time": 22608.003028154373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707928, "time": 22608.51700401306, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 707936, "time": 22608.991472244263, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 708608, "time": 22629.718278169632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 708616, "time": 22629.74826145172, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 709232, "time": 22648.915944576263, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 709760, "time": 22665.28334712982, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 709880, "time": 22668.745410203934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 709912, "time": 22669.720972537994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 22674.398123264313, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 710008, "time": 22674.427243232727, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 710008, "time": 22674.541321992874, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 710008, "time": 22675.00787615776, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 710008, "time": 22675.096285820007, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 710008, "time": 22675.286866903305, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 710008, "time": 22677.326661109924, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 710008, "time": 22678.34467482567, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 710072, "time": 22680.350715637207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710128, "time": 22682.300857305527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710128, "time": 22682.309443712234, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 710216, "time": 22684.807923078537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710240, "time": 22685.780371427536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 710728, "time": 22700.676401615143, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 710856, "time": 22704.62545323372, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 710992, "time": 22709.0659263134, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 711072, "time": 22711.551663160324, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 711080, "time": 22711.581374168396, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 711216, "time": 22716.04291343689, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 711408, "time": 22722.17804813385, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 711544, "time": 22726.151687145233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711880, "time": 22736.513209342957, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 712072, "time": 22742.43420982361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712504, "time": 22755.836488246918, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 713040, "time": 22772.95844745636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 713304, "time": 22780.988603830338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 713384, "time": 22783.479987859726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 713528, "time": 22787.936984300613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 713720, "time": 22793.850286245346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 713856, "time": 22798.266431331635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 714056, "time": 22804.234129667282, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 714080, "time": 22805.206079006195, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 714312, "time": 22812.28307700157, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 714384, "time": 22814.759011507034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 714760, "time": 22826.184094667435, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 714816, "time": 22828.145866155624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715104, "time": 22837.100378274918, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 715312, "time": 22843.682646274567, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 715352, "time": 22844.68975687027, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 715472, "time": 22848.65579724312, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 715584, "time": 22852.106351614, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 715776, "time": 22858.026552438736, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 715840, "time": 22860.01040840149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 716224, "time": 22871.945695877075, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 716400, "time": 22877.42114162445, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 716544, "time": 22881.879190444946, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 716624, "time": 22884.355261802673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 716960, "time": 22894.762657403946, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 717168, "time": 22901.298968315125, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 717352, "time": 22906.71187520027, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 717392, "time": 22908.17299389839, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 717624, "time": 22915.033262729645, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717664, "time": 22916.489822626114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718088, "time": 22929.426632404327, "episode/length": 280.0, "episode/score": 0.125, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.0}
{"step": 718088, "time": 22929.43602490425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718272, "time": 22935.327689647675, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 718840, "time": 22952.599838733673, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 719272, "time": 22966.003417491913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719480, "time": 22972.421357393265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719664, "time": 22978.282020568848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719704, "time": 22979.291591882706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719936, "time": 22986.661036491394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 719976, "time": 22987.692339658737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 22992.952679395676, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 720096, "time": 22993.17507624626, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 720096, "time": 22993.41713142395, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 720096, "time": 22994.024230003357, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 720096, "time": 22994.03197669983, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 720096, "time": 22994.485053300858, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 720096, "time": 22994.749940395355, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 720096, "time": 22994.800446271896, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 720584, "time": 23009.69021964073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720848, "time": 23018.052116394043, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 721152, "time": 23028.10161614418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 721400, "time": 23035.53387928009, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 721584, "time": 23041.434318065643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 721792, "time": 23047.875335931778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 721880, "time": 23050.487438440323, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 721968, "time": 23053.405733823776, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 721976, "time": 23053.438661575317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722016, "time": 23054.892645835876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722248, "time": 23061.846356868744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 722288, "time": 23063.31337428093, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723112, "time": 23088.567395925522, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 723120, "time": 23089.042796373367, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 723712, "time": 23107.31003022194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723840, "time": 23111.390355587006, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 724104, "time": 23119.24094581604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 724192, "time": 23122.18935084343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 724280, "time": 23124.681903600693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 724288, "time": 23125.157598733902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 724296, "time": 23125.188153743744, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 724528, "time": 23132.53105354309, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 724560, "time": 23133.52178955078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 724704, "time": 23137.95679306984, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 724704, "time": 23138.000971078873, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 724840, "time": 23142.11835050583, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 724904, "time": 23144.10003209114, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 725336, "time": 23157.398041009903, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 725432, "time": 23160.395134925842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 725520, "time": 23163.311488628387, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 725608, "time": 23165.81190943718, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 725928, "time": 23175.753669023514, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 726224, "time": 23185.073581457138, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 726248, "time": 23185.59032893181, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 726352, "time": 23189.02950310707, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 726448, "time": 23191.974439382553, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 726496, "time": 23193.46345949173, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 726872, "time": 23204.932512521744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727104, "time": 23212.26856803894, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 727152, "time": 23213.760088205338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727200, "time": 23215.22670507431, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 727216, "time": 23215.72320318222, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 727448, "time": 23222.633694171906, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 727528, "time": 23225.119702339172, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 727576, "time": 23226.59450340271, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 727672, "time": 23229.696355819702, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 727720, "time": 23231.17700624466, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 728296, "time": 23248.934401750565, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 728312, "time": 23249.429651021957, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 728384, "time": 23251.86013150215, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 728416, "time": 23252.843826293945, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 728488, "time": 23254.862954378128, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 728616, "time": 23258.928699731827, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 728656, "time": 23260.38772201538, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 728680, "time": 23260.903168201447, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 728944, "time": 23269.234493017197, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 729032, "time": 23271.708005189896, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 729289, "time": 23281.142955064774, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4981885747094847, "train/action_min": 0.0, "train/action_std": 1.838169193148014, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.008735432008739991, "train/actor_opt_grad_steps": 44490.0, "train/actor_opt_loss": -9.684293769562064, "train/adv_mag": 0.7599326204414942, "train/adv_max": 0.304467650813673, "train/adv_mean": -0.0001438896900724638, "train/adv_min": -0.7314085909469643, "train/adv_std": 0.028003130564419318, "train/cont_avg": 0.9955048680904522, "train/cont_loss_mean": 0.014311646101949502, "train/cont_loss_std": 0.21052406273838414, "train/cont_neg_acc": 0.3831807005046001, "train/cont_neg_loss": 2.5247741498219214, "train/cont_pos_acc": 0.999797779112006, "train/cont_pos_loss": 0.003061537538133281, "train/cont_pred": 0.9954552695379785, "train/cont_rate": 0.9955048680904522, "train/dyn_loss_mean": 1.0000033390581908, "train/dyn_loss_std": 8.275464569667737e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.19655541440088245, "train/extr_critic_critic_opt_grad_steps": 44490.0, "train/extr_critic_critic_opt_loss": 10104.694841394472, "train/extr_critic_mag": 1.029277675714924, "train/extr_critic_max": 1.029277675714924, "train/extr_critic_mean": 0.9415739517116067, "train/extr_critic_min": 0.7841754954064911, "train/extr_critic_std": 0.014429461159485967, "train/extr_return_normed_mag": 0.7519474095435598, "train/extr_return_normed_max": 0.28712029373226455, "train/extr_return_normed_mean": 0.025438899679774016, "train/extr_return_normed_min": -0.72205974917915, "train/extr_return_normed_std": 0.032227539714781483, "train/extr_return_rate": 0.9984218412308238, "train/extr_return_raw_mag": 1.2031114215227827, "train/extr_return_raw_max": 1.2031114215227827, "train/extr_return_raw_mean": 0.9414300771813896, "train/extr_return_raw_min": 0.19393137861136814, "train/extr_return_raw_std": 0.0322275396118212, "train/extr_reward_mag": 0.33965721322064424, "train/extr_reward_max": 0.33965721322064424, "train/extr_reward_mean": 0.001702009886269219, "train/extr_reward_min": 1.2519970611112202e-07, "train/extr_reward_std": 0.00888994027247381, "train/image_loss_mean": 0.07972895041407652, "train/image_loss_std": 0.09388248654241538, "train/model_loss_mean": 0.7026089304056599, "train/model_loss_std": 0.3646025808911827, "train/model_opt_grad_norm": 20.429670550606467, "train/model_opt_grad_steps": 44447.97487437186, "train/model_opt_loss": 3530.5865190208856, "train/model_opt_model_opt_grad_overflow": 0.005025125628140704, "train/model_opt_model_opt_grad_scale": 5025.125628140703, "train/policy_entropy_mag": 1.3200076650734522, "train/policy_entropy_max": 1.3200076650734522, "train/policy_entropy_mean": 0.1101633662254966, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1431460634398101, "train/policy_logprob_mag": 6.551080260444526, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11035782566771435, "train/policy_logprob_min": -6.551080260444526, "train/policy_logprob_std": 0.6471075241889187, "train/policy_randomness_mag": 0.6783497932568268, "train/policy_randomness_max": 0.6783497932568268, "train/policy_randomness_mean": 0.05661277347548523, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07356252929373602, "train/post_ent_mag": 39.3833533052224, "train/post_ent_max": 39.3833533052224, "train/post_ent_mean": 22.708905263162737, "train/post_ent_min": 16.592683830452923, "train/post_ent_std": 4.7459643869543795, "train/prior_ent_mag": 40.684602191100765, "train/prior_ent_max": 40.684602191100765, "train/prior_ent_mean": 23.821581375658813, "train/prior_ent_min": 16.75736310853431, "train/prior_ent_std": 4.734857743708932, "train/rep_loss_mean": 1.0000033390581908, "train/rep_loss_std": 8.275464569667737e-05, "train/reward_avg": 0.001162336345255403, "train/reward_loss_mean": 0.008566307885591035, "train/reward_loss_std": 0.1577789112018777, "train/reward_max_data": 0.6268216089986677, "train/reward_max_pred": 0.24865202388571733, "train/reward_neg_acc": 0.9996460831944068, "train/reward_neg_loss": 0.001503589178286914, "train/reward_pos_acc": 0.33196078652844707, "train/reward_pos_loss": 3.852134943008423, "train/reward_pred": 0.0009406617586383943, "train/reward_rate": 0.001791182474874372, "train_stats/mean_log_entropy": 0.09423133399296593, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.016166366636753082, "report/cont_loss_std": 0.29640883207321167, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 2.6562066078186035, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003212291980162263, "report/cont_pred": 0.9939641952514648, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08414178341627121, "report/image_loss_std": 0.10117074102163315, "report/model_loss_mean": 0.7034235596656799, "report/model_loss_std": 0.31550508737564087, "report/post_ent_mag": 36.15801239013672, "report/post_ent_max": 36.15801239013672, "report/post_ent_mean": 21.091629028320312, "report/post_ent_min": 14.618560791015625, "report/post_ent_std": 4.498669147491455, "report/prior_ent_mag": 40.55036544799805, "report/prior_ent_max": 40.55036544799805, "report/prior_ent_mean": 24.33667755126953, "report/prior_ent_min": 16.547449111938477, "report/prior_ent_std": 5.166008949279785, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008331298595294356, "report/reward_loss_mean": 0.0031153608579188585, "report/reward_loss_std": 0.049524255096912384, "report/reward_max_data": 0.8531249761581421, "report/reward_max_pred": 0.5033506155014038, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0015862955478951335, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 1.5673491954803467, "report/reward_pred": 0.001273853238672018, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.04476381838321686, "eval/cont_loss_std": 0.6231437921524048, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.6282958984375, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002646391512826085, "eval/cont_pred": 0.9974210262298584, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10225512832403183, "eval/image_loss_std": 0.10218418389558792, "eval/model_loss_mean": 0.784409761428833, "eval/model_loss_std": 1.2508238554000854, "eval/post_ent_mag": 36.011287689208984, "eval/post_ent_max": 36.011287689208984, "eval/post_ent_mean": 20.443687438964844, "eval/post_ent_min": 15.091123580932617, "eval/post_ent_std": 4.359631061553955, "eval/prior_ent_mag": 40.50758743286133, "eval/prior_ent_max": 40.50758743286133, "eval/prior_ent_mean": 23.630664825439453, "eval/prior_ent_min": 16.29619789123535, "eval/prior_ent_std": 5.013923645019531, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0021942139137536287, "eval/reward_loss_mean": 0.03739079087972641, "eval/reward_loss_std": 0.679189920425415, "eval/reward_max_data": 0.8187500238418579, "eval/reward_max_pred": 0.07117640972137451, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011531334603205323, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 12.370272636413574, "eval/reward_pred": 0.0005627417704090476, "eval/reward_rate": 0.0029296875, "replay/size": 728785.0, "replay/inserts": 31840.0, "replay/samples": 31840.0, "replay/insert_wait_avg": 1.4869486866284854e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.022590498229367e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4376.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2993703594591325e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0661313533783, "timer/env.step_count": 3980.0, "timer/env.step_total": 41.293766021728516, "timer/env.step_frac": 0.0412910353896758, "timer/env.step_avg": 0.010375318095911688, "timer/env.step_min": 0.008846044540405273, "timer/env.step_max": 0.04096245765686035, "timer/replay._sample_count": 31840.0, "timer/replay._sample_total": 17.06640601158142, "timer/replay._sample_frac": 0.017065277461687102, "timer/replay._sample_avg": 0.0005360052139315773, "timer/replay._sample_min": 0.00041937828063964844, "timer/replay._sample_max": 0.011826038360595703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4527.0, "timer/agent.policy_total": 50.80646085739136, "timer/agent.policy_frac": 0.05080310117955454, "timer/agent.policy_avg": 0.011222986714687732, "timer/agent.policy_min": 0.009276866912841797, "timer/agent.policy_max": 0.0823967456817627, "timer/dataset_train_count": 1990.0, "timer/dataset_train_total": 0.24747800827026367, "timer/dataset_train_frac": 0.00024746164329688325, "timer/dataset_train_avg": 0.0001243608081760119, "timer/dataset_train_min": 0.0001068115234375, "timer/dataset_train_max": 0.0006816387176513672, "timer/agent.train_count": 1990.0, "timer/agent.train_total": 895.3700556755066, "timer/agent.train_frac": 0.8953108475574634, "timer/agent.train_avg": 0.44993470134447566, "timer/agent.train_min": 0.43805742263793945, "timer/agent.train_max": 0.7358155250549316, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4882211685180664, "timer/agent.report_frac": 0.0004881888839264681, "timer/agent.report_avg": 0.2441105842590332, "timer/agent.report_min": 0.23837566375732422, "timer/agent.report_max": 0.2498455047607422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.839897155761719e-05, "timer/dataset_eval_frac": 4.839577107977789e-08, "timer/dataset_eval_avg": 4.839897155761719e-05, "timer/dataset_eval_min": 4.839897155761719e-05, "timer/dataset_eval_max": 4.839897155761719e-05, "fps": 31.837328902040962}
{"step": 729528, "time": 23288.331743478775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 729576, "time": 23289.920627832413, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 23307.896944761276, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 730080, "time": 23307.907858371735, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 730080, "time": 23308.324120283127, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 730080, "time": 23308.4620347023, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 730080, "time": 23308.53443646431, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 730080, "time": 23309.094065904617, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 730080, "time": 23309.146640777588, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 730080, "time": 23309.518250226974, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 730128, "time": 23311.00794005394, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 730432, "time": 23320.54121541977, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 730488, "time": 23322.041288375854, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 730608, "time": 23325.968178272247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 730696, "time": 23328.48462176323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 730848, "time": 23333.392594337463, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 730928, "time": 23335.855226755142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 730968, "time": 23336.874477386475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731120, "time": 23341.79012989998, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 731144, "time": 23342.314089536667, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 731256, "time": 23345.79614162445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731352, "time": 23348.88706088066, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 731384, "time": 23349.876023054123, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 731408, "time": 23350.839124441147, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 731560, "time": 23355.290900230408, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 732056, "time": 23370.595215797424, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 732080, "time": 23371.558063983917, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 732304, "time": 23378.62732720375, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 732440, "time": 23382.627098083496, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 732448, "time": 23383.099043130875, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 732592, "time": 23387.541724443436, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 732624, "time": 23388.52336025238, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 732704, "time": 23390.981521844864, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 732832, "time": 23394.938844919205, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 732960, "time": 23398.89138174057, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 733008, "time": 23400.365968465805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733200, "time": 23406.253003835678, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 733280, "time": 23408.829177618027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733424, "time": 23413.285881519318, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 733584, "time": 23418.230884075165, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 733664, "time": 23420.679124593735, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 733696, "time": 23421.659515857697, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 734048, "time": 23432.543145656586, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 734072, "time": 23433.070755958557, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 734096, "time": 23434.04759454727, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 734544, "time": 23448.04325556755, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 734624, "time": 23450.497873544693, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 734936, "time": 23459.868369817734, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 734936, "time": 23459.897248744965, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 735024, "time": 23462.844787836075, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 735320, "time": 23471.843671798706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735552, "time": 23479.224687576294, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 735592, "time": 23480.242073774338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735680, "time": 23483.168224573135, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 735920, "time": 23490.540731191635, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 735976, "time": 23492.069625139236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 736080, "time": 23495.486907720566, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 736384, "time": 23504.951906204224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 736560, "time": 23510.359394788742, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 736688, "time": 23514.305755853653, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 736696, "time": 23514.336830854416, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 736992, "time": 23523.609518766403, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 737104, "time": 23527.055423736572, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 737144, "time": 23528.059787750244, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 737248, "time": 23531.609434127808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 737288, "time": 23532.826423883438, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 737360, "time": 23535.60931634903, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 737816, "time": 23549.3709628582, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 737896, "time": 23551.859239816666, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 738256, "time": 23563.23819899559, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 738288, "time": 23564.223501205444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 738392, "time": 23567.21604847908, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 738440, "time": 23568.680824518204, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 738496, "time": 23570.620257616043, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 738904, "time": 23582.900665044785, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 738912, "time": 23583.377753019333, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 739008, "time": 23586.33201956749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739040, "time": 23587.316962957382, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 739112, "time": 23589.419009447098, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 739288, "time": 23594.807794332504, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 739560, "time": 23603.172326803207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739840, "time": 23611.96413588524, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 740016, "time": 23617.413319826126, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 23619.805005073547, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 740064, "time": 23620.01401734352, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 740064, "time": 23620.736626386642, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 740064, "time": 23620.766220092773, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 740064, "time": 23620.772576093674, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 740064, "time": 23621.45448732376, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 740064, "time": 23621.481722593307, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 740064, "time": 23621.508807897568, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 740256, "time": 23627.40598297119, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 740288, "time": 23628.41304922104, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 740352, "time": 23630.387831926346, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 740400, "time": 23631.8711912632, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 740448, "time": 23633.363578557968, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 740704, "time": 23641.21148967743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741152, "time": 23655.182455778122, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 741192, "time": 23656.190792560577, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 741224, "time": 23657.19054055214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741384, "time": 23662.123564481735, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 741440, "time": 23664.102278470993, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 741592, "time": 23668.55038046837, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 741760, "time": 23673.935668706894, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 742232, "time": 23688.338176727295, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 742280, "time": 23689.80987262726, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 742328, "time": 23691.27863574028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742712, "time": 23703.152952432632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742760, "time": 23704.655125379562, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 742944, "time": 23710.685403108597, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 742952, "time": 23710.717398405075, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 743016, "time": 23712.707822084427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743048, "time": 23713.68981051445, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 743240, "time": 23719.598092556, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 743384, "time": 23724.016948461533, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 743512, "time": 23727.95014834404, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 743616, "time": 23731.36346554756, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 743664, "time": 23732.86514735222, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 743776, "time": 23736.307513952255, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 744048, "time": 23744.809329271317, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 744072, "time": 23745.333889484406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744136, "time": 23747.332141637802, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 744544, "time": 23760.0973508358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744640, "time": 23763.073404312134, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 744928, "time": 23772.086098909378, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 745008, "time": 23774.550189256668, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 745336, "time": 23784.39354801178, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 745552, "time": 23791.767805576324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 745560, "time": 23791.798070669174, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 745656, "time": 23794.7480969429, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 745680, "time": 23795.713411569595, "episode/length": 257.0, "episode/score": 0.19687500596046448, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.0}
{"step": 745976, "time": 23804.71512079239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746128, "time": 23809.611899375916, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 746200, "time": 23811.61158299446, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 746360, "time": 23816.57555794716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746408, "time": 23818.05609369278, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 746616, "time": 23824.456931352615, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 746832, "time": 23831.42721414566, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 746856, "time": 23831.943143367767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747056, "time": 23838.30488538742, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 747136, "time": 23840.76333284378, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 747608, "time": 23855.033531665802, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 747616, "time": 23855.5103764534, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 747792, "time": 23861.075828313828, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 747824, "time": 23862.058091640472, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 747840, "time": 23862.554266929626, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 747864, "time": 23863.070325374603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748000, "time": 23867.46832561493, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 748064, "time": 23869.40804386139, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 748128, "time": 23871.3744494915, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 748128, "time": 23871.38244986534, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 748464, "time": 23881.654591798782, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 748464, "time": 23881.661858320236, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 748512, "time": 23883.131931066513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748552, "time": 23884.148143291473, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 748672, "time": 23888.06880879402, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 748936, "time": 23896.08702301979, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 749144, "time": 23902.49169921875, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 749264, "time": 23906.422653198242, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 749328, "time": 23908.378873109818, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 749584, "time": 23916.300263643265, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 749744, "time": 23921.34895467758, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 749776, "time": 23922.33607339859, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 23930.685660600662, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 23931.739090919495, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 750048, "time": 23932.16206097603, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 750048, "time": 23932.27542591095, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 750048, "time": 23932.782844781876, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 750048, "time": 23932.943789958954, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 750048, "time": 23933.16412115097, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 750048, "time": 23933.34720993042, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 750048, "time": 23933.921644687653, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 750112, "time": 23935.883459091187, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 750144, "time": 23936.880556106567, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 750312, "time": 23941.827848911285, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 750416, "time": 23945.29164981842, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 750504, "time": 23947.793023586273, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 750776, "time": 23956.28083539009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 750824, "time": 23957.754204034805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 750864, "time": 23959.233050107956, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 751104, "time": 23966.571976661682, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 751456, "time": 23977.363745212555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751472, "time": 23977.879007339478, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 751480, "time": 23977.908921957016, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 751752, "time": 23986.396842241287, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 751888, "time": 23990.78530550003, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 752360, "time": 24004.97512292862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 752624, "time": 24013.372133016586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 752704, "time": 24015.8164935112, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 752816, "time": 24019.270405054092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 753080, "time": 24027.169670820236, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 753088, "time": 24027.644667863846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 753328, "time": 24035.006421089172, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 753520, "time": 24041.040996551514, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 753768, "time": 24048.95423388481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 753792, "time": 24049.915198087692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 753808, "time": 24050.408688545227, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 754048, "time": 24057.786669254303, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 754064, "time": 24058.29402565956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 754152, "time": 24060.76796746254, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 754296, "time": 24065.19373178482, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 754400, "time": 24068.76553106308, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 754648, "time": 24076.146023273468, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 754728, "time": 24078.615884304047, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 754808, "time": 24081.06140089035, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 755376, "time": 24098.835002183914, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 755392, "time": 24099.327924489975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755400, "time": 24099.359124422073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755472, "time": 24101.811697483063, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 755536, "time": 24103.776384830475, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 755568, "time": 24104.758353233337, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 755800, "time": 24111.643254995346, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 756176, "time": 24123.406614542007, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 756184, "time": 24123.437330007553, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 756208, "time": 24124.39802145958, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 756312, "time": 24127.389043331146, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 756392, "time": 24129.94854927063, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 756648, "time": 24137.80286502838, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 756712, "time": 24139.77420115471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 757048, "time": 24150.08048558235, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 757088, "time": 24151.546706438065, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 757120, "time": 24152.532519817352, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 757280, "time": 24157.48000741005, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 757512, "time": 24164.52723479271, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 757544, "time": 24165.505726337433, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 757712, "time": 24170.909207820892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 757712, "time": 24170.916929721832, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 757792, "time": 24173.36064529419, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 757872, "time": 24175.833562850952, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 758032, "time": 24180.759115695953, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 758072, "time": 24181.764316797256, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 758112, "time": 24183.214375019073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 758360, "time": 24190.74918794632, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 758544, "time": 24196.615584611893, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 758552, "time": 24196.646263360977, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 758856, "time": 24205.940049648285, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 758960, "time": 24209.339559316635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 758976, "time": 24209.834233283997, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 759128, "time": 24214.266819238663, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 759368, "time": 24221.785407543182, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 759424, "time": 24223.729567289352, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 759488, "time": 24225.708552360535, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 759488, "time": 24225.720940828323, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 759728, "time": 24233.041518211365, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 759824, "time": 24235.985978603363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759904, "time": 24238.43802332878, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 760008, "time": 24241.418118476868, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 24242.371668577194, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 24243.838305711746, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 760032, "time": 24243.995999097824, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 760032, "time": 24244.068952083588, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 760032, "time": 24244.54212284088, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 760032, "time": 24244.71554374695, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 760032, "time": 24245.47157907486, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 760032, "time": 24245.583037614822, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 760032, "time": 24245.802743911743, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 760080, "time": 24247.282659053802, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 760104, "time": 24247.79898929596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 760416, "time": 24257.7200217247, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 760456, "time": 24258.756248235703, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 760712, "time": 24266.629741191864, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 760744, "time": 24267.62748813629, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 760784, "time": 24269.099321365356, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 760808, "time": 24269.620401859283, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 760856, "time": 24271.09474658966, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 761145, "time": 24281.13543653488, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6859397696490266, "train/action_min": 0.0, "train/action_std": 1.887814777580338, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010533114559433643, "train/actor_opt_grad_steps": 46480.0, "train/actor_opt_loss": -7.639116067982199, "train/adv_mag": 0.7721065174994157, "train/adv_max": 0.3565819673801786, "train/adv_mean": 0.002664768613612978, "train/adv_min": -0.7263774563319719, "train/adv_std": 0.02952340711376176, "train/cont_avg": 0.9953036667713567, "train/cont_loss_mean": 0.015489796314613153, "train/cont_loss_std": 0.2238186903662942, "train/cont_neg_acc": 0.3551108779844327, "train/cont_neg_loss": 2.648521875165843, "train/cont_pos_acc": 0.9997977054298822, "train/cont_pos_loss": 0.003078297687923751, "train/cont_pred": 0.9954547971936326, "train/cont_rate": 0.9953036667713567, "train/dyn_loss_mean": 1.0000680619148752, "train/dyn_loss_std": 0.0004549520273035364, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16669209932337453, "train/extr_critic_critic_opt_grad_steps": 46480.0, "train/extr_critic_critic_opt_loss": 11651.208596694409, "train/extr_critic_mag": 1.0656613644643045, "train/extr_critic_max": 1.0656613644643045, "train/extr_critic_mean": 0.9700436723891215, "train/extr_critic_min": 0.8547146200534687, "train/extr_critic_std": 0.017121268908993983, "train/extr_return_normed_mag": 0.7663870079433499, "train/extr_return_normed_max": 0.3778454149188708, "train/extr_return_normed_mean": 0.03616455120114076, "train/extr_return_normed_min": -0.7070698142051697, "train/extr_return_normed_std": 0.03489691918556714, "train/extr_return_rate": 0.99883634570855, "train/extr_return_raw_mag": 1.3143893048990911, "train/extr_return_raw_max": 1.3143893048990911, "train/extr_return_raw_mean": 0.9727084882295312, "train/extr_return_raw_min": 0.22947407577505063, "train/extr_return_raw_std": 0.03489691934000757, "train/extr_reward_mag": 0.39335603570219263, "train/extr_reward_max": 0.39335603570219263, "train/extr_reward_mean": 0.001871560006133332, "train/extr_reward_min": 1.3957670585593986e-07, "train/extr_reward_std": 0.010286651648833748, "train/image_loss_mean": 0.07810443879371912, "train/image_loss_std": 0.09321546352388871, "train/model_loss_mean": 0.7026070173661313, "train/model_loss_std": 0.37881358462062914, "train/model_opt_grad_norm": 19.22402363206873, "train/model_opt_grad_steps": 46435.90452261306, "train/model_opt_loss": 3451.066154748351, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4912.060301507538, "train/policy_entropy_mag": 1.3162602377896333, "train/policy_entropy_max": 1.3162602377896333, "train/policy_entropy_mean": 0.11255228133806632, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.14738478212051057, "train/policy_logprob_mag": 6.551080238879027, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11211539333190151, "train/policy_logprob_min": -6.551080238879027, "train/policy_logprob_std": 0.6465963960891992, "train/policy_randomness_mag": 0.67642399474005, "train/policy_randomness_max": 0.67642399474005, "train/policy_randomness_mean": 0.05784043302787608, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07574079964478411, "train/post_ent_mag": 38.87408665796021, "train/post_ent_max": 38.87408665796021, "train/post_ent_mean": 21.87851032659636, "train/post_ent_min": 15.827667902462446, "train/post_ent_std": 4.8966337053021, "train/prior_ent_mag": 38.14130169662399, "train/prior_ent_max": 38.14130169662399, "train/prior_ent_mean": 23.43661021707046, "train/prior_ent_min": 17.036944020333603, "train/prior_ent_std": 4.3633360443402776, "train/rep_loss_mean": 1.0000680619148752, "train/rep_loss_std": 0.0004549520273035364, "train/reward_avg": 0.0012014111113543247, "train/reward_loss_mean": 0.008971923746369855, "train/reward_loss_std": 0.16599735937048518, "train/reward_max_data": 0.6334013804493837, "train/reward_max_pred": 0.22861277697673396, "train/reward_neg_acc": 0.999645981656846, "train/reward_neg_loss": 0.0015018663388716722, "train/reward_pos_acc": 0.2711240327808746, "train/reward_pos_loss": 4.070820695439051, "train/reward_pred": 0.0009592446474002758, "train/reward_rate": 0.0018500706658291458, "train_stats/mean_log_entropy": 0.09308482792883983, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0016721505671739578, "report/cont_loss_std": 0.00872472021728754, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0009282678365707397, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0016743363812565804, "report/cont_pred": 0.995441198348999, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07049404084682465, "report/image_loss_std": 0.08987996727228165, "report/model_loss_mean": 0.6726523637771606, "report/model_loss_std": 0.09098704159259796, "report/post_ent_mag": 39.936702728271484, "report/post_ent_max": 39.936702728271484, "report/post_ent_mean": 21.686792373657227, "report/post_ent_min": 15.866849899291992, "report/post_ent_std": 4.948879241943359, "report/prior_ent_mag": 39.68402099609375, "report/prior_ent_max": 39.68402099609375, "report/prior_ent_mean": 23.834394454956055, "report/prior_ent_min": 16.708770751953125, "report/prior_ent_std": 4.585748195648193, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0004861457273364067, "report/reward_loss_std": 0.0026199701242148876, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.018097281455993652, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0004861457273364067, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002476830268278718, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.06586502492427826, "eval/cont_loss_std": 0.8346767425537109, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.826574325561523, "eval/cont_pos_acc": 0.9970559477806091, "eval/cont_pos_loss": 0.008157913573086262, "eval/cont_pred": 0.995418131351471, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1138022169470787, "eval/image_loss_std": 0.11372023075819016, "eval/model_loss_mean": 0.7901102304458618, "eval/model_loss_std": 1.0059701204299927, "eval/post_ent_mag": 40.56206130981445, "eval/post_ent_max": 40.56206130981445, "eval/post_ent_mean": 21.736526489257812, "eval/post_ent_min": 15.695914268493652, "eval/post_ent_std": 5.268986701965332, "eval/prior_ent_mag": 39.85862350463867, "eval/prior_ent_max": 39.85862350463867, "eval/prior_ent_mean": 23.737205505371094, "eval/prior_ent_min": 15.966140747070312, "eval/prior_ent_std": 4.860553741455078, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006988525274209678, "eval/reward_loss_mean": 0.01044289767742157, "eval/reward_loss_std": 0.3069252371788025, "eval/reward_max_data": 0.715624988079071, "eval/reward_max_pred": 0.18515193462371826, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.0008561974973417819, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.817636489868164, "eval/reward_pred": 0.0004059273051097989, "eval/reward_rate": 0.0009765625, "replay/size": 760641.0, "replay/inserts": 31856.0, "replay/samples": 31856.0, "replay/insert_wait_avg": 1.4739950238490811e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.020956033680799e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4512.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3165334437755829e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9790091514587, "timer/env.step_count": 3982.0, "timer/env.step_total": 41.4740047454834, "timer/env.step_frac": 0.041474875338309895, "timer/env.step_avg": 0.010415370352959166, "timer/env.step_min": 0.008813142776489258, "timer/env.step_max": 0.05475211143493652, "timer/replay._sample_count": 31856.0, "timer/replay._sample_total": 17.063318252563477, "timer/replay._sample_frac": 0.017063676433611053, "timer/replay._sample_avg": 0.0005356390712130674, "timer/replay._sample_min": 0.00041413307189941406, "timer/replay._sample_max": 0.030866384506225586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4546.0, "timer/agent.policy_total": 51.5263466835022, "timer/agent.policy_frac": 0.05152742828794511, "timer/agent.policy_avg": 0.01133443613803392, "timer/agent.policy_min": 0.009444952011108398, "timer/agent.policy_max": 0.10124683380126953, "timer/dataset_train_count": 1991.0, "timer/dataset_train_total": 0.24443912506103516, "timer/dataset_train_frac": 0.00024444425615339284, "timer/dataset_train_avg": 0.00012277203669564798, "timer/dataset_train_min": 0.00010585784912109375, "timer/dataset_train_max": 0.0006203651428222656, "timer/agent.train_count": 1991.0, "timer/agent.train_total": 893.8978536128998, "timer/agent.train_frac": 0.8939166176812301, "timer/agent.train_avg": 0.44896928860517316, "timer/agent.train_min": 0.43485546112060547, "timer/agent.train_max": 0.7259249687194824, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4802398681640625, "timer/agent.report_frac": 0.0004802499490180043, "timer/agent.report_avg": 0.24011993408203125, "timer/agent.report_min": 0.23154020309448242, "timer/agent.report_max": 0.24869966506958008, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.552436828613281e-05, "timer/dataset_eval_frac": 3.552511398841995e-08, "timer/dataset_eval_avg": 3.552436828613281e-05, "timer/dataset_eval_min": 3.552436828613281e-05, "timer/dataset_eval_max": 3.552436828613281e-05, "fps": 31.85613494204271}
{"step": 761288, "time": 24285.29267191887, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 761416, "time": 24289.214218616486, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 761528, "time": 24292.62863969803, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 761576, "time": 24294.111725330353, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 761840, "time": 24302.421449661255, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 761912, "time": 24304.933114290237, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 761960, "time": 24306.41341471672, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 762040, "time": 24308.985570430756, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 762136, "time": 24311.942226171494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 762272, "time": 24316.340104341507, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 762392, "time": 24319.865278959274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 762736, "time": 24330.71980214119, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 762816, "time": 24333.16382741928, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 763120, "time": 24342.621367692947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 763192, "time": 24344.619294404984, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 763416, "time": 24351.510049819946, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 763568, "time": 24356.40383863449, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 763800, "time": 24363.332007408142, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 763984, "time": 24369.35790657997, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 764152, "time": 24374.319821596146, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 764272, "time": 24378.235537052155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764448, "time": 24383.656307935715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764704, "time": 24391.508408546448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764984, "time": 24399.983959913254, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 765112, "time": 24403.944550037384, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 765128, "time": 24404.44403553009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 765232, "time": 24407.869302034378, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 765432, "time": 24413.780913591385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 765576, "time": 24418.195813179016, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 765816, "time": 24425.563878059387, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 766096, "time": 24434.52316570282, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 766112, "time": 24435.018169879913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766296, "time": 24440.45881652832, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 766400, "time": 24443.88015294075, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 766584, "time": 24449.30180001259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766680, "time": 24452.280886411667, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 766760, "time": 24454.734320640564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766904, "time": 24459.31912446022, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 767080, "time": 24464.700718402863, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 767136, "time": 24466.637352705002, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 767144, "time": 24466.666962385178, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 767296, "time": 24471.549960136414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767320, "time": 24472.08633852005, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 767368, "time": 24473.552670001984, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 767696, "time": 24483.846900701523, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 767720, "time": 24484.36381006241, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 767744, "time": 24485.32270526886, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 767936, "time": 24491.348605632782, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 768080, "time": 24495.761039733887, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 768360, "time": 24504.13427257538, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 768504, "time": 24508.574732780457, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 768536, "time": 24509.555109977722, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 768640, "time": 24512.994572877884, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 768648, "time": 24513.025247335434, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 768896, "time": 24520.959815263748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 768904, "time": 24520.991932868958, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 768992, "time": 24523.94069314003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769016, "time": 24524.465276002884, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 769104, "time": 24527.41372680664, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 769640, "time": 24543.638977766037, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 769720, "time": 24546.11826467514, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 24556.808509111404, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 770016, "time": 24557.00762820244, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 770016, "time": 24557.346803426743, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 770016, "time": 24557.376193523407, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 770016, "time": 24557.46786928177, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 770016, "time": 24558.256354808807, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 770016, "time": 24558.63229727745, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 770016, "time": 24559.250745534897, "eval_episode/length": 172.0, "eval_episode/score": 0.4625000059604645, "eval_episode/reward_rate": 0.005780346820809248}
{"step": 770056, "time": 24560.534811735153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 770600, "time": 24577.500116825104, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 770640, "time": 24579.104544878006, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 770848, "time": 24585.512679815292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 770936, "time": 24587.982624530792, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 770952, "time": 24588.482374429703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771080, "time": 24592.43494796753, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 771216, "time": 24596.831657409668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771304, "time": 24599.307213783264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771416, "time": 24602.75911307335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771464, "time": 24604.247042417526, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 771656, "time": 24610.274389743805, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 772032, "time": 24622.06902217865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 772048, "time": 24622.56569957733, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 772120, "time": 24624.56335067749, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 772376, "time": 24632.384443044662, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 772392, "time": 24632.881577014923, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 772776, "time": 24644.821420907974, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 772792, "time": 24645.32010126114, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 772888, "time": 24648.279636621475, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 772920, "time": 24649.288845539093, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 773248, "time": 24659.549325227737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773264, "time": 24660.046994686127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773392, "time": 24663.994349479675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773624, "time": 24670.984486818314, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 773656, "time": 24671.966188430786, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 773720, "time": 24673.937402009964, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 774032, "time": 24683.73838043213, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 774184, "time": 24688.16335916519, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 774224, "time": 24689.633979082108, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 774288, "time": 24691.596865415573, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 774504, "time": 24698.000146389008, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 774688, "time": 24704.023621320724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 774768, "time": 24706.474193572998, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 774880, "time": 24709.913456439972, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 775064, "time": 24715.326102256775, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 775168, "time": 24718.737199783325, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 775232, "time": 24720.694725751877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 775256, "time": 24721.21654009819, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 775416, "time": 24726.15490579605, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 775448, "time": 24727.131162643433, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 775768, "time": 24737.07860469818, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 775864, "time": 24740.043835878372, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 776128, "time": 24748.36901807785, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 776144, "time": 24748.865376472473, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 776328, "time": 24754.2928211689, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 776480, "time": 24759.32561159134, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 776480, "time": 24759.33406996727, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 776496, "time": 24759.834921598434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 776712, "time": 24766.229377746582, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 776992, "time": 24775.059902906418, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 777184, "time": 24780.94814634323, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 777248, "time": 24782.920786857605, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 777288, "time": 24783.93258023262, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 777368, "time": 24786.3943836689, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 777480, "time": 24789.92296385765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 777624, "time": 24794.34436440468, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 777624, "time": 24794.353269338608, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 777784, "time": 24799.275060415268, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 778056, "time": 24807.671625852585, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 778064, "time": 24808.143159866333, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 778456, "time": 24820.579350709915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 778632, "time": 24825.998469114304, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 778648, "time": 24826.49024963379, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 778680, "time": 24827.500382184982, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 779288, "time": 24846.187422037125, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 779304, "time": 24846.686975955963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 779312, "time": 24847.18492460251, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 779336, "time": 24847.704857587814, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 779520, "time": 24853.701320409775, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 779680, "time": 24858.62472677231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 779792, "time": 24862.073327302933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 779856, "time": 24864.049426794052, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 779936, "time": 24866.49978041649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 24869.217957258224, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 780000, "time": 24869.439245224, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 780000, "time": 24869.914127349854, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 780000, "time": 24870.029149770737, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 780000, "time": 24870.187091827393, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 780000, "time": 24870.238479614258, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 780000, "time": 24871.01837992668, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 780000, "time": 24871.200326681137, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 780336, "time": 24881.637194395065, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 780448, "time": 24885.08153152466, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 780456, "time": 24885.111087560654, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 780928, "time": 24899.820107221603, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 780992, "time": 24901.788808822632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 781304, "time": 24911.268459796906, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 781600, "time": 24920.554847717285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 781648, "time": 24922.02713370323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 781728, "time": 24924.49049639702, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 781832, "time": 24927.452299833298, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 781848, "time": 24927.95151090622, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 781848, "time": 24927.95955467224, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 782240, "time": 24940.30211663246, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 782248, "time": 24940.331951379776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782336, "time": 24943.233115673065, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 782648, "time": 24952.558076381683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782768, "time": 24956.467590093613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782840, "time": 24958.476452827454, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 782936, "time": 24961.39767217636, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 783160, "time": 24968.370598077774, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 783240, "time": 24970.88498735428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 783352, "time": 24974.333155155182, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 783432, "time": 24976.780559539795, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 783552, "time": 24980.695023536682, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 783736, "time": 24986.104670524597, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 784144, "time": 24998.951024770737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 784384, "time": 25006.308028936386, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 784616, "time": 25013.204456806183, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 784640, "time": 25014.16505432129, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 784960, "time": 25024.010682106018, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 785080, "time": 25027.468178272247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 785136, "time": 25029.532032966614, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 785248, "time": 25032.978611707687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 785496, "time": 25040.356588363647, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 785672, "time": 25045.760461330414, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 785696, "time": 25046.725782871246, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 785744, "time": 25048.22338438034, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 785864, "time": 25051.680509090424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 786048, "time": 25057.57190132141, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 786048, "time": 25057.62074279785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 786088, "time": 25058.776134490967, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 786376, "time": 25067.620705366135, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 786400, "time": 25068.57869076729, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 786472, "time": 25071.07923722267, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 786608, "time": 25075.480785131454, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 786720, "time": 25078.94628214836, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 786992, "time": 25087.385195970535, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 787272, "time": 25095.883783340454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 787424, "time": 25100.804234981537, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 787448, "time": 25101.324711084366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 787912, "time": 25115.589148044586, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 788368, "time": 25129.954374313354, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 788440, "time": 25131.96606516838, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 788688, "time": 25139.81317257881, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 788712, "time": 25140.334377527237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 788784, "time": 25142.791464567184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 788912, "time": 25146.732881069183, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 789032, "time": 25150.295370817184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 789240, "time": 25156.715280532837, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 789304, "time": 25158.691061258316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 789568, "time": 25167.04793357849, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 789576, "time": 25167.0782456398, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 789752, "time": 25172.482213258743, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 789760, "time": 25172.95844912529, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 789896, "time": 25176.927049160004, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 789920, "time": 25177.888687610626, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 790080, "time": 25182.930206775665, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 25183.5833234787, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 790088, "time": 25184.211953401566, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 790088, "time": 25184.557265520096, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 790088, "time": 25184.66912817955, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 790088, "time": 25186.02791619301, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 790088, "time": 25187.06899857521, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 790088, "time": 25187.139340162277, "eval_episode/length": 193.0, "eval_episode/score": 0.3968749940395355, "eval_episode/reward_rate": 0.005154639175257732}
{"step": 790088, "time": 25187.18986058235, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 790344, "time": 25195.017805337906, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 790384, "time": 25196.494797229767, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 790560, "time": 25201.925510644913, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 790560, "time": 25201.934616088867, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 790632, "time": 25203.94167160988, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 790768, "time": 25208.383353710175, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 790792, "time": 25208.979189395905, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 791144, "time": 25219.79752421379, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 791392, "time": 25227.628950357437, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 791808, "time": 25240.527092695236, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 791880, "time": 25242.511599302292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 791888, "time": 25242.98513865471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 792400, "time": 25260.74791240692, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 792504, "time": 25263.737882852554, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 792632, "time": 25267.686919927597, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 792656, "time": 25268.787816524506, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 792696, "time": 25269.799218177795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 793049, "time": 25281.578977823257, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6442552116048996, "train/action_min": 0.0, "train/action_std": 1.8807729931931998, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010555156241007262, "train/actor_opt_grad_steps": 48470.0, "train/actor_opt_loss": -9.813123077079279, "train/adv_mag": 0.8608840230721325, "train/adv_max": 0.3114401599270615, "train/adv_mean": 0.00268474613942967, "train/adv_min": -0.831843957829116, "train/adv_std": 0.028871091429013104, "train/cont_avg": 0.9949994111180904, "train/cont_loss_mean": 0.01631983627925566, "train/cont_loss_std": 0.23148517671682353, "train/cont_neg_acc": 0.3737260845273432, "train/cont_neg_loss": 2.572188356656092, "train/cont_pos_acc": 0.9998025846241707, "train/cont_pos_loss": 0.003244926692595022, "train/cont_pred": 0.995096217148268, "train/cont_rate": 0.9949994111180904, "train/dyn_loss_mean": 1.0000001341853308, "train/dyn_loss_std": 4.285808427998768e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16806800506222788, "train/extr_critic_critic_opt_grad_steps": 48470.0, "train/extr_critic_critic_opt_loss": 11939.95109826476, "train/extr_critic_mag": 1.180111947371133, "train/extr_critic_max": 1.180111947371133, "train/extr_critic_mean": 1.085203336710906, "train/extr_critic_min": 0.9033849071617701, "train/extr_critic_std": 0.02101264163926618, "train/extr_return_normed_mag": 0.8775913439803387, "train/extr_return_normed_max": 0.34397396490202475, "train/extr_return_normed_mean": 0.04234366922934151, "train/extr_return_normed_min": -0.8319744096329463, "train/extr_return_normed_std": 0.03665949976137235, "train/extr_return_rate": 0.9992089774740401, "train/extr_return_raw_mag": 1.3895183496139756, "train/extr_return_raw_max": 1.3895183496139756, "train/extr_return_raw_mean": 1.0878881096240862, "train/extr_return_raw_min": 0.2135699750790045, "train/extr_return_raw_std": 0.03665949981753251, "train/extr_reward_mag": 0.3724403003951413, "train/extr_reward_max": 0.3724403003951413, "train/extr_reward_mean": 0.0018919109686830048, "train/extr_reward_min": 2.881390365523909e-07, "train/extr_reward_std": 0.009356234904762414, "train/image_loss_mean": 0.079675981709406, "train/image_loss_std": 0.09444410943580632, "train/model_loss_mean": 0.7063978703776795, "train/model_loss_std": 0.4052281039743567, "train/model_opt_grad_norm": 19.494703422239677, "train/model_opt_grad_steps": 48423.86934673367, "train/model_opt_loss": 2970.773629500039, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4233.668341708542, "train/policy_entropy_mag": 1.334402518056745, "train/policy_entropy_max": 1.334402518056745, "train/policy_entropy_mean": 0.11268238412525186, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.14785788226966282, "train/policy_logprob_mag": 6.5510802556521925, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11286950219965461, "train/policy_logprob_min": -6.5510802556521925, "train/policy_logprob_std": 0.6498696019302062, "train/policy_randomness_mag": 0.6857472810912971, "train/policy_randomness_max": 0.6857472810912971, "train/policy_randomness_mean": 0.05790729285334822, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07598392508137765, "train/post_ent_mag": 43.06430180228535, "train/post_ent_max": 43.06430180228535, "train/post_ent_mean": 22.358650542982858, "train/post_ent_min": 15.361311222440634, "train/post_ent_std": 5.742092139756859, "train/prior_ent_mag": 42.06420444124308, "train/prior_ent_max": 42.06420444124308, "train/prior_ent_mean": 23.722938729290988, "train/prior_ent_min": 15.831897841027034, "train/prior_ent_std": 5.304599495988396, "train/rep_loss_mean": 1.0000001341853308, "train/rep_loss_std": 4.285808427998768e-06, "train/reward_avg": 0.0014356450161934085, "train/reward_loss_mean": 0.010401951619447326, "train/reward_loss_std": 0.18098619980643968, "train/reward_max_data": 0.6684359297830256, "train/reward_max_pred": 0.24367091404133706, "train/reward_neg_acc": 0.9998080916141145, "train/reward_neg_loss": 0.001616342468234013, "train/reward_pos_acc": 0.2534839940273156, "train/reward_pos_loss": 4.058023399215633, "train/reward_pred": 0.0010765872055655298, "train/reward_rate": 0.002169048366834171, "train_stats/mean_log_entropy": 0.0911005445879344, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.02326897531747818, "report/cont_loss_std": 0.2634149193763733, "report/cont_neg_acc": 0.1666666716337204, "report/cont_neg_loss": 3.2398681640625, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0043106297962367535, "report/cont_pred": 0.9951268434524536, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0810554176568985, "report/image_loss_std": 0.0905228927731514, "report/model_loss_mean": 0.7200924158096313, "report/model_loss_std": 0.5064049959182739, "report/post_ent_mag": 42.45500564575195, "report/post_ent_max": 42.45500564575195, "report/post_ent_mean": 22.285396575927734, "report/post_ent_min": 14.859960556030273, "report/post_ent_std": 5.705900192260742, "report/prior_ent_mag": 45.61981201171875, "report/prior_ent_max": 45.61981201171875, "report/prior_ent_mean": 23.26525115966797, "report/prior_ent_min": 14.654535293579102, "report/prior_ent_std": 6.258020877838135, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0021728514693677425, "report/reward_loss_mean": 0.01576799899339676, "report/reward_loss_std": 0.24788615107536316, "report/reward_max_data": 0.8656250238418579, "report/reward_max_pred": 0.048510193824768066, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002352919662371278, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.581367492675781, "report/reward_pred": 0.00125010940246284, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.060697317123413086, "eval/cont_loss_std": 0.6921025514602661, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.447813987731934, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0025310409255325794, "eval/cont_pred": 0.9975770115852356, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11489664018154144, "eval/image_loss_std": 0.12871088087558746, "eval/model_loss_mean": 0.7923347353935242, "eval/model_loss_std": 0.871706485748291, "eval/post_ent_mag": 42.77082061767578, "eval/post_ent_max": 42.77082061767578, "eval/post_ent_mean": 21.113332748413086, "eval/post_ent_min": 15.34742546081543, "eval/post_ent_std": 5.747389793395996, "eval/prior_ent_mag": 43.32389450073242, "eval/prior_ent_max": 43.32389450073242, "eval/prior_ent_mean": 22.217411041259766, "eval/prior_ent_min": 15.268925666809082, "eval/prior_ent_std": 6.179956436157227, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0024078369606286287, "eval/reward_loss_mean": 0.01674075983464718, "eval/reward_loss_std": 0.2928212881088257, "eval/reward_max_data": 0.8656250238418579, "eval/reward_max_pred": 0.06692934036254883, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.000914643460419029, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.402896404266357, "eval/reward_pred": 0.00048644456546753645, "eval/reward_rate": 0.0029296875, "replay/size": 792545.0, "replay/inserts": 31904.0, "replay/samples": 31904.0, "replay/insert_wait_avg": 1.4677270125960157e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.965843919048099e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3944.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.256352264063837e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4271976947784, "timer/env.step_count": 3988.0, "timer/env.step_total": 41.21228289604187, "timer/env.step_frac": 0.04119468462173434, "timer/env.step_avg": 0.010334072942838984, "timer/env.step_min": 0.008649587631225586, "timer/env.step_max": 0.054888248443603516, "timer/replay._sample_count": 31904.0, "timer/replay._sample_total": 16.992162704467773, "timer/replay._sample_frac": 0.016984906791440442, "timer/replay._sample_avg": 0.0005326028931942005, "timer/replay._sample_min": 0.00039887428283691406, "timer/replay._sample_max": 0.025874853134155273, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4481.0, "timer/agent.policy_total": 49.97711968421936, "timer/agent.policy_frac": 0.04995577869072182, "timer/agent.policy_avg": 0.011153117537205838, "timer/agent.policy_min": 0.009406566619873047, "timer/agent.policy_max": 0.09518814086914062, "timer/dataset_train_count": 1994.0, "timer/dataset_train_total": 0.24518203735351562, "timer/dataset_train_frac": 0.00024507734087844994, "timer/dataset_train_avg": 0.00012295989837187343, "timer/dataset_train_min": 0.00010752677917480469, "timer/dataset_train_max": 0.0010178089141845703, "timer/agent.train_count": 1994.0, "timer/agent.train_total": 897.2387177944183, "timer/agent.train_frac": 0.8968555831567446, "timer/agent.train_avg": 0.4499692666973011, "timer/agent.train_min": 0.43866658210754395, "timer/agent.train_max": 2.498121976852417, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4791848659515381, "timer/agent.report_frac": 0.0004789802466943059, "timer/agent.report_avg": 0.23959243297576904, "timer/agent.report_min": 0.2342066764831543, "timer/agent.report_max": 0.2449781894683838, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.5789947509765625e-05, "timer/dataset_eval_frac": 5.576612434999658e-08, "timer/dataset_eval_avg": 5.5789947509765625e-05, "timer/dataset_eval_min": 5.5789947509765625e-05, "timer/dataset_eval_max": 5.5789947509765625e-05, "fps": 31.88983827333808}
{"step": 793080, "time": 25282.31389117241, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 793144, "time": 25284.369454860687, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 793448, "time": 25293.67488694191, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 793456, "time": 25294.1559548378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 793464, "time": 25294.18653535843, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 793480, "time": 25294.684359312057, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 793488, "time": 25295.15978217125, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 793928, "time": 25308.620582580566, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 794000, "time": 25311.06295800209, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 794032, "time": 25312.079083442688, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 794200, "time": 25317.024075746536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 794400, "time": 25323.418081998825, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 794432, "time": 25324.407335996628, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 794648, "time": 25331.45929121971, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 794656, "time": 25331.93295764923, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 794736, "time": 25334.41339492798, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 794864, "time": 25338.37114906311, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 795016, "time": 25342.845896959305, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 795176, "time": 25347.769852876663, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 795328, "time": 25352.696598768234, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 795400, "time": 25354.68652176857, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 795624, "time": 25361.722430229187, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 795648, "time": 25362.709129333496, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 795808, "time": 25367.651046037674, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 795832, "time": 25368.1686835289, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 796296, "time": 25382.479555130005, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 796312, "time": 25382.979907989502, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 796344, "time": 25383.9685382843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 796504, "time": 25389.045922756195, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 796808, "time": 25398.46818470955, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 796960, "time": 25403.39424610138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 796968, "time": 25403.425819396973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 797240, "time": 25411.80718755722, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 797368, "time": 25415.76960992813, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 797696, "time": 25426.217557668686, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 797712, "time": 25426.735154628754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 797896, "time": 25432.185364961624, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 798048, "time": 25437.09163594246, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 798144, "time": 25440.058883666992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 798328, "time": 25445.495818138123, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 798344, "time": 25445.993468999863, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 798384, "time": 25447.476127386093, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 798488, "time": 25450.55492591858, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 798504, "time": 25451.05700135231, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 798680, "time": 25456.506799697876, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 798688, "time": 25456.975291728973, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 798872, "time": 25462.421354293823, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 799080, "time": 25468.830955266953, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 799088, "time": 25469.304547071457, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 799104, "time": 25469.80441260338, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 799120, "time": 25470.30770969391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 799304, "time": 25475.76764845848, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 799448, "time": 25480.32666707039, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 799952, "time": 25496.07699728012, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 25501.503309249878, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 800072, "time": 25501.754256010056, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 800072, "time": 25502.739203453064, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 800072, "time": 25502.794120311737, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 800072, "time": 25503.230714797974, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 800072, "time": 25503.519439697266, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 800072, "time": 25504.411492347717, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 800072, "time": 25504.67592406273, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 800792, "time": 25527.04874253273, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 800800, "time": 25527.531034231186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801184, "time": 25539.51695728302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801392, "time": 25545.958141565323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801416, "time": 25546.477688789368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801432, "time": 25546.979512691498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801504, "time": 25549.403418064117, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 801616, "time": 25552.857887744904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801760, "time": 25557.319286346436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801896, "time": 25561.279698848724, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 801992, "time": 25564.251267910004, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 802144, "time": 25569.259059906006, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 802376, "time": 25576.155218601227, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 802392, "time": 25576.65016078949, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 802496, "time": 25580.057807445526, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 802520, "time": 25580.593650341034, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 802632, "time": 25584.008942842484, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 803024, "time": 25596.839385032654, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 803112, "time": 25599.453936100006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 803144, "time": 25600.44696497917, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 803568, "time": 25613.733713150024, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 803600, "time": 25614.723957061768, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 803744, "time": 25619.168563842773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 803840, "time": 25622.13165450096, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 803920, "time": 25624.614701509476, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 804000, "time": 25627.089373350143, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 804184, "time": 25632.661996126175, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 804808, "time": 25651.88110280037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 804944, "time": 25656.302273750305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 804960, "time": 25656.79846405983, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 805080, "time": 25660.39004921913, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 805400, "time": 25670.24057149887, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 805432, "time": 25671.234660863876, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 805704, "time": 25679.594935655594, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 805880, "time": 25685.049527406693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 805912, "time": 25686.043299913406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 805992, "time": 25688.666910648346, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 806056, "time": 25690.644963741302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 806152, "time": 25693.597272396088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 806496, "time": 25704.466377973557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 806504, "time": 25704.497465610504, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 806504, "time": 25704.506067276, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 806920, "time": 25717.36297440529, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 806952, "time": 25718.416194438934, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 807136, "time": 25724.39535188675, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 807616, "time": 25739.17177081108, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 807680, "time": 25741.158957242966, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 807744, "time": 25743.133511781693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808152, "time": 25755.595720529556, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 808192, "time": 25757.049958229065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808224, "time": 25758.043582439423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808336, "time": 25761.480621814728, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 808464, "time": 25765.420011997223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808608, "time": 25769.858938217163, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 808672, "time": 25771.82788658142, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 808752, "time": 25774.308471679688, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 808816, "time": 25776.285123586655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808864, "time": 25777.776605129242, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 808896, "time": 25778.875028848648, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 809168, "time": 25787.23045372963, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 809232, "time": 25789.224957942963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 809264, "time": 25790.212502002716, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 809400, "time": 25794.184205055237, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 809552, "time": 25799.104180812836, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 809704, "time": 25803.561372756958, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 809784, "time": 25806.036669015884, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 810032, "time": 25814.086837530136, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 25815.332518577576, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 810056, "time": 25815.942541599274, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 810056, "time": 25816.23745918274, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 810056, "time": 25817.355966329575, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 810056, "time": 25817.623606681824, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 810056, "time": 25818.85311460495, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 810056, "time": 25819.420703172684, "eval_episode/length": 186.0, "eval_episode/score": 0.41874998807907104, "eval_episode/reward_rate": 0.0053475935828877}
{"step": 810056, "time": 25820.598478078842, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 810128, "time": 25823.05216193199, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 810264, "time": 25827.007476091385, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 810288, "time": 25827.982586860657, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 810432, "time": 25832.422179460526, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 810464, "time": 25833.411399126053, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 810872, "time": 25845.905536174774, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 810920, "time": 25847.382756710052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 811088, "time": 25853.37253499031, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 811112, "time": 25853.894833803177, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 811304, "time": 25859.832058906555, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 811360, "time": 25861.79828119278, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 811536, "time": 25867.226946115494, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 811712, "time": 25872.772742271423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 811720, "time": 25872.802862405777, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 812040, "time": 25882.676595687866, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 812400, "time": 25893.9996509552, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 812576, "time": 25899.578916549683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 812600, "time": 25900.122309207916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 812984, "time": 25911.907987117767, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 813184, "time": 25918.280344963074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813424, "time": 25925.689400434494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813672, "time": 25933.205196380615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813680, "time": 25933.68214416504, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 813848, "time": 25938.64434170723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 814296, "time": 25952.49983549118, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 814352, "time": 25954.462849378586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 814472, "time": 25957.914254665375, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 814648, "time": 25963.4347178936, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 814656, "time": 25963.91087770462, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 814800, "time": 25968.348066806793, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 814888, "time": 25970.847472190857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 814912, "time": 25971.81803750992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 815096, "time": 25977.261412858963, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 815152, "time": 25979.230724811554, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 815352, "time": 25985.177587985992, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 815632, "time": 25994.128605127335, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 815760, "time": 25998.08898806572, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 815816, "time": 25999.62578010559, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 815936, "time": 26003.533135175705, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 815984, "time": 26005.03173685074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 816288, "time": 26014.408262491226, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 816472, "time": 26019.959889411926, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 816480, "time": 26020.436265468597, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 816544, "time": 26022.402844190598, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 816584, "time": 26023.41231226921, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 817096, "time": 26039.191522359848, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 817312, "time": 26046.08225464821, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 817464, "time": 26050.683714151382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817560, "time": 26053.664946317673, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 817592, "time": 26054.65141439438, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 817816, "time": 26061.57031726837, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 817944, "time": 26065.509566783905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 818328, "time": 26077.31049847603, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 818600, "time": 26085.79744410515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 818784, "time": 26091.67393398285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 818856, "time": 26093.688314437866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 819424, "time": 26112.069072961807, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 819448, "time": 26112.590471744537, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 819512, "time": 26114.579469680786, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 819776, "time": 26122.93554210663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 819840, "time": 26124.929427862167, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 819872, "time": 26125.914981603622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 26132.337863445282, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 820040, "time": 26132.36686682701, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 820040, "time": 26133.03893494606, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 820040, "time": 26133.242725372314, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 820040, "time": 26133.296604156494, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 820040, "time": 26133.842236995697, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 820040, "time": 26133.91642522812, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 820040, "time": 26134.9272916317, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 820128, "time": 26137.88609600067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 820136, "time": 26137.91655421257, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 820256, "time": 26141.94597887993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 820560, "time": 26151.31316280365, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 820616, "time": 26152.832441568375, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 820648, "time": 26153.81806755066, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 820896, "time": 26161.659972190857, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 821056, "time": 26166.596034049988, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 821088, "time": 26167.610047340393, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 821096, "time": 26167.639023065567, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 821496, "time": 26180.11826109886, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 821664, "time": 26185.56065773964, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 821760, "time": 26188.539306879044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 821856, "time": 26191.502205133438, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 822152, "time": 26200.53111767769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 822168, "time": 26201.026612997055, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 822368, "time": 26207.43566942215, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 822496, "time": 26211.355916261673, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 822720, "time": 26218.25571990013, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 822808, "time": 26220.742326021194, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 822872, "time": 26222.73186659813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823144, "time": 26231.22069978714, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 823264, "time": 26235.15483880043, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 823408, "time": 26239.606528282166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823416, "time": 26239.638833522797, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 823920, "time": 26255.374868154526, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 824072, "time": 26260.03203034401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824320, "time": 26267.889565467834, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 824464, "time": 26272.31751394272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824472, "time": 26272.34756541252, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 824745, "time": 26281.74647641182, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.702799888112437, "train/action_min": 0.0, "train/action_std": 1.9127892639169741, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009659164507367915, "train/actor_opt_grad_steps": 50460.0, "train/actor_opt_loss": -10.917332359294795, "train/adv_mag": 0.8220423507930046, "train/adv_max": 0.34029756898257, "train/adv_mean": 0.0023531867567424653, "train/adv_min": -0.7696415221870844, "train/adv_std": 0.028586653728112952, "train/cont_avg": 0.9952398712311558, "train/cont_loss_mean": 0.016121974816293124, "train/cont_loss_std": 0.23103509727753138, "train/cont_neg_acc": 0.33881167000412343, "train/cont_neg_loss": 2.6775032911735153, "train/cont_pos_acc": 0.9998570180418503, "train/cont_pos_loss": 0.0033133440369028768, "train/cont_pred": 0.9952256418951791, "train/cont_rate": 0.9952398712311558, "train/dyn_loss_mean": 1.0000058843861872, "train/dyn_loss_std": 0.0001645844035440279, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13858157608789115, "train/extr_critic_critic_opt_grad_steps": 50460.0, "train/extr_critic_critic_opt_loss": 7957.03584082522, "train/extr_critic_mag": 1.2440090047654195, "train/extr_critic_max": 1.2440090047654195, "train/extr_critic_mean": 1.148472563106211, "train/extr_critic_min": 0.9389899957120119, "train/extr_critic_std": 0.02092647446721942, "train/extr_return_normed_mag": 0.8413206518594943, "train/extr_return_normed_max": 0.35737189036517886, "train/extr_return_normed_mean": 0.04150197836547042, "train/extr_return_normed_min": -0.7632118882845395, "train/extr_return_normed_std": 0.036532292048910155, "train/extr_return_rate": 0.9992577175998208, "train/extr_return_raw_mag": 1.4666955668722566, "train/extr_return_raw_max": 1.4666955668722566, "train/extr_return_raw_mean": 1.1508257143461524, "train/extr_return_raw_min": 0.3461117882225382, "train/extr_return_raw_std": 0.03653229205827018, "train/extr_reward_mag": 0.36738635008059556, "train/extr_reward_max": 0.36738635008059556, "train/extr_reward_mean": 0.0019408746323566978, "train/extr_reward_min": 1.8091058012229113e-07, "train/extr_reward_std": 0.009132360172546913, "train/image_loss_mean": 0.07724499090307921, "train/image_loss_std": 0.09292970326303238, "train/model_loss_mean": 0.704139579181096, "train/model_loss_std": 0.409212259716125, "train/model_opt_grad_norm": 19.065990313812716, "train/model_opt_grad_steps": 50412.25125628141, "train/model_opt_loss": 3520.697891312029, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5025.125628140703, "train/policy_entropy_mag": 1.3190645770211915, "train/policy_entropy_max": 1.3190645770211915, "train/policy_entropy_mean": 0.0991408887071226, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12688114932134523, "train/policy_logprob_mag": 6.55108025085986, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09934842204628279, "train/policy_logprob_min": -6.55108025085986, "train/policy_logprob_std": 0.6375308824543977, "train/policy_randomness_mag": 0.6778651374069291, "train/policy_randomness_max": 0.6778651374069291, "train/policy_randomness_mean": 0.050948340651677484, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06520401626525812, "train/post_ent_mag": 46.3981200941843, "train/post_ent_max": 46.3981200941843, "train/post_ent_mean": 22.93597901885833, "train/post_ent_min": 15.098984732699753, "train/post_ent_std": 6.55860669648827, "train/prior_ent_mag": 45.89091737066681, "train/prior_ent_max": 45.89091737066681, "train/prior_ent_mean": 23.639032162613606, "train/prior_ent_min": 15.088859462258803, "train/prior_ent_std": 6.4403383887592875, "train/rep_loss_mean": 1.0000058843861872, "train/rep_loss_std": 0.0001645844035440279, "train/reward_avg": 0.0015082891214254017, "train/reward_loss_mean": 0.010769060144818684, "train/reward_loss_std": 0.18461462350833654, "train/reward_max_data": 0.6835113057688852, "train/reward_max_pred": 0.26452153951079405, "train/reward_neg_acc": 0.9996901558871245, "train/reward_neg_loss": 0.001870261259837984, "train/reward_pos_acc": 0.23571428756474117, "train/reward_pos_loss": 4.030366323846678, "train/reward_pred": 0.0011897407174952814, "train/reward_rate": 0.002203399811557789, "train_stats/mean_log_entropy": 0.08586518148161436, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.009451027028262615, "report/cont_loss_std": 0.11190063506364822, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.4041951894760132, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005352856125682592, "report/cont_pred": 0.9934190511703491, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06419728696346283, "report/image_loss_std": 0.08476744592189789, "report/model_loss_mean": 0.6849337816238403, "report/model_loss_std": 0.2969268560409546, "report/post_ent_mag": 44.19624328613281, "report/post_ent_max": 44.19624328613281, "report/post_ent_mean": 21.83443832397461, "report/post_ent_min": 13.420995712280273, "report/post_ent_std": 6.1527276039123535, "report/prior_ent_mag": 44.73188018798828, "report/prior_ent_max": 44.73188018798828, "report/prior_ent_mean": 23.67702293395996, "report/prior_ent_min": 14.161808013916016, "report/prior_ent_std": 6.542720794677734, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0017333984142169356, "report/reward_loss_mean": 0.011285427957773209, "report/reward_loss_std": 0.16750213503837585, "report/reward_max_data": 0.809374988079071, "report/reward_max_pred": 0.5317984819412231, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0030424499418586493, "report/reward_pos_acc": 0.6666666865348816, "report/reward_pos_loss": 2.816645622253418, "report/reward_pred": 0.0023552672937512398, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.036925822496414185, "eval/cont_loss_std": 0.5232481956481934, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.914004802703857, "eval/cont_pos_acc": 0.9980391263961792, "eval/cont_pos_loss": 0.006035319995135069, "eval/cont_pred": 0.9958018660545349, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1087808683514595, "eval/image_loss_std": 0.11473926901817322, "eval/model_loss_mean": 0.7549097537994385, "eval/model_loss_std": 0.656972348690033, "eval/post_ent_mag": 46.94922637939453, "eval/post_ent_max": 46.94922637939453, "eval/post_ent_mean": 20.253032684326172, "eval/post_ent_min": 13.580057144165039, "eval/post_ent_std": 6.371894359588623, "eval/prior_ent_mag": 49.319305419921875, "eval/prior_ent_max": 49.319305419921875, "eval/prior_ent_mean": 21.914257049560547, "eval/prior_ent_min": 13.95355224609375, "eval/prior_ent_std": 6.932628154754639, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007812500116415322, "eval/reward_loss_mean": 0.009202992543578148, "eval/reward_loss_std": 0.23089922964572906, "eval/reward_max_data": 0.800000011920929, "eval/reward_max_pred": 0.44514524936676025, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.002099888166412711, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.275679588317871, "eval/reward_pred": 0.0008521040435880423, "eval/reward_rate": 0.0009765625, "replay/size": 824241.0, "replay/inserts": 31696.0, "replay/samples": 31696.0, "replay/insert_wait_avg": 1.4705813815652692e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.110714825279239e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5288.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3276235779547295e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 2.1457672119140625e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1487209796906, "timer/env.step_count": 3962.0, "timer/env.step_total": 41.045074462890625, "timer/env.step_frac": 0.04103897110690211, "timer/env.step_avg": 0.010359685629200057, "timer/env.step_min": 0.008757591247558594, "timer/env.step_max": 0.045224666595458984, "timer/replay._sample_count": 31696.0, "timer/replay._sample_total": 17.117011070251465, "timer/replay._sample_frac": 0.017114465790132274, "timer/replay._sample_avg": 0.0005400369469413007, "timer/replay._sample_min": 0.0004279613494873047, "timer/replay._sample_max": 0.02790045738220215, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4623.0, "timer/agent.policy_total": 52.674004793167114, "timer/agent.policy_frac": 0.05266617222843675, "timer/agent.policy_avg": 0.011393901101701734, "timer/agent.policy_min": 0.008335113525390625, "timer/agent.policy_max": 0.09636926651000977, "timer/dataset_train_count": 1981.0, "timer/dataset_train_total": 0.24610352516174316, "timer/dataset_train_frac": 0.0002460669298468669, "timer/dataset_train_avg": 0.00012423196626034486, "timer/dataset_train_min": 0.00010609626770019531, "timer/dataset_train_max": 0.0005435943603515625, "timer/agent.train_count": 1981.0, "timer/agent.train_total": 892.317370891571, "timer/agent.train_frac": 0.8921846843112554, "timer/agent.train_avg": 0.4504378449730293, "timer/agent.train_min": 0.4396986961364746, "timer/agent.train_max": 0.7356564998626709, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48302197456359863, "timer/agent.report_frac": 0.000482950149744187, "timer/agent.report_avg": 0.24151098728179932, "timer/agent.report_min": 0.23172712326049805, "timer/agent.report_max": 0.2512948513031006, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 3.504231959982817e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 31.690689610191928}
{"step": 824800, "time": 26283.450260162354, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 824808, "time": 26283.481873512268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 825056, "time": 26291.46205306053, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 825208, "time": 26295.949248313904, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 825288, "time": 26298.424281597137, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 825392, "time": 26301.862103700638, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 825456, "time": 26303.83319067955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 825576, "time": 26307.30632829666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 825720, "time": 26311.75449848175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 825952, "time": 26319.266882419586, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 826048, "time": 26322.21668624878, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 826184, "time": 26326.158526420593, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 826200, "time": 26326.668958425522, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 826384, "time": 26332.522206306458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 826456, "time": 26334.50394821167, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 826608, "time": 26339.412832975388, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 826800, "time": 26345.324050426483, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 826816, "time": 26345.816360473633, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 827104, "time": 26354.82043004036, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 827128, "time": 26355.340174674988, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 827504, "time": 26367.70305132866, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 827520, "time": 26368.207530260086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 827536, "time": 26368.71087193489, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 828032, "time": 26384.12024617195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 828256, "time": 26391.03422689438, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 828264, "time": 26391.065885782242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 828496, "time": 26398.41911125183, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 828680, "time": 26403.874358654022, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 828808, "time": 26407.819077968597, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 829048, "time": 26415.304854631424, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 829080, "time": 26416.317507505417, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 829128, "time": 26417.82011437416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829408, "time": 26426.68918466568, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 829416, "time": 26426.720313310623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829504, "time": 26429.654433727264, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 829512, "time": 26429.6840364933, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 829632, "time": 26433.608666419983, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 829736, "time": 26436.62112760544, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 829984, "time": 26444.596749067307, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 26446.806176185608, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 830024, "time": 26446.906540870667, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 830024, "time": 26448.16095304489, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 830024, "time": 26448.450516223907, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 830024, "time": 26448.480130672455, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 830024, "time": 26448.50983428955, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 830024, "time": 26449.48574781418, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 830024, "time": 26449.558018684387, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 830168, "time": 26453.99507021904, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 830472, "time": 26463.369807958603, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 830648, "time": 26468.89702320099, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 830776, "time": 26472.837085962296, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 830840, "time": 26474.834433555603, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 830992, "time": 26479.751143932343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 831256, "time": 26487.671996593475, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 831392, "time": 26492.08894586563, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 831424, "time": 26493.072465896606, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 831600, "time": 26498.63327383995, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 831696, "time": 26501.575431108475, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 831824, "time": 26505.534957408905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 831944, "time": 26508.98235297203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 831992, "time": 26510.4763777256, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 832112, "time": 26514.412735939026, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 832176, "time": 26516.374650239944, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 832200, "time": 26516.895013809204, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 832232, "time": 26517.877171993256, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 832296, "time": 26519.881892442703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832656, "time": 26531.256866693497, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 832792, "time": 26535.21263885498, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 832920, "time": 26539.17572402954, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 833040, "time": 26543.069134950638, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 833344, "time": 26552.432874679565, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 833408, "time": 26554.415779829025, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 833936, "time": 26570.74610900879, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 833992, "time": 26572.227853298187, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 834136, "time": 26576.645199537277, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 834136, "time": 26576.655091762543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 834256, "time": 26580.5802526474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 834488, "time": 26587.480157136917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 834600, "time": 26591.024923324585, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 834608, "time": 26591.497020483017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 834776, "time": 26596.43721461296, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 835112, "time": 26606.875679254532, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 835232, "time": 26610.80411720276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 835432, "time": 26616.7506210804, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 835688, "time": 26625.27493095398, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 835704, "time": 26625.765830755234, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 836024, "time": 26635.641673326492, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 836304, "time": 26644.532707452774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 836432, "time": 26648.629470348358, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 836448, "time": 26649.125748872757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 836688, "time": 26656.466153383255, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 836736, "time": 26657.949715852737, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 836800, "time": 26659.93764925003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 836936, "time": 26663.885251760483, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 837112, "time": 26669.28664970398, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 837424, "time": 26679.254159212112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 837608, "time": 26684.70748949051, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 837672, "time": 26686.66863012314, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 837904, "time": 26694.02980542183, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 837936, "time": 26695.0156185627, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 838128, "time": 26700.87044286728, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 838152, "time": 26701.39279103279, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 838480, "time": 26711.766282320023, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 838688, "time": 26718.18608689308, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 838712, "time": 26718.70624065399, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 838744, "time": 26719.69045972824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838944, "time": 26726.062045812607, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 839000, "time": 26727.584742069244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 839112, "time": 26731.039375543594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 839200, "time": 26733.97913837433, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 839264, "time": 26735.946729898453, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 839336, "time": 26737.968005895615, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 839624, "time": 26746.92627763748, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 839656, "time": 26747.930688858032, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 839680, "time": 26748.8934738636, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 839864, "time": 26754.348930358887, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 839920, "time": 26756.294221639633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 839928, "time": 26756.324100971222, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 26760.466588258743, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 840008, "time": 26760.5157828331, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 840008, "time": 26760.585956811905, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 840008, "time": 26761.01631617546, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 840008, "time": 26761.106902360916, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 840008, "time": 26761.508571624756, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 840008, "time": 26761.535920381546, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 840008, "time": 26763.58902812004, "eval_episode/length": 222.0, "eval_episode/score": 0.3062500059604645, "eval_episode/reward_rate": 0.004484304932735426}
{"step": 840344, "time": 26774.075866937637, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 840528, "time": 26780.020031690598, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 841256, "time": 26802.302919626236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 841296, "time": 26803.75768661499, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 841512, "time": 26810.132092237473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 841936, "time": 26823.321141719818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842144, "time": 26829.810325860977, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 842176, "time": 26830.791410446167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842232, "time": 26832.309113502502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842240, "time": 26832.782042980194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842360, "time": 26836.230346679688, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 842528, "time": 26841.60262107849, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 842704, "time": 26846.999929189682, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 842808, "time": 26849.965205669403, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 842840, "time": 26850.98028230667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843048, "time": 26857.37628388405, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 843424, "time": 26869.240136384964, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 843568, "time": 26873.650479078293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843592, "time": 26874.16956925392, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 843640, "time": 26875.66934132576, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 843648, "time": 26876.14337015152, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 843760, "time": 26879.568856477737, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 843872, "time": 26883.535420417786, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 844112, "time": 26891.014326334, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 844200, "time": 26893.479440927505, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 844248, "time": 26894.949743270874, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 844248, "time": 26894.95715522766, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 844496, "time": 26902.82830929756, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 844776, "time": 26911.22461915016, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 844912, "time": 26915.636580228806, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 845144, "time": 26922.6830637455, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 845152, "time": 26923.164046525955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845160, "time": 26923.195113897324, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 845296, "time": 26927.600229501724, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 845624, "time": 26937.47196817398, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 845912, "time": 26946.357460021973, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 845960, "time": 26947.849486351013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845968, "time": 26948.34095454216, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 846072, "time": 26951.4014647007, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 846280, "time": 26957.814556598663, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 846336, "time": 26959.74114370346, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 846368, "time": 26960.74026298523, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 846424, "time": 26962.240247011185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 847088, "time": 26983.05759048462, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 847208, "time": 26986.54296875, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 847296, "time": 26989.457723379135, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 847464, "time": 26994.404142856598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 847896, "time": 27007.685976028442, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 848232, "time": 27018.15001130104, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 848272, "time": 27019.61583328247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 848280, "time": 27019.647341251373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 848280, "time": 27019.654702425003, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 848648, "time": 27030.98218870163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 848688, "time": 27032.42951774597, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 848736, "time": 27033.90325474739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 848840, "time": 27036.882142305374, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 849072, "time": 27044.353050470352, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 849344, "time": 27052.709938764572, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 849376, "time": 27053.70419692993, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 849424, "time": 27055.202662229538, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 849632, "time": 27061.579863786697, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 849656, "time": 27062.101803064346, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 27078.039443731308, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 850096, "time": 27078.745329618454, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 850096, "time": 27078.799246549606, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 850096, "time": 27078.872465610504, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 850096, "time": 27079.425116062164, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 850096, "time": 27080.467978954315, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 850096, "time": 27081.38022994995, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 850096, "time": 27081.44813966751, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 850200, "time": 27084.443993091583, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 850328, "time": 27088.37660050392, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 850400, "time": 27090.821739673615, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 850864, "time": 27105.263456344604, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 850872, "time": 27105.29293513298, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 850960, "time": 27108.197900772095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 850968, "time": 27108.228486299515, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 851152, "time": 27114.11513352394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 851312, "time": 27119.025887727737, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 851568, "time": 27126.88409256935, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 851656, "time": 27129.469865083694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 851688, "time": 27130.4525949955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 851840, "time": 27135.363318681717, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 851920, "time": 27137.819000959396, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 851968, "time": 27139.51085615158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 851984, "time": 27140.404965877533, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 852472, "time": 27155.268844366074, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 852520, "time": 27156.76393675804, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 852624, "time": 27160.32449364662, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 852688, "time": 27162.3191883564, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 852912, "time": 27169.280991077423, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 852920, "time": 27169.310577392578, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 853184, "time": 27177.695103883743, "episode/length": 288.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0}
{"step": 853272, "time": 27180.20208144188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 853672, "time": 27192.678258895874, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 853712, "time": 27194.14086318016, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 853760, "time": 27195.62515449524, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 854152, "time": 27207.52306818962, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 854152, "time": 27207.53261947632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 854352, "time": 27213.97614645958, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 854576, "time": 27221.00315093994, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 854664, "time": 27223.5095641613, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 854784, "time": 27227.431841611862, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 854944, "time": 27232.37072777748, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 854992, "time": 27233.869566202164, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 855120, "time": 27237.84960627556, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 855232, "time": 27241.32360434532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855256, "time": 27241.84799170494, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 855264, "time": 27242.326198339462, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 855400, "time": 27246.322316884995, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 855584, "time": 27252.355892896652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 856008, "time": 27265.13481926918, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 856376, "time": 27276.485195159912, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 856480, "time": 27280.0401968956, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 856521, "time": 27282.10082578659, "train_stats/mean_log_entropy": 0.08024412793693719, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.576657690183081, "train/action_min": 0.0, "train/action_std": 1.9030074958849434, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00925126901446757, "train/actor_opt_grad_steps": 52445.0, "train/actor_opt_loss": -11.407370808938838, "train/adv_mag": 0.8384200147908143, "train/adv_max": 0.31406603678308354, "train/adv_mean": 0.001164818810083847, "train/adv_min": -0.7851785457495487, "train/adv_std": 0.02669235040443112, "train/cont_avg": 0.9952108980429293, "train/cont_loss_mean": 0.015396120019652175, "train/cont_loss_std": 0.21812498255755114, "train/cont_neg_acc": 0.3433405186491783, "train/cont_neg_loss": 2.5735657338568627, "train/cont_pos_acc": 0.9998563013293527, "train/cont_pos_loss": 0.003293188272345096, "train/cont_pred": 0.9950785739253266, "train/cont_rate": 0.9952108980429293, "train/dyn_loss_mean": 1.0000190752925295, "train/dyn_loss_std": 0.00027574347614338905, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.23946459209452373, "train/extr_critic_critic_opt_grad_steps": 52445.0, "train/extr_critic_critic_opt_loss": 4101.67287622317, "train/extr_critic_mag": 1.2913046244418982, "train/extr_critic_max": 1.2913046244418982, "train/extr_critic_mean": 1.2057200188588615, "train/extr_critic_min": 0.9980677968323833, "train/extr_critic_std": 0.019328628050520866, "train/extr_return_normed_mag": 0.8570875651908644, "train/extr_return_normed_max": 0.3410249569199302, "train/extr_return_normed_mean": 0.038672500581602855, "train/extr_return_normed_min": -0.7815544412593649, "train/extr_return_normed_std": 0.03419107506333879, "train/extr_return_rate": 0.9994890647705155, "train/extr_return_raw_mag": 1.5092372472840125, "train/extr_return_raw_max": 1.5092372472840125, "train/extr_return_raw_mean": 1.2068848363076798, "train/extr_return_raw_min": 0.3866578491047175, "train/extr_return_raw_std": 0.0341910749880804, "train/extr_reward_mag": 0.3516195205727009, "train/extr_reward_max": 0.3516195205727009, "train/extr_reward_mean": 0.0019815904661575614, "train/extr_reward_min": 1.1619895395606455e-07, "train/extr_reward_std": 0.00870333281768994, "train/image_loss_mean": 0.07739811738708405, "train/image_loss_std": 0.09297342160058142, "train/model_loss_mean": 0.7032922551487432, "train/model_loss_std": 0.39278581648161914, "train/model_opt_grad_norm": 18.615993138515588, "train/model_opt_grad_steps": 52395.333333333336, "train/model_opt_loss": 3713.431909426294, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5277.777777777777, "train/policy_entropy_mag": 1.3047675707123496, "train/policy_entropy_max": 1.3047675707123496, "train/policy_entropy_mean": 0.09667482193220746, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12167073831413731, "train/policy_logprob_mag": 6.551080258205683, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09641436404652065, "train/policy_logprob_min": -6.551080258205683, "train/policy_logprob_std": 0.6335260290088076, "train/policy_randomness_mag": 0.6705179292746265, "train/policy_randomness_max": 0.6705179292746265, "train/policy_randomness_mean": 0.049681033111280866, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06252639456605068, "train/post_ent_mag": 47.0451308741714, "train/post_ent_max": 47.0451308741714, "train/post_ent_mean": 22.768778926194315, "train/post_ent_min": 14.579463000249381, "train/post_ent_std": 6.990372270044654, "train/prior_ent_mag": 47.611511943316216, "train/prior_ent_max": 47.611511943316216, "train/prior_ent_mean": 23.781186257949983, "train/prior_ent_min": 14.562792017002298, "train/prior_ent_std": 6.939748376306861, "train/rep_loss_mean": 1.0000190752925295, "train/rep_loss_std": 0.00027574347614338905, "train/reward_avg": 0.0014591872130022055, "train/reward_loss_mean": 0.010486550135255762, "train/reward_loss_std": 0.17880711735301472, "train/reward_max_data": 0.6727430572112402, "train/reward_max_pred": 0.2529634821294534, "train/reward_neg_acc": 0.9995996178400637, "train/reward_neg_loss": 0.0018791248811693448, "train/reward_pos_acc": 0.25485606870408783, "train/reward_pos_loss": 4.00153403026236, "train/reward_pred": 0.0012021694541673618, "train/reward_rate": 0.0021750710227272725, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.013406209647655487, "report/cont_loss_std": 0.21618309617042542, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 3.1304118633270264, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004247527103871107, "report/cont_pred": 0.9948140382766724, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0842677429318428, "report/image_loss_std": 0.10745740681886673, "report/model_loss_mean": 0.7044605016708374, "report/model_loss_std": 0.3310832381248474, "report/post_ent_mag": 41.56161880493164, "report/post_ent_max": 41.56161880493164, "report/post_ent_mean": 22.22576904296875, "report/post_ent_min": 14.144256591796875, "report/post_ent_std": 6.015044689178467, "report/prior_ent_mag": 43.964813232421875, "report/prior_ent_max": 43.964813232421875, "report/prior_ent_mean": 22.979907989501953, "report/prior_ent_min": 13.41379451751709, "report/prior_ent_std": 6.411031246185303, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008453369373455644, "report/reward_loss_mean": 0.006786505226045847, "report/reward_loss_std": 0.13138450682163239, "report/reward_max_data": 0.8656250238418579, "report/reward_max_pred": 0.0737760066986084, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0026910395827144384, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.196447849273682, "report/reward_pred": 0.0014095022343099117, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.016849331557750702, "eval/cont_loss_std": 0.3607141077518463, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.929668426513672, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.0033213102724403143, "eval/cont_pred": 0.9970293045043945, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10913118720054626, "eval/image_loss_std": 0.11271468549966812, "eval/model_loss_mean": 0.7428799867630005, "eval/model_loss_std": 0.7534440159797668, "eval/post_ent_mag": 42.063270568847656, "eval/post_ent_max": 42.063270568847656, "eval/post_ent_mean": 20.451396942138672, "eval/post_ent_min": 13.555971145629883, "eval/post_ent_std": 6.0187087059021, "eval/prior_ent_mag": 44.01434326171875, "eval/prior_ent_max": 44.01434326171875, "eval/prior_ent_mean": 21.270999908447266, "eval/prior_ent_min": 13.452299118041992, "eval/prior_ent_std": 6.38192892074585, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0013366698985919356, "eval/reward_loss_mean": 0.01689939945936203, "eval/reward_loss_std": 0.37686875462532043, "eval/reward_max_data": 0.7906249761581421, "eval/reward_max_pred": 0.32546210289001465, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.0015375814400613308, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.866788387298584, "eval/reward_pred": 0.0007268071640282869, "eval/reward_rate": 0.001953125, "replay/size": 856017.0, "replay/inserts": 31776.0, "replay/samples": 31776.0, "replay/insert_wait_avg": 1.4864170899443995e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.025168172062224e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4960.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3530735046632827e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3337543010712, "timer/env.step_count": 3972.0, "timer/env.step_total": 41.42926478385925, "timer/env.step_frac": 0.04141544220189361, "timer/env.step_avg": 0.010430328495432843, "timer/env.step_min": 0.008863449096679688, "timer/env.step_max": 0.05671048164367676, "timer/replay._sample_count": 31776.0, "timer/replay._sample_total": 17.112560033798218, "timer/replay._sample_frac": 0.017106850548849757, "timer/replay._sample_avg": 0.0005385372618894203, "timer/replay._sample_min": 0.0003466606140136719, "timer/replay._sample_max": 0.028699636459350586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4592.0, "timer/agent.policy_total": 52.25375580787659, "timer/agent.policy_frac": 0.05223632171083346, "timer/agent.policy_avg": 0.01137930222296964, "timer/agent.policy_min": 0.009430646896362305, "timer/agent.policy_max": 0.0988926887512207, "timer/dataset_train_count": 1986.0, "timer/dataset_train_total": 0.24596500396728516, "timer/dataset_train_frac": 0.0002458829394786741, "timer/dataset_train_avg": 0.000123849448120486, "timer/dataset_train_min": 0.00010800361633300781, "timer/dataset_train_max": 0.00037932395935058594, "timer/agent.train_count": 1986.0, "timer/agent.train_total": 893.0561888217926, "timer/agent.train_frac": 0.8927582269237402, "timer/agent.train_avg": 0.4496758251872067, "timer/agent.train_min": 0.4375133514404297, "timer/agent.train_max": 0.7120730876922607, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.534296989440918, "timer/agent.report_frac": 0.0005341187250191601, "timer/agent.report_avg": 0.267148494720459, "timer/agent.report_min": 0.25763535499572754, "timer/agent.report_max": 0.27666163444519043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.050739615032035e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 31.764854025301172}
{"step": 856720, "time": 27288.383945703506, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 856840, "time": 27291.869560480118, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 856976, "time": 27296.284339904785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 856992, "time": 27296.780056238174, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 857096, "time": 27299.773822069168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 857160, "time": 27301.754680633545, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 857432, "time": 27310.317702054977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 857464, "time": 27311.301698446274, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 857568, "time": 27314.73581790924, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 857704, "time": 27318.698046922684, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 857808, "time": 27322.147558927536, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 857840, "time": 27323.143412828445, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 858128, "time": 27332.034415006638, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 858152, "time": 27332.553528547287, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 858280, "time": 27336.526998758316, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 858328, "time": 27338.00390958786, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 858584, "time": 27346.030591726303, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 858768, "time": 27351.89683651924, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 858816, "time": 27353.373737096786, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 858904, "time": 27355.85447382927, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 858944, "time": 27357.306265830994, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 859056, "time": 27360.753574848175, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 859248, "time": 27366.638898849487, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 859440, "time": 27372.64857983589, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 859704, "time": 27380.51112151146, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 859712, "time": 27380.98262000084, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 859856, "time": 27385.400112628937, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 859880, "time": 27385.92171382904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 859920, "time": 27387.38203573227, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 27393.92001223564, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 860080, "time": 27394.31070637703, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 860080, "time": 27394.493768453598, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 860080, "time": 27394.635585784912, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 860080, "time": 27394.98518371582, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 860080, "time": 27395.11912369728, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 860080, "time": 27395.366730451584, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 860080, "time": 27395.46340727806, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 860272, "time": 27402.10927605629, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 860616, "time": 27412.47350525856, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 860632, "time": 27412.96942448616, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 860856, "time": 27419.927958250046, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 860896, "time": 27421.396451234818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860968, "time": 27423.41540312767, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 861368, "time": 27435.845687150955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 861496, "time": 27439.802701711655, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 861536, "time": 27441.262444734573, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 861560, "time": 27441.81082701683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 861640, "time": 27444.2805249691, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 861872, "time": 27451.65741610527, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 862016, "time": 27456.07474732399, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 862168, "time": 27460.683925628662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 862192, "time": 27461.6758081913, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 862304, "time": 27465.12149834633, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 862416, "time": 27468.592725515366, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 862800, "time": 27480.47582435608, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 862832, "time": 27481.492290496826, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 862840, "time": 27481.522876024246, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 863000, "time": 27486.516800403595, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 863080, "time": 27489.143724679947, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 863096, "time": 27489.64324402809, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 863240, "time": 27494.077107429504, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 863400, "time": 27499.064088344574, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 863600, "time": 27505.45515680313, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 863616, "time": 27505.952250242233, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 863784, "time": 27510.89540028572, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 863784, "time": 27510.902965307236, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 863888, "time": 27514.331984758377, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 863920, "time": 27515.32581806183, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 863968, "time": 27516.81564950943, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 864240, "time": 27525.22929763794, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 864256, "time": 27525.723012447357, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 864448, "time": 27531.618700265884, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 864560, "time": 27535.053671836853, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 864744, "time": 27540.47344303131, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 864912, "time": 27545.895444631577, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 864936, "time": 27546.424315929413, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 865112, "time": 27551.966587543488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865136, "time": 27552.925884008408, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 865376, "time": 27560.27477669716, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 865448, "time": 27562.28785800934, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 865464, "time": 27562.789398670197, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 865832, "time": 27574.075682640076, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 865968, "time": 27578.619112730026, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 866016, "time": 27580.09237599373, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 866216, "time": 27586.002418279648, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 866240, "time": 27586.965620994568, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 866304, "time": 27588.943275928497, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 866424, "time": 27592.3963201046, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 866552, "time": 27596.34207725525, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 866632, "time": 27598.800965309143, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 866832, "time": 27605.1949467659, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 866872, "time": 27606.1940472126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 866896, "time": 27607.16919851303, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 867152, "time": 27615.170657157898, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 867328, "time": 27620.59758090973, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 867664, "time": 27630.945245027542, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 867672, "time": 27630.9768307209, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 868104, "time": 27644.308174610138, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 868208, "time": 27647.745693683624, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 868280, "time": 27649.769587516785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868328, "time": 27651.253697633743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868336, "time": 27651.73171520233, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 868440, "time": 27655.2935962677, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 868616, "time": 27660.74543905258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868896, "time": 27669.711708784103, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 869000, "time": 27672.71133685112, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 869072, "time": 27675.150683879852, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 869184, "time": 27678.592982769012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 869424, "time": 27685.930154323578, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 869816, "time": 27697.74698829651, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 870032, "time": 27704.782380342484, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 27707.10387301445, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 870064, "time": 27707.173817396164, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 870064, "time": 27707.61003112793, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 870064, "time": 27708.275247573853, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 870064, "time": 27708.537301063538, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 870064, "time": 27708.58749318123, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 870064, "time": 27709.289927959442, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 870064, "time": 27709.698403596878, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 870264, "time": 27715.64370059967, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 870384, "time": 27719.588191509247, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 870520, "time": 27723.573623657227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870592, "time": 27726.01147389412, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870640, "time": 27727.48766207695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870832, "time": 27733.55233168602, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 870864, "time": 27734.543477535248, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 871208, "time": 27744.89164209366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 871416, "time": 27751.26047730446, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 871464, "time": 27752.739097595215, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 871472, "time": 27753.235014915466, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 871704, "time": 27760.247098207474, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 871736, "time": 27761.222923517227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 871928, "time": 27767.107533931732, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 872056, "time": 27771.02697777748, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 872232, "time": 27776.401273489, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 872344, "time": 27779.858155727386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 872400, "time": 27781.792913913727, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 872456, "time": 27783.30912733078, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 872656, "time": 27789.84121155739, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 872840, "time": 27795.28737807274, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 872864, "time": 27796.261517047882, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 873048, "time": 27801.73261332512, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 873096, "time": 27803.233069181442, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 873216, "time": 27807.14527273178, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 873288, "time": 27809.147632598877, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 873840, "time": 27826.52837371826, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 873864, "time": 27827.046223640442, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 873912, "time": 27828.5530064106, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 874096, "time": 27834.450832128525, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 874144, "time": 27835.929088830948, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 874712, "time": 27853.378216266632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 874768, "time": 27855.33336043358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 874848, "time": 27857.81705713272, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 874968, "time": 27861.26977276802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 875216, "time": 27869.178837299347, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 875280, "time": 27871.159845113754, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 876104, "time": 27896.47043824196, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 876152, "time": 27897.985080242157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876176, "time": 27898.958961248398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876224, "time": 27900.43561077118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876368, "time": 27904.882026910782, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 876408, "time": 27905.902273654938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876536, "time": 27909.989609479904, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 876792, "time": 27918.412781000137, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 877040, "time": 27926.23670911789, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 877080, "time": 27927.262870788574, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 877144, "time": 27929.24729990959, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 877160, "time": 27929.753794908524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 877472, "time": 27939.738448143005, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 877528, "time": 27941.23718190193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 877744, "time": 27948.167283535004, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 877840, "time": 27951.129115104675, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 877864, "time": 27951.647465467453, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 877904, "time": 27953.129434347153, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 878272, "time": 27964.489815473557, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 878272, "time": 27964.498776197433, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 878416, "time": 27969.07568216324, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 878528, "time": 27972.55185341835, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 878808, "time": 27981.009017705917, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 878848, "time": 27982.482274532318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 879064, "time": 27988.910995960236, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 879120, "time": 27990.85524916649, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 879176, "time": 27992.372003793716, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 879624, "time": 28006.223737716675, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 879840, "time": 28013.067301034927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 879888, "time": 28014.53422689438, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 880032, "time": 28018.944647073746, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 28020.953426599503, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 880048, "time": 28021.159809350967, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 880048, "time": 28021.254083156586, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 880048, "time": 28021.753370046616, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 880048, "time": 28022.085598230362, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 880048, "time": 28022.866145133972, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 880048, "time": 28023.29061317444, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 880048, "time": 28023.29823899269, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 880072, "time": 28023.810950040817, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 880176, "time": 28027.230120658875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 880248, "time": 28029.332284927368, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 880328, "time": 28031.80216217041, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 880416, "time": 28034.724880695343, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 880824, "time": 28047.09177517891, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 880840, "time": 28047.59071111679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 880880, "time": 28049.049159526825, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 880888, "time": 28049.084775686264, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 880888, "time": 28049.09227705002, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 880976, "time": 28052.02658724785, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 881128, "time": 28056.485584020615, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 881160, "time": 28057.481628656387, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 881440, "time": 28066.399768829346, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 881472, "time": 28067.38698744774, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 881480, "time": 28067.4180560112, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 881560, "time": 28069.891086816788, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 881888, "time": 28080.164973974228, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 881968, "time": 28082.6181743145, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 882024, "time": 28084.1104824543, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 882240, "time": 28091.110607624054, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 882272, "time": 28092.103626728058, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 882320, "time": 28093.58069229126, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 882384, "time": 28095.554685354233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 882472, "time": 28098.00722503662, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 882672, "time": 28104.391226530075, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 882792, "time": 28107.85751438141, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 882880, "time": 28110.78533768654, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 882968, "time": 28113.27438735962, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 883016, "time": 28114.779042482376, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 883104, "time": 28117.700794935226, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 883136, "time": 28118.81671142578, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 883144, "time": 28118.846992731094, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 883208, "time": 28120.817437410355, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 883232, "time": 28121.78278851509, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 883424, "time": 28127.714961528778, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 883528, "time": 28130.695521593094, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 883808, "time": 28139.559195280075, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 883816, "time": 28139.59000468254, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 883888, "time": 28142.020218133926, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 884104, "time": 28148.549299001694, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 884224, "time": 28152.469733715057, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 884312, "time": 28154.95365691185, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 884376, "time": 28156.92225575447, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 884632, "time": 28164.826053619385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 884632, "time": 28164.834085702896, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 884864, "time": 28172.6446120739, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 884984, "time": 28176.116027355194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885064, "time": 28178.710633277893, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 885544, "time": 28193.480268001556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885648, "time": 28196.88786172867, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 885792, "time": 28201.32139635086, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 885912, "time": 28204.810529470444, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 886344, "time": 28218.19163441658, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 886624, "time": 28227.147550344467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 886688, "time": 28229.137187242508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 886776, "time": 28231.632214784622, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 886968, "time": 28237.571215629578, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 887016, "time": 28239.228138685226, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 887224, "time": 28245.661348581314, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 887296, "time": 28248.11638903618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887376, "time": 28250.598541021347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887552, "time": 28256.08670115471, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 887616, "time": 28258.066776037216, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 887616, "time": 28258.074904203415, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 887856, "time": 28265.50356411934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887992, "time": 28269.669909477234, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 888000, "time": 28270.143122911453, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 888048, "time": 28271.620463609695, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 888176, "time": 28275.565826416016, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 888280, "time": 28278.57718706131, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 888336, "time": 28280.527154684067, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 888361, "time": 28282.079973459244, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.549099562755182, "train/action_min": 0.0, "train/action_std": 1.8816289110998412, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01134504070950101, "train/actor_opt_grad_steps": 54430.0, "train/actor_opt_loss": -12.53190281163508, "train/adv_mag": 0.9235265557490402, "train/adv_max": 0.32732752160211304, "train/adv_mean": 0.0007884282467428243, "train/adv_min": -0.8823302502009138, "train/adv_std": 0.031035550593880554, "train/cont_avg": 0.9948129318467337, "train/cont_loss_mean": 0.01679072422724236, "train/cont_loss_std": 0.23222658053583387, "train/cont_neg_acc": 0.35939583122430735, "train/cont_neg_loss": 2.588443918599415, "train/cont_pos_acc": 0.9998520292229389, "train/cont_pos_loss": 0.003477484207183834, "train/cont_pred": 0.9947960957809908, "train/cont_rate": 0.9948129318467337, "train/dyn_loss_mean": 1.000005191894033, "train/dyn_loss_std": 0.00016605598081591253, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.26522091501883827, "train/extr_critic_critic_opt_grad_steps": 54430.0, "train/extr_critic_critic_opt_loss": 4987.22234586016, "train/extr_critic_mag": 1.3029406070709229, "train/extr_critic_max": 1.3029406070709229, "train/extr_critic_mean": 1.2166051379400282, "train/extr_critic_min": 0.9901321473433145, "train/extr_critic_std": 0.020177873375652425, "train/extr_return_normed_mag": 0.9381083663384518, "train/extr_return_normed_max": 0.3391081873495974, "train/extr_return_normed_mean": 0.03959224875735578, "train/extr_return_normed_min": -0.8806587865005187, "train/extr_return_normed_std": 0.03825583381007364, "train/extr_return_rate": 0.9992364588095315, "train/extr_return_raw_mag": 1.5169094669159933, "train/extr_return_raw_max": 1.5169094669159933, "train/extr_return_raw_mean": 1.2173935947705752, "train/extr_return_raw_min": 0.2971424930658772, "train/extr_return_raw_std": 0.038255833884953856, "train/extr_reward_mag": 0.3450532007457024, "train/extr_reward_max": 0.3450532007457024, "train/extr_reward_mean": 0.0019092411613068426, "train/extr_reward_min": 8.925720674907742e-08, "train/extr_reward_std": 0.008847286624028979, "train/image_loss_mean": 0.07980987062705822, "train/image_loss_std": 0.09622902907992727, "train/model_loss_mean": 0.7083087620423667, "train/model_loss_std": 0.4249710150100478, "train/model_opt_grad_norm": 18.75301677857212, "train/model_opt_grad_steps": 54378.40201005025, "train/model_opt_loss": 3541.543818948257, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5025.125628140703, "train/policy_entropy_mag": 1.3321663015451863, "train/policy_entropy_max": 1.3321663015451863, "train/policy_entropy_mean": 0.10288244852768116, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13191639467250163, "train/policy_logprob_mag": 6.551080267633026, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1025424076609276, "train/policy_logprob_min": -6.551080267633026, "train/policy_logprob_std": 0.6378385038232085, "train/policy_randomness_mag": 0.6845980960520068, "train/policy_randomness_max": 0.6845980960520068, "train/policy_randomness_mean": 0.0528711209157903, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.067791620353658, "train/post_ent_mag": 46.98901296260968, "train/post_ent_max": 46.98901296260968, "train/post_ent_mean": 22.357078916463422, "train/post_ent_min": 13.979014760884807, "train/post_ent_std": 7.13318941461381, "train/prior_ent_mag": 48.06620004548499, "train/prior_ent_max": 48.06620004548499, "train/prior_ent_mean": 22.86758271413832, "train/prior_ent_min": 13.329821275107225, "train/prior_ent_std": 7.4163643942406425, "train/rep_loss_mean": 1.000005191894033, "train/rep_loss_std": 0.00016605598081591253, "train/reward_avg": 0.0015977255725968705, "train/reward_loss_mean": 0.011705032526398424, "train/reward_loss_std": 0.19610858263784842, "train/reward_max_data": 0.69777010104165, "train/reward_max_pred": 0.23211922178316355, "train/reward_neg_acc": 0.9996016322068833, "train/reward_neg_loss": 0.001992967386318174, "train/reward_pos_acc": 0.20460405369489892, "train/reward_pos_loss": 4.162734044190929, "train/reward_pred": 0.0012269298108435007, "train/reward_rate": 0.0023457129396984924, "train_stats/mean_log_entropy": 0.08146502322866102, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.013976061716675758, "report/cont_loss_std": 0.18975910544395447, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 2.6366310119628906, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0036911405622959137, "report/cont_pred": 0.9953203201293945, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0828685313463211, "report/image_loss_std": 0.09918772429227829, "report/model_loss_mean": 0.7136881351470947, "report/model_loss_std": 0.4574832320213318, "report/post_ent_mag": 43.91473388671875, "report/post_ent_max": 43.91473388671875, "report/post_ent_mean": 22.517913818359375, "report/post_ent_min": 14.491233825683594, "report/post_ent_std": 6.238879680633545, "report/prior_ent_mag": 44.161808013916016, "report/prior_ent_max": 44.161808013916016, "report/prior_ent_mean": 22.1164493560791, "report/prior_ent_min": 13.68612289428711, "report/prior_ent_std": 6.148231506347656, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0026306151412427425, "report/reward_loss_mean": 0.016843553632497787, "report/reward_loss_std": 0.23863103985786438, "report/reward_max_data": 0.800000011920929, "report/reward_max_pred": 0.5491862297058105, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0030399600509554148, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.536760091781616, "report/reward_pred": 0.0021465416066348553, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02919592894613743, "eval/cont_loss_std": 0.40458542108535767, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.256664276123047, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.004774483386427164, "eval/cont_pred": 0.9962872266769409, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.08921802043914795, "eval/image_loss_std": 0.10620231926441193, "eval/model_loss_mean": 0.7251440286636353, "eval/model_loss_std": 0.4945068359375, "eval/post_ent_mag": 43.680458068847656, "eval/post_ent_max": 43.680458068847656, "eval/post_ent_mean": 21.5455265045166, "eval/post_ent_min": 13.75199031829834, "eval/post_ent_std": 6.580637454986572, "eval/prior_ent_mag": 42.463401794433594, "eval/prior_ent_max": 42.463401794433594, "eval/prior_ent_mean": 21.128662109375, "eval/prior_ent_min": 13.460216522216797, "eval/prior_ent_std": 6.516238689422607, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.000732421875, "eval/reward_loss_mean": 0.006730020046234131, "eval/reward_loss_std": 0.14987745881080627, "eval/reward_max_data": 0.75, "eval/reward_max_pred": 0.06326186656951904, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002050199778750539, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.794186115264893, "eval/reward_pred": 0.0010675120865926147, "eval/reward_rate": 0.0009765625, "replay/size": 887857.0, "replay/inserts": 31840.0, "replay/samples": 31840.0, "replay/insert_wait_avg": 1.4844177356317415e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.054714107034195e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4032.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3376157435159834e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4007091522216797e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9609003067017, "timer/env.step_count": 3980.0, "timer/env.step_total": 41.44131779670715, "timer/env.step_frac": 0.04144293820288027, "timer/env.step_avg": 0.010412391406207828, "timer/env.step_min": 0.008617401123046875, "timer/env.step_max": 0.03696465492248535, "timer/replay._sample_count": 31840.0, "timer/replay._sample_total": 16.89514398574829, "timer/replay._sample_frac": 0.016895804606526434, "timer/replay._sample_avg": 0.0005306263814619438, "timer/replay._sample_min": 0.00034356117248535156, "timer/replay._sample_max": 0.010119915008544922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4484.0, "timer/agent.policy_total": 50.59477686882019, "timer/agent.policy_frac": 0.05059675518642987, "timer/agent.policy_avg": 0.011283402513117794, "timer/agent.policy_min": 0.0098876953125, "timer/agent.policy_max": 0.19307494163513184, "timer/dataset_train_count": 1990.0, "timer/dataset_train_total": 0.24534058570861816, "timer/dataset_train_frac": 0.0002453501788253609, "timer/dataset_train_avg": 0.0001232867264867428, "timer/dataset_train_min": 0.00010585784912109375, "timer/dataset_train_max": 0.000453948974609375, "timer/agent.train_count": 1990.0, "timer/agent.train_total": 895.4856724739075, "timer/agent.train_frac": 0.8955206870581137, "timer/agent.train_avg": 0.4499928002381445, "timer/agent.train_min": 0.43720436096191406, "timer/agent.train_max": 0.7593114376068115, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5047664642333984, "timer/agent.report_frac": 0.0005047862012190473, "timer/agent.report_avg": 0.2523832321166992, "timer/agent.report_min": 0.2506868839263916, "timer/agent.report_max": 0.25407958030700684, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.6942352876210758e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 31.84071590869755}
{"step": 888592, "time": 28289.322855949402, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 888768, "time": 28294.779316186905, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 889072, "time": 28304.279705286026, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 889088, "time": 28304.78214597702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 889104, "time": 28305.28000688553, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 889232, "time": 28309.24418926239, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 889400, "time": 28314.202238559723, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 889456, "time": 28316.138457536697, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 889536, "time": 28318.60066318512, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 889648, "time": 28322.092848062515, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 889704, "time": 28323.594838142395, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 889864, "time": 28328.687050819397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 889984, "time": 28332.611189603806, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 28335.316375255585, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 890032, "time": 28336.02933740616, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 890032, "time": 28336.206968069077, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 890032, "time": 28336.381296873093, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 890032, "time": 28336.473073005676, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 890032, "time": 28336.500710487366, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 890032, "time": 28336.801730632782, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 890032, "time": 28337.637169122696, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 890048, "time": 28338.135910511017, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 890280, "time": 28345.005193710327, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 890624, "time": 28355.791340351105, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 890648, "time": 28356.305295467377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 890656, "time": 28356.777005195618, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 890744, "time": 28359.388560533524, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 890952, "time": 28365.785851716995, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 891208, "time": 28373.67822265625, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 891256, "time": 28375.15358018875, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 891408, "time": 28380.081907987595, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 891648, "time": 28387.468327760696, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 891712, "time": 28389.533935785294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 891728, "time": 28390.026331186295, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 891960, "time": 28396.941170692444, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 892032, "time": 28399.401978731155, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 892096, "time": 28401.393221139908, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 892176, "time": 28403.890656471252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 892192, "time": 28404.389028072357, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 892240, "time": 28405.866035223007, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 892296, "time": 28407.3894906044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 892424, "time": 28411.30587887764, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 892616, "time": 28417.29313826561, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 892704, "time": 28420.3262424469, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 892792, "time": 28422.826016902924, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 892888, "time": 28425.781796216965, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 893248, "time": 28437.743222236633, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 893448, "time": 28443.72349691391, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 893496, "time": 28445.2127969265, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 893648, "time": 28450.25707101822, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 893776, "time": 28454.21560525894, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 893840, "time": 28456.185783863068, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 894016, "time": 28461.605224370956, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 894176, "time": 28466.557131528854, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 894224, "time": 28468.064365148544, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 894416, "time": 28473.982537269592, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 894608, "time": 28480.096927404404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 894888, "time": 28488.503976106644, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 894952, "time": 28490.48206138611, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 895160, "time": 28496.882880687714, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 895200, "time": 28498.35356736183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 895280, "time": 28500.827830553055, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 895472, "time": 28506.76993560791, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 895576, "time": 28509.851387023926, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 895888, "time": 28519.71370792389, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 896080, "time": 28525.6366481781, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 896152, "time": 28527.65364742279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896280, "time": 28531.610080718994, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 896328, "time": 28533.098841667175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896584, "time": 28541.10717868805, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 896960, "time": 28552.912930488586, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 897168, "time": 28559.316375494003, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 897176, "time": 28559.34601545334, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 897176, "time": 28559.35612487793, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 897184, "time": 28559.832401752472, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 897472, "time": 28568.84946703911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 897488, "time": 28569.343100070953, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 897488, "time": 28569.350159168243, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 897728, "time": 28576.800629615784, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 897816, "time": 28579.321526765823, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 897912, "time": 28582.307841539383, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 898112, "time": 28588.70146369934, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 898200, "time": 28591.197540283203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 898208, "time": 28591.670780181885, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 898336, "time": 28595.607384443283, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 898568, "time": 28602.638208150864, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 898664, "time": 28605.558089733124, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 898704, "time": 28607.032383441925, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 898816, "time": 28610.452535152435, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 899168, "time": 28621.252851486206, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 899352, "time": 28626.668709993362, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 899392, "time": 28628.111646175385, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 899408, "time": 28628.755908489227, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 899680, "time": 28637.111104249954, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 899832, "time": 28641.581601142883, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 900000, "time": 28646.968405485153, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 28648.770180225372, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 900016, "time": 28648.947860479355, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 900016, "time": 28649.041867733, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 900016, "time": 28649.176535129547, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 900016, "time": 28649.339807510376, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 900016, "time": 28649.97362613678, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 900016, "time": 28650.280382871628, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 900016, "time": 28650.56951379776, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 900096, "time": 28653.028307437897, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 900176, "time": 28655.51360821724, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 900424, "time": 28663.093832731247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 900520, "time": 28666.081794261932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 900600, "time": 28668.58528637886, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 900616, "time": 28669.087080955505, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 900768, "time": 28673.983576774597, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 900976, "time": 28680.38464975357, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 901000, "time": 28680.900693893433, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 901016, "time": 28681.396829605103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 901208, "time": 28687.860594511032, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 901304, "time": 28690.95477437973, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 901440, "time": 28695.391784906387, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 901544, "time": 28698.37405705452, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 901576, "time": 28699.382009744644, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 901776, "time": 28705.776689291, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 902024, "time": 28713.1986079216, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 902064, "time": 28714.72994327545, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 902248, "time": 28720.319271087646, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 902280, "time": 28721.311447143555, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 902408, "time": 28725.28417778015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 903080, "time": 28746.022058963776, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 903168, "time": 28749.170084238052, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 903272, "time": 28752.147105693817, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 903328, "time": 28754.125852108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 903520, "time": 28760.083047628403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 903672, "time": 28764.558866500854, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 903792, "time": 28768.492921590805, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 904072, "time": 28776.94704079628, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 904088, "time": 28777.448629140854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 904192, "time": 28781.0235183239, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 904208, "time": 28781.524419546127, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 904336, "time": 28785.496472597122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 904488, "time": 28789.967601060867, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 904576, "time": 28792.923425912857, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 904592, "time": 28793.443914413452, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 904592, "time": 28793.453516721725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 904960, "time": 28804.782998800278, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 905120, "time": 28809.85320878029, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 905320, "time": 28815.7886595726, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 905352, "time": 28816.78388285637, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 905536, "time": 28822.68164372444, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 905664, "time": 28826.640503168106, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 905760, "time": 28829.606338739395, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 905800, "time": 28830.62214946747, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 905848, "time": 28832.097982406616, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 906112, "time": 28840.680106401443, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 906240, "time": 28844.657061815262, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 906256, "time": 28845.158456802368, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 906384, "time": 28849.120377779007, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 906448, "time": 28851.08301949501, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 906464, "time": 28851.58155798912, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 906592, "time": 28855.534505605698, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 906960, "time": 28866.878410100937, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 907000, "time": 28867.908888339996, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 907040, "time": 28869.472249746323, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 907192, "time": 28873.891473531723, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 907248, "time": 28875.811445236206, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 907520, "time": 28884.16418337822, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 907568, "time": 28885.628629922867, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 907632, "time": 28887.599545001984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 907672, "time": 28888.60391187668, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 907848, "time": 28893.98969078064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 908016, "time": 28899.501789808273, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 908096, "time": 28901.93170428276, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 908112, "time": 28902.450403928757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 908216, "time": 28905.411405086517, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 908344, "time": 28909.32794213295, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 908456, "time": 28912.777005910873, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 908752, "time": 28922.08318924904, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 908968, "time": 28928.61132287979, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 909048, "time": 28931.070831298828, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 909088, "time": 28932.541870594025, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 909088, "time": 28932.549443244934, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 909208, "time": 28935.99702525139, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 909544, "time": 28946.844566106796, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 909688, "time": 28951.278359889984, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 909808, "time": 28955.19472527504, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 909984, "time": 28960.748509168625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 28961.72714328766, "eval_episode/length": 14.0, "eval_episode/score": 0.956250011920929, "eval_episode/reward_rate": 0.06666666666666667}
{"step": 910000, "time": 28963.115617275238, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 910000, "time": 28963.86467719078, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 910000, "time": 28964.00078678131, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 910000, "time": 28964.859228610992, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 910000, "time": 28965.115132808685, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 910000, "time": 28965.185347557068, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 910000, "time": 28965.279188394547, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 910160, "time": 28970.160326480865, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 910272, "time": 28973.62266278267, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 910272, "time": 28973.63127708435, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 910312, "time": 28974.642192840576, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 910408, "time": 28977.58881998062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 910680, "time": 28985.945697546005, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 910928, "time": 28993.88902068138, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 910944, "time": 28994.386669158936, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 910976, "time": 28995.367516040802, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 911200, "time": 29002.261591911316, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 911280, "time": 29004.709371328354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 911400, "time": 29008.185720443726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 911480, "time": 29010.656832933426, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 911536, "time": 29012.58891415596, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 911624, "time": 29015.079203605652, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 911640, "time": 29015.599246025085, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 911888, "time": 29023.586660146713, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 911912, "time": 29024.104533672333, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 912200, "time": 29032.96872162819, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 912224, "time": 29033.936342954636, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 912456, "time": 29040.888521194458, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 912584, "time": 29044.821097373962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 912696, "time": 29048.323187351227, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 912800, "time": 29051.79719901085, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 913136, "time": 29062.117929935455, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 913256, "time": 29065.61235141754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 913656, "time": 29077.97999572754, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 913712, "time": 29080.103288650513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 913952, "time": 29087.477856636047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 913952, "time": 29087.490540266037, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 914024, "time": 29089.469923734665, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 914056, "time": 29090.47087454796, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 914224, "time": 29095.893567085266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 914728, "time": 29111.406414031982, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 914768, "time": 29112.88084435463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 914872, "time": 29115.8977124691, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 914968, "time": 29118.868589878082, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 915008, "time": 29120.356860160828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915112, "time": 29123.356536626816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915288, "time": 29128.799139738083, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 915416, "time": 29132.779732227325, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 915768, "time": 29143.777396440506, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 915792, "time": 29144.76820921898, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 915800, "time": 29144.798970222473, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 916064, "time": 29153.13324904442, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 916144, "time": 29155.62351512909, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 916200, "time": 29157.139401197433, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 916328, "time": 29161.130806207657, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 916336, "time": 29161.608287096024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 916464, "time": 29165.55402493477, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 917080, "time": 29184.39661860466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 917152, "time": 29186.83814716339, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 917176, "time": 29187.35819888115, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 917192, "time": 29187.85647702217, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 917312, "time": 29191.764742851257, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 917488, "time": 29197.187415361404, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 917688, "time": 29203.86896300316, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 917728, "time": 29205.353887557983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 917832, "time": 29208.340235948563, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 917888, "time": 29210.298622131348, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 918024, "time": 29214.232991218567, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 918032, "time": 29214.7218542099, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 918304, "time": 29223.049277067184, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 918536, "time": 29230.13194155693, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 918640, "time": 29233.567672014236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 918936, "time": 29242.51163458824, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 918944, "time": 29242.99194264412, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 918984, "time": 29244.011494874954, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 919016, "time": 29245.020654201508, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 919168, "time": 29249.960849285126, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 919280, "time": 29253.413133621216, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 919488, "time": 29259.979087352753, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 919584, "time": 29262.95193338394, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 919920, "time": 29273.29425907135, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 919928, "time": 29273.32558321953, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 920000, "time": 29275.788789749146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 920056, "time": 29277.290307998657, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 920064, "time": 29277.765106201172, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 29280.082002162933, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 920088, "time": 29280.256855010986, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 920088, "time": 29280.26340985298, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 920088, "time": 29280.37775039673, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 920088, "time": 29281.021847963333, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 920088, "time": 29281.050433158875, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 920088, "time": 29281.36003780365, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 920088, "time": 29281.496490955353, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 920088, "time": 29281.50358057022, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 920089, "time": 29282.540577173233, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.590566307607323, "train/action_min": 0.0, "train/action_std": 1.888828776099465, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009301867933398244, "train/actor_opt_grad_steps": 56415.0, "train/actor_opt_loss": -12.863623780433578, "train/adv_mag": 0.7642785292683225, "train/adv_max": 0.3080598362768539, "train/adv_mean": 0.0009063535567338936, "train/adv_min": -0.6967370184985074, "train/adv_std": 0.023467197374563025, "train/cont_avg": 0.9951270517676768, "train/cont_loss_mean": 0.016728660328116155, "train/cont_loss_std": 0.22717432464670503, "train/cont_neg_acc": 0.3304533487317538, "train/cont_neg_loss": 2.6645084637866328, "train/cont_pos_acc": 0.9998611660316737, "train/cont_pos_loss": 0.003640285677234219, "train/cont_pred": 0.994930860069063, "train/cont_rate": 0.9951270517676768, "train/dyn_loss_mean": 1.000002626216773, "train/dyn_loss_std": 7.792975579510734e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.22096728363234286, "train/extr_critic_critic_opt_grad_steps": 56415.0, "train/extr_critic_critic_opt_loss": 5320.4242831143465, "train/extr_critic_mag": 1.3106647344550701, "train/extr_critic_max": 1.3106647344550701, "train/extr_critic_mean": 1.2223007389993379, "train/extr_critic_min": 0.957398017849585, "train/extr_critic_std": 0.020585574374317822, "train/extr_return_normed_mag": 0.7934386730194092, "train/extr_return_normed_max": 0.290189676212542, "train/extr_return_normed_mean": 0.0394200037534565, "train/extr_return_normed_min": -0.6987726899108502, "train/extr_return_normed_std": 0.03206368635474431, "train/extr_return_rate": 0.9995936269711967, "train/extr_return_raw_mag": 1.473976700594931, "train/extr_return_raw_max": 1.473976700594931, "train/extr_return_raw_mean": 1.2232070938505308, "train/extr_return_raw_min": 0.4850143344715388, "train/extr_return_raw_std": 0.03206368615719104, "train/extr_reward_mag": 0.28466060847947094, "train/extr_reward_max": 0.28466060847947094, "train/extr_reward_mean": 0.001844838677877278, "train/extr_reward_min": 6.141084613222064e-08, "train/extr_reward_std": 0.007397186496727771, "train/image_loss_mean": 0.07601524885706228, "train/image_loss_std": 0.0924999996116667, "train/model_loss_mean": 0.7039413560520519, "train/model_loss_std": 0.404429262673313, "train/model_opt_grad_norm": 17.781701458825005, "train/model_opt_grad_steps": 56361.4494949495, "train/model_opt_loss": 3572.883287217882, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5101.010101010101, "train/policy_entropy_mag": 1.3200842093939733, "train/policy_entropy_max": 1.3200842093939733, "train/policy_entropy_mean": 0.10599527492968723, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.1359701050501881, "train/policy_logprob_mag": 6.5510802822883685, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10582272734756422, "train/policy_logprob_min": -6.5510802822883685, "train/policy_logprob_std": 0.641417080705816, "train/policy_randomness_mag": 0.6783891260021865, "train/policy_randomness_max": 0.6783891260021865, "train/policy_randomness_mean": 0.054470797097592644, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06987481552994612, "train/post_ent_mag": 46.83431490503176, "train/post_ent_max": 46.83431490503176, "train/post_ent_mean": 22.384309604914503, "train/post_ent_min": 13.598329414020885, "train/post_ent_std": 7.319267735336766, "train/prior_ent_mag": 48.73356179516725, "train/prior_ent_max": 48.73356179516725, "train/prior_ent_mean": 23.035313798923685, "train/prior_ent_min": 13.557248756138966, "train/prior_ent_std": 7.418463750319048, "train/rep_loss_mean": 1.000002626216773, "train/rep_loss_std": 7.792975579510734e-05, "train/reward_avg": 0.0015483817667406373, "train/reward_loss_mean": 0.011195847618210159, "train/reward_loss_std": 0.18470891813672327, "train/reward_max_data": 0.7004892695130724, "train/reward_max_pred": 0.2549616116465944, "train/reward_neg_acc": 0.9996786126584718, "train/reward_neg_loss": 0.0021635223864436602, "train/reward_pos_acc": 0.24461983918155755, "train/reward_pos_loss": 3.919093398758061, "train/reward_pred": 0.0013491901042259702, "train/reward_rate": 0.0023033065025252525, "train_stats/mean_log_entropy": 0.08248812016479823, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.011279807426035404, "report/cont_loss_std": 0.1519976407289505, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.291876792907715, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004578738939017057, "report/cont_pred": 0.9944742918014526, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.062485456466674805, "report/image_loss_std": 0.07492749392986298, "report/model_loss_mean": 0.6813706755638123, "report/model_loss_std": 0.29853376746177673, "report/post_ent_mag": 43.63618087768555, "report/post_ent_max": 43.63618087768555, "report/post_ent_mean": 21.094764709472656, "report/post_ent_min": 13.264305114746094, "report/post_ent_std": 6.786532878875732, "report/prior_ent_mag": 45.38325500488281, "report/prior_ent_max": 45.38325500488281, "report/prior_ent_mean": 21.205934524536133, "report/prior_ent_min": 12.982927322387695, "report/prior_ent_std": 6.645096778869629, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004730224609375, "report/reward_loss_mean": 0.007605392020195723, "report/reward_loss_std": 0.15677239000797272, "report/reward_max_data": 0.484375, "report/reward_max_pred": 0.05588853359222412, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002711805747821927, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.013744354248047, "report/reward_pred": 0.0014351089484989643, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02421281859278679, "eval/cont_loss_std": 0.36298835277557373, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.135297775268555, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00416934909299016, "eval/cont_pred": 0.9958088397979736, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11450309306383133, "eval/image_loss_std": 0.12077315151691437, "eval/model_loss_mean": 0.7551883459091187, "eval/model_loss_std": 0.5744739770889282, "eval/post_ent_mag": 43.63567352294922, "eval/post_ent_max": 43.63567352294922, "eval/post_ent_mean": 21.558305740356445, "eval/post_ent_min": 12.94395637512207, "eval/post_ent_std": 7.32076358795166, "eval/prior_ent_mag": 44.9367790222168, "eval/prior_ent_max": 44.9367790222168, "eval/prior_ent_mean": 21.270469665527344, "eval/prior_ent_min": 12.433758735656738, "eval/prior_ent_std": 6.971073150634766, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0020507811568677425, "eval/reward_loss_mean": 0.016472455114126205, "eval/reward_loss_std": 0.26717376708984375, "eval/reward_max_data": 0.824999988079071, "eval/reward_max_pred": 0.03165137767791748, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002109985798597336, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.904499530792236, "eval/reward_pred": 0.0011370426509529352, "eval/reward_rate": 0.0029296875, "replay/size": 919585.0, "replay/inserts": 31728.0, "replay/samples": 31728.0, "replay/insert_wait_avg": 1.4736444374196048e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.997557663641009e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4840.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3142085272418567e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4454712867737, "timer/env.step_count": 3966.0, "timer/env.step_total": 41.430196046829224, "timer/env.step_frac": 0.04141174830202557, "timer/env.step_avg": 0.010446342926583264, "timer/env.step_min": 0.008794069290161133, "timer/env.step_max": 0.0362699031829834, "timer/replay._sample_count": 31728.0, "timer/replay._sample_total": 16.924094915390015, "timer/replay._sample_frac": 0.016916559074051513, "timer/replay._sample_avg": 0.0005334119678325143, "timer/replay._sample_min": 0.00037288665771484375, "timer/replay._sample_max": 0.01149606704711914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4571.0, "timer/agent.policy_total": 52.01610064506531, "timer/agent.policy_frac": 0.05199293928349954, "timer/agent.policy_avg": 0.011379588852562964, "timer/agent.policy_min": 0.009494543075561523, "timer/agent.policy_max": 0.10618448257446289, "timer/dataset_train_count": 1983.0, "timer/dataset_train_total": 0.2447042465209961, "timer/dataset_train_frac": 0.0002445952863440496, "timer/dataset_train_avg": 0.00012340103203277664, "timer/dataset_train_min": 0.0001068115234375, "timer/dataset_train_max": 0.0010716915130615234, "timer/agent.train_count": 1983.0, "timer/agent.train_total": 893.3925800323486, "timer/agent.train_frac": 0.8929947765001789, "timer/agent.train_avg": 0.4505257589673972, "timer/agent.train_min": 0.4363243579864502, "timer/agent.train_max": 0.8832499980926514, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5011918544769287, "timer/agent.report_frac": 0.0005009686873111589, "timer/agent.report_avg": 0.25059592723846436, "timer/agent.report_min": 0.24777579307556152, "timer/agent.report_max": 0.2534160614013672, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8359177713697973e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 31.713318757899852}
{"step": 920192, "time": 29285.785924434662, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 920192, "time": 29285.794543027878, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 920232, "time": 29286.79993700981, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 920760, "time": 29303.21527814865, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 920776, "time": 29303.714323997498, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 920872, "time": 29306.689723730087, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 920872, "time": 29306.696697235107, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 921032, "time": 29311.632148504257, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 921176, "time": 29316.12293601036, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 921304, "time": 29320.260650634766, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 921360, "time": 29322.22082233429, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 921536, "time": 29327.656455755234, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 921632, "time": 29330.629917621613, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 922072, "time": 29343.989993095398, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 922368, "time": 29353.480696439743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 922528, "time": 29358.408878087997, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 922544, "time": 29358.91380214691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 922656, "time": 29362.350821971893, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 923344, "time": 29383.682693004608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923352, "time": 29383.711990356445, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 923488, "time": 29388.127407312393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923504, "time": 29388.62430047989, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 923848, "time": 29399.039585113525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923944, "time": 29402.01204419136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 924184, "time": 29409.538076400757, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 924384, "time": 29415.919848680496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 924408, "time": 29416.441947698593, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 924600, "time": 29422.36489868164, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 924768, "time": 29427.79522252083, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 924840, "time": 29429.793186426163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 924888, "time": 29431.26551604271, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 925136, "time": 29439.28667473793, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 925184, "time": 29440.773844242096, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 925488, "time": 29450.153074741364, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 925632, "time": 29454.58212161064, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 925664, "time": 29455.57617521286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 926008, "time": 29466.50221681595, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 926416, "time": 29479.492112874985, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 926440, "time": 29480.017112493515, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 926656, "time": 29486.902939081192, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 926696, "time": 29487.938373565674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 926912, "time": 29494.86946129799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 927024, "time": 29498.400188446045, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 927128, "time": 29501.445618391037, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 927200, "time": 29503.90454006195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 927472, "time": 29512.291442155838, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 927496, "time": 29512.812262535095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 927568, "time": 29515.257494688034, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 927584, "time": 29515.758621931076, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 927648, "time": 29517.74645113945, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 927920, "time": 29526.16832137108, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 927944, "time": 29526.695177555084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 927960, "time": 29527.21451163292, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 928096, "time": 29531.748228549957, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 928248, "time": 29536.187707662582, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 928392, "time": 29540.632048130035, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 928472, "time": 29543.111292123795, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 928752, "time": 29551.975618362427, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 928928, "time": 29557.41308927536, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 929120, "time": 29563.461049556732, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 929240, "time": 29566.964206695557, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 929248, "time": 29567.44775700569, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 929616, "time": 29578.76991915703, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 929688, "time": 29580.756934165955, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 929848, "time": 29585.69953417778, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 929880, "time": 29586.71903705597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 929896, "time": 29587.221445083618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 29593.4515311718, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 930072, "time": 29594.68016767502, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 930072, "time": 29594.818639278412, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 930072, "time": 29595.106134414673, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 930072, "time": 29595.388991832733, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 930072, "time": 29595.501022815704, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 930072, "time": 29595.638900756836, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 930072, "time": 29596.161991596222, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 930232, "time": 29601.11394882202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 930320, "time": 29604.044947385788, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 930368, "time": 29605.585113048553, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 930408, "time": 29606.593185901642, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 930704, "time": 29615.963018894196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 930752, "time": 29617.44407272339, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 930928, "time": 29622.99325656891, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 930936, "time": 29623.023638010025, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 931104, "time": 29628.423444747925, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 931344, "time": 29635.822440862656, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 931416, "time": 29637.81614112854, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 931512, "time": 29640.772878408432, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 931600, "time": 29643.700706005096, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 931928, "time": 29653.696385622025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 931960, "time": 29654.704119443893, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 931976, "time": 29655.20905661583, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 932088, "time": 29658.653289556503, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 932192, "time": 29662.09740614891, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 932544, "time": 29672.87197804451, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 932616, "time": 29674.860817670822, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 932632, "time": 29675.356908082962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 932952, "time": 29685.241793870926, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 932960, "time": 29685.71581196785, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 933056, "time": 29688.662127494812, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 933256, "time": 29694.584924936295, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 933424, "time": 29699.939159154892, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 933440, "time": 29700.435460090637, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 933480, "time": 29701.444660663605, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 933768, "time": 29710.468371629715, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 933912, "time": 29715.47093462944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 934064, "time": 29720.403005361557, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 934240, "time": 29725.80789923668, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 934360, "time": 29729.31079673767, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 934392, "time": 29730.297484636307, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 934512, "time": 29734.216522932053, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 934552, "time": 29735.236067533493, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 934640, "time": 29738.21079349518, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 934776, "time": 29742.31333589554, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 935320, "time": 29759.14520931244, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 935424, "time": 29762.562529087067, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 935456, "time": 29763.552031993866, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 935488, "time": 29764.555262565613, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 935560, "time": 29766.55950808525, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 935568, "time": 29767.037026643753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 935672, "time": 29770.162407159805, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 935928, "time": 29777.991247177124, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 936000, "time": 29780.41509461403, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 936024, "time": 29780.9317548275, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 936080, "time": 29782.87535381317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 936248, "time": 29787.802995204926, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 936384, "time": 29792.21249985695, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 936760, "time": 29803.695536136627, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 936808, "time": 29805.17110300064, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 936896, "time": 29808.061975240707, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 937288, "time": 29819.883541345596, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 937632, "time": 29830.861369371414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 937688, "time": 29832.37189769745, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 937872, "time": 29838.293553113937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 937928, "time": 29839.783670663834, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 938200, "time": 29848.182671785355, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 938240, "time": 29849.63701224327, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 938368, "time": 29853.58768582344, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 938640, "time": 29862.115812540054, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 938696, "time": 29863.648297548294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 938856, "time": 29868.58362197876, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 938864, "time": 29869.058260440826, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 939176, "time": 29878.47868347168, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 939208, "time": 29879.476212978363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939480, "time": 29890.390599489212, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 939512, "time": 29891.37989783287, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 939856, "time": 29902.224346399307, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 29909.689455509186, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 940056, "time": 29909.783749103546, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 940056, "time": 29909.898040533066, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 940056, "time": 29909.991734981537, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 940056, "time": 29910.171508550644, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 940056, "time": 29910.57131743431, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 940056, "time": 29911.09875559807, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 940056, "time": 29911.190078020096, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 940232, "time": 29916.638531446457, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 940416, "time": 29922.686078071594, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 940512, "time": 29925.65500330925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 940680, "time": 29930.62179851532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 940784, "time": 29934.05390882492, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 941024, "time": 29941.41912984848, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 941168, "time": 29945.88769006729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 941176, "time": 29945.918843507767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 941192, "time": 29946.416724443436, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 941264, "time": 29949.002950668335, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 941456, "time": 29954.913259267807, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 941488, "time": 29955.90318441391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 941520, "time": 29956.894483566284, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 941640, "time": 29960.39616560936, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 941768, "time": 29964.363635778427, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 941872, "time": 29967.815065145493, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 942144, "time": 29976.699251651764, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 942152, "time": 29976.728749275208, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 942464, "time": 29986.742529392242, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 942520, "time": 29988.247168779373, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 942808, "time": 29997.10816001892, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 942848, "time": 29998.59861111641, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 943232, "time": 30010.60705757141, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 943432, "time": 30016.54510951042, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 943704, "time": 30024.93648457527, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 943768, "time": 30026.907577753067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 943832, "time": 30028.89333319664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 944136, "time": 30038.377028226852, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 944224, "time": 30041.38091135025, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 944296, "time": 30043.395790338516, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 944528, "time": 30050.791474819183, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 944664, "time": 30054.771361351013, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 944720, "time": 30056.716622829437, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 944744, "time": 30057.244806289673, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 944776, "time": 30058.252210378647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 944832, "time": 30060.195814847946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 945120, "time": 30069.222524404526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 945120, "time": 30069.22958254814, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 945208, "time": 30071.700332403183, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 945528, "time": 30081.568861722946, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 945808, "time": 30090.4254655838, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 945832, "time": 30090.948237657547, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 945920, "time": 30093.899302482605, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 946224, "time": 30103.41541671753, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 946400, "time": 30108.842770814896, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 946448, "time": 30110.330538511276, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 946448, "time": 30110.33957886696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 946736, "time": 30119.244438409805, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 946744, "time": 30119.275639772415, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 946760, "time": 30119.779161930084, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 947032, "time": 30128.21630167961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 947080, "time": 30129.829073905945, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 947200, "time": 30133.792058706284, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 947328, "time": 30137.73429107666, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 947416, "time": 30140.232534646988, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 947432, "time": 30140.73712015152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 947824, "time": 30153.03834939003, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 947936, "time": 30156.486333608627, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 948024, "time": 30159.152676582336, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 948064, "time": 30160.602771520615, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 948184, "time": 30164.096878051758, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 948512, "time": 30174.4359664917, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 948712, "time": 30180.396589040756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 948728, "time": 30180.897943735123, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 948992, "time": 30189.363657712936, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 949096, "time": 30192.364447832108, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 949176, "time": 30194.823437213898, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 949192, "time": 30195.33690738678, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 949496, "time": 30204.803958892822, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 949552, "time": 30206.780963659286, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 949640, "time": 30209.280581474304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 949736, "time": 30212.287200450897, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 949952, "time": 30219.33783173561, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 949992, "time": 30220.35242486, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 30222.493826389313, "eval_episode/length": 28.0, "eval_episode/score": 0.9125000238418579, "eval_episode/reward_rate": 0.034482758620689655}
{"step": 950040, "time": 30222.890753746033, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 950040, "time": 30224.06106209755, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 950040, "time": 30224.307230472565, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 950040, "time": 30224.88092494011, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 950040, "time": 30224.910398960114, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 950040, "time": 30225.163053035736, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 950040, "time": 30225.913992643356, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 950136, "time": 30228.89097881317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 950496, "time": 30240.720443725586, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 950616, "time": 30244.234482049942, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 950744, "time": 30248.257299661636, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 950752, "time": 30248.806361198425, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 950824, "time": 30250.81353187561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 951088, "time": 30259.20380783081, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 951216, "time": 30263.16965675354, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 951224, "time": 30263.19882965088, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 951512, "time": 30272.0846722126, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 951560, "time": 30273.56333398819, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 951808, "time": 30281.634395122528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 951817, "time": 30282.69060063362, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5767751722479586, "train/action_min": 0.0, "train/action_std": 1.875886453456016, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00857708405998147, "train/actor_opt_grad_steps": 58400.0, "train/actor_opt_loss": -13.114198905139713, "train/adv_mag": 0.783114593831738, "train/adv_max": 0.290639217175431, "train/adv_mean": 0.0009647374052420404, "train/adv_min": -0.714439619725673, "train/adv_std": 0.02341881360222197, "train/cont_avg": 0.9949650596733668, "train/cont_loss_mean": 0.01778734030538992, "train/cont_loss_std": 0.23671818713437598, "train/cont_neg_acc": 0.32004467345512094, "train/cont_neg_loss": 2.7326349578247915, "train/cont_pos_acc": 0.9998372724307841, "train/cont_pos_loss": 0.0037360049125471683, "train/cont_pred": 0.9948735317992206, "train/cont_rate": 0.9949650596733668, "train/dyn_loss_mean": 1.0000101561522363, "train/dyn_loss_std": 0.000264953952937869, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2034065720704782, "train/extr_critic_critic_opt_grad_steps": 58400.0, "train/extr_critic_critic_opt_loss": 5574.240570528424, "train/extr_critic_mag": 1.316687872661418, "train/extr_critic_max": 1.316687872661418, "train/extr_critic_mean": 1.2250109593472889, "train/extr_critic_min": 0.9544946374605648, "train/extr_critic_std": 0.021718107323026536, "train/extr_return_normed_mag": 0.805193846549221, "train/extr_return_normed_max": 0.28138459807065264, "train/extr_return_normed_mean": 0.041602907421525996, "train/extr_return_normed_min": -0.7149275972615534, "train/extr_return_normed_std": 0.032989934292720194, "train/extr_return_rate": 0.9995871632542442, "train/extr_return_raw_mag": 1.465757337047826, "train/extr_return_raw_max": 1.465757337047826, "train/extr_return_raw_mean": 1.2259757081467901, "train/extr_return_raw_min": 0.46944514171562, "train/extr_return_raw_std": 0.03298993421783998, "train/extr_reward_mag": 0.2815243389139223, "train/extr_reward_max": 0.2815243389139223, "train/extr_reward_mean": 0.0019266736508234774, "train/extr_reward_min": 5.0319499106862437e-08, "train/extr_reward_std": 0.007613650179145175, "train/image_loss_mean": 0.07762542743254547, "train/image_loss_std": 0.09480677309197996, "train/model_loss_mean": 0.7079168363432189, "train/model_loss_std": 0.4296271897215939, "train/model_opt_grad_norm": 17.87443299509173, "train/model_opt_grad_steps": 58344.53266331658, "train/model_opt_loss": 3699.476131880104, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5226.130653266332, "train/policy_entropy_mag": 1.3205925825253204, "train/policy_entropy_max": 1.3205925825253204, "train/policy_entropy_mean": 0.10330211592080006, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13255601705768, "train/policy_logprob_mag": 6.551080248463693, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10330278609865275, "train/policy_logprob_min": -6.551080248463693, "train/policy_logprob_std": 0.6398555208091161, "train/policy_randomness_mag": 0.6786503770842625, "train/policy_randomness_max": 0.6786503770842625, "train/policy_randomness_mean": 0.05308678736863424, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06812032143674304, "train/post_ent_mag": 46.41439228920481, "train/post_ent_max": 46.41439228920481, "train/post_ent_mean": 22.13516653243022, "train/post_ent_min": 13.779207665716584, "train/post_ent_std": 7.354689806549993, "train/prior_ent_mag": 44.539361426578694, "train/prior_ent_max": 44.539361426578694, "train/prior_ent_mean": 22.370898299480803, "train/prior_ent_min": 13.99737523907992, "train/prior_ent_std": 6.9083142568118605, "train/rep_loss_mean": 1.0000101561522363, "train/rep_loss_std": 0.000264953952937869, "train/reward_avg": 0.0016966546611010972, "train/reward_loss_mean": 0.012497950050436971, "train/reward_loss_std": 0.19992984752240942, "train/reward_max_data": 0.7242305277280472, "train/reward_max_pred": 0.25219040899420503, "train/reward_neg_acc": 0.9996506068574723, "train/reward_neg_loss": 0.002269360236823559, "train/reward_pos_acc": 0.20394265427384325, "train/reward_pos_loss": 4.04361587410332, "train/reward_pred": 0.0014015230924667949, "train/reward_rate": 0.002512562814070352, "train_stats/mean_log_entropy": 0.08425211949673082, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.012756384909152985, "report/cont_loss_std": 0.20425671339035034, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.435199737548828, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004101896658539772, "report/cont_pred": 0.9959148168563843, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06823673844337463, "report/image_loss_std": 0.08913778513669968, "report/model_loss_mean": 0.6873677372932434, "report/model_loss_std": 0.31238579750061035, "report/post_ent_mag": 44.31535339355469, "report/post_ent_max": 44.31535339355469, "report/post_ent_mean": 22.662817001342773, "report/post_ent_min": 14.973183631896973, "report/post_ent_std": 6.49354887008667, "report/prior_ent_mag": 36.50818634033203, "report/prior_ent_max": 36.50818634033203, "report/prior_ent_mean": 21.58855628967285, "report/prior_ent_min": 15.748226165771484, "report/prior_ent_std": 4.450188159942627, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007202148553915322, "report/reward_loss_mean": 0.006374589167535305, "report/reward_loss_std": 0.12808892130851746, "report/reward_max_data": 0.737500011920929, "report/reward_max_pred": 0.03478062152862549, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0023783843498677015, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.094491958618164, "report/reward_pred": 0.0012355215149000287, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02283807471394539, "eval/cont_loss_std": 0.27605071663856506, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.039908409118652, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.00708485534414649, "eval/cont_pred": 0.9954752922058105, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09175265580415726, "eval/image_loss_std": 0.11110225319862366, "eval/model_loss_mean": 0.7359695434570312, "eval/model_loss_std": 0.6147684454917908, "eval/post_ent_mag": 44.83138656616211, "eval/post_ent_max": 44.83138656616211, "eval/post_ent_mean": 22.59950065612793, "eval/post_ent_min": 14.632543563842773, "eval/post_ent_std": 7.046283721923828, "eval/prior_ent_mag": 38.231414794921875, "eval/prior_ent_max": 38.231414794921875, "eval/prior_ent_mean": 21.834613800048828, "eval/prior_ent_min": 16.20421600341797, "eval/prior_ent_std": 4.87224817276001, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0029479980003088713, "eval/reward_loss_mean": 0.02137882076203823, "eval/reward_loss_std": 0.31448057293891907, "eval/reward_max_data": 0.8218749761581421, "eval/reward_max_pred": 0.18179869651794434, "eval/reward_neg_acc": 0.9990195631980896, "eval/reward_neg_loss": 0.0017789239063858986, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.019351959228516, "eval/reward_pred": 0.0009219760540872812, "eval/reward_rate": 0.00390625, "replay/size": 951313.0, "replay/inserts": 31728.0, "replay/samples": 31728.0, "replay/insert_wait_avg": 1.4861184301486956e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.03723397786366e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3038833090599547e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1336188316345, "timer/env.step_count": 3966.0, "timer/env.step_total": 41.38058161735535, "timer/env.step_frac": 0.041375053131097156, "timer/env.step_avg": 0.010433832984708862, "timer/env.step_min": 0.008770942687988281, "timer/env.step_max": 0.04174017906188965, "timer/replay._sample_count": 31728.0, "timer/replay._sample_total": 16.934831619262695, "timer/replay._sample_frac": 0.016932569109161758, "timer/replay._sample_avg": 0.0005337503662147849, "timer/replay._sample_min": 0.00038886070251464844, "timer/replay._sample_max": 0.037374258041381836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4436.0, "timer/agent.policy_total": 50.02688431739807, "timer/agent.policy_frac": 0.050020200676625534, "timer/agent.policy_avg": 0.01127747617614925, "timer/agent.policy_min": 0.009473562240600586, "timer/agent.policy_max": 0.08531451225280762, "timer/dataset_train_count": 1983.0, "timer/dataset_train_total": 0.2437748908996582, "timer/dataset_train_frac": 0.00024374232233532786, "timer/dataset_train_avg": 0.0001229323705999285, "timer/dataset_train_min": 0.00010633468627929688, "timer/dataset_train_max": 0.0006172657012939453, "timer/agent.train_count": 1983.0, "timer/agent.train_total": 896.7075524330139, "timer/agent.train_frac": 0.8965877514252106, "timer/agent.train_avg": 0.4521974545804407, "timer/agent.train_min": 0.4377772808074951, "timer/agent.train_max": 2.8063406944274902, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.49150800704956055, "timer/agent.report_frac": 0.0004914423410981273, "timer/agent.report_avg": 0.24575400352478027, "timer/agent.report_min": 0.24161314964294434, "timer/agent.report_max": 0.2498948574066162, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7176086780614102e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 31.723217787906506}
{"step": 951864, "time": 30283.969749212265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 952056, "time": 30289.899569511414, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 952120, "time": 30291.902958869934, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 952160, "time": 30293.36277961731, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 952272, "time": 30296.831933021545, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 952320, "time": 30298.315258979797, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 952416, "time": 30301.26255917549, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 952512, "time": 30304.21931362152, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 952720, "time": 30310.757234096527, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 952928, "time": 30317.195963859558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 952976, "time": 30318.679235696793, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 953152, "time": 30324.140151262283, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 953400, "time": 30331.58535885811, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 953728, "time": 30342.096570014954, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 953824, "time": 30345.02862763405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 953824, "time": 30345.037853717804, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 953872, "time": 30346.525739192963, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 953920, "time": 30347.990713596344, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 954176, "time": 30355.844254493713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 954520, "time": 30366.323080778122, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 954688, "time": 30371.81630730629, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 954744, "time": 30373.322753190994, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 954760, "time": 30373.824836969376, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 954800, "time": 30375.27851819992, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 954824, "time": 30375.79632949829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 955152, "time": 30386.149296045303, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 955288, "time": 30390.11566710472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 955360, "time": 30392.58970093727, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 955552, "time": 30398.649367570877, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 955936, "time": 30410.46892476082, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 956072, "time": 30414.450546741486, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 956184, "time": 30417.90763759613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 956536, "time": 30428.867547273636, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 956688, "time": 30433.766394615173, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 956832, "time": 30438.21521091461, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 956952, "time": 30441.75254034996, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 957072, "time": 30445.692370653152, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 957136, "time": 30447.669749975204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 957672, "time": 30464.04674911499, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 957864, "time": 30469.96750831604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 957912, "time": 30471.45818066597, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 958024, "time": 30474.907046079636, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 958048, "time": 30475.87690114975, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 958232, "time": 30481.276618242264, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 958432, "time": 30487.614812135696, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 958696, "time": 30496.194239377975, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 958848, "time": 30501.101869106293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 958872, "time": 30501.62272953987, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 959000, "time": 30505.57390022278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 959112, "time": 30509.027645111084, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 959224, "time": 30512.484138011932, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 959360, "time": 30516.904668092728, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 959680, "time": 30526.877038240433, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 959832, "time": 30531.355031490326, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 959864, "time": 30532.356956481934, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 959984, "time": 30536.31629729271, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 959984, "time": 30536.324530124664, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 30538.81894469261, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 960024, "time": 30539.227132081985, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 960024, "time": 30539.384422063828, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 960024, "time": 30539.799711227417, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 960024, "time": 30539.891223192215, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 960024, "time": 30540.23060441017, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 960024, "time": 30540.345488786697, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 960024, "time": 30540.418776988983, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 960496, "time": 30555.35375070572, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 960600, "time": 30558.331520795822, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 960632, "time": 30559.31203532219, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 960640, "time": 30559.782871246338, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 960680, "time": 30560.785420417786, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 961008, "time": 30571.086441755295, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 961416, "time": 30583.583135843277, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 961480, "time": 30585.548516511917, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 961944, "time": 30599.797622919083, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 962080, "time": 30604.189849615097, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 962144, "time": 30606.13890504837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 962176, "time": 30607.12064242363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 962296, "time": 30610.71212720871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 962616, "time": 30620.58837413788, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 962744, "time": 30624.52135157585, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 962912, "time": 30629.900532245636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 963048, "time": 30633.857219696045, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 963144, "time": 30636.78013420105, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 963280, "time": 30641.27915763855, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 963320, "time": 30642.311020374298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 963704, "time": 30654.032809734344, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 963824, "time": 30657.939148187637, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 964344, "time": 30673.873685598373, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 964376, "time": 30674.86922478676, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 964456, "time": 30677.35306429863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 964488, "time": 30678.3478577137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 964904, "time": 30691.187460660934, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 965056, "time": 30696.093950271606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 965128, "time": 30698.106845855713, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 965224, "time": 30701.18547797203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 965456, "time": 30708.590883493423, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 965456, "time": 30708.598405122757, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 965592, "time": 30712.563321113586, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 965640, "time": 30714.045516967773, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 965664, "time": 30715.007903814316, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 965920, "time": 30722.890973091125, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 965952, "time": 30723.881997585297, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 966016, "time": 30725.854160308838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 966032, "time": 30726.376098155975, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 966272, "time": 30733.861404657364, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 966368, "time": 30736.833681821823, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 966608, "time": 30744.221470832825, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 966728, "time": 30748.218210935593, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 967176, "time": 30762.15727353096, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 967216, "time": 30763.613223075867, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 967368, "time": 30768.080988883972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 967488, "time": 30772.015543699265, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 967712, "time": 30778.931680440903, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 967904, "time": 30784.84461760521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 967944, "time": 30785.867736577988, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 968192, "time": 30793.836300849915, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 968328, "time": 30797.80011820793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 968584, "time": 30805.688151359558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 968736, "time": 30810.608144521713, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 968872, "time": 30814.584748506546, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 968920, "time": 30816.08522415161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969264, "time": 30827.059692144394, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 969488, "time": 30833.9379632473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969568, "time": 30836.407124757767, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 969608, "time": 30837.410470485687, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 969784, "time": 30842.889781951904, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 30850.759064912796, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 970008, "time": 30851.139635324478, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 970008, "time": 30851.88483953476, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 970008, "time": 30852.268403053284, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 970008, "time": 30852.339604139328, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 970008, "time": 30852.591336011887, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 970008, "time": 30853.548402786255, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 970008, "time": 30853.847591161728, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 970080, "time": 30856.302468299866, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 970240, "time": 30861.260875940323, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 970256, "time": 30861.769329547882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 970264, "time": 30861.798917770386, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 970504, "time": 30869.206716299057, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 970640, "time": 30873.629363298416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 970784, "time": 30878.07205939293, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 970896, "time": 30881.65491294861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 971120, "time": 30888.5916159153, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 971232, "time": 30892.0460627079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 971256, "time": 30892.56100320816, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 971352, "time": 30895.527985334396, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 971952, "time": 30914.37022447586, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 972096, "time": 30918.807155370712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972120, "time": 30919.352452278137, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 972176, "time": 30921.302062034607, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 972576, "time": 30933.635902881622, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972744, "time": 30938.724605083466, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 972816, "time": 30941.18784379959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972952, "time": 30945.15471315384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972960, "time": 30945.631537914276, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 973176, "time": 30952.069156885147, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 973352, "time": 30957.481989622116, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 973432, "time": 30959.95449733734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 973544, "time": 30963.43500351906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 973640, "time": 30966.426710128784, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 973736, "time": 30969.52749657631, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 973864, "time": 30973.473789215088, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 973984, "time": 30977.402152776718, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 974312, "time": 30987.287546873093, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 974488, "time": 30992.719754457474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 974688, "time": 30999.2916970253, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 974848, "time": 31004.404822587967, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 975144, "time": 31013.615019083023, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 975328, "time": 31019.538201093674, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 975384, "time": 31021.044828653336, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 975488, "time": 31024.48080611229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 975512, "time": 31025.004546165466, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 975664, "time": 31030.066747665405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 975720, "time": 31031.571245908737, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 975832, "time": 31035.04544854164, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 975856, "time": 31036.023535251617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 975880, "time": 31036.546807289124, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 976168, "time": 31045.451035261154, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 976288, "time": 31049.38402581215, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 976400, "time": 31052.815715551376, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 976408, "time": 31052.845147132874, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 976456, "time": 31054.34337925911, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 976624, "time": 31059.850538492203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 976696, "time": 31061.845490932465, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 976728, "time": 31062.8321621418, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 977128, "time": 31075.216478824615, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 977144, "time": 31075.71625518799, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 977224, "time": 31078.18565583229, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 977432, "time": 31084.61559009552, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 977792, "time": 31096.070076465607, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 977976, "time": 31101.57513833046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 978136, "time": 31106.526080608368, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 978168, "time": 31107.523946762085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 978424, "time": 31115.435242652893, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 978544, "time": 31119.50850892067, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 978560, "time": 31120.006556987762, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 978712, "time": 31124.48109960556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 978776, "time": 31126.43932580948, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 978936, "time": 31131.36186361313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 979048, "time": 31134.850645065308, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 979296, "time": 31142.704867839813, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 979456, "time": 31147.63667321205, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 979536, "time": 31150.288161754608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 979696, "time": 31155.23419070244, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 979848, "time": 31159.730667829514, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 979888, "time": 31161.198678970337, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 979952, "time": 31163.209114313126, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 980040, "time": 31165.693514823914, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 980056, "time": 31166.189989089966, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 31168.109961748123, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 980096, "time": 31168.438961982727, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 980096, "time": 31169.198979854584, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 980096, "time": 31169.627618789673, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 980096, "time": 31170.106372117996, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 980096, "time": 31170.198902845383, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 980096, "time": 31170.52028274536, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 980096, "time": 31170.60898208618, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 980304, "time": 31177.041469573975, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 980568, "time": 31185.03328347206, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 980632, "time": 31187.02262210846, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 980720, "time": 31189.96883893013, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 980744, "time": 31190.48978662491, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 981000, "time": 31198.368331193924, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 981024, "time": 31199.33220243454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981056, "time": 31200.32085084915, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 981152, "time": 31203.280650138855, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 981552, "time": 31215.74890446663, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 981568, "time": 31216.24241423607, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 981576, "time": 31216.270359754562, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 981808, "time": 31223.599859952927, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 981848, "time": 31224.608132123947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981888, "time": 31226.094840765, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 982096, "time": 31232.482528209686, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 982336, "time": 31239.984184741974, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 982432, "time": 31242.9401781559, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 982464, "time": 31243.92934155464, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 982512, "time": 31245.43253159523, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 982992, "time": 31260.2329788208, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 983032, "time": 31261.245505809784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 983152, "time": 31265.735050201416, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 983224, "time": 31267.73751974106, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 983336, "time": 31271.31970191002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 983673, "time": 31282.73435330391, "train_stats/mean_log_entropy": 0.08190569223477207, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.582758764525754, "train/action_min": 0.0, "train/action_std": 1.8764208111930731, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010007823059269831, "train/actor_opt_grad_steps": 60390.0, "train/actor_opt_loss": -14.15304157602128, "train/adv_mag": 0.855400464642587, "train/adv_max": 0.3495584588554037, "train/adv_mean": 0.00277688581966791, "train/adv_min": -0.7968716082261436, "train/adv_std": 0.02703329057774352, "train/cont_avg": 0.9946460819723618, "train/cont_loss_mean": 0.018830511583268043, "train/cont_loss_std": 0.24776200453128347, "train/cont_neg_acc": 0.316254075560438, "train/cont_neg_loss": 2.7942433242999654, "train/cont_pos_acc": 0.9999062368019143, "train/cont_pos_loss": 0.0038550534383885227, "train/cont_pred": 0.9946169448857332, "train/cont_rate": 0.9946460819723618, "train/dyn_loss_mean": 1.0000010279554818, "train/dyn_loss_std": 2.879194722829115e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.14623035930434064, "train/extr_critic_critic_opt_grad_steps": 60390.0, "train/extr_critic_critic_opt_loss": 11053.496000510364, "train/extr_critic_mag": 1.3930701358833504, "train/extr_critic_max": 1.3930701358833504, "train/extr_critic_mean": 1.295036391996259, "train/extr_critic_min": 0.9596377167869453, "train/extr_critic_std": 0.025770699848706398, "train/extr_return_normed_mag": 0.9007818956470969, "train/extr_return_normed_max": 0.31601577727638896, "train/extr_return_normed_mean": 0.05215102263805854, "train/extr_return_normed_min": -0.8222367907289284, "train/extr_return_normed_std": 0.03791086048112443, "train/extr_return_rate": 0.9995606661441937, "train/extr_return_raw_mag": 1.5616779489133825, "train/extr_return_raw_max": 1.5616779489133825, "train/extr_return_raw_mean": 1.2978132681630963, "train/extr_return_raw_min": 0.4234253809080651, "train/extr_return_raw_std": 0.03791086027520386, "train/extr_reward_mag": 0.3012172337153449, "train/extr_reward_max": 0.3012172337153449, "train/extr_reward_mean": 0.0020269308105841204, "train/extr_reward_min": 3.5942499362044595e-08, "train/extr_reward_std": 0.008465539245168918, "train/image_loss_mean": 0.07613315627952318, "train/image_loss_std": 0.09377030260748599, "train/model_loss_mean": 0.7084683188840971, "train/model_loss_std": 0.45271643648045745, "train/model_opt_grad_norm": 17.183969315572, "train/model_opt_grad_steps": 60332.668341708544, "train/model_opt_loss": 3720.2337039199906, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5276.381909547738, "train/policy_entropy_mag": 1.3132455402882255, "train/policy_entropy_max": 1.3132455402882255, "train/policy_entropy_mean": 0.10276488742636676, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13180194723995486, "train/policy_logprob_mag": 6.551080258048359, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10269810843407809, "train/policy_logprob_min": -6.551080258048359, "train/policy_logprob_std": 0.6390280951207606, "train/policy_randomness_mag": 0.6748747466197565, "train/policy_randomness_max": 0.6748747466197565, "train/policy_randomness_mean": 0.05281070696573761, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06773280621922795, "train/post_ent_mag": 46.736842169833544, "train/post_ent_max": 46.736842169833544, "train/post_ent_mean": 23.230021146074613, "train/post_ent_min": 14.282039757349983, "train/post_ent_std": 7.419202814150096, "train/prior_ent_mag": 43.36777126369764, "train/prior_ent_max": 43.36777126369764, "train/prior_ent_mean": 23.48870466222715, "train/prior_ent_min": 15.209230312749968, "train/prior_ent_std": 6.297617040087829, "train/rep_loss_mean": 1.0000010279554818, "train/rep_loss_std": 2.879194722829115e-05, "train/reward_avg": 0.001903024041848538, "train/reward_loss_mean": 0.013504010260142573, "train/reward_loss_std": 0.2116276391515106, "train/reward_max_data": 0.7437500017671729, "train/reward_max_pred": 0.2962294840932491, "train/reward_neg_acc": 0.9996651992126925, "train/reward_neg_loss": 0.0023952416239666693, "train/reward_pos_acc": 0.22770563038912686, "train/reward_pos_loss": 3.9928607035448205, "train/reward_pred": 0.0015753236606286549, "train/reward_rate": 0.0027922817211055275, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.013338368386030197, "report/cont_loss_std": 0.17964176833629608, "report/cont_neg_acc": 0.625, "report/cont_neg_loss": 1.1648333072662354, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004271479789167643, "report/cont_pred": 0.9908727407455444, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06996916234493256, "report/image_loss_std": 0.087590791285038, "report/model_loss_mean": 0.6983148455619812, "report/model_loss_std": 0.44512641429901123, "report/post_ent_mag": 46.09789276123047, "report/post_ent_max": 46.09789276123047, "report/post_ent_mean": 22.40916633605957, "report/post_ent_min": 13.71516227722168, "report/post_ent_std": 7.503246307373047, "report/prior_ent_mag": 48.74245071411133, "report/prior_ent_max": 48.74245071411133, "report/prior_ent_mean": 24.723793029785156, "report/prior_ent_min": 14.85472297668457, "report/prior_ent_std": 8.120230674743652, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0018432617653161287, "report/reward_loss_mean": 0.015007291920483112, "report/reward_loss_std": 0.24660144746303558, "report/reward_max_data": 0.671875, "report/reward_max_pred": 0.543192982673645, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.002475363202393055, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 3.210649013519287, "report/reward_pred": 0.002077667973935604, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.019981445744633675, "eval/cont_loss_std": 0.3384197950363159, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.653957366943359, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0034271564800292253, "eval/cont_pred": 0.9966191053390503, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.0829334706068039, "eval/image_loss_std": 0.1020381823182106, "eval/model_loss_mean": 0.7245587110519409, "eval/model_loss_std": 0.7767711281776428, "eval/post_ent_mag": 45.348636627197266, "eval/post_ent_max": 45.348636627197266, "eval/post_ent_mean": 21.540733337402344, "eval/post_ent_min": 13.589473724365234, "eval/post_ent_std": 7.457762241363525, "eval/prior_ent_mag": 48.74245071411133, "eval/prior_ent_max": 48.74245071411133, "eval/prior_ent_mean": 23.97296142578125, "eval/prior_ent_min": 14.443775177001953, "eval/prior_ent_std": 8.045336723327637, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002197265625, "eval/reward_loss_mean": 0.021643806248903275, "eval/reward_loss_std": 0.4096945822238922, "eval/reward_max_data": 0.828125, "eval/reward_max_pred": 0.032453179359436035, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014362129149958491, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.89896297454834, "eval/reward_pred": 0.0007585878483951092, "eval/reward_rate": 0.0029296875, "replay/size": 983169.0, "replay/inserts": 31856.0, "replay/samples": 31856.0, "replay/insert_wait_avg": 1.466046739977727e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.065711907080703e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3456.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3030237621731228e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0176649093628, "timer/env.step_count": 3982.0, "timer/env.step_total": 41.418498516082764, "timer/env.step_frac": 0.041417766874984906, "timer/env.step_avg": 0.010401431068830428, "timer/env.step_min": 0.008801460266113281, "timer/env.step_max": 0.03610038757324219, "timer/replay._sample_count": 31856.0, "timer/replay._sample_total": 16.97786808013916, "timer/replay._sample_frac": 0.016977568172936185, "timer/replay._sample_avg": 0.0005329566825759404, "timer/replay._sample_min": 0.00040268898010253906, "timer/replay._sample_max": 0.025813579559326172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4414.0, "timer/agent.policy_total": 49.974939584732056, "timer/agent.policy_frac": 0.04997405679754824, "timer/agent.policy_avg": 0.011321916534828287, "timer/agent.policy_min": 0.009567022323608398, "timer/agent.policy_max": 0.09387707710266113, "timer/dataset_train_count": 1991.0, "timer/dataset_train_total": 0.24617385864257812, "timer/dataset_train_frac": 0.0002461695100804947, "timer/dataset_train_avg": 0.00012364332428055154, "timer/dataset_train_min": 0.00010728836059570312, "timer/dataset_train_max": 0.0010530948638916016, "timer/agent.train_count": 1991.0, "timer/agent.train_total": 897.0930359363556, "timer/agent.train_frac": 0.8970771891491178, "timer/agent.train_avg": 0.4505741014245884, "timer/agent.train_min": 0.43736720085144043, "timer/agent.train_max": 0.6908345222473145, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4940640926361084, "timer/agent.report_frac": 0.000494055365192862, "timer/agent.report_avg": 0.2470320463180542, "timer/agent.report_min": 0.24561810493469238, "timer/agent.report_max": 0.24844598770141602, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.552436828613281e-05, "timer/dataset_eval_frac": 3.552374076247202e-08, "timer/dataset_eval_avg": 3.552436828613281e-05, "timer/dataset_eval_min": 3.552436828613281e-05, "timer/dataset_eval_max": 3.552436828613281e-05, "fps": 31.854819535623733}
{"step": 983808, "time": 31286.902827501297, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 983968, "time": 31291.833933115005, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 984008, "time": 31292.854939460754, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 984200, "time": 31298.88359284401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 984408, "time": 31305.26561164856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 984432, "time": 31306.250649690628, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 984648, "time": 31312.654863119125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 984888, "time": 31320.016481399536, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 985144, "time": 31327.87562894821, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 985304, "time": 31332.89389038086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 985648, "time": 31343.68963766098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 985664, "time": 31344.18120956421, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 986024, "time": 31355.01570034027, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 986120, "time": 31357.96294951439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 986320, "time": 31364.421130895615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 986496, "time": 31369.810450553894, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 986512, "time": 31370.332355976105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 986600, "time": 31372.80051469803, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 986736, "time": 31377.21496796608, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 986880, "time": 31381.62789797783, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 986936, "time": 31383.129657268524, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 986960, "time": 31384.09194612503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 987048, "time": 31386.602674245834, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 987160, "time": 31390.174380540848, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 987200, "time": 31391.62421798706, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 987496, "time": 31400.45371079445, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 987696, "time": 31406.805367708206, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 987920, "time": 31413.69483065605, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 987952, "time": 31414.702922821045, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 988120, "time": 31419.7800822258, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 988320, "time": 31426.165808439255, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 988400, "time": 31428.659435272217, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 988480, "time": 31431.16454434395, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 989192, "time": 31453.010625600815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 989360, "time": 31458.408629655838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 989400, "time": 31459.435936927795, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 989416, "time": 31459.933582544327, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 989808, "time": 31472.188339710236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 989904, "time": 31475.150205373764, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 31481.664848089218, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 990080, "time": 31482.041184425354, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 990080, "time": 31482.841042280197, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 990080, "time": 31483.121742486954, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 990080, "time": 31484.520634889603, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 990080, "time": 31484.695437192917, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 990080, "time": 31484.891047477722, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 990080, "time": 31484.965460062027, "eval_episode/length": 195.0, "eval_episode/score": 0.390625, "eval_episode/reward_rate": 0.00510204081632653}
{"step": 990232, "time": 31489.41431951523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 990280, "time": 31490.88226056099, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 990384, "time": 31494.317814588547, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 990432, "time": 31495.796988725662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 990488, "time": 31497.29775595665, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 990560, "time": 31499.73909330368, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 990712, "time": 31504.189354896545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 990880, "time": 31509.724747657776, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 991136, "time": 31517.58864927292, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 991368, "time": 31525.00806069374, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 991544, "time": 31530.44500899315, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 991648, "time": 31533.87079691887, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 991936, "time": 31542.82408261299, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 991984, "time": 31544.327675819397, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 992032, "time": 31545.809156894684, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 992216, "time": 31551.2509162426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 992416, "time": 31557.62048435211, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 992488, "time": 31559.655148267746, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 992656, "time": 31565.01891374588, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 992696, "time": 31566.03213787079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 992944, "time": 31574.00693178177, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 993024, "time": 31576.454439163208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 993064, "time": 31577.46340250969, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 993192, "time": 31581.41734457016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 993504, "time": 31591.225297927856, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 993696, "time": 31597.07168698311, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 993712, "time": 31597.589340686798, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 993800, "time": 31600.210861206055, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 993872, "time": 31602.63844394684, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 993984, "time": 31606.025394439697, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 994160, "time": 31611.39880156517, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 994296, "time": 31615.35198187828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 994464, "time": 31620.712557315826, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 994496, "time": 31621.698123693466, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 994528, "time": 31622.702943086624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 994624, "time": 31625.633551836014, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 994696, "time": 31627.62644124031, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 994816, "time": 31631.645282268524, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 995128, "time": 31640.988183259964, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 995184, "time": 31642.948229789734, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 995192, "time": 31642.97987985611, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 995368, "time": 31648.404745340347, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 995760, "time": 31660.742921829224, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 996024, "time": 31668.67864894867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 996056, "time": 31669.65994977951, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 996144, "time": 31672.598960399628, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 996440, "time": 31681.488097667694, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 996616, "time": 31686.88823056221, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 996736, "time": 31690.88761138916, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 996840, "time": 31693.882426261902, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 996848, "time": 31694.35401725769, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 996936, "time": 31696.847501039505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 997296, "time": 31708.209327220917, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 997304, "time": 31708.23951292038, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 997320, "time": 31708.741717100143, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 997472, "time": 31713.632296085358, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 997760, "time": 31722.637170791626, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 997912, "time": 31727.096792697906, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 997976, "time": 31729.07366681099, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 998368, "time": 31741.426175117493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 998448, "time": 31743.893629074097, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 998760, "time": 31753.40045619011, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 998768, "time": 31753.870408058167, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 998928, "time": 31758.803920030594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 999216, "time": 31767.699023723602, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 999248, "time": 31768.693823099136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 999320, "time": 31770.71460723877, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 999568, "time": 31779.295167684555, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 999632, "time": 31781.27082133293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 999696, "time": 31783.23246717453, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 999784, "time": 31785.7122194767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 31795.262231349945, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 1000064, "time": 31795.630516290665, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1000064, "time": 31796.151418685913, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1000064, "time": 31796.830419063568, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1000064, "time": 31796.988079547882, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1000064, "time": 31798.647533416748, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1000064, "time": 31798.675992250443, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1000064, "time": 31800.79073739052, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 31800.80494737625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 31800.815220594406, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 31800.822451114655, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000064, "time": 31800.82963848114, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1000216, "time": 31805.27843761444, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1000288, "time": 31807.742807149887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000416, "time": 31811.760429382324, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1000464, "time": 31813.252753973007, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1000600, "time": 31817.198498249054, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1000672, "time": 31819.631522655487, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1000896, "time": 31826.479436397552, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1001368, "time": 31840.92801117897, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1001416, "time": 31842.414698839188, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1001528, "time": 31845.862703084946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1001528, "time": 31845.874042749405, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1001608, "time": 31848.355974912643, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1001616, "time": 31848.829914331436, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1001624, "time": 31848.86096262932, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1001944, "time": 31858.69889855385, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1001944, "time": 31858.708426237106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1002136, "time": 31864.606838703156, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1002344, "time": 31871.155967473984, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1002528, "time": 31877.078265428543, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1002640, "time": 31880.5074570179, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1002712, "time": 31882.513912200928, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1002736, "time": 31883.481310367584, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1002864, "time": 31887.436571359634, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1003072, "time": 31893.834567308426, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1003320, "time": 31901.339313983917, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1003512, "time": 31907.216175556183, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1003608, "time": 31910.167631864548, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1003928, "time": 31920.004869937897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1004136, "time": 31926.408135414124, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1004256, "time": 31930.42156600952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1004288, "time": 31931.4347281456, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1004624, "time": 31941.79188466072, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1004768, "time": 31946.235584020615, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1004952, "time": 31951.68706560135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1005048, "time": 31954.643555164337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1005216, "time": 31960.174090385437, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1005360, "time": 31964.60799384117, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1005512, "time": 31969.05709719658, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1005544, "time": 31970.045616865158, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1005712, "time": 31975.47328352928, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1005824, "time": 31978.925672531128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1005944, "time": 31982.41860795021, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1006144, "time": 31988.914642572403, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1006168, "time": 31989.434133052826, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1006360, "time": 31995.361444234848, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1006384, "time": 31996.340460777283, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1006384, "time": 31996.35124373436, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1006440, "time": 31997.881147623062, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 1006600, "time": 32002.82633447647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1006864, "time": 32011.17384648323, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1006936, "time": 32013.169897317886, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1007056, "time": 32017.107150793076, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1007264, "time": 32023.647260189056, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1007368, "time": 32026.629977941513, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1007608, "time": 32034.035171747208, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1007712, "time": 32038.006476163864, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1007736, "time": 32038.525226831436, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1007776, "time": 32039.975220680237, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1007944, "time": 32044.938010931015, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1008168, "time": 32051.975239753723, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1008280, "time": 32055.42628645897, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1008488, "time": 32061.85888028145, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 1008672, "time": 32067.7428586483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1008712, "time": 32068.759130477905, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1009080, "time": 32080.260064840317, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1009088, "time": 32080.73579597473, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1009112, "time": 32081.2534096241, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1009184, "time": 32083.683056116104, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1009920, "time": 32106.23217368126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1009936, "time": 32106.736574411392, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1010000, "time": 32108.833483934402, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1010008, "time": 32108.864139080048, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 32110.853299856186, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 1010048, "time": 32111.41547846794, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 1010048, "time": 32112.025809049606, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1010048, "time": 32112.055060863495, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1010048, "time": 32112.788409471512, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 1010048, "time": 32113.00629878044, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 1010048, "time": 32113.739087343216, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1010048, "time": 32113.87030673027, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1010176, "time": 32117.805213451385, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1010208, "time": 32118.80723309517, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1010256, "time": 32120.27843427658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1010568, "time": 32129.698669672012, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1010704, "time": 32134.123936891556, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1010840, "time": 32138.126517534256, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1010872, "time": 32139.2487680912, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1010984, "time": 32142.697969913483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1011024, "time": 32144.174062013626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1011096, "time": 32146.150794267654, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1011176, "time": 32148.637368679047, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1011368, "time": 32154.59814786911, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1011488, "time": 32158.50747871399, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1011624, "time": 32162.42168712616, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1011680, "time": 32164.378538131714, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1012184, "time": 32179.708833694458, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1012216, "time": 32180.6917886734, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1012232, "time": 32181.19492673874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1012520, "time": 32190.024137735367, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1012528, "time": 32190.49710702896, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1012928, "time": 32202.88451743126, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1013024, "time": 32205.80600833893, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1013152, "time": 32209.738442897797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1013200, "time": 32211.212951660156, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1013336, "time": 32215.197264909744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1013376, "time": 32216.645484924316, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1013640, "time": 32224.575221300125, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1014120, "time": 32239.465077877045, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1014120, "time": 32239.47369670868, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1014408, "time": 32248.335089683533, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1014544, "time": 32252.74137878418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1014832, "time": 32261.77396798134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1014832, "time": 32261.78208756447, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1014880, "time": 32263.29247713089, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1015112, "time": 32270.254620313644, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1015168, "time": 32272.227180957794, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1015304, "time": 32276.188813447952, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1015336, "time": 32277.200021505356, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1015464, "time": 32281.143483161926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1015472, "time": 32281.63817167282, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1015497, "time": 32283.205581188202, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6078929805276383, "train/action_min": 0.0, "train/action_std": 1.881281514862674, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011388871940461235, "train/actor_opt_grad_steps": 62380.0, "train/actor_opt_loss": -14.23437759355085, "train/adv_mag": 0.9172808171516686, "train/adv_max": 0.351826999654722, "train/adv_mean": 0.0013011501927092778, "train/adv_min": -0.845730910049611, "train/adv_std": 0.027375134681562083, "train/cont_avg": 0.9947344142587939, "train/cont_loss_mean": 0.01823964815858246, "train/cont_loss_std": 0.23830579556805553, "train/cont_neg_acc": 0.31556281326385927, "train/cont_neg_loss": 2.6900503885247367, "train/cont_pos_acc": 0.9998125817308474, "train/cont_pos_loss": 0.003956906677658983, "train/cont_pred": 0.994583665426053, "train/cont_rate": 0.9947344142587939, "train/dyn_loss_mean": 1.0000183732066321, "train/dyn_loss_std": 0.0005652083311552866, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1118476573125127, "train/extr_critic_critic_opt_grad_steps": 62380.0, "train/extr_critic_critic_opt_loss": 13120.903757066582, "train/extr_critic_mag": 1.4496134884992438, "train/extr_critic_max": 1.4496134884992438, "train/extr_critic_mean": 1.350110836364516, "train/extr_critic_min": 0.9833203308546363, "train/extr_critic_std": 0.0244516853767274, "train/extr_return_normed_mag": 0.9185945595329131, "train/extr_return_normed_max": 0.2900411046330054, "train/extr_return_normed_mean": 0.047289159261251816, "train/extr_return_normed_min": -0.8477938675401199, "train/extr_return_normed_std": 0.03722457564318899, "train/extr_return_rate": 0.9995511785224455, "train/extr_return_raw_mag": 1.5941637634631975, "train/extr_return_raw_max": 1.5941637634631975, "train/extr_return_raw_mean": 1.3514118841545066, "train/extr_return_raw_min": 0.45632879129007237, "train/extr_return_raw_std": 0.03722457573678925, "train/extr_reward_mag": 0.27075915719995547, "train/extr_reward_max": 0.27075915719995547, "train/extr_reward_mean": 0.0020129627357447642, "train/extr_reward_min": 1.2579874776715609e-08, "train/extr_reward_std": 0.008244007602380823, "train/image_loss_mean": 0.07631034465815553, "train/image_loss_std": 0.09329553420220188, "train/model_loss_mean": 0.7080679907271611, "train/model_loss_std": 0.439944908172641, "train/model_opt_grad_norm": 17.374714230046127, "train/model_opt_grad_steps": 62320.75879396985, "train/model_opt_loss": 3699.3357228034706, "train/model_opt_model_opt_grad_overflow": 0.005025125628140704, "train/model_opt_model_opt_grad_scale": 5226.130653266332, "train/policy_entropy_mag": 1.3042287694748922, "train/policy_entropy_max": 1.3042287694748922, "train/policy_entropy_mean": 0.09928095580345422, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12695738489753636, "train/policy_logprob_mag": 6.551080241275193, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09893305588457453, "train/policy_logprob_min": -6.551080241275193, "train/policy_logprob_std": 0.6346082453751684, "train/policy_randomness_mag": 0.6702410419981684, "train/policy_randomness_max": 0.6702410419981684, "train/policy_randomness_mean": 0.0510203205423439, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06524319385164347, "train/post_ent_mag": 50.24129064358659, "train/post_ent_max": 50.24129064358659, "train/post_ent_mean": 24.1097093706754, "train/post_ent_min": 13.982211812656729, "train/post_ent_std": 8.445621291596686, "train/prior_ent_mag": 53.28119500318364, "train/prior_ent_max": 53.28119500318364, "train/prior_ent_mean": 24.974352697631222, "train/prior_ent_min": 13.541092685718633, "train/prior_ent_std": 9.117044506360537, "train/rep_loss_mean": 1.0000183732066321, "train/rep_loss_std": 0.0005652083311552866, "train/reward_avg": 0.0019456412879096101, "train/reward_loss_mean": 0.013506954028060538, "train/reward_loss_std": 0.20671397508660228, "train/reward_max_data": 0.7445979870893248, "train/reward_max_pred": 0.3004256013649792, "train/reward_neg_acc": 0.9996209998226645, "train/reward_neg_loss": 0.0024942639687487002, "train/reward_pos_acc": 0.26010638562605737, "train/reward_pos_loss": 3.8218654324399663, "train/reward_pred": 0.0015779596211706948, "train/reward_rate": 0.0028462625628140705, "train_stats/mean_log_entropy": 0.08631007906955641, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.012960545718669891, "report/cont_loss_std": 0.15944141149520874, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 1.7505954504013062, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0044343676418066025, "report/cont_pred": 0.9938387274742126, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07559339702129364, "report/image_loss_std": 0.09661120176315308, "report/model_loss_mean": 0.7021811604499817, "report/model_loss_std": 0.3948567807674408, "report/post_ent_mag": 54.4715690612793, "report/post_ent_max": 54.4715690612793, "report/post_ent_mean": 25.12762451171875, "report/post_ent_min": 14.564644813537598, "report/post_ent_std": 8.681193351745605, "report/prior_ent_mag": 55.33647537231445, "report/prior_ent_max": 55.33647537231445, "report/prior_ent_mean": 26.9056396484375, "report/prior_ent_min": 14.44582748413086, "report/prior_ent_std": 9.198307037353516, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0020477294456213713, "report/reward_loss_mean": 0.01362723857164383, "report/reward_loss_std": 0.203153595328331, "report/reward_max_data": 0.75, "report/reward_max_pred": 0.10073769092559814, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0029097350779920816, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.66115140914917, "report/reward_pred": 0.0016165326815098524, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.0486898310482502, "eval/cont_loss_std": 0.5845745801925659, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.653203964233398, "eval/cont_pos_acc": 0.9990166425704956, "eval/cont_pos_loss": 0.00323103042319417, "eval/cont_pred": 0.9970341920852661, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.11228989064693451, "eval/image_loss_std": 0.1203739121556282, "eval/model_loss_mean": 0.7821957468986511, "eval/model_loss_std": 0.849137544631958, "eval/post_ent_mag": 53.381996154785156, "eval/post_ent_max": 53.381996154785156, "eval/post_ent_mean": 23.806598663330078, "eval/post_ent_min": 13.756072998046875, "eval/post_ent_std": 9.91358470916748, "eval/prior_ent_mag": 54.8362922668457, "eval/prior_ent_max": 54.8362922668457, "eval/prior_ent_mean": 25.18715476989746, "eval/prior_ent_min": 12.86520004272461, "eval/prior_ent_std": 10.657483100891113, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0019775391556322575, "eval/reward_loss_mean": 0.021215997636318207, "eval/reward_loss_std": 0.37086325883865356, "eval/reward_max_data": 0.887499988079071, "eval/reward_max_pred": 0.22968578338623047, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.0018532525282353163, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.611003398895264, "eval/reward_pred": 0.000943568185903132, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 31824.0, "replay/samples": 31824.0, "replay/insert_wait_avg": 1.4696185944846314e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.025200538385927e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5176.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2595281350373117e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4336495399475, "timer/env.step_count": 3978.0, "timer/env.step_total": 41.61780381202698, "timer/env.step_frac": 0.04159976409346592, "timer/env.step_avg": 0.010461991908503514, "timer/env.step_min": 0.008928775787353516, "timer/env.step_max": 0.03648805618286133, "timer/replay._sample_count": 31824.0, "timer/replay._sample_total": 16.961100339889526, "timer/replay._sample_frac": 0.01695374835471512, "timer/replay._sample_avg": 0.0005329656969547991, "timer/replay._sample_min": 0.00042629241943359375, "timer/replay._sample_max": 0.011223793029785156, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4625.0, "timer/agent.policy_total": 52.02148962020874, "timer/agent.policy_frac": 0.0519989403036683, "timer/agent.policy_avg": 0.0112478896476127, "timer/agent.policy_min": 0.00944828987121582, "timer/agent.policy_max": 0.08925795555114746, "timer/dataset_train_count": 1989.0, "timer/dataset_train_total": 0.24977326393127441, "timer/dataset_train_frac": 0.0002496649968202623, "timer/dataset_train_avg": 0.00012557730715498966, "timer/dataset_train_min": 0.00010776519775390625, "timer/dataset_train_max": 0.0006413459777832031, "timer/agent.train_count": 1989.0, "timer/agent.train_total": 892.9971339702606, "timer/agent.train_frac": 0.8926100540309776, "timer/agent.train_avg": 0.4489678903822326, "timer/agent.train_min": 0.43687868118286133, "timer/agent.train_max": 0.7042384147644043, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5008115768432617, "timer/agent.report_frac": 0.0005005944942711208, "timer/agent.report_avg": 0.25040578842163086, "timer/agent.report_min": 0.24269318580627441, "timer/agent.report_max": 0.2581183910369873, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8597828057206994e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 31.809665786343224}
{"step": 1015680, "time": 32289.029770851135, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1015800, "time": 32292.524884700775, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1015952, "time": 32298.001552820206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1016008, "time": 32299.517237901688, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1016160, "time": 32304.449388742447, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1016544, "time": 32316.271821260452, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1017480, "time": 32345.012183904648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1017616, "time": 32349.582387924194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1017648, "time": 32350.573854207993, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1017760, "time": 32354.036479473114, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 1017776, "time": 32354.535956144333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1017992, "time": 32360.951271533966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018320, "time": 32371.22236251831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018392, "time": 32373.23249912262, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1018472, "time": 32375.713053941727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018528, "time": 32377.683070898056, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1018568, "time": 32378.835062742233, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1018624, "time": 32380.784606695175, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1018792, "time": 32385.740172624588, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1018840, "time": 32387.23563337326, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1018984, "time": 32391.657655000687, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1019000, "time": 32392.170867919922, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1019368, "time": 32403.49408340454, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1019440, "time": 32405.92694067955, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1019504, "time": 32407.91661810875, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1019664, "time": 32412.988256931305, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1019808, "time": 32417.39566540718, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1019928, "time": 32420.833639860153, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1020032, "time": 32425.368096113205, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1020032, "time": 32425.46102619171, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1020032, "time": 32425.912407159805, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1020032, "time": 32425.961977005005, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1020032, "time": 32426.329771518707, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1020032, "time": 32426.65631723404, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1020032, "time": 32427.17024254799, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1020032, "time": 32427.26509284973, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1020304, "time": 32435.612782001495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1020432, "time": 32439.67053103447, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1020536, "time": 32442.62754559517, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1020728, "time": 32448.51839208603, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1020880, "time": 32453.397464990616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1020952, "time": 32455.410143613815, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1021296, "time": 32466.2609603405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1021344, "time": 32467.755734205246, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1021680, "time": 32478.256950855255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1021912, "time": 32485.207208395004, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1021936, "time": 32486.18263578415, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1021976, "time": 32487.195283412933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1022120, "time": 32491.637758493423, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1022416, "time": 32501.17721414566, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1022512, "time": 32504.1683447361, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1022672, "time": 32509.121316432953, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1022800, "time": 32513.05193710327, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1022904, "time": 32516.055862665176, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1022936, "time": 32517.0465760231, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1023040, "time": 32520.493937015533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1023192, "time": 32524.985261917114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1023248, "time": 32526.939448833466, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1023256, "time": 32526.969936847687, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1023536, "time": 32535.989726543427, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1023608, "time": 32538.01924085617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1023728, "time": 32541.951858758926, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1024168, "time": 32555.784599542618, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1024168, "time": 32555.79244017601, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1024288, "time": 32559.858287334442, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1024336, "time": 32561.338527202606, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1024400, "time": 32563.307771921158, "episode/length": 215.0, "episode/score": 0.328125, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.0}
{"step": 1024808, "time": 32575.668328285217, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1024832, "time": 32576.639342308044, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 1024888, "time": 32578.143879890442, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1025112, "time": 32585.075060606003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1025224, "time": 32588.678457260132, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1025248, "time": 32589.66246032715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1025464, "time": 32596.06973838806, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1025488, "time": 32597.035927057266, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1025584, "time": 32600.034641981125, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1025896, "time": 32609.45246386528, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1025960, "time": 32611.421853780746, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1026048, "time": 32614.375379562378, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1026056, "time": 32614.4063975811, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1026088, "time": 32615.40331053734, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1026568, "time": 32630.389011383057, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1026600, "time": 32631.381048202515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1026616, "time": 32631.890393018723, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1026640, "time": 32632.85866522789, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1026640, "time": 32632.866112947464, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1026648, "time": 32632.896719694138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1026912, "time": 32641.3134868145, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1027072, "time": 32646.306475400925, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1027200, "time": 32650.423845529556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1027264, "time": 32652.39895415306, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1027264, "time": 32652.40789246559, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1027760, "time": 32667.84485077858, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1027864, "time": 32670.850108146667, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1027960, "time": 32673.824179172516, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1028152, "time": 32679.857508420944, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1028248, "time": 32682.824797153473, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1028272, "time": 32683.818551301956, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1028448, "time": 32689.270052433014, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1028544, "time": 32692.21781849861, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1028952, "time": 32704.658504724503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1028952, "time": 32704.673553466797, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1028960, "time": 32705.163737535477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1028968, "time": 32705.19313120842, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1029128, "time": 32710.293817281723, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1029152, "time": 32711.262457609177, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1029392, "time": 32718.69161748886, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1029704, "time": 32728.08813238144, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1029792, "time": 32731.02057337761, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1029792, "time": 32731.028628349304, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1030016, "time": 32738.93260884285, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 1030016, "time": 32739.30593085289, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1030016, "time": 32740.002866744995, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1030016, "time": 32740.230231761932, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1030016, "time": 32740.96201324463, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1030016, "time": 32741.339628219604, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1030016, "time": 32741.853729963303, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 1030016, "time": 32742.158304929733, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1030128, "time": 32745.627159118652, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1030560, "time": 32758.982828617096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1030832, "time": 32767.405062913895, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1030856, "time": 32767.937601566315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1031056, "time": 32774.4524409771, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1031224, "time": 32779.40490579605, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1031280, "time": 32781.36914944649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1031464, "time": 32786.83122396469, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1031608, "time": 32791.30481505394, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1031608, "time": 32791.31226658821, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1031896, "time": 32800.339451789856, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1032000, "time": 32803.79527378082, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1032104, "time": 32806.787093400955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1032280, "time": 32812.76321768761, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1032392, "time": 32816.20570254326, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1032432, "time": 32817.68414616585, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1032872, "time": 32831.11706018448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1032888, "time": 32831.620062589645, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1033040, "time": 32836.52598786354, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1033184, "time": 32840.981351614, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1033264, "time": 32843.455436229706, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1033472, "time": 32849.859090805054, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1033632, "time": 32854.80939126015, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1033736, "time": 32857.79592490196, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 1033920, "time": 32863.79623866081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1034104, "time": 32869.247405052185, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1034464, "time": 32880.54945588112, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1034648, "time": 32886.01071739197, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1034744, "time": 32889.1361451149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1035216, "time": 32903.97689509392, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1035240, "time": 32904.49850201607, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1035336, "time": 32907.48914885521, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 1035352, "time": 32907.99036383629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1035496, "time": 32912.43770647049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1035784, "time": 32921.46733593941, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1035848, "time": 32923.47985672951, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1036416, "time": 32941.31991791725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1036816, "time": 32953.83379006386, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1036960, "time": 32958.303987026215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1037320, "time": 32969.198514699936, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1037528, "time": 32975.60983920097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1037552, "time": 32976.62064790726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1037648, "time": 32979.70483851433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1037808, "time": 32984.655092954636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1037856, "time": 32986.12345170975, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1037880, "time": 32986.6652905941, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1038160, "time": 32995.51880311966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1038376, "time": 33002.00022673607, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1038504, "time": 33005.94026350975, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1038608, "time": 33009.52592611313, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1038728, "time": 33013.034182310104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1038728, "time": 33013.041917324066, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1038888, "time": 33018.01765036583, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1038928, "time": 33019.48805689812, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1039128, "time": 33025.40301203728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1039232, "time": 33028.829486846924, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1039248, "time": 33029.32531499863, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1039408, "time": 33034.26820707321, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1039424, "time": 33034.7716217041, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1039440, "time": 33035.27814388275, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1039792, "time": 33046.310905218124, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1039928, "time": 33050.25181365013, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1040000, "time": 33053.84793305397, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1040000, "time": 33054.37030529976, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1040000, "time": 33054.76423192024, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1040000, "time": 33054.796023607254, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 1040000, "time": 33054.82534337044, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1040000, "time": 33055.62624025345, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 1040000, "time": 33056.02401423454, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1040000, "time": 33056.70082330704, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1040296, "time": 33065.592276096344, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1040312, "time": 33066.08582687378, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1040472, "time": 33071.66194200516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1040632, "time": 33076.59958863258, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 1040656, "time": 33077.57326030731, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1040824, "time": 33082.53437399864, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1041000, "time": 33087.98704075813, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1041040, "time": 33089.45444178581, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1041216, "time": 33094.850140571594, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1041568, "time": 33105.818445920944, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1041720, "time": 33110.294167518616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1041744, "time": 33111.25750851631, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1042032, "time": 33120.110181331635, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 1042248, "time": 33126.49907851219, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1042312, "time": 33128.58883976936, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1042576, "time": 33136.9378528595, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1042608, "time": 33137.931755542755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1042944, "time": 33148.3254802227, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1043144, "time": 33154.34350991249, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1043312, "time": 33159.8353331089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1043344, "time": 33160.80868887901, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1043352, "time": 33160.83952307701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1043496, "time": 33165.24136710167, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1043696, "time": 33171.62435603142, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1043912, "time": 33178.03070306778, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1044160, "time": 33185.933926820755, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1044248, "time": 33188.55379509926, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1044320, "time": 33191.007563352585, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1044344, "time": 33191.53148770332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1044384, "time": 33193.01033806801, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1044400, "time": 33193.5091919899, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1044560, "time": 33198.47366452217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1044640, "time": 33200.96138739586, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1044928, "time": 33209.867285490036, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1044944, "time": 33210.363444805145, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1044960, "time": 33210.8643078804, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1044960, "time": 33210.8895816803, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1045336, "time": 33222.41224884987, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1045408, "time": 33224.89969277382, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1045568, "time": 33229.83472561836, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1045624, "time": 33231.33857154846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1045672, "time": 33232.82104229927, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1046128, "time": 33247.13916826248, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1046160, "time": 33248.12370324135, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1046200, "time": 33249.295078754425, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1046264, "time": 33251.26891732216, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1046536, "time": 33259.67367243767, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1046920, "time": 33271.49743723869, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1046952, "time": 33272.49048781395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1047192, "time": 33280.042919158936, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1047256, "time": 33282.01337766647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1047273, "time": 33283.61065721512, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6204818571456756, "train/action_min": 0.0, "train/action_std": 1.8573426092513885, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010363009364362994, "train/actor_opt_grad_steps": 64365.0, "train/actor_opt_loss": -15.983505778842503, "train/adv_mag": 0.8664825892809666, "train/adv_max": 0.38087709925391455, "train/adv_mean": 0.0010549661807512753, "train/adv_min": -0.7954990595880181, "train/adv_std": 0.026861373640860272, "train/cont_avg": 0.9948163273358586, "train/cont_loss_mean": 0.018742874462270374, "train/cont_loss_std": 0.24095660976294164, "train/cont_neg_acc": 0.27227542895560314, "train/cont_neg_loss": 2.8252972049601586, "train/cont_pos_acc": 0.9998264228454744, "train/cont_pos_loss": 0.004116191268860918, "train/cont_pred": 0.9946403894761596, "train/cont_rate": 0.9948163273358586, "train/dyn_loss_mean": 1.0000065559088582, "train/dyn_loss_std": 0.0001946186712670206, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09646803333019519, "train/extr_critic_critic_opt_grad_steps": 64365.0, "train/extr_critic_critic_opt_loss": 13205.507610282513, "train/extr_critic_mag": 1.4997146623303192, "train/extr_critic_max": 1.4997146623303192, "train/extr_critic_mean": 1.397250508419191, "train/extr_critic_min": 1.0049592443186828, "train/extr_critic_std": 0.0268544415012002, "train/extr_return_normed_mag": 0.905191011501081, "train/extr_return_normed_max": 0.3064255431444958, "train/extr_return_normed_mean": 0.049898226670168265, "train/extr_return_normed_min": -0.8221994831104471, "train/extr_return_normed_std": 0.038064494587932575, "train/extr_return_rate": 0.9996330846439708, "train/extr_return_raw_mag": 1.654832823710008, "train/extr_return_raw_max": 1.654832823710008, "train/extr_return_raw_mean": 1.3983055720425615, "train/extr_return_raw_min": 0.5262077974550652, "train/extr_return_raw_std": 0.038064494738449355, "train/extr_reward_mag": 0.28906470115738686, "train/extr_reward_max": 0.28906470115738686, "train/extr_reward_mean": 0.0019482361488491109, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.008316755714600511, "train/image_loss_mean": 0.07865090562839701, "train/image_loss_std": 0.09544511782852086, "train/model_loss_mean": 0.7116893168651697, "train/model_loss_std": 0.45302424677694686, "train/model_opt_grad_norm": 16.909161697734486, "train/model_opt_grad_steps": 64303.85858585859, "train/model_opt_loss": 3665.6466249408145, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5151.515151515152, "train/policy_entropy_mag": 1.3223747894017384, "train/policy_entropy_max": 1.3223747894017384, "train/policy_entropy_mean": 0.09872125488038015, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12484031008801075, "train/policy_logprob_mag": 6.551080241347805, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09865032290719976, "train/policy_logprob_min": -6.551080241347805, "train/policy_logprob_std": 0.6354450101804252, "train/policy_randomness_mag": 0.6795662512080838, "train/policy_randomness_max": 0.6795662512080838, "train/policy_randomness_mean": 0.05073269072807196, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06415523283860901, "train/post_ent_mag": 52.87952529059516, "train/post_ent_max": 52.87952529059516, "train/post_ent_mean": 24.065976846097694, "train/post_ent_min": 13.15270313590464, "train/post_ent_std": 9.183409642691563, "train/prior_ent_mag": 54.8949567428743, "train/prior_ent_max": 54.8949567428743, "train/prior_ent_mean": 24.9772527675436, "train/prior_ent_min": 13.23700914960919, "train/prior_ent_std": 9.651974858659687, "train/rep_loss_mean": 1.0000065559088582, "train/rep_loss_std": 0.0001946186712670206, "train/reward_avg": 0.0020202328533291667, "train/reward_loss_mean": 0.014291582208107969, "train/reward_loss_std": 0.21577783841451612, "train/reward_max_data": 0.7764046694895234, "train/reward_max_pred": 0.26955916303576843, "train/reward_neg_acc": 0.9995843731995785, "train/reward_neg_loss": 0.0025895321003815176, "train/reward_pos_acc": 0.20606897556290185, "train/reward_pos_loss": 3.9182269345853746, "train/reward_pred": 0.0015872862540430041, "train/reward_rate": 0.002934619633838384, "train_stats/mean_log_entropy": 0.08582475857679234, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.016821295022964478, "report/cont_loss_std": 0.24427685141563416, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.7232539653778076, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0035414500162005424, "report/cont_pred": 0.9945980906486511, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06535475701093674, "report/image_loss_std": 0.08417225629091263, "report/model_loss_mean": 0.6943776607513428, "report/model_loss_std": 0.4826095700263977, "report/post_ent_mag": 45.45447540283203, "report/post_ent_max": 45.45447540283203, "report/post_ent_mean": 19.3547306060791, "report/post_ent_min": 11.76177978515625, "report/post_ent_std": 7.938978672027588, "report/prior_ent_mag": 50.75940704345703, "report/prior_ent_max": 50.75940704345703, "report/prior_ent_mean": 21.95803451538086, "report/prior_ent_min": 12.905531883239746, "report/prior_ent_std": 8.865009307861328, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0014709471724927425, "report/reward_loss_mean": 0.012201543897390366, "report/reward_loss_std": 0.233818918466568, "report/reward_max_data": 0.8062499761581421, "report/reward_max_pred": 0.08417737483978271, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0018735319608822465, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.2898149490356445, "report/reward_pred": 0.0009717983193695545, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.014171757735311985, "eval/cont_loss_std": 0.19929835200309753, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.6822688579559326, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0033938023261725903, "eval/cont_pred": 0.9965826869010925, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.08799315989017487, "eval/image_loss_std": 0.09895734488964081, "eval/model_loss_mean": 0.7187610864639282, "eval/model_loss_std": 0.49622148275375366, "eval/post_ent_mag": 46.78703689575195, "eval/post_ent_max": 46.78703689575195, "eval/post_ent_mean": 20.271621704101562, "eval/post_ent_min": 11.777274131774902, "eval/post_ent_std": 8.319829940795898, "eval/prior_ent_mag": 52.6953125, "eval/prior_ent_max": 52.6953125, "eval/prior_ent_mean": 23.254243850708008, "eval/prior_ent_min": 12.618889808654785, "eval/prior_ent_std": 9.198770523071289, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0020599365234375, "eval/reward_loss_mean": 0.016596106812357903, "eval/reward_loss_std": 0.2663295567035675, "eval/reward_max_data": 0.7593749761581421, "eval/reward_max_pred": 0.22014451026916504, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.0023779498878866434, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.855508804321289, "eval/reward_pred": 0.0012098297011107206, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 31776.0, "replay/samples": 31776.0, "replay/insert_wait_avg": 1.455676879767565e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.063058838743458e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3824.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.303758082529491e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3215811252594, "timer/env.step_count": 3972.0, "timer/env.step_total": 41.95111036300659, "timer/env.step_frac": 0.041937624014685246, "timer/env.step_avg": 0.010561709557655235, "timer/env.step_min": 0.008794307708740234, "timer/env.step_max": 0.04889965057373047, "timer/replay._sample_count": 31776.0, "timer/replay._sample_total": 17.03918981552124, "timer/replay._sample_frac": 0.017033712095218315, "timer/replay._sample_avg": 0.000536228279692889, "timer/replay._sample_min": 0.0004265308380126953, "timer/replay._sample_max": 0.02817082405090332, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4450.0, "timer/agent.policy_total": 50.72028923034668, "timer/agent.policy_frac": 0.05070398378618558, "timer/agent.policy_avg": 0.011397817804572288, "timer/agent.policy_min": 0.009467124938964844, "timer/agent.policy_max": 0.08678770065307617, "timer/dataset_train_count": 1986.0, "timer/dataset_train_total": 0.25114870071411133, "timer/dataset_train_frac": 0.00025106796199637595, "timer/dataset_train_avg": 0.00012645956732835415, "timer/dataset_train_min": 0.00010848045349121094, "timer/dataset_train_max": 0.0010559558868408203, "timer/agent.train_count": 1986.0, "timer/agent.train_total": 895.0737357139587, "timer/agent.train_frac": 0.894785989428612, "timer/agent.train_avg": 0.4506917098257597, "timer/agent.train_min": 0.4366874694824219, "timer/agent.train_max": 0.703871488571167, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47702932357788086, "timer/agent.report_frac": 0.0004768759692670748, "timer/agent.report_avg": 0.23851466178894043, "timer/agent.report_min": 0.2320082187652588, "timer/agent.report_max": 0.24502110481262207, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.814697265625e-05, "timer/dataset_eval_frac": 3.813470925353681e-08, "timer/dataset_eval_avg": 3.814697265625e-05, "timer/dataset_eval_min": 3.814697265625e-05, "timer/dataset_eval_max": 3.814697265625e-05, "fps": 31.765203226519162}
{"step": 1047336, "time": 33285.34009575844, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1047384, "time": 33286.80296278, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1047624, "time": 33294.12513756752, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1047768, "time": 33298.57468223572, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1047880, "time": 33302.02036190033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1048000, "time": 33305.93385410309, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1048200, "time": 33312.003693819046, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1048288, "time": 33314.951585531235, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1048440, "time": 33319.42184495926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1048688, "time": 33327.80471158028, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1048688, "time": 33327.81607866287, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1048704, "time": 33328.31881594658, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 1049248, "time": 33345.210087776184, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1049648, "time": 33357.50245261192, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1049808, "time": 33362.45008063316, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1049936, "time": 33366.4126496315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1050072, "time": 33370.507043123245, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 1050088, "time": 33371.60483264923, "eval_episode/length": 27.0, "eval_episode/score": 0.9156249761581421, "eval_episode/reward_rate": 0.03571428571428571}
{"step": 1050088, "time": 33372.261775016785, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1050088, "time": 33372.59209442139, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 1050088, "time": 33372.6640663147, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1050088, "time": 33372.71298074722, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1050088, "time": 33372.8262860775, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1050088, "time": 33372.96064019203, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1050088, "time": 33373.457661151886, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 1050192, "time": 33376.90734624863, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1050240, "time": 33378.39068508148, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1050376, "time": 33382.35206222534, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1050432, "time": 33384.29892683029, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1050512, "time": 33386.77884435654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1050648, "time": 33390.73726081848, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1050824, "time": 33396.163335084915, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1050864, "time": 33397.64189481735, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1051000, "time": 33401.75463938713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1051104, "time": 33405.177130937576, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1051104, "time": 33405.19138050079, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1051256, "time": 33409.64318871498, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1051456, "time": 33416.03903532028, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1051608, "time": 33420.49849009514, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1051696, "time": 33423.44658303261, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1051864, "time": 33428.511387348175, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1051984, "time": 33432.44775509834, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1052024, "time": 33433.45594930649, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1052320, "time": 33442.79464149475, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1052416, "time": 33445.737364292145, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1052600, "time": 33451.203578948975, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1052600, "time": 33451.21066069603, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1052744, "time": 33455.63011431694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1053088, "time": 33466.563596725464, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1053088, "time": 33466.583652973175, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1053136, "time": 33468.07062005997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1053280, "time": 33472.493277549744, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1053496, "time": 33478.90736961365, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1053600, "time": 33482.352858781815, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1053688, "time": 33484.84673547745, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1053768, "time": 33487.3273794651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1053896, "time": 33491.44765377045, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1054048, "time": 33496.36124539375, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1054048, "time": 33496.36852431297, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 1054280, "time": 33503.30102968216, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1054584, "time": 33512.6946811676, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1054888, "time": 33522.27410030365, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1054936, "time": 33523.75756812096, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1055000, "time": 33525.78387475014, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1055032, "time": 33526.773958683014, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1055056, "time": 33527.75989317894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1055400, "time": 33538.148549079895, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1055568, "time": 33543.56642580032, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1055696, "time": 33547.53957152367, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1055744, "time": 33549.16111588478, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1055920, "time": 33554.615426540375, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1056000, "time": 33557.10792684555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1056072, "time": 33559.10310006142, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1056128, "time": 33561.07517814636, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 1056360, "time": 33568.02798962593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1056416, "time": 33569.97371220589, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1056648, "time": 33576.9451482296, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1056664, "time": 33577.44681954384, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1056888, "time": 33585.012640953064, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1056944, "time": 33586.98220705986, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1057032, "time": 33589.45624399185, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1057080, "time": 33590.95049786568, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1057328, "time": 33598.83834147453, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1057712, "time": 33610.83344221115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1057720, "time": 33610.863448381424, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1058056, "time": 33621.215403318405, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1058232, "time": 33626.65816617012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1058328, "time": 33629.60512638092, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1058352, "time": 33630.595114946365, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1058384, "time": 33631.58667302132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1058928, "time": 33648.478079319, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1059200, "time": 33656.87191271782, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1059256, "time": 33658.375383615494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1059304, "time": 33659.863513708115, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1059304, "time": 33659.87304735184, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1059456, "time": 33664.80311822891, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1060032, "time": 33682.667904376984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1060072, "time": 33684.88340425491, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 1060072, "time": 33685.410036325455, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1060072, "time": 33685.722989320755, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1060072, "time": 33685.79458069801, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 1060072, "time": 33687.1754360199, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1060072, "time": 33687.63965511322, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1060072, "time": 33687.64718532562, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1060072, "time": 33689.8575835228, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1060120, "time": 33691.36243391037, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1060544, "time": 33704.738440036774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1060640, "time": 33707.704323768616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1060888, "time": 33715.10132956505, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 1061096, "time": 33721.51814579964, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1061192, "time": 33724.474546670914, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1061288, "time": 33727.46220207214, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1061616, "time": 33737.955470085144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1061616, "time": 33737.9655957222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1061768, "time": 33742.440136909485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1061944, "time": 33747.90500950813, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1062160, "time": 33754.758149147034, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1062320, "time": 33759.82655453682, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1062432, "time": 33763.30661034584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1062512, "time": 33765.79082775116, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1062688, "time": 33771.23827791214, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1062760, "time": 33773.23229765892, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1063064, "time": 33782.611031770706, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1063288, "time": 33789.67870283127, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 1063408, "time": 33793.61121058464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1063600, "time": 33799.56460976601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1063632, "time": 33800.58705639839, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1063680, "time": 33802.0731446743, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1063688, "time": 33802.10618376732, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1063696, "time": 33802.581287145615, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1063968, "time": 33810.97648024559, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1064072, "time": 33813.94508647919, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1064128, "time": 33815.92927479744, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1064200, "time": 33817.92694354057, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1064496, "time": 33827.404146909714, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1064712, "time": 33833.80492949486, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1065176, "time": 33848.754345178604, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1065200, "time": 33849.72241640091, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1065200, "time": 33849.73893404007, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1065440, "time": 33857.15266466141, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1065544, "time": 33860.12430071831, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1065672, "time": 33864.079748630524, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1065848, "time": 33869.52125477791, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1065944, "time": 33872.47622847557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1065960, "time": 33872.973487615585, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1066016, "time": 33874.92200541496, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1066280, "time": 33882.99538350105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1066384, "time": 33886.46173453331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1066560, "time": 33891.901941776276, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1066632, "time": 33893.89147520065, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1066672, "time": 33895.36973309517, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1066800, "time": 33899.30561876297, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1066800, "time": 33899.313173532486, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1066928, "time": 33903.29251432419, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1067048, "time": 33906.76595926285, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1067344, "time": 33916.248311042786, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1067512, "time": 33921.22930598259, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1067624, "time": 33924.67116379738, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1067888, "time": 33933.04602813721, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1067920, "time": 33934.04032087326, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1068104, "time": 33939.65463733673, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1068240, "time": 33944.07458329201, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1068328, "time": 33946.57492804527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1068872, "time": 33963.35620427132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1069056, "time": 33969.40334892273, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1069112, "time": 33970.93390965462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1069360, "time": 33978.82106471062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1069440, "time": 33981.31335115433, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1069632, "time": 33987.22230029106, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1069824, "time": 33993.12613606453, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1069872, "time": 33994.632907152176, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1069928, "time": 33996.14176988602, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1070040, "time": 33999.748749017715, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1070056, "time": 34001.64545726776, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 1070056, "time": 34001.71663117409, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1070056, "time": 34002.06094312668, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 1070056, "time": 34002.13188004494, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1070056, "time": 34002.37632226944, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1070056, "time": 34003.02490854263, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1070056, "time": 34003.11866950989, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1070056, "time": 34003.885623931885, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 1070200, "time": 34008.301589012146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1070232, "time": 34009.287694215775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1070344, "time": 34012.72470879555, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1070416, "time": 34015.186027765274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1070576, "time": 34020.11954855919, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1070584, "time": 34020.14893865585, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1070872, "time": 34029.19547581673, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1070912, "time": 34030.64495706558, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1071008, "time": 34033.606457710266, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1071080, "time": 34035.613996744156, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1071328, "time": 34043.519082307816, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1071456, "time": 34047.46020269394, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1071648, "time": 34053.389865875244, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1071824, "time": 34058.95549750328, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1072136, "time": 34068.38592553139, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1072408, "time": 34076.84363460541, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1072512, "time": 34080.30660748482, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1072544, "time": 34081.29672074318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1072576, "time": 34082.284623622894, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1072656, "time": 34084.77360248566, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1072800, "time": 34089.34930372238, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 1073088, "time": 34098.28827571869, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1073096, "time": 34098.318655490875, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1073320, "time": 34105.750228405, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1073360, "time": 34107.20683145523, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1073392, "time": 34108.23005747795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1073720, "time": 34118.14084982872, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1074136, "time": 34131.11867928505, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1074152, "time": 34131.62450838089, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1074688, "time": 34148.528269290924, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1074792, "time": 34151.54010391235, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1074856, "time": 34153.533796072006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1074888, "time": 34154.52970933914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1074952, "time": 34156.49909162521, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1075408, "time": 34170.795321941376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1075568, "time": 34175.7202899456, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1075632, "time": 34177.71655058861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1075904, "time": 34186.186277627945, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1076032, "time": 34190.134556531906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1076464, "time": 34203.43387770653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1076648, "time": 34209.0315451622, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1076880, "time": 34216.403967380524, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1077104, "time": 34223.31664943695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1077168, "time": 34225.27875137329, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1077224, "time": 34226.78254652023, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1077272, "time": 34228.27294039726, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1077336, "time": 34230.23470568657, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1077576, "time": 34237.63327074051, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1077720, "time": 34242.21638703346, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1077720, "time": 34242.23287677765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1078216, "time": 34257.469260931015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1078216, "time": 34257.47854232788, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1078640, "time": 34270.90547323227, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1078832, "time": 34276.846131801605, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1079033, "time": 34283.865972042084, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.665285963508951, "train/action_min": 0.0, "train/action_std": 1.8991725594554114, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009221776079704714, "train/actor_opt_grad_steps": 66350.0, "train/actor_opt_loss": -18.94883509976181, "train/adv_mag": 0.8646788848704429, "train/adv_max": 0.36356529937916665, "train/adv_mean": 0.00048019885747379334, "train/adv_min": -0.777802610816668, "train/adv_std": 0.026479875579963078, "train/cont_avg": 0.9945577496859297, "train/cont_loss_mean": 0.019846484956598312, "train/cont_loss_std": 0.2479153136212622, "train/cont_neg_acc": 0.25496982648294775, "train/cont_neg_loss": 2.87694601955076, "train/cont_pos_acc": 0.9998469442578416, "train/cont_pos_loss": 0.004218187700283138, "train/cont_pred": 0.9945187568664551, "train/cont_rate": 0.9945577496859297, "train/dyn_loss_mean": 1.0000015455274727, "train/dyn_loss_std": 4.763135919932407e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1032933512955305, "train/extr_critic_critic_opt_grad_steps": 66350.0, "train/extr_critic_critic_opt_loss": 13064.041256085113, "train/extr_critic_mag": 1.5150898844752478, "train/extr_critic_max": 1.5150898844752478, "train/extr_critic_mean": 1.4073850916857695, "train/extr_critic_min": 0.997733752332141, "train/extr_critic_std": 0.028280297060258426, "train/extr_return_normed_mag": 0.881294625188837, "train/extr_return_normed_max": 0.28419475040244097, "train/extr_return_normed_mean": 0.05340042978001, "train/extr_return_normed_min": -0.7966006787578065, "train/extr_return_normed_std": 0.039170496811594194, "train/extr_return_rate": 0.9996476844327533, "train/extr_return_raw_mag": 1.638659656347342, "train/extr_return_raw_max": 1.638659656347342, "train/extr_return_raw_mean": 1.4078654188606607, "train/extr_return_raw_min": 0.5578642271870944, "train/extr_return_raw_std": 0.03917049683031425, "train/extr_reward_mag": 0.2570362839866523, "train/extr_reward_max": 0.2570362839866523, "train/extr_reward_mean": 0.0019288824294370847, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.007939777087803987, "train/image_loss_mean": 0.0778197257512778, "train/image_loss_std": 0.09529472370842594, "train/model_loss_mean": 0.713956439614895, "train/model_loss_std": 0.4829078588503689, "train/model_opt_grad_norm": 16.423476813426568, "train/model_opt_grad_steps": 66286.97487437187, "train/model_opt_loss": 3750.2671904444096, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5251.256281407035, "train/policy_entropy_mag": 1.3123921832846637, "train/policy_entropy_max": 1.3123921832846637, "train/policy_entropy_mean": 0.09471202772765902, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11743258692361602, "train/policy_logprob_mag": 6.55108025085986, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09463453199246422, "train/policy_logprob_min": -6.55108025085986, "train/policy_logprob_std": 0.6314442367409941, "train/policy_randomness_mag": 0.6744362073927069, "train/policy_randomness_max": 0.6744362073927069, "train/policy_randomness_mean": 0.04867235580506037, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06034841530736367, "train/post_ent_mag": 49.49891045345134, "train/post_ent_max": 49.49891045345134, "train/post_ent_mean": 23.76176184266057, "train/post_ent_min": 13.341855188110966, "train/post_ent_std": 8.446440833297807, "train/prior_ent_mag": 48.77479790922386, "train/prior_ent_max": 48.77479790922386, "train/prior_ent_mean": 23.789497720536275, "train/prior_ent_min": 13.521705790380736, "train/prior_ent_std": 8.064189295073849, "train/rep_loss_mean": 1.0000015455274727, "train/rep_loss_std": 4.763135919932407e-05, "train/reward_avg": 0.002209027922137795, "train/reward_loss_mean": 0.01628927857820974, "train/reward_loss_std": 0.23636433814919025, "train/reward_max_data": 0.7624999988618208, "train/reward_max_pred": 0.2915170911568493, "train/reward_neg_acc": 0.9995471298994132, "train/reward_neg_loss": 0.0027742082295218605, "train/reward_pos_acc": 0.20782283623702824, "train/reward_pos_loss": 4.051947670678298, "train/reward_pred": 0.0017068176676551974, "train/reward_rate": 0.0033026460427135677, "train_stats/mean_log_entropy": 0.0826644041350385, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.014032305218279362, "report/cont_loss_std": 0.18874041736125946, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.1161487102508545, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003717701882123947, "report/cont_pred": 0.9944502711296082, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07442236691713333, "report/image_loss_std": 0.09585624188184738, "report/model_loss_mean": 0.7033559083938599, "report/model_loss_std": 0.4471294581890106, "report/post_ent_mag": 45.40979766845703, "report/post_ent_max": 45.40979766845703, "report/post_ent_mean": 23.422954559326172, "report/post_ent_min": 14.076123237609863, "report/post_ent_std": 7.748652458190918, "report/prior_ent_mag": 40.2647819519043, "report/prior_ent_max": 40.2647819519043, "report/prior_ent_mean": 22.42772102355957, "report/prior_ent_min": 14.507730484008789, "report/prior_ent_std": 5.690990924835205, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0021148682571947575, "report/reward_loss_mean": 0.0149012366309762, "report/reward_loss_std": 0.2263588160276413, "report/reward_max_data": 0.731249988079071, "report/reward_max_pred": 0.08319878578186035, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0026494113262742758, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.184605598449707, "report/reward_pred": 0.0014104526489973068, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.030331933870911598, "eval/cont_loss_std": 0.4866020679473877, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.7924323081970215, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0038138958625495434, "eval/cont_pred": 0.9962154626846313, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1081107035279274, "eval/image_loss_std": 0.11370622366666794, "eval/model_loss_mean": 0.7494146823883057, "eval/model_loss_std": 0.5988014340400696, "eval/post_ent_mag": 45.66984558105469, "eval/post_ent_max": 45.66984558105469, "eval/post_ent_mean": 23.144916534423828, "eval/post_ent_min": 13.93705940246582, "eval/post_ent_std": 8.095827102661133, "eval/prior_ent_mag": 41.87019348144531, "eval/prior_ent_max": 41.87019348144531, "eval/prior_ent_mean": 22.394689559936523, "eval/prior_ent_min": 14.544168472290039, "eval/prior_ent_std": 6.043904781341553, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0013854980934411287, "eval/reward_loss_mean": 0.01097200345247984, "eval/reward_loss_std": 0.19936735928058624, "eval/reward_max_data": 0.715624988079071, "eval/reward_max_pred": 0.15108704566955566, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.0021709809079766273, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.508294105529785, "eval/reward_pred": 0.0011453743791207671, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 31760.0, "replay/samples": 31760.0, "replay/insert_wait_avg": 1.4333190485572335e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.044074704725136e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4512.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3106152520957567e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.275269985199, "timer/env.step_count": 3970.0, "timer/env.step_total": 41.91636300086975, "timer/env.step_frac": 0.041904827859525096, "timer/env.step_avg": 0.01055827783397223, "timer/env.step_min": 0.008806705474853516, "timer/env.step_max": 0.045305728912353516, "timer/replay._sample_count": 31760.0, "timer/replay._sample_total": 17.048175573349, "timer/replay._sample_frac": 0.017043484013756792, "timer/replay._sample_avg": 0.0005367813467679156, "timer/replay._sample_min": 0.0003941059112548828, "timer/replay._sample_max": 0.011279106140136719, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4534.0, "timer/agent.policy_total": 51.33734607696533, "timer/agent.policy_frac": 0.05132321833541378, "timer/agent.policy_avg": 0.011322749465585648, "timer/agent.policy_min": 0.009178400039672852, "timer/agent.policy_max": 0.09100198745727539, "timer/dataset_train_count": 1985.0, "timer/dataset_train_total": 0.24807071685791016, "timer/dataset_train_frac": 0.000248002449227382, "timer/dataset_train_avg": 0.000124972653328922, "timer/dataset_train_min": 0.0001068115234375, "timer/dataset_train_max": 0.001056671142578125, "timer/agent.train_count": 1985.0, "timer/agent.train_total": 893.7557971477509, "timer/agent.train_frac": 0.8935098407071242, "timer/agent.train_avg": 0.4502548096462221, "timer/agent.train_min": 0.4385707378387451, "timer/agent.train_max": 0.7013189792633057, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4777412414550781, "timer/agent.report_frac": 0.00047760976982080865, "timer/agent.report_avg": 0.23887062072753906, "timer/agent.report_min": 0.230332612991333, "timer/agent.report_max": 0.24740862846374512, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.217765063729627e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 31.750668939753712}
{"step": 1079160, "time": 34287.577094078064, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1079200, "time": 34289.04352807999, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1079240, "time": 34290.06189441681, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1079264, "time": 34291.029562950134, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1079480, "time": 34297.45703244209, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1079584, "time": 34301.00051307678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1079648, "time": 34302.98331427574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1080024, "time": 34314.3879404068, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1080032, "time": 34314.86505961418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1080040, "time": 34315.968871831894, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1080040, "time": 34316.781037569046, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1080040, "time": 34317.135120391846, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1080040, "time": 34317.420420885086, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 1080040, "time": 34317.84520626068, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 1080040, "time": 34318.00382399559, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 1080040, "time": 34318.499846458435, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 1080040, "time": 34319.02368426323, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1080280, "time": 34326.43812084198, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1080632, "time": 34337.40402054787, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1080712, "time": 34339.87379407883, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1080912, "time": 34346.281457424164, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1081512, "time": 34365.28178191185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1081544, "time": 34366.274639844894, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1081552, "time": 34366.77551627159, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1081896, "time": 34377.177748680115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1081912, "time": 34377.68036913872, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1081960, "time": 34379.18134021759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1082088, "time": 34383.1318924427, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1082344, "time": 34391.12669992447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1082488, "time": 34395.56555175781, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1082584, "time": 34398.54571580887, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1082664, "time": 34400.99842596054, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1082696, "time": 34402.003533124924, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1082872, "time": 34407.423385858536, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1082880, "time": 34407.89961695671, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1082944, "time": 34409.85542225838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1083104, "time": 34414.78736400604, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1083304, "time": 34420.830362558365, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1083800, "time": 34436.125438928604, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1083832, "time": 34437.11324620247, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1083840, "time": 34437.5867831707, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1084072, "time": 34444.547979831696, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1084160, "time": 34447.51433134079, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1084368, "time": 34454.04481911659, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1084656, "time": 34462.92806363106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1084664, "time": 34462.95834302902, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1085168, "time": 34478.927199840546, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1085192, "time": 34479.45003414154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1085256, "time": 34481.43165373802, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1085536, "time": 34490.26586008072, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 1085552, "time": 34490.786944150925, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1085672, "time": 34494.2561173439, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1085792, "time": 34498.21031689644, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1085872, "time": 34500.68060731888, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1085896, "time": 34501.20151472092, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1086112, "time": 34508.10149717331, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1086128, "time": 34508.73805260658, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1086208, "time": 34511.21516036987, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1086496, "time": 34520.078974962234, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1086576, "time": 34522.55547571182, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1086584, "time": 34522.58668637276, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1087000, "time": 34535.41786956787, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1087040, "time": 34536.86835551262, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1087192, "time": 34541.42997455597, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1087328, "time": 34545.866194963455, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1087376, "time": 34547.34674048424, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1087480, "time": 34550.333577394485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1087648, "time": 34555.735424518585, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1088176, "time": 34572.24445962906, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1088264, "time": 34574.71783876419, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1088312, "time": 34576.21614074707, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1088424, "time": 34579.67720246315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1088432, "time": 34580.17858552933, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1088440, "time": 34580.21652841568, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1089064, "time": 34599.50056171417, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1089080, "time": 34600.02223396301, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1089352, "time": 34608.40857338905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1089592, "time": 34616.36022615433, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1089688, "time": 34619.324454307556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1089872, "time": 34625.2391474247, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1089896, "time": 34625.75548171997, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1090024, "time": 34631.171010017395, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 1090024, "time": 34631.32701206207, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 1090024, "time": 34631.770413160324, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1090024, "time": 34632.16839718819, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1090024, "time": 34632.41098380089, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1090024, "time": 34633.008338689804, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1090024, "time": 34633.07909631729, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 1090024, "time": 34633.107486486435, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 1090456, "time": 34646.435807943344, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1090488, "time": 34647.42718362808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1090504, "time": 34647.92910504341, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1090624, "time": 34651.85066437721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1090640, "time": 34652.348287820816, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1090736, "time": 34655.30958223343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1090744, "time": 34655.34221124649, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1090856, "time": 34659.00101518631, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1091144, "time": 34667.87825989723, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1091176, "time": 34668.88884925842, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1091264, "time": 34671.817754507065, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1091456, "time": 34677.71767425537, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1091536, "time": 34680.184890031815, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1091608, "time": 34682.18680167198, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1091704, "time": 34685.14730095863, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1091960, "time": 34693.246175050735, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1092072, "time": 34696.699966192245, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1092288, "time": 34703.59967112541, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1092312, "time": 34704.11995482445, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1092824, "time": 34720.10885500908, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1093000, "time": 34725.54452729225, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1093072, "time": 34728.00127077103, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1093088, "time": 34728.50273823738, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1093168, "time": 34730.9679813385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1093400, "time": 34737.933052778244, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1093448, "time": 34739.41854453087, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 1093488, "time": 34740.87977600098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1093760, "time": 34749.393000125885, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1093784, "time": 34749.914924144745, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1093912, "time": 34753.86613678932, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1093920, "time": 34754.3460521698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1093976, "time": 34755.8508310318, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1094360, "time": 34767.707277059555, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1094584, "time": 34774.59897875786, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1094600, "time": 34775.098232507706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1094800, "time": 34781.65057730675, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1095080, "time": 34790.09328889847, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1095144, "time": 34792.06857299805, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1095232, "time": 34795.00801157951, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 1095424, "time": 34800.953933000565, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1095712, "time": 34809.99537944794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1095760, "time": 34811.4750854969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1096232, "time": 34825.831505060196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1096264, "time": 34826.821835279465, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1096384, "time": 34830.752141714096, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1096512, "time": 34834.6982293129, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1096872, "time": 34845.68788409233, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1096912, "time": 34847.171108961105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1096976, "time": 34849.13367700577, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1097112, "time": 34853.095418930054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1097392, "time": 34861.949348926544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1097416, "time": 34862.47193455696, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1097544, "time": 34866.40643811226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1097640, "time": 34869.51318526268, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1097720, "time": 34872.01336359978, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 1097752, "time": 34873.519407749176, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1098112, "time": 34884.823976278305, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1098264, "time": 34889.29066133499, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1098824, "time": 34906.656430482864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1098984, "time": 34911.58942079544, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1099064, "time": 34914.07886123657, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1099184, "time": 34917.99374270439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1099424, "time": 34925.3830909729, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1099728, "time": 34934.87820100784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1099736, "time": 34934.90932512283, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1099784, "time": 34936.39310669899, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1099936, "time": 34941.32753896713, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1099952, "time": 34941.8619954586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1100008, "time": 34944.50341629982, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 1100008, "time": 34944.5308675766, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1100008, "time": 34944.53739929199, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 1100008, "time": 34944.88436770439, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1100008, "time": 34945.08491587639, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 1100008, "time": 34945.542880773544, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1100008, "time": 34945.63451862335, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 1100008, "time": 34946.133689165115, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1100032, "time": 34947.10611367226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1100536, "time": 34962.555279016495, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1100800, "time": 34970.92375779152, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1101136, "time": 34981.277844667435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1101176, "time": 34982.292387247086, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1101496, "time": 34992.28821730614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1101584, "time": 34995.235659360886, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1101608, "time": 34995.75868344307, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 1102048, "time": 35009.596184015274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1102248, "time": 35015.55360078812, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 1102288, "time": 35017.027441978455, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1102344, "time": 35018.67572641373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1102848, "time": 35034.47956609726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1102896, "time": 35035.95475649834, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1103048, "time": 35040.42832779884, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1103056, "time": 35040.90514397621, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1103360, "time": 35050.42884349823, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1103368, "time": 35050.45836186409, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1103488, "time": 35054.379593372345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1103624, "time": 35058.35124325752, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1103776, "time": 35063.2690474987, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1103896, "time": 35066.756868839264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1103920, "time": 35067.73145842552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1103960, "time": 35068.76090836525, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1103960, "time": 35068.768550634384, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1104144, "time": 35074.68779230118, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1104336, "time": 35080.767751932144, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1104688, "time": 35091.64045667648, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1104792, "time": 35094.65640473366, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1104840, "time": 35096.13662600517, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1105000, "time": 35101.08144521713, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1105160, "time": 35106.02054333687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1105272, "time": 35109.639989852905, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1105376, "time": 35113.07951879501, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1105576, "time": 35119.08369755745, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1105664, "time": 35122.00618171692, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1105752, "time": 35124.52155995369, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1105928, "time": 35130.1947221756, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1106088, "time": 35135.420103788376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1106272, "time": 35141.4542453289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1106544, "time": 35149.846855163574, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1106656, "time": 35153.30798244476, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1106712, "time": 35154.82820725441, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1107000, "time": 35163.72599387169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1107208, "time": 35170.33365035057, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1107688, "time": 35185.134098529816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1107776, "time": 35188.082965135574, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1107888, "time": 35191.53807282448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1107896, "time": 35191.56806373596, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1107976, "time": 35194.061133384705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1108240, "time": 35202.60353517532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1108464, "time": 35209.53468823433, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1108504, "time": 35210.54947137833, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 1108832, "time": 35220.88047027588, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1108856, "time": 35221.40097999573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1109200, "time": 35232.385866642, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1109264, "time": 35234.37763094902, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1109448, "time": 35239.855798244476, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1109560, "time": 35243.314205408096, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1110088, "time": 35259.72398400307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1110096, "time": 35260.72779965401, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 1110096, "time": 35261.401628255844, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1110096, "time": 35261.409118652344, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1110096, "time": 35262.34209394455, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1110096, "time": 35262.55058860779, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1110096, "time": 35263.046481609344, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 1110096, "time": 35263.29101419449, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1110096, "time": 35263.47004699707, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 1110208, "time": 35266.918251276016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1110256, "time": 35268.39621043205, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1110288, "time": 35269.394079208374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1110360, "time": 35271.41747879982, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1110424, "time": 35273.396877765656, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 1110745, "time": 35284.38754153252, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5746201023910986, "train/action_min": 0.0, "train/action_std": 1.8684601946310564, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009701150677618429, "train/actor_opt_grad_steps": 68335.0, "train/actor_opt_loss": -16.836352382043394, "train/adv_mag": 0.8739365754705487, "train/adv_max": 0.37439321207277704, "train/adv_mean": -4.5416008464544024e-06, "train/adv_min": -0.8047926263375715, "train/adv_std": 0.028468931150255783, "train/cont_avg": 0.99429352114899, "train/cont_loss_mean": 0.021038201545844928, "train/cont_loss_std": 0.2626781673593955, "train/cont_neg_acc": 0.24552706478521077, "train/cont_neg_loss": 2.984759774087279, "train/cont_pos_acc": 0.999846197137929, "train/cont_pos_loss": 0.004201395725807871, "train/cont_pred": 0.9945034610502648, "train/cont_rate": 0.99429352114899, "train/dyn_loss_mean": 1.000001599090268, "train/dyn_loss_std": 5.114108037128292e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1096852111343219, "train/extr_critic_critic_opt_grad_steps": 68335.0, "train/extr_critic_critic_opt_loss": 13343.046776357323, "train/extr_critic_mag": 1.5024359358681574, "train/extr_critic_max": 1.5024359358681574, "train/extr_critic_mean": 1.3877786229355167, "train/extr_critic_min": 1.0166146797363205, "train/extr_critic_std": 0.025832825312108704, "train/extr_return_normed_mag": 0.9124196611269556, "train/extr_return_normed_max": 0.3280337934542184, "train/extr_return_normed_mean": 0.047867873147355786, "train/extr_return_normed_min": -0.8282503846919897, "train/extr_return_normed_std": 0.03897856751626188, "train/extr_return_rate": 0.9996465664319317, "train/extr_return_raw_mag": 1.667939999488869, "train/extr_return_raw_max": 1.667939999488869, "train/extr_return_raw_mean": 1.3877741586078296, "train/extr_return_raw_min": 0.511655821342661, "train/extr_return_raw_std": 0.038978567619742166, "train/extr_reward_mag": 0.3137465649180942, "train/extr_reward_max": 0.3137465649180942, "train/extr_reward_mean": 0.0020500316191699847, "train/extr_reward_min": 3.010335594716698e-09, "train/extr_reward_std": 0.008818220133150015, "train/image_loss_mean": 0.07665114364389217, "train/image_loss_std": 0.09437021272576819, "train/model_loss_mean": 0.7140631335552292, "train/model_loss_std": 0.4918999294138918, "train/model_opt_grad_norm": 16.04497771311288, "train/model_opt_grad_steps": 68270.0505050505, "train/model_opt_loss": 3680.7460173019253, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5151.515151515152, "train/policy_entropy_mag": 1.2943057965750646, "train/policy_entropy_max": 1.2943057965750646, "train/policy_entropy_mean": 0.09420332384079394, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11604888966739779, "train/policy_logprob_mag": 6.551080272655295, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09499284610001728, "train/policy_logprob_min": -6.551080272655295, "train/policy_logprob_std": 0.6352272346766308, "train/policy_randomness_mag": 0.6651416438998599, "train/policy_randomness_max": 0.6651416438998599, "train/policy_randomness_mean": 0.04841093525215231, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05963733538307927, "train/post_ent_mag": 49.47503947248362, "train/post_ent_max": 49.47503947248362, "train/post_ent_mean": 24.149503361095082, "train/post_ent_min": 13.443398162572072, "train/post_ent_std": 8.43071509611727, "train/prior_ent_mag": 48.10330055699204, "train/prior_ent_max": 48.10330055699204, "train/prior_ent_mean": 24.72935348086887, "train/prior_ent_min": 13.78999962469544, "train/prior_ent_std": 7.743569304244687, "train/rep_loss_mean": 1.000001599090268, "train/rep_loss_std": 5.114108037128292e-05, "train/reward_avg": 0.0022994532781086315, "train/reward_loss_mean": 0.016372805330761228, "train/reward_loss_std": 0.23717103670163062, "train/reward_max_data": 0.7806976017626849, "train/reward_max_pred": 0.3075264963236722, "train/reward_neg_acc": 0.999678231851019, "train/reward_neg_loss": 0.0028011876380663703, "train/reward_pos_acc": 0.20287800956632673, "train/reward_pos_loss": 4.022954559203276, "train/reward_pred": 0.0017542568167125939, "train/reward_rate": 0.0033735795454545455, "train_stats/mean_log_entropy": 0.08160010182741777, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.026187527924776077, "report/cont_loss_std": 0.29641368985176086, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 3.309769868850708, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003586666891351342, "report/cont_pred": 0.9953649640083313, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.05764390528202057, "report/image_loss_std": 0.07269936800003052, "report/model_loss_mean": 0.7076126337051392, "report/model_loss_std": 0.6060219407081604, "report/post_ent_mag": 42.33540344238281, "report/post_ent_max": 42.33540344238281, "report/post_ent_mean": 21.512432098388672, "report/post_ent_min": 12.71249008178711, "report/post_ent_std": 6.541539669036865, "report/prior_ent_mag": 48.05434799194336, "report/prior_ent_max": 48.05434799194336, "report/prior_ent_mean": 24.886356353759766, "report/prior_ent_min": 13.539424896240234, "report/prior_ent_std": 7.648482322692871, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003292846493422985, "report/reward_loss_mean": 0.023781178519129753, "report/reward_loss_std": 0.3044069707393646, "report/reward_max_data": 0.7250000238418579, "report/reward_max_pred": 0.021916747093200684, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0024710071738809347, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.366794109344482, "report/reward_pred": 0.0013513517333194613, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.049172788858413696, "eval/cont_loss_std": 0.5800531506538391, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.79850959777832, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0039024169091135263, "eval/cont_pred": 0.9961217045783997, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.09528347849845886, "eval/image_loss_std": 0.11135707795619965, "eval/model_loss_mean": 0.771443247795105, "eval/model_loss_std": 0.8394609093666077, "eval/post_ent_mag": 42.337120056152344, "eval/post_ent_max": 42.337120056152344, "eval/post_ent_mean": 21.53317642211914, "eval/post_ent_min": 12.678949356079102, "eval/post_ent_std": 7.013599395751953, "eval/prior_ent_mag": 47.510414123535156, "eval/prior_ent_max": 47.510414123535156, "eval/prior_ent_mean": 24.885669708251953, "eval/prior_ent_min": 12.733503341674805, "eval/prior_ent_std": 8.305866241455078, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0038330077659338713, "eval/reward_loss_mean": 0.02698700688779354, "eval/reward_loss_std": 0.34897616505622864, "eval/reward_max_data": 0.8999999761581421, "eval/reward_max_pred": 0.07082831859588623, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002590880962088704, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.998917579650879, "eval/reward_pred": 0.001392764737829566, "eval/reward_rate": 0.0048828125, "replay/size": 1000000.0, "replay/inserts": 31712.0, "replay/samples": 31712.0, "replay/insert_wait_avg": 1.4395183318799248e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.147296342551408e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4680.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.288784874810113e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4276089668274, "timer/env.step_count": 3964.0, "timer/env.step_total": 41.83834409713745, "timer/env.step_frac": 0.041820461292891756, "timer/env.step_avg": 0.010554577219257682, "timer/env.step_min": 0.008658170700073242, "timer/env.step_max": 0.04996895790100098, "timer/replay._sample_count": 31712.0, "timer/replay._sample_total": 17.07858443260193, "timer/replay._sample_frac": 0.017071284598232463, "timer/replay._sample_avg": 0.0005385527381622708, "timer/replay._sample_min": 0.0004200935363769531, "timer/replay._sample_max": 0.03210282325744629, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4549.0, "timer/agent.policy_total": 52.08136177062988, "timer/agent.policy_frac": 0.05205910083230902, "timer/agent.policy_avg": 0.011448969393411713, "timer/agent.policy_min": 0.009059429168701172, "timer/agent.policy_max": 0.09534120559692383, "timer/dataset_train_count": 1982.0, "timer/dataset_train_total": 0.24788379669189453, "timer/dataset_train_frac": 0.00024777784466373514, "timer/dataset_train_avg": 0.00012506750589903862, "timer/dataset_train_min": 0.00010800361633300781, "timer/dataset_train_max": 0.0003762245178222656, "timer/agent.train_count": 1982.0, "timer/agent.train_total": 892.9102168083191, "timer/agent.train_frac": 0.8925285635913779, "timer/agent.train_avg": 0.45050969566514587, "timer/agent.train_min": 0.43750953674316406, "timer/agent.train_max": 0.7381830215454102, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4810466766357422, "timer/agent.report_frac": 0.0004808410646848641, "timer/agent.report_avg": 0.2405233383178711, "timer/agent.report_min": 0.23372530937194824, "timer/agent.report_max": 0.24732136726379395, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.647804260253906e-05, "timer/dataset_eval_frac": 3.646245093156822e-08, "timer/dataset_eval_avg": 3.647804260253906e-05, "timer/dataset_eval_min": 3.647804260253906e-05, "timer/dataset_eval_max": 3.647804260253906e-05, "fps": 31.697785571138457}
{"step": 1110776, "time": 35285.10280394554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1110816, "time": 35286.664073467255, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1110928, "time": 35290.23904013634, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1111000, "time": 35292.26999950409, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1111272, "time": 35300.61733841896, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1111512, "time": 35308.00543022156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1111512, "time": 35308.012902736664, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1111760, "time": 35315.83584904671, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1111768, "time": 35315.865916252136, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1111808, "time": 35317.34283399582, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1111928, "time": 35320.921350479126, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1112136, "time": 35327.329160928726, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 1112200, "time": 35329.30251932144, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1112264, "time": 35331.26795530319, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1112416, "time": 35336.18404173851, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1112520, "time": 35339.19311785698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1112560, "time": 35340.63324713707, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1112560, "time": 35340.64239144325, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1112576, "time": 35341.137620449066, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1112736, "time": 35346.08579611778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1112888, "time": 35350.64986038208, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1112944, "time": 35352.60831809044, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1113272, "time": 35362.46937561035, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1113352, "time": 35364.925256729126, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1113448, "time": 35367.91025829315, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1113472, "time": 35368.87595939636, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1113648, "time": 35374.334087371826, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1113912, "time": 35382.38012075424, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1113984, "time": 35384.80594468117, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1114032, "time": 35386.29986810684, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1114448, "time": 35399.57119655609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1114696, "time": 35406.984941244125, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1114728, "time": 35407.96328353882, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1114872, "time": 35412.47654294968, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1115472, "time": 35431.11315822601, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 1115584, "time": 35434.54022979736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1115760, "time": 35440.11401462555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1115912, "time": 35444.56958270073, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1116224, "time": 35454.40569519997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1116440, "time": 35460.85098719597, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1116464, "time": 35461.813520908356, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1116688, "time": 35468.85945177078, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1116760, "time": 35470.874817848206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1117008, "time": 35478.76594734192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1117040, "time": 35479.76135802269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1117080, "time": 35480.7956635952, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1117184, "time": 35484.235290288925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1117264, "time": 35486.72018623352, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1117360, "time": 35489.71330451965, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1117672, "time": 35499.31364965439, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1117672, "time": 35499.32450008392, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 1117696, "time": 35500.290747880936, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1118264, "time": 35517.65770626068, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1118464, "time": 35524.0466940403, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1118472, "time": 35524.07690143585, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1118496, "time": 35525.045289993286, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1118544, "time": 35526.54953980446, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1118728, "time": 35532.143374443054, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1119056, "time": 35542.533552885056, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1119072, "time": 35543.03271150589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1119128, "time": 35544.53351163864, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1119160, "time": 35545.54848194122, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1119416, "time": 35553.4952442646, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1119424, "time": 35553.97066283226, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1119576, "time": 35558.550647974014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1119792, "time": 35565.48127603531, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1119928, "time": 35569.432871580124, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1120080, "time": 35575.10672068596, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 1120080, "time": 35575.728984832764, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1120080, "time": 35575.79927277565, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1120080, "time": 35575.84823322296, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1120080, "time": 35575.917806863785, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1120080, "time": 35575.92415308952, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1120080, "time": 35576.59486722946, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 1120080, "time": 35576.88686680794, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 1120576, "time": 35592.3238735199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1120608, "time": 35593.33993649483, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1120784, "time": 35598.774610996246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1120928, "time": 35603.22213602066, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1120960, "time": 35604.207686662674, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1121032, "time": 35606.19242143631, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1121088, "time": 35608.16797232628, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1121368, "time": 35616.54768681526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1121416, "time": 35618.06355595589, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1121472, "time": 35620.14398479462, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1121472, "time": 35620.1541762352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1121592, "time": 35623.63609147072, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1121648, "time": 35625.570510149, "episode/length": 6.0, "episode/score": 0.981249988079071, "episode/reward_rate": 0.14285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1121728, "time": 35628.04517889023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1121736, "time": 35628.077640771866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1121928, "time": 35633.971219062805, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1121976, "time": 35635.44958233833, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1122072, "time": 35638.425397872925, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1122160, "time": 35641.34568786621, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1122224, "time": 35643.33302164078, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1122232, "time": 35643.36278343201, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1122304, "time": 35645.95537805557, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1122488, "time": 35651.881524801254, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1122872, "time": 35663.82028841972, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1122952, "time": 35666.321367025375, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1122952, "time": 35666.330355644226, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1123144, "time": 35672.30257296562, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1123608, "time": 35686.849977493286, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1123696, "time": 35689.834864616394, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1123768, "time": 35691.84432673454, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1123960, "time": 35697.81016111374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1124112, "time": 35702.739250183105, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1124264, "time": 35707.198360681534, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1124472, "time": 35713.79845452309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1124544, "time": 35716.2380502224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1124632, "time": 35718.74701452255, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1124632, "time": 35718.756487846375, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1124664, "time": 35719.750712156296, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1124696, "time": 35720.74635219574, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1124728, "time": 35721.74189066887, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1124944, "time": 35728.67451930046, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1125072, "time": 35732.647210121155, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1125184, "time": 35736.12671208382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1125256, "time": 35738.174928188324, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1125528, "time": 35746.75465774536, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1125600, "time": 35749.21538567543, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1125624, "time": 35749.73894882202, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1125736, "time": 35753.21443557739, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1125760, "time": 35754.187067747116, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1125968, "time": 35760.63206720352, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1126024, "time": 35762.134954214096, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1126256, "time": 35769.71029353142, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1126288, "time": 35770.710829496384, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1126576, "time": 35779.62294244766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1126728, "time": 35784.093299627304, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1126744, "time": 35784.60058617592, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1126784, "time": 35786.05840563774, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1127008, "time": 35792.97641301155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1127032, "time": 35793.49989557266, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1127104, "time": 35795.940714120865, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1127168, "time": 35797.9293513298, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1127384, "time": 35804.51348614693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1127384, "time": 35804.52220606804, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1127456, "time": 35806.96029663086, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1127624, "time": 35811.92275238037, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1127648, "time": 35812.91051721573, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1127672, "time": 35813.42565822601, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1127808, "time": 35817.84722185135, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1127824, "time": 35818.3492565155, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1127936, "time": 35821.80797338486, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1127976, "time": 35822.84277629852, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1128328, "time": 35833.83548593521, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1128408, "time": 35836.29870843887, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1128408, "time": 35836.32419514656, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1128520, "time": 35839.80757665634, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1128616, "time": 35842.77207803726, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1128848, "time": 35850.09700536728, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1129024, "time": 35855.50192117691, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1129096, "time": 35857.5209839344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1129120, "time": 35858.65463876724, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1129224, "time": 35861.62777137756, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1129272, "time": 35863.13195872307, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1129432, "time": 35868.064158678055, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1129432, "time": 35868.07760667801, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1129512, "time": 35870.54786705971, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1129640, "time": 35874.51309990883, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1129696, "time": 35876.45895242691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1129880, "time": 35881.94296860695, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1130064, "time": 35888.64336514473, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 1130064, "time": 35889.237610816956, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1130064, "time": 35889.26571178436, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 1130064, "time": 35889.61191725731, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 1130064, "time": 35890.10692238808, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1130064, "time": 35890.246436834335, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 1130064, "time": 35890.60188913345, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 1130064, "time": 35890.65386033058, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 1130176, "time": 35894.08309006691, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1130184, "time": 35894.112307071686, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1130192, "time": 35894.60250258446, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1130328, "time": 35898.56772732735, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1130352, "time": 35899.558582782745, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1130360, "time": 35899.58851647377, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1130640, "time": 35908.94725394249, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1130824, "time": 35914.4256632328, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1130936, "time": 35917.92301988602, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1130992, "time": 35920.02599787712, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1131248, "time": 35927.90774965286, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1131392, "time": 35932.35997509956, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1131464, "time": 35934.357298374176, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1131608, "time": 35938.79948401451, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1131640, "time": 35939.80885910988, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1131744, "time": 35943.239904642105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1131752, "time": 35943.27236008644, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1132256, "time": 35959.14803481102, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1132264, "time": 35959.17773294449, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1132360, "time": 35962.17268753052, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1132384, "time": 35963.142615795135, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1133000, "time": 35982.12047958374, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1133296, "time": 35991.4395968914, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1133424, "time": 35995.384165763855, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1133504, "time": 35997.84060692787, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1133776, "time": 36006.25897336006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1133920, "time": 36010.84718418121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1133928, "time": 36010.875583171844, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1133952, "time": 36011.84863328934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1134056, "time": 36014.913675785065, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1134064, "time": 36015.392369031906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1134192, "time": 36019.37249827385, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1134272, "time": 36021.84165620804, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1134520, "time": 36029.336836099625, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1134800, "time": 36038.17631435394, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1134896, "time": 36041.26399254799, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1134952, "time": 36042.75812244415, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1135056, "time": 36046.18247246742, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1135088, "time": 36047.18019556999, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 1135312, "time": 36054.13673520088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1135560, "time": 36061.567668676376, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1135704, "time": 36065.992492198944, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1135784, "time": 36068.5848531723, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1135864, "time": 36071.040147066116, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1135984, "time": 36074.96352815628, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1136096, "time": 36078.37895464897, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1136232, "time": 36082.36756873131, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1136368, "time": 36086.82164168358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1136760, "time": 36098.871022462845, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1136776, "time": 36099.36652851105, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1136928, "time": 36104.27531218529, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1137000, "time": 36106.24593305588, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1137400, "time": 36118.55859851837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1137464, "time": 36120.53908777237, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1137832, "time": 36132.00685453415, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1137984, "time": 36136.92222285271, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1138016, "time": 36137.919780254364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1138040, "time": 36138.475908994675, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1138064, "time": 36139.44512844086, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1138192, "time": 36143.400988817215, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1138304, "time": 36146.84392094612, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1138408, "time": 36149.86314582825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1138512, "time": 36153.341207027435, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1138520, "time": 36153.37113404274, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1139040, "time": 36170.29219865799, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1139072, "time": 36171.28303337097, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1139088, "time": 36171.77589178085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1139096, "time": 36171.8072783947, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1139280, "time": 36177.70111298561, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1140000, "time": 36200.07174897194, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1140040, "time": 36201.080316782, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1140048, "time": 36203.1381881237, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 1140048, "time": 36203.80331993103, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1140048, "time": 36204.072855472565, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1140048, "time": 36204.31461453438, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 1140048, "time": 36204.406319618225, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1140048, "time": 36204.717435359955, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 1140048, "time": 36205.04262757301, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 1140048, "time": 36205.412142038345, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1140144, "time": 36208.37784361839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1140304, "time": 36213.31449127197, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1140360, "time": 36214.825644254684, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1140464, "time": 36218.33973693848, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1140720, "time": 36226.337961912155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1140832, "time": 36229.81178069115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1140904, "time": 36231.81447267532, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1141152, "time": 36239.71384716034, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1141224, "time": 36241.71303009987, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1141312, "time": 36244.66723179817, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1141320, "time": 36244.69827198982, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1141384, "time": 36246.6804420948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1141448, "time": 36248.818460941315, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1141496, "time": 36250.306470394135, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1141512, "time": 36250.80278134346, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1141816, "time": 36260.19022488594, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1141944, "time": 36264.14941215515, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1142048, "time": 36267.60498189926, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1142176, "time": 36271.54087495804, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1142352, "time": 36276.98978924751, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1142352, "time": 36277.00323557854, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1142569, "time": 36284.68669462204, "train_stats/mean_log_entropy": 0.07930041044226542, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.6104141312028895, "train/action_min": 0.0, "train/action_std": 1.8426438042865925, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01039217570071207, "train/actor_opt_grad_steps": 70320.0, "train/actor_opt_loss": -20.011430400100785, "train/adv_mag": 0.8079385613676292, "train/adv_max": 0.3423970188926812, "train/adv_mean": -0.00022482785888127156, "train/adv_min": -0.7329155050929467, "train/adv_std": 0.02912199854775889, "train/cont_avg": 0.9942436793341709, "train/cont_loss_mean": 0.022078919863262818, "train/cont_loss_std": 0.26764744598811596, "train/cont_neg_acc": 0.22350515657333872, "train/cont_neg_loss": 3.0623462841139366, "train/cont_pos_acc": 0.9998618040851612, "train/cont_pos_loss": 0.00454020517382153, "train/cont_pred": 0.9943341924317518, "train/cont_rate": 0.9942436793341709, "train/dyn_loss_mean": 1.0000034061508563, "train/dyn_loss_std": 0.0001038221473309525, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11133346432848043, "train/extr_critic_critic_opt_grad_steps": 70320.0, "train/extr_critic_critic_opt_loss": 13332.121245877826, "train/extr_critic_mag": 1.4961356757274225, "train/extr_critic_max": 1.4961356757274225, "train/extr_critic_mean": 1.37443603702526, "train/extr_critic_min": 1.0145721028198549, "train/extr_critic_std": 0.02735070692347222, "train/extr_return_normed_mag": 0.8196695093533501, "train/extr_return_normed_max": 0.2980145174055243, "train/extr_return_normed_mean": 0.052103540799276316, "train/extr_return_normed_min": -0.7211090137611083, "train/extr_return_normed_std": 0.04079154679486201, "train/extr_return_rate": 0.9995174716465437, "train/extr_return_raw_mag": 1.6201220948492463, "train/extr_return_raw_max": 1.6201220948492463, "train/extr_return_raw_mean": 1.374211196324334, "train/extr_return_raw_min": 0.6009985636826136, "train/extr_return_raw_std": 0.04079154676678193, "train/extr_reward_mag": 0.27436410901534497, "train/extr_reward_max": 0.27436410901534497, "train/extr_reward_mean": 0.0021372458197869097, "train/extr_reward_min": 7.188499872408919e-09, "train/extr_reward_std": 0.008627334356907025, "train/image_loss_mean": 0.07673998628204791, "train/image_loss_std": 0.09489567589070928, "train/model_loss_mean": 0.7161488712732517, "train/model_loss_std": 0.5040372622072996, "train/model_opt_grad_norm": 15.676051194943375, "train/model_opt_grad_steps": 70253.1608040201, "train/model_opt_loss": 3798.1052663218434, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5301.507537688442, "train/policy_entropy_mag": 1.2819648376062287, "train/policy_entropy_max": 1.2819648376062287, "train/policy_entropy_mean": 0.09452979154323214, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11637955630694202, "train/policy_logprob_mag": 6.551080258048359, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09524504679381549, "train/policy_logprob_min": -6.551080258048359, "train/policy_logprob_std": 0.6353008944784576, "train/policy_randomness_mag": 0.6587996434925789, "train/policy_randomness_max": 0.6587996434925789, "train/policy_randomness_mean": 0.048578706087928324, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05980726460640754, "train/post_ent_mag": 49.4489691461151, "train/post_ent_max": 49.4489691461151, "train/post_ent_mean": 24.22191460767583, "train/post_ent_min": 13.219084912209055, "train/post_ent_std": 8.537842451028489, "train/prior_ent_mag": 50.20827710328989, "train/prior_ent_max": 50.20827710328989, "train/prior_ent_mean": 24.982700041191062, "train/prior_ent_min": 12.780306523768745, "train/prior_ent_std": 8.839109854482526, "train/rep_loss_mean": 1.0000034061508563, "train/rep_loss_std": 0.0001038221473309525, "train/reward_avg": 0.002476601142889057, "train/reward_loss_mean": 0.017327896343899807, "train/reward_loss_std": 0.24321963117415807, "train/reward_max_data": 0.7944095474691247, "train/reward_max_pred": 0.31138302573007554, "train/reward_neg_acc": 0.9996109464060721, "train/reward_neg_loss": 0.002941259381890147, "train/reward_pos_acc": 0.20993885922492767, "train/reward_pos_loss": 3.937626130118662, "train/reward_pred": 0.0018586169257900449, "train/reward_rate": 0.003621623743718593, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.012632288038730621, "report/cont_loss_std": 0.15403245389461517, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 1.5901292562484741, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004891871940344572, "report/cont_pred": 0.993011474609375, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.069473035633564, "report/image_loss_std": 0.08573096990585327, "report/model_loss_mean": 0.6956683397293091, "report/model_loss_std": 0.38353729248046875, "report/post_ent_mag": 49.83757019042969, "report/post_ent_max": 49.83757019042969, "report/post_ent_mean": 23.446252822875977, "report/post_ent_min": 12.466253280639648, "report/post_ent_std": 8.350263595581055, "report/prior_ent_mag": 50.253910064697266, "report/prior_ent_max": 50.253910064697266, "report/prior_ent_mean": 23.725269317626953, "report/prior_ent_min": 12.664838790893555, "report/prior_ent_std": 8.215313911437988, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0020019530784338713, "report/reward_loss_mean": 0.013562943786382675, "report/reward_loss_std": 0.20489457249641418, "report/reward_max_data": 0.7437499761581421, "report/reward_max_pred": 0.12152862548828125, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0029229626525193453, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.6347033977508545, "report/reward_pred": 0.001613819389604032, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.024810107424855232, "eval/cont_loss_std": 0.4292276203632355, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.117808818817139, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0039687794633209705, "eval/cont_pred": 0.9960954189300537, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.0998382568359375, "eval/image_loss_std": 0.12421532720327377, "eval/model_loss_mean": 0.739328145980835, "eval/model_loss_std": 0.6401490569114685, "eval/post_ent_mag": 49.8376350402832, "eval/post_ent_max": 49.8376350402832, "eval/post_ent_mean": 24.682281494140625, "eval/post_ent_min": 12.633962631225586, "eval/post_ent_std": 9.068004608154297, "eval/prior_ent_mag": 48.60847473144531, "eval/prior_ent_max": 48.60847473144531, "eval/prior_ent_mean": 24.68494415283203, "eval/prior_ent_min": 12.5337553024292, "eval/prior_ent_std": 9.040478706359863, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0015289306174963713, "eval/reward_loss_mean": 0.014679723419249058, "eval/reward_loss_std": 0.28052210807800293, "eval/reward_max_data": 0.7875000238418579, "eval/reward_max_pred": 0.13622713088989258, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.002566542709246278, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.20451545715332, "eval/reward_pred": 0.0013239940162748098, "eval/reward_rate": 0.001953125, "replay/size": 1000000.0, "replay/inserts": 31824.0, "replay/samples": 31824.0, "replay/insert_wait_avg": 1.4667342570991958e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.08363646463631e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3304.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2688717599642479e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3488268852234, "timer/env.step_count": 3978.0, "timer/env.step_total": 42.11554169654846, "timer/env.step_frac": 0.04210085578615934, "timer/env.step_avg": 0.010587114554185133, "timer/env.step_min": 0.008589029312133789, "timer/env.step_max": 0.0403742790222168, "timer/replay._sample_count": 31824.0, "timer/replay._sample_total": 17.222781658172607, "timer/replay._sample_frac": 0.017216775983832578, "timer/replay._sample_avg": 0.0005411884633664092, "timer/replay._sample_min": 0.00042366981506347656, "timer/replay._sample_max": 0.011692523956298828, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4391.0, "timer/agent.policy_total": 50.42014718055725, "timer/agent.policy_frac": 0.05040256541065778, "timer/agent.policy_avg": 0.011482611519143078, "timer/agent.policy_min": 0.009649991989135742, "timer/agent.policy_max": 0.08434081077575684, "timer/dataset_train_count": 1989.0, "timer/dataset_train_total": 0.24608445167541504, "timer/dataset_train_frac": 0.000245998640735798, "timer/dataset_train_avg": 0.00012372270069151083, "timer/dataset_train_min": 0.0001068115234375, "timer/dataset_train_max": 0.00039958953857421875, "timer/agent.train_count": 1989.0, "timer/agent.train_total": 895.8498737812042, "timer/agent.train_frac": 0.8955374862292821, "timer/agent.train_avg": 0.4504021487084989, "timer/agent.train_min": 0.4371771812438965, "timer/agent.train_max": 0.703331708908081, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48494601249694824, "timer/agent.report_frac": 0.0004847769092776567, "timer/agent.report_avg": 0.24247300624847412, "timer/agent.report_min": 0.2358229160308838, "timer/agent.report_max": 0.24912309646606445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.00543212890625e-05, "timer/dataset_eval_frac": 4.004035413704563e-08, "timer/dataset_eval_avg": 4.00543212890625e-05, "timer/dataset_eval_min": 4.00543212890625e-05, "timer/dataset_eval_max": 4.00543212890625e-05, "fps": 31.812193396886954}
{"step": 1142696, "time": 36288.43695139885, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1143368, "time": 36309.24672484398, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1143536, "time": 36314.660655260086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1143760, "time": 36321.58768773079, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1143968, "time": 36328.040157556534, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 1144128, "time": 36332.99007344246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1144152, "time": 36333.506417512894, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1144160, "time": 36333.98102355003, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1144248, "time": 36336.47655963898, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 1144256, "time": 36336.96741938591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1144664, "time": 36349.59967160225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1144680, "time": 36350.098707675934, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1144928, "time": 36357.97893810272, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1145008, "time": 36360.45345234871, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1145144, "time": 36364.425204992294, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1145296, "time": 36369.45239281654, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1145416, "time": 36372.95010781288, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1145640, "time": 36379.87548184395, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1145904, "time": 36388.27238035202, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1146440, "time": 36404.73014450073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1146472, "time": 36405.72059106827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1146496, "time": 36406.693101644516, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1146528, "time": 36407.70097947121, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1146560, "time": 36408.68873977661, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1146568, "time": 36408.719541311264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1146752, "time": 36414.61828875542, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1147080, "time": 36425.05531692505, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1147192, "time": 36428.66620850563, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1147320, "time": 36432.612107515335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1147512, "time": 36438.526045799255, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1147608, "time": 36441.470828294754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1147640, "time": 36442.48728084564, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1147688, "time": 36443.968970775604, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1147968, "time": 36452.857919454575, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1148008, "time": 36453.87066912651, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1148184, "time": 36459.40660119057, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1148208, "time": 36460.38035273552, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1148472, "time": 36468.327714681625, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1148608, "time": 36472.75597524643, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1148752, "time": 36477.18398451805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1148992, "time": 36484.568282842636, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1149032, "time": 36485.57073402405, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1149080, "time": 36487.05853390694, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1149272, "time": 36493.09053850174, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1149416, "time": 36497.55452299118, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1149504, "time": 36500.53392601013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1149672, "time": 36505.48179268837, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1149728, "time": 36507.46447658539, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1149896, "time": 36512.42583298683, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1149960, "time": 36514.388328790665, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1150032, "time": 36517.28414607048, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 1150032, "time": 36517.532180309296, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 1150032, "time": 36518.68140697479, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1150032, "time": 36518.88332080841, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 1150032, "time": 36519.01781010628, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 1150032, "time": 36519.53848004341, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 1150032, "time": 36519.946343660355, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 1150032, "time": 36519.95333266258, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 1150280, "time": 36527.36470603943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1150440, "time": 36532.26091623306, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 1150648, "time": 36538.66418170929, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1150712, "time": 36540.664578676224, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1150808, "time": 36543.61728525162, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1150936, "time": 36547.547105550766, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1151000, "time": 36549.672785282135, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1151152, "time": 36554.60091662407, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1151688, "time": 36570.91498017311, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1151768, "time": 36573.37293624878, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1151768, "time": 36573.380902051926, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1151816, "time": 36574.88456749916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1151872, "time": 36576.854251384735, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1152128, "time": 36584.88671684265, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1152240, "time": 36588.33027124405, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 1152272, "time": 36589.34555768967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1152384, "time": 36592.79989004135, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1152520, "time": 36596.77938389778, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1152536, "time": 36597.2773399353, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1152632, "time": 36600.238636255264, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1152776, "time": 36604.70448255539, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1152960, "time": 36610.76383519173, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 1153184, "time": 36617.69014620781, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1153248, "time": 36619.689046382904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1153288, "time": 36620.709082365036, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1153472, "time": 36626.627202272415, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1153792, "time": 36636.4765856266, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 1154104, "time": 36646.04140114784, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1154160, "time": 36647.984533786774, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1154552, "time": 36659.85667872429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1154664, "time": 36663.29097485542, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1154696, "time": 36664.30246543884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1154832, "time": 36668.865151166916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1155496, "time": 36689.64531826973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1155520, "time": 36690.60919857025, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1155568, "time": 36692.08328509331, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1155592, "time": 36692.61166739464, "episode/length": 287.0, "episode/score": 0.10312499850988388, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.0}
{"step": 1155792, "time": 36699.15445113182, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1155928, "time": 36703.08007001877, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1156104, "time": 36708.462564229965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1156192, "time": 36711.39295172691, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 1156232, "time": 36712.396204948425, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1156272, "time": 36713.86810088158, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1156416, "time": 36718.289478302, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1156424, "time": 36718.31986832619, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1156592, "time": 36723.73218369484, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1156680, "time": 36726.19925260544, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1156848, "time": 36731.72485280037, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1156880, "time": 36732.71687793732, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1156920, "time": 36733.744505405426, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 1156920, "time": 36733.76302790642, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1157040, "time": 36737.65972161293, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1157056, "time": 36738.158777952194, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1157248, "time": 36744.08937692642, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1157456, "time": 36750.5181620121, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1157824, "time": 36761.98489689827, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1157880, "time": 36763.51076936722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1157952, "time": 36765.96340179443, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1158192, "time": 36773.38498020172, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1158496, "time": 36782.76318502426, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1158512, "time": 36783.280351400375, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1158616, "time": 36786.26142644882, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1158952, "time": 36796.77443289757, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1158984, "time": 36797.76287984848, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1158992, "time": 36798.25877690315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1159200, "time": 36804.66451835632, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1159232, "time": 36805.65229058266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1159296, "time": 36807.62690639496, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1159320, "time": 36808.16685771942, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1159360, "time": 36809.61894440651, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1159688, "time": 36819.67910838127, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1159792, "time": 36823.10262918472, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1159896, "time": 36826.08088731766, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 1159944, "time": 36827.5607919693, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1159968, "time": 36828.545773267746, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1160016, "time": 36830.41703629494, "eval_episode/length": 17.0, "eval_episode/score": 0.9468749761581421, "eval_episode/reward_rate": 0.05555555555555555}
{"step": 1160016, "time": 36831.35201048851, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 1160016, "time": 36831.893661022186, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1160016, "time": 36832.25180912018, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1160016, "time": 36832.98724222183, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 1160016, "time": 36834.070949077606, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1160016, "time": 36834.49169874191, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 1160016, "time": 36836.998527765274, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1160016, "time": 36837.006752491, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1160016, "time": 36837.015271663666, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1160016, "time": 36837.024935245514, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1160024, "time": 36837.05442357063, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1160544, "time": 36853.519018650055, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1160560, "time": 36854.017634153366, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 1160576, "time": 36854.513092279434, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1161024, "time": 36868.28839826584, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1161256, "time": 36875.269188165665, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 1161264, "time": 36875.7512152195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1161360, "time": 36878.842324733734, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1161424, "time": 36880.82970261574, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1161552, "time": 36884.78857922554, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1161624, "time": 36886.773748874664, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 1161792, "time": 36892.186903715134, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1161872, "time": 36894.65515470505, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1162088, "time": 36901.05447268486, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1162096, "time": 36901.529015779495, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1162104, "time": 36901.56038093567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1162128, "time": 36902.52837228775, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1162248, "time": 36906.01439356804, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1162544, "time": 36915.507803201675, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1162592, "time": 36916.98138618469, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1162768, "time": 36922.406994342804, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 1162832, "time": 36924.399492025375, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1162864, "time": 36925.38020157814, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1162888, "time": 36925.898345947266, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1163272, "time": 36937.95273900032, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1163320, "time": 36939.943878650665, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1163424, "time": 36943.36572551727, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1163464, "time": 36944.37121319771, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1163496, "time": 36945.37657928467, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1163792, "time": 36954.73144984245, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1163968, "time": 36960.16941285133, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1164104, "time": 36964.132071495056, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1164184, "time": 36966.612303733826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1164552, "time": 36978.11996507645, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1164648, "time": 36981.09629654884, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1164672, "time": 36982.06760931015, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1164856, "time": 36987.52887392044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1164928, "time": 36989.981785058975, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1164960, "time": 36990.96936750412, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1165232, "time": 36999.498733997345, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1165736, "time": 37014.785157203674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1165776, "time": 37016.24258351326, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1165776, "time": 37016.251856803894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1165808, "time": 37017.241361141205, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1165856, "time": 37018.72781586647, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1165872, "time": 37019.24111318588, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1166080, "time": 37025.66186976433, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1166296, "time": 37032.254294633865, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1166344, "time": 37033.736060619354, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1166664, "time": 37043.61337351799, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1166888, "time": 37050.54621767998, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1166920, "time": 37051.5295522213, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1167048, "time": 37055.469311237335, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1167192, "time": 37060.053414821625, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1167272, "time": 37062.518342256546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1167328, "time": 37064.49364757538, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 1167400, "time": 37066.51199936867, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1167448, "time": 37068.00409960747, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1167496, "time": 37069.49778842926, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1167672, "time": 37074.921216487885, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1167680, "time": 37075.39785838127, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1167792, "time": 37078.853888988495, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1167912, "time": 37082.31138443947, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1168064, "time": 37087.20806598663, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1168088, "time": 37087.72950696945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1168392, "time": 37097.274713516235, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1168392, "time": 37097.28293633461, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1168520, "time": 37101.26003217697, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1168520, "time": 37101.26808953285, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1168584, "time": 37103.23335123062, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1168656, "time": 37105.68118929863, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1168752, "time": 37108.65079379082, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1168944, "time": 37114.57375049591, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1169152, "time": 37121.12214803696, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1169288, "time": 37125.12505984306, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1169296, "time": 37125.60049057007, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1169336, "time": 37126.60950422287, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1169416, "time": 37129.085539102554, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1169600, "time": 37135.018879413605, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1169712, "time": 37138.48566651344, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1169752, "time": 37139.49820828438, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1169856, "time": 37142.93827295303, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1170000, "time": 37148.865054130554, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 1170000, "time": 37149.605879068375, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 1170000, "time": 37149.78550338745, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1170000, "time": 37149.79209661484, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 1170000, "time": 37149.842831373215, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 1170000, "time": 37149.91551446915, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1170000, "time": 37150.67298388481, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 1170000, "time": 37150.80912256241, "eval_episode/length": 5.0, "eval_episode/score": 0.984375, "eval_episode/reward_rate": 0.16666666666666666}
{"step": 1170032, "time": 37151.81843709946, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1170208, "time": 37157.24746513367, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1170624, "time": 37170.08988904953, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1170688, "time": 37172.09093117714, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1170824, "time": 37176.060983181, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1170832, "time": 37176.56246089935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1170928, "time": 37179.66747379303, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1171256, "time": 37189.576966524124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1171640, "time": 37201.929364681244, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1171768, "time": 37205.85452604294, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1171768, "time": 37205.86254668236, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1171856, "time": 37208.91750574112, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1171912, "time": 37210.415318250656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1172200, "time": 37219.28006672859, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1172304, "time": 37222.719470739365, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1172344, "time": 37223.732964754105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1172680, "time": 37234.09411406517, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1172936, "time": 37242.125116825104, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1173152, "time": 37249.023166418076, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1173240, "time": 37251.52252602577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1173312, "time": 37253.96559381485, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1173568, "time": 37261.86756181717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1173744, "time": 37267.283710479736, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1173760, "time": 37267.7797870636, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1173928, "time": 37272.815648794174, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1173960, "time": 37273.808844566345, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1174080, "time": 37277.73981785774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1174080, "time": 37277.7487308979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1174281, "time": 37284.809316158295, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.60652206883286, "train/action_min": 0.0, "train/action_std": 1.819935360942224, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01048676288602027, "train/actor_opt_grad_steps": 72305.0, "train/actor_opt_loss": -20.079198095533584, "train/adv_mag": 0.8144978242691117, "train/adv_max": 0.35515611641334766, "train/adv_mean": 0.0001999926351418988, "train/adv_min": -0.72860804079759, "train/adv_std": 0.02738577550785108, "train/cont_avg": 0.9942343355429293, "train/cont_loss_mean": 0.023043092250861603, "train/cont_loss_std": 0.2727338969707489, "train/cont_neg_acc": 0.18773533219490388, "train/cont_neg_loss": 3.1969086702423866, "train/cont_pos_acc": 0.9997965076355019, "train/cont_pos_loss": 0.004757891325609326, "train/cont_pred": 0.9942655009452743, "train/cont_rate": 0.9942343355429293, "train/dyn_loss_mean": 1.0000019103589683, "train/dyn_loss_std": 6.112647033568455e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12159736259285399, "train/extr_critic_critic_opt_grad_steps": 72305.0, "train/extr_critic_critic_opt_loss": 13202.285023082386, "train/extr_critic_mag": 1.4752009480890602, "train/extr_critic_max": 1.4752009480890602, "train/extr_critic_mean": 1.3575107587708368, "train/extr_critic_min": 0.9897308054596486, "train/extr_critic_std": 0.02770825591164105, "train/extr_return_normed_mag": 0.8343723681237962, "train/extr_return_normed_max": 0.2904048236933621, "train/extr_return_normed_mean": 0.05431617768199155, "train/extr_return_normed_min": -0.7392383512824473, "train/extr_return_normed_std": 0.03918030055597274, "train/extr_return_rate": 0.9996041444816974, "train/extr_return_raw_mag": 1.5937993369921288, "train/extr_return_raw_max": 1.5937993369921288, "train/extr_return_raw_mean": 1.3577107606512127, "train/extr_return_raw_min": 0.5641561620163195, "train/extr_return_raw_std": 0.039180300452492454, "train/extr_reward_mag": 0.2736450837116049, "train/extr_reward_max": 0.2736450837116049, "train/extr_reward_mean": 0.002209923946242215, "train/extr_reward_min": 4.214469832603377e-09, "train/extr_reward_std": 0.00869593894428978, "train/image_loss_mean": 0.07596452547368979, "train/image_loss_std": 0.09343492354482713, "train/model_loss_mean": 0.7170141926317504, "train/model_loss_std": 0.5190010938530016, "train/model_opt_grad_norm": 15.345989680049396, "train/model_opt_grad_steps": 72236.39393939394, "train/model_opt_loss": 4020.852842388731, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5606.060606060606, "train/policy_entropy_mag": 1.2952931944770043, "train/policy_entropy_max": 1.2952931944770043, "train/policy_entropy_mean": 0.09287433130572541, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11362036430474484, "train/policy_logprob_mag": 6.551080258205683, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09371528052019351, "train/policy_logprob_min": -6.551080258205683, "train/policy_logprob_std": 0.6347861672290648, "train/policy_randomness_mag": 0.6656490639604703, "train/policy_randomness_max": 0.6656490639604703, "train/policy_randomness_mean": 0.04772796797933, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05838932034869989, "train/post_ent_mag": 51.10419198238488, "train/post_ent_max": 51.10419198238488, "train/post_ent_mean": 24.600589106781314, "train/post_ent_min": 12.911081790924072, "train/post_ent_std": 9.055596142104179, "train/prior_ent_mag": 50.486376116974185, "train/prior_ent_max": 50.486376116974185, "train/prior_ent_mean": 25.030236571726174, "train/prior_ent_min": 12.474758615397443, "train/prior_ent_std": 9.04135374348573, "train/rep_loss_mean": 1.0000019103589683, "train/rep_loss_std": 6.112647033568455e-05, "train/reward_avg": 0.00252318719235564, "train/reward_loss_mean": 0.018005408543030347, "train/reward_loss_std": 0.2549559135140494, "train/reward_max_data": 0.8114898982975218, "train/reward_max_pred": 0.3188594254580411, "train/reward_neg_acc": 0.9995295850917546, "train/reward_neg_loss": 0.0030610701386732135, "train/reward_pos_acc": 0.1599206377309982, "train/reward_pos_loss": 4.142010596063402, "train/reward_pred": 0.0019004013409339494, "train/reward_rate": 0.003664575441919192, "train_stats/mean_log_entropy": 0.07994378561035116, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.024789851158857346, "report/cont_loss_std": 0.3358928859233856, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 4.259496212005615, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004011115990579128, "report/cont_pred": 0.9951000213623047, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08731544017791748, "report/image_loss_std": 0.10737871378660202, "report/model_loss_mean": 0.7195804715156555, "report/model_loss_std": 0.44239863753318787, "report/post_ent_mag": 48.889034271240234, "report/post_ent_max": 48.889034271240234, "report/post_ent_mean": 23.968360900878906, "report/post_ent_min": 11.678237915039062, "report/post_ent_std": 8.968464851379395, "report/prior_ent_mag": 46.996910095214844, "report/prior_ent_max": 46.996910095214844, "report/prior_ent_mean": 22.964927673339844, "report/prior_ent_min": 10.215532302856445, "report/prior_ent_std": 8.866336822509766, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008361816289834678, "report/reward_loss_mean": 0.007475132588297129, "report/reward_loss_std": 0.159522145986557, "report/reward_max_data": 0.856249988079071, "report/reward_max_pred": 0.06610536575317383, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002494304906576872, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.1028618812561035, "report/reward_pred": 0.0013493162114173174, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.01865091547369957, "eval/cont_loss_std": 0.25413641333580017, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 3.6919941902160645, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.004245647694915533, "eval/cont_pred": 0.9954097867012024, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.12634849548339844, "eval/image_loss_std": 0.11982150375843048, "eval/model_loss_mean": 0.7647338509559631, "eval/model_loss_std": 0.570557713508606, "eval/post_ent_mag": 49.46806335449219, "eval/post_ent_max": 49.46806335449219, "eval/post_ent_mean": 24.162158966064453, "eval/post_ent_min": 12.859746932983398, "eval/post_ent_std": 9.20097541809082, "eval/prior_ent_mag": 46.996910095214844, "eval/prior_ent_max": 46.996910095214844, "eval/prior_ent_mean": 23.50692367553711, "eval/prior_ent_min": 11.892974853515625, "eval/prior_ent_std": 8.952682495117188, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0029083252884447575, "eval/reward_loss_mean": 0.019734390079975128, "eval/reward_loss_std": 0.2797316908836365, "eval/reward_max_data": 0.828125, "eval/reward_max_pred": 0.15439748764038086, "eval/reward_neg_acc": 0.9980391263961792, "eval/reward_neg_loss": 0.0029151160269975662, "eval/reward_pos_acc": 0.25, "eval/reward_pos_loss": 4.308649063110352, "eval/reward_pred": 0.0017361387144774199, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 31712.0, "replay/samples": 31712.0, "replay/insert_wait_avg": 1.4369245374238817e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.148950356407435e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4560.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.424969288340786e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0356800556183, "timer/env.step_count": 3964.0, "timer/env.step_total": 41.80546045303345, "timer/env.step_frac": 0.04180396888509856, "timer/env.step_avg": 0.010546281648091183, "timer/env.step_min": 0.008878469467163086, "timer/env.step_max": 0.04845690727233887, "timer/replay._sample_count": 31712.0, "timer/replay._sample_total": 17.089109659194946, "timer/replay._sample_frac": 0.017088499940566635, "timer/replay._sample_avg": 0.000538884638597217, "timer/replay._sample_min": 0.00042629241943359375, "timer/replay._sample_max": 0.02940058708190918, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4534.0, "timer/agent.policy_total": 51.92183542251587, "timer/agent.policy_frac": 0.05191998291463777, "timer/agent.policy_avg": 0.011451661981145979, "timer/agent.policy_min": 0.009334325790405273, "timer/agent.policy_max": 0.09813523292541504, "timer/dataset_train_count": 1982.0, "timer/dataset_train_total": 0.251422643661499, "timer/dataset_train_frac": 0.00025141367320765577, "timer/dataset_train_avg": 0.0001268529988201307, "timer/dataset_train_min": 0.0001125335693359375, "timer/dataset_train_max": 0.0007343292236328125, "timer/agent.train_count": 1982.0, "timer/agent.train_total": 892.5470933914185, "timer/agent.train_frac": 0.8925152483977155, "timer/agent.train_avg": 0.45032648506126055, "timer/agent.train_min": 0.43810176849365234, "timer/agent.train_max": 0.8917500972747803, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4949684143066406, "timer/agent.report_frac": 0.000494950754436194, "timer/agent.report_avg": 0.2474842071533203, "timer/agent.report_min": 0.23819732666015625, "timer/agent.report_max": 0.2567710876464844, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7893978496178653e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 31.710210793717856}
{"step": 1174344, "time": 37286.58921170235, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1174360, "time": 37287.10949206352, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1174512, "time": 37291.99206209183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1174600, "time": 37294.46513295174, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1174800, "time": 37301.00468468666, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 1174904, "time": 37303.99927663803, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1175032, "time": 37307.93227362633, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 1175248, "time": 37314.77014350891, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1175320, "time": 37316.7847571373, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1175488, "time": 37322.21111536026, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1175664, "time": 37327.657942295074, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1175752, "time": 37330.283458948135, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1176048, "time": 37339.65752410889, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1176080, "time": 37340.65290594101, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 1176080, "time": 37340.66031193733, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1176336, "time": 37348.59238290787, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1176392, "time": 37350.09271001816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1176504, "time": 37353.56221365929, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1176648, "time": 37358.03695702553, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1176672, "time": 37359.148713588715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1176680, "time": 37359.178164958954, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1176800, "time": 37363.12029361725, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1176880, "time": 37365.56481552124, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1176960, "time": 37368.05127596855, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1177000, "time": 37369.06322431564, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1177096, "time": 37372.025872945786, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1177112, "time": 37372.52059340477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1177312, "time": 37378.89410829544, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1177456, "time": 37383.336690187454, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1177528, "time": 37385.30906176567, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 1177624, "time": 37388.339801073074, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1177896, "time": 37396.78229904175, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1178048, "time": 37401.73873782158, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1178104, "time": 37403.24053645134, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1178200, "time": 37406.20766091347, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1178624, "time": 37419.66607093811, "episode/length": 207.0, "episode/score": 0.3531250059604645, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.0}
{"step": 1178960, "time": 37430.06728029251, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1178992, "time": 37431.07238316536, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1179088, "time": 37434.03113722801, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1179408, "time": 37443.93996477127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1179424, "time": 37444.437915086746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1179464, "time": 37445.45025706291, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1179752, "time": 37455.12666773796, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1179768, "time": 37455.62759780884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1179792, "time": 37456.61157846451, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1180088, "time": 37466.689131975174, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 1180088, "time": 37466.97470331192, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1180088, "time": 37467.086003780365, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1180088, "time": 37467.48312807083, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 1180088, "time": 37467.88346362114, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1180088, "time": 37468.00334382057, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1180088, "time": 37468.214616298676, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 1180088, "time": 37468.3105802536, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1180112, "time": 37469.30417346954, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1180360, "time": 37476.7434926033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1180624, "time": 37485.288246154785, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1180800, "time": 37490.72157883644, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1181160, "time": 37501.60878992081, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1181192, "time": 37502.60346007347, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1181272, "time": 37505.100383758545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1181320, "time": 37506.59286427498, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1181400, "time": 37509.211591959, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1181728, "time": 37519.5474088192, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1181856, "time": 37523.50870466232, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1181920, "time": 37525.51069903374, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1182064, "time": 37529.95672082901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1182104, "time": 37530.977863788605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1182160, "time": 37532.9332280159, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1182272, "time": 37536.38570570946, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 1182616, "time": 37546.892743349075, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1182696, "time": 37549.38811826706, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1182936, "time": 37556.786707401276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1183056, "time": 37560.73814558983, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1183184, "time": 37564.69514942169, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 1183184, "time": 37564.70399308205, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1183424, "time": 37572.26972985268, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1183584, "time": 37577.2110478878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1183880, "time": 37586.13779616356, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1184024, "time": 37590.586029052734, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1184168, "time": 37595.03398299217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1184408, "time": 37602.62327337265, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1184472, "time": 37604.62222146988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1184488, "time": 37605.12019133568, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1184584, "time": 37608.08734893799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1184688, "time": 37611.54336166382, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1184808, "time": 37615.05208492279, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1184928, "time": 37619.009627103806, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1185208, "time": 37627.42753958702, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1185320, "time": 37631.016251564026, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1185496, "time": 37636.45799064636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1185608, "time": 37639.96614193916, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1185656, "time": 37641.44138622284, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1185752, "time": 37644.422773361206, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1185776, "time": 37645.39793539047, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1186000, "time": 37652.32944583893, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1186192, "time": 37658.36800861359, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1186304, "time": 37661.87171769142, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1186304, "time": 37661.87953662872, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1186384, "time": 37664.371475458145, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1186424, "time": 37665.38264966011, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1186784, "time": 37676.70403981209, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1186808, "time": 37677.21733880043, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1186856, "time": 37678.71343421936, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1187056, "time": 37685.1282119751, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1187072, "time": 37685.62763547897, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1187480, "time": 37698.13390159607, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1187504, "time": 37699.0995695591, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1187520, "time": 37699.601157188416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1187600, "time": 37702.05575180054, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1187632, "time": 37703.07523941994, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1187952, "time": 37713.47423839569, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1188168, "time": 37720.030341386795, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1188208, "time": 37721.48492860794, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1188312, "time": 37724.48125624657, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1188504, "time": 37730.398950338364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1188608, "time": 37733.84273481369, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1188624, "time": 37734.33871841431, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1188640, "time": 37734.838636398315, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1188928, "time": 37743.758675575256, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1189032, "time": 37746.75166606903, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1189088, "time": 37748.89118742943, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1189120, "time": 37749.889260053635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1189168, "time": 37751.37017083168, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1189296, "time": 37755.32707500458, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1189368, "time": 37757.33755469322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1189536, "time": 37762.755618572235, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1189648, "time": 37766.211606264114, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1189944, "time": 37775.131956100464, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 1189968, "time": 37776.106021642685, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1190008, "time": 37777.13178348541, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1190072, "time": 37780.57410740852, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1190072, "time": 37780.64714407921, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 1190072, "time": 37781.46503996849, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 1190072, "time": 37781.68206214905, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 1190072, "time": 37782.827471494675, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 1190072, "time": 37783.15217900276, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 1190072, "time": 37783.1588177681, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 1190072, "time": 37783.37714147568, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 1190104, "time": 37784.369349479675, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1190232, "time": 37788.310371637344, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1190344, "time": 37791.768795251846, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1190680, "time": 37802.14963841438, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1190896, "time": 37809.15234041214, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1190960, "time": 37811.12479496002, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1191480, "time": 37826.9356071949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1191544, "time": 37828.9109749794, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1191608, "time": 37830.874918460846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1191608, "time": 37830.8929669857, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1191688, "time": 37833.37858891487, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1192128, "time": 37847.364960193634, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1192168, "time": 37848.374675273895, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1192280, "time": 37851.864213466644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1192320, "time": 37853.3216149807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1192480, "time": 37858.274010419846, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1192616, "time": 37862.27772974968, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 1192760, "time": 37866.72890353203, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1192816, "time": 37868.81896543503, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 1192960, "time": 37873.244374513626, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 1192968, "time": 37873.27326631546, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1193016, "time": 37874.740607738495, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1193272, "time": 37882.64692759514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1193488, "time": 37889.49345302582, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1193656, "time": 37894.44735908508, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 1193808, "time": 37899.47567605972, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1193920, "time": 37902.92682480812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1194032, "time": 37906.38206219673, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1194168, "time": 37910.307069301605, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1194480, "time": 37920.14017510414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1194656, "time": 37925.55985879898, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1194688, "time": 37926.56436061859, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1195000, "time": 37936.051302194595, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1195096, "time": 37939.01219177246, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1195272, "time": 37944.41353750229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1195328, "time": 37946.3902220726, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1195440, "time": 37949.84840846062, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1195584, "time": 37954.305185079575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1195624, "time": 37955.327795267105, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 1195640, "time": 37955.853857278824, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1195648, "time": 37956.32947778702, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1195952, "time": 37965.85599350929, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1196208, "time": 37974.28704738617, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1196320, "time": 37977.77049279213, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1196480, "time": 37982.72982287407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1196608, "time": 37986.70815086365, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1196880, "time": 37995.272577524185, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1197296, "time": 38008.15548968315, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1197584, "time": 38017.11016082764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1197784, "time": 38023.24174427986, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1197952, "time": 38028.657686948776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1197960, "time": 38028.68902468681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1198024, "time": 38030.668164014816, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1198168, "time": 38035.11171603203, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1198360, "time": 38041.09772324562, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 1198424, "time": 38043.086889743805, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1198632, "time": 38049.6836335659, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1198792, "time": 38054.63769698143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1198888, "time": 38057.63295292854, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1199008, "time": 38061.56501722336, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1199152, "time": 38066.03583455086, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1199192, "time": 38067.043514728546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1199376, "time": 38072.931047677994, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1199504, "time": 38076.91151356697, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1199864, "time": 38087.87749314308, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1200056, "time": 38094.97440648079, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 1200056, "time": 38095.22714185715, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 1200056, "time": 38095.32109451294, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1200056, "time": 38095.50446128845, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 1200056, "time": 38095.66012811661, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1200056, "time": 38095.79262089729, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1200056, "time": 38096.128205776215, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 1200056, "time": 38096.513221502304, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 1200072, "time": 38097.012061834335, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1200096, "time": 38097.990364551544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1200384, "time": 38106.91365146637, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1200440, "time": 38108.59336256981, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1200712, "time": 38116.9779317379, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1200736, "time": 38117.9493830204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1200888, "time": 38122.424157619476, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1200936, "time": 38123.918189525604, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 1200944, "time": 38124.39371943474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1201072, "time": 38128.35687327385, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1201104, "time": 38129.344390153885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1201464, "time": 38140.36814689636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1201552, "time": 38143.3174533844, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1201656, "time": 38146.27772021294, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1201680, "time": 38147.24788093567, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1201752, "time": 38149.267339468, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1201768, "time": 38149.76749372482, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1202232, "time": 38164.05783486366, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1202368, "time": 38168.64344954491, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1202528, "time": 38173.565433979034, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1202696, "time": 38178.573186159134, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1202992, "time": 38187.9639377594, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1203048, "time": 38189.46994018555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1203256, "time": 38195.85940146446, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1203256, "time": 38195.86928296089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1203296, "time": 38197.33191823959, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1203344, "time": 38198.937999010086, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1203512, "time": 38203.89265704155, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1203992, "time": 38218.66836690903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1204064, "time": 38221.10701775551, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1204136, "time": 38223.116725444794, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1204248, "time": 38227.07795262337, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1204352, "time": 38230.66119337082, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1204536, "time": 38236.107868909836, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1205048, "time": 38251.89158368111, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1205240, "time": 38257.837819337845, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1205360, "time": 38261.873052835464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1205824, "time": 38276.1882083416, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1206089, "time": 38285.24391293526, "train_stats/mean_log_entropy": 0.07223013735479779, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5365404291967653, "train/action_min": 0.0, "train/action_std": 1.8274316655930563, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009641858903532053, "train/actor_opt_grad_steps": 74290.0, "train/actor_opt_loss": -18.60579748968383, "train/adv_mag": 0.8604638579502777, "train/adv_max": 0.34346316986946607, "train/adv_mean": 0.0018906356575524425, "train/adv_min": -0.7847384379137701, "train/adv_std": 0.03029077373744555, "train/cont_avg": 0.9941504396984925, "train/cont_loss_mean": 0.023162445198538616, "train/cont_loss_std": 0.27224246876772923, "train/cont_neg_acc": 0.2154558912368875, "train/cont_neg_loss": 3.0938735518138856, "train/cont_pos_acc": 0.999832263843498, "train/cont_pos_loss": 0.0049075587996604605, "train/cont_pred": 0.994002230802373, "train/cont_rate": 0.9941504396984925, "train/dyn_loss_mean": 1.000005351838155, "train/dyn_loss_std": 5.757656424006812e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10926140578529193, "train/extr_critic_critic_opt_grad_steps": 74290.0, "train/extr_critic_critic_opt_loss": 13106.192063834798, "train/extr_critic_mag": 1.5104940668422373, "train/extr_critic_max": 1.5104940668422373, "train/extr_critic_mean": 1.4003009382803835, "train/extr_critic_min": 1.0765521160921259, "train/extr_critic_std": 0.028664490657310988, "train/extr_return_normed_mag": 0.8650053398093985, "train/extr_return_normed_max": 0.33296518409671494, "train/extr_return_normed_mean": 0.058799366836422055, "train/extr_return_normed_min": -0.7708873059881393, "train/extr_return_normed_std": 0.04177401081925661, "train/extr_return_rate": 0.9995475737892803, "train/extr_return_raw_mag": 1.6763573106209837, "train/extr_return_raw_max": 1.6763573106209837, "train/extr_return_raw_mean": 1.4021915718538678, "train/extr_return_raw_min": 0.5725048205361294, "train/extr_return_raw_std": 0.041774010837976654, "train/extr_reward_mag": 0.3247354611679537, "train/extr_reward_max": 0.3247354611679537, "train/extr_reward_mean": 0.002437315995327604, "train/extr_reward_min": 1.7971249681022298e-09, "train/extr_reward_std": 0.009206815852067578, "train/image_loss_mean": 0.07583668339417209, "train/image_loss_std": 0.09325008320823387, "train/model_loss_mean": 0.7169806555886964, "train/model_loss_std": 0.5087945129179475, "train/model_opt_grad_norm": 15.237787419228098, "train/model_opt_grad_steps": 74219.02010050252, "train/model_opt_loss": 2677.3376403501884, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3743.718592964824, "train/policy_entropy_mag": 1.2686339700641345, "train/policy_entropy_max": 1.2686339700641345, "train/policy_entropy_mean": 0.08602006677257355, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09962040691369742, "train/policy_logprob_mag": 6.551080267633026, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08601681865639423, "train/policy_logprob_min": -6.551080267633026, "train/policy_logprob_std": 0.6238796234729901, "train/policy_randomness_mag": 0.6519489324272577, "train/policy_randomness_max": 0.6519489324272577, "train/policy_randomness_mean": 0.044205573448284186, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05119476525403147, "train/post_ent_mag": 50.79407234766975, "train/post_ent_max": 50.79407234766975, "train/post_ent_mean": 24.210872075066494, "train/post_ent_min": 12.601285594192582, "train/post_ent_std": 9.001811219220185, "train/prior_ent_mag": 49.97509702366201, "train/prior_ent_max": 49.97509702366201, "train/prior_ent_mean": 24.799272153844786, "train/prior_ent_min": 12.008089669385747, "train/prior_ent_std": 9.035545267651429, "train/rep_loss_mean": 1.000005351838155, "train/rep_loss_std": 5.757656424006812e-05, "train/reward_avg": 0.0025444452442584474, "train/reward_loss_mean": 0.017978292637172356, "train/reward_loss_std": 0.24461875037856437, "train/reward_max_data": 0.7866363085095008, "train/reward_max_pred": 0.3205323620657226, "train/reward_neg_acc": 0.9995320562142224, "train/reward_neg_loss": 0.0033046984723324527, "train/reward_pos_acc": 0.2030058856193836, "train/reward_pos_loss": 3.9182385496604137, "train/reward_pred": 0.002062935152222126, "train/reward_rate": 0.0037050486809045227, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.020299134775996208, "report/cont_loss_std": 0.22170299291610718, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.0920379161834717, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005226814188063145, "report/cont_pred": 0.9945447444915771, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07764545828104019, "report/image_loss_std": 0.0955989807844162, "report/model_loss_mean": 0.7186859846115112, "report/model_loss_std": 0.5199793577194214, "report/post_ent_mag": 46.07014465332031, "report/post_ent_max": 46.07014465332031, "report/post_ent_mean": 24.937217712402344, "report/post_ent_min": 12.420166969299316, "report/post_ent_std": 8.165742874145508, "report/prior_ent_mag": 46.46022033691406, "report/prior_ent_max": 46.46022033691406, "report/prior_ent_mean": 25.739459991455078, "report/prior_ent_min": 12.542064666748047, "report/prior_ent_std": 7.673349857330322, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0030303956009447575, "report/reward_loss_mean": 0.02074136957526207, "report/reward_loss_std": 0.2677587866783142, "report/reward_max_data": 0.8656250238418579, "report/reward_max_pred": 0.030454635620117188, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.004004273097962141, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.288700580596924, "report/reward_pred": 0.0021541332826018333, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.02783520519733429, "eval/cont_loss_std": 0.3280717134475708, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.473634243011475, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.006020683329552412, "eval/cont_pred": 0.9939846992492676, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.08769632875919342, "eval/image_loss_std": 0.09365469217300415, "eval/model_loss_mean": 0.73197340965271, "eval/model_loss_std": 0.5148109197616577, "eval/post_ent_mag": 46.39136505126953, "eval/post_ent_max": 46.39136505126953, "eval/post_ent_mean": 25.25045394897461, "eval/post_ent_min": 12.47342300415039, "eval/post_ent_std": 7.850911617279053, "eval/prior_ent_mag": 46.813232421875, "eval/prior_ent_max": 46.813232421875, "eval/prior_ent_mean": 26.00765609741211, "eval/prior_ent_min": 13.158465385437012, "eval/prior_ent_std": 7.453888416290283, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0023712157271802425, "eval/reward_loss_mean": 0.01644189842045307, "eval/reward_loss_std": 0.23027403652668, "eval/reward_max_data": 0.859375, "eval/reward_max_pred": 0.11587512493133545, "eval/reward_neg_acc": 0.999020516872406, "eval/reward_neg_loss": 0.003986509051173925, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.255425930023193, "eval/reward_pred": 0.00213055987842381, "eval/reward_rate": 0.0029296875, "replay/size": 1000000.0, "replay/inserts": 31808.0, "replay/samples": 31808.0, "replay/insert_wait_avg": 1.46148310340866e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.135074580939004e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3472.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3337569302677559e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4778287410736, "timer/env.step_count": 3976.0, "timer/env.step_total": 42.04709243774414, "timer/env.step_frac": 0.04202701072411875, "timer/env.step_avg": 0.010575224456173074, "timer/env.step_min": 0.008857250213623047, "timer/env.step_max": 0.040784597396850586, "timer/replay._sample_count": 31808.0, "timer/replay._sample_total": 17.067312002182007, "timer/replay._sample_frac": 0.017059160644927268, "timer/replay._sample_avg": 0.0005365729376943538, "timer/replay._sample_min": 0.0004279613494873047, "timer/replay._sample_max": 0.010994911193847656, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4410.0, "timer/agent.policy_total": 50.28747200965881, "timer/agent.policy_frac": 0.05026345468638401, "timer/agent.policy_avg": 0.011403054877473654, "timer/agent.policy_min": 0.009232044219970703, "timer/agent.policy_max": 0.09788393974304199, "timer/dataset_train_count": 1988.0, "timer/dataset_train_total": 0.2540624141693115, "timer/dataset_train_frac": 0.0002539410738256985, "timer/dataset_train_avg": 0.00012779799505498567, "timer/dataset_train_min": 0.00011205673217773438, "timer/dataset_train_max": 0.0005092620849609375, "timer/agent.train_count": 1988.0, "timer/agent.train_total": 896.1840195655823, "timer/agent.train_frac": 0.8957560016030272, "timer/agent.train_avg": 0.45079679052594684, "timer/agent.train_min": 0.43697381019592285, "timer/agent.train_max": 0.7212731838226318, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.5413341522216797, "timer/agent.report_frac": 0.0005410756107437723, "timer/agent.report_avg": 0.27066707611083984, "timer/agent.report_min": 0.2621164321899414, "timer/agent.report_max": 0.2792177200317383, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9311479362209537e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 31.792083515458618}
{"step": 1206296, "time": 38291.66022825241, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1206304, "time": 38292.13765048981, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1206448, "time": 38296.58868956566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1206536, "time": 38299.10662770271, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1206664, "time": 38303.04957818985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1206848, "time": 38308.97173333168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1207112, "time": 38316.85301423073, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1207296, "time": 38322.85165429115, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1207360, "time": 38324.82838988304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1207472, "time": 38328.27736949921, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1207568, "time": 38331.212505340576, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1207816, "time": 38338.6184899807, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1207824, "time": 38339.09158825874, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1208032, "time": 38345.49978041649, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1208136, "time": 38348.66820979118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1208304, "time": 38354.03570342064, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1208312, "time": 38354.06604003906, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1208392, "time": 38356.53434538841, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1208456, "time": 38358.52937054634, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1208568, "time": 38361.99868988991, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1208744, "time": 38367.44922876358, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1208872, "time": 38371.40038895607, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1209144, "time": 38379.918008327484, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1209168, "time": 38380.8768491745, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1209208, "time": 38381.88819479942, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1209232, "time": 38382.87764215469, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1209432, "time": 38388.825974702835, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1209488, "time": 38390.76594209671, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1209608, "time": 38394.25549650192, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1209872, "time": 38402.64324259758, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1210016, "time": 38407.07290196419, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1210040, "time": 38408.87323665619, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 1210040, "time": 38409.331043958664, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1210040, "time": 38409.65350651741, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 1210040, "time": 38409.87031793594, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 1210040, "time": 38410.56463479996, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 1210040, "time": 38410.63679623604, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 1210040, "time": 38411.07609653473, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 1210040, "time": 38411.671305179596, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1210496, "time": 38425.93419671059, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1210528, "time": 38426.94994139671, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1210624, "time": 38429.92780542374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1210648, "time": 38430.44716048241, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1210672, "time": 38431.43310713768, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1211056, "time": 38443.35936307907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1211296, "time": 38450.763046741486, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1211456, "time": 38455.69471216202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1211520, "time": 38457.68440437317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1211544, "time": 38458.211851358414, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1211592, "time": 38459.69582438469, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1211672, "time": 38462.18246245384, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1212120, "time": 38476.11932134628, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1212128, "time": 38476.598659038544, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 1212168, "time": 38477.60798573494, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1212176, "time": 38478.08465194702, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1212352, "time": 38483.498230695724, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1212368, "time": 38483.99482035637, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1212424, "time": 38485.746626377106, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1212464, "time": 38487.52818131447, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1212664, "time": 38493.48726940155, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1213056, "time": 38505.96261429787, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1213176, "time": 38509.44299221039, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1213200, "time": 38510.40630412102, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1213368, "time": 38515.3850479126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1213656, "time": 38524.26173496246, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 1213672, "time": 38524.76134800911, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1213784, "time": 38528.307218551636, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1213864, "time": 38530.82823443413, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1213880, "time": 38531.34887671471, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1214304, "time": 38544.63133978844, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1214344, "time": 38545.655109643936, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 1214440, "time": 38548.63339614868, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1214488, "time": 38550.10658097267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1214504, "time": 38550.600521564484, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1214648, "time": 38555.03617334366, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1214664, "time": 38555.5360686779, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1214736, "time": 38558.02109789848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1214920, "time": 38563.61440825462, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1214920, "time": 38563.62208485603, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 1215032, "time": 38567.07049250603, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1215376, "time": 38577.81609606743, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1215424, "time": 38579.3248693943, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1215624, "time": 38585.276589632034, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1215624, "time": 38585.2844851017, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1215688, "time": 38587.28032374382, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1215840, "time": 38592.29669594765, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 1215928, "time": 38594.77649021149, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1215976, "time": 38596.266293764114, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1216040, "time": 38598.26700282097, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 1216232, "time": 38604.222666502, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1216304, "time": 38606.70375776291, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 1216384, "time": 38609.164954423904, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1216384, "time": 38609.17465209961, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1216528, "time": 38613.63032960892, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1216528, "time": 38613.63817167282, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1216872, "time": 38624.18314623833, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1216904, "time": 38625.1764690876, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1217016, "time": 38628.63897061348, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1217160, "time": 38633.053094387054, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1217240, "time": 38635.53352665901, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1217336, "time": 38638.49044299126, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1217344, "time": 38638.96931672096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1217528, "time": 38644.42674303055, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1217624, "time": 38647.409596443176, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1217800, "time": 38652.976937532425, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1217992, "time": 38658.867367744446, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1218000, "time": 38659.34265899658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1218040, "time": 38660.36848807335, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1218392, "time": 38671.232306957245, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1218640, "time": 38679.26394176483, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1218704, "time": 38681.25022530556, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 1218792, "time": 38683.729560136795, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1218920, "time": 38687.68220925331, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1218976, "time": 38689.64113736153, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 1219216, "time": 38697.0380730629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1219552, "time": 38707.403989076614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1219704, "time": 38712.00893950462, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 1219752, "time": 38713.485301971436, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1219824, "time": 38715.955958366394, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 1220024, "time": 38721.92420721054, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1220024, "time": 38723.224741220474, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1220024, "time": 38723.635962724686, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 1220024, "time": 38723.965178489685, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 1220024, "time": 38724.07945561409, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1220024, "time": 38724.52540111542, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 1220024, "time": 38724.961700201035, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1220024, "time": 38725.01325130463, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 1220024, "time": 38725.32254195213, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 1220200, "time": 38730.75991177559, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 1220296, "time": 38733.72893834114, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1220352, "time": 38735.68397927284, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1220664, "time": 38745.78078341484, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1220840, "time": 38751.248455286026, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1220848, "time": 38751.71853637695, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1221016, "time": 38756.65512061119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1221096, "time": 38759.13825392723, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1221144, "time": 38760.611592531204, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1221152, "time": 38761.0901927948, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1221184, "time": 38762.08116197586, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1221392, "time": 38768.711033821106, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1221528, "time": 38772.67732191086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1221616, "time": 38775.64047193527, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1221848, "time": 38782.57157301903, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1221896, "time": 38784.072382450104, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 1222064, "time": 38789.49587106705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1222072, "time": 38789.526794433594, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1222120, "time": 38791.00745892525, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1222208, "time": 38793.95689415932, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 1222240, "time": 38794.945056438446, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 1222512, "time": 38803.49054431915, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1222520, "time": 38803.520917892456, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 1222760, "time": 38810.88790011406, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1222896, "time": 38815.30535650253, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1222952, "time": 38816.794014930725, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1223056, "time": 38820.223593235016, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1223136, "time": 38822.69532966614, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1223320, "time": 38828.16512417793, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1223704, "time": 38840.14160847664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1223816, "time": 38843.58828520775, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 1223928, "time": 38847.038007736206, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1223928, "time": 38847.04971289635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1224144, "time": 38853.95328974724, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1224272, "time": 38857.90644431114, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1224432, "time": 38862.98804759979, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1224432, "time": 38862.99800944328, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1224648, "time": 38869.42926836014, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1224736, "time": 38872.349466085434, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1224824, "time": 38874.84349370003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1224912, "time": 38877.78982615471, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1225200, "time": 38886.669878959656, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1225208, "time": 38886.70379424095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1225400, "time": 38892.797522068024, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1225496, "time": 38895.758564949036, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1225656, "time": 38900.70683979988, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1225968, "time": 38910.57232570648, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1226240, "time": 38919.13292217255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1226312, "time": 38921.12941408157, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1226776, "time": 38935.46635222435, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1226960, "time": 38941.38085579872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1227048, "time": 38943.90334606171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1227520, "time": 38958.82361841202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1227704, "time": 38964.28509402275, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1227808, "time": 38967.722912073135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1227864, "time": 38969.23724389076, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1227968, "time": 38972.676122903824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1228280, "time": 38982.202446460724, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 1228552, "time": 38990.569184064865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1228624, "time": 38993.01373887062, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1228632, "time": 38993.04339122772, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 1228944, "time": 39003.58015012741, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1228952, "time": 39003.61054086685, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1229088, "time": 39008.06194257736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1229224, "time": 39012.14170002937, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1229272, "time": 39013.64523983002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1229304, "time": 39014.63445901871, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1229440, "time": 39019.05578875542, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1229616, "time": 39024.515498161316, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1229680, "time": 39026.4753549099, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1229848, "time": 39031.4180688858, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1229952, "time": 39034.842781066895, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 1230008, "time": 39037.18477463722, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 1230008, "time": 39037.321204185486, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1230008, "time": 39037.39260554314, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 1230008, "time": 39037.835789203644, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 1230008, "time": 39038.74203467369, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 1230008, "time": 39038.76977992058, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 1230008, "time": 39038.929154634476, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 1230008, "time": 39039.50042319298, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1230016, "time": 39039.978098869324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1230176, "time": 39044.8989880085, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1230240, "time": 39046.89360713959, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 1230432, "time": 39052.80524945259, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1230488, "time": 39054.31115150452, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 1230520, "time": 39055.3228726387, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1230544, "time": 39056.290742874146, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1230600, "time": 39057.79070568085, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 1230624, "time": 39058.755715847015, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1230704, "time": 39061.23601984978, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1231008, "time": 39070.72236776352, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1231016, "time": 39070.75326061249, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1231264, "time": 39078.614164829254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1231368, "time": 39081.61132597923, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1231504, "time": 39086.036178827286, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1231520, "time": 39086.53613734245, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 1231528, "time": 39086.5658891201, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1231544, "time": 39087.06452131271, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1231648, "time": 39090.51694536209, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1231688, "time": 39091.52252936363, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1231856, "time": 39096.923198223114, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1231992, "time": 39101.05277109146, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1232072, "time": 39103.53318691254, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1232136, "time": 39105.52813911438, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1232336, "time": 39111.89190006256, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1232360, "time": 39112.41091299057, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1232616, "time": 39120.31705570221, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1232640, "time": 39121.281297922134, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1232696, "time": 39122.77731466293, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1232968, "time": 39131.304595947266, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1233136, "time": 39136.701628923416, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1233200, "time": 39138.67482948303, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1233224, "time": 39139.19874048233, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 1233320, "time": 39142.18738222122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1233376, "time": 39144.13091993332, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1233600, "time": 39151.04927897453, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1233624, "time": 39151.56846952438, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1233824, "time": 39157.95711660385, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1234088, "time": 39166.04988002777, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1234192, "time": 39169.49461078644, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1234208, "time": 39169.99128651619, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 1234304, "time": 39172.93117928505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1234344, "time": 39173.94290924072, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1234584, "time": 39181.34072327614, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1234672, "time": 39184.30402970314, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1234912, "time": 39191.79087996483, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1234928, "time": 39192.28804516792, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1234952, "time": 39192.809391498566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1235040, "time": 39195.756662130356, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1235040, "time": 39195.76435160637, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1235336, "time": 39204.751968860626, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 1235480, "time": 39209.232519865036, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1235544, "time": 39211.23588991165, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1235640, "time": 39214.2305958271, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1235736, "time": 39217.208986759186, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1235840, "time": 39220.791462898254, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1235920, "time": 39223.26762509346, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1236144, "time": 39230.1821949482, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1236208, "time": 39232.15818285942, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1236272, "time": 39234.151643037796, "episode/length": 7.0, "episode/score": 0.9781249761581421, "episode/reward_rate": 0.125, "episode/intrinsic_return": 0.0}
{"step": 1236392, "time": 39237.62022161484, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 1236400, "time": 39238.104279994965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1236648, "time": 39245.55725336075, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1237240, "time": 39264.494208574295, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1237288, "time": 39265.98645591736, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 1237360, "time": 39268.42692685127, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 1237384, "time": 39268.94799757004, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 1237792, "time": 39281.92108273506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1237881, "time": 39288.16841816902, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5577125741009734, "train/action_min": 0.0, "train/action_std": 1.8145319355193095, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010750239634249903, "train/actor_opt_grad_steps": 76280.0, "train/actor_opt_loss": -19.458060221456403, "train/adv_mag": 0.7817196618372472, "train/adv_max": 0.3335738194048704, "train/adv_mean": 0.0006940689271316809, "train/adv_min": -0.6955065688296179, "train/adv_std": 0.02826366357355561, "train/cont_avg": 0.9939443310301508, "train/cont_loss_mean": 0.02386437752869111, "train/cont_loss_std": 0.27429828965502917, "train/cont_neg_acc": 0.19736598289791663, "train/cont_neg_loss": 3.100459640415095, "train/cont_pos_acc": 0.999876533021879, "train/cont_pos_loss": 0.004953227420080098, "train/cont_pred": 0.9939996908657515, "train/cont_rate": 0.9939443310301508, "train/dyn_loss_mean": 1.0000037877403911, "train/dyn_loss_std": 0.0001038671719804219, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10386716021252937, "train/extr_critic_critic_opt_grad_steps": 76280.0, "train/extr_critic_critic_opt_loss": 12721.08679137877, "train/extr_critic_mag": 1.5429477475995395, "train/extr_critic_max": 1.5429477475995395, "train/extr_critic_mean": 1.422976647190113, "train/extr_critic_min": 1.120269752627042, "train/extr_critic_std": 0.029373590380477547, "train/extr_return_normed_mag": 0.7910618683201583, "train/extr_return_normed_max": 0.3249498815392729, "train/extr_return_normed_mean": 0.05908405524327527, "train/extr_return_normed_min": -0.6713001356652034, "train/extr_return_normed_std": 0.04147238148629066, "train/extr_return_rate": 0.9996087455270278, "train/extr_return_raw_mag": 1.6895365145937282, "train/extr_return_raw_max": 1.6895365145937282, "train/extr_return_raw_mean": 1.4236707549598349, "train/extr_return_raw_min": 0.6932864973892519, "train/extr_return_raw_std": 0.04147238161733102, "train/extr_reward_mag": 0.30584808450248374, "train/extr_reward_max": 0.30584808450248374, "train/extr_reward_mean": 0.0024335101690265027, "train/extr_reward_min": 1.0483228980596341e-07, "train/extr_reward_std": 0.009205431944161803, "train/image_loss_mean": 0.07636775503206493, "train/image_loss_std": 0.09341897673193533, "train/model_loss_mean": 0.7189151848380889, "train/model_loss_std": 0.5170571607486087, "train/model_opt_grad_norm": 15.338592332811212, "train/model_opt_grad_steps": 76207.65326633166, "train/model_opt_loss": 3790.7271869601914, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5276.381909547738, "train/policy_entropy_mag": 1.2827475424387946, "train/policy_entropy_max": 1.2827475424387946, "train/policy_entropy_mean": 0.08603791256046775, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.09923632252006674, "train/policy_logprob_mag": 6.551080262840693, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.08583693730471721, "train/policy_logprob_min": -6.551080262840693, "train/policy_logprob_std": 0.6226276147305666, "train/policy_randomness_mag": 0.659201873307252, "train/policy_randomness_max": 0.659201873307252, "train/policy_randomness_mean": 0.04421474438291698, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05099738473493849, "train/post_ent_mag": 49.31268086265679, "train/post_ent_max": 49.31268086265679, "train/post_ent_mean": 24.880495473967127, "train/post_ent_min": 12.898802522438855, "train/post_ent_std": 8.699191634978481, "train/prior_ent_mag": 49.55961087480861, "train/prior_ent_max": 49.55961087480861, "train/prior_ent_mean": 25.77023117027091, "train/prior_ent_min": 12.425136249868116, "train/prior_ent_std": 8.91223090617501, "train/rep_loss_mean": 1.0000037877403911, "train/rep_loss_std": 0.0001038671719804219, "train/reward_avg": 0.002688644647372456, "train/reward_loss_mean": 0.018680755334471038, "train/reward_loss_std": 0.2519157928035562, "train/reward_max_data": 0.7979428407235362, "train/reward_max_pred": 0.3439967835967864, "train/reward_neg_acc": 0.999507260382475, "train/reward_neg_loss": 0.003417233811883284, "train/reward_pos_acc": 0.21575295363481228, "train/reward_pos_loss": 3.916041263555869, "train/reward_pred": 0.0021607336066382463, "train/reward_rate": 0.00390625, "train_stats/mean_log_entropy": 0.07227224142601092, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.01830839365720749, "report/cont_loss_std": 0.2110433131456375, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 2.620026111602783, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005542361177504063, "report/cont_pred": 0.9936298727989197, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.06701802462339401, "report/image_loss_std": 0.08116233348846436, "report/model_loss_mean": 0.7048012614250183, "report/model_loss_std": 0.49412164092063904, "report/post_ent_mag": 47.286746978759766, "report/post_ent_max": 47.286746978759766, "report/post_ent_mean": 24.101009368896484, "report/post_ent_min": 13.45212173461914, "report/post_ent_std": 7.597558498382568, "report/prior_ent_mag": 53.02191925048828, "report/prior_ent_max": 53.02191925048828, "report/prior_ent_mean": 25.818004608154297, "report/prior_ent_min": 13.0175142288208, "report/prior_ent_std": 8.88697624206543, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002667236141860485, "report/reward_loss_mean": 0.019474811851978302, "report/reward_loss_std": 0.25375235080718994, "report/reward_max_data": 0.7906249761581421, "report/reward_max_pred": 0.27044224739074707, "report/reward_neg_acc": 0.9990195631980896, "report/reward_neg_loss": 0.004233004990965128, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.9061355590820312, "report/reward_pred": 0.0024106327909976244, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.021707192063331604, "eval/cont_loss_std": 0.2673565447330475, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.237847328186035, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.005173307843506336, "eval/cont_pred": 0.9948474764823914, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.10068099200725555, "eval/image_loss_std": 0.11445266753435135, "eval/model_loss_mean": 0.7477878928184509, "eval/model_loss_std": 0.6464401483535767, "eval/post_ent_mag": 47.462100982666016, "eval/post_ent_max": 47.462100982666016, "eval/post_ent_mean": 24.92819595336914, "eval/post_ent_min": 13.27364730834961, "eval/post_ent_std": 7.913541316986084, "eval/prior_ent_mag": 53.41844177246094, "eval/prior_ent_max": 53.41844177246094, "eval/prior_ent_mean": 26.7567081451416, "eval/prior_ent_min": 12.563040733337402, "eval/prior_ent_std": 9.35665225982666, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002688598819077015, "eval/reward_loss_mean": 0.025399668142199516, "eval/reward_loss_std": 0.3469245433807373, "eval/reward_max_data": 0.893750011920929, "eval/reward_max_pred": 0.05026888847351074, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.003717715386301279, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.55429744720459, "eval/reward_pred": 0.0019694583024829626, "eval/reward_rate": 0.00390625, "replay/size": 1000000.0, "replay/inserts": 31792.0, "replay/samples": 31792.0, "replay/insert_wait_avg": 1.4565566345621846e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.056901121595485e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3456.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3947762824870921e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2637274265289, "timer/env.step_count": 3974.0, "timer/env.step_total": 41.91276216506958, "timer/env.step_frac": 0.04190171153451942, "timer/env.step_avg": 0.010546744379735677, "timer/env.step_min": 0.008881807327270508, "timer/env.step_max": 0.03713345527648926, "timer/replay._sample_count": 31792.0, "timer/replay._sample_total": 17.04760193824768, "timer/replay._sample_frac": 0.01704310720344486, "timer/replay._sample_avg": 0.0005362230101361249, "timer/replay._sample_min": 0.0003960132598876953, "timer/replay._sample_max": 0.03368091583251953, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4406.0, "timer/agent.policy_total": 50.67070126533508, "timer/agent.policy_frac": 0.050657341535017254, "timer/agent.policy_avg": 0.011500386124678866, "timer/agent.policy_min": 0.009444236755371094, "timer/agent.policy_max": 0.09648489952087402, "timer/dataset_train_count": 1987.0, "timer/dataset_train_total": 0.25585341453552246, "timer/dataset_train_frac": 0.000255785956763403, "timer/dataset_train_avg": 0.00012876367113010692, "timer/dataset_train_min": 0.00011134147644042969, "timer/dataset_train_max": 0.0010623931884765625, "timer/agent.train_count": 1987.0, "timer/agent.train_total": 895.2434854507446, "timer/agent.train_frac": 0.8950074474399071, "timer/agent.train_avg": 0.45055031980409893, "timer/agent.train_min": 0.43784189224243164, "timer/agent.train_max": 0.8063535690307617, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4839146137237549, "timer/agent.report_frac": 0.0004837870258164482, "timer/agent.report_avg": 0.24195730686187744, "timer/agent.report_min": 0.23273253440856934, "timer/agent.report_max": 0.25118207931518555, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.4799934851566346e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 31.7828027053708}
{"step": 1237952, "time": 39290.399841308594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1237952, "time": 39290.4074883461, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1238136, "time": 39295.870794057846, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1238232, "time": 39298.84078001976, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1238232, "time": 39298.85129237175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1238440, "time": 39305.272107839584, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1238552, "time": 39308.8786406517, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 1238640, "time": 39311.81875348091, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1238704, "time": 39313.813677072525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1238920, "time": 39320.23578286171, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1239008, "time": 39323.1790933609, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 1239152, "time": 39327.62122249603, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1239240, "time": 39330.11524558067, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 1239304, "time": 39332.080629110336, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 1239360, "time": 39334.03663253784, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1239416, "time": 39335.54209065437, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 1239600, "time": 39341.594578027725, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1239656, "time": 39343.12253975868, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 1239856, "time": 39349.527136325836, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1239896, "time": 39350.53906393051, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1240096, "time": 39358.43690824509, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 1240096, "time": 39358.46447467804, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 1240096, "time": 39358.606862306595, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1240096, "time": 39359.406240701675, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 1240096, "time": 39359.47611737251, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1240096, "time": 39359.6594953537, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 1240096, "time": 39359.752732753754, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 1240096, "time": 39360.412806749344, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1240552, "time": 39374.34643864632, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 1240616, "time": 39376.33709144592, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1240912, "time": 39385.72294163704, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1241128, "time": 39392.16836261749, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1241208, "time": 39394.68642473221, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1241232, "time": 39395.68442249298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1241296, "time": 39397.695529699326, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 1241320, "time": 39398.27900338173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1241552, "time": 39405.81138730049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1241864, "time": 39415.24692964554, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1241888, "time": 39416.241916418076, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 1242040, "time": 39420.72868800163, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1242216, "time": 39426.18974137306, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1242472, "time": 39434.22898054123, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1242624, "time": 39439.15107345581, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1242928, "time": 39448.535610198975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1243088, "time": 39453.471997499466, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 1243440, "time": 39464.44680380821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1243512, "time": 39466.45229077339, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1243544, "time": 39467.45168995857, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1243712, "time": 39472.84171938896, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 1243960, "time": 39480.2369287014, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1244176, "time": 39487.04841351509, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1244352, "time": 39492.59027051926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1244480, "time": 39496.51386189461, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1244504, "time": 39497.027176856995, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1244784, "time": 39505.87958431244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1244912, "time": 39509.84394621849, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1245120, "time": 39516.24811792374, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1245240, "time": 39520.418850421906, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1245400, "time": 39525.34581589699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1245440, "time": 39526.801968336105, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 1245536, "time": 39529.77643060684, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1245752, "time": 39536.21193957329, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1245840, "time": 39539.12798666954, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1246040, "time": 39545.076004981995, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 1246520, "time": 39559.967807769775, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1246584, "time": 39561.93574500084, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 1246688, "time": 39565.36662340164, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1246792, "time": 39568.329976797104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1246880, "time": 39571.28012609482, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1246960, "time": 39573.72923541069, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1247096, "time": 39577.70469331741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1247432, "time": 39588.16057729721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1247584, "time": 39593.07936453819, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 1247584, "time": 39593.08743929863, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1247600, "time": 39593.58758473396, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1247712, "time": 39597.03509616852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1248104, "time": 39609.03630757332, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 1248152, "time": 39610.53288054466, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 1248312, "time": 39615.448217868805, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1248352, "time": 39616.906931877136, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 1248688, "time": 39627.27288413048, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1248728, "time": 39628.2954185009, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 1248888, "time": 39633.22607421875, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1249000, "time": 39636.68938136101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1249272, "time": 39645.19382882118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1249448, "time": 39650.598440885544, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 1249896, "time": 39664.43485021591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1249912, "time": 39664.93338608742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1250080, "time": 39672.0557179451, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 1250080, "time": 39673.075080394745, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 1250080, "time": 39673.22748160362, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 1250080, "time": 39674.475492954254, "eval_episode/length": 189.0, "eval_episode/score": 0.40937501192092896, "eval_episode/reward_rate": 0.005263157894736842}
{"step": 1250080, "time": 39675.368119716644, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 1250080, "time": 39675.79519176483, "eval_episode/length": 251.0, "eval_episode/score": 0.21562500298023224, "eval_episode/reward_rate": 0.003968253968253968}
{"step": 1250080, "time": 39676.082094192505, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 1250080, "time": 39676.59959435463, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1250080, "time": 39676.607466459274, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1250080, "time": 39676.61574959755, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1250128, "time": 39678.082228899, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 1250216, "time": 39680.57949876785, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1250576, "time": 39691.85899567604, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1250664, "time": 39694.315146923065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1250904, "time": 39701.802374362946, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1251040, "time": 39706.202204465866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1251120, "time": 39708.67574095726, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1251376, "time": 39716.6080019474, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1251384, "time": 39716.63742208481, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 1251448, "time": 39718.62195730209, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1251584, "time": 39723.0600566864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1251680, "time": 39726.04541730881, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 1251760, "time": 39728.65909361839, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1252080, "time": 39738.52478504181, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1252272, "time": 39744.49695277214, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1252312, "time": 39745.51422429085, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1252528, "time": 39752.41826462746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1252784, "time": 39760.48471903801, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1253136, "time": 39771.39328122139, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 1253168, "time": 39772.388573646545, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1253216, "time": 39773.87072920799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1253688, "time": 39788.85769248009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1253760, "time": 39791.30344867706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1254072, "time": 39800.70955348015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1254088, "time": 39801.20987415314, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1254392, "time": 39810.63144659996, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 1254512, "time": 39814.59257698059, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1254560, "time": 39816.07732129097, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 1254672, "time": 39819.680305719376, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 1254808, "time": 39823.63894510269, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1254984, "time": 39829.05327177048, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1255104, "time": 39832.96645283699, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1255408, "time": 39842.32044959068, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1255480, "time": 39844.32765293121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1255504, "time": 39845.28514480591, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 1255528, "time": 39845.806899785995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
